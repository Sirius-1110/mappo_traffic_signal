# MAPPO-TSC 调试记录（2026-02-02）

本文档用于持续记录 `marl_sigctrl`（MAPPO 多信号交叉口控制）在训练不稳定/疑似不收敛问题上的排查与修复过程，确保每一步都有“现象-证据-推断-改动-预期影响”的闭环。

## 0. 背景与现象（2026-02-02）

在 `exp_results` 中观察到部分实验的评估指标非常差，甚至低于 baseline，因此怀疑算法（self-attention/cross-attention + 聚类特征）存在实现错误或训练配置不合理。

我首先对比了如下实验输出：

- `exp_results/3roads_base_test_myself_250220_172109`
- `exp_results/3roads_mappo`
- `exp_results/3roads_sota`

并重点查看 `log/evaluator/evaluator_logger.txt` 与 `log/collector/collector_logger.txt`。

## 1. 关键发现 A：训练期间几乎没有进行评估（导致“看起来一直不收敛”的误判）

### 1.1 证据

在 `3roads_base_test_myself_250220_172109/total_config.py` 中，评估频率配置为：

- `policy.eval.evaluator.eval_freq = 1e+100`

这意味着训练循环里 `evaluator.should_eval(learner.train_iter)` 只有在 `train_iter=0` 时会触发一次评估，后续迭代几乎永远不会触发评估。

对应地，`3roads_base_test_myself_250220_172109/log/evaluator/evaluator_logger.txt` 仅出现一次评估记录（train_iter=0），例如 reward_mean 约为 `-2354`。

### 1.2 推断

如果你主要依据 `evaluator_logger` 或 `tensorboard` 中的 eval 曲线判断收敛，那么在 `eval_freq=1e100` 的情况下，曲线基本不会更新，会造成两类问题：

1) 误以为训练过程中评估指标“始终很差”。
2) 无法判断模型是否真的在变好（只能看到初始策略）。

同时需要注意：collector 的训练采样日志（`collector_logger`）是会持续刷新的，它反映的是训练数据分布下的回报，与 evaluator 的“固定评估”不是一回事。

### 1.3 已做修改

把多套配置中的 `eval_freq` 从 `1e100` 改为 `1000`，让训练期间能稳定地产生评估曲线：

- `signal_control/entry/sumo_config/sumo_3roads_mappo_baseline.py`
- `signal_control/entry/sumo_config/sumo_3roads_mappo_sota.py`
- `signal_control/entry/sumo_config/sumo_7roads_mappo_baseline.py`
- `signal_control/entry/sumo_config/sumo_7roads_mappo_sota.py`

修改目标：每 1000 次 training iteration 触发一次 evaluator，便于判断是否收敛、是否优于 baseline。

## 2. 关键发现 B：SOTA 模型的 cross-attention 调用与实现存在方向不一致

### 2.1 证据

在 `framework/ding/model/template/mavac_sota.py` 中，`compute_critic` 需要把 agent embedding 与 cluster embedding 通过 cross-attention 融合。

但原实现中，cross-attention 的输入顺序与使用方式不一致：

- `compute_critic` 里调用 `_cros_attn` 时，参数顺序出现了反置（cluster/agent 互换）。
- `CrosAttention.forward` 内部对 query/key/value 的来源与期望的输出形状也不一致，容易导致“注意力在不对的维度上做匹配”。

此外，训练过程中残留 `print` 会在长训练时显著拖慢速度并污染日志（尤其是多进程环境）。

### 2.2 已做修改

在 `framework/ding/model/template/mavac_sota.py` 中做了两处修复：

1) 统一 cross-attention 语义：以 **agent embedding 作为 query**，以 **cluster embedding 作为 key/value**，输出维度为 `(T, B, A, H)`，从而能与 self-attention 输出的 `(T, B, A, H)` 做逐元素融合。

2) 删除训练期间残留的 `print` 输出。

这部分修改的目的，是让“cluster 信息”以合理的注意力方式注入到每个 agent 的 critic 表达中，避免实现错误导致性能异常或训练不稳定。

## 3. 关键发现 C：环境 seed 被硬编码为 0（破坏复现与多进程多样性）

### 3.1 证据

在 `signal_control/smartcross/envs/sumo_env.py` 中，`seed(self, seed, dynamic_seed)` 原本会把 `seed` 与 `dynamic_seed` 强行改为 0。

这会导致：

- 你在命令行传入的 `--seed` 实际上不起作用。
- 多环境并行采样时，随机过程被人为锁死，可能降低数据多样性。
- 复现实验与对比实验（不同 seed）不成立，评估置信区间也会失真。

### 3.2 已做修改

修复 `SumoEnv.seed`：不再覆盖传入 seed，并同时设置 `numpy` 与 `random` 的随机种子。

## 4. 关键发现 D：`mavac.py` 的 sota 分支存在三个致命 bug（2026-02-08）

虽然 baseline 配置 `sota=False` 不会触发 `MAVAC.compute_critic` 的 sota 分支，但该分支的代码存在严重错误，必须修复以保持代码一致性和未来可用性。

### 4.1 Bug 列表

1) **冗余计算**（原第438行）：`clsnt_emb = self._agent_encoder(agent_state)` 计算了一个从未使用的变量，浪费计算资源且令人困惑。

2) **cross-attention 参数顺序错误**（原第441行）：`self._cros_attn(cls_emb, agent_emb)` 将 cluster embedding 作为第一个参数（被当作 query），agent embedding 作为第二个参数（被当作 key/value）。这与 `mavac_sota.py` 修复后的语义不一致，且会导致输出形状为 `(T, B, K, H)` 而非期望的 `(T, B, A, H)`，后续与 self-attention 输出的逐元素相加会产生维度错误或广播错误。

3) **critic_head 输入错误**（原第443行）：`x = self.critic_head(x)` 中的 `x` 仍然是原始的 obs dict，而不是 `integrate_emb` 拼接 `global_state` 后的张量。这意味着 critic 根本没有使用注意力融合后的特征，而是试图把一个 dict 传入 `nn.Sequential`，会直接报错。

### 4.2 已做修改

在 `framework/ding/model/template/mavac.py` 中修复了以上三个 bug：
- 删除冗余的 `clsnt_emb` 行
- 统一 cross-attention 调用顺序为 `_cros_attn(agent_emb, cls_emb)`
- 修复 critic_head 输入为 `critic_encoder(concat([integrate_emb, global_state]))`

## 5. `cls_state` 维度流转分析（2026-02-08）

### 5.1 数据流

环境 `_get_cls` 返回 `cls_state` 形状为 `(K, A, obs_dim)`，其中 K=`cls_num`（3roads 场景 K=1），A=`agent_num`（3roads 场景 A=3），obs_dim=174。

经过 collector 的 `default_collate`（batch 多个环境）后：
- `agent_state`: `(B, A, obs_dim)` = `(B, 3, 174)`
- `global_state`: `(B, A, global_obs_dim)` = `(B, 3, 442)`
- `cls_state`: `(B, K, A, obs_dim)` = `(B, 1, 3, 174)`

在 `compute_critic` 中，`single_step` 检测 `agent_state` 为 3 维后 `unsqueeze(0)`：
- `agent_state`: `(T=1, B, A, obs_dim)`
- `cls_state`: `(T=1, B, K, A, obs_dim)`

`ClsEncoder` 中 GCN 处理 `cls_state` 后 `torch.mean(dim=-2)` 在 agent 维度取均值：
- 输入: `(T, B, K, A, obs_dim)` → GCN → `(T, B, K, A, H=4)` → mean → `(T, B, K, H=4)`

cross-attention 中：
- `agent_emb`: `(T, B, A, H=4)`，作为 query
- `cls_emb`: `(T, B, K, H=4)`，作为 key/value
- `matmul(Q, K^T)`: `(T, B, A, K)` → softmax → `matmul(attn, V)`: `(T, B, A, H=4)`

最终 `integrate_emb` 形状为 `(T, B, A, H=4)`，与 `global_state` `(T, B, A, 442)` 拼接后为 `(T, B, A, 446)`，与 `critic_head` 输入维度 `global_obs_shape + 4 = 446` 匹配。

### 5.2 潜在风险

`cls_state` 没有在 `observation_space`（`sumo_obs.py` 中定义的 `gym.spaces.Dict`）中声明。DI-engine 的 `default_collate` 对 dict 类型数据是按 key 递归处理的，所以只要所有环境返回的 obs dict 结构一致，collate 就能正常工作。但如果框架内部有基于 `observation_space` 做 shape 校验的逻辑，可能会出问题。建议后续在 `sumo_obs.py` 中补充 `cls_state` 的声明。

## 6. 其他审查发现（2026-02-08）

### 6.1 `ppo.py` 残留 print

`framework/ding/policy/ppo.py` 原第144行有 `print("check", ...)` 残留调试语句，**已删除**。

### 6.2 `discount_factor` 差异

baseline 配置使用 `discount_factor=0.6`，而 sota 配置使用 `discount_factor=0.99`。这是一个非常大的差异：$\gamma=0.6$ 意味着模型只关注约 2-3 步的未来回报，而 $\gamma=0.99$ 则关注约 100 步。对于交通信号控制这种需要长期规划的任务，$\gamma=0.6$ 可能过低。建议在对比实验中统一 $\gamma$ 值，或者分别测试两个值的效果。

### 6.3 `sumo_train` 中硬编码的 Linux 路径

`signal_control/entry/sumo_train` 第6行 `sys.path.append(r"/home/cidi/mappo_traffic_signal/")` 是硬编码的 Linux 路径，在 Windows 上运行时需要修改。

## 7. 当前状态与下一步（2026-02-08 更新）

### 已完成的修复

| 文件 | 修改内容 |
|------|----------|
| `sumo_3roads_mappo_baseline.py` | `eval_freq`: 1e100 → 1000 |
| `sumo_3roads_mappo_sota.py` | `eval_freq`: 1e100 → 1000 |
| `sumo_7roads_mappo_baseline.py` | `eval_freq`: 1e100 → 1000 |
| `sumo_7roads_mappo_sota.py` | `eval_freq`: 1e100 → 1000 |
| `mavac_sota.py` | cross-attention 方向修复 + 删除残留 print |
| `mavac.py` | cross-attention 方向修复 + 删除冗余变量 + 修复 critic_head 输入 |
| `sumo_env.py` | seed 不再硬编码为 0 |
| `ppo.py` | 删除残留 `print("check", ...)` |

### 下一步建议

1) 当前 Windows 机器未安装 SUMO，无法直接跑训练。需要在有 SUMO 环境的机器上验证修复效果。
2) 修改 `sumo_train` 中的硬编码路径，或使用相对路径/环境变量。
3) 跑一个短训练确认 evaluator 日志按 1000 iter 频率更新。
4) 统一 baseline 与 sota 的 `discount_factor` 进行公平对比。
5) 考虑在 `sumo_obs.py` 中补充 `cls_state` 的 observation space 声明。

---

## 2026-02-09 Windows 验证结果

### 新增修复

| 文件 | 修改内容 |
|------|---------|
| `signal_control/entry/sumo_train` | 硬编码 Linux 路径改为动态计算（`_SCRIPT_DIR` + `_PROJECT_ROOT`） |
| `signal_control/smartcross/envs/__init__.py` | 不再自动 `from .sumo_env import SumoEnv`，避免多 `sys.path` 下重复注册 |

### 验证结果

**环境**：Windows + SUMO `D:\sumo` + Python 3.12 + PyTorch 2.5.1（CPU）

#### 1. Baseline 快速测试（eval_freq=5, train_iterations=10）
- iteration 0-9 全部完成，零报错
- evaluator 在 `train_iter=0` 和 `train_iter=8` 两次触发评估 → **eval_freq 修复验证通过**

#### 2. Baseline 完整训练（eval_freq=1000, 4 env）
- iteration 0-1000+ 完成，运行约 2.4 小时
- evaluator 在 `train_iter=0`（reward=-1265）和 `train_iter=1020`（reward=-1611）触发评估 → **eval_freq=1000 验证通过**

#### 3. Sota 快速测试（eval_freq=5, train_iterations=10, sota=True）
- iteration 0-11 全部完成，**cross-attention / self-attention / GCN 全部正常运行，零报错**
- value_loss 从 2096 稳步下降到 217
- evaluator 在 `train_iter=0`（reward=-1998）和 `train_iter=8`（reward=-1728，改善 270 分）触发评估
- → **cross-attention 修复验证通过**，模型在学习

### 结论

所有之前的修复（eval_freq / cross-attention / seed / mavac bug / 残留 print）均已在 Windows 上验证通过。训练流程完整运行，无报错。

### 验证命令模板（在有 SUMO 的 Linux 机器上执行）

```bash
# 进入项目根目录
cd /path/to/marl_sigctrl

# 3roads baseline 短训练（seed=42）
python signal_control/entry/sumo_train \
  -d signal_control/entry/sumo_config/sumo_3roads_mappo_baseline.py \
  -e signal_control/smartcross/envs/sumo_3roads_multi_agent_config.yaml \
  -s 42 \
  --exp-name debug_3roads_baseline_s42

# 3roads sota 短训练（seed=42）
python signal_control/entry/sumo_train \
  -d signal_control/entry/sumo_config/sumo_3roads_mappo_sota.py \
  -e signal_control/smartcross/envs/sumo_3roads_multi_agent_config.yaml \
  -s 42 \
  --exp-name debug_3roads_sota_s42

# 检查 evaluator 日志是否按 1000 iter 更新
tail -f debug_3roads_sota_s42/log/evaluator/evaluator_logger.txt
```
