[2025-02-20 17:23:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 12
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.16443786064545
avg_train_sample_per_sec: 16.16443786064545
avg_episode_per_sec: 0.13934860224694354
collect_time: 86.11496496200562
reward_mean: -344.5770891690009
reward_std: 31.921281341990788
reward_max: -283.78011204481794
reward_min: -400.5483193277311
queue_len: 0.22849939600066374
wait_time: 2.0655802108641867
delay_time: 17.765755164055495
pressure: 2.8288572060123784
total_envstep_count: 1392
total_train_sample_count: 1392
total_episode_count: 12
total_duration: 86.11496496200562
[2025-02-20 17:23:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.113474229231667
avg_train_sample_per_sec: 17.113474229231667
avg_episode_per_sec: 0.1475299502519971
collect_time: 40.669708013534546
reward_mean: -289.8267973856209
reward_std: 10.393485852373702
reward_max: -274.48109243697473
reward_min: -307.35154061624655
queue_len: 0.19219283646261334
wait_time: 1.792291408163619
delay_time: 15.041504468901378
pressure: 2.287577365163572
total_envstep_count: 2088
total_train_sample_count: 2088
total_episode_count: 18
total_duration: 126.78467297554016
[2025-02-20 17:24:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.690656606307789
avg_train_sample_per_sec: 15.690656606307789
avg_episode_per_sec: 0.13526428108886024
collect_time: 44.35760831832886
reward_mean: -244.59243697478993
reward_std: 10.649734780297692
reward_max: -229.43907563025218
reward_min: -257.87745098039215
queue_len: 0.1621965762432294
wait_time: 1.5542579321737533
delay_time: 11.793817028818816
pressure: 1.9540229885057467
total_envstep_count: 2784
total_train_sample_count: 2784
total_episode_count: 24
total_duration: 171.14228129386902
[2025-02-20 17:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.871181366373882
avg_train_sample_per_sec: 17.871181366373882
avg_episode_per_sec: 0.15406190833080935
collect_time: 38.945382833480835
reward_mean: -231.17355275443504
reward_std: 16.49826807365175
reward_max: -212.9719887955182
reward_min: -259.5308123249299
queue_len: 0.15329811190612402
wait_time: 1.5252989347816932
delay_time: 10.403475117725158
pressure: 1.8694739168877101
total_envstep_count: 3480
total_train_sample_count: 3480
total_episode_count: 30
total_duration: 210.08766412734985
[2025-02-20 17:25:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.030369363351664
avg_train_sample_per_sec: 18.030369363351664
avg_episode_per_sec: 0.1554342186495833
collect_time: 38.60153865814209
reward_mean: -204.6171802054155
reward_std: 10.578553212881154
reward_max: -190.34873949579838
reward_min: -222.34173669467793
queue_len: 0.13568778528210576
wait_time: 1.3493549497606292
delay_time: 9.067210627175777
pressure: 1.660698496905394
total_envstep_count: 4176
total_train_sample_count: 4176
total_episode_count: 36
total_duration: 248.68920278549194
[2025-02-20 17:26:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.36816535234666
avg_train_sample_per_sec: 18.36816535234666
avg_episode_per_sec: 0.1583462530374712
collect_time: 37.8916449546814
reward_mean: -184.14565826330534
reward_std: 7.427200767417585
reward_max: -177.87535014005604
reward_min: -199.8627450980392
queue_len: 0.12211250547964543
wait_time: 1.2113245386571956
delay_time: 7.863664814001542
pressure: 1.4725906277630416
total_envstep_count: 4872
total_train_sample_count: 4872
total_episode_count: 42
total_duration: 286.58084774017334
[2025-02-20 17:27:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.96447349592768
avg_train_sample_per_sec: 17.96447349592768
avg_episode_per_sec: 0.15486615082696278
collect_time: 38.743133783340454
reward_mean: -191.61986461251163
reward_std: 16.939804572015873
reward_max: -174.0217086834733
reward_min: -221.4348739495798
queue_len: 0.1270688757377398
wait_time: 1.2329870940418608
delay_time: 8.798546254845796
pressure: 1.5118258178603006
total_envstep_count: 5568
total_train_sample_count: 5568
total_episode_count: 48
total_duration: 325.3239815235138
[2025-02-20 17:27:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.898228969062647
avg_train_sample_per_sec: 18.898228969062647
avg_episode_per_sec: 0.16291576697467797
collect_time: 36.828847885131836
reward_mean: -174.2528011204482
reward_std: 8.150474666606536
reward_max: -163.7871148459384
reward_min: -187.30462184873952
queue_len: 0.11555225538491258
wait_time: 1.141707500860645
delay_time: 7.466239349928657
pressure: 1.406498673740053
total_envstep_count: 6264
total_train_sample_count: 6264
total_episode_count: 54
total_duration: 362.15282940864563
[2025-02-20 17:28:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.18627601918858
avg_train_sample_per_sec: 18.18627601918858
avg_episode_per_sec: 0.15677824154472914
collect_time: 38.27061676979065
reward_mean: -163.26949112978525
reward_std: 4.981190647456405
reward_max: -155.0
reward_min: -168.6008403361345
queue_len: 0.10826889332213878
wait_time: 1.0737748348676344
delay_time: 6.897261006721474
pressure: 1.306476569407604
total_envstep_count: 6960
total_train_sample_count: 6960
total_episode_count: 60
total_duration: 400.4234461784363
[2025-02-20 17:29:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.951997943785805
avg_train_sample_per_sec: 17.951997943785805
avg_episode_per_sec: 0.15475860296367072
collect_time: 38.770057916641235
reward_mean: -161.25420168067228
reward_std: 3.842906968815921
reward_max: -155.80602240896357
reward_min: -167.59383753501396
queue_len: 0.10693249448320442
wait_time: 1.0395751138651745
delay_time: 6.894155368189252
pressure: 1.2946507515473031
total_envstep_count: 7656
total_train_sample_count: 7656
total_episode_count: 66
total_duration: 439.1935040950775
[2025-02-20 17:29:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.176500799380833
avg_train_sample_per_sec: 18.176500799380833
avg_episode_per_sec: 0.15669397240845545
collect_time: 38.29119849205017
reward_mean: -159.24778244631185
reward_std: 9.424008616588635
reward_max: -151.72549019607848
reward_min: -179.91036414565832
queue_len: 0.10560197774954368
wait_time: 1.0172511312217194
delay_time: 6.910924605919266
pressure: 1.2705570291777188
total_envstep_count: 8352
total_train_sample_count: 8352
total_episode_count: 72
total_duration: 477.4847025871277
[2025-02-20 17:30:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.70386381928372
avg_train_sample_per_sec: 18.70386381928372
avg_episode_per_sec: 0.16124020533865274
collect_time: 37.211562633514404
reward_mean: -152.60049019607845
reward_std: 3.694672003399917
reward_max: -149.06582633053222
reward_min: -159.5413165266106
queue_len: 0.10119395901596713
wait_time: 0.9912726584886826
delay_time: 6.329283627889411
pressure: 1.232869142351901
total_envstep_count: 9048
total_train_sample_count: 9048
total_episode_count: 78
total_duration: 514.6962652206421
[2025-02-20 17:31:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.09273569177239
avg_train_sample_per_sec: 19.09273569177239
avg_episode_per_sec: 0.16459254906700335
collect_time: 36.45365500450134
reward_mean: -154.50770308123245
reward_std: 5.826539223732331
reward_max: -147.9768907563025
reward_min: -163.40476190476198
queue_len: 0.10245868904591014
wait_time: 0.999239273516657
delay_time: 6.601864979138269
pressure: 1.2270114942528736
total_envstep_count: 9744
total_train_sample_count: 9744
total_episode_count: 84
total_duration: 551.1499202251434
[2025-02-20 17:31:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.097847512545652
avg_train_sample_per_sec: 17.097847512545652
avg_episode_per_sec: 0.1473952371771177
collect_time: 40.706878423690796
reward_mean: -150.812675070028
reward_std: 3.928415864901171
reward_max: -146.08683473389362
reward_min: -158.00350140056022
queue_len: 0.10000840521885146
wait_time: 0.9860267493381084
delay_time: 6.240465016811175
pressure: 1.206896551724138
total_envstep_count: 10440
total_train_sample_count: 10440
total_episode_count: 90
total_duration: 591.8567986488342
[2025-02-20 17:32:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.979538323651415
avg_train_sample_per_sec: 16.979538323651415
avg_episode_per_sec: 0.1463753303763053
collect_time: 40.99051380157471
reward_mean: -144.36321195144723
reward_std: 2.446438591239033
reward_max: -141.4719887955182
reward_min: -148.9432773109244
queue_len: 0.09573157291210029
wait_time: 0.9548652905017002
delay_time: 5.986221612285962
pressure: 1.163129973474801
total_envstep_count: 11136
total_train_sample_count: 11136
total_episode_count: 96
total_duration: 632.8473124504089
[2025-02-20 17:33:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.285526557646577
avg_train_sample_per_sec: 18.285526557646577
avg_episode_per_sec: 0.15763384963488428
collect_time: 38.06289076805115
reward_mean: -145.6069094304388
reward_std: 4.9040438362339
reward_max: -139.01470588235293
reward_min: -152.9551820728291
queue_len: 0.09655630598835467
wait_time: 0.9491979594667224
delay_time: 6.017799595560063
pressure: 1.1784924845269673
total_envstep_count: 11832
total_train_sample_count: 11832
total_episode_count: 102
total_duration: 670.9102032184601
[2025-02-20 17:33:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.24626471787201
avg_train_sample_per_sec: 18.24626471787201
avg_episode_per_sec: 0.15729538549889663
collect_time: 38.14479351043701
reward_mean: -142.21055088702147
reward_std: 3.253949851050515
reward_max: -137.33963585434174
reward_min: -146.3676470588235
queue_len: 0.09430407883754738
wait_time: 0.9243640205861303
delay_time: 5.722528294799859
pressure: 1.1648983200707341
total_envstep_count: 12528
total_train_sample_count: 12528
total_episode_count: 108
total_duration: 709.0549967288971
[2025-02-20 17:34:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.659225004365773
avg_train_sample_per_sec: 18.659225004365773
avg_episode_per_sec: 0.16085538796867044
collect_time: 37.30058455467224
reward_mean: -142.63398692810458
reward_std: 3.883300398759854
reward_max: -136.51400560224087
reward_min: -148.53081232493
queue_len: 0.0945848719682391
wait_time: 0.9222314478399669
delay_time: 5.865760961405971
pressure: 1.1477674624226348
total_envstep_count: 13224
total_train_sample_count: 13224
total_episode_count: 114
total_duration: 746.3555812835693
[2025-02-20 17:35:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.983535544509554
avg_train_sample_per_sec: 17.983535544509554
avg_episode_per_sec: 0.15503047883197893
collect_time: 38.702067136764526
reward_mean: -139.69794584500468
reward_std: 5.25301429446298
reward_max: -130.4747899159664
reward_min: -145.84593837535013
queue_len: 0.09263789512268215
wait_time: 0.9111487875433107
delay_time: 5.62687466676329
pressure: 1.1385941644562332
total_envstep_count: 13920
total_train_sample_count: 13920
total_episode_count: 120
total_duration: 785.0576484203339
[2025-02-20 17:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.281852605449753
avg_train_sample_per_sec: 18.281852605449753
avg_episode_per_sec: 0.1576021776331875
collect_time: 38.07053995132446
reward_mean: -138.21323529411765
reward_std: 1.8981152720477337
reward_max: -135.99159663865544
reward_min: -140.5791316526611
queue_len: 0.09165333905445466
wait_time: 0.8953040212548325
delay_time: 5.723157606059002
pressure: 1.1142793987621573
total_envstep_count: 14616
total_train_sample_count: 14616
total_episode_count: 126
total_duration: 823.1281883716583
[2025-02-20 17:36:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.16562234590733
avg_train_sample_per_sec: 18.16562234590733
avg_episode_per_sec: 0.15660019263713215
collect_time: 38.314129114151
reward_mean: -141.7390289449113
reward_std: 2.8978270681112015
reward_max: -138.87114845938373
reward_min: -146.9642857142857
queue_len: 0.09399139850458309
wait_time: 0.9242174323310225
delay_time: 5.732505992866553
pressure: 1.1570512820512822
total_envstep_count: 15312
total_train_sample_count: 15312
total_episode_count: 132
total_duration: 861.4423174858093
[2025-02-20 17:36:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.624215524614094
avg_train_sample_per_sec: 18.624215524614094
avg_episode_per_sec: 0.16055358210874218
collect_time: 37.37070155143738
reward_mean: -140.0393323996265
reward_std: 4.546660894628959
reward_max: -135.48949579831927
reward_min: -148.15266106442579
queue_len: 0.09286427877959318
wait_time: 0.9130376399012302
delay_time: 5.717904726794984
pressure: 1.1384836427939875
total_envstep_count: 16008
total_train_sample_count: 16008
total_episode_count: 138
total_duration: 898.8130190372467
[2025-02-20 17:37:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.53718023121065
avg_train_sample_per_sec: 17.53718023121065
avg_episode_per_sec: 0.15118258820009184
collect_time: 39.68710994720459
reward_mean: -139.77894491129783
reward_std: 3.7830192399828766
reward_max: -134.3424369747899
reward_min: -145.95518207282907
queue_len: 0.09269160803136461
wait_time: 0.9120745225588024
delay_time: 5.689952826395042
pressure: 1.1434571175950485
total_envstep_count: 16704
total_train_sample_count: 16704
total_episode_count: 144
total_duration: 938.5001289844513
[2025-02-20 17:38:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.436350082442484
avg_train_sample_per_sec: 18.436350082442484
avg_episode_per_sec: 0.158934052434849
collect_time: 37.7515070438385
reward_mean: -134.01704014939307
reward_std: 3.704277299690898
reward_max: -127.64565826330534
reward_min: -139.95028011204477
queue_len: 0.08887071627943838
wait_time: 0.8670013429775091
delay_time: 5.42675153046666
pressure: 1.0932802829354553
total_envstep_count: 17400
total_train_sample_count: 17400
total_episode_count: 150
total_duration: 976.2516360282898
[2025-02-20 17:38:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.927554714292167
avg_train_sample_per_sec: 18.927554714292167
avg_episode_per_sec: 0.16316857512320834
collect_time: 36.77178645133972
reward_mean: -131.937558356676
reward_std: 2.8242277071027657
reward_max: -128.44957983193274
reward_min: -136.94397759103643
queue_len: 0.08749174957339256
wait_time: 0.8552488192447624
delay_time: 5.294803686546833
pressure: 1.0746021220159152
total_envstep_count: 18096
total_train_sample_count: 18096
total_episode_count: 156
total_duration: 1013.0234224796295
[2025-02-20 17:39:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.375783632109382
avg_train_sample_per_sec: 19.375783632109382
avg_episode_per_sec: 0.16703261751818432
collect_time: 35.921127796173096
reward_mean: -135.59068627450984
reward_std: 4.122529050216225
reward_max: -129.1981792717087
reward_min: -141.59313725490202
queue_len: 0.08991424819264578
wait_time: 0.87247038514787
delay_time: 5.535309283387785
pressure: 1.1031167108753317
total_envstep_count: 18792
total_train_sample_count: 18792
total_episode_count: 162
total_duration: 1048.9445502758026
[2025-02-20 17:40:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.81895263323106
avg_train_sample_per_sec: 18.81895263323106
avg_episode_per_sec: 0.16223235028647465
collect_time: 36.98399233818054
reward_mean: -135.30859010270777
reward_std: 2.924769040914615
reward_max: -130.89425770308125
reward_min: -139.5168067226891
queue_len: 0.08972718176572132
wait_time: 0.872953414345402
delay_time: 5.682724124491752
pressure: 1.10289566755084
total_envstep_count: 19488
total_train_sample_count: 19488
total_episode_count: 168
total_duration: 1085.9285426139832
[2025-02-20 17:40:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.139853635348764
avg_train_sample_per_sec: 17.139853635348764
avg_episode_per_sec: 0.14775735892542036
collect_time: 40.60711455345154
reward_mean: -137.453197945845
reward_std: 2.0150294414690832
reward_max: -135.74159663865547
reward_min: -141.55812324929974
queue_len: 0.0911493355078548
wait_time: 0.8911544281726838
delay_time: 5.756500974744216
pressure: 1.113284703801945
total_envstep_count: 20184
total_train_sample_count: 20184
total_episode_count: 174
total_duration: 1126.5356571674347
[2025-02-20 17:41:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.697038437253045
avg_train_sample_per_sec: 18.697038437253045
avg_episode_per_sec: 0.16118136583838832
collect_time: 37.225146770477295
reward_mean: -137.8831699346405
reward_std: 7.182379177128733
reward_max: -130.49159663865552
reward_min: -148.3039215686274
queue_len: 0.09143446282137964
wait_time: 0.887981032377584
delay_time: 5.747252923685589
pressure: 1.124447391688771
total_envstep_count: 20880
total_train_sample_count: 20880
total_episode_count: 180
total_duration: 1163.760803937912
[2025-02-20 17:42:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.938636917435765
avg_train_sample_per_sec: 18.938636917435765
avg_episode_per_sec: 0.16326411135720487
collect_time: 36.75026893615723
reward_mean: -134.30508870214751
reward_std: 3.1041177713233186
reward_max: -129.26610644257707
reward_min: -138.7044817927171
queue_len: 0.0890617299085859
wait_time: 0.861010186567996
delay_time: 5.600255080546521
pressure: 1.0904067197170646
total_envstep_count: 21576
total_train_sample_count: 21576
total_episode_count: 186
total_duration: 1200.5110728740692
[2025-02-20 17:42:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.80435879315939
avg_train_sample_per_sec: 19.80435879315939
avg_episode_per_sec: 0.170727230975512
collect_time: 35.143778562545776
reward_mean: -132.92133520074694
reward_std: 2.0135708697797154
reward_max: -130.90476190476195
reward_min: -136.97478991596637
queue_len: 0.08814412148590649
wait_time: 0.8535792301005283
delay_time: 5.528930495242967
pressure: 1.074712643678161
total_envstep_count: 22272
total_train_sample_count: 22272
total_episode_count: 192
total_duration: 1235.654851436615
[2025-02-20 17:43:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.679513430635673
avg_train_sample_per_sec: 19.679513430635673
avg_episode_per_sec: 0.16965097785030753
collect_time: 35.36672806739807
reward_mean: -133.13492063492063
reward_std: 3.440767229068938
reward_max: -129.48039215686276
reward_min: -138.0329131652661
queue_len: 0.08828575638920466
wait_time: 0.8527401013455781
delay_time: 5.528066740737621
pressure: 1.07736516357206
total_envstep_count: 22968
total_train_sample_count: 22968
total_episode_count: 198
total_duration: 1271.021579504013
[2025-02-20 17:43:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.67418024461949
avg_train_sample_per_sec: 19.67418024461949
avg_episode_per_sec: 0.1696050021087887
collect_time: 35.376315116882324
reward_mean: -132.5187908496732
reward_std: 3.2563813684987877
reward_max: -127.55742296918771
reward_min: -136.75350140056022
queue_len: 0.0878771822610565
wait_time: 0.8506754823945494
delay_time: 5.473073848977491
pressure: 1.0858753315649865
total_envstep_count: 23664
total_train_sample_count: 23664
total_episode_count: 204
total_duration: 1306.3978946208954
[2025-02-20 17:44:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.670023370400845
avg_train_sample_per_sec: 19.670023370400845
avg_episode_per_sec: 0.1695691669862142
collect_time: 35.38379120826721
reward_mean: -133.98961251167134
reward_std: 2.8577699056712027
reward_max: -130.13305322128855
reward_min: -138.41596638655457
queue_len: 0.08885252819076349
wait_time: 0.8587160107190533
delay_time: 5.598344557597719
pressure: 1.0811229000884175
total_envstep_count: 24360
total_train_sample_count: 24360
total_episode_count: 210
total_duration: 1341.7816858291626
[2025-02-20 17:45:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.886551861139214
avg_train_sample_per_sec: 18.886551861139214
avg_episode_per_sec: 0.1628151022512001
collect_time: 36.85161828994751
reward_mean: -132.14274042950515
reward_std: 1.6473766986219698
reward_max: -129.9138655462185
reward_min: -134.76820728291315
queue_len: 0.08762781195590529
wait_time: 0.8491008582920349
delay_time: 5.594597937669089
pressure: 1.0710654288240495
total_envstep_count: 25056
total_train_sample_count: 25056
total_episode_count: 216
total_duration: 1378.63330411911
[2025-02-20 17:45:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.432785034632
avg_train_sample_per_sec: 19.432785034632
avg_episode_per_sec: 0.16752400891924138
collect_time: 35.81576180458069
reward_mean: -135.4035947712418
reward_std: 5.7378755761527005
reward_max: -127.32983193277313
reward_min: -145.20658263305324
queue_len: 0.08979018220904632
wait_time: 0.8649190777106598
delay_time: 5.642184776298238
pressure: 1.0811229000884173
total_envstep_count: 25752
total_train_sample_count: 25752
total_episode_count: 222
total_duration: 1414.4490659236908
[2025-02-20 17:46:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.39760488880132
avg_train_sample_per_sec: 19.39760488880132
avg_episode_per_sec: 0.1672207318000114
collect_time: 35.88071846961975
reward_mean: -131.9609010270775
reward_std: 5.1084676357880365
reward_max: -125.01680672268904
reward_min: -137.71078431372553
queue_len: 0.08750722879779675
wait_time: 0.8531073459445669
delay_time: 5.471731257583229
pressure: 1.0668656056587091
total_envstep_count: 26448
total_train_sample_count: 26448
total_episode_count: 228
total_duration: 1450.3297843933105
[2025-02-20 17:47:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.152978033300503
avg_train_sample_per_sec: 19.152978033300503
avg_episode_per_sec: 0.16511187959741813
collect_time: 36.33899641036987
reward_mean: -135.14052287581697
reward_std: 3.8773011633932417
reward_max: -129.8179271708683
reward_min: -139.82983193277306
queue_len: 0.08961573135001126
wait_time: 0.8662824104000576
delay_time: 5.6915766708898525
pressure: 1.0898541114058355
total_envstep_count: 27144
total_train_sample_count: 27144
total_episode_count: 234
total_duration: 1486.6687808036804
[2025-02-20 17:47:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.96200749713769
avg_train_sample_per_sec: 18.96200749713769
avg_episode_per_sec: 0.16346558187187665
collect_time: 36.70497441291809
reward_mean: -131.4480625583567
reward_std: 3.255982219136149
reward_max: -127.51820728291315
reward_min: -137.28151260504202
queue_len: 0.08716715023763706
wait_time: 0.844198820111599
delay_time: 5.468285916949704
pressure: 1.05868700265252
total_envstep_count: 27840
total_train_sample_count: 27840
total_episode_count: 240
total_duration: 1523.3737552165985
[2025-02-20 17:48:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.255198604445177
avg_train_sample_per_sec: 19.255198604445177
avg_episode_per_sec: 0.16599309141763083
collect_time: 36.146082639694214
reward_mean: -134.73856209150327
reward_std: 2.9078677982472625
reward_max: -129.08333333333334
reward_min: -138.11274509803928
queue_len: 0.08934917910577139
wait_time: 0.8704772028174665
delay_time: 5.564846296412239
pressure: 1.085212201591512
total_envstep_count: 28536
total_train_sample_count: 28536
total_episode_count: 246
total_duration: 1559.5198378562927
[2025-02-20 17:48:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.982400605598304
avg_train_sample_per_sec: 18.982400605598304
avg_episode_per_sec: 0.16364138453101987
collect_time: 36.665541648864746
reward_mean: -130.63165266106446
reward_std: 4.657092813900787
reward_max: -126.00840336134456
reward_min: -137.4040616246499
queue_len: 0.08662576436410109
wait_time: 0.8395496350618057
delay_time: 5.50677234074725
pressure: 1.0551503094606545
total_envstep_count: 29232
total_train_sample_count: 29232
total_episode_count: 252
total_duration: 1596.1853795051575
[2025-02-20 17:49:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.071154031688984
avg_train_sample_per_sec: 19.071154031688984
avg_episode_per_sec: 0.16440650027318088
collect_time: 36.49490737915039
reward_mean: -131.05438842203546
reward_std: 2.547988944558399
reward_max: -127.39915966386557
reward_min: -134.13235294117652
queue_len: 0.08690609311806063
wait_time: 0.8367984351123297
delay_time: 5.451505357096097
pressure: 1.0600132625994694
total_envstep_count: 29928
total_train_sample_count: 29928
total_episode_count: 258
total_duration: 1632.6802868843079
[2025-02-20 17:50:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.262315263801227
avg_train_sample_per_sec: 19.262315263801227
avg_episode_per_sec: 0.16605444192932092
collect_time: 36.132728099823
reward_mean: -134.0236928104575
reward_std: 3.5440566820072834
reward_max: -129.2990196078431
reward_min: -140.27591036414566
queue_len: 0.08887512785839358
wait_time: 0.8610532962079614
delay_time: 5.6329936055716585
pressure: 1.079133510167993
total_envstep_count: 30624
total_train_sample_count: 30624
total_episode_count: 264
total_duration: 1668.8130149841309
[2025-02-20 17:50:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 20.897795071111233
avg_train_sample_per_sec: 20.897795071111233
avg_episode_per_sec: 0.18015340578544167
collect_time: 33.304949045181274
reward_mean: -130.6471755368814
reward_std: 4.19711126060339
reward_max: -125.15756302521008
reward_min: -138.1015406162465
queue_len: 0.08663605804832986
wait_time: 0.8337454676830943
delay_time: 5.4818665120427035
pressure: 1.0517241379310345
total_envstep_count: 31320
total_train_sample_count: 31320
total_episode_count: 270
total_duration: 1702.1179640293121
[2025-02-20 17:51:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.187035820616284
avg_train_sample_per_sec: 18.187035820616284
avg_episode_per_sec: 0.15678479155703695
collect_time: 38.269017934799194
reward_mean: -130.02310924369746
reward_std: 1.027426596939889
reward_max: -128.22128851540617
reward_min: -131.22338935574228
queue_len: 0.08622222098388425
wait_time: 0.8378484682997865
delay_time: 5.387506114021263
pressure: 1.04763483642794
total_envstep_count: 32016
total_train_sample_count: 32016
total_episode_count: 276
total_duration: 1740.3869819641113
[2025-02-20 17:52:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.441877009707824
avg_train_sample_per_sec: 18.441877009707824
avg_episode_per_sec: 0.15898169835955023
collect_time: 37.740193128585815
reward_mean: -131.3815359477124
reward_std: 2.6868290666423404
reward_max: -125.7514005602241
reward_min: -134.29341736694678
queue_len: 0.08712303444808515
wait_time: 0.8409175341224024
delay_time: 5.486393204213205
pressure: 1.0573607427055702
total_envstep_count: 32712
total_train_sample_count: 32712
total_episode_count: 282
total_duration: 1778.1271750926971
[2025-02-20 17:52:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.33236149933754
avg_train_sample_per_sec: 18.33236149933754
avg_episode_per_sec: 0.15803759913222018
collect_time: 37.965648889541626
reward_mean: -132.27626050420167
reward_std: 4.032578347798667
reward_max: -128.2717086834734
reward_min: -139.46708683473383
queue_len: 0.08771635311949712
wait_time: 0.8561247885537947
delay_time: 5.441049797559759
pressure: 1.0749336870026525
total_envstep_count: 33408
total_train_sample_count: 33408
total_episode_count: 288
total_duration: 1816.0928239822388
[2025-02-20 17:53:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 19.6476573210346
avg_train_sample_per_sec: 19.6476573210346
avg_episode_per_sec: 0.1693763562158155
collect_time: 35.424070596694946
reward_mean: -130.9611344537815
reward_std: 4.73933363762154
reward_max: -125.38375350140058
reward_min: -139.5700280112045
queue_len: 0.086844253616566
wait_time: 0.8423211901913729
delay_time: 5.558990686962104
pressure: 1.0570291777188328
total_envstep_count: 34104
total_train_sample_count: 34104
total_episode_count: 294
total_duration: 1851.5168945789337
[2025-02-20 17:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.27105551940685
avg_train_sample_per_sec: 30.27105551940685
avg_episode_per_sec: 0.26095737516730044
collect_time: 22.992260694503784
reward_mean: -131.1334033613445
reward_std: 2.985952758119165
reward_max: -126.20658263305319
reward_min: -135.20378151260502
queue_len: 0.08695849029266878
wait_time: 0.8442214197792292
delay_time: 5.4670724898036385
pressure: 1.0704022988505748
total_envstep_count: 34800
total_train_sample_count: 34800
total_episode_count: 300
total_duration: 1874.5091552734375
[2025-02-20 17:54:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79384387548379
avg_train_sample_per_sec: 31.79384387548379
avg_episode_per_sec: 0.2740848609955499
collect_time: 21.891030311584473
reward_mean: -128.76715686274505
reward_std: 2.6085567884529315
reward_max: -123.59033613445378
reward_min: -131.1750700280112
queue_len: 0.08538936131481768
wait_time: 0.8294849659580897
delay_time: 5.471349413703211
pressure: 1.037687886825818
total_envstep_count: 35496
total_train_sample_count: 35496
total_episode_count: 306
total_duration: 1896.400185585022
[2025-02-20 17:54:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.889194744835752
avg_train_sample_per_sec: 31.889194744835752
avg_episode_per_sec: 0.27490685124858405
collect_time: 21.82557463645935
reward_mean: -130.5842670401494
reward_std: 2.672502099800491
reward_max: -127.10084033613448
reward_min: -135.6743697478991
queue_len: 0.0865943415385606
wait_time: 0.8363559614827362
delay_time: 5.511970064871966
pressure: 1.056476569407604
total_envstep_count: 36192
total_train_sample_count: 36192
total_episode_count: 312
total_duration: 1918.2257602214813
[2025-02-20 17:54:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19495914387951
avg_train_sample_per_sec: 32.19495914387951
avg_episode_per_sec: 0.27754275124034056
collect_time: 21.61829113960266
reward_mean: -129.1970121381886
reward_std: 2.311249045843149
reward_max: -126.60574229691872
reward_min: -133.8816526610644
queue_len: 0.08567441123222054
wait_time: 0.8326485324456926
delay_time: 5.34182880689698
pressure: 1.0533819628647214
total_envstep_count: 36888
total_train_sample_count: 36888
total_episode_count: 318
total_duration: 1939.844051361084
[2025-02-20 17:55:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.752212202259475
avg_train_sample_per_sec: 31.752212202259475
avg_episode_per_sec: 0.2737259672608575
collect_time: 21.919732570648193
reward_mean: -128.6498599439776
reward_std: 5.252280233475343
reward_max: -121.46218487394954
reward_min: -135.35434173669464
queue_len: 0.08531157821218673
wait_time: 0.8267024205791955
delay_time: 5.334973196661772
pressure: 1.0394562334217505
total_envstep_count: 37584
total_train_sample_count: 37584
total_episode_count: 324
total_duration: 1961.7637839317322
[2025-02-20 17:55:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.894287066651682
avg_train_sample_per_sec: 31.894287066651682
avg_episode_per_sec: 0.27495075057458346
collect_time: 21.822089910507202
reward_mean: -130.60749299719888
reward_std: 6.532549888141649
reward_max: -123.7121848739496
reward_min: -143.74649859943975
queue_len: 0.08660974336684278
wait_time: 0.8372051517335493
delay_time: 5.471096126648102
pressure: 1.053492484526967
total_envstep_count: 38280
total_train_sample_count: 38280
total_episode_count: 330
total_duration: 1983.5858738422394
[2025-02-20 17:55:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.610212798285534
avg_train_sample_per_sec: 31.610212798285534
avg_episode_per_sec: 0.2725018344679787
collect_time: 22.018200397491455
reward_mean: -132.02217553688143
reward_std: 2.7281678200607677
reward_max: -127.61484593837537
reward_min: -136.2079831932773
queue_len: 0.0875478617618577
wait_time: 0.8562420436786563
delay_time: 5.434344246330535
pressure: 1.0683023872679045
total_envstep_count: 38976
total_train_sample_count: 38976
total_episode_count: 336
total_duration: 2005.6040742397308
[2025-02-20 17:56:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.66505428003388
avg_train_sample_per_sec: 31.66505428003388
avg_episode_per_sec: 0.272974605862361
collect_time: 21.980066537857056
reward_mean: -132.12628384687207
reward_std: 3.87928176247496
reward_max: -125.58613445378148
reward_min: -137.3074229691877
queue_len: 0.0876168991027003
wait_time: 0.8537298429539808
delay_time: 5.548904856321012
pressure: 1.0650972590627763
total_envstep_count: 39672
total_train_sample_count: 39672
total_episode_count: 342
total_duration: 2027.584140777588
[2025-02-20 17:56:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95674288524776
avg_train_sample_per_sec: 31.95674288524776
avg_episode_per_sec: 0.27548916280386
collect_time: 21.779441118240356
reward_mean: -132.2203548085901
reward_std: 2.392834724589015
reward_max: -129.18627450980392
reward_min: -135.78711484593842
queue_len: 0.08767928037704914
wait_time: 0.8520148222861205
delay_time: 5.487312045101745
pressure: 1.060897435897436
total_envstep_count: 40368
total_train_sample_count: 40368
total_episode_count: 348
total_duration: 2049.3635818958282
[2025-02-20 17:57:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07414777521988
avg_train_sample_per_sec: 32.07414777521988
avg_episode_per_sec: 0.2765012739243093
collect_time: 21.699719190597534
reward_mean: -129.6235994397759
reward_std: 2.592095032876139
reward_max: -126.13795518207283
reward_min: -134.31932773109241
queue_len: 0.08595729405820685
wait_time: 0.8370339515116393
delay_time: 5.289114201623824
pressure: 1.05316091954023
total_envstep_count: 41064
total_train_sample_count: 41064
total_episode_count: 354
total_duration: 2071.063301086426
[2025-02-20 17:57:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.821533722778106
avg_train_sample_per_sec: 30.821533722778106
avg_episode_per_sec: 0.26570287692050093
collect_time: 22.58161473274231
reward_mean: -129.8967086834734
reward_std: 2.7936582954577496
reward_max: -124.97128851540613
reward_min: -133.0077030812325
queue_len: 0.08613840098373567
wait_time: 0.8331451833607008
delay_time: 5.36435354931503
pressure: 1.0500663129973475
total_envstep_count: 41760
total_train_sample_count: 41760
total_episode_count: 360
total_duration: 2093.644915819168
[2025-02-20 17:57:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99139881091682
avg_train_sample_per_sec: 31.99139881091682
avg_episode_per_sec: 0.2757879207837657
collect_time: 21.755847692489624
reward_mean: -130.05999066293185
reward_std: 6.735156733134809
reward_max: -120.02801120448183
reward_min: -137.87254901960787
queue_len: 0.08624667815844288
wait_time: 0.8377796631473103
delay_time: 5.478900875966666
pressure: 1.045977011494253
total_envstep_count: 42456
total_train_sample_count: 42456
total_episode_count: 366
total_duration: 2115.4007635116577
[2025-02-20 17:58:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.18543701479256
avg_train_sample_per_sec: 32.18543701479256
avg_episode_per_sec: 0.2774606639206255
collect_time: 21.62468695640564
reward_mean: -127.31617647058823
reward_std: 5.475721658735899
reward_max: -117.45868347338934
reward_min: -134.5266106442577
queue_len: 0.08442717272585426
wait_time: 0.8250862347591558
delay_time: 5.310151475062377
pressure: 1.0249778956675508
total_envstep_count: 43152
total_train_sample_count: 43152
total_episode_count: 372
total_duration: 2137.0254504680634
[2025-02-20 17:58:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04273706136317
avg_train_sample_per_sec: 32.04273706136317
avg_episode_per_sec: 0.2762304919083032
collect_time: 21.720990896224976
reward_mean: -131.05030345471525
reward_std: 2.447337810007681
reward_max: -127.21988795518209
reward_min: -135.4474789915966
queue_len: 0.08690338425378992
wait_time: 0.849668791035424
delay_time: 5.443081674352729
pressure: 1.0675287356321839
total_envstep_count: 43848
total_train_sample_count: 43848
total_episode_count: 378
total_duration: 2158.7464413642883
[2025-02-20 17:58:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.005001104187585
avg_train_sample_per_sec: 32.005001104187585
avg_episode_per_sec: 0.27590518193265157
collect_time: 21.746601343154907
reward_mean: -127.00361811391224
reward_std: 2.992308647894663
reward_max: -121.03991596638657
reward_min: -130.09383753501405
queue_len: 0.08421990591108237
wait_time: 0.8183392278219864
delay_time: 5.325761118807749
pressure: 1.0264146772767462
total_envstep_count: 44544
total_train_sample_count: 44544
total_episode_count: 384
total_duration: 2180.4930427074432
[2025-02-20 17:59:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.820816714820428
avg_train_sample_per_sec: 31.820816714820428
avg_episode_per_sec: 0.2743173854725899
collect_time: 21.872474431991577
reward_mean: -124.28408029878615
reward_std: 2.4223708960371337
reward_max: -120.93697478991596
reward_min: -128.86764705882356
queue_len: 0.08241649887187412
wait_time: 0.7987950816931547
delay_time: 5.137975265840002
pressure: 1.0019893899204244
total_envstep_count: 45240
total_train_sample_count: 45240
total_episode_count: 390
total_duration: 2202.365517139435
[2025-02-20 17:59:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.867719051273152
avg_train_sample_per_sec: 31.867719051273152
avg_episode_per_sec: 0.2747217159592513
collect_time: 21.840282917022705
reward_mean: -125.07703081232494
reward_std: 4.897275989332836
reward_max: -116.35994397759104
reward_min: -130.75490196078437
queue_len: 0.0829423281248839
wait_time: 0.8035048679064906
delay_time: 5.182854548741642
pressure: 1.0122679045092837
total_envstep_count: 45936
total_train_sample_count: 45936
total_episode_count: 396
total_duration: 2224.2058000564575
[2025-02-20 17:59:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.903233574941936
avg_train_sample_per_sec: 31.903233574941936
avg_episode_per_sec: 0.2750278756460512
collect_time: 21.815970420837402
reward_mean: -126.24147992530345
reward_std: 4.62070106454754
reward_max: -118.46988795518206
reward_min: -132.9859943977591
queue_len: 0.0837145092342861
wait_time: 0.8117151259265865
delay_time: 5.2007039019515355
pressure: 1.0240937223695845
total_envstep_count: 46632
total_train_sample_count: 46632
total_episode_count: 402
total_duration: 2246.021770477295
[2025-02-20 18:00:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639447185652262
avg_train_sample_per_sec: 31.639447185652262
avg_episode_per_sec: 0.2727538550487264
collect_time: 21.99785590171814
reward_mean: -126.33286647992531
reward_std: 3.9674060718800264
reward_max: -120.83963585434176
reward_min: -132.4915966386555
queue_len: 0.08377511039782846
wait_time: 0.8160301919176159
delay_time: 5.20467331339467
pressure: 1.0299513704686118
total_envstep_count: 47328
total_train_sample_count: 47328
total_episode_count: 408
total_duration: 2268.019626379013
[2025-02-20 18:00:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.949068779502554
avg_train_sample_per_sec: 31.949068779502554
avg_episode_per_sec: 0.2754230067198496
collect_time: 21.784672498703003
reward_mean: -128.20751633986927
reward_std: 2.1739697909034073
reward_max: -125.87815126050415
reward_min: -131.86764705882356
queue_len: 0.08501824690972763
wait_time: 0.8223629748097294
delay_time: 5.314130818559552
pressure: 1.037687886825818
total_envstep_count: 48024
total_train_sample_count: 48024
total_episode_count: 414
total_duration: 2289.804298877716
[2025-02-20 18:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.22396698189169
avg_train_sample_per_sec: 31.22396698189169
avg_episode_per_sec: 0.2691721291542387
collect_time: 22.290569305419922
reward_mean: -128.17355275443512
reward_std: 3.893012472373553
reward_max: -122.53221288515408
reward_min: -134.1827731092436
queue_len: 0.08499572463821957
wait_time: 0.8279430804151898
delay_time: 5.2606889060401265
pressure: 1.029398762157383
total_envstep_count: 48720
total_train_sample_count: 48720
total_episode_count: 420
total_duration: 2312.094868183136
[2025-02-20 18:01:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09098743760667
avg_train_sample_per_sec: 32.09098743760667
avg_episode_per_sec: 0.2766464434276437
collect_time: 21.688332319259644
reward_mean: -131.53092903828198
reward_std: 1.8307387229976462
reward_max: -128.03851540616247
reward_min: -133.7514005602241
queue_len: 0.08722210148427186
wait_time: 0.8547537936483168
delay_time: 5.465717669387108
pressure: 1.062997347480106
total_envstep_count: 49416
total_train_sample_count: 49416
total_episode_count: 426
total_duration: 2333.7832005023956
[2025-02-20 18:01:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.803727808598975
avg_train_sample_per_sec: 31.803727808598975
avg_episode_per_sec: 0.2741700673155084
collect_time: 21.88422703742981
reward_mean: -127.26400560224089
reward_std: 3.9970015579598432
reward_max: -120.5546218487395
reward_min: -131.92787114845936
queue_len: 0.08439257665931092
wait_time: 0.81714330294452
delay_time: 5.341569832232541
pressure: 1.0354774535809017
total_envstep_count: 50112
total_train_sample_count: 50112
total_episode_count: 432
total_duration: 2355.6674275398254
[2025-02-20 18:02:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96930108405514
avg_train_sample_per_sec: 31.96930108405514
avg_episode_per_sec: 0.2755974231384064
collect_time: 21.770885705947876
reward_mean: -130.0528711484594
reward_std: 1.7570940551948202
reward_max: -127.47268907563026
reward_min: -133.1078431372549
queue_len: 0.08624195699499959
wait_time: 0.8359743212050513
delay_time: 5.443704911657729
pressure: 1.0579133510167993
total_envstep_count: 50808
total_train_sample_count: 50808
total_episode_count: 438
total_duration: 2377.4383132457733
[2025-02-20 18:02:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.884567911974763
avg_train_sample_per_sec: 31.884567911974763
avg_episode_per_sec: 0.2748669647584031
collect_time: 21.828741788864136
reward_mean: -127.2095004668534
reward_std: 3.1330576669492904
reward_max: -122.39915966386555
reward_min: -132.0266106442577
queue_len: 0.0843564326703272
wait_time: 0.8208832383528124
delay_time: 5.283669050584456
pressure: 1.0267462422634837
total_envstep_count: 51504
total_train_sample_count: 51504
total_episode_count: 444
total_duration: 2399.2670550346375
[2025-02-20 18:02:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.58247422106015
avg_train_sample_per_sec: 31.58247422106015
avg_episode_per_sec: 0.2722627088022427
collect_time: 22.037538766860962
reward_mean: -128.36297852474323
reward_std: 2.81649369353354
reward_max: -124.55252100840337
reward_min: -132.35854341736695
queue_len: 0.08512133854425945
wait_time: 0.8277113564258595
delay_time: 5.279622025086534
pressure: 1.0387931034482758
total_envstep_count: 52200
total_train_sample_count: 52200
total_episode_count: 450
total_duration: 2421.3045938014984
[2025-02-20 18:03:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.943709374702397
avg_train_sample_per_sec: 31.943709374702397
avg_episode_per_sec: 0.27537680495433103
collect_time: 21.78832745552063
reward_mean: -126.92075163398692
reward_std: 3.8817312289409256
reward_max: -119.89285714285714
reward_min: -132.2443977591036
queue_len: 0.08416495466444757
wait_time: 0.8088829696334766
delay_time: 5.223840838544771
pressure: 1.0363616268788685
total_envstep_count: 52896
total_train_sample_count: 52896
total_episode_count: 456
total_duration: 2443.092921257019
[2025-02-20 18:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95669915667614
avg_train_sample_per_sec: 31.95669915667614
avg_episode_per_sec: 0.275488785833415
collect_time: 21.779470920562744
reward_mean: -130.10901027077497
reward_std: 2.944408839902357
reward_max: -125.8018207282913
reward_min: -134.8564425770308
queue_len: 0.08627918452969162
wait_time: 0.8317190824163442
delay_time: 5.403058978156488
pressure: 1.0543766578249338
total_envstep_count: 53592
total_train_sample_count: 53592
total_episode_count: 462
total_duration: 2464.872392177582
[2025-02-20 18:04:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10594851459502
avg_train_sample_per_sec: 32.10594851459502
avg_episode_per_sec: 0.27677541822926743
collect_time: 21.67822575569153
reward_mean: -125.55112044817929
reward_std: 1.4817360692117225
reward_max: -123.38585434173672
reward_min: -127.39215686274505
queue_len: 0.08325671117253268
wait_time: 0.8076346475814021
delay_time: 5.14662960318494
pressure: 1.020446507515473
total_envstep_count: 54288
total_train_sample_count: 54288
total_episode_count: 468
total_duration: 2486.5506179332733
[2025-02-20 18:04:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01139693601197
avg_train_sample_per_sec: 32.01139693601197
avg_episode_per_sec: 0.2759603184138963
collect_time: 21.74225640296936
reward_mean: -126.03699813258636
reward_std: 2.855221544657729
reward_max: -121.7745098039216
reward_min: -130.66946778711483
queue_len: 0.08357891122850554
wait_time: 0.8037859706216702
delay_time: 5.155264684136464
pressure: 1.0311671087533159
total_envstep_count: 54984
total_train_sample_count: 54984
total_episode_count: 474
total_duration: 2508.2928743362427
[2025-02-20 18:04:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.981178223646655
avg_train_sample_per_sec: 31.981178223646655
avg_episode_per_sec: 0.275699812272816
collect_time: 21.762800455093384
reward_mean: -128.45564892623716
reward_std: 2.21721894126842
reward_max: -124.99369747899158
reward_min: -131.60084033613444
queue_len: 0.085182791065144
wait_time: 0.8271412565910539
delay_time: 5.281375899890108
pressure: 1.0387931034482758
total_envstep_count: 55680
total_train_sample_count: 55680
total_episode_count: 480
total_duration: 2530.055674791336
[2025-02-20 18:05:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0390413217379
avg_train_sample_per_sec: 32.0390413217379
avg_episode_per_sec: 0.2761986320839474
collect_time: 21.723496437072754
reward_mean: -126.68055555555554
reward_std: 4.215214245651882
reward_max: -119.187675070028
reward_min: -131.9719887955182
queue_len: 0.08400567344532861
wait_time: 0.8135657446002275
delay_time: 5.239323918232224
pressure: 1.0202254641909814
total_envstep_count: 56376
total_train_sample_count: 56376
total_episode_count: 486
total_duration: 2551.779171228409
[2025-02-20 18:05:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86346675291557
avg_train_sample_per_sec: 31.86346675291557
avg_episode_per_sec: 0.2746850582147894
collect_time: 21.84319758415222
reward_mean: -127.91071428571429
reward_std: 3.4955274447785096
reward_max: -121.51750700280112
reward_min: -131.08123249299717
queue_len: 0.08482142857142856
wait_time: 0.8196928086000094
delay_time: 5.196775236526565
pressure: 1.0393457117595049
total_envstep_count: 57072
total_train_sample_count: 57072
total_episode_count: 492
total_duration: 2573.622368812561
[2025-02-20 18:05:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99837247861335
avg_train_sample_per_sec: 31.99837247861335
avg_episode_per_sec: 0.2758480386087358
collect_time: 21.75110626220703
reward_mean: -128.37990196078428
reward_std: 4.488117177565834
reward_max: -121.87324929971993
reward_min: -136.93837535014003
queue_len: 0.08513256098195247
wait_time: 0.8283523511084362
delay_time: 5.30839151808985
pressure: 1.0323828470380194
total_envstep_count: 57768
total_train_sample_count: 57768
total_episode_count: 498
total_duration: 2595.373475074768
[2025-02-20 18:06:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87640317742455
avg_train_sample_per_sec: 31.87640317742455
avg_episode_per_sec: 0.27479657911572886
collect_time: 21.834332942962646
reward_mean: -125.72140522875814
reward_std: 3.258202547405475
reward_max: -121.03221288515401
reward_min: -131.99719887955183
queue_len: 0.08336963211456111
wait_time: 0.803494342033896
delay_time: 5.196515566692519
pressure: 1.01657824933687
total_envstep_count: 58464
total_train_sample_count: 58464
total_episode_count: 504
total_duration: 2617.2078080177307
[2025-02-20 18:06:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94858520558202
avg_train_sample_per_sec: 31.94858520558202
avg_episode_per_sec: 0.27541883797915534
collect_time: 21.7850022315979
reward_mean: -129.78559757236226
reward_std: 2.065276296739921
reward_max: -126.00140056022411
reward_min: -132.53991596638656
queue_len: 0.08606471987557181
wait_time: 0.8268869329340932
delay_time: 5.366808471200542
pressure: 1.0450928381962865
total_envstep_count: 59160
total_train_sample_count: 59160
total_episode_count: 510
total_duration: 2638.9928102493286
[2025-02-20 18:07:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.847332260960876
avg_train_sample_per_sec: 31.847332260960876
avg_episode_per_sec: 0.2745459677669041
collect_time: 21.85426378250122
reward_mean: -126.85842670401495
reward_std: 3.073176762886962
reward_max: -122.55042016806726
reward_min: -132.03921568627447
queue_len: 0.08412362513528843
wait_time: 0.8112208742913611
delay_time: 5.278248907239614
pressure: 1.0201149425287355
total_envstep_count: 59856
total_train_sample_count: 59856
total_episode_count: 516
total_duration: 2660.84707403183
[2025-02-20 18:07:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93704252018791
avg_train_sample_per_sec: 31.93704252018791
avg_episode_per_sec: 0.27531933207058545
collect_time: 21.79287576675415
reward_mean: -126.98797852474324
reward_std: 3.0687074983738944
reward_max: -122.72689075630254
reward_min: -130.3067226890756
queue_len: 0.08420953483073158
wait_time: 0.820718694197396
delay_time: 5.249466328757521
pressure: 1.0282935455349247
total_envstep_count: 60552
total_train_sample_count: 60552
total_episode_count: 522
total_duration: 2682.639949798584
[2025-02-20 18:07:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65375979886185
avg_train_sample_per_sec: 31.65375979886185
avg_episode_per_sec: 0.27287723964536076
collect_time: 21.9879093170166
reward_mean: -128.7945845004668
reward_std: 4.953132793135191
reward_max: -123.82072829131644
reward_min: -139.27310924369738
queue_len: 0.08540754940349259
wait_time: 0.8302888794775205
delay_time: 5.328156627695106
pressure: 1.038793103448276
total_envstep_count: 61248
total_train_sample_count: 61248
total_episode_count: 528
total_duration: 2704.6278591156006
[2025-02-20 18:08:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.069782785787176
avg_train_sample_per_sec: 32.069782785787176
avg_episode_per_sec: 0.27646364470506185
collect_time: 21.702672719955444
reward_mean: -127.49031279178338
reward_std: 3.9598339519671435
reward_max: -123.91596638655462
reward_min: -135.38025210084035
queue_len: 0.0845426477399094
wait_time: 0.8171455474320585
delay_time: 5.215990902619478
pressure: 1.0276304155614502
total_envstep_count: 61944
total_train_sample_count: 61944
total_episode_count: 534
total_duration: 2726.330531835556
[2025-02-20 18:08:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92193471860215
avg_train_sample_per_sec: 31.92193471860215
avg_episode_per_sec: 0.27518909240174266
collect_time: 21.803189754486084
reward_mean: -127.07341269841267
reward_std: 3.758175155928301
reward_max: -120.69047619047618
reward_min: -131.89775910364142
queue_len: 0.08426618879205085
wait_time: 0.8170125808944265
delay_time: 5.229285574429119
pressure: 1.0405614500442086
total_envstep_count: 62640
total_train_sample_count: 62640
total_episode_count: 540
total_duration: 2748.133721590042
[2025-02-20 18:08:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.688628156826578
avg_train_sample_per_sec: 31.688628156826578
avg_episode_per_sec: 0.2731778289381601
collect_time: 21.963715076446533
reward_mean: -129.80520541549953
reward_std: 4.506409120058424
reward_max: -123.88655462184875
reward_min: -136.03641456582633
queue_len: 0.0860777224240713
wait_time: 0.8350772227547073
delay_time: 5.331891546011331
pressure: 1.050287356321839
total_envstep_count: 63336
total_train_sample_count: 63336
total_episode_count: 546
total_duration: 2770.0974366664886
[2025-02-20 18:09:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23555644763949
avg_train_sample_per_sec: 32.23555644763949
avg_episode_per_sec: 0.27789272799689213
collect_time: 21.591065168380737
reward_mean: -127.33776844070958
reward_std: 3.27192338369671
reward_max: -122.7955182072829
reward_min: -132.12605042016804
queue_len: 0.08444149100842811
wait_time: 0.8176898743582314
delay_time: 5.246720737889587
pressure: 1.0431034482758619
total_envstep_count: 64032
total_train_sample_count: 64032
total_episode_count: 552
total_duration: 2791.6885018348694
[2025-02-20 18:09:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.18736327745574
avg_train_sample_per_sec: 32.18736327745574
avg_episode_per_sec: 0.2774772696332391
collect_time: 21.623392820358276
reward_mean: -126.12231559290383
reward_std: 1.7095510774823681
reward_max: -122.94677871148458
reward_min: -127.94537815126056
queue_len: 0.08363548779370282
wait_time: 0.8109565665346598
delay_time: 5.176979105328928
pressure: 1.0202254641909814
total_envstep_count: 64728
total_train_sample_count: 64728
total_episode_count: 558
total_duration: 2813.3118946552277
[2025-02-20 18:10:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17552651181689
avg_train_sample_per_sec: 32.17552651181689
avg_episode_per_sec: 0.27737522855014557
collect_time: 21.63134765625
reward_mean: -125.4669701213819
reward_std: 4.145506797691578
reward_max: -120.90406162464988
reward_min: -130.40266106442576
queue_len: 0.08320090856855562
wait_time: 0.7988989472889069
delay_time: 5.178146637137369
pressure: 1.017683465959328
total_envstep_count: 65424
total_train_sample_count: 65424
total_episode_count: 564
total_duration: 2834.9432423114777
[2025-02-20 18:10:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0435463764857
avg_train_sample_per_sec: 32.0435463764857
avg_episode_per_sec: 0.27623746876280775
collect_time: 21.720442295074463
reward_mean: -128.42892156862746
reward_std: 2.1411053355653897
reward_max: -125.20658263305322
reward_min: -131.18697478991595
queue_len: 0.08516506735320123
wait_time: 0.8283360205266899
delay_time: 5.291210153182189
pressure: 1.05868700265252
total_envstep_count: 66120
total_train_sample_count: 66120
total_episode_count: 570
total_duration: 2856.663684606552
[2025-02-20 18:10:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00792565874895
avg_train_sample_per_sec: 32.00792565874895
avg_episode_per_sec: 0.27593039360990473
collect_time: 21.744614362716675
reward_mean: -128.44887955182074
reward_std: 6.1573542835650485
reward_max: -119.61624649859947
reward_min: -136.9740896358543
queue_len: 0.08517830209006681
wait_time: 0.8243084811289677
delay_time: 5.41896201956416
pressure: 1.023762157382847
total_envstep_count: 66816
total_train_sample_count: 66816
total_episode_count: 576
total_duration: 2878.408298969269
[2025-02-20 18:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87653997043026
avg_train_sample_per_sec: 31.87653997043026
avg_episode_per_sec: 0.27479775836577813
collect_time: 21.83423924446106
reward_mean: -127.6126283846872
reward_std: 5.288407538197125
reward_max: -121.98809523809524
reward_min: -138.84173669467785
queue_len: 0.08462375887578727
wait_time: 0.8176158062694574
delay_time: 5.314901121414352
pressure: 1.030503978779841
total_envstep_count: 67512
total_train_sample_count: 67512
total_episode_count: 582
total_duration: 2900.24253821373
[2025-02-20 18:11:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14362926858466
avg_train_sample_per_sec: 32.14362926858466
avg_episode_per_sec: 0.27710025231538504
collect_time: 21.65281319618225
reward_mean: -125.37990196078432
reward_std: 2.87257094951344
reward_max: -119.28431372549016
reward_min: -127.68137254901961
queue_len: 0.08314317106152806
wait_time: 0.8024559956608638
delay_time: 5.111521444052495
pressure: 1.0164677276746241
total_envstep_count: 68208
total_train_sample_count: 68208
total_episode_count: 588
total_duration: 2921.895351409912
[2025-02-20 18:11:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.861183676131567
avg_train_sample_per_sec: 31.861183676131567
avg_episode_per_sec: 0.2746653765183756
collect_time: 21.844762802124023
reward_mean: -125.51797385620914
reward_std: 1.080383846388248
reward_max: -123.91246498599435
reward_min: -126.9138655462185
queue_len: 0.08323473067387872
wait_time: 0.8073917011543785
delay_time: 5.141482992274215
pressure: 1.0173519009725907
total_envstep_count: 68904
total_train_sample_count: 68904
total_episode_count: 594
total_duration: 2943.740114212036
[2025-02-20 18:12:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.987891910864576
avg_train_sample_per_sec: 31.987891910864576
avg_episode_per_sec: 0.2757576888867636
collect_time: 21.758232831954956
reward_mean: -122.13678804855276
reward_std: 2.203891423900062
reward_max: -119.91246498599443
reward_min: -126.10784313725489
queue_len: 0.08099256501893418
wait_time: 0.7836513694779416
delay_time: 4.946436862212052
pressure: 0.9976790450928382
total_envstep_count: 69600
total_train_sample_count: 69600
total_episode_count: 600
total_duration: 2965.498347043991
[2025-02-20 18:12:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91776984102505
avg_train_sample_per_sec: 31.91776984102505
avg_episode_per_sec: 0.2751531882846987
collect_time: 21.806034803390503
reward_mean: -130.13083566760034
reward_std: 4.887081683778694
reward_max: -123.92016806722688
reward_min: -137.2787114845938
queue_len: 0.08629365760450952
wait_time: 0.8451305146284863
delay_time: 5.300119368054263
pressure: 1.0582449160035368
total_envstep_count: 70296
total_train_sample_count: 70296
total_episode_count: 606
total_duration: 2987.3043818473816
[2025-02-20 18:13:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.998961734478677
avg_train_sample_per_sec: 31.998961734478677
avg_episode_per_sec: 0.2758531184006782
collect_time: 21.75070571899414
reward_mean: -126.37021475256769
reward_std: 3.667494860480005
reward_max: -119.82773109243698
reward_min: -131.671568627451
queue_len: 0.08379987715687515
wait_time: 0.8135918270933483
delay_time: 5.200306936764327
pressure: 1.030393457117595
total_envstep_count: 70992
total_train_sample_count: 70992
total_episode_count: 612
total_duration: 3009.0550875663757
[2025-02-20 18:13:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.055338312179416
avg_train_sample_per_sec: 32.055338312179416
avg_episode_per_sec: 0.27633912338085703
collect_time: 21.712452173233032
reward_mean: -125.76470588235297
reward_std: 3.3074533150142202
reward_max: -121.58333333333334
reward_min: -130.64215686274508
queue_len: 0.08339834607583085
wait_time: 0.8130600383389429
delay_time: 5.166514408924473
pressure: 1.0141467727674625
total_envstep_count: 71688
total_train_sample_count: 71688
total_episode_count: 618
total_duration: 3030.7675397396088
[2025-02-20 18:13:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.979676983346256
avg_train_sample_per_sec: 31.979676983346256
avg_episode_per_sec: 0.27568687054608837
collect_time: 21.763822078704834
reward_mean: -124.48424369747897
reward_std: 1.4323433131770125
reward_max: -122.20028011204484
reward_min: -125.99369747899159
queue_len: 0.08254923322113993
wait_time: 0.7974010227433149
delay_time: 5.206228272947327
pressure: 1.0023209549071617
total_envstep_count: 72384
total_train_sample_count: 72384
total_episode_count: 624
total_duration: 3052.5313618183136
[2025-02-20 18:14:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.220865913074924
avg_train_sample_per_sec: 32.220865913074924
avg_episode_per_sec: 0.27776608545754244
collect_time: 21.60090923309326
reward_mean: -125.2748599439776
reward_std: 2.466554817259037
reward_max: -121.54061624649859
reward_min: -128.94747899159663
queue_len: 0.08307351455170926
wait_time: 0.8082076110727229
delay_time: 5.186698006036617
pressure: 1.0097259062776305
total_envstep_count: 73080
total_train_sample_count: 73080
total_episode_count: 630
total_duration: 3074.132271051407
[2025-02-20 18:14:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02455320385393
avg_train_sample_per_sec: 32.02455320385393
avg_episode_per_sec: 0.2760737345159821
collect_time: 21.7333242893219
reward_mean: -127.77894491129786
reward_std: 4.1426199149276535
reward_max: -120.98039215686278
reward_min: -132.50280112044817
queue_len: 0.08473404834966702
wait_time: 0.8314676998120204
delay_time: 5.246304937936249
pressure: 1.0446507515473031
total_envstep_count: 73776
total_train_sample_count: 73776
total_episode_count: 636
total_duration: 3095.8655953407288
[2025-02-20 18:14:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.825619014481003
avg_train_sample_per_sec: 31.825619014481003
avg_episode_per_sec: 0.27435878460759483
collect_time: 21.869174003601074
reward_mean: -124.2454481792717
reward_std: 2.7468321362460246
reward_max: -121.05882352941177
reward_min: -128.21078431372547
queue_len: 0.08239088075548522
wait_time: 0.7967542233515865
delay_time: 5.143155182179495
pressure: 1.0053050397877985
total_envstep_count: 74472
total_train_sample_count: 74472
total_episode_count: 642
total_duration: 3117.73476934433
[2025-02-20 18:15:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.608842355419082
avg_train_sample_per_sec: 31.608842355419082
avg_episode_per_sec: 0.2724900203053369
collect_time: 22.019155025482178
reward_mean: -124.22047152194212
reward_std: 0.5959795756135886
reward_max: -123.39635854341735
reward_min: -125.30742296918773
queue_len: 0.08237431798537276
wait_time: 0.8034345148315736
delay_time: 5.0936632293018596
pressure: 1.0048629531388151
total_envstep_count: 75168
total_train_sample_count: 75168
total_episode_count: 648
total_duration: 3139.753924369812
[2025-02-20 18:15:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.31029976757056
avg_train_sample_per_sec: 32.31029976757056
avg_episode_per_sec: 0.2785370669618152
collect_time: 21.541118621826172
reward_mean: -124.78536414565826
reward_std: 3.3359846572588387
reward_max: -118.92717086834736
reward_min: -129.29971988795518
queue_len: 0.08274891521595376
wait_time: 0.8081881846460953
delay_time: 5.169250287182365
pressure: 1.016025641025641
total_envstep_count: 75864
total_train_sample_count: 75864
total_episode_count: 654
total_duration: 3161.295042991638
[2025-02-20 18:15:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.201701089941274
avg_train_sample_per_sec: 32.201701089941274
avg_episode_per_sec: 0.27760087146501095
collect_time: 21.613765001296997
reward_mean: -125.76774042950517
reward_std: 3.6797611361792244
reward_max: -122.09103641456585
reward_min: -131.48039215686276
queue_len: 0.08340035837500342
wait_time: 0.8125417165097691
delay_time: 5.180011487186211
pressure: 1.0109416445623343
total_envstep_count: 76560
total_train_sample_count: 76560
total_episode_count: 660
total_duration: 3182.908807992935
[2025-02-20 18:16:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.770190356319368
avg_train_sample_per_sec: 31.770190356319368
avg_episode_per_sec: 0.2738809513475808
collect_time: 21.907328605651855
reward_mean: -128.03221288515405
reward_std: 3.926174599345453
reward_max: -122.38725490196079
reward_min: -133.3515406162465
queue_len: 0.0849019979344523
wait_time: 0.824653203456449
delay_time: 5.318488109859271
pressure: 1.0362511052166223
total_envstep_count: 77256
total_train_sample_count: 77256
total_episode_count: 666
total_duration: 3204.816136598587
[2025-02-20 18:16:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04098737809904
avg_train_sample_per_sec: 32.04098737809904
avg_episode_per_sec: 0.2762154084318883
collect_time: 21.722177028656006
reward_mean: -126.37605042016806
reward_std: 3.9241788032090223
reward_max: -119.97408963585436
reward_min: -130.90686274509807
queue_len: 0.08380374696297617
wait_time: 0.8135368758467134
delay_time: 5.191445435515873
pressure: 1.0292882404951371
total_envstep_count: 77952
total_train_sample_count: 77952
total_episode_count: 672
total_duration: 3226.538313627243
[2025-02-20 18:17:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26108866364556
avg_train_sample_per_sec: 32.26108866364556
avg_episode_per_sec: 0.2781128333072893
collect_time: 21.57397747039795
reward_mean: -123.35247432306255
reward_std: 2.188181379514323
reward_max: -121.078431372549
reward_min: -126.6582633053221
queue_len: 0.08179872302590355
wait_time: 0.790228491927275
delay_time: 5.1497767083548345
pressure: 0.997347480106101
total_envstep_count: 78648
total_train_sample_count: 78648
total_episode_count: 678
total_duration: 3248.112291097641
[2025-02-20 18:17:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.227709084484346
avg_train_sample_per_sec: 32.227709084484346
avg_episode_per_sec: 0.2778250783145202
collect_time: 21.596322536468506
reward_mean: -126.31080765639592
reward_std: 4.952772573841533
reward_max: -122.49229691876752
reward_min: -136.93277310924367
queue_len: 0.08376048253076651
wait_time: 0.8109526193324367
delay_time: 5.238648527833282
pressure: 1.023099027409372
total_envstep_count: 79344
total_train_sample_count: 79344
total_episode_count: 684
total_duration: 3269.7086136341095
[2025-02-20 18:17:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.156338705751345
avg_train_sample_per_sec: 32.156338705751345
avg_episode_per_sec: 0.27720981642889087
collect_time: 21.6442551612854
reward_mean: -124.82551353874885
reward_std: 4.034710288623481
reward_max: -117.55042016806722
reward_min: -129.65546218487393
queue_len: 0.08277553948192894
wait_time: 0.7954800509947568
delay_time: 5.119186844218812
pressure: 1.0161361626878869
total_envstep_count: 80040
total_train_sample_count: 80040
total_episode_count: 690
total_duration: 3291.352868795395
[2025-02-20 18:18:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.089956311275024
avg_train_sample_per_sec: 32.089956311275024
avg_episode_per_sec: 0.27663755440754334
collect_time: 21.689029216766357
reward_mean: -124.86006069094306
reward_std: 3.1185086947487344
reward_max: -121.24649859943986
reward_min: -130.67717086834736
queue_len: 0.08279844873404713
wait_time: 0.8061592453073182
delay_time: 5.089694599221998
pressure: 1.0151414677276747
total_envstep_count: 80736
total_train_sample_count: 80736
total_episode_count: 696
total_duration: 3313.0418980121613
[2025-02-20 18:18:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1458046861145
avg_train_sample_per_sec: 32.1458046861145
avg_episode_per_sec: 0.27711900591478017
collect_time: 21.651347875595093
reward_mean: -122.38923902894491
reward_std: 3.754394900775459
reward_max: -116.68907563025208
reward_min: -127.10364145658265
queue_len: 0.08115997283086533
wait_time: 0.7789580686385958
delay_time: 5.085950931520457
pressure: 0.9938107869142353
total_envstep_count: 81432
total_train_sample_count: 81432
total_episode_count: 702
total_duration: 3334.6932458877563
[2025-02-20 18:18:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.983052081396753
avg_train_sample_per_sec: 31.983052081396753
avg_episode_per_sec: 0.2757159662189375
collect_time: 21.76152539253235
reward_mean: -127.33123249299722
reward_std: 2.183267353243059
reward_max: -124.249299719888
reward_min: -130.52521008403366
queue_len: 0.08443715682559498
wait_time: 0.8177422715328396
delay_time: 5.2881568449980705
pressure: 1.0314986737400529
total_envstep_count: 82128
total_train_sample_count: 82128
total_episode_count: 708
total_duration: 3356.4547712802887
[2025-02-20 18:19:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.334938740370994
avg_train_sample_per_sec: 32.334938740370994
avg_episode_per_sec: 0.27874947189974997
collect_time: 21.524704456329346
reward_mean: -123.8605275443511
reward_std: 3.608910875089724
reward_max: -119.96078431372555
reward_min: -130.86694677871148
queue_len: 0.08213562834506043
wait_time: 0.793815569994576
delay_time: 5.124365879902275
pressure: 0.9979000884173298
total_envstep_count: 82824
total_train_sample_count: 82824
total_episode_count: 714
total_duration: 3377.979475736618
[2025-02-20 18:19:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03168227451491
avg_train_sample_per_sec: 32.03168227451491
avg_episode_per_sec: 0.27613519202168024
collect_time: 21.728487253189087
reward_mean: -123.4765406162465
reward_std: 2.7025959138566837
reward_max: -119.66036414565828
reward_min: -128.797619047619
queue_len: 0.08188099510361173
wait_time: 0.7882327555248448
delay_time: 5.089772269428374
pressure: 0.9938107869142351
total_envstep_count: 83520
total_train_sample_count: 83520
total_episode_count: 720
total_duration: 3399.707962989807
[2025-02-20 18:20:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13509821621006
avg_train_sample_per_sec: 32.13509821621006
avg_episode_per_sec: 0.27702670876043156
collect_time: 21.65856146812439
reward_mean: -123.47175536881419
reward_std: 3.239070966828586
reward_max: -120.29481792717087
reward_min: -129.91806722689077
queue_len: 0.08187782186260889
wait_time: 0.7891154582964927
delay_time: 5.119351605131936
pressure: 0.9990053050397877
total_envstep_count: 84216
total_train_sample_count: 84216
total_episode_count: 726
total_duration: 3421.3665244579315
[2025-02-20 18:20:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0063941838714
avg_train_sample_per_sec: 32.0063941838714
avg_episode_per_sec: 0.2759171912402707
collect_time: 21.745654821395874
reward_mean: -126.3529411764706
reward_std: 6.237380360607394
reward_max: -116.41806722689071
reward_min: -134.28011204481788
queue_len: 0.08378842253081603
wait_time: 0.8127249905267145
delay_time: 5.209889625870033
pressure: 1.0150309460654288
total_envstep_count: 84912
total_train_sample_count: 84912
total_episode_count: 732
total_duration: 3443.1121792793274
[2025-02-20 18:20:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.270415890859226
avg_train_sample_per_sec: 32.270415890859226
avg_episode_per_sec: 0.2781932404384416
collect_time: 21.567741870880127
reward_mean: -121.42845471521942
reward_std: 2.4460101471497624
reward_max: -117.7415966386555
reward_min: -125.92927170868344
queue_len: 0.08052284795438953
wait_time: 0.7742797826469227
delay_time: 4.977973191549563
pressure: 0.9970159151193633
total_envstep_count: 85608
total_train_sample_count: 85608
total_episode_count: 738
total_duration: 3464.6799211502075
[2025-02-20 18:21:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04017362067812
avg_train_sample_per_sec: 32.04017362067812
avg_episode_per_sec: 0.27620839328170793
collect_time: 21.722728729248047
reward_mean: -123.89764239028942
reward_std: 2.065609090504674
reward_max: -120.97268907563021
reward_min: -127.51540616246498
queue_len: 0.08216024031186302
wait_time: 0.7922864548118097
delay_time: 5.1814391678954115
pressure: 0.9960212201591512
total_envstep_count: 86304
total_train_sample_count: 86304
total_episode_count: 744
total_duration: 3486.4026498794556
[2025-02-20 18:21:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.053557336567636
avg_train_sample_per_sec: 32.053557336567636
avg_episode_per_sec: 0.27632377014282444
collect_time: 21.713658571243286
reward_mean: -124.35014005602243
reward_std: 4.287120489050019
reward_max: -117.4404761904762
reward_min: -129.73949579831938
queue_len: 0.08246030507693795
wait_time: 0.7941838207431514
delay_time: 5.287774214046633
pressure: 0.9928160919540229
total_envstep_count: 87000
total_train_sample_count: 87000
total_episode_count: 750
total_duration: 3508.116308450699
[2025-02-20 18:21:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91527066846907
avg_train_sample_per_sec: 31.91527066846907
avg_episode_per_sec: 0.27513164369369886
collect_time: 21.80774235725403
reward_mean: -125.29785247432305
reward_std: 2.1177137382525184
reward_max: -122.14845938375348
reward_min: -127.96288515406158
queue_len: 0.08308876158774739
wait_time: 0.8076913789388435
delay_time: 5.282638755561857
pressure: 0.9964633068081343
total_envstep_count: 87696
total_train_sample_count: 87696
total_episode_count: 756
total_duration: 3529.924050807953
[2025-02-20 18:22:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92886730573935
avg_train_sample_per_sec: 31.92886730573935
avg_episode_per_sec: 0.27524885608395994
collect_time: 21.798455715179443
reward_mean: -124.87593370681601
reward_std: 2.205889704635042
reward_max: -120.6911764705882
reward_min: -127.44887955182068
queue_len: 0.08280897460664192
wait_time: 0.8027257211461065
delay_time: 5.277808355276884
pressure: 0.9896109637488948
total_envstep_count: 88392
total_train_sample_count: 88392
total_episode_count: 762
total_duration: 3551.7225065231323
[2025-02-20 18:22:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99001965632999
avg_train_sample_per_sec: 31.99001965632999
avg_episode_per_sec: 0.2757760315200861
collect_time: 21.75678563117981
reward_mean: -124.75151727357611
reward_std: 2.945333513938714
reward_max: -120.73039215686279
reward_min: -129.6134453781513
queue_len: 0.08272647034056771
wait_time: 0.7930532181926706
delay_time: 5.15812188928193
pressure: 1.0125994694960212
total_envstep_count: 89088
total_train_sample_count: 89088
total_episode_count: 768
total_duration: 3573.479292154312
[2025-02-20 18:22:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.072244905299975
avg_train_sample_per_sec: 32.072244905299975
avg_episode_per_sec: 0.27648486987327564
collect_time: 21.701006650924683
reward_mean: -123.68359010270774
reward_std: 4.518272195053467
reward_max: -115.17156862745092
reward_min: -129.94677871148463
queue_len: 0.08201829582407676
wait_time: 0.7846842981224321
delay_time: 5.279412767075429
pressure: 0.9977895667550839
total_envstep_count: 89784
total_train_sample_count: 89784
total_episode_count: 774
total_duration: 3595.180298805237
[2025-02-20 18:23:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.648129818022653
avg_train_sample_per_sec: 31.648129818022653
avg_episode_per_sec: 0.2728287053277815
collect_time: 21.991820812225342
reward_mean: -124.83928571428574
reward_std: 3.414778296185953
reward_max: -121.4565826330532
reward_min: -131.062324929972
queue_len: 0.08278467222432741
wait_time: 0.7999449558780188
delay_time: 5.257404387067531
pressure: 1.0135941644562332
total_envstep_count: 90480
total_train_sample_count: 90480
total_episode_count: 780
total_duration: 3617.172119617462
[2025-02-20 18:23:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.58188347199878
avg_train_sample_per_sec: 30.58188347199878
avg_episode_per_sec: 0.2636369264827481
collect_time: 22.758572101593018
reward_mean: -125.5856676003735
reward_std: 4.872616361080379
reward_max: -118.37535014005609
reward_min: -133.22198879551826
queue_len: 0.08327962042465085
wait_time: 0.8022533726134133
delay_time: 5.301035831096208
pressure: 1.0108311229000886
total_envstep_count: 91176
total_train_sample_count: 91176
total_episode_count: 786
total_duration: 3639.930691719055
[2025-02-20 18:24:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.002401948755015
avg_train_sample_per_sec: 32.002401948755015
avg_episode_per_sec: 0.2758827754203018
collect_time: 21.74836754798889
reward_mean: -124.36134453781511
reward_std: 3.397077277229213
reward_max: -117.296218487395
reward_min: -128.09593837535007
queue_len: 0.08246773510465194
wait_time: 0.797998366013072
delay_time: 5.210845608742062
pressure: 1.0101679929266136
total_envstep_count: 91872
total_train_sample_count: 91872
total_episode_count: 792
total_duration: 3661.679059267044
[2025-02-20 18:24:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.063187521526814
avg_train_sample_per_sec: 32.063187521526814
avg_episode_per_sec: 0.27640678897867943
collect_time: 21.707136869430542
reward_mean: -123.01995798319327
reward_std: 2.0010139047914355
reward_max: -120.04621848739497
reward_min: -126.71638655462185
queue_len: 0.08157822147426609
wait_time: 0.780956668697541
delay_time: 5.165521898556467
pressure: 1.0
total_envstep_count: 92568
total_train_sample_count: 92568
total_episode_count: 798
total_duration: 3683.3861961364746
[2025-02-20 18:24:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5773095047549
avg_train_sample_per_sec: 31.5773095047549
avg_episode_per_sec: 0.2722181853858181
collect_time: 22.04114317893982
reward_mean: -124.00081699346406
reward_std: 4.23987128129298
reward_max: -117.1827731092437
reward_min: -128.0266106442577
queue_len: 0.08222865848372947
wait_time: 0.8037701818127782
delay_time: 5.183221957319919
pressure: 1.0041998231653404
total_envstep_count: 93264
total_train_sample_count: 93264
total_episode_count: 804
total_duration: 3705.4273393154144
[2025-02-20 18:25:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95753666708237
avg_train_sample_per_sec: 31.95753666708237
avg_episode_per_sec: 0.2754960057507101
collect_time: 21.778900146484375
reward_mean: -122.75046685340801
reward_std: 1.194244917970965
reward_max: -120.81092436974792
reward_min: -124.42436974789918
queue_len: 0.08139951382851991
wait_time: 0.7813198113020627
delay_time: 5.252645059112628
pressure: 0.9964633068081344
total_envstep_count: 93960
total_train_sample_count: 93960
total_episode_count: 810
total_duration: 3727.206239461899
[2025-02-20 18:25:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17427327885331
avg_train_sample_per_sec: 32.17427327885331
avg_episode_per_sec: 0.277364424817701
collect_time: 21.632190227508545
reward_mean: -120.13958916900094
reward_std: 2.2688797773924736
reward_max: -116.33403361344537
reward_min: -123.55882352941178
queue_len: 0.07966816257891308
wait_time: 0.7656371124930964
delay_time: 5.077636362559518
pressure: 0.9580017683465959
total_envstep_count: 94656
total_train_sample_count: 94656
total_episode_count: 816
total_duration: 3748.8384296894073
[2025-02-20 18:25:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.18218546147365
avg_train_sample_per_sec: 32.18218546147365
avg_episode_per_sec: 0.277432633288566
collect_time: 21.626871824264526
reward_mean: -125.23471055088703
reward_std: 2.971877839218719
reward_max: -120.88445378151262
reward_min: -130.640056022409
queue_len: 0.0830468902857341
wait_time: 0.8020727300646163
delay_time: 5.237533842950994
pressure: 1.0043103448275863
total_envstep_count: 95352
total_train_sample_count: 95352
total_episode_count: 822
total_duration: 3770.465301513672
[2025-02-20 18:26:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8781140446595
avg_train_sample_per_sec: 31.8781140446595
avg_episode_per_sec: 0.2748113279712026
collect_time: 21.833161115646362
reward_mean: -123.31687675070027
reward_std: 2.603806750779856
reward_max: -119.42787114845937
reward_min: -127.58193277310923
queue_len: 0.08177511720868719
wait_time: 0.7864594555771028
delay_time: 5.165111436257285
pressure: 0.9916003536693192
total_envstep_count: 96048
total_train_sample_count: 96048
total_episode_count: 828
total_duration: 3792.2984626293182
[2025-02-20 18:26:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.175985771315894
avg_train_sample_per_sec: 32.175985771315894
avg_episode_per_sec: 0.2773791876837577
collect_time: 21.631038904190063
reward_mean: -123.00571895424838
reward_std: 3.616976277052945
reward_max: -117.31792717086833
reward_min: -127.59803921568627
queue_len: 0.08156877914737955
wait_time: 0.7850434935247309
delay_time: 5.19511363111981
pressure: 0.9805481874447391
total_envstep_count: 96744
total_train_sample_count: 96744
total_episode_count: 834
total_duration: 3813.9295015335083
[2025-02-20 18:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25590777450938
avg_train_sample_per_sec: 32.25590777450938
avg_episode_per_sec: 0.27806817046990845
collect_time: 21.57744264602661
reward_mean: -122.57061157796454
reward_std: 2.3103519230107117
reward_max: -119.313025210084
reward_min: -126.46358543417367
queue_len: 0.08128024640448576
wait_time: 0.7793045710768833
delay_time: 5.143360595321816
pressure: 0.9834217506631299
total_envstep_count: 97440
total_train_sample_count: 97440
total_episode_count: 840
total_duration: 3835.506944179535
[2025-02-20 18:27:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93179822070996
avg_train_sample_per_sec: 31.93179822070996
avg_episode_per_sec: 0.27527412259232725
collect_time: 21.796454906463623
reward_mean: -125.47747432306257
reward_std: 2.0307363961089524
reward_max: -122.44187675070029
reward_min: -127.95728291316527
queue_len: 0.0832078742195375
wait_time: 0.7994989994229346
delay_time: 5.306992579360039
pressure: 1.0130415561450044
total_envstep_count: 98136
total_train_sample_count: 98136
total_episode_count: 846
total_duration: 3857.3033990859985
[2025-02-20 18:27:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04278876345365
avg_train_sample_per_sec: 32.04278876345365
avg_episode_per_sec: 0.2762309376159797
collect_time: 21.720955848693848
reward_mean: -123.11041083099907
reward_std: 1.564687891901049
reward_max: -120.72759103641458
reward_min: -125.57913165266108
queue_len: 0.08163820346883228
wait_time: 0.7872055541933839
delay_time: 5.170564582351986
pressure: 0.9891688770999115
total_envstep_count: 98832
total_train_sample_count: 98832
total_episode_count: 852
total_duration: 3879.0243549346924
[2025-02-20 18:28:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.949844346550414
avg_train_sample_per_sec: 31.949844346550414
avg_episode_per_sec: 0.27542969264267597
collect_time: 21.784143686294556
reward_mean: -124.37861811391224
reward_std: 4.352862985082633
reward_max: -120.02380952380949
reward_min: -130.82703081232492
queue_len: 0.08247918973071104
wait_time: 0.7941844399121276
delay_time: 5.244544234824974
pressure: 1.0048629531388154
total_envstep_count: 99528
total_train_sample_count: 99528
total_episode_count: 858
total_duration: 3900.808498620987
[2025-02-20 18:28:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1268495893097
avg_train_sample_per_sec: 32.1268495893097
avg_episode_per_sec: 0.27695559990784224
collect_time: 21.664122343063354
reward_mean: -126.3013538748833
reward_std: 4.602087111102085
reward_max: -122.74369747899158
reward_min: -135.43697478991598
queue_len: 0.08375421344488282
wait_time: 0.7980512275644122
delay_time: 5.44687173751725
pressure: 1.0077365163572058
total_envstep_count: 100224
total_train_sample_count: 100224
total_episode_count: 864
total_duration: 3922.4726209640503
[2025-02-20 18:28:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.395890208473396
avg_train_sample_per_sec: 31.395890208473396
avg_episode_per_sec: 0.2706542259351155
collect_time: 22.168506622314453
reward_mean: -123.57084500466851
reward_std: 2.4430064840292185
reward_max: -118.54551820728288
reward_min: -126.31232492997194
queue_len: 0.0819435311702046
wait_time: 0.7882507114251537
delay_time: 5.220712080177268
pressure: 0.9909372236958442
total_envstep_count: 100920
total_train_sample_count: 100920
total_episode_count: 870
total_duration: 3944.6411275863647
[2025-02-20 18:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.959840571912142
avg_train_sample_per_sec: 31.959840571912142
avg_episode_per_sec: 0.27551586699924263
collect_time: 21.77733016014099
reward_mean: -123.48249299719889
reward_std: 2.680724740619412
reward_max: -119.5448179271709
reward_min: -127.35504201680675
queue_len: 0.0818849423058348
wait_time: 0.7880555958015388
delay_time: 5.143604384638731
pressure: 1.0022104332449162
total_envstep_count: 101616
total_train_sample_count: 101616
total_episode_count: 876
total_duration: 3966.4184577465057
[2025-02-20 18:29:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.2130974313072
avg_train_sample_per_sec: 29.2130974313072
avg_episode_per_sec: 0.25183704682161384
collect_time: 23.82492995262146
reward_mean: -124.04003267973859
reward_std: 5.111129262254512
reward_max: -118.1162464985995
reward_min: -132.4978991596639
queue_len: 0.08225466358072851
wait_time: 0.7903107640049832
delay_time: 5.184225482722391
pressure: 0.9963527851458887
total_envstep_count: 102312
total_train_sample_count: 102312
total_episode_count: 882
total_duration: 3990.243387699127
[2025-02-20 18:30:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8472447068947
avg_train_sample_per_sec: 31.8472447068947
avg_episode_per_sec: 0.2745452129904715
collect_time: 21.854323863983154
reward_mean: -123.33204948646126
reward_std: 5.610020354554795
reward_max: -118.08473389355744
reward_min: -133.90126050420167
queue_len: 0.08178517870454992
wait_time: 0.7910728062224005
delay_time: 5.190056127287478
pressure: 0.9909372236958442
total_envstep_count: 103008
total_train_sample_count: 103008
total_episode_count: 888
total_duration: 4012.0977115631104
[2025-02-20 18:30:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97645250843241
avg_train_sample_per_sec: 31.97645250843241
avg_episode_per_sec: 0.2756590733485553
collect_time: 21.766016721725464
reward_mean: -125.13865546218489
reward_std: 3.506014140689601
reward_max: -120.36764705882356
reward_min: -128.42436974789914
queue_len: 0.08298319327731092
wait_time: 0.8020388305631713
delay_time: 5.22594779313708
pressure: 1.0158045977011494
total_envstep_count: 103704
total_train_sample_count: 103704
total_episode_count: 894
total_duration: 4033.863728284836
[2025-02-20 18:30:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.881466345226073
avg_train_sample_per_sec: 31.881466345226073
avg_episode_per_sec: 0.27484022711401784
collect_time: 21.830865383148193
reward_mean: -124.35679271708682
reward_std: 4.3448382183992456
reward_max: -121.18067226890754
reward_min: -133.91736694677866
queue_len: 0.08246471665589312
wait_time: 0.7972450695574427
delay_time: 5.234317695725396
pressure: 0.9925950486295315
total_envstep_count: 104400
total_train_sample_count: 104400
total_episode_count: 900
total_duration: 4055.694593667984
[2025-02-20 18:31:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.641405361164974
avg_train_sample_per_sec: 31.641405361164974
avg_episode_per_sec: 0.2727707358721118
collect_time: 21.99649453163147
reward_mean: -125.79365079365077
reward_std: 3.17943123863652
reward_max: -121.54131652661066
reward_min: -130.470588235294
queue_len: 0.08341754031409203
wait_time: 0.8072567223175744
delay_time: 5.2686603798363185
pressure: 1.015915119363395
total_envstep_count: 105096
total_train_sample_count: 105096
total_episode_count: 906
total_duration: 4077.6910881996155
[2025-02-20 18:31:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54482300243968
avg_train_sample_per_sec: 31.54482300243968
avg_episode_per_sec: 0.27193812933137657
collect_time: 22.063842296600342
reward_mean: -126.58099906629319
reward_std: 2.928864722929582
reward_max: -122.05532212885156
reward_min: -130.36064425770311
queue_len: 0.08393965455324481
wait_time: 0.8164067240512475
delay_time: 5.267866797572157
pressure: 1.0205570291777188
total_envstep_count: 105792
total_train_sample_count: 105792
total_episode_count: 912
total_duration: 4099.754930496216
[2025-02-20 18:31:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.652746281945483
avg_train_sample_per_sec: 31.652746281945483
avg_episode_per_sec: 0.2728685024305645
collect_time: 21.98861336708069
reward_mean: -124.14904295051355
reward_std: 4.193846501646172
reward_max: -119.37464985994396
reward_min: -132.8319327731092
queue_len: 0.08232695155869597
wait_time: 0.7982838803072068
delay_time: 5.17390695725351
pressure: 0.997347480106101
total_envstep_count: 106488
total_train_sample_count: 106488
total_episode_count: 918
total_duration: 4121.7435438632965
[2025-02-20 18:32:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75144723631722
avg_train_sample_per_sec: 31.75144723631722
avg_episode_per_sec: 0.2737193727268726
collect_time: 21.920260667800903
reward_mean: -125.96008403361344
reward_std: 5.761645910046662
reward_max: -117.81792717086834
reward_min: -131.8872549019608
queue_len: 0.0835279071840938
wait_time: 0.8030000130025484
delay_time: 5.256858988335122
pressure: 1.014367816091954
total_envstep_count: 107184
total_train_sample_count: 107184
total_episode_count: 924
total_duration: 4143.663804531097
[2025-02-20 18:32:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.236308363191704
avg_train_sample_per_sec: 31.236308363191704
avg_episode_per_sec: 0.2692785203723423
collect_time: 22.28176236152649
reward_mean: -122.26949112978524
reward_std: 5.880868874536496
reward_max: -115.51610644257701
reward_min: -132.83683473389354
queue_len: 0.08108056440967192
wait_time: 0.7798649963964367
delay_time: 5.085838815649725
pressure: 0.9869584438549955
total_envstep_count: 107880
total_train_sample_count: 107880
total_episode_count: 930
total_duration: 4165.945566892624
[2025-02-20 18:33:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.860068512936877
avg_train_sample_per_sec: 31.860068512936877
avg_episode_per_sec: 0.2746557630425593
collect_time: 21.845527410507202
reward_mean: -123.88503734827263
reward_std: 2.481949452395149
reward_max: -118.95098039215685
reward_min: -126.60434173669466
queue_len: 0.08215188153068477
wait_time: 0.7864692848845993
delay_time: 5.212158386396008
pressure: 0.9970159151193635
total_envstep_count: 108576
total_train_sample_count: 108576
total_episode_count: 936
total_duration: 4187.791094303131
[2025-02-20 18:33:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.503072839521707
avg_train_sample_per_sec: 31.503072839521707
avg_episode_per_sec: 0.27157821413380784
collect_time: 22.093082904815674
reward_mean: -125.64635854341736
reward_std: 3.4505868647793414
reward_max: -121.01260504201684
reward_min: -132.46778711484592
queue_len: 0.08331986640810168
wait_time: 0.8121943627141396
delay_time: 5.271977678811981
pressure: 1.0141467727674625
total_envstep_count: 109272
total_train_sample_count: 109272
total_episode_count: 942
total_duration: 4209.884177207947
[2025-02-20 18:33:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.610290496782817
avg_train_sample_per_sec: 31.610290496782817
avg_episode_per_sec: 0.27250250428261047
collect_time: 22.018146276474
reward_mean: -122.65604575163398
reward_std: 4.338917291422551
reward_max: -116.19117647058826
reward_min: -130.06232492997196
queue_len: 0.08133690036580503
wait_time: 0.7812637765097198
delay_time: 5.1224137106117595
pressure: 0.9932581786030061
total_envstep_count: 109968
total_train_sample_count: 109968
total_episode_count: 948
total_duration: 4231.902323484421
[2025-02-20 18:34:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.800774627883893
avg_train_sample_per_sec: 31.800774627883893
avg_episode_per_sec: 0.274144608861068
collect_time: 21.88625931739807
reward_mean: -122.42647058823529
reward_std: 4.211153440158702
reward_max: -116.24019607843135
reward_min: -129.3613445378151
queue_len: 0.08118466219378999
wait_time: 0.7833311817211412
delay_time: 5.116210237901753
pressure: 0.9933687002652519
total_envstep_count: 110664
total_train_sample_count: 110664
total_episode_count: 954
total_duration: 4253.788582801819
[2025-02-20 18:34:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71306982967295
avg_train_sample_per_sec: 31.71306982967295
avg_episode_per_sec: 0.273388533014422
collect_time: 21.946787357330322
reward_mean: -124.40429505135388
reward_std: 4.331026700233013
reward_max: -119.31092436974792
reward_min: -133.15056022408965
queue_len: 0.08249621687755562
wait_time: 0.800075755324234
delay_time: 5.157832148689466
pressure: 1.0014367816091954
total_envstep_count: 111360
total_train_sample_count: 111360
total_episode_count: 960
total_duration: 4275.735370159149
[2025-02-20 18:34:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.832785784178068
avg_train_sample_per_sec: 31.832785784178068
avg_episode_per_sec: 0.2744205671049833
collect_time: 21.864250421524048
reward_mean: -125.09885620915036
reward_std: 3.925109829387692
reward_max: -119.42086834733894
reward_min: -130.6995798319328
queue_len: 0.08295680119970181
wait_time: 0.8047196774377303
delay_time: 5.1758625337359465
pressure: 1.0076259946949602
total_envstep_count: 112056
total_train_sample_count: 112056
total_episode_count: 966
total_duration: 4297.599620580673
[2025-02-20 18:35:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52366006397372
avg_train_sample_per_sec: 31.52366006397372
avg_episode_per_sec: 0.27175569020667
collect_time: 22.078654527664185
reward_mean: -123.16374883286649
reward_std: 3.794154169172121
reward_max: -118.81652661064425
reward_min: -130.90686274509804
queue_len: 0.0816735734965958
wait_time: 0.7824426742403415
delay_time: 5.187635035681341
pressure: 0.9909372236958444
total_envstep_count: 112752
total_train_sample_count: 112752
total_episode_count: 972
total_duration: 4319.678275108337
[2025-02-20 18:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.568302454044414
avg_train_sample_per_sec: 31.568302454044414
avg_episode_per_sec: 0.2721405383969346
collect_time: 22.04743194580078
reward_mean: -124.7749766573296
reward_std: 3.4622613993544156
reward_max: -118.30042016806722
reward_min: -128.87394957983196
queue_len: 0.08274202696109391
wait_time: 0.8010942882900287
delay_time: 5.184932364535739
pressure: 1.0075154730327143
total_envstep_count: 113448
total_train_sample_count: 113448
total_episode_count: 978
total_duration: 4341.725707054138
[2025-02-20 18:36:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.616207657641972
avg_train_sample_per_sec: 31.616207657641972
avg_episode_per_sec: 0.272553514290017
collect_time: 22.014025449752808
reward_mean: -126.10772642390289
reward_std: 4.443181997063693
reward_max: -122.04621848739491
reward_min: -133.77661064425772
queue_len: 0.0836258132784502
wait_time: 0.8076556993265918
delay_time: 5.318066985798898
pressure: 1.0134836427939877
total_envstep_count: 114144
total_train_sample_count: 114144
total_episode_count: 984
total_duration: 4363.739732503891
[2025-02-20 18:36:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.331147821369814
avg_train_sample_per_sec: 31.331147821369814
avg_episode_per_sec: 0.2700961019083605
collect_time: 22.21431541442871
reward_mean: -123.42390289449112
reward_std: 0.6540715797815188
reward_max: -122.19467787114841
reward_min: -124.04621848739501
queue_len: 0.08184608945258033
wait_time: 0.7945167014639631
delay_time: 5.145395717726557
pressure: 0.9970159151193635
total_envstep_count: 114840
total_train_sample_count: 114840
total_episode_count: 990
total_duration: 4385.95404791832
[2025-02-20 18:36:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.481528919042383
avg_train_sample_per_sec: 31.481528919042383
avg_episode_per_sec: 0.27139249068139987
collect_time: 22.10820198059082
reward_mean: -123.58776844070962
reward_std: 3.2698004099144926
reward_max: -119.36484593837535
reward_min: -129.42366946778714
queue_len: 0.08195475360789763
wait_time: 0.792049313093938
delay_time: 5.180366845978399
pressure: 0.9920424403183024
total_envstep_count: 115536
total_train_sample_count: 115536
total_episode_count: 996
total_duration: 4408.0622498989105
[2025-02-20 18:37:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.502886198775588
avg_train_sample_per_sec: 31.502886198775588
avg_episode_per_sec: 0.2715766051618585
collect_time: 22.0932137966156
reward_mean: -122.85597572362279
reward_std: 2.404426446601335
reward_max: -119.63095238095237
reward_min: -125.71708683473386
queue_len: 0.08146947992282677
wait_time: 0.7833187209454958
delay_time: 5.181846664944156
pressure: 0.9945844385499557
total_envstep_count: 116232
total_train_sample_count: 116232
total_episode_count: 1002
total_duration: 4430.155463695526
[2025-02-20 18:37:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.655790460133296
avg_train_sample_per_sec: 31.655790460133296
avg_episode_per_sec: 0.2728947453459767
collect_time: 21.986498832702637
reward_mean: -123.57528011204481
reward_std: 7.663989337197147
reward_max: -113.60854341736687
reward_min: -133.79201680672273
queue_len: 0.08194647222284139
wait_time: 0.7879159731974132
delay_time: 5.2826660004363655
pressure: 0.9855216622458002
total_envstep_count: 116928
total_train_sample_count: 116928
total_episode_count: 1008
total_duration: 4452.141962528229
[2025-02-20 18:37:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54384746656676
avg_train_sample_per_sec: 31.54384746656676
avg_episode_per_sec: 0.2719297195393686
collect_time: 22.06452465057373
reward_mean: -120.54738562091502
reward_std: 2.5444611995286857
reward_max: -116.08123249299724
reward_min: -123.85154061624651
queue_len: 0.079938584629254
wait_time: 0.7663181983668798
delay_time: 5.092883991850979
pressure: 0.9694960212201592
total_envstep_count: 117624
total_train_sample_count: 117624
total_episode_count: 1014
total_duration: 4474.2064871788025
[2025-02-20 18:38:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55214758373882
avg_train_sample_per_sec: 31.55214758373882
avg_episode_per_sec: 0.2720012722736105
collect_time: 22.058720350265503
reward_mean: -125.43627450980392
reward_std: 2.3376484378906577
reward_max: -122.42296918767502
reward_min: -128.50070028011203
queue_len: 0.08318055338846415
wait_time: 0.8024390459101413
delay_time: 5.166600605586731
pressure: 1.0076259946949602
total_envstep_count: 118320
total_train_sample_count: 118320
total_episode_count: 1020
total_duration: 4496.265207529068
[2025-02-20 18:38:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.480555936045214
avg_train_sample_per_sec: 31.480555936045214
avg_episode_per_sec: 0.2713841028969415
collect_time: 22.108885288238525
reward_mean: -125.11904761904763
reward_std: 3.4653781224675613
reward_max: -118.96988795518209
reward_min: -130.39215686274517
queue_len: 0.08297019072881141
wait_time: 0.8020002098982829
delay_time: 5.217538218536682
pressure: 0.9949160035366934
total_envstep_count: 119016
total_train_sample_count: 119016
total_episode_count: 1026
total_duration: 4518.3740928173065
[2025-02-20 18:39:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.602055554853102
avg_train_sample_per_sec: 31.602055554853102
avg_episode_per_sec: 0.2724315134039061
collect_time: 22.023883819580078
reward_mean: -124.64507469654525
reward_std: 2.5668491974344283
reward_max: -121.4894957983193
reward_min: -129.40686274509804
queue_len: 0.08265588507728465
wait_time: 0.8014976768780014
delay_time: 5.189763561939398
pressure: 1.0
total_envstep_count: 119712
total_train_sample_count: 119712
total_episode_count: 1032
total_duration: 4540.397976636887
[2025-02-20 18:39:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.742028571435405
avg_train_sample_per_sec: 31.742028571435405
avg_episode_per_sec: 0.2736381773399604
collect_time: 21.926764965057373
reward_mean: -124.88235294117646
reward_std: 3.713746624073482
reward_max: -120.38865546218486
reward_min: -130.53431372549014
queue_len: 0.0828132313933531
wait_time: 0.8027433674619272
delay_time: 5.216654421932232
pressure: 1.0065207780725023
total_envstep_count: 120408
total_train_sample_count: 120408
total_episode_count: 1038
total_duration: 4562.324741601944
[2025-02-20 18:39:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.623679165262907
avg_train_sample_per_sec: 31.623679165262907
avg_episode_per_sec: 0.27261792383847333
collect_time: 22.008824348449707
reward_mean: -123.72443977591034
reward_std: 4.615874083529986
reward_max: -117.78641456582628
reward_min: -129.6890756302521
queue_len: 0.08204538446678404
wait_time: 0.7891252102078674
delay_time: 5.11967729284256
pressure: 1.0025419982316535
total_envstep_count: 121104
total_train_sample_count: 121104
total_episode_count: 1044
total_duration: 4584.333565950394
[2025-02-20 18:40:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.357989723852505
avg_train_sample_per_sec: 31.357989723852505
avg_episode_per_sec: 0.27032749761941816
collect_time: 22.195300340652466
reward_mean: -122.50700280112045
reward_std: 4.291232000018343
reward_max: -115.91736694677874
reward_min: -128.86344537815125
queue_len: 0.08123806551798439
wait_time: 0.7860186072660719
delay_time: 5.122495884223598
pressure: 0.9811007957559682
total_envstep_count: 121800
total_train_sample_count: 121800
total_episode_count: 1050
total_duration: 4606.528866291046
[2025-02-20 18:40:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.216307931051595
avg_train_sample_per_sec: 31.216307931051595
avg_episode_per_sec: 0.2691061028538931
collect_time: 22.296038389205933
reward_mean: -123.28956582633054
reward_std: 4.441498658237566
reward_max: -116.59033613445378
reward_min: -127.42086834733897
queue_len: 0.08175700651613431
wait_time: 0.784405749479279
delay_time: 5.211205596388919
pressure: 0.9952475685234305
total_envstep_count: 122496
total_train_sample_count: 122496
total_episode_count: 1056
total_duration: 4628.824904680252
[2025-02-20 18:40:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.617547234552713
avg_train_sample_per_sec: 31.617547234552713
avg_episode_per_sec: 0.27256506236683375
collect_time: 22.013092756271362
reward_mean: -121.7641223155929
reward_std: 4.643585908907171
reward_max: -114.96988795518207
reward_min: -129.72619047619048
queue_len: 0.08074543920132154
wait_time: 0.7764560842020275
delay_time: 5.187976352237572
pressure: 0.9788903625110521
total_envstep_count: 123192
total_train_sample_count: 123192
total_episode_count: 1062
total_duration: 4650.837997436523
[2025-02-20 18:41:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.265714495604396
avg_train_sample_per_sec: 31.265714495604396
avg_episode_per_sec: 0.269532021513831
collect_time: 22.26080584526062
reward_mean: -125.44829598506068
reward_std: 4.016418441099668
reward_max: -118.65756302521008
reward_min: -131.24719887955186
queue_len: 0.08318852518903228
wait_time: 0.8070099060844496
delay_time: 5.185984171917325
pressure: 1.0039787798408486
total_envstep_count: 123888
total_train_sample_count: 123888
total_episode_count: 1068
total_duration: 4673.098803281784
[2025-02-20 18:41:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.555412572585915
avg_train_sample_per_sec: 31.555412572585915
avg_episode_per_sec: 0.2720294187291889
collect_time: 22.056437969207764
reward_mean: -120.67705415499533
reward_std: 4.95090588021845
reward_max: -115.27591036414563
reward_min: -129.75910364145656
queue_len: 0.08002457172081917
wait_time: 0.7705041676263785
delay_time: 5.038368140852611
pressure: 0.965185676392573
total_envstep_count: 124584
total_train_sample_count: 124584
total_episode_count: 1074
total_duration: 4695.155241250992
[2025-02-20 18:42:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.20582027205944
avg_train_sample_per_sec: 31.20582027205944
avg_episode_per_sec: 0.2690156920005124
collect_time: 22.303531646728516
reward_mean: -124.97525676937443
reward_std: 4.234134383665956
reward_max: -116.98529411764707
reward_min: -130.88515406162463
queue_len: 0.08287483870648171
wait_time: 0.8050927267458707
delay_time: 5.23220149534659
pressure: 0.9962422634836426
total_envstep_count: 125280
total_train_sample_count: 125280
total_episode_count: 1080
total_duration: 4717.45877289772
[2025-02-20 18:42:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.615184560324966
avg_train_sample_per_sec: 31.615184560324966
avg_episode_per_sec: 0.27254469448556007
collect_time: 22.014737844467163
reward_mean: -123.95704948646124
reward_std: 4.48852564309075
reward_max: -118.99649859943976
reward_min: -130.77941176470594
queue_len: 0.08219963493797165
wait_time: 0.7960818832395912
delay_time: 5.151210339713264
pressure: 0.9875110521662247
total_envstep_count: 125976
total_train_sample_count: 125976
total_episode_count: 1086
total_duration: 4739.4735107421875
[2025-02-20 18:42:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.459476139289677
avg_train_sample_per_sec: 30.459476139289677
avg_episode_per_sec: 0.2625816908559455
collect_time: 22.850031852722168
reward_mean: -122.59243697478992
reward_std: 3.054535208851007
reward_max: -118.37324929971994
reward_min: -127.85784313725483
queue_len: 0.08129471947930365
wait_time: 0.7875488059945465
delay_time: 5.160811666904817
pressure: 0.9848585322723253
total_envstep_count: 126672
total_train_sample_count: 126672
total_episode_count: 1092
total_duration: 4762.32354259491
[2025-02-20 18:43:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.542668518936658
avg_train_sample_per_sec: 31.542668518936658
avg_episode_per_sec: 0.2719195561977298
collect_time: 22.065349340438843
reward_mean: -126.78069561157797
reward_std: 2.8575378077575015
reward_max: -122.796918767507
reward_min: -131.41946778711485
queue_len: 0.08407207931802253
wait_time: 0.8174111709228341
delay_time: 5.250834394108231
pressure: 1.018236074270557
total_envstep_count: 127368
total_train_sample_count: 127368
total_episode_count: 1098
total_duration: 4784.3888919353485
[2025-02-20 18:43:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.12813917384311
avg_train_sample_per_sec: 31.12813917384311
avg_episode_per_sec: 0.26834602736071644
collect_time: 22.359190702438354
reward_mean: -120.83274976657329
reward_std: 3.788399023616332
reward_max: -112.95658263305322
reward_min: -124.60084033613444
queue_len: 0.08012781814759502
wait_time: 0.7750225532299568
delay_time: 5.068384407533206
pressure: 0.9692749778956676
total_envstep_count: 128064
total_train_sample_count: 128064
total_episode_count: 1104
total_duration: 4806.748082637787
[2025-02-20 18:44:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.248145723681514
avg_train_sample_per_sec: 31.248145723681514
avg_episode_per_sec: 0.2693805665834613
collect_time: 22.273321628570557
reward_mean: -124.7700746965453
reward_std: 4.969006938240882
reward_max: -118.24089635854338
reward_min: -131.84173669467788
queue_len: 0.08273877632396902
wait_time: 0.8004911403111201
delay_time: 5.320586120679583
pressure: 1.000552608311229
total_envstep_count: 128760
total_train_sample_count: 128760
total_episode_count: 1110
total_duration: 4829.021404266357
[2025-02-20 18:44:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59900015366331
avg_train_sample_per_sec: 31.59900015366331
avg_episode_per_sec: 0.27240517373847684
collect_time: 22.026013374328613
reward_mean: -124.74544817927172
reward_std: 4.666994775701104
reward_max: -117.95658263305322
reward_min: -131.50630252100842
queue_len: 0.08272244574222262
wait_time: 0.8050397104022865
delay_time: 5.227801301649125
pressure: 0.9929266136162688
total_envstep_count: 129456
total_train_sample_count: 129456
total_episode_count: 1116
total_duration: 4851.047417640686
[2025-02-20 18:44:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.691560200284485
avg_train_sample_per_sec: 31.691560200284485
avg_episode_per_sec: 0.27320310517486623
collect_time: 21.96168303489685
reward_mean: -121.48436041083097
reward_std: 3.181933064562982
reward_max: -118.13865546218484
reward_min: -127.52030812324931
queue_len: 0.08055992069683753
wait_time: 0.7789739348436102
delay_time: 5.1302100413182705
pressure: 0.970711759504863
total_envstep_count: 130152
total_train_sample_count: 130152
total_episode_count: 1122
total_duration: 4873.009100675583
[2025-02-20 18:45:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.427942625153133
avg_train_sample_per_sec: 31.427942625153133
avg_episode_per_sec: 0.27093053987200977
collect_time: 22.14589762687683
reward_mean: -121.90849673202615
reward_std: 1.6736509433060014
reward_max: -118.74929971988797
reward_min: -123.64495798319328
queue_len: 0.08084117820426139
wait_time: 0.7853661579574358
delay_time: 5.117327391463028
pressure: 0.9808797524314766
total_envstep_count: 130848
total_train_sample_count: 130848
total_episode_count: 1128
total_duration: 4895.15499830246
[2025-02-20 18:45:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.512423004949902
avg_train_sample_per_sec: 31.512423004949902
avg_episode_per_sec: 0.2716588190081888
collect_time: 22.086527585983276
reward_mean: -122.38153594771244
reward_std: 3.2852557437890817
reward_max: -116.56162464985992
reward_min: -127.31652661064429
queue_len: 0.08115486468681195
wait_time: 0.788965000235284
delay_time: 5.151166462895219
pressure: 0.9861847922192748
total_envstep_count: 131544
total_train_sample_count: 131544
total_episode_count: 1134
total_duration: 4917.241525888443
[2025-02-20 18:45:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.580229524413404
avg_train_sample_per_sec: 31.580229524413404
avg_episode_per_sec: 0.27224335796908106
collect_time: 22.03910517692566
reward_mean: -120.04925303454716
reward_std: 3.3786814049526854
reward_max: -113.64635854341736
reward_min: -123.34523809523805
queue_len: 0.07960825798046893
wait_time: 0.764842873488918
delay_time: 5.062189683032506
pressure: 0.9678381962864723
total_envstep_count: 132240
total_train_sample_count: 132240
total_episode_count: 1140
total_duration: 4939.280631065369
[2025-02-20 18:46:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69154058960311
avg_train_sample_per_sec: 31.69154058960311
avg_episode_per_sec: 0.2732029361172682
collect_time: 21.96169662475586
reward_mean: -126.52217553688142
reward_std: 3.7105088667462116
reward_max: -121.86624649859947
reward_min: -131.5119047619048
queue_len: 0.0839006469077463
wait_time: 0.8086590626524703
delay_time: 5.392084659383435
pressure: 1.0152519893899206
total_envstep_count: 132936
total_train_sample_count: 132936
total_episode_count: 1146
total_duration: 4961.2423276901245
[2025-02-20 18:46:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.51807966628729
avg_train_sample_per_sec: 31.51807966628729
avg_episode_per_sec: 0.27170758333006284
collect_time: 22.082563638687134
reward_mean: -123.05252100840336
reward_std: 3.7383378837944776
reward_max: -117.27310924369748
reward_min: -128.13165266106446
queue_len: 0.08159981499230992
wait_time: 0.7869564934727208
delay_time: 5.210715255294336
pressure: 0.9977895667550839
total_envstep_count: 133632
total_train_sample_count: 133632
total_episode_count: 1152
total_duration: 4983.324891328812
[2025-02-20 18:47:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.147390317539035
avg_train_sample_per_sec: 31.147390317539035
avg_episode_per_sec: 0.2685119854960262
collect_time: 22.34537124633789
reward_mean: -123.95214752567689
reward_std: 1.1873405501610634
reward_max: -121.80322128851539
reward_min: -124.99229691876747
queue_len: 0.08219638430084675
wait_time: 0.7983300083959314
delay_time: 5.14755859525284
pressure: 0.9923740053050398
total_envstep_count: 134328
total_train_sample_count: 134328
total_episode_count: 1158
total_duration: 5005.6702625751495
[2025-02-20 18:47:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.881842038996744
avg_train_sample_per_sec: 31.881842038996744
avg_episode_per_sec: 0.27484346585342023
collect_time: 21.830608129501343
reward_mean: -121.36332866479925
reward_std: 2.6971285384059995
reward_max: -118.99369747899158
reward_min: -126.46498599439776
queue_len: 0.08047966091830187
wait_time: 0.7729363407608845
delay_time: 5.169873624559639
pressure: 0.9788903625110521
total_envstep_count: 135024
total_train_sample_count: 135024
total_episode_count: 1164
total_duration: 5027.500870704651
[2025-02-20 18:47:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.51296354241118
avg_train_sample_per_sec: 31.51296354241118
avg_episode_per_sec: 0.27166347881388947
collect_time: 22.086148738861084
reward_mean: -120.77719421101772
reward_std: 3.1150867400076327
reward_max: -117.3060224089635
reward_min: -126.89425770308122
queue_len: 0.0800909775935131
wait_time: 0.7745231934506783
delay_time: 5.127913301583399
pressure: 0.9599911582670204
total_envstep_count: 135720
total_train_sample_count: 135720
total_episode_count: 1170
total_duration: 5049.587019443512
[2025-02-20 18:48:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.17130211337827
avg_train_sample_per_sec: 31.17130211337827
avg_episode_per_sec: 0.26871812166705406
collect_time: 22.328229904174805
reward_mean: -124.9470121381886
reward_std: 2.5428839279889486
reward_max: -121.76540616246497
reward_min: -128.92507002801122
queue_len: 0.08285610884495266
wait_time: 0.8002724962664113
delay_time: 5.30747459383528
pressure: 1.0020999115826703
total_envstep_count: 136416
total_train_sample_count: 136416
total_episode_count: 1176
total_duration: 5071.915249347687
[2025-02-20 18:48:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.367253953099393
avg_train_sample_per_sec: 31.367253953099393
avg_episode_per_sec: 0.27040736166464996
collect_time: 22.18874502182007
reward_mean: -124.19444444444444
reward_std: 3.1204891351919
reward_max: -119.78781512605043
reward_min: -127.62605042016801
queue_len: 0.08235705865016209
wait_time: 0.7941236065602193
delay_time: 5.296201060171068
pressure: 0.9941423519009726
total_envstep_count: 137112
total_train_sample_count: 137112
total_episode_count: 1182
total_duration: 5094.103994369507
[2025-02-20 18:48:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.41454978044035
avg_train_sample_per_sec: 31.41454978044035
avg_episode_per_sec: 0.2708150843141409
collect_time: 22.155339002609253
reward_mean: -121.89892623716152
reward_std: 3.235495471386545
reward_max: -118.74929971988794
reward_min: -127.92577030812322
queue_len: 0.08083483172225565
wait_time: 0.7793420307999416
delay_time: 5.175212435153534
pressure: 0.9720380194518126
total_envstep_count: 137808
total_train_sample_count: 137808
total_episode_count: 1188
total_duration: 5116.259333372116
[2025-02-20 18:49:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.19336063951508
avg_train_sample_per_sec: 31.19336063951508
avg_episode_per_sec: 0.26890828137513
collect_time: 22.312440395355225
reward_mean: -121.80777310924371
reward_std: 4.504381406031454
reward_max: -115.19117647058825
reward_min: -128.82983193277315
queue_len: 0.08077438535095736
wait_time: 0.7752973868592532
delay_time: 5.130837192812823
pressure: 0.9735853227232538
total_envstep_count: 138504
total_train_sample_count: 138504
total_episode_count: 1194
total_duration: 5138.571773767471
[2025-02-20 18:49:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.174465118076117
avg_train_sample_per_sec: 31.174465118076117
avg_episode_per_sec: 0.2687453889489321
collect_time: 22.32596445083618
reward_mean: -125.18697478991596
reward_std: 4.491842505142974
reward_max: -116.14285714285711
reward_min: -129.66876750700288
queue_len: 0.08301523527182757
wait_time: 0.7978364533258041
delay_time: 5.3221106243697145
pressure: 0.9952475685234305
total_envstep_count: 139200
total_train_sample_count: 139200
total_episode_count: 1200
total_duration: 5160.8977382183075
[2025-02-20 18:50:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.499336366103805
avg_train_sample_per_sec: 31.499336366103805
avg_episode_per_sec: 0.27154600315606725
collect_time: 22.095703601837158
reward_mean: -121.51762371615314
reward_std: 2.567134989816047
reward_max: -117.91596638655463
reward_min: -125.19957983193278
queue_len: 0.08058197859161349
wait_time: 0.7753509449756913
delay_time: 5.099734457829017
pressure: 0.9681697612732095
total_envstep_count: 139896
total_train_sample_count: 139896
total_episode_count: 1206
total_duration: 5182.993441820145
[2025-02-20 18:50:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.405774191900992
avg_train_sample_per_sec: 31.405774191900992
avg_episode_per_sec: 0.27073943268880163
collect_time: 22.161529779434204
reward_mean: -124.6670168067227
reward_std: 5.251797808718265
reward_max: -117.1043417366947
reward_min: -131.95938375350138
queue_len: 0.08267043554822459
wait_time: 0.8026850881820454
delay_time: 5.174150853166666
pressure: 1.0020999115826703
total_envstep_count: 140592
total_train_sample_count: 140592
total_episode_count: 1212
total_duration: 5205.154971599579
[2025-02-20 18:50:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61617410119108
avg_train_sample_per_sec: 31.61617410119108
avg_episode_per_sec: 0.2725532250102679
collect_time: 22.01404881477356
reward_mean: -124.1531279178338
reward_std: 4.027331699062807
reward_max: -119.0126050420168
reward_min: -130.2514005602241
queue_len: 0.0823296604229667
wait_time: 0.8019067927790037
delay_time: 5.200810480846123
pressure: 0.9878426171529621
total_envstep_count: 141288
total_train_sample_count: 141288
total_episode_count: 1218
total_duration: 5227.169020414352
[2025-02-20 18:51:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.356692595846205
avg_train_sample_per_sec: 31.356692595846205
avg_episode_per_sec: 0.2703163154814328
collect_time: 22.196218490600586
reward_mean: -120.91071428571428
reward_std: 2.859906932864703
reward_max: -116.91386554621847
reward_min: -126.00490196078432
queue_len: 0.08017951875710495
wait_time: 0.7729492659132617
delay_time: 5.158601414604718
pressure: 0.9725906277630415
total_envstep_count: 141984
total_train_sample_count: 141984
total_episode_count: 1224
total_duration: 5249.365238904953
[2025-02-20 18:51:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.465421677859148
avg_train_sample_per_sec: 31.465421677859148
avg_episode_per_sec: 0.2712536351539582
collect_time: 22.119519233703613
reward_mean: -121.80438842203552
reward_std: 5.012579861132103
reward_max: -115.71148459383754
reward_min: -130.78431372549022
queue_len: 0.08077214086341877
wait_time: 0.7849670261561741
delay_time: 5.104165919592262
pressure: 0.9772325375773652
total_envstep_count: 142680
total_train_sample_count: 142680
total_episode_count: 1230
total_duration: 5271.484758138657
[2025-02-20 18:51:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.170304944627254
avg_train_sample_per_sec: 31.170304944627254
avg_episode_per_sec: 0.2687095253847177
collect_time: 22.328944206237793
reward_mean: -122.67436974789916
reward_std: 4.74731796734204
reward_max: -117.84663865546224
reward_min: -131.97759103641457
queue_len: 0.0813490515569623
wait_time: 0.7951017387503189
delay_time: 5.166547645178087
pressure: 0.9846374889478339
total_envstep_count: 143376
total_train_sample_count: 143376
total_episode_count: 1236
total_duration: 5293.813702344894
[2025-02-20 18:52:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.695716492090455
avg_train_sample_per_sec: 31.695716492090455
avg_episode_per_sec: 0.27323893527664184
collect_time: 21.958803176879883
reward_mean: -122.08333333333331
reward_std: 6.5456450835936
reward_max: -114.15336134453783
reward_min: -133.28711484593833
queue_len: 0.0809571175950486
wait_time: 0.7777631499107159
delay_time: 5.08398846538964
pressure: 0.985632183908046
total_envstep_count: 144072
total_train_sample_count: 144072
total_episode_count: 1242
total_duration: 5315.772505521774
[2025-02-20 18:52:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.728292613372457
avg_train_sample_per_sec: 31.728292613372457
avg_episode_per_sec: 0.2735197639083833
collect_time: 21.9362576007843
reward_mean: -120.90732959850607
reward_std: 3.0657485561897944
reward_max: -115.92577030812325
reward_min: -125.41806722689074
queue_len: 0.08017727426956638
wait_time: 0.778909154289479
delay_time: 5.043495963207285
pressure: 0.9757957559681699
total_envstep_count: 144768
total_train_sample_count: 144768
total_episode_count: 1248
total_duration: 5337.708763122559
[2025-02-20 18:53:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.283188382445047
avg_train_sample_per_sec: 31.283188382445047
avg_episode_per_sec: 0.26968265846935385
collect_time: 22.248371601104736
reward_mean: -122.40126050420169
reward_std: 3.0615896249757397
reward_max: -117.24509803921572
reward_min: -127.10224089635858
queue_len: 0.08116794463143347
wait_time: 0.7829288766788767
delay_time: 5.1191083034861995
pressure: 0.9828691423519009
total_envstep_count: 145464
total_train_sample_count: 145464
total_episode_count: 1254
total_duration: 5359.957134723663
[2025-02-20 18:53:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.256560004598917
avg_train_sample_per_sec: 31.256560004598917
avg_episode_per_sec: 0.2694531034879217
collect_time: 22.26732563972473
reward_mean: -122.16795051353874
reward_std: 6.3331739334179336
reward_max: -114.73529411764703
reward_min: -132.93767507002804
queue_len: 0.08101322978351376
wait_time: 0.7844132569031149
delay_time: 5.1684822761818126
pressure: 0.9777851458885941
total_envstep_count: 146160
total_train_sample_count: 146160
total_episode_count: 1260
total_duration: 5382.224460363388
[2025-02-20 18:53:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.454112218396627
avg_train_sample_per_sec: 31.454112218396627
avg_episode_per_sec: 0.271156139813764
collect_time: 22.127472400665283
reward_mean: -124.0228758169935
reward_std: 2.783828502831405
reward_max: -118.56022408963591
reward_min: -127.02240896358546
queue_len: 0.08224328635079145
wait_time: 0.7895485669953216
delay_time: 5.250715308337603
pressure: 0.9946949602122016
total_envstep_count: 146856
total_train_sample_count: 146856
total_episode_count: 1266
total_duration: 5404.351932764053
[2025-02-20 18:54:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72168330681869
avg_train_sample_per_sec: 31.72168330681869
avg_episode_per_sec: 0.2734627871277473
collect_time: 21.94082808494568
reward_mean: -122.03256302521008
reward_std: 4.97071748896461
reward_max: -113.35924369747902
reward_min: -129.4747899159663
queue_len: 0.08092345028196955
wait_time: 0.7810663390024445
delay_time: 5.146031649633336
pressure: 0.9752431476569408
total_envstep_count: 147552
total_train_sample_count: 147552
total_episode_count: 1272
total_duration: 5426.292760848999
[2025-02-20 18:54:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.146936024202898
avg_train_sample_per_sec: 31.146936024202898
avg_episode_per_sec: 0.2685080691741629
collect_time: 22.345697164535522
reward_mean: -124.77217553688142
reward_std: 2.661818215596566
reward_max: -122.13935574229693
reward_min: -129.3466386554622
queue_len: 0.08274016945416542
wait_time: 0.8004379691752918
delay_time: 5.2403167992752735
pressure: 1.0113837312113174
total_envstep_count: 148248
total_train_sample_count: 148248
total_episode_count: 1278
total_duration: 5448.638458013535
[2025-02-20 18:54:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.41962723335537
avg_train_sample_per_sec: 31.41962723335537
avg_episode_per_sec: 0.2708588554599601
collect_time: 22.151758670806885
reward_mean: -123.62943510737627
reward_std: 4.085650818168611
reward_max: -116.62254901960785
reward_min: -128.46638655462186
queue_len: 0.08198238402345907
wait_time: 0.7944188727657288
delay_time: 5.176351773261744
pressure: 0.9929266136162688
total_envstep_count: 148944
total_train_sample_count: 148944
total_episode_count: 1284
total_duration: 5470.790216684341
[2025-02-20 18:55:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.671392263161152
avg_train_sample_per_sec: 31.671392263161152
avg_episode_per_sec: 0.27302924364794096
collect_time: 21.97566795349121
reward_mean: -119.87826797385621
reward_std: 2.426181311067942
reward_max: -117.43347338935573
reward_min: -123.89425770308127
queue_len: 0.07949487266170836
wait_time: 0.7642851570336356
delay_time: 5.065926274566769
pressure: 0.9675066312997349
total_envstep_count: 149640
total_train_sample_count: 149640
total_episode_count: 1290
total_duration: 5492.765884637833
[2025-02-20 18:55:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.320409809134084
avg_train_sample_per_sec: 31.320409809134084
avg_episode_per_sec: 0.2700035328373628
collect_time: 22.22193145751953
reward_mean: -123.43487394957982
reward_std: 3.4808437636165555
reward_max: -116.54411764705881
reward_min: -127.20308123249292
queue_len: 0.08185336468805028
wait_time: 0.7890249822298504
delay_time: 5.193871439338415
pressure: 1.0004420866489834
total_envstep_count: 150336
total_train_sample_count: 150336
total_episode_count: 1296
total_duration: 5514.987816095352
[2025-02-20 18:56:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.306515512976507
avg_train_sample_per_sec: 31.306515512976507
avg_episode_per_sec: 0.26988375442221124
collect_time: 22.231793880462646
reward_mean: -122.32294584500465
reward_std: 3.727371645181001
reward_max: -117.05252100840337
reward_min: -127.94957983193277
queue_len: 0.08111601183355747
wait_time: 0.7912201684387282
delay_time: 5.120937242156523
pressure: 0.9817639257294429
total_envstep_count: 151032
total_train_sample_count: 151032
total_episode_count: 1302
total_duration: 5537.219609975815
[2025-02-20 18:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.852885276098675
avg_train_sample_per_sec: 30.852885276098675
avg_episode_per_sec: 0.2659731489318851
collect_time: 22.55866813659668
reward_mean: -121.43872549019606
reward_std: 4.300555918130294
reward_max: -114.09453781512606
reward_min: -128.32282913165264
queue_len: 0.08052965881312736
wait_time: 0.7797656971718836
delay_time: 5.099138378340528
pressure: 0.9766799292661362
total_envstep_count: 151728
total_train_sample_count: 151728
total_episode_count: 1308
total_duration: 5559.7782781124115
[2025-02-20 18:56:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.98953011020459
avg_train_sample_per_sec: 30.98953011020459
avg_episode_per_sec: 0.26715112163969473
collect_time: 22.459198236465454
reward_mean: -122.86227824463118
reward_std: 3.557945031671882
reward_max: -117.19117647058822
reward_min: -127.8956582633053
queue_len: 0.0814736593134159
wait_time: 0.7910170036184235
delay_time: 5.1151200580048375
pressure: 0.9794429708222813
total_envstep_count: 152424
total_train_sample_count: 152424
total_episode_count: 1314
total_duration: 5582.237476348877
[2025-02-20 18:57:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.2753618698033
avg_train_sample_per_sec: 31.2753618698033
avg_episode_per_sec: 0.2696151885327871
collect_time: 22.253939151763916
reward_mean: -123.02170868347342
reward_std: 3.5349831855593865
reward_max: -116.96148459383754
reward_min: -126.88375350140063
queue_len: 0.08157938241609643
wait_time: 0.7910354238954644
delay_time: 5.070567639742252
pressure: 0.9896109637488948
total_envstep_count: 153120
total_train_sample_count: 153120
total_episode_count: 1320
total_duration: 5604.491415500641
[2025-02-20 18:57:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.522116554587708
avg_train_sample_per_sec: 30.522116554587708
avg_episode_per_sec: 0.26312169443610095
collect_time: 22.803136825561523
reward_mean: -121.59640522875816
reward_std: 1.1710163005519887
reward_max: -119.67436974789914
reward_min: -123.47969187675068
queue_len: 0.08063422097397754
wait_time: 0.7841518128029282
delay_time: 5.115669040512246
pressure: 0.9826480990274092
total_envstep_count: 153816
total_train_sample_count: 153816
total_episode_count: 1326
total_duration: 5627.294552326202
[2025-02-20 18:58:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.40238740861368
avg_train_sample_per_sec: 31.40238740861368
avg_episode_per_sec: 0.2707102362811524
collect_time: 22.163919925689697
reward_mean: -120.49719887955182
reward_std: 2.546421604181134
reward_max: -115.1183473389355
reward_min: -123.09103641456583
queue_len: 0.07990530429678501
wait_time: 0.7753586071917716
delay_time: 5.058341894702842
pressure: 0.970711759504863
total_envstep_count: 154512
total_train_sample_count: 154512
total_episode_count: 1332
total_duration: 5649.458472251892
[2025-02-20 18:58:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.402703252277618
avg_train_sample_per_sec: 31.402703252277618
avg_episode_per_sec: 0.2707129590713588
collect_time: 22.163697004318237
reward_mean: -121.67098506069094
reward_std: 3.7145678800278863
reward_max: -115.7373949579832
reward_min: -126.18837535014009
queue_len: 0.08068367709594891
wait_time: 0.7803982556771604
delay_time: 5.1665926458826625
pressure: 0.9748010610079575
total_envstep_count: 155208
total_train_sample_count: 155208
total_episode_count: 1338
total_duration: 5671.62216925621
[2025-02-20 18:58:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32661560607892
avg_train_sample_per_sec: 31.32661560607892
avg_episode_per_sec: 0.2700570310868872
collect_time: 22.217529296875
reward_mean: -123.4090802987862
reward_std: 4.6316841318582185
reward_max: -116.72058823529412
reward_min: -130.4383753501401
queue_len: 0.08183626014508368
wait_time: 0.7941063472250085
delay_time: 5.1951275767370015
pressure: 0.9769009725906278
total_envstep_count: 155904
total_train_sample_count: 155904
total_episode_count: 1344
total_duration: 5693.839698553085
[2025-02-20 18:59:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.344671228718145
avg_train_sample_per_sec: 31.344671228718145
avg_episode_per_sec: 0.2702126830061909
collect_time: 22.204731225967407
reward_mean: -122.11601307189541
reward_std: 1.0335165487220626
reward_max: -119.983893557423
reward_min: -123.32072829131656
queue_len: 0.08097878850921447
wait_time: 0.775042057052706
delay_time: 5.1235804129335465
pressure: 0.9706012378426171
total_envstep_count: 156600
total_train_sample_count: 156600
total_episode_count: 1350
total_duration: 5716.044429779053
[2025-02-20 18:59:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30195786363053
avg_train_sample_per_sec: 31.30195786363053
avg_episode_per_sec: 0.2698444643416425
collect_time: 22.23503088951111
reward_mean: -122.28641456582636
reward_std: 2.0042621162347487
reward_max: -119.06372549019612
reward_min: -125.16666666666669
queue_len: 0.08109178684736496
wait_time: 0.7816831860949507
delay_time: 5.141814587224345
pressure: 0.9835322723253759
total_envstep_count: 157296
total_train_sample_count: 157296
total_episode_count: 1356
total_duration: 5738.279460668564
[2025-02-20 18:59:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72451769665204
avg_train_sample_per_sec: 31.72451769665204
avg_episode_per_sec: 0.2734872215228624
collect_time: 21.938867807388306
reward_mean: -122.07901493930906
reward_std: 3.609937828720388
reward_max: -115.79131652661064
reward_min: -126.0252100840336
queue_len: 0.08095425393853385
wait_time: 0.78087927257552
delay_time: 5.071990664332874
pressure: 0.9864058355437666
total_envstep_count: 157992
total_train_sample_count: 157992
total_episode_count: 1362
total_duration: 5760.218328475952
[2025-02-20 19:00:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49998080371925
avg_train_sample_per_sec: 31.49998080371925
avg_episode_per_sec: 0.27155155865275216
collect_time: 22.09525156021118
reward_mean: -123.91631652661066
reward_std: 3.669357592687244
reward_max: -117.97058823529412
reward_min: -129.53921568627453
queue_len: 0.08217262369138638
wait_time: 0.7968464795290354
delay_time: 5.115224627654865
pressure: 0.9959106984969054
total_envstep_count: 158688
total_train_sample_count: 158688
total_episode_count: 1368
total_duration: 5782.313580036163
[2025-02-20 19:00:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5229326215463
avg_train_sample_per_sec: 31.5229326215463
avg_episode_per_sec: 0.2717494191512612
collect_time: 22.079164028167725
reward_mean: -124.27100840336134
reward_std: 2.839497464336602
reward_max: -119.74579831932778
reward_min: -128.6211484593838
queue_len: 0.08240783050620777
wait_time: 0.8017687180973185
delay_time: 5.163439004877843
pressure: 0.9953580901856763
total_envstep_count: 159384
total_train_sample_count: 159384
total_episode_count: 1374
total_duration: 5804.392744064331
[2025-02-20 19:01:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54706471389921
avg_train_sample_per_sec: 31.54706471389921
avg_episode_per_sec: 0.2719574544301656
collect_time: 22.06227445602417
reward_mean: -121.61729691876752
reward_std: 3.3865495234793865
reward_max: -117.29971988795522
reward_min: -126.73669467787116
queue_len: 0.0806480748798193
wait_time: 0.7818863509152556
delay_time: 5.144149189861705
pressure: 0.9765694076038905
total_envstep_count: 160080
total_train_sample_count: 160080
total_episode_count: 1380
total_duration: 5826.455018520355
[2025-02-20 19:01:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.484027852973366
avg_train_sample_per_sec: 31.484027852973366
avg_episode_per_sec: 0.2714140332152876
collect_time: 22.106447219848633
reward_mean: -121.82399626517271
reward_std: 4.352317865770526
reward_max: -116.23599439775911
reward_min: -127.9705882352941
queue_len: 0.08078514341191827
wait_time: 0.7813554909143144
delay_time: 5.040947366297657
pressure: 0.9741379310344828
total_envstep_count: 160776
total_train_sample_count: 160776
total_episode_count: 1386
total_duration: 5848.561465740204
[2025-02-20 19:01:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.168293161172397
avg_train_sample_per_sec: 31.168293161172397
avg_episode_per_sec: 0.2686921824239
collect_time: 22.330385446548462
reward_mean: -122.92833800186742
reward_std: 4.177253000607316
reward_max: -114.7682072829132
reward_min: -126.36134453781514
queue_len: 0.08151746551847973
wait_time: 0.7805247983366644
delay_time: 5.196868525962672
pressure: 0.9840848806366048
total_envstep_count: 161472
total_train_sample_count: 161472
total_episode_count: 1392
total_duration: 5870.891851186752
[2025-02-20 19:02:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.50972127599345
avg_train_sample_per_sec: 31.50972127599345
avg_episode_per_sec: 0.2716355282413228
collect_time: 22.08842134475708
reward_mean: -122.85679271708686
reward_std: 2.853525449745166
reward_max: -119.13095238095241
reward_min: -126.11344537815121
queue_len: 0.08147002169568093
wait_time: 0.7884996173535727
delay_time: 5.137819234005211
pressure: 0.9851900972590628
total_envstep_count: 162168
total_train_sample_count: 162168
total_episode_count: 1398
total_duration: 5892.980272531509
[2025-02-20 19:02:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.38592875827213
avg_train_sample_per_sec: 31.38592875827213
avg_episode_per_sec: 0.2705683513644149
collect_time: 22.17554259300232
reward_mean: -122.86356209150328
reward_std: 2.7021299848413096
reward_max: -118.1575630252101
reward_min: -126.71778711484596
queue_len: 0.08147451067075814
wait_time: 0.7961859036275872
delay_time: 5.14958032185485
pressure: 0.9880636604774535
total_envstep_count: 162864
total_train_sample_count: 162864
total_episode_count: 1404
total_duration: 5915.155815124512
[2025-02-20 19:02:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.826920530144644
avg_train_sample_per_sec: 31.826920530144644
avg_episode_per_sec: 0.27437000457021243
collect_time: 21.868279695510864
reward_mean: -120.5410830999066
reward_std: 0.9981209040463217
reward_max: -118.90686274509801
reward_min: -121.78641456582629
queue_len: 0.07993440523866485
wait_time: 0.7724533115633522
delay_time: 5.049775497772868
pressure: 0.966290893015031
total_envstep_count: 163560
total_train_sample_count: 163560
total_episode_count: 1410
total_duration: 5937.024094820023
[2025-02-20 19:03:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.460204307352967
avg_train_sample_per_sec: 31.460204307352967
avg_episode_per_sec: 0.2712086578220083
collect_time: 22.12318754196167
reward_mean: -120.54493464052287
reward_std: 3.2947201002499753
reward_max: -113.7079831932773
reward_min: -124.23459383753499
queue_len: 0.07993695931069156
wait_time: 0.7623587675565364
delay_time: 5.063845227899329
pressure: 0.9634173297966401
total_envstep_count: 164256
total_train_sample_count: 164256
total_episode_count: 1416
total_duration: 5959.147282361984
[2025-02-20 19:03:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.130185944821992
avg_train_sample_per_sec: 31.130185944821992
avg_episode_per_sec: 0.2683636719381206
collect_time: 22.357720613479614
reward_mean: -123.80742296918767
reward_std: 2.0034036135164683
reward_max: -121.59943977591037
reward_min: -127.49159663865551
queue_len: 0.0821004131095409
wait_time: 0.7913494973586251
delay_time: 5.119015041806982
pressure: 0.987290008841733
total_envstep_count: 164952
total_train_sample_count: 164952
total_episode_count: 1422
total_duration: 5981.505002975464
[2025-02-20 19:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.476374423471654
avg_train_sample_per_sec: 31.476374423471654
avg_episode_per_sec: 0.27134805537475565
collect_time: 22.111822366714478
reward_mean: -123.18872549019608
reward_std: 4.983629436652852
reward_max: -116.22969187675069
reward_min: -132.203081232493
queue_len: 0.08169013626670828
wait_time: 0.7868623797883432
delay_time: 5.259496321990697
pressure: 0.9714854111405836
total_envstep_count: 165648
total_train_sample_count: 165648
total_episode_count: 1428
total_duration: 6003.616825342178
[2025-02-20 19:04:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.212002429656696
avg_train_sample_per_sec: 31.212002429656696
avg_episode_per_sec: 0.2690689864625577
collect_time: 22.299113988876343
reward_mean: -121.54388422035481
reward_std: 3.919167612873662
reward_max: -115.56022408963588
reward_min: -126.22408963585434
queue_len: 0.08059939271906817
wait_time: 0.772382803696191
delay_time: 5.1305973702689185
pressure: 0.9706012378426171
total_envstep_count: 166344
total_train_sample_count: 166344
total_episode_count: 1434
total_duration: 6025.915939331055
[2025-02-20 19:04:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.359701315591757
avg_train_sample_per_sec: 31.359701315591757
avg_episode_per_sec: 0.27034225272061857
collect_time: 22.19408893585205
reward_mean: -123.30812324929974
reward_std: 2.6766774090076324
reward_max: -119.02521008403365
reward_min: -126.02030812324928
queue_len: 0.08176931249953563
wait_time: 0.7849450456575203
delay_time: 5.177820586979279
pressure: 0.9812113174182139
total_envstep_count: 167040
total_train_sample_count: 167040
total_episode_count: 1440
total_duration: 6048.110028266907
[2025-02-20 19:05:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.356995395405097
avg_train_sample_per_sec: 31.356995395405097
avg_episode_per_sec: 0.27031892582245776
collect_time: 22.196004152297974
reward_mean: -122.52007469654525
reward_std: 1.7074884496976501
reward_max: -120.06862745098039
reward_min: -125.15406162464984
queue_len: 0.08124673388365071
wait_time: 0.7780850403822007
delay_time: 5.1848002218715505
pressure: 0.9830901856763926
total_envstep_count: 167736
total_train_sample_count: 167736
total_episode_count: 1446
total_duration: 6070.306032419205
[2025-02-20 19:05:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74648189769525
avg_train_sample_per_sec: 31.74648189769525
avg_episode_per_sec: 0.27367656808357976
collect_time: 21.923689126968384
reward_mean: -122.1576797385621
reward_std: 4.0474970099888425
reward_max: -116.30532212885151
reward_min: -129.37254901960787
queue_len: 0.08100641892477593
wait_time: 0.7806820672566106
delay_time: 5.168907685604019
pressure: 0.9680592396109637
total_envstep_count: 168432
total_train_sample_count: 168432
total_episode_count: 1452
total_duration: 6092.229721546173
[2025-02-20 19:05:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.272482543349977
avg_train_sample_per_sec: 31.272482543349977
avg_episode_per_sec: 0.269590366753017
collect_time: 22.255988121032715
reward_mean: -121.05485527544353
reward_std: 3.26011384701881
reward_max: -116.15126050420172
reward_min: -124.56652661064426
queue_len: 0.08027510296780073
wait_time: 0.7776207410461974
delay_time: 5.041590917530481
pressure: 0.9757957559681697
total_envstep_count: 169128
total_train_sample_count: 169128
total_episode_count: 1458
total_duration: 6114.485709667206
[2025-02-20 19:06:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.324463935365944
avg_train_sample_per_sec: 31.324463935365944
avg_episode_per_sec: 0.27003848220143056
collect_time: 22.21905541419983
reward_mean: -121.85877684407096
reward_std: 2.2647073139015568
reward_max: -118.55952380952375
reward_min: -125.17436974789915
queue_len: 0.08080820745628048
wait_time: 0.7818972637684606
delay_time: 5.183526227308852
pressure: 0.9847480106100795
total_envstep_count: 169824
total_train_sample_count: 169824
total_episode_count: 1464
total_duration: 6136.704765081406
[2025-02-20 19:06:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.17155374548049
avg_train_sample_per_sec: 31.17155374548049
avg_episode_per_sec: 0.26872029090931454
collect_time: 22.328049659729004
reward_mean: -119.83181605975723
reward_std: 3.72020653947546
reward_max: -115.15336134453786
reward_min: -125.10294117647055
queue_len: 0.07946406900514404
wait_time: 0.7576118312046304
delay_time: 5.034169367008656
pressure: 0.9576702033598585
total_envstep_count: 170520
total_train_sample_count: 170520
total_episode_count: 1470
total_duration: 6159.032814741135
[2025-02-20 19:07:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85620898885007
avg_train_sample_per_sec: 31.85620898885007
avg_episode_per_sec: 0.2746224912831903
collect_time: 21.84817409515381
reward_mean: -122.63725490196076
reward_std: 3.934417496837659
reward_max: -117.24649859943972
reward_min: -129.93137254901956
queue_len: 0.08132443959015966
wait_time: 0.7859335489279707
delay_time: 5.193205974988485
pressure: 0.9848585322723254
total_envstep_count: 171216
total_train_sample_count: 171216
total_episode_count: 1476
total_duration: 6180.880988836288
[2025-02-20 19:07:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.36970443891811
avg_train_sample_per_sec: 31.36970443891811
avg_episode_per_sec: 0.2704284865423975
collect_time: 22.18701171875
reward_mean: -123.72630718954247
reward_std: 4.442531541378792
reward_max: -117.37254901960782
reward_min: -130.55252100840337
queue_len: 0.08204662280473639
wait_time: 0.7907451110417641
delay_time: 5.177349567711995
pressure: 0.999336870026525
total_envstep_count: 171912
total_train_sample_count: 171912
total_episode_count: 1482
total_duration: 6203.068000555038
[2025-02-20 19:07:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.414198541039614
avg_train_sample_per_sec: 31.414198541039614
avg_episode_per_sec: 0.27081205638827255
collect_time: 22.15558671951294
reward_mean: -120.86636321195147
reward_std: 1.7053049848941702
reward_max: -119.45098039215692
reward_min: -124.3739495798319
queue_len: 0.08015010823073705
wait_time: 0.7709734977103131
delay_time: 5.062354012502761
pressure: 0.9753536693191865
total_envstep_count: 172608
total_train_sample_count: 172608
total_episode_count: 1488
total_duration: 6225.223587274551
[2025-02-20 19:08:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.325616207181785
avg_train_sample_per_sec: 31.325616207181785
avg_episode_per_sec: 0.2700484155791533
collect_time: 22.21823811531067
reward_mean: -121.23856209150328
reward_std: 3.0071333103078173
reward_max: -116.56302521008406
reward_min: -126.859243697479
queue_len: 0.0803969244638616
wait_time: 0.7718587545539878
delay_time: 5.040329165863059
pressure: 0.9766799292661362
total_envstep_count: 173304
total_train_sample_count: 173304
total_episode_count: 1494
total_duration: 6247.441825389862
[2025-02-20 19:08:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71441624924672
avg_train_sample_per_sec: 31.71441624924672
avg_episode_per_sec: 0.27340014007971314
collect_time: 21.945855617523193
reward_mean: -120.9033613445378
reward_std: 2.9960893792308236
reward_max: -116.47899159663865
reward_min: -125.86834733893556
queue_len: 0.08017464280141763
wait_time: 0.7691433890090078
delay_time: 5.053847840470772
pressure: 0.9683908045977011
total_envstep_count: 174000
total_train_sample_count: 174000
total_episode_count: 1500
total_duration: 6269.387681007385
[2025-02-20 19:08:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.616730188710655
avg_train_sample_per_sec: 31.616730188710655
avg_episode_per_sec: 0.2725580188681953
collect_time: 22.0136616230011
reward_mean: -124.1810224089636
reward_std: 3.646954473621582
reward_max: -118.0700280112045
reward_min: -129.02310924369752
queue_len: 0.08234815809612972
wait_time: 0.7856882806172866
delay_time: 5.249164919195715
pressure: 0.9934792219274978
total_envstep_count: 174696
total_train_sample_count: 174696
total_episode_count: 1506
total_duration: 6291.401342630386
[2025-02-20 19:09:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.463857912794893
avg_train_sample_per_sec: 31.463857912794893
avg_episode_per_sec: 0.27124015442064564
collect_time: 22.12061858177185
reward_mean: -117.03676470588238
reward_std: 4.2096839384319935
reward_max: -112.8858543417367
reward_min: -125.18557422969188
queue_len: 0.07761058667498831
wait_time: 0.7406421896787009
delay_time: 4.946870839402714
pressure: 0.9445181255526083
total_envstep_count: 175392
total_train_sample_count: 175392
total_episode_count: 1512
total_duration: 6313.521961212158
[2025-02-20 19:09:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.480206613836167
avg_train_sample_per_sec: 31.480206613836167
avg_episode_per_sec: 0.27138109149858763
collect_time: 22.10913062095642
reward_mean: -123.250350140056
reward_std: 3.882218767975807
reward_max: -118.1911764705882
reward_min: -128.29201680672267
queue_len: 0.08173100141913528
wait_time: 0.78774043879267
delay_time: 5.102998741627781
pressure: 0.9920424403183024
total_envstep_count: 176088
total_train_sample_count: 176088
total_episode_count: 1518
total_duration: 6335.631091833115
[2025-02-20 19:10:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.410745386882766
avg_train_sample_per_sec: 31.410745386882766
avg_episode_per_sec: 0.2707822878179549
collect_time: 22.15802240371704
reward_mean: -121.24941643323997
reward_std: 3.0225795781323095
reward_max: -117.26820728291318
reward_min: -127.24159663865547
queue_len: 0.08040412230320954
wait_time: 0.7779066423209428
delay_time: 5.094496552581778
pressure: 0.9832007073386384
total_envstep_count: 176784
total_train_sample_count: 176784
total_episode_count: 1524
total_duration: 6357.789114236832
[2025-02-20 19:10:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.546992142616634
avg_train_sample_per_sec: 30.546992142616634
avg_episode_per_sec: 0.2633361391604882
collect_time: 22.78456735610962
reward_mean: -120.68125583566761
reward_std: 3.6270234512384403
reward_max: -116.92296918767514
reward_min: -125.7205882352941
queue_len: 0.08002735798121195
wait_time: 0.7716906501769585
delay_time: 5.0269895689421
pressure: 0.9727011494252874
total_envstep_count: 177480
total_train_sample_count: 177480
total_episode_count: 1530
total_duration: 6380.573681592941
[2025-02-20 19:10:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.287235225139096
avg_train_sample_per_sec: 31.287235225139096
avg_episode_per_sec: 0.2697175450443025
collect_time: 22.24549388885498
reward_mean: -120.62885154061622
reward_std: 2.7480104871937905
reward_max: -117.8004201680672
reward_min: -124.52380952380955
queue_len: 0.07999260712242455
wait_time: 0.765691599362999
delay_time: 5.035582854916414
pressure: 0.9672855879752431
total_envstep_count: 178176
total_train_sample_count: 178176
total_episode_count: 1536
total_duration: 6402.819175481796
[2025-02-20 19:11:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.555446682376314
avg_train_sample_per_sec: 31.555446682376314
avg_episode_per_sec: 0.27202971277910615
collect_time: 22.056414127349854
reward_mean: -122.43172268907561
reward_std: 3.155015159979708
reward_max: -117.98249299719886
reward_min: -127.00560224089637
queue_len: 0.08118814501928091
wait_time: 0.7815379135739177
delay_time: 5.145799055208694
pressure: 0.9797745358090185
total_envstep_count: 178872
total_train_sample_count: 178872
total_episode_count: 1542
total_duration: 6424.875589609146
[2025-02-20 19:11:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.535943147843348
avg_train_sample_per_sec: 31.535943147843348
avg_episode_per_sec: 0.27186157886071854
collect_time: 22.07005500793457
reward_mean: -119.84803921568626
reward_std: 3.3394734942664877
reward_max: -114.98389355742297
reward_min: -124.86974789915965
queue_len: 0.07947482706610495
wait_time: 0.7649216627411354
delay_time: 5.057173413603929
pressure: 0.9598806366047746
total_envstep_count: 179568
total_train_sample_count: 179568
total_episode_count: 1548
total_duration: 6446.945644617081
[2025-02-20 19:11:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.546744255092563
avg_train_sample_per_sec: 31.546744255092563
avg_episode_per_sec: 0.2719546918542462
collect_time: 22.062498569488525
reward_mean: -119.8454715219421
reward_std: 4.296610266203053
reward_max: -112.80462184873954
reward_min: -125.31232492997196
queue_len: 0.07947312435142051
wait_time: 0.7686003004207872
delay_time: 5.024284016604446
pressure: 0.96131741821397
total_envstep_count: 180264
total_train_sample_count: 180264
total_episode_count: 1554
total_duration: 6469.008143186569
[2025-02-20 19:12:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.677518974729534
avg_train_sample_per_sec: 31.677518974729534
avg_episode_per_sec: 0.2730820601269787
collect_time: 21.971417665481567
reward_mean: -120.671685340803
reward_std: 2.5396221038672424
reward_max: -118.3550420168067
reward_min: -124.45938375350141
queue_len: 0.08002101149920622
wait_time: 0.7746126633677345
delay_time: 5.007925369020189
pressure: 0.9759062776304156
total_envstep_count: 180960
total_train_sample_count: 180960
total_episode_count: 1560
total_duration: 6490.979560852051
[2025-02-20 19:12:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.561843912734382
avg_train_sample_per_sec: 31.561843912734382
avg_episode_per_sec: 0.2720848613166757
collect_time: 22.05194354057312
reward_mean: -122.46323529411767
reward_std: 5.019405507964089
reward_max: -118.38935574229696
reward_min: -132.79971988795518
queue_len: 0.08120904197222656
wait_time: 0.7831886180643787
delay_time: 5.0793272419339175
pressure: 0.9878426171529621
total_envstep_count: 181656
total_train_sample_count: 181656
total_episode_count: 1566
total_duration: 6513.031504392624
[2025-02-20 19:13:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.655288605811684
avg_train_sample_per_sec: 31.655288605811684
avg_episode_per_sec: 0.27289041901561795
collect_time: 21.986847400665283
reward_mean: -124.73751167133518
reward_std: 3.8865062626147044
reward_max: -119.07142857142857
reward_min: -129.782212885154
queue_len: 0.0827171828059252
wait_time: 0.7977294918851715
delay_time: 5.225067143850099
pressure: 1.0085101679929267
total_envstep_count: 182352
total_train_sample_count: 182352
total_episode_count: 1572
total_duration: 6535.018351793289
[2025-02-20 19:13:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.27208757354708
avg_train_sample_per_sec: 31.27208757354708
avg_episode_per_sec: 0.2695869618409231
collect_time: 22.256269216537476
reward_mean: -119.87710084033615
reward_std: 1.2346244057273703
reward_max: -118.67577030812328
reward_min: -122.02240896358545
queue_len: 0.07949409870048815
wait_time: 0.7649420179212266
delay_time: 5.033180367066964
pressure: 0.9581122900088417
total_envstep_count: 183048
total_train_sample_count: 183048
total_episode_count: 1578
total_duration: 6557.274621009827
[2025-02-20 19:13:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.749718859840513
avg_train_sample_per_sec: 31.749718859840513
avg_episode_per_sec: 0.2737044729296596
collect_time: 21.921453952789307
reward_mean: -121.12990196078431
reward_std: 2.6399880909586826
reward_max: -116.30812324929973
reward_min: -124.62254901960782
queue_len: 0.08032486867426016
wait_time: 0.7807432875891295
delay_time: 5.093176823192533
pressure: 0.9807692307692308
total_envstep_count: 183744
total_train_sample_count: 183744
total_episode_count: 1584
total_duration: 6579.196074962616
[2025-02-20 19:14:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.352076553036284
avg_train_sample_per_sec: 31.352076553036284
avg_episode_per_sec: 0.2702765220089335
collect_time: 22.19948649406433
reward_mean: -120.9281045751634
reward_std: 4.298830601190045
reward_max: -113.54621848739498
reward_min: -125.47759103641455
queue_len: 0.08019105077928608
wait_time: 0.7703513876815093
delay_time: 5.117334028035354
pressure: 0.9660698496905393
total_envstep_count: 184440
total_train_sample_count: 184440
total_episode_count: 1590
total_duration: 6601.39556145668
[2025-02-20 19:14:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.400954537797826
avg_train_sample_per_sec: 31.400954537797826
avg_episode_per_sec: 0.270697883946533
collect_time: 22.164931297302246
reward_mean: -124.72630718954248
reward_std: 3.712252255244809
reward_max: -120.01540616246498
reward_min: -129.65476190476193
queue_len: 0.0827097527782112
wait_time: 0.8057898336169127
delay_time: 5.119857400871944
pressure: 1.0038682581786031
total_envstep_count: 185136
total_train_sample_count: 185136
total_episode_count: 1596
total_duration: 6623.5604927539825
[2025-02-20 19:14:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.503338015969597
avg_train_sample_per_sec: 31.503338015969597
avg_episode_per_sec: 0.27158050013766893
collect_time: 22.092896938323975
reward_mean: -122.0925536881419
reward_std: 3.0806431778947054
reward_max: -118.19327731092437
reward_min: -127.42016806722691
queue_len: 0.08096323188868827
wait_time: 0.779829935953161
delay_time: 5.04632123044566
pressure: 0.9818744473916886
total_envstep_count: 185832
total_train_sample_count: 185832
total_episode_count: 1602
total_duration: 6645.6533896923065
[2025-02-20 19:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.391733856743322
avg_train_sample_per_sec: 31.391733856743322
avg_episode_per_sec: 0.2706183953167528
collect_time: 22.171441793441772
reward_mean: -122.12756769374418
reward_std: 3.4633661216777236
reward_max: -115.99019607843137
reward_min: -126.92296918767504
queue_len: 0.08098645072529455
wait_time: 0.7812599840997407
delay_time: 5.095571840893812
pressure: 0.9826480990274092
total_envstep_count: 186528
total_train_sample_count: 186528
total_episode_count: 1608
total_duration: 6667.824831485748
[2025-02-20 19:15:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.550607240192477
avg_train_sample_per_sec: 31.550607240192477
avg_episode_per_sec: 0.27198799344993513
collect_time: 22.059797286987305
reward_mean: -121.4859943977591
reward_std: 4.481034253194519
reward_max: -114.25910364145656
reward_min: -127.32072829131657
queue_len: 0.08056100424254582
wait_time: 0.7807263378384067
delay_time: 5.048458055604621
pressure: 0.9793324491600354
total_envstep_count: 187224
total_train_sample_count: 187224
total_episode_count: 1614
total_duration: 6689.884628772736
[2025-02-20 19:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.677990252647557
avg_train_sample_per_sec: 31.677990252647557
avg_episode_per_sec: 0.2730861228676514
collect_time: 21.97109079360962
reward_mean: -122.3795518207283
reward_std: 4.245209725993757
reward_max: -116.67366946778711
reward_min: -127.86554621848738
queue_len: 0.08115354895273759
wait_time: 0.7907808680501379
delay_time: 5.118246868194306
pressure: 0.9847480106100795
total_envstep_count: 187920
total_train_sample_count: 187920
total_episode_count: 1620
total_duration: 6711.855719566345
[2025-02-20 19:16:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.43011462678895
avg_train_sample_per_sec: 31.43011462678895
avg_episode_per_sec: 0.2709492640240427
collect_time: 22.144367218017578
reward_mean: -120.48342670401495
reward_std: 1.781194948797176
reward_max: -116.96498599439771
reward_min: -122.80112044817926
queue_len: 0.07989617155438657
wait_time: 0.7664483012479968
delay_time: 5.070655503848314
pressure: 0.9688328912466844
total_envstep_count: 188616
total_train_sample_count: 188616
total_episode_count: 1626
total_duration: 6734.000086784363
[2025-02-20 19:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49303341640681
avg_train_sample_per_sec: 31.49303341640681
avg_episode_per_sec: 0.2714916673828173
collect_time: 22.100125789642334
reward_mean: -119.9625350140056
reward_std: 4.359918684313318
reward_max: -113.170868347339
reward_min: -125.54271708683473
queue_len: 0.07955075266180743
wait_time: 0.7672454039086899
delay_time: 5.0318810805079535
pressure: 0.9644120247568523
total_envstep_count: 189312
total_train_sample_count: 189312
total_episode_count: 1632
total_duration: 6756.100212574005
[2025-02-20 19:17:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.543267013860962
avg_train_sample_per_sec: 31.543267013860962
avg_episode_per_sec: 0.27192471563673243
collect_time: 22.06493067741394
reward_mean: -121.499649859944
reward_std: 4.628090241217172
reward_max: -115.2731092436975
reward_min: -130.23809523809527
queue_len: 0.08057005958882228
wait_time: 0.7702531720026649
delay_time: 5.203194728648753
pressure: 0.96684350132626
total_envstep_count: 190008
total_train_sample_count: 190008
total_episode_count: 1638
total_duration: 6778.165143251419
[2025-02-20 19:17:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.288113464544526
avg_train_sample_per_sec: 31.288113464544526
avg_episode_per_sec: 0.26972511607365973
collect_time: 22.244869470596313
reward_mean: -120.09372082166199
reward_std: 2.566797868605029
reward_max: -116.97268907563023
reward_min: -124.78851540616247
queue_len: 0.07963774590295887
wait_time: 0.7686961942159708
delay_time: 5.073199876013681
pressure: 0.9571175950486296
total_envstep_count: 190704
total_train_sample_count: 190704
total_episode_count: 1644
total_duration: 6800.410012722015
[2025-02-20 19:18:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.565981948829606
avg_train_sample_per_sec: 31.565981948829606
avg_episode_per_sec: 0.27212053404163455
collect_time: 22.049052715301514
reward_mean: -121.14507469654528
reward_std: 2.7286796368927826
reward_max: -116.72759103641452
reward_min: -125.60784313725483
queue_len: 0.08033493017012285
wait_time: 0.7739709721200594
delay_time: 5.116894110127965
pressure: 0.9665119363395225
total_envstep_count: 191400
total_train_sample_count: 191400
total_episode_count: 1650
total_duration: 6822.459065437317
[2025-02-20 19:18:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.430069620437763
avg_train_sample_per_sec: 31.430069620437763
avg_episode_per_sec: 0.27094887603825657
collect_time: 22.1443989276886
reward_mean: -118.40242763772174
reward_std: 4.276191351323914
reward_max: -111.4754901960784
reward_min: -124.42787114845937
queue_len: 0.07851619869875447
wait_time: 0.7537949640510493
delay_time: 4.951092323813597
pressure: 0.9589964633068081
total_envstep_count: 192096
total_train_sample_count: 192096
total_episode_count: 1656
total_duration: 6844.6034643650055
[2025-02-20 19:18:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.159278103659545
avg_train_sample_per_sec: 31.159278103659545
avg_episode_per_sec: 0.2686144664108581
collect_time: 22.336846113204956
reward_mean: -118.61297852474321
reward_std: 3.628980316417472
reward_max: -111.88235294117645
reward_min: -123.37044817927169
queue_len: 0.07865582130288011
wait_time: 0.755941855079786
delay_time: 4.99930414243477
pressure: 0.950817860300619
total_envstep_count: 192792
total_train_sample_count: 192792
total_episode_count: 1662
total_duration: 6866.94031047821
[2025-02-20 19:19:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.364804187085856
avg_train_sample_per_sec: 31.364804187085856
avg_episode_per_sec: 0.27038624299211944
collect_time: 22.190478086471558
reward_mean: -120.65966386554624
reward_std: 3.453072900886925
reward_max: -115.52240896358548
reward_min: -126.9187675070028
queue_len: 0.08001303969863809
wait_time: 0.7712747234172185
delay_time: 5.120741892424163
pressure: 0.9660698496905393
total_envstep_count: 193488
total_train_sample_count: 193488
total_episode_count: 1668
total_duration: 6889.130788564682
[2025-02-20 19:19:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.394578801346533
avg_train_sample_per_sec: 31.394578801346533
avg_episode_per_sec: 0.2706429207012632
collect_time: 22.169432640075684
reward_mean: -117.11869747899159
reward_std: 2.616213938308208
reward_max: -113.5420168067227
reward_min: -121.14705882352945
queue_len: 0.07766491875264694
wait_time: 0.7476180569486859
delay_time: 5.019125184560054
pressure: 0.9420866489832006
total_envstep_count: 194184
total_train_sample_count: 194184
total_episode_count: 1674
total_duration: 6911.300221204758
[2025-02-20 19:19:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47163656024251
avg_train_sample_per_sec: 31.47163656024251
avg_episode_per_sec: 0.2713072117262285
collect_time: 22.115151166915894
reward_mean: -121.98704481792716
reward_std: 2.441297792877376
reward_max: -119.75070028011208
reward_min: -127.30812324929975
queue_len: 0.08089326579438141
wait_time: 0.7794571962295086
delay_time: 5.052867438343278
pressure: 0.9912687886825817
total_envstep_count: 194880
total_train_sample_count: 194880
total_episode_count: 1680
total_duration: 6933.415372371674
[2025-02-20 19:20:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.818695117180354
avg_train_sample_per_sec: 31.818695117180354
avg_episode_per_sec: 0.2742990958377617
collect_time: 21.87393283843994
reward_mean: -118.46043417366946
reward_std: 1.8636739113375083
reward_max: -116.5140056022409
reward_min: -122.17086834733897
queue_len: 0.07855466457139886
wait_time: 0.7576281617863768
delay_time: 4.969987569551857
pressure: 0.9509283819628647
total_envstep_count: 195576
total_train_sample_count: 195576
total_episode_count: 1686
total_duration: 6955.2893052101135
[2025-02-20 19:20:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67254305319919
avg_train_sample_per_sec: 31.67254305319919
avg_episode_per_sec: 0.27303916425171715
collect_time: 21.9748694896698
reward_mean: -121.35807656395893
reward_std: 4.898782610954101
reward_max: -111.3683473389356
reward_min: -127.53361344537817
queue_len: 0.08047617809281098
wait_time: 0.7727529119516948
delay_time: 5.216004534613513
pressure: 0.9727011494252874
total_envstep_count: 196272
total_train_sample_count: 196272
total_episode_count: 1692
total_duration: 6977.264174699783
[2025-02-20 19:21:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.767259993615284
avg_train_sample_per_sec: 31.767259993615284
avg_episode_per_sec: 0.2738556896001318
collect_time: 21.90934944152832
reward_mean: -121.96813725490193
reward_std: 2.874318117572705
reward_max: -116.64495798319327
reward_min: -125.66456582633052
queue_len: 0.08088072762261402
wait_time: 0.7833739043804967
delay_time: 5.162316275174419
pressure: 0.9813218390804598
total_envstep_count: 196968
total_train_sample_count: 196968
total_episode_count: 1698
total_duration: 6999.173524141312
[2025-02-20 19:21:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.51695028121345
avg_train_sample_per_sec: 31.51695028121345
avg_episode_per_sec: 0.2716978472518401
collect_time: 22.083354949951172
reward_mean: -122.0421335200747
reward_std: 2.161471992141792
reward_max: -120.0098039215686
reward_min: -126.35364145658266
queue_len: 0.08092979676397527
wait_time: 0.7804009645414313
delay_time: 5.103964757233576
pressure: 0.9790008841732979
total_envstep_count: 197664
total_train_sample_count: 197664
total_episode_count: 1704
total_duration: 7021.256879091263
[2025-02-20 19:21:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72941546927317
avg_train_sample_per_sec: 31.72941546927317
avg_episode_per_sec: 0.2735294437006308
collect_time: 21.935481309890747
reward_mean: -118.57971521942109
reward_std: 2.3006864586528097
reward_max: -113.75980392156865
reward_min: -121.27521008403366
queue_len: 0.07863376340810418
wait_time: 0.7596683235628469
delay_time: 4.972892151250606
pressure: 0.9427497789566756
total_envstep_count: 198360
total_train_sample_count: 198360
total_episode_count: 1710
total_duration: 7043.192360401154
[2025-02-20 19:22:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.425396767710414
avg_train_sample_per_sec: 31.425396767710414
avg_episode_per_sec: 0.2709085928250898
collect_time: 22.14769172668457
reward_mean: -122.87546685340801
reward_std: 1.9521456869837264
reward_max: -119.78151260504198
reward_min: -126.28851540616246
queue_len: 0.08148240507520425
wait_time: 0.7815109797234543
delay_time: 5.206278984175415
pressure: 0.9907161803713529
total_envstep_count: 199056
total_train_sample_count: 199056
total_episode_count: 1716
total_duration: 7065.340052127838
[2025-02-20 19:22:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.325806467916834
avg_train_sample_per_sec: 31.325806467916834
avg_episode_per_sec: 0.27005005575790375
collect_time: 22.218103170394897
reward_mean: -120.36204481792718
reward_std: 4.134427943974041
reward_max: -114.49159663865547
reward_min: -125.69257703081233
queue_len: 0.07981567958748488
wait_time: 0.7772132504637576
delay_time: 5.045184374236021
pressure: 0.9703801945181256
total_envstep_count: 199752
total_train_sample_count: 199752
total_episode_count: 1722
total_duration: 7087.558155298233
[2025-02-20 19:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.869543452520755
avg_train_sample_per_sec: 31.869543452520755
avg_episode_per_sec: 0.27473744355621343
collect_time: 21.839032649993896
reward_mean: -123.02731092436977
reward_std: 2.8044941459798505
reward_max: -119.14705882352943
reward_min: -126.48669467787116
queue_len: 0.08158309742995343
wait_time: 0.7871129110353247
delay_time: 5.164792866754033
pressure: 0.9755747126436781
total_envstep_count: 200448
total_train_sample_count: 200448
total_episode_count: 1728
total_duration: 7109.397187948227
[2025-02-20 19:23:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.311495633299835
avg_train_sample_per_sec: 31.311495633299835
avg_episode_per_sec: 0.26992668649396406
collect_time: 22.22825789451599
reward_mean: -117.51925770308124
reward_std: 3.4066497935524263
reward_max: -113.19257703081232
reward_min: -123.16596638655463
queue_len: 0.07793054224342258
wait_time: 0.7525555425530072
delay_time: 4.930042441413874
pressure: 0.9465075154730327
total_envstep_count: 201144
total_train_sample_count: 201144
total_episode_count: 1734
total_duration: 7131.625445842743
[2025-02-20 19:23:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.26383066810962
avg_train_sample_per_sec: 31.26383066810962
avg_episode_per_sec: 0.26951578162163464
collect_time: 22.262147188186646
reward_mean: -121.50361811391222
reward_std: 4.02739547859517
reward_max: -117.16246498599436
reward_min: -129.79901960784315
queue_len: 0.08057269105697097
wait_time: 0.7741861333392775
delay_time: 5.14663208708923
pressure: 0.9771220159151194
total_envstep_count: 201840
total_train_sample_count: 201840
total_episode_count: 1740
total_duration: 7153.88759303093
[2025-02-20 19:24:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.617267119360367
avg_train_sample_per_sec: 31.617267119360367
avg_episode_per_sec: 0.2725626475806928
collect_time: 22.013287782669067
reward_mean: -118.99509803921569
reward_std: 2.176534126236936
reward_max: -116.46638655462188
reward_min: -122.19257703081234
queue_len: 0.07890921620637645
wait_time: 0.76082926539316
delay_time: 4.996375971796065
pressure: 0.951923076923077
total_envstep_count: 202536
total_train_sample_count: 202536
total_episode_count: 1746
total_duration: 7175.900880813599
[2025-02-20 19:24:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.83035633182078
avg_train_sample_per_sec: 30.83035633182078
avg_episode_per_sec: 0.26577893389500673
collect_time: 22.57515263557434
reward_mean: -121.32913165266109
reward_std: 3.4365872217116076
reward_max: -116.26820728291317
reward_min: -125.56022408963585
queue_len: 0.08045698385454979
wait_time: 0.7801414553442948
delay_time: 5.116879031271904
pressure: 0.9696065428824049
total_envstep_count: 203232
total_train_sample_count: 203232
total_episode_count: 1752
total_duration: 7198.476033449173
[2025-02-20 19:24:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.465254136279924
avg_train_sample_per_sec: 31.465254136279924
avg_episode_per_sec: 0.27125219082999935
collect_time: 22.11963701248169
reward_mean: -119.13258636788048
reward_std: 1.7224945265765537
reward_max: -116.37464985994396
reward_min: -121.62815126050418
queue_len: 0.07900038883811701
wait_time: 0.7556028600653347
delay_time: 5.023743384858819
pressure: 0.954686118479222
total_envstep_count: 203928
total_train_sample_count: 203928
total_episode_count: 1758
total_duration: 7220.595670461655
[2025-02-20 19:25:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.801333417403796
avg_train_sample_per_sec: 31.801333417403796
avg_episode_per_sec: 0.2741494260121017
collect_time: 21.88587474822998
reward_mean: -118.00035014005603
reward_std: 2.651683972456633
reward_max: -115.01750700280114
reward_min: -121.9292717086835
queue_len: 0.07824956905839259
wait_time: 0.7492164416606606
delay_time: 4.949390146472021
pressure: 0.9471706454465075
total_envstep_count: 204624
total_train_sample_count: 204624
total_episode_count: 1764
total_duration: 7242.481545209885
[2025-02-20 19:25:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.665283720987343
avg_train_sample_per_sec: 31.665283720987343
avg_episode_per_sec: 0.27297658380161505
collect_time: 21.979907274246216
reward_mean: -120.68043884220354
reward_std: 4.352834012666858
reward_max: -115.92857142857144
reward_min: -127.86974789915966
queue_len: 0.08002681620835779
wait_time: 0.7669426302793444
delay_time: 5.114074059241177
pressure: 0.9694960212201592
total_envstep_count: 205320
total_train_sample_count: 205320
total_episode_count: 1770
total_duration: 7264.461452484131
[2025-02-20 19:25:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.399361036384846
avg_train_sample_per_sec: 31.399361036384846
avg_episode_per_sec: 0.2706841468653866
collect_time: 22.166056156158447
reward_mean: -122.22782446311858
reward_std: 3.8169436435707707
reward_max: -115.20028011204481
reward_min: -127.4026610644257
queue_len: 0.08105293399411047
wait_time: 0.7799808583911019
delay_time: 5.1295004744747965
pressure: 0.9876215738284705
total_envstep_count: 206016
total_train_sample_count: 206016
total_episode_count: 1776
total_duration: 7286.627508640289
[2025-02-20 19:26:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.536094068368733
avg_train_sample_per_sec: 31.536094068368733
avg_episode_per_sec: 0.27186287989973046
collect_time: 22.06994938850403
reward_mean: -124.26190476190474
reward_std: 3.552991258696622
reward_max: -119.87044817927173
reward_min: -130.32282913165264
queue_len: 0.08240179360869017
wait_time: 0.7901586806252121
delay_time: 5.287973219749496
pressure: 0.9897214854111406
total_envstep_count: 206712
total_train_sample_count: 206712
total_episode_count: 1782
total_duration: 7308.697458028793
[2025-02-20 19:26:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.679986206481626
avg_train_sample_per_sec: 31.679986206481626
avg_episode_per_sec: 0.2731033293662209
collect_time: 21.969706535339355
reward_mean: -120.90137721755366
reward_std: 3.774313582167126
reward_max: -114.04621848739494
reward_min: -126.79201680672269
queue_len: 0.08017332706734329
wait_time: 0.7673409107232637
delay_time: 5.13526593465879
pressure: 0.9681697612732094
total_envstep_count: 207408
total_train_sample_count: 207408
total_episode_count: 1788
total_duration: 7330.667164564133
[2025-02-20 19:27:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.628043487639655
avg_train_sample_per_sec: 31.628043487639655
avg_episode_per_sec: 0.2726555473072384
collect_time: 22.00578737258911
reward_mean: -116.53302987861814
reward_std: 7.1166045477871185
reward_max: -107.54131652661063
reward_min: -129.6736694677871
queue_len: 0.07727654501234622
wait_time: 0.7422138727285784
delay_time: 4.875946670035156
pressure: 0.9412024756852344
total_envstep_count: 208104
total_train_sample_count: 208104
total_episode_count: 1794
total_duration: 7352.672951936722
[2025-02-20 19:27:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68034100793045
avg_train_sample_per_sec: 31.68034100793045
avg_episode_per_sec: 0.27310638799940046
collect_time: 21.969460487365723
reward_mean: -122.93744164332401
reward_std: 2.399266075284779
reward_max: -119.60224089635857
reward_min: -127.24159663865547
queue_len: 0.08152350241599736
wait_time: 0.7848914101449598
delay_time: 5.163338908524593
pressure: 0.9875110521662246
total_envstep_count: 208800
total_train_sample_count: 208800
total_episode_count: 1800
total_duration: 7374.6424124240875
[2025-02-20 19:27:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.270843098657686
avg_train_sample_per_sec: 31.270843098657686
avg_episode_per_sec: 0.269576233609118
collect_time: 22.257154941558838
reward_mean: -120.04855275443511
reward_std: 1.807019725773839
reward_max: -118.0119047619048
reward_min: -123.71778711484593
queue_len: 0.0796077936037368
wait_time: 0.7664585949322259
delay_time: 5.009993734147371
pressure: 0.9704907161803714
total_envstep_count: 209496
total_train_sample_count: 209496
total_episode_count: 1806
total_duration: 7396.899567365646
[2025-02-20 19:28:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.403798789217156
avg_train_sample_per_sec: 31.403798789217156
avg_episode_per_sec: 0.27072240335532033
collect_time: 22.16292381286621
reward_mean: -120.21755368814195
reward_std: 3.1818259509520646
reward_max: -117.43697478991601
reward_min: -126.53501400560226
queue_len: 0.07971986318842304
wait_time: 0.7672518277868173
delay_time: 5.025793019460559
pressure: 0.9691644562334217
total_envstep_count: 210192
total_train_sample_count: 210192
total_episode_count: 1812
total_duration: 7419.062491178513
[2025-02-20 19:28:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.302381447187145
avg_train_sample_per_sec: 31.302381447187145
avg_episode_per_sec: 0.26984811592402713
collect_time: 22.234730005264282
reward_mean: -123.83181605975726
reward_std: 4.329345617132332
reward_max: -117.24299719887959
reward_min: -130.6281512605042
queue_len: 0.08211658889904327
wait_time: 0.7927834927074278
delay_time: 5.1975056595715525
pressure: 0.9940318302387269
total_envstep_count: 210888
total_train_sample_count: 210888
total_episode_count: 1818
total_duration: 7441.297221183777
[2025-02-20 19:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.40790663539026
avg_train_sample_per_sec: 31.40790663539026
avg_episode_per_sec: 0.27075781582232983
collect_time: 22.160025119781494
reward_mean: -121.63433706816056
reward_std: 3.0986299393681485
reward_max: -117.07773109243695
reward_min: -125.69747899159665
queue_len: 0.08065937471363434
wait_time: 0.7779564854235238
delay_time: 5.065151268679885
pressure: 0.976790450928382
total_envstep_count: 211584
total_train_sample_count: 211584
total_episode_count: 1824
total_duration: 7463.457246303558
[2025-02-20 19:29:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73641855859906
avg_train_sample_per_sec: 31.73641855859906
avg_episode_per_sec: 0.2735898151603367
collect_time: 21.930640935897827
reward_mean: -119.48541083099904
reward_std: 1.9225599425532904
reward_max: -117.54481792717084
reward_min: -123.45238095238093
queue_len: 0.07923435731498611
wait_time: 0.7569164270482731
delay_time: 5.055438311643754
pressure: 0.9630857648099026
total_envstep_count: 212280
total_train_sample_count: 212280
total_episode_count: 1830
total_duration: 7485.387887239456
[2025-02-20 19:29:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67021372642281
avg_train_sample_per_sec: 31.67021372642281
avg_episode_per_sec: 0.2730190838484725
collect_time: 21.97648572921753
reward_mean: -118.74486461251168
reward_std: 4.661459432994432
reward_max: -111.43347338935574
reward_min: -125.67156862745102
queue_len: 0.07874327892076372
wait_time: 0.755507043666273
delay_time: 4.973964398378459
pressure: 0.9639699381078692
total_envstep_count: 212976
total_train_sample_count: 212976
total_episode_count: 1836
total_duration: 7507.364372968674
[2025-02-20 19:30:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.563871329530997
avg_train_sample_per_sec: 31.563871329530997
avg_episode_per_sec: 0.272102339047681
collect_time: 22.050527095794678
reward_mean: -120.12173202614379
reward_std: 3.1703027066816034
reward_max: -116.29971988795515
reward_min: -125.46148459383751
queue_len: 0.07965632097224389
wait_time: 0.7616568621259291
delay_time: 5.109315192978106
pressure: 0.96131741821397
total_envstep_count: 213672
total_train_sample_count: 213672
total_episode_count: 1842
total_duration: 7529.414900064468
[2025-02-20 19:30:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32474191150233
avg_train_sample_per_sec: 31.32474191150233
avg_episode_per_sec: 0.27004087854743386
collect_time: 22.218858242034912
reward_mean: -119.74603174603173
reward_std: 4.375427599576258
reward_max: -111.97689075630251
reward_min: -125.08473389355744
queue_len: 0.07940718285545871
wait_time: 0.7616189380261389
delay_time: 5.102152144773679
pressure: 0.9545755968169761
total_envstep_count: 214368
total_train_sample_count: 214368
total_episode_count: 1848
total_duration: 7551.633758306503
[2025-02-20 19:30:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.643205656130217
avg_train_sample_per_sec: 31.643205656130217
avg_episode_per_sec: 0.272786255656295
collect_time: 21.995243072509766
reward_mean: -119.9515639589169
reward_std: 3.313395470377145
reward_max: -114.82983193277312
reward_min: -124.62535014005604
queue_len: 0.07954347742633747
wait_time: 0.7603002628991473
delay_time: 4.985804327521272
pressure: 0.9722590627763043
total_envstep_count: 215064
total_train_sample_count: 215064
total_episode_count: 1854
total_duration: 7573.629001379013
[2025-02-20 19:31:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.854893605821317
avg_train_sample_per_sec: 31.854893605821317
avg_episode_per_sec: 0.2746111517743217
collect_time: 21.84907627105713
reward_mean: -120.96393557422967
reward_std: 2.485047976434657
reward_max: -117.19887955182071
reward_min: -124.05112044817926
queue_len: 0.08021481138874646
wait_time: 0.7723549410922635
delay_time: 5.075915119684937
pressure: 0.9686118479221927
total_envstep_count: 215760
total_train_sample_count: 215760
total_episode_count: 1860
total_duration: 7595.47807765007
[2025-02-20 19:31:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.046191292298232
avg_train_sample_per_sec: 31.046191292298232
avg_episode_per_sec: 0.26763958010601924
collect_time: 22.418208837509155
reward_mean: -121.72934173669466
reward_std: 3.757015609110928
reward_max: -117.27731092436974
reward_min: -127.79551820728294
queue_len: 0.08072237515695933
wait_time: 0.7751696832579187
delay_time: 5.085564240072219
pressure: 0.9875110521662246
total_envstep_count: 216456
total_train_sample_count: 216456
total_episode_count: 1866
total_duration: 7617.896286487579
[2025-02-20 19:31:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8510721723383
avg_train_sample_per_sec: 31.8510721723383
avg_episode_per_sec: 0.2745782083822267
collect_time: 21.85169768333435
reward_mean: -120.5920868347339
reward_std: 3.1745451542351466
reward_max: -115.63165266106441
reward_min: -125.17647058823532
queue_len: 0.079968227343988
wait_time: 0.7673820080640569
delay_time: 4.9540444943233455
pressure: 0.9780061892130858
total_envstep_count: 217152
total_train_sample_count: 217152
total_episode_count: 1872
total_duration: 7639.747984170914
[2025-02-20 19:32:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.767538970178194
avg_train_sample_per_sec: 31.767538970178194
avg_episode_per_sec: 0.2738580945705017
collect_time: 21.909157037734985
reward_mean: -118.7484827264239
reward_std: 2.0381301642451892
reward_max: -115.71848739495798
reward_min: -122.41526610644259
queue_len: 0.07874567820054636
wait_time: 0.7504616678678545
delay_time: 4.972202064663434
pressure: 0.9567860300618921
total_envstep_count: 217848
total_train_sample_count: 217848
total_episode_count: 1878
total_duration: 7661.657141208649
[2025-02-20 19:32:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.643871086573895
avg_train_sample_per_sec: 31.643871086573895
avg_episode_per_sec: 0.27279199212563704
collect_time: 21.99478054046631
reward_mean: -121.59593837535014
reward_std: 2.535276145713005
reward_max: -117.51190476190474
reward_min: -124.77450980392159
queue_len: 0.08063391138948947
wait_time: 0.7802790656492483
delay_time: 5.134247280297646
pressure: 0.9830901856763924
total_envstep_count: 218544
total_train_sample_count: 218544
total_episode_count: 1884
total_duration: 7683.651921749115
[2025-02-20 19:33:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.740823719787613
avg_train_sample_per_sec: 31.740823719787613
avg_episode_per_sec: 0.2736277906878242
collect_time: 21.927597284317017
reward_mean: -122.35936041083096
reward_std: 3.6703151176856417
reward_max: -116.80812324929974
reward_min: -126.48039215686269
queue_len: 0.08114015942362797
wait_time: 0.787409570371031
delay_time: 5.0987717568609225
pressure: 0.9925950486295313
total_envstep_count: 219240
total_train_sample_count: 219240
total_episode_count: 1890
total_duration: 7705.579519033432
[2025-02-20 19:33:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.747377483719703
avg_train_sample_per_sec: 28.747377483719703
avg_episode_per_sec: 0.2478222196872388
collect_time: 24.210904121398926
reward_mean: -121.37628384687207
reward_std: 6.0351036684542985
reward_max: -112.58333333333331
reward_min: -132.2485994397759
queue_len: 0.08048825188784618
wait_time: 0.771374100037893
delay_time: 5.044500737647733
pressure: 0.9813218390804598
total_envstep_count: 219936
total_train_sample_count: 219936
total_episode_count: 1896
total_duration: 7729.790423154831
[2025-02-20 19:33:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.30080378973375
avg_train_sample_per_sec: 24.30080378973375
avg_episode_per_sec: 0.2094896878425323
collect_time: 28.64102792739868
reward_mean: -118.81535947712416
reward_std: 0.7018242390773158
reward_max: -117.95308123249298
reward_min: -120.07282913165268
queue_len: 0.0787900261784643
wait_time: 0.7577201083793375
delay_time: 4.908705389384802
pressure: 0.9612068965517239
total_envstep_count: 220632
total_train_sample_count: 220632
total_episode_count: 1902
total_duration: 7758.43145108223
[2025-02-20 19:34:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 26.787682136606172
avg_train_sample_per_sec: 26.787682136606172
avg_episode_per_sec: 0.2309282942810877
collect_time: 25.982091188430786
reward_mean: -119.14635854341736
reward_std: 3.1823463386107544
reward_max: -113.7233893557423
reward_min: -123.35224089635857
queue_len: 0.07900952158051548
wait_time: 0.7607048124289504
delay_time: 4.9217846854812555
pressure: 0.9675066312997348
total_envstep_count: 221328
total_train_sample_count: 221328
total_episode_count: 1908
total_duration: 7784.41354227066
[2025-02-20 19:34:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 26.83704153501888
avg_train_sample_per_sec: 26.83704153501888
avg_episode_per_sec: 0.23135380633636965
collect_time: 25.934304237365723
reward_mean: -118.35737628384686
reward_std: 2.5733554209452447
reward_max: -114.46778711484592
reward_min: -121.29131652661067
queue_len: 0.07848632379565441
wait_time: 0.7561801577394885
delay_time: 4.936810554811504
pressure: 0.9634173297966401
total_envstep_count: 222024
total_train_sample_count: 222024
total_episode_count: 1914
total_duration: 7810.347846508026
[2025-02-20 19:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 25.130011783466266
avg_train_sample_per_sec: 25.130011783466266
avg_episode_per_sec: 0.21663803261608852
collect_time: 27.69596791267395
reward_mean: -118.95646591970122
reward_std: 1.5021042909483688
reward_max: -116.29971988795516
reward_min: -121.093837535014
queue_len: 0.07888359808998756
wait_time: 0.7579406873270971
delay_time: 4.97064795630404
pressure: 0.9662908930150311
total_envstep_count: 222720
total_train_sample_count: 222720
total_episode_count: 1920
total_duration: 7838.0438144207
[2025-02-20 19:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 26.070001781083096
avg_train_sample_per_sec: 26.070001781083096
avg_episode_per_sec: 0.22474139466450946
collect_time: 26.697351455688477
reward_mean: -120.37931839402427
reward_std: 3.018702926440081
reward_max: -116.61484593837531
reward_min: -125.70238095238092
queue_len: 0.07982713421354394
wait_time: 0.7654854934900576
delay_time: 5.0608225263185735
pressure: 0.96684350132626
total_envstep_count: 223416
total_train_sample_count: 223416
total_episode_count: 1926
total_duration: 7864.741165876389
[2025-02-20 19:36:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.655649304589435
avg_train_sample_per_sec: 24.655649304589435
avg_episode_per_sec: 0.21254870090163305
collect_time: 28.228824615478516
reward_mean: -122.046685340803
reward_std: 1.6669307056240024
reward_max: -119.21078431372551
reward_min: -124.68697478991595
queue_len: 0.08093281521273409
wait_time: 0.7837461797274171
delay_time: 5.047718215645736
pressure: 0.9892793987621573
total_envstep_count: 224112
total_train_sample_count: 224112
total_episode_count: 1932
total_duration: 7892.969990491867
[2025-02-20 19:36:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 25.823006835061012
avg_train_sample_per_sec: 25.823006835061012
avg_episode_per_sec: 0.22261212788845702
collect_time: 26.952709436416626
reward_mean: -117.4669701213819
reward_std: 1.8972072585226527
reward_max: -115.01680672268911
reward_min: -121.09873949579833
queue_len: 0.07789586878075723
wait_time: 0.7474634968930101
delay_time: 4.886833566046877
pressure: 0.9531388152077808
total_envstep_count: 224808
total_train_sample_count: 224808
total_episode_count: 1938
total_duration: 7919.922699928284
[2025-02-20 19:37:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 25.12222524437202
avg_train_sample_per_sec: 25.12222524437202
avg_episode_per_sec: 0.21657090727906916
collect_time: 27.704552173614502
reward_mean: -118.69304388422036
reward_std: 3.647290487394534
reward_max: -114.25490196078431
reward_min: -125.19257703081232
queue_len: 0.07870891504258644
wait_time: 0.7516292657646614
delay_time: 4.93067927417274
pressure: 0.9535809018567639
total_envstep_count: 225504
total_train_sample_count: 225504
total_episode_count: 1944
total_duration: 7947.627252101898
[2025-02-20 19:37:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.82035926198864
avg_train_sample_per_sec: 24.82035926198864
avg_episode_per_sec: 0.21396861432748826
collect_time: 28.04149580001831
reward_mean: -122.61974789915966
reward_std: 3.843089382563812
reward_max: -115.17647058823529
reward_min: -127.93977591036408
queue_len: 0.08131283017185652
wait_time: 0.7862459196764471
delay_time: 5.075078738516987
pressure: 0.9893899204244033
total_envstep_count: 226200
total_train_sample_count: 226200
total_episode_count: 1950
total_duration: 7975.6687479019165
[2025-02-20 19:38:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.224839754289828
avg_train_sample_per_sec: 24.224839754289828
avg_episode_per_sec: 0.20883482546801577
collect_time: 28.73084020614624
reward_mean: -119.78863211951449
reward_std: 2.9490889803180163
reward_max: -116.28081232492997
reward_min: -123.54131652661066
queue_len: 0.07943543243999635
wait_time: 0.7654137472849442
delay_time: 4.994608798480157
pressure: 0.9599911582670204
total_envstep_count: 226896
total_train_sample_count: 226896
total_episode_count: 1956
total_duration: 8004.399588108063
[2025-02-20 19:38:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.67475698403459
avg_train_sample_per_sec: 24.67475698403459
avg_episode_per_sec: 0.21271342227616027
collect_time: 28.20696473121643
reward_mean: -118.9140989729225
reward_std: 2.8209976541079835
reward_max: -114.42156862745097
reward_min: -122.09593837535013
queue_len: 0.07885550329769397
wait_time: 0.763029327557725
delay_time: 4.887796038796615
pressure: 0.9585543766578248
total_envstep_count: 227592
total_train_sample_count: 227592
total_episode_count: 1962
total_duration: 8032.606552839279
[2025-02-20 19:39:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.64855286928557
avg_train_sample_per_sec: 24.64855286928557
avg_episode_per_sec: 0.21248752473522042
collect_time: 28.23695182800293
reward_mean: -120.72198879551821
reward_std: 4.494101055894944
reward_max: -115.687675070028
reward_min: -128.11834733893562
queue_len: 0.08005436922779723
wait_time: 0.7643480800808388
delay_time: 5.1256462353982055
pressure: 0.9647435897435898
total_envstep_count: 228288
total_train_sample_count: 228288
total_episode_count: 1968
total_duration: 8060.843504667282
[2025-02-20 19:39:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.969091025058074
avg_train_sample_per_sec: 24.969091025058074
avg_episode_per_sec: 0.2152507846987765
collect_time: 27.874462842941284
reward_mean: -116.61694677871147
reward_std: 4.561924289097505
reward_max: -109.27801120448179
reward_min: -122.12254901960787
queue_len: 0.07733219282407923
wait_time: 0.7435285232572252
delay_time: 4.830662665087118
pressure: 0.9427497789566753
total_envstep_count: 228984
total_train_sample_count: 228984
total_episode_count: 1974
total_duration: 8088.717967510223
[2025-02-20 19:40:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.083718247790273
avg_train_sample_per_sec: 24.083718247790273
avg_episode_per_sec: 0.20761826075681272
collect_time: 28.899192094802856
reward_mean: -119.88923902894493
reward_std: 3.8182874285654473
reward_max: -113.47969187675068
reward_min: -125.99999999999999
queue_len: 0.07950214789717833
wait_time: 0.7621474761434195
delay_time: 5.09787649171226
pressure: 0.9586648983200706
total_envstep_count: 229680
total_train_sample_count: 229680
total_episode_count: 1980
total_duration: 8117.617159605026
[2025-02-20 19:40:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 25.771590340845876
avg_train_sample_per_sec: 25.771590340845876
avg_episode_per_sec: 0.22216888224867132
collect_time: 27.006482362747192
reward_mean: -121.07516339869282
reward_std: 2.394360167860997
reward_max: -116.27731092436973
reward_min: -123.95728291316529
queue_len: 0.08028856989303237
wait_time: 0.7701145555481256
delay_time: 5.037982506265959
pressure: 0.9647435897435898
total_envstep_count: 230376
total_train_sample_count: 230376
total_episode_count: 1986
total_duration: 8144.623641967773
[2025-02-20 19:40:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.23653384549186
avg_train_sample_per_sec: 27.23653384549186
avg_episode_per_sec: 0.23479770556458499
collect_time: 25.55391240119934
reward_mean: -120.53302987861811
reward_std: 2.342874632235581
reward_max: -117.71568627450979
reward_min: -123.93207282913168
queue_len: 0.07992906490624543
wait_time: 0.7740812615939389
delay_time: 4.991413556931234
pressure: 0.9667329796640142
total_envstep_count: 231072
total_train_sample_count: 231072
total_episode_count: 1992
total_duration: 8170.177554368973
[2025-02-20 19:41:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.091503984440504
avg_train_sample_per_sec: 27.091503984440504
avg_episode_per_sec: 0.23354744814172848
collect_time: 25.69071102142334
reward_mean: -117.56255835667599
reward_std: 2.32129156269257
reward_max: -114.82072829131646
reward_min: -122.26820728291317
queue_len: 0.07795925620469231
wait_time: 0.7499539493073977
delay_time: 4.933416980242838
pressure: 0.9455128205128206
total_envstep_count: 231768
total_train_sample_count: 231768
total_episode_count: 1998
total_duration: 8195.868265390396
[2025-02-20 19:41:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.164547117422302
avg_train_sample_per_sec: 27.164547117422302
avg_episode_per_sec: 0.23417713032260606
collect_time: 25.621630907058716
reward_mean: -116.42250233426704
reward_std: 3.330338159423074
reward_max: -111.63935574229691
reward_min: -121.03431372549022
queue_len: 0.07720325088479248
wait_time: 0.7410464296240159
delay_time: 4.763326170816605
pressure: 0.9491600353669319
total_envstep_count: 232464
total_train_sample_count: 232464
total_episode_count: 2004
total_duration: 8221.489896297455
[2025-02-20 19:42:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.1551178033757
avg_train_sample_per_sec: 27.1551178033757
avg_episode_per_sec: 0.2340958431325491
collect_time: 25.63052773475647
reward_mean: -121.77159197012135
reward_std: 3.4922932307609407
reward_max: -117.74439775910365
reward_min: -126.22759103641455
queue_len: 0.08075039255313088
wait_time: 0.7827173530773938
delay_time: 5.0267880758845624
pressure: 0.9770114942528735
total_envstep_count: 233160
total_train_sample_count: 233160
total_episode_count: 2010
total_duration: 8247.120424032211
[2025-02-20 19:42:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.600020932344986
avg_train_sample_per_sec: 27.600020932344986
avg_episode_per_sec: 0.2379312149340085
collect_time: 25.217372179031372
reward_mean: -120.37546685340801
reward_std: 4.979203669256528
reward_max: -113.68557422969187
reward_min: -126.90476190476188
queue_len: 0.07982458014151726
wait_time: 0.7713411292899122
delay_time: 5.064272384792539
pressure: 0.9688328912466844
total_envstep_count: 233856
total_train_sample_count: 233856
total_episode_count: 2016
total_duration: 8272.337796211243
[2025-02-20 19:43:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.692758906257485
avg_train_sample_per_sec: 31.692758906257485
avg_episode_per_sec: 0.2732134388470473
collect_time: 21.96085238456726
reward_mean: -118.47817460317462
reward_std: 1.9904394867231132
reward_max: -115.04831932773111
reward_min: -120.85224089635857
queue_len: 0.07856642878194603
wait_time: 0.7673669932163847
delay_time: 4.960928935732585
pressure: 0.9557913351016799
total_envstep_count: 234552
total_train_sample_count: 234552
total_episode_count: 2022
total_duration: 8294.29864859581
[2025-02-20 19:43:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06725376385243
avg_train_sample_per_sec: 32.06725376385243
avg_episode_per_sec: 0.27644184279183126
collect_time: 21.704384326934814
reward_mean: -119.06232492997201
reward_std: 2.3538525798659005
reward_max: -116.52240896358545
reward_min: -123.75280112044818
queue_len: 0.07895379637266048
wait_time: 0.7513183655425036
delay_time: 4.943803358966209
pressure: 0.9518125552608311
total_envstep_count: 235248
total_train_sample_count: 235248
total_episode_count: 2028
total_duration: 8316.003032922745
[2025-02-20 19:43:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.37067438940462
avg_train_sample_per_sec: 32.37067438940462
avg_episode_per_sec: 0.279057537839695
collect_time: 21.50094223022461
reward_mean: -119.79108309990664
reward_std: 2.81322866419025
reward_max: -117.39985994397762
reward_min: -124.97549019607845
queue_len: 0.07943705775855876
wait_time: 0.7724138395411213
delay_time: 5.128579653862176
pressure: 0.9531388152077809
total_envstep_count: 235944
total_train_sample_count: 235944
total_episode_count: 2034
total_duration: 8337.50397515297
[2025-02-20 19:44:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.353759801420026
avg_train_sample_per_sec: 32.353759801420026
avg_episode_per_sec: 0.2789117224260347
collect_time: 21.51218295097351
reward_mean: -118.82703081232494
reward_std: 2.2266802953005738
reward_max: -114.00980392156862
reward_min: -120.88725490196079
queue_len: 0.0787977657906664
wait_time: 0.7600541432311209
delay_time: 4.901077419212954
pressure: 0.9616489832007072
total_envstep_count: 236640
total_train_sample_count: 236640
total_episode_count: 2040
total_duration: 8359.016158103943
[2025-02-20 19:44:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.419965368853624
avg_train_sample_per_sec: 32.419965368853624
avg_episode_per_sec: 0.2794824600763244
collect_time: 21.468252420425415
reward_mean: -119.4090802987862
reward_std: 3.482644099730297
reward_max: -114.93907563025209
reward_min: -124.27591036414563
queue_len: 0.07918374025118448
wait_time: 0.7568967684332796
delay_time: 4.9784021559582925
pressure: 0.9689434129089302
total_envstep_count: 237336
total_train_sample_count: 237336
total_episode_count: 2046
total_duration: 8380.484410524368
[2025-02-20 19:44:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22294936133396
avg_train_sample_per_sec: 32.22294936133396
avg_episode_per_sec: 0.2777840462183962
collect_time: 21.599512577056885
reward_mean: -119.32983193277312
reward_std: 2.4633927401259132
reward_max: -116.04271708683477
reward_min: -122.75280112044824
queue_len: 0.07913118828433231
wait_time: 0.7618843293285483
delay_time: 5.013041664782599
pressure: 0.9610963748894784
total_envstep_count: 238032
total_train_sample_count: 238032
total_episode_count: 2052
total_duration: 8402.083923101425
[2025-02-20 19:45:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19629139904625
avg_train_sample_per_sec: 32.19629139904625
avg_episode_per_sec: 0.2775542361986746
collect_time: 21.617396593093872
reward_mean: -120.88048552754435
reward_std: 3.2467722869239264
reward_max: -115.718487394958
reward_min: -125.51680672268911
queue_len: 0.08015947316150156
wait_time: 0.7700412614205717
delay_time: 5.125783326946855
pressure: 0.9756852343059239
total_envstep_count: 238728
total_train_sample_count: 238728
total_episode_count: 2058
total_duration: 8423.701319694519
[2025-02-20 19:45:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.203838901884545
avg_train_sample_per_sec: 32.203838901884545
avg_episode_per_sec: 0.27761930087831505
collect_time: 21.612330198287964
reward_mean: -120.8692810457516
reward_std: 4.105948220583312
reward_max: -114.36484593837532
reward_min: -125.99439775910359
queue_len: 0.08015204313378754
wait_time: 0.7717252462435017
delay_time: 5.0281072550223875
pressure: 0.9734748010610078
total_envstep_count: 239424
total_train_sample_count: 239424
total_episode_count: 2064
total_duration: 8445.313649892807
[2025-02-20 19:46:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.43958128291868
avg_train_sample_per_sec: 32.43958128291868
avg_episode_per_sec: 0.2796515627837818
collect_time: 21.455270767211914
reward_mean: -118.59780578898226
reward_std: 3.894978078878013
reward_max: -114.07212885154057
reward_min: -126.53501400560224
queue_len: 0.07864575980701739
wait_time: 0.7549133380142509
delay_time: 4.996555070523187
pressure: 0.9564544650751546
total_envstep_count: 240120
total_train_sample_count: 240120
total_episode_count: 2070
total_duration: 8466.768920660019
[2025-02-20 19:46:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03889996581257
avg_train_sample_per_sec: 32.03889996581257
avg_episode_per_sec: 0.27619741349838417
collect_time: 21.723592281341553
reward_mean: -118.67565359477125
reward_std: 2.9672236651521553
reward_max: -114.80532212885149
reward_min: -123.09033613445382
queue_len: 0.07869738302040533
wait_time: 0.7573630026723333
delay_time: 4.927121989874968
pressure: 0.9637488947833776
total_envstep_count: 240816
total_train_sample_count: 240816
total_episode_count: 2076
total_duration: 8488.49251294136
[2025-02-20 19:46:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84705500806945
avg_train_sample_per_sec: 31.84705500806945
avg_episode_per_sec: 0.27454357765577114
collect_time: 21.854454040527344
reward_mean: -117.91806722689076
reward_std: 4.8736681348975175
reward_max: -110.3970588235294
reward_min: -125.2885154061625
queue_len: 0.07819500479236786
wait_time: 0.7580831735877375
delay_time: 4.935340949290514
pressure: 0.9498231653404067
total_envstep_count: 241512
total_train_sample_count: 241512
total_episode_count: 2082
total_duration: 8510.346966981888
[2025-02-20 19:47:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.828751020885587
avg_train_sample_per_sec: 31.828751020885587
avg_episode_per_sec: 0.2743857846628068
collect_time: 21.867022037506104
reward_mean: -118.15616246498602
reward_std: 2.9332143461603755
reward_max: -112.51820728291317
reward_min: -121.42507002801125
queue_len: 0.07835289288129045
wait_time: 0.7565785155795298
delay_time: 4.911855860383349
pressure: 0.9480548187444738
total_envstep_count: 242208
total_train_sample_count: 242208
total_episode_count: 2088
total_duration: 8532.213989019394
[2025-02-20 19:47:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.588639724398753
avg_train_sample_per_sec: 31.588639724398753
avg_episode_per_sec: 0.2723158596930927
collect_time: 22.03323745727539
reward_mean: -119.5519374416433
reward_std: 2.971412967156455
reward_max: -114.1631652661064
reward_min: -123.82633053221289
queue_len: 0.079278473104538
wait_time: 0.7641626389724768
delay_time: 4.957658656986998
pressure: 0.9727011494252874
total_envstep_count: 242904
total_train_sample_count: 242904
total_episode_count: 2094
total_duration: 8554.24722647667
[2025-02-20 19:47:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11357276721259
avg_train_sample_per_sec: 32.11357276721259
avg_episode_per_sec: 0.27684114454493614
collect_time: 21.673079013824463
reward_mean: -117.32784780578898
reward_std: 2.2179060883932564
reward_max: -113.8242296918768
reward_min: -120.42857142857144
queue_len: 0.07780361260330836
wait_time: 0.7428590468017445
delay_time: 4.847627136643154
pressure: 0.9557913351016799
total_envstep_count: 243600
total_train_sample_count: 243600
total_episode_count: 2100
total_duration: 8575.920305490494
[2025-02-20 19:48:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.158102781428276
avg_train_sample_per_sec: 32.158102781428276
avg_episode_per_sec: 0.27722502397782994
collect_time: 21.643067836761475
reward_mean: -121.1083099906629
reward_std: 3.4919236516885768
reward_max: -117.0413165266106
reward_min: -125.40616246498602
queue_len: 0.08031055039168629
wait_time: 0.7733890306785843
delay_time: 5.066708561855983
pressure: 0.9859637488947833
total_envstep_count: 244296
total_train_sample_count: 244296
total_episode_count: 2106
total_duration: 8597.563373327255
[2025-02-20 19:48:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0339272815451
avg_train_sample_per_sec: 32.0339272815451
avg_episode_per_sec: 0.2761545455305612
collect_time: 21.726964473724365
reward_mean: -120.75630252100841
reward_std: 3.3559403043390543
reward_max: -116.59873949579833
reward_min: -125.64145658263304
queue_len: 0.08007712368767135
wait_time: 0.7699137900076035
delay_time: 5.047869998784568
pressure: 0.973474801061008
total_envstep_count: 244992
total_train_sample_count: 244992
total_episode_count: 2112
total_duration: 8619.29033780098
[2025-02-20 19:49:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.953963385376948
avg_train_sample_per_sec: 31.953963385376948
avg_episode_per_sec: 0.27546520159807714
collect_time: 21.781335592269897
reward_mean: -119.5484360410831
reward_std: 1.651603749157279
reward_max: -117.83333333333333
reward_min: -122.87885154061621
queue_len: 0.07927615122087739
wait_time: 0.7628783277236625
delay_time: 4.9585495387322736
pressure: 0.9664014146772767
total_envstep_count: 245688
total_train_sample_count: 245688
total_episode_count: 2118
total_duration: 8641.07167339325
[2025-02-20 19:49:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.489374730814003
avg_train_sample_per_sec: 31.489374730814003
avg_episode_per_sec: 0.2714601269897759
collect_time: 22.102693557739258
reward_mean: -120.43872549019612
reward_std: 3.8518767943854546
reward_max: -113.08333333333337
reward_min: -123.58193277310924
queue_len: 0.07986652883965259
wait_time: 0.7660155021336563
delay_time: 4.990294857384028
pressure: 0.9840848806366047
total_envstep_count: 246384
total_train_sample_count: 246384
total_episode_count: 2124
total_duration: 8663.174366950989
[2025-02-20 19:49:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54259933220662
avg_train_sample_per_sec: 31.54259933220662
avg_episode_per_sec: 0.2719189597604019
collect_time: 22.0653977394104
reward_mean: -118.26353874883289
reward_std: 3.6787533855120644
reward_max: -112.93697478991598
reward_min: -122.3109243697479
queue_len: 0.07842409731354967
wait_time: 0.7542557031654394
delay_time: 5.019968107554875
pressure: 0.950817860300619
total_envstep_count: 247080
total_train_sample_count: 247080
total_episode_count: 2130
total_duration: 8685.2397646904
[2025-02-20 19:50:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74459906626214
avg_train_sample_per_sec: 31.74459906626214
avg_episode_per_sec: 0.2736603367781219
collect_time: 21.924989461898804
reward_mean: -116.71965452847803
reward_std: 1.6943126765548262
reward_max: -114.14355742296915
reward_min: -118.3361344537815
queue_len: 0.07740030141145758
wait_time: 0.7464685697444319
delay_time: 4.945037249140243
pressure: 0.9522546419098142
total_envstep_count: 247776
total_train_sample_count: 247776
total_episode_count: 2136
total_duration: 8707.164754152298
[2025-02-20 19:50:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.538683449092424
avg_train_sample_per_sec: 31.538683449092424
avg_episode_per_sec: 0.27188520214734846
collect_time: 22.068137407302856
reward_mean: -121.40546218487395
reward_std: 1.5749967084008425
reward_max: -119.58333333333333
reward_min: -123.47128851540616
queue_len: 0.08050760091835141
wait_time: 0.7777034001045159
delay_time: 5.026189728449292
pressure: 0.9901635720601237
total_envstep_count: 248472
total_train_sample_count: 248472
total_episode_count: 2142
total_duration: 8729.2328915596
[2025-02-20 19:50:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.725748893845342
avg_train_sample_per_sec: 31.725748893845342
avg_episode_per_sec: 0.2734978352917702
collect_time: 21.938016414642334
reward_mean: -118.7824463118581
reward_std: 5.46949113132939
reward_max: -113.24019607843138
reward_min: -126.33403361344538
queue_len: 0.07876820047205442
wait_time: 0.758813019018394
delay_time: 5.0004657670744805
pressure: 0.9567860300618921
total_envstep_count: 249168
total_train_sample_count: 249168
total_episode_count: 2148
total_duration: 8751.170907974243
[2025-02-20 19:51:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.532916184754626
avg_train_sample_per_sec: 31.532916184754626
avg_episode_per_sec: 0.271835484351333
collect_time: 22.072173595428467
reward_mean: -119.96545284780579
reward_std: 4.248542547968211
reward_max: -116.093837535014
reward_min: -128.43347338935575
queue_len: 0.07955268756485796
wait_time: 0.7596527669423208
delay_time: 5.042071604085032
pressure: 0.9742484526967287
total_envstep_count: 249864
total_train_sample_count: 249864
total_episode_count: 2154
total_duration: 8773.243081569672
[2025-02-20 19:51:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73950715034801
avg_train_sample_per_sec: 31.73950715034801
avg_episode_per_sec: 0.27361644095127596
collect_time: 21.92850685119629
reward_mean: -119.16748366013074
reward_std: 1.645212130195556
reward_max: -116.27030812324928
reward_min: -120.45308123249302
queue_len: 0.07902353027860128
wait_time: 0.7564874203439113
delay_time: 4.984391074291335
pressure: 0.9626436781609194
total_envstep_count: 250560
total_train_sample_count: 250560
total_episode_count: 2160
total_duration: 8795.171588420868
[2025-02-20 19:52:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.81334061633382
avg_train_sample_per_sec: 30.81334061633382
avg_episode_per_sec: 0.26563224669253294
collect_time: 22.587619066238403
reward_mean: -117.23074229691876
reward_std: 0.9527170232483857
reward_max: -115.54551820728292
reward_min: -118.66106442577028
queue_len: 0.07773921902978698
wait_time: 0.7467107422102351
delay_time: 4.903543209637342
pressure: 0.9458443854995578
total_envstep_count: 251256
total_train_sample_count: 251256
total_episode_count: 2166
total_duration: 8817.759207487106
[2025-02-20 19:52:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.628353606620344
avg_train_sample_per_sec: 31.628353606620344
avg_episode_per_sec: 0.2726582207467271
collect_time: 22.005571603775024
reward_mean: -118.13235294117648
reward_std: 3.957260214821311
reward_max: -114.20168067226895
reward_min: -125.57002801120453
queue_len: 0.0783371040723982
wait_time: 0.7538037872089595
delay_time: 4.865907714924269
pressure: 0.951923076923077
total_envstep_count: 251952
total_train_sample_count: 251952
total_episode_count: 2172
total_duration: 8839.764779090881
[2025-02-20 19:52:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.506734369056034
avg_train_sample_per_sec: 31.506734369056034
avg_episode_per_sec: 0.27160977904358646
collect_time: 22.09051537513733
reward_mean: -119.74533146591973
reward_std: 2.3499770713267365
reward_max: -116.82703081232495
reward_min: -123.1827731092437
queue_len: 0.07940671847872662
wait_time: 0.7674249629117784
delay_time: 4.994396889424197
pressure: 0.977343059239611
total_envstep_count: 252648
total_train_sample_count: 252648
total_episode_count: 2178
total_duration: 8861.855294466019
[2025-02-20 19:53:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6264117794424
avg_train_sample_per_sec: 31.6264117794424
avg_episode_per_sec: 0.27264148085726203
collect_time: 22.006922721862793
reward_mean: -121.54785247432307
reward_std: 3.5326638055417976
reward_max: -115.74929971988797
reward_min: -125.88235294117642
queue_len: 0.08060202418721688
wait_time: 0.7772031115717728
delay_time: 5.099615477371959
pressure: 0.9865163572060126
total_envstep_count: 253344
total_train_sample_count: 253344
total_episode_count: 2184
total_duration: 8883.862217187881
[2025-02-20 19:53:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49202405062905
avg_train_sample_per_sec: 31.49202405062905
avg_episode_per_sec: 0.2714829659536987
collect_time: 22.100834131240845
reward_mean: -119.25186741363213
reward_std: 3.0800986175168488
reward_max: -114.90546218487398
reward_min: -123.44187675070032
queue_len: 0.07907948767482237
wait_time: 0.7602700784115592
delay_time: 4.930716034163647
pressure: 0.9666224580017682
total_envstep_count: 254040
total_train_sample_count: 254040
total_episode_count: 2190
total_duration: 8905.963051319122
[2025-02-20 19:53:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.370404599890637
avg_train_sample_per_sec: 31.370404599890637
avg_episode_per_sec: 0.2704345224128503
collect_time: 22.186516523361206
reward_mean: -119.33846872082167
reward_std: 3.5486692125186448
reward_max: -115.18627450980395
reward_min: -125.05042016806729
queue_len: 0.07913691559736186
wait_time: 0.757250933087647
delay_time: 4.940334963933281
pressure: 0.9540229885057472
total_envstep_count: 254736
total_train_sample_count: 254736
total_episode_count: 2196
total_duration: 8928.149567842484
[2025-02-20 19:54:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31484940167505
avg_train_sample_per_sec: 31.31484940167505
avg_episode_per_sec: 0.26995559829030213
collect_time: 22.225877285003662
reward_mean: -118.68382352941178
reward_std: 5.257861480535114
reward_max: -112.71428571428571
reward_min: -126.60364145658265
queue_len: 0.0787028007489468
wait_time: 0.7560733510910996
delay_time: 5.010281343975634
pressure: 0.9566755083996462
total_envstep_count: 255432
total_train_sample_count: 255432
total_episode_count: 2202
total_duration: 8950.375445127487
[2025-02-20 19:54:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44646316217026
avg_train_sample_per_sec: 31.44646316217026
avg_episode_per_sec: 0.2710901996738816
collect_time: 22.1328547000885
reward_mean: -118.1986461251167
reward_std: 2.3476375825155618
reward_max: -115.42436974789916
reward_min: -122.60854341736687
queue_len: 0.07838106506970603
wait_time: 0.7532145705320148
delay_time: 4.931440667630128
pressure: 0.9688328912466844
total_envstep_count: 256128
total_train_sample_count: 256128
total_episode_count: 2208
total_duration: 8972.508299827576
[2025-02-20 19:55:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.387682549157972
avg_train_sample_per_sec: 31.387682549157972
avg_episode_per_sec: 0.2705834702513618
collect_time: 22.17430353164673
reward_mean: -121.37243230625582
reward_std: 4.057498858679479
reward_max: -115.86204481792714
reward_min: -126.30672268907564
queue_len: 0.0804856978158195
wait_time: 0.7725735077408503
delay_time: 5.055751188284497
pressure: 0.9793324491600354
total_envstep_count: 256824
total_train_sample_count: 256824
total_episode_count: 2214
total_duration: 8994.682603359222
[2025-02-20 19:55:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.23137284538838
avg_train_sample_per_sec: 31.23137284538838
avg_episode_per_sec: 0.2692359728050722
collect_time: 22.28528356552124
reward_mean: -120.89927637721757
reward_std: 4.028948564505254
reward_max: -114.26120448179275
reward_min: -125.06932773109243
queue_len: 0.08017193393714693
wait_time: 0.7722027803163706
delay_time: 5.071777249738779
pressure: 0.9801061007957559
total_envstep_count: 257520
total_train_sample_count: 257520
total_episode_count: 2220
total_duration: 9016.967886924744
[2025-02-20 19:55:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.638274796916335
avg_train_sample_per_sec: 31.638274796916335
avg_episode_per_sec: 0.2727437482492787
collect_time: 21.998671054840088
reward_mean: -121.04866946778712
reward_std: 2.1769536389083735
reward_max: -116.73739495798321
reward_min: -122.9145658263305
queue_len: 0.08027100097333363
wait_time: 0.7756518610981086
delay_time: 5.007527555531621
pressure: 0.9714854111405836
total_envstep_count: 258216
total_train_sample_count: 258216
total_episode_count: 2226
total_duration: 9038.966557979584
[2025-02-20 19:56:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96109990038664
avg_train_sample_per_sec: 31.96109990038664
avg_episode_per_sec: 0.27552672327919514
collect_time: 21.776472091674805
reward_mean: -118.17320261437906
reward_std: 1.7597120842334473
reward_max: -116.25980392156858
reward_min: -121.05882352941171
queue_len: 0.07836419271510547
wait_time: 0.7554134717547497
delay_time: 4.928953989256944
pressure: 0.9571175950486294
total_envstep_count: 258912
total_train_sample_count: 258912
total_episode_count: 2232
total_duration: 9060.743030071259
[2025-02-20 19:56:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.608789990703606
avg_train_sample_per_sec: 31.608789990703606
avg_episode_per_sec: 0.27248956888537595
collect_time: 22.01919150352478
reward_mean: -119.62780112044817
reward_std: 3.8393150920895684
reward_max: -116.61554621848741
reward_min: -127.8886554621849
queue_len: 0.07932878058385157
wait_time: 0.7571226877134585
delay_time: 4.999756503377181
pressure: 0.9617595048629531
total_envstep_count: 259608
total_train_sample_count: 259608
total_episode_count: 2238
total_duration: 9082.762221574783
[2025-02-20 19:56:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.948604008840686
avg_train_sample_per_sec: 30.948604008840686
avg_episode_per_sec: 0.2667983104210404
collect_time: 22.488898038864136
reward_mean: -116.98249299719886
reward_std: 5.911667582211071
reward_max: -108.69187675070027
reward_min: -126.64145658263308
queue_len: 0.0775745974782486
wait_time: 0.7396101123915525
delay_time: 4.941370356439887
pressure: 0.9482758620689656
total_envstep_count: 260304
total_train_sample_count: 260304
total_episode_count: 2244
total_duration: 9105.251119613647
[2025-02-20 19:57:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.43725094800593
avg_train_sample_per_sec: 31.43725094800593
avg_episode_per_sec: 0.2710107840345339
collect_time: 22.1393404006958
reward_mean: -118.26949112978524
reward_std: 4.85368115372245
reward_max: -111.57072829131651
reward_min: -124.73389355742296
queue_len: 0.07842804451577269
wait_time: 0.7509396663174553
delay_time: 4.942666857853258
pressure: 0.9476127320954908
total_envstep_count: 261000
total_train_sample_count: 261000
total_episode_count: 2250
total_duration: 9127.390460014343
[2025-02-20 19:57:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.374723227599222
avg_train_sample_per_sec: 30.374723227599222
avg_episode_per_sec: 0.26185106230688987
collect_time: 22.91378903388977
reward_mean: -119.1844070961718
reward_std: 5.3456542542128185
reward_max: -112.63515406162463
reward_min: -127.32352941176472
queue_len: 0.0790347527162943
wait_time: 0.7549426711444966
delay_time: 4.974926597826941
pressure: 0.967838196286472
total_envstep_count: 261696
total_train_sample_count: 261696
total_episode_count: 2256
total_duration: 9150.304249048233
[2025-02-20 19:58:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.134801959710956
avg_train_sample_per_sec: 31.134801959710956
avg_episode_per_sec: 0.26840346516992203
collect_time: 22.354405879974365
reward_mean: -120.61916433239965
reward_std: 2.806686854139853
reward_max: -116.89355742296917
reward_min: -125.17226890756307
queue_len: 0.07998618324429685
wait_time: 0.7664270173144413
delay_time: 5.051412376357252
pressure: 0.9808797524314765
total_envstep_count: 262392
total_train_sample_count: 262392
total_episode_count: 2262
total_duration: 9172.658654928207
[2025-02-20 19:58:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.162726750187918
avg_train_sample_per_sec: 31.162726750187918
avg_episode_per_sec: 0.26864419612230966
collect_time: 22.33437418937683
reward_mean: -123.49323062558356
reward_std: 4.381857257510935
reward_max: -119.84593837535012
reward_min: -132.30462184873946
queue_len: 0.08189206274906072
wait_time: 0.7854058621680324
delay_time: 5.323313327955684
pressure: 0.9918213969938107
total_envstep_count: 263088
total_train_sample_count: 263088
total_episode_count: 2268
total_duration: 9194.993029117584
[2025-02-20 19:58:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.23013528393348
avg_train_sample_per_sec: 31.23013528393348
avg_episode_per_sec: 0.2692253041718403
collect_time: 22.286166667938232
reward_mean: -118.11367880485527
reward_std: 4.208928208282173
reward_max: -113.38935574229689
reward_min: -126.2871148459384
queue_len: 0.07832472069287484
wait_time: 0.7543324027223622
delay_time: 4.897530610866973
pressure: 0.9655172413793104
total_envstep_count: 263784
total_train_sample_count: 263784
total_episode_count: 2274
total_duration: 9217.279195785522
[2025-02-20 19:59:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73891740407306
avg_train_sample_per_sec: 31.73891740407306
avg_episode_per_sec: 0.2736113569316643
collect_time: 21.928914308547974
reward_mean: -119.13865546218487
reward_std: 4.158380174274463
reward_max: -111.59173669467786
reward_min: -125.36064425770306
queue_len: 0.07900441343646211
wait_time: 0.7574780907057783
delay_time: 4.93034919248986
pressure: 0.9655172413793104
total_envstep_count: 264480
total_train_sample_count: 264480
total_episode_count: 2280
total_duration: 9239.20811009407
[2025-02-20 19:59:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.34729086875243
avg_train_sample_per_sec: 31.34729086875243
avg_episode_per_sec: 0.27023526610993476
collect_time: 22.20287561416626
reward_mean: -120.67110177404294
reward_std: 4.275832962320491
reward_max: -115.15406162464987
reward_min: -128.8025210084033
queue_len: 0.08002062451859611
wait_time: 0.776750963426927
delay_time: 5.0116368150856365
pressure: 0.9805481874447391
total_envstep_count: 265176
total_train_sample_count: 265176
total_episode_count: 2286
total_duration: 9261.410985708237
[2025-02-20 19:59:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31278969635567
avg_train_sample_per_sec: 31.31278969635567
avg_episode_per_sec: 0.26993784220996264
collect_time: 22.227339267730713
reward_mean: -119.96323529411764
reward_std: 3.5301740185776334
reward_max: -115.07843137254905
reward_min: -124.89495798319328
queue_len: 0.07955121703853955
wait_time: 0.7629714352584536
delay_time: 5.039478968088243
pressure: 0.9701591511936342
total_envstep_count: 265872
total_train_sample_count: 265872
total_episode_count: 2292
total_duration: 9283.638324975967
[2025-02-20 20:00:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.339893188006407
avg_train_sample_per_sec: 31.339893188006407
avg_episode_per_sec: 0.2701714930000552
collect_time: 22.20811653137207
reward_mean: -121.29738562091507
reward_std: 3.706142052369361
reward_max: -116.76330532212887
reward_min: -128.49579831932778
queue_len: 0.08043593210936012
wait_time: 0.7808531126862769
delay_time: 4.935864464403823
pressure: 0.984526967285588
total_envstep_count: 266568
total_train_sample_count: 266568
total_episode_count: 2298
total_duration: 9305.84644150734
[2025-02-20 20:00:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.210971288191583
avg_train_sample_per_sec: 31.210971288191583
avg_episode_per_sec: 0.2690600973119964
collect_time: 22.299850702285767
reward_mean: -121.91596638655459
reward_std: 3.369686655624363
reward_max: -116.5770308123249
reward_min: -126.53081232492993
queue_len: 0.08084613155607068
wait_time: 0.7862094661029753
delay_time: 5.107407716024789
pressure: 0.9973474801061007
total_envstep_count: 267264
total_train_sample_count: 267264
total_episode_count: 2304
total_duration: 9328.146292209625
[2025-02-20 20:01:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.17975298336196
avg_train_sample_per_sec: 31.17975298336196
avg_episode_per_sec: 0.2687909739944997
collect_time: 22.32217812538147
reward_mean: -118.6315359477124
reward_std: 4.195940161495044
reward_max: -114.57913165266106
reward_min: -125.19817927170865
queue_len: 0.07866812728628143
wait_time: 0.7591627720938067
delay_time: 4.898017329970039
pressure: 0.9538019451812555
total_envstep_count: 267960
total_train_sample_count: 267960
total_episode_count: 2310
total_duration: 9350.468470335007
[2025-02-20 20:01:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.467384828317716
avg_train_sample_per_sec: 31.467384828317716
avg_episode_per_sec: 0.2712705588648079
collect_time: 22.118139266967773
reward_mean: -122.51423902894491
reward_std: 1.0320909122307182
reward_max: -120.92366946778712
reward_min: -123.9516806722689
queue_len: 0.08124286407754967
wait_time: 0.7840570799495749
delay_time: 5.112409969942843
pressure: 0.9783377541998232
total_envstep_count: 268656
total_train_sample_count: 268656
total_episode_count: 2316
total_duration: 9372.586609601974
[2025-02-20 20:01:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7317373017667
avg_train_sample_per_sec: 31.7317373017667
avg_episode_per_sec: 0.27354945949798876
collect_time: 21.933876276016235
reward_mean: -116.34021942110176
reward_std: 3.288861362941559
reward_max: -112.32983193277312
reward_min: -120.87044817927168
queue_len: 0.07714868661876774
wait_time: 0.7367689007521666
delay_time: 4.868569488356287
pressure: 0.9402077807250221
total_envstep_count: 269352
total_train_sample_count: 269352
total_episode_count: 2322
total_duration: 9394.52048587799
[2025-02-20 20:02:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.221196949330952
avg_train_sample_per_sec: 31.221196949330952
avg_episode_per_sec: 0.2691482495631979
collect_time: 22.29254698753357
reward_mean: -117.38923902894491
reward_std: 1.7128694753053721
reward_max: -115.5112044817927
reward_min: -119.3235294117647
queue_len: 0.07784432296349135
wait_time: 0.7502588126320378
delay_time: 4.843102176129471
pressure: 0.9493810786914235
total_envstep_count: 270048
total_train_sample_count: 270048
total_episode_count: 2328
total_duration: 9416.813032865524
[2025-02-20 20:02:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.2938438538555
avg_train_sample_per_sec: 31.2938438538555
avg_episode_per_sec: 0.2697745159815129
collect_time: 22.240796089172363
reward_mean: -119.50676937441646
reward_std: 2.7567877954969933
reward_max: -116.78151260504202
reward_min: -124.0819327731093
queue_len: 0.07924852080531596
wait_time: 0.7604703021792272
delay_time: 4.9469297936425205
pressure: 0.9625331564986738
total_envstep_count: 270744
total_train_sample_count: 270744
total_episode_count: 2334
total_duration: 9439.053828954697
[2025-02-20 20:03:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.220790585656047
avg_train_sample_per_sec: 31.220790585656047
avg_episode_per_sec: 0.2691447464280694
collect_time: 22.292837142944336
reward_mean: -121.24112978524745
reward_std: 2.5261782265540664
reward_max: -117.81232492997201
reward_min: -125.22969187675072
queue_len: 0.08039862717854605
wait_time: 0.7719714433076502
delay_time: 5.00968723926403
pressure: 0.9772325375773652
total_envstep_count: 271440
total_train_sample_count: 271440
total_episode_count: 2340
total_duration: 9461.346666097641
[2025-02-20 20:03:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.428697834550142
avg_train_sample_per_sec: 31.428697834550142
avg_episode_per_sec: 0.27093705029784604
collect_time: 22.145365476608276
reward_mean: -117.47840802987862
reward_std: 2.976108540001005
reward_max: -112.31652661064425
reward_min: -120.28991596638657
queue_len: 0.07790345360071527
wait_time: 0.7443170349483738
delay_time: 4.839822172773638
pressure: 0.9523651635720601
total_envstep_count: 272136
total_train_sample_count: 272136
total_episode_count: 2346
total_duration: 9483.49203157425
[2025-02-20 20:03:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.210591217956452
avg_train_sample_per_sec: 31.210591217956452
avg_episode_per_sec: 0.26905682084445215
collect_time: 22.300122261047363
reward_mean: -121.97829131652658
reward_std: 2.246250788190526
reward_max: -119.35644257703083
reward_min: -126.52591036414562
queue_len: 0.08088746108522983
wait_time: 0.7826353131880515
delay_time: 5.1143362765564016
pressure: 0.9908267020335986
total_envstep_count: 272832
total_train_sample_count: 272832
total_episode_count: 2352
total_duration: 9505.792153835297
[2025-02-20 20:04:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.09350012107273
avg_train_sample_per_sec: 31.09350012107273
avg_episode_per_sec: 0.26804741483683386
collect_time: 22.38409948348999
reward_mean: -120.36041083099904
reward_std: 0.7263578923440135
reward_max: -119.19887955182071
reward_min: -121.18207282913158
queue_len: 0.07981459604177656
wait_time: 0.7706764513939971
delay_time: 4.976013532798285
pressure: 0.9878426171529621
total_envstep_count: 273528
total_train_sample_count: 273528
total_episode_count: 2358
total_duration: 9528.176253318787
[2025-02-20 20:04:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.137790167131694
avg_train_sample_per_sec: 31.137790167131694
avg_episode_per_sec: 0.2684292255787215
collect_time: 22.35226058959961
reward_mean: -120.33403361344538
reward_std: 3.3275307923461908
reward_max: -114.17296918767506
reward_min: -124.05532212885153
queue_len: 0.07979710451819985
wait_time: 0.7659444524936413
delay_time: 4.963551812122858
pressure: 0.9672855879752432
total_envstep_count: 274224
total_train_sample_count: 274224
total_episode_count: 2364
total_duration: 9550.528513908386
[2025-02-20 20:04:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32124286438373
avg_train_sample_per_sec: 31.32124286438373
avg_episode_per_sec: 0.2700107143481356
collect_time: 22.22134041786194
reward_mean: -119.38468720821662
reward_std: 3.5518296029744962
reward_max: -114.19957983193282
reward_min: -126.18277310924367
queue_len: 0.0791675644616821
wait_time: 0.7641397297203585
delay_time: 4.928057338481861
pressure: 0.9635278514588858
total_envstep_count: 274920
total_train_sample_count: 274920
total_episode_count: 2370
total_duration: 9572.749854326248
[2025-02-20 20:05:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.322149227749765
avg_train_sample_per_sec: 31.322149227749765
avg_episode_per_sec: 0.270018527825429
collect_time: 22.2206974029541
reward_mean: -119.23260971055088
reward_std: 2.229844706498909
reward_max: -116.39145658263298
reward_min: -122.25630252100844
queue_len: 0.07906671731468891
wait_time: 0.7615570211285222
delay_time: 4.899403751334121
pressure: 0.9710433244916002
total_envstep_count: 275616
total_train_sample_count: 275616
total_episode_count: 2376
total_duration: 9594.970551729202
[2025-02-20 20:05:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.337093466765836
avg_train_sample_per_sec: 31.337093466765836
avg_episode_per_sec: 0.27014735747211926
collect_time: 22.210100650787354
reward_mean: -118.56057422969184
reward_std: 2.892073572580471
reward_max: -114.38305322128852
reward_min: -122.46638655462183
queue_len: 0.07862107044409274
wait_time: 0.7592784792962277
delay_time: 4.9632815835428685
pressure: 0.9637488947833776
total_envstep_count: 276312
total_train_sample_count: 276312
total_episode_count: 2382
total_duration: 9617.18065237999
[2025-02-20 20:06:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.826503392187
avg_train_sample_per_sec: 29.826503392187
avg_episode_per_sec: 0.25712502924299135
collect_time: 23.334951162338257
reward_mean: -121.99276377217552
reward_std: 2.493216802645688
reward_max: -118.9334733893557
reward_min: -126.23389355742299
queue_len: 0.08089705820436043
wait_time: 0.7796561816592242
delay_time: 5.072563749265088
pressure: 0.9925950486295313
total_envstep_count: 277008
total_train_sample_count: 277008
total_episode_count: 2388
total_duration: 9640.515603542328
[2025-02-20 20:06:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.171824021522905
avg_train_sample_per_sec: 31.171824021522905
avg_episode_per_sec: 0.26872262087519744
collect_time: 22.327856063842773
reward_mean: -119.16141456582632
reward_std: 4.087112603619202
reward_max: -113.37114845938373
reward_min: -125.11064425770313
queue_len: 0.07901950568025619
wait_time: 0.7621546739827672
delay_time: 5.0089834904495305
pressure: 0.9694960212201592
total_envstep_count: 277704
total_train_sample_count: 277704
total_episode_count: 2394
total_duration: 9662.84345960617
[2025-02-20 20:06:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.8349115347644
avg_train_sample_per_sec: 30.8349115347644
avg_episode_per_sec: 0.2658182028859
collect_time: 22.571817636489868
reward_mean: -119.41503267973854
reward_std: 2.9947892163746683
reward_max: -114.60574229691873
reward_min: -122.94887955182071
queue_len: 0.07918768745340753
wait_time: 0.7633859688879975
delay_time: 4.901599967570074
pressure: 0.9592175066312998
total_envstep_count: 278400
total_train_sample_count: 278400
total_episode_count: 2400
total_duration: 9685.41527724266
[2025-02-20 20:07:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.227703547573427
avg_train_sample_per_sec: 31.227703547573427
avg_episode_per_sec: 0.2692043409273571
collect_time: 22.287902116775513
reward_mean: -120.14425770308124
reward_std: 0.843967798369114
reward_max: -118.71288515406162
reward_min: -121.19607843137256
queue_len: 0.07967125842379391
wait_time: 0.7660090008594064
delay_time: 4.997232311065344
pressure: 0.9755747126436782
total_envstep_count: 279096
total_train_sample_count: 279096
total_episode_count: 2406
total_duration: 9707.703179359436
[2025-02-20 20:07:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.27130871831146
avg_train_sample_per_sec: 31.27130871831146
avg_episode_per_sec: 0.2695802475716505
collect_time: 22.256823539733887
reward_mean: -118.40662931839402
reward_std: 3.1499920848691194
reward_max: -113.06372549019605
reward_min: -121.57843137254909
queue_len: 0.07851898495914723
wait_time: 0.7597052415130507
delay_time: 4.940274902770182
pressure: 0.9634173297966403
total_envstep_count: 279792
total_train_sample_count: 279792
total_episode_count: 2412
total_duration: 9729.96000289917
[2025-02-20 20:07:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.08069054507363
avg_train_sample_per_sec: 31.08069054507363
avg_episode_per_sec: 0.26793698745753125
collect_time: 22.393324851989746
reward_mean: -118.01015406162468
reward_std: 3.6082172201743257
reward_max: -111.49649859943983
reward_min: -121.89985994397759
queue_len: 0.07825607033264236
wait_time: 0.7464051049243747
delay_time: 4.954509308134242
pressure: 0.9498231653404069
total_envstep_count: 280488
total_train_sample_count: 280488
total_episode_count: 2418
total_duration: 9752.35332775116
[2025-02-20 20:08:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.253978594647382
avg_train_sample_per_sec: 31.253978594647382
avg_episode_per_sec: 0.26943084995385674
collect_time: 22.26916480064392
reward_mean: -120.03478057889822
reward_std: 4.476220013530319
reward_max: -113.12535014005597
reward_min: -125.69397759103643
queue_len: 0.07959866086133835
wait_time: 0.7653052379218708
delay_time: 5.016701934184539
pressure: 0.9772325375773652
total_envstep_count: 281184
total_train_sample_count: 281184
total_episode_count: 2424
total_duration: 9774.622492551804
[2025-02-20 20:08:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54699243964231
avg_train_sample_per_sec: 31.54699243964231
avg_episode_per_sec: 0.27195683137622684
collect_time: 22.06232500076294
reward_mean: -118.59827264239028
reward_std: 5.2333446240037125
reward_max: -113.88025210084035
reward_min: -127.3494397759104
queue_len: 0.0786460693915055
wait_time: 0.7581902124244925
delay_time: 4.872943866704038
pressure: 0.9630857648099026
total_envstep_count: 281880
total_train_sample_count: 281880
total_episode_count: 2430
total_duration: 9796.684817552567
[2025-02-20 20:09:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.639688633522546
avg_train_sample_per_sec: 30.639688633522546
avg_episode_per_sec: 0.2641352468407116
collect_time: 22.715635538101196
reward_mean: -119.56664332399629
reward_std: 2.9636162509900053
reward_max: -114.44467787114849
reward_min: -123.47478991596644
queue_len: 0.07928822501591265
wait_time: 0.7628122314354565
delay_time: 5.026936764538678
pressure: 0.9701591511936339
total_envstep_count: 282576
total_train_sample_count: 282576
total_episode_count: 2436
total_duration: 9819.400453090668
[2025-02-20 20:09:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.905099126748915
avg_train_sample_per_sec: 30.905099126748915
avg_episode_per_sec: 0.26642326833404234
collect_time: 22.52055549621582
reward_mean: -119.58800186741361
reward_std: 3.464857523984727
reward_max: -116.35434173669466
reward_min: -127.10504201680678
queue_len: 0.07930238850624245
wait_time: 0.7609400192437716
delay_time: 5.018221211346541
pressure: 0.9633068081343944
total_envstep_count: 283272
total_train_sample_count: 283272
total_episode_count: 2442
total_duration: 9841.921008586884
[2025-02-20 20:09:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.364978411483776
avg_train_sample_per_sec: 31.364978411483776
avg_episode_per_sec: 0.27038774492658424
collect_time: 22.190354824066162
reward_mean: -118.07924836601308
reward_std: 2.6291974114895087
reward_max: -115.33963585434171
reward_min: -123.14145658263305
queue_len: 0.07830188883687869
wait_time: 0.754105322500353
delay_time: 4.903270437185436
pressure: 0.951923076923077
total_envstep_count: 283968
total_train_sample_count: 283968
total_episode_count: 2448
total_duration: 9864.11136341095
[2025-02-20 20:10:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.535077511966726
avg_train_sample_per_sec: 31.535077511966726
avg_episode_per_sec: 0.27185411648247176
collect_time: 22.070660829544067
reward_mean: -119.55695611577964
reward_std: 2.92369333219227
reward_max: -116.71148459383754
reward_min: -125.68977591036413
queue_len: 0.07928180113778491
wait_time: 0.7627161054519068
delay_time: 4.993168930996145
pressure: 0.9724801061007957
total_envstep_count: 284664
total_train_sample_count: 284664
total_episode_count: 2454
total_duration: 9886.182024240494
[2025-02-20 20:10:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.281616866972517
avg_train_sample_per_sec: 31.281616866972517
avg_episode_per_sec: 0.2696691109221769
collect_time: 22.249489307403564
reward_mean: -119.51937441643322
reward_std: 2.7820187184371936
reward_max: -116.65616246498598
reward_min: -124.68277310924374
queue_len: 0.07925687958649419
wait_time: 0.7640727820748107
delay_time: 4.909039726459607
pressure: 0.9714854111405836
total_envstep_count: 285360
total_train_sample_count: 285360
total_episode_count: 2460
total_duration: 9908.431513547897
[2025-02-20 20:11:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.548708701760958
avg_train_sample_per_sec: 31.548708701760958
avg_episode_per_sec: 0.2719716267393186
collect_time: 22.061124801635742
reward_mean: -117.79586834733895
reward_std: 4.7823637735345965
reward_max: -109.05952380952384
reward_min: -124.9509803921569
queue_len: 0.07811397105261204
wait_time: 0.7519303366793225
delay_time: 4.9489039550416
pressure: 0.9479442970822282
total_envstep_count: 286056
total_train_sample_count: 286056
total_episode_count: 2466
total_duration: 9930.492638349533
[2025-02-20 20:11:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.76697063048524
avg_train_sample_per_sec: 30.76697063048524
avg_episode_per_sec: 0.2652325054352176
collect_time: 22.62166166305542
reward_mean: -120.79971988795519
reward_std: 3.0576047970883797
reward_max: -117.13235294117652
reward_min: -125.29131652661064
queue_len: 0.08010591504506312
wait_time: 0.7699941271822609
delay_time: 5.089511028346824
pressure: 0.9699381078691424
total_envstep_count: 286752
total_train_sample_count: 286752
total_episode_count: 2472
total_duration: 9953.114300012589
[2025-02-20 20:11:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.474528244977353
avg_train_sample_per_sec: 31.474528244977353
avg_episode_per_sec: 0.27133214004290823
collect_time: 22.11311936378479
reward_mean: -116.30578898225959
reward_std: 3.802350656112505
reward_max: -111.0
reward_min: -120.62254901960785
queue_len: 0.0771258547627716
wait_time: 0.7334119213556334
delay_time: 4.8755304186886255
pressure: 0.934681697612732
total_envstep_count: 287448
total_train_sample_count: 287448
total_episode_count: 2478
total_duration: 9975.227419376373
[2025-02-20 20:12:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.516284053436163
avg_train_sample_per_sec: 31.516284053436163
avg_episode_per_sec: 0.27169210390893245
collect_time: 22.083821773529053
reward_mean: -117.9873949579832
reward_std: 3.149115490523686
reward_max: -114.02450980392156
reward_min: -124.28011204481791
queue_len: 0.07824097808884826
wait_time: 0.7471428447594777
delay_time: 5.001906971310506
pressure: 0.9523651635720602
total_envstep_count: 288144
total_train_sample_count: 288144
total_episode_count: 2484
total_duration: 9997.311241149902
[2025-02-20 20:12:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.943190893501942
avg_train_sample_per_sec: 30.943190893501942
avg_episode_per_sec: 0.2667516456336374
collect_time: 22.49283218383789
reward_mean: -119.95985060690941
reward_std: 4.148509714931964
reward_max: -113.88165266106444
reward_min: -126.09803921568626
queue_len: 0.07954897255100095
wait_time: 0.765217238531133
delay_time: 4.9974477572167695
pressure: 0.9715959328028294
total_envstep_count: 288840
total_train_sample_count: 288840
total_episode_count: 2490
total_duration: 10019.80407333374
[2025-02-20 20:12:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.14527781644988
avg_train_sample_per_sec: 31.14527781644988
avg_episode_per_sec: 0.26849377427974036
collect_time: 22.34688687324524
reward_mean: -117.80718954248368
reward_std: 2.8347754310584077
reward_max: -115.17577030812328
reward_min: -123.86204481792724
queue_len: 0.07812147847644806
wait_time: 0.7557961181820209
delay_time: 4.839474214519146
pressure: 0.9571175950486296
total_envstep_count: 289536
total_train_sample_count: 289536
total_episode_count: 2496
total_duration: 10042.150960206985
[2025-02-20 20:13:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.002255420573466
avg_train_sample_per_sec: 31.002255420573466
avg_episode_per_sec: 0.2672608225911506
collect_time: 22.449979543685913
reward_mean: -117.65277777777776
reward_std: 3.272909606753708
reward_max: -114.6190476190476
reward_min: -123.44047619047616
queue_len: 0.07801908340701443
wait_time: 0.7554092923641605
delay_time: 4.849140720526087
pressure: 0.9501547303271441
total_envstep_count: 290232
total_train_sample_count: 290232
total_episode_count: 2502
total_duration: 10064.600939750671
[2025-02-20 20:13:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.012012334029805
avg_train_sample_per_sec: 31.012012334029805
avg_episode_per_sec: 0.26734493391405006
collect_time: 22.44291639328003
reward_mean: -121.27766106442577
reward_std: 3.8618033153195293
reward_max: -115.5735294117647
reward_min: -127.2303921568627
queue_len: 0.08042285216473859
wait_time: 0.7722031672969808
delay_time: 5.076546065007118
pressure: 0.9728116710875332
total_envstep_count: 290928
total_train_sample_count: 290928
total_episode_count: 2508
total_duration: 10087.043856143951
[2025-02-20 20:14:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.05066815453914
avg_train_sample_per_sec: 31.05066815453914
avg_episode_per_sec: 0.26767817374602704
collect_time: 22.414976596832275
reward_mean: -117.23237628384685
reward_std: 4.601475792307295
reward_max: -108.89285714285711
reward_min: -122.54831932773106
queue_len: 0.07774030257549526
wait_time: 0.7445728291316526
delay_time: 4.8483212144131285
pressure: 0.9441865605658709
total_envstep_count: 291624
total_train_sample_count: 291624
total_episode_count: 2514
total_duration: 10109.458832740784
[2025-02-20 20:14:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.22812311950385
avg_train_sample_per_sec: 31.22812311950385
avg_episode_per_sec: 0.26920795792675734
collect_time: 22.28760266304016
reward_mean: -118.90522875816994
reward_std: 5.767461678654586
reward_max: -113.61274509803923
reward_min: -130.406162464986
queue_len: 0.07884962119242038
wait_time: 0.7570847636136683
delay_time: 4.996834893599729
pressure: 0.9587754199823166
total_envstep_count: 292320
total_train_sample_count: 292320
total_episode_count: 2520
total_duration: 10131.746435403824
[2025-02-20 20:14:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.281045689722255
avg_train_sample_per_sec: 31.281045689722255
avg_episode_per_sec: 0.26966418698036426
collect_time: 22.249895572662354
reward_mean: -120.0605742296919
reward_std: 3.773358816375804
reward_max: -115.44537815126056
reward_min: -125.67787114845937
queue_len: 0.07961576540430497
wait_time: 0.7651814815227592
delay_time: 4.931231538874395
pressure: 0.9710433244916002
total_envstep_count: 293016
total_train_sample_count: 293016
total_episode_count: 2526
total_duration: 10153.996330976486
[2025-02-20 20:15:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.313206519610734
avg_train_sample_per_sec: 31.313206519610734
avg_episode_per_sec: 0.26994143551388566
collect_time: 22.227043390274048
reward_mean: -117.9780578898226
reward_std: 2.0677704009373064
reward_max: -114.76540616246498
reward_min: -121.00490196078432
queue_len: 0.07823478639908661
wait_time: 0.7527191579549593
delay_time: 4.904447548958957
pressure: 0.9523651635720602
total_envstep_count: 293712
total_train_sample_count: 293712
total_episode_count: 2532
total_duration: 10176.22337436676
[2025-02-20 20:15:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.175154593167644
avg_train_sample_per_sec: 31.175154593167644
avg_episode_per_sec: 0.26875133269972107
collect_time: 22.325470685958862
reward_mean: -119.12254901960785
reward_std: 1.9349412391697027
reward_max: -116.75980392156863
reward_min: -121.94327731092436
queue_len: 0.07899373277162325
wait_time: 0.7563907525875071
delay_time: 4.968469718020492
pressure: 0.965185676392573
total_envstep_count: 294408
total_train_sample_count: 294408
total_episode_count: 2538
total_duration: 10198.54884505272
[2025-02-20 20:15:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.404862306762727
avg_train_sample_per_sec: 31.404862306762727
avg_episode_per_sec: 0.2707315716100235
collect_time: 22.1621732711792
reward_mean: -117.69421101774043
reward_std: 4.6438010812938675
reward_max: -109.84523809523813
reward_min: -123.92647058823529
queue_len: 0.07804655903033185
wait_time: 0.7480024060906413
delay_time: 4.910622327214626
pressure: 0.9576702033598584
total_envstep_count: 295104
total_train_sample_count: 295104
total_episode_count: 2544
total_duration: 10220.711018323898
[2025-02-20 20:16:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.046529067585997
avg_train_sample_per_sec: 31.046529067585997
avg_episode_per_sec: 0.2676424919619483
collect_time: 22.417964935302734
reward_mean: -120.0731792717087
reward_std: 3.6418481068248805
reward_max: -117.03851540616247
reward_min: -127.78711484593838
queue_len: 0.07962412418548322
wait_time: 0.7611945750890983
delay_time: 4.96489973713738
pressure: 0.9736958443854996
total_envstep_count: 295800
total_train_sample_count: 295800
total_episode_count: 2550
total_duration: 10243.128983259201
[2025-02-20 20:16:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.984433505066008
avg_train_sample_per_sec: 30.984433505066008
avg_episode_per_sec: 0.2671071853885001
collect_time: 22.462892532348633
reward_mean: -120.56816059757234
reward_std: 2.7072394597854887
reward_max: -117.29481792717088
reward_min: -125.43417366946775
queue_len: 0.07995236113897372
wait_time: 0.7750320729529654
delay_time: 4.955857197137458
pressure: 0.9785587975243147
total_envstep_count: 296496
total_train_sample_count: 296496
total_episode_count: 2556
total_duration: 10265.59187579155
[2025-02-20 20:17:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.103750680692578
avg_train_sample_per_sec: 31.103750680692578
avg_episode_per_sec: 0.26813578173010844
collect_time: 22.37672257423401
reward_mean: -118.46825396825396
reward_std: 3.344999374483903
reward_max: -114.69047619047618
reward_min: -122.38445378151256
queue_len: 0.07855985011157424
wait_time: 0.758960613423088
delay_time: 4.969440179364553
pressure: 0.9596595932802829
total_envstep_count: 297192
total_train_sample_count: 297192
total_episode_count: 2562
total_duration: 10287.968598365784
[2025-02-20 20:17:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39111476896633
avg_train_sample_per_sec: 31.39111476896633
avg_episode_per_sec: 0.270613058353158
collect_time: 22.171879053115845
reward_mean: -118.63527077497668
reward_std: 3.197347153828517
reward_max: -114.98669467787117
reward_min: -123.69677871148464
queue_len: 0.07867060396218613
wait_time: 0.7585229383530602
delay_time: 4.9718502540879745
pressure: 0.962422634836428
total_envstep_count: 297888
total_train_sample_count: 297888
total_episode_count: 2568
total_duration: 10310.1404774189
[2025-02-20 20:17:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.045765038959768
avg_train_sample_per_sec: 31.045765038959768
avg_episode_per_sec: 0.2676359055082739
collect_time: 22.418516635894775
reward_mean: -115.63363678804855
reward_std: 4.054126288973413
reward_max: -107.68487394957984
reward_min: -121.39285714285712
queue_len: 0.07668013049605342
wait_time: 0.7371047999217372
delay_time: 4.868215478471451
pressure: 0.9316976127320955
total_envstep_count: 298584
total_train_sample_count: 298584
total_episode_count: 2574
total_duration: 10332.558994054794
[2025-02-20 20:18:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.507038373091003
avg_train_sample_per_sec: 31.507038373091003
avg_episode_per_sec: 0.27161239976802587
collect_time: 22.090302228927612
reward_mean: -117.64775910364146
reward_std: 3.2436055835631987
reward_max: -111.98669467787114
reward_min: -122.45028011204478
queue_len: 0.07801575537376752
wait_time: 0.7413272227547075
delay_time: 4.996179174440116
pressure: 0.9460654288240495
total_envstep_count: 299280
total_train_sample_count: 299280
total_episode_count: 2580
total_duration: 10354.649296283722
[2025-02-20 20:18:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.172955770138604
avg_train_sample_per_sec: 31.172955770138604
avg_episode_per_sec: 0.2687323773287811
collect_time: 22.327045440673828
reward_mean: -117.42285247432307
reward_std: 2.5228021168561803
reward_max: -113.32492997198878
reward_min: -121.50000000000001
queue_len: 0.07786661304663334
wait_time: 0.752525280669297
delay_time: 4.924615819524192
pressure: 0.9435234305923962
total_envstep_count: 299976
total_train_sample_count: 299976
total_episode_count: 2586
total_duration: 10376.976341724396
[2025-02-20 20:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.18439137258735
avg_train_sample_per_sec: 31.18439137258735
avg_episode_per_sec: 0.26883096010851165
collect_time: 22.3188579082489
reward_mean: -118.57271241830067
reward_std: 2.085810946483095
reward_max: -114.80042016806722
reward_min: -121.33263305322133
queue_len: 0.07862911964078294
wait_time: 0.7545159863237956
delay_time: 4.915334805149642
pressure: 0.9549071618037135
total_envstep_count: 300672
total_train_sample_count: 300672
total_episode_count: 2592
total_duration: 10399.295199632645
[2025-02-20 20:19:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.16767420312242
avg_train_sample_per_sec: 31.16767420312242
avg_episode_per_sec: 0.26868684657864156
collect_time: 22.33082890510559
reward_mean: -119.64857609710549
reward_std: 3.119485182629111
reward_max: -115.64285714285714
reward_min: -122.97128851540616
queue_len: 0.0793425570935713
wait_time: 0.7634861194698924
delay_time: 5.079395213259238
pressure: 0.9539124668435014
total_envstep_count: 301368
total_train_sample_count: 301368
total_episode_count: 2598
total_duration: 10421.62602853775
[2025-02-20 20:19:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.162312779763482
avg_train_sample_per_sec: 30.162312779763482
avg_episode_per_sec: 0.2600199377565818
collect_time: 23.075153589248657
reward_mean: -118.97630718954248
reward_std: 3.4387625365725105
reward_max: -114.29971988795518
reward_min: -122.94187675070032
queue_len: 0.07889675543073109
wait_time: 0.7567781975743436
delay_time: 5.012123355566726
pressure: 0.9624226348364279
total_envstep_count: 302064
total_train_sample_count: 302064
total_episode_count: 2604
total_duration: 10444.701182126999
[2025-02-20 20:20:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.92002032400952
avg_train_sample_per_sec: 30.92002032400952
avg_episode_per_sec: 0.26655189934490964
collect_time: 22.509687662124634
reward_mean: -117.18335667600371
reward_std: 2.302312328276016
reward_max: -113.9516806722689
reward_min: -119.80672268907564
queue_len: 0.07770779620424649
wait_time: 0.7422312868560333
delay_time: 4.957886516412969
pressure: 0.9498231653404069
total_envstep_count: 302760
total_train_sample_count: 302760
total_episode_count: 2610
total_duration: 10467.210869789124
[2025-02-20 20:20:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.143120084612836
avg_train_sample_per_sec: 31.143120084612836
avg_episode_per_sec: 0.2684751731432141
collect_time: 22.348435163497925
reward_mean: -120.21767040149393
reward_std: 5.073050105891859
reward_max: -114.28081232493003
reward_min: -128.9306722689075
queue_len: 0.07971994058454505
wait_time: 0.7689177019171947
delay_time: 5.0972296912715525
pressure: 0.9683908045977012
total_envstep_count: 303456
total_train_sample_count: 303456
total_episode_count: 2616
total_duration: 10489.559304952621
[2025-02-20 20:20:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.072560185533877
avg_train_sample_per_sec: 31.072560185533877
avg_episode_per_sec: 0.2678668981511541
collect_time: 22.399184226989746
reward_mean: -117.49498132586366
reward_std: 3.317198985298582
reward_max: -114.26820728291317
reward_min: -122.73669467787118
queue_len: 0.07791444385004222
wait_time: 0.7439264941166565
delay_time: 4.9282160500864896
pressure: 0.9497126436781609
total_envstep_count: 304152
total_train_sample_count: 304152
total_episode_count: 2622
total_duration: 10511.958489179611
[2025-02-20 20:21:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.96611635121805
avg_train_sample_per_sec: 30.96611635121805
avg_episode_per_sec: 0.2669492788898108
collect_time: 22.476179838180542
reward_mean: -120.92647058823529
reward_std: 2.5289327810089874
reward_max: -118.42436974789915
reward_min: -126.26750700280111
queue_len: 0.08018996723357778
wait_time: 0.7714593131682381
delay_time: 5.112818965033339
pressure: 0.9679487179487181
total_envstep_count: 304848
total_train_sample_count: 304848
total_episode_count: 2628
total_duration: 10534.434669017792
[2025-02-20 20:21:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.35395520297035
avg_train_sample_per_sec: 31.35395520297035
avg_episode_per_sec: 0.2702927172669858
collect_time: 22.198156356811523
reward_mean: -118.38970588235294
reward_std: 1.9648213888175567
reward_max: -116.16736694677873
reward_min: -121.79411764705885
queue_len: 0.07850776252145421
wait_time: 0.7589981505422682
delay_time: 4.941682265920949
pressure: 0.958001768346596
total_envstep_count: 305544
total_train_sample_count: 305544
total_episode_count: 2634
total_duration: 10556.632825374603
[2025-02-20 20:22:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.147662168755232
avg_train_sample_per_sec: 31.147662168755232
avg_episode_per_sec: 0.26851432904099337
collect_time: 22.345176219940186
reward_mean: -117.61274509803921
reward_std: 2.4850039123073904
reward_max: -113.58263305322126
reward_min: -119.92927170868349
queue_len: 0.07799253653716127
wait_time: 0.7526778284258001
delay_time: 4.905273661176356
pressure: 0.9559018567639258
total_envstep_count: 306240
total_train_sample_count: 306240
total_episode_count: 2640
total_duration: 10578.978001594543
[2025-02-20 20:22:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.956664040599648
avg_train_sample_per_sec: 30.956664040599648
avg_episode_per_sec: 0.26686779345344525
collect_time: 22.48304271697998
reward_mean: -118.64787581699346
reward_std: 3.277487670919189
reward_max: -112.36834733893556
reward_min: -122.80322128851543
queue_len: 0.07867896274336438
wait_time: 0.7619056906582262
delay_time: 4.963305556906085
pressure: 0.9595490716180372
total_envstep_count: 306936
total_train_sample_count: 306936
total_episode_count: 2646
total_duration: 10601.461044311523
[2025-02-20 20:22:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39217303905028
avg_train_sample_per_sec: 31.39217303905028
avg_episode_per_sec: 0.2706221813711231
collect_time: 22.17113161087036
reward_mean: -118.87628384687207
reward_std: 2.7474615588093907
reward_max: -116.59663865546221
reward_min: -124.77100840336132
queue_len: 0.0788304269541592
wait_time: 0.7588698277719576
delay_time: 5.038002841122722
pressure: 0.9542440318302386
total_envstep_count: 307632
total_train_sample_count: 307632
total_episode_count: 2652
total_duration: 10623.632175922394
[2025-02-20 20:23:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.241557382925613
avg_train_sample_per_sec: 31.241557382925613
avg_episode_per_sec: 0.26932377054246215
collect_time: 22.278018712997437
reward_mean: -119.67962184873949
reward_std: 3.7036365669679094
reward_max: -114.67296918767505
reward_min: -124.60994397759104
queue_len: 0.07936314446202884
wait_time: 0.7661505583665829
delay_time: 4.918149729011414
pressure: 0.9718169761273209
total_envstep_count: 308328
total_train_sample_count: 308328
total_episode_count: 2658
total_duration: 10645.910194635391
[2025-02-20 20:23:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.191640827633474
avg_train_sample_per_sec: 31.191640827633474
avg_episode_per_sec: 0.2688934554106334
collect_time: 22.31367063522339
reward_mean: -119.41328197945846
reward_std: 5.567748206785193
reward_max: -111.93767507002802
reward_min: -128.28151260504202
queue_len: 0.07918652651157723
wait_time: 0.7637919889441186
delay_time: 4.985226732670491
pressure: 0.9641909814323607
total_envstep_count: 309024
total_train_sample_count: 309024
total_episode_count: 2664
total_duration: 10668.223865270615
[2025-02-20 20:23:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.914601487665518
avg_train_sample_per_sec: 30.914601487665518
avg_episode_per_sec: 0.26650518523849587
collect_time: 22.513633251190186
reward_mean: -119.20926704014938
reward_std: 2.2174073278399296
reward_max: -117.04691876750707
reward_min: -123.81932773109239
queue_len: 0.07905123809028475
wait_time: 0.7559827976283352
delay_time: 4.943481262040788
pressure: 0.9604332449160036
total_envstep_count: 309720
total_train_sample_count: 309720
total_episode_count: 2670
total_duration: 10690.737498521805
[2025-02-20 20:24:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.972867686969302
avg_train_sample_per_sec: 30.972867686969302
avg_episode_per_sec: 0.2670074800600802
collect_time: 22.471280574798584
reward_mean: -118.80217086834733
reward_std: 2.9220427649453358
reward_max: -114.31442577030808
reward_min: -121.46988795518205
queue_len: 0.07878128041667594
wait_time: 0.7579502844462277
delay_time: 4.982780645891972
pressure: 0.9652961980548187
total_envstep_count: 310416
total_train_sample_count: 310416
total_episode_count: 2676
total_duration: 10713.208779096603
[2025-02-20 20:24:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.068157685921292
avg_train_sample_per_sec: 31.068157685921292
avg_episode_per_sec: 0.267828945568287
collect_time: 22.402358293533325
reward_mean: -119.49031279178335
reward_std: 3.7154525416687822
reward_max: -114.4173669467787
reward_min: -124.83893557422964
queue_len: 0.07923760795211099
wait_time: 0.7587418145861351
delay_time: 5.0445794454298545
pressure: 0.9592175066312997
total_envstep_count: 311112
total_train_sample_count: 311112
total_episode_count: 2682
total_duration: 10735.611137390137
[2025-02-20 20:25:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.629793255143657
avg_train_sample_per_sec: 31.629793255143657
avg_episode_per_sec: 0.2726706315098591
collect_time: 22.00457000732422
reward_mean: -119.71451914098975
reward_std: 5.187751428903523
reward_max: -115.52380952380955
reward_min: -131.0287114845939
queue_len: 0.0793862859025131
wait_time: 0.7650829562594268
delay_time: 5.003774315315513
pressure: 0.9651856763925729
total_envstep_count: 311808
total_train_sample_count: 311808
total_episode_count: 2688
total_duration: 10757.615707397461
[2025-02-20 20:25:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31226070618863
avg_train_sample_per_sec: 31.31226070618863
avg_episode_per_sec: 0.269933281949902
collect_time: 22.227714776992798
reward_mean: -122.06314192343604
reward_std: 4.172823512153382
reward_max: -115.87745098039218
reward_min: -126.64005602240896
queue_len: 0.08094372806593901
wait_time: 0.7782814717398896
delay_time: 5.121568248789117
pressure: 0.9896109637488948
total_envstep_count: 312504
total_train_sample_count: 312504
total_episode_count: 2694
total_duration: 10779.843422174454
[2025-02-20 20:25:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.05008853666552
avg_train_sample_per_sec: 31.05008853666552
avg_episode_per_sec: 0.26767317704022
collect_time: 22.4153950214386
reward_mean: -119.06722689075629
reward_std: 3.9664357412468347
reward_max: -114.38865546218483
reward_min: -125.79901960784312
queue_len: 0.07895704700978534
wait_time: 0.7599865764165967
delay_time: 4.983229152262488
pressure: 0.9620910698496905
total_envstep_count: 313200
total_train_sample_count: 313200
total_episode_count: 2700
total_duration: 10802.258817195892
[2025-02-20 20:26:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.08670139541616
avg_train_sample_per_sec: 31.08670139541616
avg_episode_per_sec: 0.2679888051328979
collect_time: 22.388994932174683
reward_mean: -117.89180672268911
reward_std: 1.7514559410240198
reward_max: -115.65966386554624
reward_min: -120.82563025210082
queue_len: 0.07817759066491319
wait_time: 0.7524656856553408
delay_time: 4.954573666355077
pressure: 0.9521441202475684
total_envstep_count: 313896
total_train_sample_count: 313896
total_episode_count: 2706
total_duration: 10824.647812128067
[2025-02-20 20:26:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.120477624855084
avg_train_sample_per_sec: 31.120477624855084
avg_episode_per_sec: 0.2682799795246128
collect_time: 22.36469531059265
reward_mean: -117.69070961718019
reward_std: 2.756573672483043
reward_max: -113.07142857142856
reward_min: -122.22268907563027
queue_len: 0.07804423714667122
wait_time: 0.7525351099767935
delay_time: 4.922697122966516
pressure: 0.9574491600353668
total_envstep_count: 314592
total_train_sample_count: 314592
total_episode_count: 2712
total_duration: 10847.01250743866
[2025-02-20 20:27:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.144806970803934
avg_train_sample_per_sec: 31.144806970803934
avg_episode_per_sec: 0.26848971526555115
collect_time: 22.347224712371826
reward_mean: -117.85130718954248
reward_std: 3.3650657231262304
reward_max: -113.4453781512605
reward_min: -122.44117647058829
queue_len: 0.07815073421057193
wait_time: 0.7512340811656228
delay_time: 4.9144267602383
pressure: 0.9587754199823166
total_envstep_count: 315288
total_train_sample_count: 315288
total_episode_count: 2718
total_duration: 10869.359732151031
[2025-02-20 20:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.209151106042597
avg_train_sample_per_sec: 31.209151106042597
avg_episode_per_sec: 0.2690444060865741
collect_time: 22.301151275634766
reward_mean: -114.89600840336134
reward_std: 3.0436796451370203
reward_max: -110.14845938375348
reward_min: -118.39145658263303
queue_len: 0.07619098700488153
wait_time: 0.7311319089970204
delay_time: 4.820872918276534
pressure: 0.9320291777188329
total_envstep_count: 315984
total_train_sample_count: 315984
total_episode_count: 2724
total_duration: 10891.660883426666
[2025-02-20 20:27:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.157253111343387
avg_train_sample_per_sec: 31.157253111343387
avg_episode_per_sec: 0.26859700958054644
collect_time: 22.338297843933105
reward_mean: -117.18639122315592
reward_std: 2.2159808202752047
reward_max: -114.85574229691873
reward_min: -121.04481792717088
queue_len: 0.07770980850341906
wait_time: 0.7534051971805521
delay_time: 4.868176046328569
pressure: 0.948496905393457
total_envstep_count: 316680
total_train_sample_count: 316680
total_episode_count: 2730
total_duration: 10913.9991812706
[2025-02-20 20:28:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.070706175368073
avg_train_sample_per_sec: 31.070706175368073
avg_episode_per_sec: 0.2678509153048972
collect_time: 22.40052080154419
reward_mean: -118.09477124183006
reward_std: 3.8256582535176937
reward_max: -114.36834733893556
reward_min: -126.06932773109246
queue_len: 0.07831218252110746
wait_time: 0.7550336115878711
delay_time: 4.964659430236845
pressure: 0.9487179487179488
total_envstep_count: 317376
total_train_sample_count: 317376
total_episode_count: 2736
total_duration: 10936.399702072144
[2025-02-20 20:28:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.425258744968488
avg_train_sample_per_sec: 31.425258744968488
avg_episode_per_sec: 0.2709074029738663
collect_time: 22.147789001464844
reward_mean: -120.69409430438844
reward_std: 2.0305062881816087
reward_max: -118.5525210084034
reward_min: -124.00770308123253
queue_len: 0.08003587155463424
wait_time: 0.776131871846882
delay_time: 5.042968487163379
pressure: 0.9713748894783377
total_envstep_count: 318072
total_train_sample_count: 318072
total_episode_count: 2742
total_duration: 10958.547491073608
[2025-02-20 20:28:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.42951804931013
avg_train_sample_per_sec: 31.42951804931013
avg_episode_per_sec: 0.2709441211147425
collect_time: 22.144787549972534
reward_mean: -120.70763305322129
reward_std: 3.3239114194661727
reward_max: -116.90826330532214
reward_min: -125.65546218487397
queue_len: 0.08004484950478866
wait_time: 0.7732032025896124
delay_time: 4.981943651695113
pressure: 0.985079575596817
total_envstep_count: 318768
total_train_sample_count: 318768
total_episode_count: 2748
total_duration: 10980.692278623581
[2025-02-20 20:29:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.926447523801908
avg_train_sample_per_sec: 30.926447523801908
avg_episode_per_sec: 0.2666073062396716
collect_time: 22.505009651184082
reward_mean: -118.03384687208217
reward_std: 3.1263218157354307
reward_max: -113.21008403361341
reward_min: -122.45658263305327
queue_len: 0.07827178174541258
wait_time: 0.7540936356859279
delay_time: 4.970026885432219
pressure: 0.9554597701149424
total_envstep_count: 319464
total_train_sample_count: 319464
total_episode_count: 2754
total_duration: 11003.197288274765
[2025-02-20 20:29:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30966975222032
avg_train_sample_per_sec: 31.30966975222032
avg_episode_per_sec: 0.26991094613983035
collect_time: 22.229554176330566
reward_mean: -117.49089635854341
reward_std: 1.1628019996779264
reward_max: -116.16036414565826
reward_min: -119.50140056022406
queue_len: 0.07791173498577149
wait_time: 0.7467523813238824
delay_time: 4.957915727380487
pressure: 0.9454022988505746
total_envstep_count: 320160
total_train_sample_count: 320160
total_episode_count: 2760
total_duration: 11025.426842451096
[2025-02-20 20:30:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.22349876345029
avg_train_sample_per_sec: 31.22349876345029
avg_episode_per_sec: 0.26916809278836457
collect_time: 22.290903568267822
reward_mean: -121.18732492997201
reward_std: 3.2182290140857646
reward_max: -116.42016806722688
reward_min: -125.43487394957987
queue_len: 0.08036294756629443
wait_time: 0.78094629761719
delay_time: 5.034590233127106
pressure: 0.9825375773651636
total_envstep_count: 320856
total_train_sample_count: 320856
total_episode_count: 2766
total_duration: 11047.717746019363
[2025-02-20 20:30:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.951534592986345
avg_train_sample_per_sec: 30.951534592986345
avg_episode_per_sec: 0.2668235740774685
collect_time: 22.48676872253418
reward_mean: -120.44677871148461
reward_std: 4.587658763052919
reward_max: -113.63585434173672
reward_min: -127.70658263305324
queue_len: 0.07987186917207202
wait_time: 0.7699239288995882
delay_time: 5.005420685434241
pressure: 0.9793324491600354
total_envstep_count: 321552
total_train_sample_count: 321552
total_episode_count: 2772
total_duration: 11070.204514741898
[2025-02-20 20:30:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.291911017403265
avg_train_sample_per_sec: 31.291911017403265
avg_episode_per_sec: 0.269757853598304
collect_time: 22.242169857025146
reward_mean: -117.46358543417364
reward_std: 3.565298284997457
reward_max: -112.05252100840336
reward_min: -122.23809523809517
queue_len: 0.0778936242932186
wait_time: 0.7450052412653831
delay_time: 4.8828059341277275
pressure: 0.9534703801945182
total_envstep_count: 322248
total_train_sample_count: 322248
total_episode_count: 2778
total_duration: 11092.446684598923
[2025-02-20 20:31:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.962471676238486
avg_train_sample_per_sec: 30.962471676238486
avg_episode_per_sec: 0.26691785927791795
collect_time: 22.478825569152832
reward_mean: -120.24299719887956
reward_std: 2.1688417093466286
reward_max: -117.56792717086834
reward_min: -123.12675070028013
queue_len: 0.07973673554302357
wait_time: 0.7706616687346909
delay_time: 5.008439938419893
pressure: 0.9706012378426171
total_envstep_count: 322944
total_train_sample_count: 322944
total_episode_count: 2784
total_duration: 11114.925510168076
[2025-02-20 20:31:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29208979978527
avg_train_sample_per_sec: 31.29208979978527
avg_episode_per_sec: 0.2697593948257351
collect_time: 22.242042779922485
reward_mean: -118.99929971988796
reward_std: 3.3175730212905283
reward_max: -113.6295518207283
reward_min: -124.02591036414566
queue_len: 0.0789120024667692
wait_time: 0.7624667351467557
delay_time: 5.030587156667583
pressure: 0.9605437665782494
total_envstep_count: 323640
total_train_sample_count: 323640
total_episode_count: 2790
total_duration: 11137.167552947998
[2025-02-20 20:31:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.38057613313114
avg_train_sample_per_sec: 31.38057613313114
avg_episode_per_sec: 0.27052220804423394
collect_time: 22.179325103759766
reward_mean: -118.32154528478058
reward_std: 2.8810009330896627
reward_max: -113.67156862745095
reward_min: -122.76470588235298
queue_len: 0.07846256318619402
wait_time: 0.7584426011784026
delay_time: 5.045720458068616
pressure: 0.9547966401414677
total_envstep_count: 324336
total_train_sample_count: 324336
total_episode_count: 2796
total_duration: 11159.346878051758
[2025-02-20 20:32:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.097870384309683
avg_train_sample_per_sec: 31.097870384309683
avg_episode_per_sec: 0.26808508951991106
collect_time: 22.380953788757324
reward_mean: -116.749883286648
reward_std: 3.656351388120344
reward_max: -112.94117647058819
reward_min: -123.72058823529416
queue_len: 0.07742034700706102
wait_time: 0.746895022376767
delay_time: 4.902716091471596
pressure: 0.9567860300618921
total_envstep_count: 325032
total_train_sample_count: 325032
total_episode_count: 2802
total_duration: 11181.727831840515
[2025-02-20 20:32:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.353139937554612
avg_train_sample_per_sec: 31.353139937554612
avg_episode_per_sec: 0.2702856891168501
collect_time: 22.19873356819153
reward_mean: -115.70553221288515
reward_std: 1.3496665060127633
reward_max: -114.09663865546213
reward_min: -117.46288515406161
queue_len: 0.07672780650721826
wait_time: 0.7408317327815298
delay_time: 4.923515362071587
pressure: 0.9299292661361628
total_envstep_count: 325728
total_train_sample_count: 325728
total_episode_count: 2808
total_duration: 11203.926565408707
[2025-02-20 20:33:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.214912351236965
avg_train_sample_per_sec: 31.214912351236965
avg_episode_per_sec: 0.2690940719934221
collect_time: 22.297035217285156
reward_mean: -119.00676937441642
reward_std: 2.116791978895996
reward_max: -115.98459383753499
reward_min: -122.67366946778711
queue_len: 0.07891695581857854
wait_time: 0.7653273732127687
delay_time: 4.98445379692123
pressure: 0.9643015030946066
total_envstep_count: 326424
total_train_sample_count: 326424
total_episode_count: 2814
total_duration: 11226.223600625992
[2025-02-20 20:33:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.6858599657885
avg_train_sample_per_sec: 30.6858599657885
avg_episode_per_sec: 0.26453327556714223
collect_time: 22.681456565856934
reward_mean: -119.69747899159661
reward_std: 2.518005655446725
reward_max: -116.03991596638653
reward_min: -124.30392156862746
queue_len: 0.07937498606869803
wait_time: 0.765528912714511
delay_time: 5.0278714269761595
pressure: 0.9623121131741822
total_envstep_count: 327120
total_train_sample_count: 327120
total_episode_count: 2820
total_duration: 11248.905057191849
[2025-02-20 20:33:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.55388268318683
avg_train_sample_per_sec: 30.55388268318683
avg_episode_per_sec: 0.2633955403723003
collect_time: 22.779428958892822
reward_mean: -117.24381419234358
reward_std: 2.130655664316948
reward_max: -113.76890756302515
reward_min: -120.30672268907563
queue_len: 0.07774788739545331
wait_time: 0.7476266479182301
delay_time: 4.972710978683932
pressure: 0.9518125552608313
total_envstep_count: 327816
total_train_sample_count: 327816
total_episode_count: 2826
total_duration: 11271.684486150742
[2025-02-20 20:34:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.209086377534554
avg_train_sample_per_sec: 31.209086377534554
avg_episode_per_sec: 0.26904384808219445
collect_time: 22.30119752883911
reward_mean: -118.82294584500467
reward_std: 3.8880585329090076
reward_max: -113.36764705882354
reward_min: -123.99159663865547
queue_len: 0.07879505692639567
wait_time: 0.76026628600158
delay_time: 5.018688264189813
pressure: 0.9671750663129973
total_envstep_count: 328512
total_train_sample_count: 328512
total_episode_count: 2832
total_duration: 11293.98568367958
[2025-02-20 20:34:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30121074656799
avg_train_sample_per_sec: 31.30121074656799
avg_episode_per_sec: 0.26983802367731025
collect_time: 22.23556160926819
reward_mean: -119.0604575163399
reward_std: 2.56905403870877
reward_max: -115.44397759103643
reward_min: -122.5973389355743
queue_len: 0.07895255803470815
wait_time: 0.765851499751094
delay_time: 4.964168620865739
pressure: 0.9703801945181256
total_envstep_count: 329208
total_train_sample_count: 329208
total_episode_count: 2838
total_duration: 11316.221245288849
[2025-02-20 20:35:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.18369016317827
avg_train_sample_per_sec: 31.18369016317827
avg_episode_per_sec: 0.26882491519981266
collect_time: 22.31935977935791
reward_mean: -120.43767507002802
reward_std: 4.593575491831632
reward_max: -112.58823529411768
reward_min: -125.71988795518206
queue_len: 0.0798658322745544
wait_time: 0.7712956977662859
delay_time: 5.075592912189252
pressure: 0.9710433244916005
total_envstep_count: 329904
total_train_sample_count: 329904
total_episode_count: 2844
total_duration: 11338.540605068207
[2025-02-20 20:35:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.225029709517706
avg_train_sample_per_sec: 31.225029709517706
avg_episode_per_sec: 0.2691812905992906
collect_time: 22.28981065750122
reward_mean: -118.58508403361344
reward_std: 2.127629337272276
reward_max: -116.66386554621849
reward_min: -122.40266106442573
queue_len: 0.07863732362971713
wait_time: 0.7579286135320619
delay_time: 4.977671949037528
pressure: 0.9633068081343944
total_envstep_count: 330600
total_train_sample_count: 330600
total_episode_count: 2850
total_duration: 11360.830415725708
[2025-02-20 20:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.147009800273516
avg_train_sample_per_sec: 31.147009800273516
avg_episode_per_sec: 0.26850870517477166
collect_time: 22.345644235610962
reward_mean: -120.21020074696544
reward_std: 4.21016349999261
reward_max: -112.43557422969188
reward_min: -125.47478991596641
queue_len: 0.07971498723273569
wait_time: 0.7624965326537333
delay_time: 5.029436789284934
pressure: 0.9748010610079575
total_envstep_count: 331296
total_train_sample_count: 331296
total_episode_count: 2856
total_duration: 11383.176059961319
[2025-02-20 20:36:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.10180679243802
avg_train_sample_per_sec: 31.10180679243802
avg_episode_per_sec: 0.2681190240727415
collect_time: 22.37812113761902
reward_mean: -120.7516339869281
reward_std: 3.5351281430057315
reward_max: -116.26820728291318
reward_min: -126.60434173669466
queue_len: 0.08007402784279051
wait_time: 0.7754451360561908
delay_time: 5.039261484715298
pressure: 0.9809902740937225
total_envstep_count: 331992
total_train_sample_count: 331992
total_episode_count: 2862
total_duration: 11405.554181098938
[2025-02-20 20:36:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.230354122030736
avg_train_sample_per_sec: 31.230354122030736
avg_episode_per_sec: 0.2692271907071615
collect_time: 22.28601050376892
reward_mean: -118.03991596638654
reward_std: 1.6959328466617505
reward_max: -115.80182072829133
reward_min: -120.34103641456585
queue_len: 0.07827580634375765
wait_time: 0.7555598278214911
delay_time: 4.99953767961169
pressure: 0.9539124668435014
total_envstep_count: 332688
total_train_sample_count: 332688
total_episode_count: 2868
total_duration: 11427.840191602707
[2025-02-20 20:36:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.779564731101782
avg_train_sample_per_sec: 30.779564731101782
avg_episode_per_sec: 0.26534107526811884
collect_time: 22.61240553855896
reward_mean: -116.67950513538749
reward_std: 4.4883336603804525
reward_max: -111.8648459383753
reward_min: -122.86974789915963
queue_len: 0.07737367714548242
wait_time: 0.7412926266881642
delay_time: 5.032434711150873
pressure: 0.9391025641025642
total_envstep_count: 333384
total_train_sample_count: 333384
total_episode_count: 2874
total_duration: 11450.452597141266
[2025-02-20 20:37:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.10534381630596
avg_train_sample_per_sec: 31.10534381630596
avg_episode_per_sec: 0.26814951565781003
collect_time: 22.375576496124268
reward_mean: -114.50396825396824
reward_std: 2.8015021526420973
reward_max: -108.40476190476188
reward_min: -116.86134453781517
queue_len: 0.07593101343101342
wait_time: 0.7261606786834981
delay_time: 4.873355159693777
pressure: 0.9266136162687887
total_envstep_count: 334080
total_train_sample_count: 334080
total_episode_count: 2880
total_duration: 11472.82817363739
[2025-02-20 20:37:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.117108971848975
avg_train_sample_per_sec: 31.117108971848975
avg_episode_per_sec: 0.2682509394124912
collect_time: 22.367116451263428
reward_mean: -118.52976190476191
reward_std: 2.588903238715132
reward_max: -115.25700280112045
reward_min: -122.25700280112045
queue_len: 0.07860063786787926
wait_time: 0.7599930002947245
delay_time: 5.0082487631627
pressure: 0.9647435897435898
total_envstep_count: 334776
total_train_sample_count: 334776
total_episode_count: 2886
total_duration: 11495.195290088654
[2025-02-20 20:38:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.284335272723432
avg_train_sample_per_sec: 31.284335272723432
avg_episode_per_sec: 0.2696925454545123
collect_time: 22.24755597114563
reward_mean: -117.22934173669465
reward_std: 3.9580831737682747
reward_max: -111.98529411764706
reward_min: -123.45518207282917
queue_len: 0.07773829027632272
wait_time: 0.751483451470774
delay_time: 4.95625489121343
pressure: 0.9524756852343058
total_envstep_count: 335472
total_train_sample_count: 335472
total_episode_count: 2892
total_duration: 11517.4428460598
[2025-02-20 20:38:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.044740560025957
avg_train_sample_per_sec: 31.044740560025957
avg_episode_per_sec: 0.26762707379332723
collect_time: 22.419256448745728
reward_mean: -119.48809523809524
reward_std: 2.262790020241729
reward_max: -116.406862745098
reward_min: -122.33823529411764
queue_len: 0.0792361374257926
wait_time: 0.7587712251125031
delay_time: 5.00273532768997
pressure: 0.9664014146772767
total_envstep_count: 336168
total_train_sample_count: 336168
total_episode_count: 2898
total_duration: 11539.862102508545
[2025-02-20 20:38:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.26334484753972
avg_train_sample_per_sec: 31.26334484753972
avg_episode_per_sec: 0.2695115935132734
collect_time: 22.262493133544922
reward_mean: -120.22922502334268
reward_std: 4.896572446454104
reward_max: -112.75140056022408
reward_min: -128.53501400560228
queue_len: 0.07972760280062512
wait_time: 0.770576378208224
delay_time: 5.070059683264078
pressure: 0.9798850574712642
total_envstep_count: 336864
total_train_sample_count: 336864
total_episode_count: 2904
total_duration: 11562.12459564209
[2025-02-20 20:39:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.991194805237544
avg_train_sample_per_sec: 30.991194805237544
avg_episode_per_sec: 0.26716547245894434
collect_time: 22.4579918384552
reward_mean: -117.10562558356675
reward_std: 1.7790046874082561
reward_max: -114.9418767507003
reward_min: -120.74019607843135
queue_len: 0.07765625038698061
wait_time: 0.753134388149601
delay_time: 4.942335373497198
pressure: 0.9524756852343059
total_envstep_count: 337560
total_train_sample_count: 337560
total_episode_count: 2910
total_duration: 11584.582587480545
[2025-02-20 20:39:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.65107932545852
avg_train_sample_per_sec: 30.65107932545852
avg_episode_per_sec: 0.26423344246084934
collect_time: 22.707193851470947
reward_mean: -121.21055088702151
reward_std: 5.156072233135229
reward_max: -111.72338935574227
reward_min: -128.05532212885154
queue_len: 0.0803783493945766
wait_time: 0.7783287607704444
delay_time: 5.0152773148250205
pressure: 0.9819849690539346
total_envstep_count: 338256
total_train_sample_count: 338256
total_episode_count: 2916
total_duration: 11607.289781332016
[2025-02-20 20:39:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4426313930426
avg_train_sample_per_sec: 31.4426313930426
avg_episode_per_sec: 0.2710571671814017
collect_time: 22.135551929473877
reward_mean: -119.50443510737627
reward_std: 3.073985904618511
reward_max: -115.43977591036418
reward_min: -125.65826330532211
queue_len: 0.07924697288287552
wait_time: 0.767931210945917
delay_time: 5.028815390993061
pressure: 0.9689434129089302
total_envstep_count: 338952
total_train_sample_count: 338952
total_episode_count: 2922
total_duration: 11629.42533326149
[2025-02-20 20:40:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.972357020263008
avg_train_sample_per_sec: 30.972357020263008
avg_episode_per_sec: 0.267003077760888
collect_time: 22.471651077270508
reward_mean: -116.06652661064426
reward_std: 3.1082538159383755
reward_max: -111.30742296918768
reward_min: -120.17577030812326
queue_len: 0.07696719271262882
wait_time: 0.7394235877374823
delay_time: 4.912753160321977
pressure: 0.9421971706454465
total_envstep_count: 339648
total_train_sample_count: 339648
total_episode_count: 2928
total_duration: 11651.89698433876
[2025-02-20 20:40:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.776021263702724
avg_train_sample_per_sec: 30.776021263702724
avg_episode_per_sec: 0.2653105281353683
collect_time: 22.61500906944275
reward_mean: -122.0126050420168
reward_std: 4.079377474630136
reward_max: -118.08963585434172
reward_min: -128.94747899159663
queue_len: 0.08091021554510398
wait_time: 0.7821337863173564
delay_time: 5.10801889347812
pressure: 0.9896109637488947
total_envstep_count: 340344
total_train_sample_count: 340344
total_episode_count: 2934
total_duration: 11674.511993408203
[2025-02-20 20:41:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.04011985474311
avg_train_sample_per_sec: 31.04011985474311
avg_episode_per_sec: 0.2675872401270958
collect_time: 22.42259383201599
reward_mean: -120.37068160597573
reward_std: 3.5748902747490825
reward_max: -116.14985994397759
reward_min: -127.63445378151259
queue_len: 0.07982140690051441
wait_time: 0.77411423234192
delay_time: 5.004163836356005
pressure: 0.970711759504863
total_envstep_count: 341040
total_train_sample_count: 341040
total_episode_count: 2940
total_duration: 11696.93458724022
[2025-02-20 20:41:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.983973100567198
avg_train_sample_per_sec: 30.983973100567198
avg_episode_per_sec: 0.2671032163842
collect_time: 22.463226318359375
reward_mean: -118.44257703081233
reward_std: 4.068042054242986
reward_max: -110.95378151260505
reward_min: -124.00420168067227
queue_len: 0.07854282296472966
wait_time: 0.7550572948012099
delay_time: 5.016212462040165
pressure: 0.963527851458886
total_envstep_count: 341736
total_train_sample_count: 341736
total_episode_count: 2946
total_duration: 11719.397813558578
[2025-02-20 20:41:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.736944146719317
avg_train_sample_per_sec: 30.736944146719317
avg_episode_per_sec: 0.26497365643723547
collect_time: 22.643760442733765
reward_mean: -119.64694211017739
reward_std: 3.156371346143123
reward_max: -113.02170868347332
reward_min: -123.14845938375348
queue_len: 0.079341473547863
wait_time: 0.7626245458395561
delay_time: 5.042818176898417
pressure: 0.973364279398762
total_envstep_count: 342432
total_train_sample_count: 342432
total_episode_count: 2952
total_duration: 11742.041574001312
[2025-02-20 20:42:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.471911725856685
avg_train_sample_per_sec: 31.471911725856685
avg_episode_per_sec: 0.2713095838435921
collect_time: 22.114957809448242
reward_mean: -118.04283380018676
reward_std: 2.8379893709552984
reward_max: -114.27170868347338
reward_min: -122.06022408963587
queue_len: 0.07827774124680818
wait_time: 0.7570771787937104
delay_time: 4.951091800923623
pressure: 0.955128205128205
total_envstep_count: 343128
total_train_sample_count: 343128
total_episode_count: 2958
total_duration: 11764.15653181076
[2025-02-20 20:42:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.052034553072776
avg_train_sample_per_sec: 31.052034553072776
avg_episode_per_sec: 0.26768995304373083
collect_time: 22.413990259170532
reward_mean: -119.08228291316527
reward_std: 2.918687104452986
reward_max: -114.36904761904763
reward_min: -122.27380952380956
queue_len: 0.07896703110952603
wait_time: 0.7639460846230625
delay_time: 4.993643422328814
pressure: 0.9708222811671087
total_envstep_count: 343824
total_train_sample_count: 343824
total_episode_count: 2964
total_duration: 11786.570522069931
[2025-02-20 20:43:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.475381396872518
avg_train_sample_per_sec: 31.475381396872518
avg_episode_per_sec: 0.27133949480062514
collect_time: 22.11251997947693
reward_mean: -114.94351073762836
reward_std: 2.567084470622537
reward_max: -109.96428571428568
reward_min: -117.81862745098037
queue_len: 0.076222487226544
wait_time: 0.7295798071660139
delay_time: 4.855473107528662
pressure: 0.9268346595932803
total_envstep_count: 344520
total_train_sample_count: 344520
total_episode_count: 2970
total_duration: 11808.683042049408
[2025-02-20 20:43:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.951704256381063
avg_train_sample_per_sec: 30.951704256381063
avg_episode_per_sec: 0.2668250366929402
collect_time: 22.486645460128784
reward_mean: -119.05228758169936
reward_std: 3.9505107940117514
reward_max: -111.85644257703083
reward_min: -123.21148459383751
queue_len: 0.07894714030616667
wait_time: 0.7574351358580568
delay_time: 4.997795972825245
pressure: 0.9596595932802829
total_envstep_count: 345216
total_train_sample_count: 345216
total_episode_count: 2976
total_duration: 11831.169687509537
[2025-02-20 20:43:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.129596051494755
avg_train_sample_per_sec: 31.129596051494755
avg_episode_per_sec: 0.26835858665081685
collect_time: 22.358144283294678
reward_mean: -120.4176003734827
reward_std: 4.871240065192524
reward_max: -112.68557422969188
reward_min: -124.88585434173667
queue_len: 0.07985252014156678
wait_time: 0.7678562914998008
delay_time: 4.989974898660464
pressure: 0.9742484526967287
total_envstep_count: 345912
total_train_sample_count: 345912
total_episode_count: 2982
total_duration: 11853.527831792831
[2025-02-20 20:44:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.46929801639764
avg_train_sample_per_sec: 31.46929801639764
avg_episode_per_sec: 0.2712870518654969
collect_time: 22.11679458618164
reward_mean: -117.18323996265171
reward_std: 4.7192870625117695
reward_max: -112.17507002801122
reward_min: -124.30742296918768
queue_len: 0.07770771880812449
wait_time: 0.7462772465307962
delay_time: 4.960494237794608
pressure: 0.9450707338638374
total_envstep_count: 346608
total_train_sample_count: 346608
total_episode_count: 2988
total_duration: 11875.644626379013
[2025-02-20 20:44:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.022142304883072
avg_train_sample_per_sec: 31.022142304883072
avg_episode_per_sec: 0.267432261248992
collect_time: 22.435587882995605
reward_mean: -119.23225957049488
reward_std: 3.6259138613218362
reward_max: -112.92507002801119
reward_min: -124.2542016806723
queue_len: 0.07906648512632286
wait_time: 0.7607925796313221
delay_time: 5.106556553795524
pressure: 0.9648541114058357
total_envstep_count: 347304
total_train_sample_count: 347304
total_episode_count: 2994
total_duration: 11898.080214262009
[2025-02-20 20:44:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.325026615271156
avg_train_sample_per_sec: 31.325026615271156
avg_episode_per_sec: 0.2700433328902686
collect_time: 22.218656301498413
reward_mean: -117.34652194211019
reward_std: 2.8045951376227194
reward_max: -112.86484593837535
reward_min: -122.38095238095237
queue_len: 0.07781599598283166
wait_time: 0.7484946454266942
delay_time: 4.945772933899213
pressure: 0.9450707338638374
total_envstep_count: 348000
total_train_sample_count: 348000
total_episode_count: 3000
total_duration: 11920.298870563507
[2025-02-20 20:45:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.192771349280132
avg_train_sample_per_sec: 31.192771349280132
avg_episode_per_sec: 0.2689032012868977
collect_time: 22.312861919403076
reward_mean: -117.04236694677871
reward_std: 1.6262642172329944
reward_max: -114.66946778711487
reward_min: -119.81302521008406
queue_len: 0.0776143016888453
wait_time: 0.7495936703593905
delay_time: 4.9613199583031875
pressure: 0.9441865605658708
total_envstep_count: 348696
total_train_sample_count: 348696
total_episode_count: 3006
total_duration: 11942.61173248291
[2025-02-20 20:45:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.087460819143118
avg_train_sample_per_sec: 31.087460819143118
avg_episode_per_sec: 0.2679953518891648
collect_time: 22.388447999954224
reward_mean: -118.55112044817929
reward_std: 2.747977592058627
reward_max: -114.6743697478991
reward_min: -121.88375350140058
queue_len: 0.07861480135820907
wait_time: 0.7579904530335565
delay_time: 5.006884236840286
pressure: 0.9550176834659595
total_envstep_count: 349392
total_train_sample_count: 349392
total_episode_count: 3012
total_duration: 11965.000180482864
[2025-02-20 20:46:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.15721520136791
avg_train_sample_per_sec: 31.15721520136791
avg_episode_per_sec: 0.26859668277041304
collect_time: 22.338325023651123
reward_mean: -118.76528944911297
reward_std: 1.7665139860077477
reward_max: -115.86134453781513
reward_min: -121.72268907563027
queue_len: 0.07875682324211737
wait_time: 0.7628571985823508
delay_time: 4.985506997555627
pressure: 0.9524756852343059
total_envstep_count: 350088
total_train_sample_count: 350088
total_episode_count: 3018
total_duration: 11987.338505506516
[2025-02-20 20:46:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.00690009830699
avg_train_sample_per_sec: 31.00690009830699
avg_episode_per_sec: 0.26730086291643956
collect_time: 22.446616649627686
reward_mean: -118.1609477124183
reward_std: 4.5972422467751235
reward_max: -110.89355742296924
reward_min: -123.65266106442579
queue_len: 0.0783560661222933
wait_time: 0.754268473525573
delay_time: 5.037714272855019
pressure: 0.946286472148541
total_envstep_count: 350784
total_train_sample_count: 350784
total_episode_count: 3024
total_duration: 12009.785122156143
[2025-02-20 20:46:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.430178583404466
avg_train_sample_per_sec: 31.430178583404466
avg_episode_per_sec: 0.27094981537417645
collect_time: 22.144322156906128
reward_mean: -117.84313725490198
reward_std: 2.0031668569052252
reward_max: -113.90896358543418
reward_min: -120.609243697479
queue_len: 0.07814531648203048
wait_time: 0.7516674994489397
delay_time: 4.968548001283837
pressure: 0.9482758620689656
total_envstep_count: 351480
total_train_sample_count: 351480
total_episode_count: 3030
total_duration: 12031.92944431305
[2025-02-20 20:47:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.004448667817996
avg_train_sample_per_sec: 31.004448667817996
avg_episode_per_sec: 0.2672797298949827
collect_time: 22.448391437530518
reward_mean: -118.56874416433239
reward_std: 4.108487803917161
reward_max: -112.296918767507
reward_min: -124.05532212885159
queue_len: 0.07862648817263422
wait_time: 0.7531619411690404
delay_time: 5.014650806811132
pressure: 0.94683908045977
total_envstep_count: 352176
total_train_sample_count: 352176
total_episode_count: 3036
total_duration: 12054.37783575058
[2025-02-20 20:47:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.423230458726742
avg_train_sample_per_sec: 30.423230458726742
avg_episode_per_sec: 0.2622692280924719
collect_time: 22.877254962921143
reward_mean: -119.38246965452849
reward_std: 4.710483323791671
reward_max: -113.11064425770309
reward_min: -127.98529411764709
queue_len: 0.07916609393536371
wait_time: 0.7652796972016039
delay_time: 5.002651988570892
pressure: 0.9649646330680813
total_envstep_count: 352872
total_train_sample_count: 352872
total_episode_count: 3042
total_duration: 12077.255090713501
[2025-02-20 20:47:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.041856996697387
avg_train_sample_per_sec: 31.041856996697387
avg_episode_per_sec: 0.26760221548877056
collect_time: 22.42133903503418
reward_mean: -116.03933239962653
reward_std: 4.3980121379095145
reward_max: -109.28571428571428
reward_min: -121.88025210084035
queue_len: 0.07694915941619797
wait_time: 0.7434038381046494
delay_time: 4.82913534837752
pressure: 0.9324712643678161
total_envstep_count: 353568
total_train_sample_count: 353568
total_episode_count: 3048
total_duration: 12099.676429748535
[2025-02-20 20:48:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.415058567514468
avg_train_sample_per_sec: 31.415058567514468
avg_episode_per_sec: 0.27081947040960747
collect_time: 22.154980182647705
reward_mean: -115.55123716153128
reward_std: 4.528230139009064
reward_max: -109.92927170868347
reward_min: -121.95588235294119
queue_len: 0.07662548883390669
wait_time: 0.7411579574358479
delay_time: 4.866568609899432
pressure: 0.9345711759504862
total_envstep_count: 354264
total_train_sample_count: 354264
total_episode_count: 3054
total_duration: 12121.831409931183
[2025-02-20 20:48:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.884496722831113
avg_train_sample_per_sec: 30.884496722831113
avg_episode_per_sec: 0.26624566140371647
collect_time: 22.53557848930359
reward_mean: -119.60737628384686
reward_std: 4.291359030528278
reward_max: -114.84033613445376
reward_min: -126.98179271708679
queue_len: 0.07931523626249792
wait_time: 0.7736131698479568
delay_time: 5.058529689909988
pressure: 0.9675066312997348
total_envstep_count: 354960
total_train_sample_count: 354960
total_episode_count: 3060
total_duration: 12144.366988420486
[2025-02-20 20:49:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.13935822577797
avg_train_sample_per_sec: 31.13935822577797
avg_episode_per_sec: 0.26844274332567214
collect_time: 22.35113501548767
reward_mean: -120.47408963585433
reward_std: 4.1215509570084565
reward_max: -112.5721288515406
reward_min: -125.58683473389364
queue_len: 0.07988997986462489
wait_time: 0.7716008706754143
delay_time: 5.168242765952194
pressure: 0.9766799292661362
total_envstep_count: 355656
total_train_sample_count: 355656
total_episode_count: 3066
total_duration: 12166.718123435974
[2025-02-20 20:49:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.21127561800315
avg_train_sample_per_sec: 31.21127561800315
avg_episode_per_sec: 0.2690627208448547
collect_time: 22.299633264541626
reward_mean: -116.7715919701214
reward_std: 2.7573321525357666
reward_max: -112.01610644257704
reward_min: -120.28571428571429
queue_len: 0.07743474268575691
wait_time: 0.7495391834894877
delay_time: 4.93712099964091
pressure: 0.9500442086648984
total_envstep_count: 356352
total_train_sample_count: 356352
total_episode_count: 3072
total_duration: 12189.017756700516
[2025-02-20 20:49:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.194656956404383
avg_train_sample_per_sec: 31.194656956404383
avg_episode_per_sec: 0.26891945652072746
collect_time: 22.3115131855011
reward_mean: -117.63503734827266
reward_std: 2.872937129777481
reward_max: -113.73879551820731
reward_min: -122.50700280112049
queue_len: 0.07800731919646728
wait_time: 0.7538989070429233
delay_time: 4.978761124261186
pressure: 0.9571175950486296
total_envstep_count: 357048
total_train_sample_count: 357048
total_episode_count: 3078
total_duration: 12211.329269886017
[2025-02-20 20:50:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.25682439396233
avg_train_sample_per_sec: 31.25682439396233
avg_episode_per_sec: 0.2694553827065718
collect_time: 22.26713728904724
reward_mean: -118.80870681605977
reward_std: 2.7803384188360614
reward_max: -116.22478991596635
reward_min: -123.93767507002805
queue_len: 0.07878561459950911
wait_time: 0.7563602585154311
delay_time: 4.961723070791943
pressure: 0.9610963748894782
total_envstep_count: 357744
total_train_sample_count: 357744
total_episode_count: 3084
total_duration: 12233.596407175064
[2025-02-20 20:50:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.17464089637149
avg_train_sample_per_sec: 31.17464089637149
avg_episode_per_sec: 0.26874690427906456
collect_time: 22.325838565826416
reward_mean: -115.46335200746962
reward_std: 4.215293340633429
reward_max: -109.99159663865544
reward_min: -120.2801120448179
queue_len: 0.07656720955402496
wait_time: 0.7428549448072773
delay_time: 4.822439977196718
pressure: 0.9333554376657826
total_envstep_count: 358440
total_train_sample_count: 358440
total_episode_count: 3090
total_duration: 12255.92224574089
[2025-02-20 20:51:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.3796920207625
avg_train_sample_per_sec: 31.3796920207625
avg_episode_per_sec: 0.2705145863858836
collect_time: 22.17994999885559
reward_mean: -116.67623716153128
reward_std: 5.2868460067728185
reward_max: -107.75560224089638
reward_min: -123.51120448179272
queue_len: 0.07737151005406584
wait_time: 0.7519207395601919
delay_time: 4.893668131452236
pressure: 0.947502210433245
total_envstep_count: 359136
total_train_sample_count: 359136
total_episode_count: 3096
total_duration: 12278.102195739746
[2025-02-20 20:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.302559677926407
avg_train_sample_per_sec: 31.302559677926407
avg_episode_per_sec: 0.2698496523959173
collect_time: 22.23460340499878
reward_mean: -117.05555555555554
reward_std: 1.7239695841068978
reward_max: -114.5861344537815
reward_min: -120.09943977591033
queue_len: 0.07762304745063364
wait_time: 0.7467226612130262
delay_time: 4.85279532615817
pressure: 0.9497126436781609
total_envstep_count: 359832
total_train_sample_count: 359832
total_episode_count: 3102
total_duration: 12300.336799144745
[2025-02-20 20:51:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.20803040654817
avg_train_sample_per_sec: 31.20803040654817
avg_episode_per_sec: 0.26903474488403595
collect_time: 22.301952123641968
reward_mean: -116.19467787114844
reward_std: 5.334450329875308
reward_max: -111.47268907563023
reward_min: -126.73949579831937
queue_len: 0.07705217365460772
wait_time: 0.7394772232500428
delay_time: 4.865544776627123
pressure: 0.9398762157382848
total_envstep_count: 360528
total_train_sample_count: 360528
total_episode_count: 3108
total_duration: 12322.638751268387
[2025-02-20 20:52:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62832756324551
avg_train_sample_per_sec: 31.62832756324551
avg_episode_per_sec: 0.2726579962348751
collect_time: 22.005589723587036
reward_mean: -115.40499533146591
reward_std: 2.9922911190579233
reward_max: -110.96708683473388
reward_min: -120.13445378151263
queue_len: 0.07652851149301454
wait_time: 0.7393879855213527
delay_time: 4.830193018788109
pressure: 0.9340185676392573
total_envstep_count: 361224
total_train_sample_count: 361224
total_episode_count: 3114
total_duration: 12344.644340991974
[2025-02-20 20:52:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.257226006615866
avg_train_sample_per_sec: 31.257226006615866
avg_episode_per_sec: 0.2694588448846196
collect_time: 22.26685118675232
reward_mean: -116.6330532212885
reward_std: 2.382781846436007
reward_max: -112.32212885154055
reward_min: -119.75140056022406
queue_len: 0.0773428734889181
wait_time: 0.7444496919015174
delay_time: 4.8964000235544125
pressure: 0.9439655172413794
total_envstep_count: 361920
total_train_sample_count: 361920
total_episode_count: 3120
total_duration: 12366.911192178726
[2025-02-20 20:52:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.157425037565467
avg_train_sample_per_sec: 31.157425037565467
avg_episode_per_sec: 0.2685984917031506
collect_time: 22.33817458152771
reward_mean: -116.43253968253966
reward_std: 4.724378532647909
reward_max: -110.82563025210082
reward_min: -125.27591036414564
queue_len: 0.07720990695128625
wait_time: 0.742356049404731
delay_time: 4.886880923593428
pressure: 0.9428603006189213
total_envstep_count: 362616
total_train_sample_count: 362616
total_episode_count: 3126
total_duration: 12389.249366760254
[2025-02-20 20:53:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31424677882963
avg_train_sample_per_sec: 31.31424677882963
avg_episode_per_sec: 0.2699504032657727
collect_time: 22.22630500793457
reward_mean: -116.37698412698411
reward_std: 3.294121583816355
reward_max: -112.35434173669465
reward_min: -121.0077030812325
queue_len: 0.07717306639720432
wait_time: 0.7431790797663007
delay_time: 4.96586684015753
pressure: 0.9456233421750664
total_envstep_count: 363312
total_train_sample_count: 363312
total_episode_count: 3132
total_duration: 12411.475671768188
[2025-02-20 20:53:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.299192097843736
avg_train_sample_per_sec: 31.299192097843736
avg_episode_per_sec: 0.26982062153313563
collect_time: 22.236995697021484
reward_mean: -116.21673669467788
reward_std: 3.0434295256822907
reward_max: -112.14705882352942
reward_min: -119.76960784313728
queue_len: 0.07706680152166968
wait_time: 0.7417815379909699
delay_time: 4.830274077600808
pressure: 0.9413129973474801
total_envstep_count: 364008
total_train_sample_count: 364008
total_episode_count: 3138
total_duration: 12433.71266746521
[2025-02-20 20:54:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.035349078357473
avg_train_sample_per_sec: 31.035349078357473
avg_episode_per_sec: 0.267546112744461
collect_time: 22.426040649414062
reward_mean: -117.74054621848741
reward_std: 2.836181160351309
reward_max: -114.71358543417368
reward_min: -121.12324929971987
queue_len: 0.07807728529077414
wait_time: 0.7500664058726937
delay_time: 5.003055759044259
pressure: 0.9587754199823166
total_envstep_count: 364704
total_train_sample_count: 364704
total_episode_count: 3144
total_duration: 12456.138708114624
[2025-02-20 20:54:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44150232887445
avg_train_sample_per_sec: 31.44150232887445
avg_episode_per_sec: 0.27104743386960733
collect_time: 22.1363468170166
reward_mean: -117.09850606909431
reward_std: 3.7105434272275235
reward_max: -112.579131652661
reward_min: -124.52100840336135
queue_len: 0.07765152922353734
wait_time: 0.74486724397982
delay_time: 4.89336408903584
pressure: 0.9408709106984969
total_envstep_count: 365400
total_train_sample_count: 365400
total_episode_count: 3150
total_duration: 12478.27505493164
[2025-02-20 20:54:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.261848307049977
avg_train_sample_per_sec: 31.261848307049977
avg_episode_per_sec: 0.26949869230215495
collect_time: 22.263558864593506
reward_mean: -117.62219887955183
reward_std: 3.269780190144198
reward_max: -113.0756302521008
reward_min: -122.87815126050415
queue_len: 0.07799880562304497
wait_time: 0.7477379435416962
delay_time: 4.842609540965818
pressure: 0.9622015915119365
total_envstep_count: 366096
total_train_sample_count: 366096
total_episode_count: 3156
total_duration: 12500.538613796234
[2025-02-20 20:55:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.938562330343128
avg_train_sample_per_sec: 30.938562330343128
avg_episode_per_sec: 0.2667117442270959
collect_time: 22.49619722366333
reward_mean: -119.90849673202615
reward_std: 4.242998463803733
reward_max: -115.17717086834737
reward_min: -128.47058823529414
queue_len: 0.07951491825731179
wait_time: 0.7660052858455494
delay_time: 5.043598731526546
pressure: 0.960654288240495
total_envstep_count: 366792
total_train_sample_count: 366792
total_episode_count: 3162
total_duration: 12523.034811019897
[2025-02-20 20:55:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.409231322230966
avg_train_sample_per_sec: 31.409231322230966
avg_episode_per_sec: 0.2707692355364738
collect_time: 22.159090518951416
reward_mean: -117.16631652661063
reward_std: 3.0632222008916594
reward_max: -113.703781512605
reward_min: -121.4719887955182
queue_len: 0.07769649637043145
wait_time: 0.746791853346113
delay_time: 4.93309705628865
pressure: 0.9552387267904509
total_envstep_count: 367488
total_train_sample_count: 367488
total_episode_count: 3168
total_duration: 12545.193901538849
[2025-02-20 20:55:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.553641693569407
avg_train_sample_per_sec: 31.553641693569407
avg_episode_per_sec: 0.27201415253077077
collect_time: 22.05767583847046
reward_mean: -116.6769374416433
reward_std: 4.313763908170056
reward_max: -110.78081232492994
reward_min: -122.76190476190474
queue_len: 0.07737197443079795
wait_time: 0.7462046489683406
delay_time: 4.859744236378967
pressure: 0.9484969053934572
total_envstep_count: 368184
total_train_sample_count: 368184
total_episode_count: 3174
total_duration: 12567.25157737732
[2025-02-20 20:56:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32700355004283
avg_train_sample_per_sec: 31.32700355004283
avg_episode_per_sec: 0.2700603754314037
collect_time: 22.217254161834717
reward_mean: -118.14425770308124
reward_std: 5.570789017140651
reward_max: -109.25280112044818
reward_min: -127.4768907563025
queue_len: 0.07834499847684433
wait_time: 0.7530388813350274
delay_time: 5.021934304396587
pressure: 0.9492705570291776
total_envstep_count: 368880
total_train_sample_count: 368880
total_episode_count: 3180
total_duration: 12589.468831539154
[2025-02-20 20:56:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.158412070462877
avg_train_sample_per_sec: 31.158412070462877
avg_episode_per_sec: 0.2686070006074386
collect_time: 22.337466955184937
reward_mean: -117.39834267040148
reward_std: 3.786931989526656
reward_max: -111.57983193277308
reward_min: -123.03011204481794
queue_len: 0.07785035986100895
wait_time: 0.744645039713498
delay_time: 4.982281758246169
pressure: 0.9578912466843502
total_envstep_count: 369576
total_train_sample_count: 369576
total_episode_count: 3186
total_duration: 12611.806298494339
[2025-02-20 20:57:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.94523867268551
avg_train_sample_per_sec: 30.94523867268551
avg_episode_per_sec: 0.26676929890246126
collect_time: 22.49134373664856
reward_mean: -117.28232959850607
reward_std: 4.365583389428642
reward_max: -109.89565826330534
reward_min: -123.72198879551819
queue_len: 0.0777734281157202
wait_time: 0.7475683686383484
delay_time: 4.942600463680054
pressure: 0.9444076038903625
total_envstep_count: 370272
total_train_sample_count: 370272
total_episode_count: 3192
total_duration: 12634.297642230988
[2025-02-20 20:57:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.387676474500704
avg_train_sample_per_sec: 31.387676474500704
avg_episode_per_sec: 0.2705834178836268
collect_time: 22.174307823181152
reward_mean: -118.8641456582633
reward_std: 3.5687892336394795
reward_max: -114.82913165266105
reward_min: -125.27591036414572
queue_len: 0.07882237775746903
wait_time: 0.7561402987366476
delay_time: 5.012761779101158
pressure: 0.9633068081343943
total_envstep_count: 370968
total_train_sample_count: 370968
total_episode_count: 3198
total_duration: 12656.471950054169
[2025-02-20 20:57:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.352330553229464
avg_train_sample_per_sec: 30.352330553229464
avg_episode_per_sec: 0.26165802201059885
collect_time: 22.930693864822388
reward_mean: -114.87243230625586
reward_std: 2.6682894759016853
reward_max: -110.00420168067228
reward_min: -117.43137254901963
queue_len: 0.07617535298823332
wait_time: 0.7323039958689046
delay_time: 4.807887512964289
pressure: 0.9258399646330681
total_envstep_count: 371664
total_train_sample_count: 371664
total_episode_count: 3204
total_duration: 12679.402643918991
[2025-02-20 20:58:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.22652272690223
avg_train_sample_per_sec: 31.22652272690223
avg_episode_per_sec: 0.2691941614388123
collect_time: 22.288744926452637
reward_mean: -117.64133986928105
reward_std: 4.494449394493674
reward_max: -112.13515406162465
reward_min: -126.19117647058822
queue_len: 0.07801149858705639
wait_time: 0.7525632821652092
delay_time: 4.943611104151485
pressure: 0.9504862953138815
total_envstep_count: 372360
total_train_sample_count: 372360
total_episode_count: 3210
total_duration: 12701.691388845444
[2025-02-20 20:58:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.00797576767704
avg_train_sample_per_sec: 31.00797576767704
avg_episode_per_sec: 0.2673101359282503
collect_time: 22.44583797454834
reward_mean: -116.10772642390289
reward_std: 3.1234580007319415
reward_max: -113.02871148459386
reward_min: -122.50840336134453
queue_len: 0.0769945135437022
wait_time: 0.7405743906758105
delay_time: 4.891978555727818
pressure: 0.949049513704686
total_envstep_count: 373056
total_train_sample_count: 373056
total_episode_count: 3216
total_duration: 12724.137226819992
[2025-02-20 20:59:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.266895268241726
avg_train_sample_per_sec: 31.266895268241726
avg_episode_per_sec: 0.2695422005882907
collect_time: 22.259965181350708
reward_mean: -119.11169467787114
reward_std: 4.872534572996264
reward_max: -110.88235294117648
reward_min: -126.30602240896364
queue_len: 0.0789865349322753
wait_time: 0.7611059565293846
delay_time: 4.942179494168612
pressure: 0.9659593280282935
total_envstep_count: 373752
total_train_sample_count: 373752
total_episode_count: 3222
total_duration: 12746.397192001343
[2025-02-20 20:59:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.057578668035713
avg_train_sample_per_sec: 31.057578668035713
avg_episode_per_sec: 0.2677377471382389
collect_time: 22.40998911857605
reward_mean: -117.140522875817
reward_std: 4.787318725731584
reward_max: -110.42927170868347
reward_min: -125.78571428571428
queue_len: 0.07767939182746485
wait_time: 0.7511713903067859
delay_time: 4.977656231763592
pressure: 0.9465075154730327
total_envstep_count: 374448
total_train_sample_count: 374448
total_episode_count: 3228
total_duration: 12768.807181119919
[2025-02-20 20:59:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29427560472111
avg_train_sample_per_sec: 31.29427560472111
avg_episode_per_sec: 0.2697782379717337
collect_time: 22.24048924446106
reward_mean: -117.63678804855277
reward_std: 2.9845538191738905
reward_max: -113.19467787114846
reward_min: -121.10924369747902
queue_len: 0.0780084801382976
wait_time: 0.7484656992770583
delay_time: 4.92972162846644
pressure: 0.956896551724138
total_envstep_count: 375144
total_train_sample_count: 375144
total_episode_count: 3234
total_duration: 12791.04767036438
[2025-02-20 21:00:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.946580716957556
avg_train_sample_per_sec: 30.946580716957556
avg_episode_per_sec: 0.2667808682496341
collect_time: 22.490368366241455
reward_mean: -116.39437441643322
reward_std: 2.976888873311855
reward_max: -112.16876750700277
reward_min: -122.1946778711484
queue_len: 0.07718459841938545
wait_time: 0.7395140638041249
delay_time: 4.905176662356027
pressure: 0.9350132625994695
total_envstep_count: 375840
total_train_sample_count: 375840
total_episode_count: 3240
total_duration: 12813.538038730621
[2025-02-20 21:00:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.170447726225667
avg_train_sample_per_sec: 31.170447726225667
avg_episode_per_sec: 0.2687107562605661
collect_time: 22.32884192466736
reward_mean: -117.9920634920635
reward_std: 3.031317366533672
reward_max: -113.51260504201682
reward_min: -122.20868347338936
queue_len: 0.0782440739337291
wait_time: 0.7528513505313709
delay_time: 4.92038062654645
pressure: 0.9648541114058355
total_envstep_count: 376536
total_train_sample_count: 376536
total_episode_count: 3246
total_duration: 12835.866880655289
[2025-02-20 21:00:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.119937861516217
avg_train_sample_per_sec: 31.119937861516217
avg_episode_per_sec: 0.26827532639238116
collect_time: 22.36508321762085
reward_mean: -119.85224089635854
reward_std: 4.013473780091825
reward_max: -115.23249299719892
reward_min: -126.99509803921568
queue_len: 0.0794776133264977
wait_time: 0.7649246811898943
delay_time: 5.035901370908887
pressure: 0.9652961980548188
total_envstep_count: 377232
total_train_sample_count: 377232
total_episode_count: 3252
total_duration: 12858.23196387291
[2025-02-20 21:01:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.056376269449945
avg_train_sample_per_sec: 30.056376269449945
avg_episode_per_sec: 0.2591066919780168
collect_time: 23.156484127044678
reward_mean: -116.93580765639591
reward_std: 2.1230091101753654
reward_max: -114.63025210084034
reward_min: -120.56162464985994
queue_len: 0.07754363902944027
wait_time: 0.748434663432128
delay_time: 4.848508706512921
pressure: 0.9473916887709993
total_envstep_count: 377928
total_train_sample_count: 377928
total_episode_count: 3258
total_duration: 12881.388447999954
[2025-02-20 21:01:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.07831411867662
avg_train_sample_per_sec: 31.07831411867662
avg_episode_per_sec: 0.2679165010230743
collect_time: 22.395037174224854
reward_mean: -121.5950046685341
reward_std: 4.668813944692717
reward_max: -113.66456582633057
reward_min: -127.10574229691876
queue_len: 0.08063329222051333
wait_time: 0.7851320346883228
delay_time: 5.062041182400248
pressure: 0.9956896551724138
total_envstep_count: 378624
total_train_sample_count: 378624
total_episode_count: 3264
total_duration: 12903.783485174179
[2025-02-20 21:02:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.307775587887964
avg_train_sample_per_sec: 31.307775587887964
avg_episode_per_sec: 0.2698946171369652
collect_time: 22.23089909553528
reward_mean: -117.953314659197
reward_std: 3.192258892781665
reward_max: -113.234593837535
reward_min: -122.26820728291311
queue_len: 0.07821837842121816
wait_time: 0.755744804553121
delay_time: 4.943926439632974
pressure: 0.9556808134394341
total_envstep_count: 379320
total_train_sample_count: 379320
total_episode_count: 3270
total_duration: 12926.014384269714
[2025-02-20 21:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.40270054984499
avg_train_sample_per_sec: 31.40270054984499
avg_episode_per_sec: 0.27071293577452576
collect_time: 22.16369891166687
reward_mean: -115.51213818860874
reward_std: 2.9375533369171234
reward_max: -111.42366946778704
reward_min: -119.41316526610643
queue_len: 0.07659956113302968
wait_time: 0.740705577102636
delay_time: 4.785258162618632
pressure: 0.9337975243147657
total_envstep_count: 380016
total_train_sample_count: 380016
total_episode_count: 3276
total_duration: 12948.178083181381
[2025-02-20 21:02:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.99635912955614
avg_train_sample_per_sec: 30.99635912955614
avg_episode_per_sec: 0.2672099924961736
collect_time: 22.45425009727478
reward_mean: -118.21428571428572
reward_std: 1.131593219473167
reward_max: -116.40476190476194
reward_min: -119.89355742296921
queue_len: 0.07839143615005684
wait_time: 0.7539577280956591
delay_time: 4.891729763922997
pressure: 0.9520335985853228
total_envstep_count: 380712
total_train_sample_count: 380712
total_episode_count: 3282
total_duration: 12970.632333278656
[2025-02-20 21:03:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.23680002872826
avg_train_sample_per_sec: 31.23680002872826
avg_episode_per_sec: 0.26928275886834707
collect_time: 22.28141164779663
reward_mean: -114.28209617180205
reward_std: 3.014438945788602
reward_max: -110.57422969187678
reward_min: -118.68977591036415
queue_len: 0.07578388340305175
wait_time: 0.7309241004093945
delay_time: 4.727417685664272
pressure: 0.929708222811671
total_envstep_count: 381408
total_train_sample_count: 381408
total_episode_count: 3288
total_duration: 12992.913744926453
[2025-02-20 21:03:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.959182450837176
avg_train_sample_per_sec: 30.959182450837176
avg_episode_per_sec: 0.2668895038865274
collect_time: 22.481213808059692
reward_mean: -117.19946311858075
reward_std: 3.4322506550145127
reward_max: -113.85364145658257
reward_min: -123.65336134453781
queue_len: 0.07771847686908538
wait_time: 0.742433445526752
delay_time: 4.976021226879383
pressure: 0.9438549955791337
total_envstep_count: 382104
total_train_sample_count: 382104
total_episode_count: 3294
total_duration: 13015.394958734512
[2025-02-20 21:03:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.873773662377697
avg_train_sample_per_sec: 30.873773662377697
avg_episode_per_sec: 0.26615322122739393
collect_time: 22.543405532836914
reward_mean: -117.20809990662933
reward_std: 5.369083246668322
reward_max: -111.76470588235291
reward_min: -127.95308123249299
queue_len: 0.07772420418211494
wait_time: 0.7419485588222909
delay_time: 5.004869740687643
pressure: 0.9553492484526968
total_envstep_count: 382800
total_train_sample_count: 382800
total_episode_count: 3300
total_duration: 13037.93836426735
[2025-02-20 21:04:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.181300958126506
avg_train_sample_per_sec: 31.181300958126506
avg_episode_per_sec: 0.26880431860453885
collect_time: 22.321069955825806
reward_mean: -118.70133053221288
reward_std: 3.8033199004562706
reward_max: -112.46148459383754
reward_min: -123.26680672268907
queue_len: 0.07871441016724992
wait_time: 0.7571069763006881
delay_time: 4.988945885147299
pressure: 0.9612068965517242
total_envstep_count: 383496
total_train_sample_count: 383496
total_episode_count: 3306
total_duration: 13060.259434223175
[2025-02-20 21:04:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67942514134134
avg_train_sample_per_sec: 31.67942514134134
avg_episode_per_sec: 0.2730984925977702
collect_time: 21.97009563446045
reward_mean: -115.47595704948644
reward_std: 1.7665125632840941
reward_max: -113.85784313725489
reward_min: -119.14985994397756
queue_len: 0.07657556833520322
wait_time: 0.7375145349917157
delay_time: 4.825297765535756
pressure: 0.9367816091954023
total_envstep_count: 384192
total_train_sample_count: 384192
total_episode_count: 3312
total_duration: 13082.229529857635
[2025-02-20 21:05:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.182126629722124
avg_train_sample_per_sec: 31.182126629722124
avg_episode_per_sec: 0.2688114364631217
collect_time: 22.320478916168213
reward_mean: -116.57539682539681
reward_std: 3.745726219209748
reward_max: -112.34593837535012
reward_min: -123.10644257703085
queue_len: 0.0773046398046398
wait_time: 0.7458361660313991
delay_time: 4.916921467830863
pressure: 0.9462864721485412
total_envstep_count: 384888
total_train_sample_count: 384888
total_episode_count: 3318
total_duration: 13104.550008773804
[2025-02-20 21:05:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.268357460278118
avg_train_sample_per_sec: 31.268357460278118
avg_episode_per_sec: 0.26955480569205276
collect_time: 22.25892424583435
reward_mean: -114.54948646125116
reward_std: 3.21353257489171
reward_max: -109.18557422969187
reward_min: -119.13515406162465
queue_len: 0.07596119791860158
wait_time: 0.7350949000289771
delay_time: 4.742922087402894
pressure: 0.9279398762157384
total_envstep_count: 385584
total_train_sample_count: 385584
total_episode_count: 3324
total_duration: 13126.808933019638
[2025-02-20 21:05:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.091061469257127
avg_train_sample_per_sec: 31.091061469257127
avg_episode_per_sec: 0.2680263919763545
collect_time: 22.385855197906494
reward_mean: -115.48797852474321
reward_std: 2.8801147094234536
reward_max: -113.10014005602238
reward_min: -121.66246498599436
queue_len: 0.07658354013577136
wait_time: 0.7359222645733802
delay_time: 4.917819693545157
pressure: 0.9366710875331566
total_envstep_count: 386280
total_train_sample_count: 386280
total_episode_count: 3330
total_duration: 13149.194788217545
[2025-02-20 21:06:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.455973627991785
avg_train_sample_per_sec: 31.455973627991785
avg_episode_per_sec: 0.27117218644820507
collect_time: 22.126163005828857
reward_mean: -115.8779178338002
reward_std: 2.834238500890089
reward_max: -112.11834733893559
reward_min: -121.38935574229698
queue_len: 0.0768421205794431
wait_time: 0.7374065674014965
delay_time: 4.882323151615637
pressure: 0.9337975243147657
total_envstep_count: 386976
total_train_sample_count: 386976
total_episode_count: 3336
total_duration: 13171.320951223373
[2025-02-20 21:06:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.93949717931184
avg_train_sample_per_sec: 30.93949717931184
avg_episode_per_sec: 0.26671980326992967
collect_time: 22.49551749229431
reward_mean: -117.24042950513541
reward_std: 1.772465897513066
reward_max: -114.22689075630255
reward_min: -120.23599439775909
queue_len: 0.0777456429079147
wait_time: 0.748127478223827
delay_time: 4.858849679991068
pressure: 0.9449602122015914
total_envstep_count: 387672
total_train_sample_count: 387672
total_episode_count: 3342
total_duration: 13193.816468715668
[2025-02-20 21:07:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.078878908903615
avg_train_sample_per_sec: 31.078878908903615
avg_episode_per_sec: 0.2679213699043415
collect_time: 22.394630193710327
reward_mean: -116.26633986928105
reward_std: 4.950864117659584
reward_max: -108.22338935574233
reward_min: -122.10084033613448
queue_len: 0.07709969487352855
wait_time: 0.7437957720665631
delay_time: 4.915204374065351
pressure: 0.9410919540229886
total_envstep_count: 388368
total_train_sample_count: 388368
total_episode_count: 3348
total_duration: 13216.211098909378
[2025-02-20 21:07:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4555157116457
avg_train_sample_per_sec: 31.4555157116457
avg_episode_per_sec: 0.2711682388934974
collect_time: 22.126485109329224
reward_mean: -114.31711017740429
reward_std: 4.256357716899985
reward_max: -107.75280112044817
reward_min: -118.72759103641455
queue_len: 0.07580710223965802
wait_time: 0.731333216310397
delay_time: 4.710276449294217
pressure: 0.9354553492484526
total_envstep_count: 389064
total_train_sample_count: 389064
total_episode_count: 3354
total_duration: 13238.337584018707
[2025-02-20 21:07:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.377223111553967
avg_train_sample_per_sec: 31.377223111553967
avg_episode_per_sec: 0.27049330268581007
collect_time: 22.181695222854614
reward_mean: -114.8267973856209
reward_std: 1.804525226640134
reward_max: -112.97759103641457
reward_min: -118.24579831932772
queue_len: 0.07614509110452315
wait_time: 0.738076740422075
delay_time: 4.85150344714505
pressure: 0.9352343059239611
total_envstep_count: 389760
total_train_sample_count: 389760
total_episode_count: 3360
total_duration: 13260.519279241562
[2025-02-20 21:08:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.98537967926256
avg_train_sample_per_sec: 30.98537967926256
avg_episode_per_sec: 0.2671153420626083
collect_time: 22.462206602096558
reward_mean: -116.08064892623713
reward_std: 2.102715604710792
reward_max: -113.12044817927165
reward_min: -119.7913165266106
queue_len: 0.07697655764339333
wait_time: 0.7412310193750354
delay_time: 4.926152374789456
pressure: 0.9511494252873564
total_envstep_count: 390456
total_train_sample_count: 390456
total_episode_count: 3366
total_duration: 13282.981485843658
[2025-02-20 21:08:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.066967740424985
avg_train_sample_per_sec: 31.066967740424985
avg_episode_per_sec: 0.26781868741745674
collect_time: 22.40321636199951
reward_mean: -117.96311858076562
reward_std: 3.06293927931812
reward_max: -112.69677871148455
reward_min: -123.1470588235294
queue_len: 0.07822487969546793
wait_time: 0.7555193496496743
delay_time: 4.939176630133793
pressure: 0.9584438549955792
total_envstep_count: 391152
total_train_sample_count: 391152
total_episode_count: 3372
total_duration: 13305.384702205658
[2025-02-20 21:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.26552529897669
avg_train_sample_per_sec: 31.26552529897669
avg_episode_per_sec: 0.26953039050841976
collect_time: 22.260940551757812
reward_mean: -116.56279178338004
reward_std: 3.1426469234984262
reward_max: -111.25210084033614
reward_min: -120.74789915966389
queue_len: 0.07729628102346157
wait_time: 0.7533860029422911
delay_time: 4.8861594661291
pressure: 0.9472811671087534
total_envstep_count: 391848
total_train_sample_count: 391848
total_episode_count: 3378
total_duration: 13327.645642757416
[2025-02-20 21:09:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39523685471957
avg_train_sample_per_sec: 31.39523685471957
avg_episode_per_sec: 0.2706485935751687
collect_time: 22.168967962265015
reward_mean: -116.99509803921568
reward_std: 4.77433051939743
reward_max: -112.08473389355743
reward_min: -125.31582633053225
queue_len: 0.07758295625942685
wait_time: 0.7483602857588658
delay_time: 4.82475515616444
pressure: 0.9481653404067197
total_envstep_count: 392544
total_train_sample_count: 392544
total_episode_count: 3384
total_duration: 13349.81461071968
[2025-02-20 21:09:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.509710392462733
avg_train_sample_per_sec: 31.509710392462733
avg_episode_per_sec: 0.2716354344177822
collect_time: 22.08842897415161
reward_mean: -115.89670868347338
reward_std: 2.7619927320091553
reward_max: -113.61064425770306
reward_min: -121.68697478991596
queue_len: 0.07685458135508845
wait_time: 0.7369103808632205
delay_time: 4.771734304227432
pressure: 0.9398762157382846
total_envstep_count: 393240
total_train_sample_count: 393240
total_episode_count: 3390
total_duration: 13371.903039693832
[2025-02-20 21:10:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.563165577383835
avg_train_sample_per_sec: 31.563165577383835
avg_episode_per_sec: 0.2720962549774469
collect_time: 22.05102014541626
reward_mean: -112.6281512605042
reward_std: 1.8480901637454785
reward_max: -109.26960784313724
reward_min: -114.47058823529416
queue_len: 0.07468710295789403
wait_time: 0.7165461454254557
delay_time: 4.65830653296284
pressure: 0.9135720601237843
total_envstep_count: 393936
total_train_sample_count: 393936
total_episode_count: 3396
total_duration: 13393.954059839249
[2025-02-20 21:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.263011712595116
avg_train_sample_per_sec: 31.263011712595116
avg_episode_per_sec: 0.2695087216603027
collect_time: 22.262730360031128
reward_mean: -114.29283380018676
reward_std: 3.868531773257206
reward_max: -109.43347338935578
reward_min: -120.34173669467786
queue_len: 0.0757910038462777
wait_time: 0.7290989450598984
delay_time: 4.794319980448839
pressure: 0.9181034482758621
total_envstep_count: 394632
total_train_sample_count: 394632
total_episode_count: 3402
total_duration: 13416.21679019928
[2025-02-20 21:10:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.207388517875682
avg_train_sample_per_sec: 31.207388517875682
avg_episode_per_sec: 0.2690292113609973
collect_time: 22.30241084098816
reward_mean: -112.44747899159664
reward_std: 4.211407702829554
reward_max: -105.51960784313728
reward_min: -118.07282913165268
queue_len: 0.07456729376100572
wait_time: 0.717993143322758
delay_time: 4.630915509512083
pressure: 0.914345711759505
total_envstep_count: 395328
total_train_sample_count: 395328
total_episode_count: 3408
total_duration: 13438.519201040268
[2025-02-20 21:11:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.09202045887948
avg_train_sample_per_sec: 31.09202045887948
avg_episode_per_sec: 0.2680346591282714
collect_time: 22.385164737701416
reward_mean: -118.14250700280114
reward_std: 1.783415738865544
reward_max: -115.50210084033613
reward_min: -120.95518207282917
queue_len: 0.07834383753501402
wait_time: 0.7608342961410912
delay_time: 4.9156014019818555
pressure: 0.9482758620689654
total_envstep_count: 396024
total_train_sample_count: 396024
total_episode_count: 3414
total_duration: 13460.90436577797
[2025-02-20 21:11:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44959857110762
avg_train_sample_per_sec: 31.44959857110762
avg_episode_per_sec: 0.2711172290612726
collect_time: 22.130648136138916
reward_mean: -116.1155462184874
reward_std: 3.7327670773848816
reward_max: -113.24159663865551
reward_min: -124.09173669467786
queue_len: 0.07699969908387759
wait_time: 0.7388422654649837
delay_time: 4.924690634539577
pressure: 0.9438549955791337
total_envstep_count: 396720
total_train_sample_count: 396720
total_episode_count: 3420
total_duration: 13483.035013914108
[2025-02-20 21:11:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.618591375131363
avg_train_sample_per_sec: 31.618591375131363
avg_episode_per_sec: 0.27257406357871866
collect_time: 22.01236581802368
reward_mean: -112.62873482726422
reward_std: 2.0554333680477894
reward_max: -110.41106442577032
reward_min: -116.23319327731093
queue_len: 0.07468748993850415
wait_time: 0.7154872890800883
delay_time: 4.763659326672212
pressure: 0.9177718832891247
total_envstep_count: 397416
total_train_sample_count: 397416
total_episode_count: 3426
total_duration: 13505.047379732132
[2025-02-20 21:12:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.252439455372716
avg_train_sample_per_sec: 31.252439455372716
avg_episode_per_sec: 0.26941758151183376
collect_time: 22.270261526107788
reward_mean: -116.3234126984127
reward_std: 3.5965926928474987
reward_max: -111.6134453781513
reward_min: -122.25700280112041
queue_len: 0.07713754157719675
wait_time: 0.7431166210958301
delay_time: 4.895268490480842
pressure: 0.9381078691423519
total_envstep_count: 398112
total_train_sample_count: 398112
total_episode_count: 3432
total_duration: 13527.31764125824
[2025-02-20 21:12:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.732802531496368
avg_train_sample_per_sec: 30.732802531496368
avg_episode_per_sec: 0.2649379528577273
collect_time: 22.646811962127686
reward_mean: -115.94374416433239
reward_std: 4.26678233151458
reward_max: -109.48459383753497
reward_min: -121.72759103641461
queue_len: 0.07688577199226286
wait_time: 0.7403696779330652
delay_time: 4.817182902881578
pressure: 0.9393236074270558
total_envstep_count: 398808
total_train_sample_count: 398808
total_episode_count: 3438
total_duration: 13549.964453220367
[2025-02-20 21:13:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.109222443137778
avg_train_sample_per_sec: 31.109222443137778
avg_episode_per_sec: 0.26818295209601534
collect_time: 22.3727867603302
reward_mean: -114.79470121381884
reward_std: 2.9294058413317288
reward_max: -109.88515406162465
reward_min: -119.92927170868344
queue_len: 0.07612380717096741
wait_time: 0.7335997617437778
delay_time: 4.8007845188659966
pressure: 0.9335764809902741
total_envstep_count: 399504
total_train_sample_count: 399504
total_episode_count: 3444
total_duration: 13572.337239980698
[2025-02-20 21:13:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.97643033504625
avg_train_sample_per_sec: 30.97643033504625
avg_episode_per_sec: 0.26703819254350214
collect_time: 22.468696117401123
reward_mean: -119.28816526610645
reward_std: 5.672663150844992
reward_max: -114.37464985994399
reward_min: -130.38165266106444
queue_len: 0.07910355786877085
wait_time: 0.7639666719915198
delay_time: 5.0325768386099705
pressure: 0.9772325375773652
total_envstep_count: 400200
total_train_sample_count: 400200
total_episode_count: 3450
total_duration: 13594.805936098099
[2025-02-20 21:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.20946307452463
avg_train_sample_per_sec: 31.20946307452463
avg_episode_per_sec: 0.2690470954700399
collect_time: 22.300928354263306
reward_mean: -114.58029878618113
reward_std: 3.7032924640984786
reward_max: -110.32002801120453
reward_min: -122.09033613445379
queue_len: 0.07598163049481509
wait_time: 0.731964459081599
delay_time: 4.712429174465002
pressure: 0.9298187444739169
total_envstep_count: 400896
total_train_sample_count: 400896
total_episode_count: 3456
total_duration: 13617.106864452362
[2025-02-20 21:14:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.14269648127451
avg_train_sample_per_sec: 31.14269648127451
avg_episode_per_sec: 0.2684715213902975
collect_time: 22.34873914718628
reward_mean: -115.76050420168069
reward_std: 3.4635750040525024
reward_max: -109.82773109243696
reward_min: -120.36904761904759
queue_len: 0.07676426008069011
wait_time: 0.7379176139952003
delay_time: 4.814424262675189
pressure: 0.9412024756852343
total_envstep_count: 401592
total_train_sample_count: 401592
total_episode_count: 3462
total_duration: 13639.455603599548
[2025-02-20 21:14:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.136052898732576
avg_train_sample_per_sec: 31.136052898732576
avg_episode_per_sec: 0.26841424912700496
collect_time: 22.35350775718689
reward_mean: -116.6264005602241
reward_std: 1.7255814588641967
reward_max: -114.25910364145662
reward_min: -119.09453781512606
queue_len: 0.07733846190996292
wait_time: 0.7414909929489036
delay_time: 4.924576006268164
pressure: 0.9479442970822282
total_envstep_count: 402288
total_train_sample_count: 402288
total_episode_count: 3468
total_duration: 13661.809111356735
[2025-02-20 21:15:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.92525595946688
avg_train_sample_per_sec: 30.92525595946688
avg_episode_per_sec: 0.2665970341333352
collect_time: 22.505876779556274
reward_mean: -116.67355275443511
reward_std: 3.199573354237237
reward_max: -111.01330532212887
reward_min: -120.82002801120444
queue_len: 0.07736972994325936
wait_time: 0.7415380497910924
delay_time: 4.821597993626482
pressure: 0.9541335101679929
total_envstep_count: 402984
total_train_sample_count: 402984
total_episode_count: 3474
total_duration: 13684.314988136292
[2025-02-20 21:15:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.85616238895492
avg_train_sample_per_sec: 30.85616238895492
avg_episode_per_sec: 0.26600139990478383
collect_time: 22.556272268295288
reward_mean: -114.84325396825399
reward_std: 3.9398176169454096
reward_max: -109.59593837535017
reward_min: -121.11834733893559
queue_len: 0.0761560039577281
wait_time: 0.7336550999710229
delay_time: 4.846564805347707
pressure: 0.9308134394341291
total_envstep_count: 403680
total_train_sample_count: 403680
total_episode_count: 3480
total_duration: 13706.871260404587
[2025-02-20 21:15:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.00581758785688
avg_train_sample_per_sec: 31.00581758785688
avg_episode_per_sec: 0.2672915309298007
collect_time: 22.447400331497192
reward_mean: -113.74439775910362
reward_std: 2.1812676730884553
reward_max: -109.563025210084
reward_min: -116.48529411764702
queue_len: 0.0754273194689016
wait_time: 0.7181778878660218
delay_time: 4.768186075843895
pressure: 0.918656056587091
total_envstep_count: 404376
total_train_sample_count: 404376
total_episode_count: 3486
total_duration: 13729.318660736084
[2025-02-20 21:16:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.099315153317743
avg_train_sample_per_sec: 31.099315153317743
avg_episode_per_sec: 0.268097544425153
collect_time: 22.379914045333862
reward_mean: -117.81430905695612
reward_std: 4.523890742143574
reward_max: -110.54481792717087
reward_min: -123.52661064425772
queue_len: 0.07812619963989133
wait_time: 0.752807234741819
delay_time: 4.9672808539395215
pressure: 0.9686118479221929
total_envstep_count: 405072
total_train_sample_count: 405072
total_episode_count: 3492
total_duration: 13751.698574781418
[2025-02-20 21:16:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.061287742603636
avg_train_sample_per_sec: 31.061287742603636
avg_episode_per_sec: 0.26776972191899684
collect_time: 22.407313108444214
reward_mean: -113.77287581699345
reward_std: 3.345198286553488
reward_max: -109.98949579831931
reward_min: -119.67296918767506
queue_len: 0.0754462041226747
wait_time: 0.7321829483340639
delay_time: 4.721834886164814
pressure: 0.9357869142351901
total_envstep_count: 405768
total_train_sample_count: 405768
total_episode_count: 3498
total_duration: 13774.105887889862
[2025-02-20 21:16:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.366717391620618
avg_train_sample_per_sec: 31.366717391620618
avg_episode_per_sec: 0.27040273613466054
collect_time: 22.189124584197998
reward_mean: -115.48202614379085
reward_std: 1.9596357124463581
reward_max: -112.85014005602235
reward_min: -117.43697478991595
queue_len: 0.07657959293354831
wait_time: 0.7370654826917504
delay_time: 4.811904596764735
pressure: 0.9446286472148541
total_envstep_count: 406464
total_train_sample_count: 406464
total_episode_count: 3504
total_duration: 13796.29501247406
[2025-02-20 21:17:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.129090493856594
avg_train_sample_per_sec: 31.129090493856594
avg_episode_per_sec: 0.2683542283953155
collect_time: 22.35850739479065
reward_mean: -116.5675770308123
reward_std: 3.8101837138095633
reward_max: -110.85154061624651
reward_min: -122.96918767507002
queue_len: 0.0772994542644644
wait_time: 0.7446823446443123
delay_time: 4.8049048495969755
pressure: 0.9496021220159152
total_envstep_count: 407160
total_train_sample_count: 407160
total_episode_count: 3510
total_duration: 13818.65351986885
[2025-02-20 21:17:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.066354122577962
avg_train_sample_per_sec: 31.066354122577962
avg_episode_per_sec: 0.2678133976084307
collect_time: 22.403658866882324
reward_mean: -113.92868814192343
reward_std: 4.4292293856671945
reward_max: -108.39565826330528
reward_min: -119.390756302521
queue_len: 0.07554952794557256
wait_time: 0.7257104654417028
delay_time: 4.760492267593322
pressure: 0.924292661361627
total_envstep_count: 407856
total_train_sample_count: 407856
total_episode_count: 3516
total_duration: 13841.057178735733
[2025-02-20 21:18:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61484456975095
avg_train_sample_per_sec: 31.61484456975095
avg_episode_per_sec: 0.2725417635323358
collect_time: 22.01497459411621
reward_mean: -112.95063025210084
reward_std: 2.8765089886493924
reward_max: -107.63445378151259
reward_min: -116.4446778711484
queue_len: 0.07490094844303768
wait_time: 0.723564348374186
delay_time: 4.716041694377134
pressure: 0.9220822281167108
total_envstep_count: 408552
total_train_sample_count: 408552
total_episode_count: 3522
total_duration: 13863.07215332985
[2025-02-20 21:18:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.273835365404366
avg_train_sample_per_sec: 31.273835365404366
avg_episode_per_sec: 0.2696020290121066
collect_time: 22.255025386810303
reward_mean: -116.79610177404295
reward_std: 3.288495011501378
reward_max: -112.26400560224091
reward_min: -120.14145658263313
queue_len: 0.07745099587138128
wait_time: 0.7492302181703804
delay_time: 4.869335711115784
pressure: 0.9536914235190097
total_envstep_count: 409248
total_train_sample_count: 409248
total_episode_count: 3528
total_duration: 13885.32717871666
[2025-02-20 21:18:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.19421328323855
avg_train_sample_per_sec: 31.19421328323855
avg_episode_per_sec: 0.26891563175205646
collect_time: 22.311830520629883
reward_mean: -114.65756302521008
reward_std: 3.313069196244462
reward_max: -109.67366946778718
reward_min: -118.78361344537808
queue_len: 0.0760328667275929
wait_time: 0.7323185463398444
delay_time: 4.797990096486791
pressure: 0.9315870910698497
total_envstep_count: 409944
total_train_sample_count: 409944
total_episode_count: 3534
total_duration: 13907.63900923729
[2025-02-20 21:19:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.199907324836037
avg_train_sample_per_sec: 31.199907324836037
avg_episode_per_sec: 0.26896471831755203
collect_time: 22.307758569717407
reward_mean: -117.1434407096172
reward_std: 3.0813879410926863
reward_max: -112.00420168067225
reward_min: -121.67436974789916
queue_len: 0.07768132673051538
wait_time: 0.7508142845997817
delay_time: 4.934047375366975
pressure: 0.9610963748894784
total_envstep_count: 410640
total_train_sample_count: 410640
total_episode_count: 3540
total_duration: 13929.946767807007
[2025-02-20 21:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.606722578730658
avg_train_sample_per_sec: 31.606722578730658
avg_episode_per_sec: 0.27247174636836774
collect_time: 22.020631790161133
reward_mean: -114.88223622782446
reward_std: 4.037165669407567
reward_max: -108.02240896358542
reward_min: -119.03641456582635
queue_len: 0.07618185426248307
wait_time: 0.7353742226333505
delay_time: 4.801277718873827
pressure: 0.9391025641025642
total_envstep_count: 411336
total_train_sample_count: 411336
total_episode_count: 3546
total_duration: 13951.967399597168
[2025-02-20 21:19:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.36698567006541
avg_train_sample_per_sec: 31.36698567006541
avg_episode_per_sec: 0.2704050488798742
collect_time: 22.188934803009033
reward_mean: -113.93604108309991
reward_std: 4.7432203442288925
reward_max: -108.5385154061625
reward_min: -120.70728291316523
queue_len: 0.07555440390125988
wait_time: 0.7230445560186939
delay_time: 4.746114325456987
pressure: 0.9295977011494251
total_envstep_count: 412032
total_train_sample_count: 412032
total_episode_count: 3552
total_duration: 13974.156334400177
[2025-02-20 21:20:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.353578377378657
avg_train_sample_per_sec: 31.353578377378657
avg_episode_per_sec: 0.27028946877050564
collect_time: 22.198423147201538
reward_mean: -117.55228758169936
reward_std: 2.6561387919376886
reward_max: -112.86694677871145
reward_min: -120.7436974789916
queue_len: 0.07795244534595447
wait_time: 0.749109325427784
delay_time: 4.9209895680828515
pressure: 0.9543545534924845
total_envstep_count: 412728
total_train_sample_count: 412728
total_episode_count: 3558
total_duration: 13996.354757547379
[2025-02-20 21:20:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.520364885454477
avg_train_sample_per_sec: 31.520364885454477
avg_episode_per_sec: 0.27172728349529723
collect_time: 22.080962657928467
reward_mean: -113.87161531279177
reward_std: 3.6540730245755513
reward_max: -109.71848739495796
reward_min: -118.6743697478991
queue_len: 0.07551168124190435
wait_time: 0.7249488876010174
delay_time: 4.763793300610754
pressure: 0.9220822281167108
total_envstep_count: 413424
total_train_sample_count: 413424
total_episode_count: 3564
total_duration: 14018.435720205307
[2025-02-20 21:21:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.069933681315472
avg_train_sample_per_sec: 31.069933681315472
avg_episode_per_sec: 0.2678442558734092
collect_time: 22.40107774734497
reward_mean: -116.47373949579833
reward_std: 3.992134911984039
reward_max: -109.60434173669466
reward_min: -121.83543417366947
queue_len: 0.07723722778235963
wait_time: 0.7474674440952332
delay_time: 4.856861960238189
pressure: 0.9497126436781609
total_envstep_count: 414120
total_train_sample_count: 414120
total_episode_count: 3570
total_duration: 14040.836797952652
[2025-02-20 21:21:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.140592589335487
avg_train_sample_per_sec: 31.140592589335487
avg_episode_per_sec: 0.26845338439082317
collect_time: 22.35024905204773
reward_mean: -114.17086834733895
reward_std: 2.4153877234986934
reward_max: -110.45378151260503
reward_min: -117.96218487394955
queue_len: 0.07571012489876588
wait_time: 0.7282834221221645
delay_time: 4.7698791086331385
pressure: 0.9238505747126435
total_envstep_count: 414816
total_train_sample_count: 414816
total_episode_count: 3576
total_duration: 14063.1870470047
[2025-02-20 21:21:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.276248825239865
avg_train_sample_per_sec: 31.276248825239865
avg_episode_per_sec: 0.26962283470034365
collect_time: 22.253308057785034
reward_mean: -115.86577964519142
reward_std: 2.690773050903745
reward_max: -111.3095238095238
reward_min: -120.50770308123248
queue_len: 0.0768340713827529
wait_time: 0.736302821305357
delay_time: 4.773335465030551
pressure: 0.9484969053934572
total_envstep_count: 415512
total_train_sample_count: 415512
total_episode_count: 3582
total_duration: 14085.440355062485
[2025-02-20 21:22:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.379400588304993
avg_train_sample_per_sec: 31.379400588304993
avg_episode_per_sec: 0.270512074037112
collect_time: 22.180155992507935
reward_mean: -114.0964052287582
reward_std: 4.590075666069643
reward_max: -108.35084033613447
reward_min: -123.45658263305326
queue_len: 0.07566074617291656
wait_time: 0.726991371261148
delay_time: 4.764430284129687
pressure: 0.9199823165340407
total_envstep_count: 416208
total_train_sample_count: 416208
total_episode_count: 3588
total_duration: 14107.620511054993
[2025-02-20 21:22:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.174101582890778
avg_train_sample_per_sec: 31.174101582890778
avg_episode_per_sec: 0.2687422550249205
collect_time: 22.32622480392456
reward_mean: -113.87068160597572
reward_std: 2.6274155700525337
reward_max: -111.39705882352939
reward_min: -118.28431372549022
queue_len: 0.07551106207292818
wait_time: 0.7232482626118529
delay_time: 4.715284003306454
pressure: 0.9283819628647215
total_envstep_count: 416904
total_train_sample_count: 416904
total_episode_count: 3594
total_duration: 14129.946735858917
[2025-02-20 21:23:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.231424969459542
avg_train_sample_per_sec: 31.231424969459542
avg_episode_per_sec: 0.2692364221505133
collect_time: 22.2852463722229
reward_mean: -115.30964052287584
reward_std: 2.5801310303607705
reward_max: -111.99649859943975
reward_min: -119.48179271708688
queue_len: 0.0764652788613235
wait_time: 0.7375839593131683
delay_time: 4.792891770206531
pressure: 0.9289345711759505
total_envstep_count: 417600
total_train_sample_count: 417600
total_episode_count: 3600
total_duration: 14152.23198223114
[2025-02-20 21:23:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53167538639576
avg_train_sample_per_sec: 31.53167538639576
avg_episode_per_sec: 0.2718247878137566
collect_time: 22.073042154312134
reward_mean: -112.32598039215686
reward_std: 2.9822863301263967
reward_max: -108.47829131652664
reward_min: -116.26820728291315
queue_len: 0.07448672439798201
wait_time: 0.7149629303533969
delay_time: 4.656264282376022
pressure: 0.9160035366931917
total_envstep_count: 418296
total_train_sample_count: 418296
total_episode_count: 3606
total_duration: 14174.305024385452
[2025-02-20 21:23:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.575076470902605
avg_train_sample_per_sec: 31.575076470902605
avg_episode_per_sec: 0.27219893509398796
collect_time: 22.042701959609985
reward_mean: -114.8035714285714
reward_std: 2.611810778397133
reward_max: -111.062324929972
reward_min: -117.94957983193275
queue_len: 0.07612968927624099
wait_time: 0.7337107477827559
delay_time: 4.754015685162634
pressure: 0.9367816091954024
total_envstep_count: 418992
total_train_sample_count: 418992
total_episode_count: 3612
total_duration: 14196.347726345062
[2025-02-20 21:24:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.96413182324147
avg_train_sample_per_sec: 30.96413182324147
avg_episode_per_sec: 0.26693217089001264
collect_time: 22.477620363235474
reward_mean: -116.6795051353875
reward_std: 4.014509231248281
reward_max: -112.0427170868347
reward_min: -124.40826330532212
queue_len: 0.07737367714548242
wait_time: 0.7438858611525955
delay_time: 4.894336719756223
pressure: 0.9428603006189212
total_envstep_count: 419688
total_train_sample_count: 419688
total_episode_count: 3618
total_duration: 14218.825346708298
[2025-02-20 21:24:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29800452243791
avg_train_sample_per_sec: 31.29800452243791
avg_episode_per_sec: 0.2698103838141199
collect_time: 22.237839460372925
reward_mean: -115.20343137254902
reward_std: 3.6284393210948407
reward_max: -108.1806722689076
reward_min: -118.0329131652661
queue_len: 0.0763948483902845
wait_time: 0.7282478973021568
delay_time: 4.771847255349702
pressure: 0.939655172413793
total_envstep_count: 420384
total_train_sample_count: 420384
total_episode_count: 3624
total_duration: 14241.06318616867
[2025-02-20 21:24:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30708896374863
avg_train_sample_per_sec: 31.30708896374863
avg_episode_per_sec: 0.26988869796335024
collect_time: 22.23138666152954
reward_mean: -114.76295518207284
reward_std: 4.825564328338334
reward_max: -108.15266106442579
reward_min: -124.14215686274508
queue_len: 0.07610275542577774
wait_time: 0.7297990703796992
delay_time: 4.778557637025559
pressure: 0.9354553492484526
total_envstep_count: 421080
total_train_sample_count: 421080
total_episode_count: 3630
total_duration: 14263.2945728302
[2025-02-20 21:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.258915904925484
avg_train_sample_per_sec: 31.258915904925484
avg_episode_per_sec: 0.26947341297349553
collect_time: 22.265647411346436
reward_mean: -114.9439775910364
reward_std: 2.915303141599593
reward_max: -110.2780112044818
reward_min: -119.77941176470588
queue_len: 0.0762227968110321
wait_time: 0.7310417425148662
delay_time: 4.778549743579647
pressure: 0.9376657824933687
total_envstep_count: 421776
total_train_sample_count: 421776
total_episode_count: 3636
total_duration: 14285.560220241547
[2025-02-20 21:25:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.274713522798663
avg_train_sample_per_sec: 31.274713522798663
avg_episode_per_sec: 0.26960959933447126
collect_time: 22.254400491714478
reward_mean: -113.31384220354808
reward_std: 3.3553068688436434
reward_max: -107.71218487394957
reward_min: -118.297619047619
queue_len: 0.07514180517476664
wait_time: 0.7263474355259345
delay_time: 4.735406460829959
pressure: 0.9223032714412024
total_envstep_count: 422472
total_train_sample_count: 422472
total_episode_count: 3642
total_duration: 14307.814620733261
[2025-02-20 21:26:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.277972953197594
avg_train_sample_per_sec: 31.277972953197594
avg_episode_per_sec: 0.26963769787239306
collect_time: 22.252081394195557
reward_mean: -114.53886554621846
reward_std: 5.979983888778326
reward_max: -106.97829131652657
reward_min: -123.95168067226894
queue_len: 0.07595415487149765
wait_time: 0.7272804457768961
delay_time: 4.771534819718771
pressure: 0.9263925729442971
total_envstep_count: 423168
total_train_sample_count: 423168
total_episode_count: 3648
total_duration: 14330.066702127457
[2025-02-20 21:26:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29608459256853
avg_train_sample_per_sec: 31.29608459256853
avg_episode_per_sec: 0.2697938326945563
collect_time: 22.239203691482544
reward_mean: -116.02766106442579
reward_std: 5.518311298264429
reward_max: -106.22619047619048
reward_min: -124.32563025210085
queue_len: 0.07694141980399588
wait_time: 0.7459778783308195
delay_time: 4.873172083547551
pressure: 0.9337975243147657
total_envstep_count: 423864
total_train_sample_count: 423864
total_episode_count: 3654
total_duration: 14352.30590581894
[2025-02-20 21:26:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.205692844416184
avg_train_sample_per_sec: 31.205692844416184
avg_episode_per_sec: 0.2690145934863464
collect_time: 22.303622722625732
reward_mean: -114.05520541549953
reward_std: 1.791253807675123
reward_max: -112.02030812324927
reward_min: -116.52731092436976
queue_len: 0.07563342534184318
wait_time: 0.7249892883767123
delay_time: 4.799296496197226
pressure: 0.9265030946065429
total_envstep_count: 424560
total_train_sample_count: 424560
total_episode_count: 3660
total_duration: 14374.609528541565
[2025-02-20 21:27:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54138776157426
avg_train_sample_per_sec: 31.54138776157426
avg_episode_per_sec: 0.271908515185985
collect_time: 22.066245317459106
reward_mean: -113.66281512605043
reward_std: 3.085942222996081
reward_max: -109.97619047619051
reward_min: -117.80392156862747
queue_len: 0.07537321957960903
wait_time: 0.7242907883754741
delay_time: 4.751111870386401
pressure: 0.9228558797524316
total_envstep_count: 425256
total_train_sample_count: 425256
total_episode_count: 3666
total_duration: 14396.675773859024
[2025-02-20 21:27:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.078768728530605
avg_train_sample_per_sec: 31.078768728530605
avg_episode_per_sec: 0.2679204200735397
collect_time: 22.394709587097168
reward_mean: -114.90196078431372
reward_std: 2.4443417496950657
reward_max: -110.82843137254903
reward_min: -118.04271708683473
queue_len: 0.07619493420710459
wait_time: 0.7348329915520585
delay_time: 4.76781660467689
pressure: 0.9393236074270557
total_envstep_count: 425952
total_train_sample_count: 425952
total_episode_count: 3672
total_duration: 14419.070483446121
[2025-02-20 21:27:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.128549103983868
avg_train_sample_per_sec: 31.128549103983868
avg_episode_per_sec: 0.26834956124124026
collect_time: 22.358896255493164
reward_mean: -113.37348272642392
reward_std: 4.800784539396157
reward_max: -107.92577030812326
reward_min: -120.15896358543415
queue_len: 0.07518135459311931
wait_time: 0.7269909842805381
delay_time: 4.708779272836684
pressure: 0.9268346595932803
total_envstep_count: 426648
total_train_sample_count: 426648
total_episode_count: 3678
total_duration: 14441.429379701614
[2025-02-20 21:28:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.323299648785667
avg_train_sample_per_sec: 31.323299648785667
avg_episode_per_sec: 0.2700284452481523
collect_time: 22.219881296157837
reward_mean: -113.62686741363213
reward_std: 2.6710810918428445
reward_max: -111.04901960784316
reward_min: -119.23809523809524
queue_len: 0.07534938157402658
wait_time: 0.7239390230008892
delay_time: 4.717291293243812
pressure: 0.9323607427055703
total_envstep_count: 427344
total_train_sample_count: 427344
total_episode_count: 3684
total_duration: 14463.649260997772
[2025-02-20 21:28:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.8585124640465
avg_train_sample_per_sec: 30.8585124640465
avg_episode_per_sec: 0.2660216591728146
collect_time: 22.55455446243286
reward_mean: -116.4781746031746
reward_std: 3.0352649643908727
reward_max: -112.63935574229693
reward_min: -121.42226890756298
queue_len: 0.07724016883499642
wait_time: 0.7495245556224258
delay_time: 4.856658252225181
pressure: 0.9410919540229886
total_envstep_count: 428040
total_train_sample_count: 428040
total_episode_count: 3690
total_duration: 14486.203815460205
[2025-02-20 21:29:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.226002612355423
avg_train_sample_per_sec: 30.226002612355423
avg_episode_per_sec: 0.26056898803754674
collect_time: 23.026531457901
reward_mean: -112.76528944911297
reward_std: 2.491866672629777
reward_max: -108.38935574229686
reward_min: -115.82633053221286
queue_len: 0.07477804340126855
wait_time: 0.7126473931747767
delay_time: 4.748458971638413
pressure: 0.9187665782493369
total_envstep_count: 428736
total_train_sample_count: 428736
total_episode_count: 3696
total_duration: 14509.230346918106
[2025-02-20 21:29:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.276380180680604
avg_train_sample_per_sec: 31.276380180680604
avg_episode_per_sec: 0.2696239670748328
collect_time: 22.253214597702026
reward_mean: -112.49766573295987
reward_std: 3.4652249245899207
reward_max: -107.84733893557423
reward_min: -116.58053221288519
queue_len: 0.0746005740934747
wait_time: 0.7134274686886247
delay_time: 4.717687222372089
pressure: 0.9192086648983201
total_envstep_count: 429432
total_train_sample_count: 429432
total_episode_count: 3702
total_duration: 14531.483561515808
[2025-02-20 21:29:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.975471888987773
avg_train_sample_per_sec: 30.975471888987773
avg_episode_per_sec: 0.2670299300774808
collect_time: 22.469391345977783
reward_mean: -115.81360877684405
reward_std: 2.708833235794337
reward_max: -111.00210084033611
reward_min: -118.40336134453784
queue_len: 0.07679947531620959
wait_time: 0.7405908760498009
delay_time: 4.785270569911792
pressure: 0.9493810786914234
total_envstep_count: 430128
total_train_sample_count: 430128
total_episode_count: 3708
total_duration: 14553.952952861786
[2025-02-20 21:30:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.16364558668664
avg_train_sample_per_sec: 31.16364558668664
avg_episode_per_sec: 0.26865211712660897
collect_time: 22.333715677261353
reward_mean: -112.3970588235294
reward_std: 3.424431159097929
reward_max: -108.00490196078432
reward_min: -116.87745098039214
queue_len: 0.07453385863629271
wait_time: 0.7113268605408565
delay_time: 4.7796018118672015
pressure: 0.9137931034482758
total_envstep_count: 430824
total_train_sample_count: 430824
total_episode_count: 3714
total_duration: 14576.286668539047
[2025-02-20 21:30:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.558875774808413
avg_train_sample_per_sec: 31.558875774808413
avg_episode_per_sec: 0.2720592739207622
collect_time: 22.054017543792725
reward_mean: -113.29154995331466
reward_std: 4.357948796285895
reward_max: -106.75980392156859
reward_min: -118.8102240896359
queue_len: 0.07512702251546065
wait_time: 0.7214926089799314
delay_time: 4.7425322324049715
pressure: 0.923076923076923
total_envstep_count: 431520
total_train_sample_count: 431520
total_episode_count: 3720
total_duration: 14598.34068608284
[2025-02-20 21:30:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.457571185922937
avg_train_sample_per_sec: 31.457571185922937
avg_episode_per_sec: 0.2711859584993357
collect_time: 22.12503933906555
reward_mean: -113.52112511671335
reward_std: 3.5398395054240264
reward_max: -108.21288515406165
reward_min: -116.42647058823533
queue_len: 0.0752792606874757
wait_time: 0.7252521256070953
delay_time: 4.756737487876799
pressure: 0.9263925729442971
total_envstep_count: 432216
total_train_sample_count: 432216
total_episode_count: 3726
total_duration: 14620.465725421906
[2025-02-20 21:31:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.185348132918087
avg_train_sample_per_sec: 31.185348132918087
avg_episode_per_sec: 0.2688392080423973
collect_time: 22.31817317008972
reward_mean: -116.42577030812326
reward_std: 3.519162743742603
reward_max: -110.5427170868347
reward_min: -120.89775910364146
queue_len: 0.07720541797620904
wait_time: 0.7482336657032397
delay_time: 4.893145215384119
pressure: 0.9499336870026526
total_envstep_count: 432912
total_train_sample_count: 432912
total_episode_count: 3732
total_duration: 14642.783898591995
[2025-02-20 21:31:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.22725626157048
avg_train_sample_per_sec: 31.22725626157048
avg_episode_per_sec: 0.26920048501353866
collect_time: 22.28822135925293
reward_mean: -115.05100373482725
reward_std: 3.5715005992413467
reward_max: -109.28921568627447
reward_min: -119.03291316526611
queue_len: 0.07629376905492523
wait_time: 0.7355942598082557
delay_time: 4.840234058084962
pressure: 0.937444739168877
total_envstep_count: 433608
total_train_sample_count: 433608
total_episode_count: 3738
total_duration: 14665.072119951248
[2025-02-20 21:32:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.055138048895163
avg_train_sample_per_sec: 31.055138048895163
avg_episode_per_sec: 0.26771670731806174
collect_time: 22.411750316619873
reward_mean: -115.04108309990663
reward_std: 3.1188323880776747
reward_max: -110.5196078431373
reward_min: -118.60014005602237
queue_len: 0.07628719038455345
wait_time: 0.7372108326089056
delay_time: 4.856829776189339
pressure: 0.9459549071618037
total_envstep_count: 434304
total_train_sample_count: 434304
total_episode_count: 3744
total_duration: 14687.483870267868
[2025-02-20 21:32:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.243579304382045
avg_train_sample_per_sec: 31.243579304382045
avg_episode_per_sec: 0.2693412008998452
collect_time: 22.27657699584961
reward_mean: -114.82633053221288
reward_std: 2.5856857021010904
reward_max: -109.17226890756305
reward_min: -116.9299719887955
queue_len: 0.07614478152003508
wait_time: 0.7400902779325701
delay_time: 4.8548108975890125
pressure: 0.9366710875331563
total_envstep_count: 435000
total_train_sample_count: 435000
total_episode_count: 3750
total_duration: 14709.760447263718
[2025-02-20 21:32:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.307242738077996
avg_train_sample_per_sec: 31.307242738077996
avg_episode_per_sec: 0.2698900236041207
collect_time: 22.231277465820312
reward_mean: -116.7139355742297
reward_std: 3.244261538183784
reward_max: -111.7142857142857
reward_min: -120.80672268907561
queue_len: 0.07739650900147858
wait_time: 0.744530029076175
delay_time: 4.958739876716657
pressure: 0.9504862953138815
total_envstep_count: 435696
total_train_sample_count: 435696
total_episode_count: 3756
total_duration: 14731.991724729538
[2025-02-20 21:33:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39295691379938
avg_train_sample_per_sec: 31.39295691379938
avg_episode_per_sec: 0.27062893891206363
collect_time: 22.170578002929688
reward_mean: -115.62266573295985
reward_std: 4.735553710863441
reward_max: -109.40056022408966
reward_min: -124.47619047619045
queue_len: 0.07667285526058344
wait_time: 0.7458865509068348
delay_time: 4.83843796659012
pressure: 0.9365605658709107
total_envstep_count: 436392
total_train_sample_count: 436392
total_episode_count: 3762
total_duration: 14754.162302732468
[2025-02-20 21:33:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.45733423678317
avg_train_sample_per_sec: 31.45733423678317
avg_episode_per_sec: 0.27118391583433765
collect_time: 22.125205993652344
reward_mean: -112.85667600373485
reward_std: 2.140612617212234
reward_max: -110.14005602240898
reward_min: -116.9670868347339
queue_len: 0.07483864456481092
wait_time: 0.7180222442646379
delay_time: 4.7426654283325105
pressure: 0.920866489832007
total_envstep_count: 437088
total_train_sample_count: 437088
total_episode_count: 3768
total_duration: 14776.28750872612
[2025-02-20 21:34:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.186362922686804
avg_train_sample_per_sec: 31.186362922686804
avg_episode_per_sec: 0.2688479562300587
collect_time: 22.31744694709778
reward_mean: -116.91304855275443
reward_std: 2.6279121448215554
reward_max: -112.36694677871151
reward_min: -120.24439775910359
queue_len: 0.07752854678564618
wait_time: 0.743869298382483
delay_time: 4.860857566702772
pressure: 0.946286472148541
total_envstep_count: 437784
total_train_sample_count: 437784
total_episode_count: 3774
total_duration: 14798.604955673218
[2025-02-20 21:34:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.45902143311532
avg_train_sample_per_sec: 31.45902143311532
avg_episode_per_sec: 0.2711984606303045
collect_time: 22.124019384384155
reward_mean: -114.23389355742297
reward_std: 6.723378184024821
reward_max: -108.78641456582632
reward_min: -128.92086834733897
queue_len: 0.07575191880465713
wait_time: 0.7270563066075239
delay_time: 4.8077930445017545
pressure: 0.925950486295314
total_envstep_count: 438480
total_train_sample_count: 438480
total_episode_count: 3780
total_duration: 14820.728975057602
[2025-02-20 21:34:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.374543503108434
avg_train_sample_per_sec: 31.374543503108434
avg_episode_per_sec: 0.27047020261300375
collect_time: 22.183589696884155
reward_mean: -113.86916433239962
reward_std: 4.116648987426094
reward_max: -106.25490196078428
reward_min: -118.63235294117645
queue_len: 0.07551005592334191
wait_time: 0.7240842181258001
delay_time: 4.854276577583014
pressure: 0.9227453580901858
total_envstep_count: 439176
total_train_sample_count: 439176
total_episode_count: 3786
total_duration: 14842.912564754486
[2025-02-20 21:35:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.48682570361471
avg_train_sample_per_sec: 31.48682570361471
avg_episode_per_sec: 0.2714381526173682
collect_time: 22.104482889175415
reward_mean: -113.22105508870213
reward_std: 5.357132736890576
reward_max: -104.06582633053218
reward_min: -119.96358543417367
queue_len: 0.07508027525776002
wait_time: 0.7246225081544555
delay_time: 4.731565868041986
pressure: 0.9183244916003535
total_envstep_count: 439872
total_train_sample_count: 439872
total_episode_count: 3792
total_duration: 14865.017047643661
[2025-02-20 21:35:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.239480563286172
avg_train_sample_per_sec: 31.239480563286172
avg_episode_per_sec: 0.2693058669248808
collect_time: 22.279499769210815
reward_mean: -111.20168067226889
reward_std: 2.668312742501744
reward_max: -107.4040616246499
reward_min: -115.08823529411762
queue_len: 0.07374116755455497
wait_time: 0.7122105694620907
delay_time: 4.643341450166257
pressure: 0.9098143236074271
total_envstep_count: 440568
total_train_sample_count: 440568
total_episode_count: 3798
total_duration: 14887.296547412872
[2025-02-20 21:35:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.918314146726097
avg_train_sample_per_sec: 30.918314146726097
avg_episode_per_sec: 0.26653719092005257
collect_time: 22.510929822921753
reward_mean: -111.38818860877683
reward_std: 3.452112540694099
reward_max: -106.47829131652661
reward_min: -116.00140056022407
queue_len: 0.07386484655754431
wait_time: 0.7127021122330452
delay_time: 4.708824441437541
pressure: 0.9010831122900088
total_envstep_count: 441264
total_train_sample_count: 441264
total_episode_count: 3804
total_duration: 14909.807477235794
[2025-02-20 21:36:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.410700435986012
avg_train_sample_per_sec: 31.410700435986012
avg_episode_per_sec: 0.27078190031022425
collect_time: 22.15805411338806
reward_mean: -113.83648459383755
reward_std: 4.408514704646791
reward_max: -108.47058823529414
reward_min: -120.31022408963584
queue_len: 0.0754883850091761
wait_time: 0.7260723697082724
delay_time: 4.7814878307613755
pressure: 0.9218611847922195
total_envstep_count: 441960
total_train_sample_count: 441960
total_episode_count: 3810
total_duration: 14931.965531349182
[2025-02-20 21:36:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.63525318465379
avg_train_sample_per_sec: 31.63525318465379
avg_episode_per_sec: 0.2727176998677051
collect_time: 22.00077223777771
reward_mean: -118.21533613445378
reward_std: 1.895628933836577
reward_max: -114.3109243697479
reward_min: -120.44117647058825
queue_len: 0.07839213271515504
wait_time: 0.7528015074287892
delay_time: 4.926185863572695
pressure: 0.9603227232537578
total_envstep_count: 442656
total_train_sample_count: 442656
total_episode_count: 3816
total_duration: 14953.96630358696
[2025-02-20 21:37:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.931656822367284
avg_train_sample_per_sec: 30.931656822367284
avg_episode_per_sec: 0.26665221398592487
collect_time: 22.501219511032104
reward_mean: -115.41468253968254
reward_std: 2.906387766925803
reward_max: -112.67226890756301
reward_min: -121.55602240896361
queue_len: 0.07653493537114227
wait_time: 0.7393140722248228
delay_time: 4.782862160856239
pressure: 0.9409814323607427
total_envstep_count: 443352
total_train_sample_count: 443352
total_episode_count: 3822
total_duration: 14976.467523097992
[2025-02-20 21:37:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.436290517276497
avg_train_sample_per_sec: 31.436290517276497
avg_episode_per_sec: 0.27100250445928015
collect_time: 22.140016794204712
reward_mean: -114.47945845004666
reward_std: 2.752801199622833
reward_max: -110.83823529411765
reward_min: -119.67997198879547
queue_len: 0.07591476024538904
wait_time: 0.7292673590214159
delay_time: 4.822408845949032
pressure: 0.9303713527851457
total_envstep_count: 444048
total_train_sample_count: 444048
total_episode_count: 3828
total_duration: 14998.607539892197
[2025-02-20 21:37:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.215373302688775
avg_train_sample_per_sec: 31.215373302688775
avg_episode_per_sec: 0.2690980457128343
collect_time: 22.296705961227417
reward_mean: -114.98529411764703
reward_std: 2.6510496657564344
reward_max: -111.64355742296917
reward_min: -119.35014005602243
queue_len: 0.07625019503822748
wait_time: 0.7347636446267277
delay_time: 4.826095055521701
pressure: 0.9391025641025642
total_envstep_count: 444744
total_train_sample_count: 444744
total_episode_count: 3834
total_duration: 15020.904245853424
[2025-02-20 21:38:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47140007773315
avg_train_sample_per_sec: 31.47140007773315
avg_episode_per_sec: 0.2713051730839065
collect_time: 22.115317344665527
reward_mean: -111.9278711484594
reward_std: 2.989022127130208
reward_max: -107.33963585434175
reward_min: -115.72198879551823
queue_len: 0.07422272622576882
wait_time: 0.7055789601428546
delay_time: 4.659522401848167
pressure: 0.9105879752431476
total_envstep_count: 445440
total_train_sample_count: 445440
total_episode_count: 3840
total_duration: 15043.01956319809
[2025-02-20 21:38:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.231543919914532
avg_train_sample_per_sec: 31.231543919914532
avg_episode_per_sec: 0.26923744758547014
collect_time: 22.28516149520874
reward_mean: -113.56535947712418
reward_std: 4.7203577578782125
reward_max: -107.40476190476193
reward_min: -120.7387955182073
queue_len: 0.0753085938177216
wait_time: 0.7200733188943128
delay_time: 4.765175711429629
pressure: 0.925950486295314
total_envstep_count: 446136
total_train_sample_count: 446136
total_episode_count: 3846
total_duration: 15065.304724693298
[2025-02-20 21:38:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.314023404458556
avg_train_sample_per_sec: 31.314023404458556
avg_episode_per_sec: 0.26994847762464275
collect_time: 22.226463556289673
reward_mean: -114.4080298786181
reward_std: 3.4205442981352463
reward_max: -111.10854341736689
reward_min: -120.92647058823526
queue_len: 0.07586739381871227
wait_time: 0.7232714040523373
delay_time: 4.792702602807463
pressure: 0.9284924845269672
total_envstep_count: 446832
total_train_sample_count: 446832
total_episode_count: 3852
total_duration: 15087.531188249588
[2025-02-20 21:39:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.371278412263845
avg_train_sample_per_sec: 31.371278412263845
avg_episode_per_sec: 0.2704420552781366
collect_time: 22.185898542404175
reward_mean: -112.67915499533144
reward_std: 1.9547641014112496
reward_max: -109.89425770308124
reward_min: -115.02170868347336
queue_len: 0.07472092506321715
wait_time: 0.7164709163948514
delay_time: 4.747120258381851
pressure: 0.9183244916003536
total_envstep_count: 447528
total_train_sample_count: 447528
total_episode_count: 3858
total_duration: 15109.717086791992
[2025-02-20 21:39:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.385687488158744
avg_train_sample_per_sec: 31.385687488158744
avg_episode_per_sec: 0.27056627144964435
collect_time: 22.175713062286377
reward_mean: -113.67401960784316
reward_std: 3.542910613695867
reward_max: -108.16316526610642
reward_min: -119.21428571428572
queue_len: 0.07538064960732305
wait_time: 0.7155997456453846
delay_time: 4.789420964610218
pressure: 0.9088196286472149
total_envstep_count: 448224
total_train_sample_count: 448224
total_episode_count: 3864
total_duration: 15131.892799854279
[2025-02-20 21:40:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.268311576315
avg_train_sample_per_sec: 31.268311576315
avg_episode_per_sec: 0.26955441014064657
collect_time: 22.258956909179688
reward_mean: -114.10527544351076
reward_std: 1.7135341914604065
reward_max: -111.87254901960786
reward_min: -116.312324929972
queue_len: 0.07566662827819014
wait_time: 0.7232022893153726
delay_time: 4.807669829117499
pressure: 0.9184350132625995
total_envstep_count: 448920
total_train_sample_count: 448920
total_episode_count: 3870
total_duration: 15154.151756763458
[2025-02-20 21:40:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.419486894131925
avg_train_sample_per_sec: 31.419486894131925
avg_episode_per_sec: 0.27085764563906833
collect_time: 22.151857614517212
reward_mean: -113.86788048552752
reward_std: 3.7662778338332523
reward_max: -107.89215686274508
reward_min: -120.59103641456579
queue_len: 0.0755092045659997
wait_time: 0.7295627800191694
delay_time: 4.72775646689283
pressure: 0.9195402298850573
total_envstep_count: 449616
total_train_sample_count: 449616
total_episode_count: 3876
total_duration: 15176.303614377975
[2025-02-20 21:40:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.422831704919183
avg_train_sample_per_sec: 31.422831704919183
avg_episode_per_sec: 0.27088648021482054
collect_time: 22.149499654769897
reward_mean: -114.9938141923436
reward_std: 3.9617364864735665
reward_max: -109.42296918767508
reward_min: -122.37254901960785
queue_len: 0.07625584495513502
wait_time: 0.7334821970344283
delay_time: 4.793830881148031
pressure: 0.9383289124668436
total_envstep_count: 450312
total_train_sample_count: 450312
total_episode_count: 3882
total_duration: 15198.453114032745
[2025-02-20 21:41:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.411318944580927
avg_train_sample_per_sec: 31.411318944580927
avg_episode_per_sec: 0.27078723228087004
collect_time: 22.157617807388306
reward_mean: -111.92226890756302
reward_std: 4.2743587278254696
reward_max: -105.89985994397756
reward_min: -116.1813725490196
queue_len: 0.07421901121191181
wait_time: 0.7162696864775971
delay_time: 4.711271970804931
pressure: 0.9076038903625112
total_envstep_count: 451008
total_train_sample_count: 451008
total_episode_count: 3888
total_duration: 15220.610731840134
[2025-02-20 21:41:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.667729809432277
avg_train_sample_per_sec: 31.667729809432277
avg_episode_per_sec: 0.2729976707709679
collect_time: 21.978209495544434
reward_mean: -114.64437441643327
reward_std: 3.4677554714460825
reward_max: -110.78921568627453
reward_min: -119.89425770308131
queue_len: 0.07602412096580453
wait_time: 0.7303639072782074
delay_time: 4.784171588673326
pressure: 0.9297082228116711
total_envstep_count: 451704
total_train_sample_count: 451704
total_episode_count: 3894
total_duration: 15242.588941335678
[2025-02-20 21:41:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32896594069284
avg_train_sample_per_sec: 31.32896594069284
avg_episode_per_sec: 0.27007729259217966
collect_time: 22.2158625125885
reward_mean: -116.07177871148457
reward_std: 2.2348619860086516
reward_max: -112.0483193277311
reward_min: -118.96358543417364
queue_len: 0.07697067553811975
wait_time: 0.7344107183103127
delay_time: 4.88654877101022
pressure: 0.9393236074270557
total_envstep_count: 452400
total_train_sample_count: 452400
total_episode_count: 3900
total_duration: 15264.804803848267
[2025-02-20 21:42:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.464011196274566
avg_train_sample_per_sec: 31.464011196274566
avg_episode_per_sec: 0.27124147582995317
collect_time: 22.120510816574097
reward_mean: -114.25910364145658
reward_std: 4.493385650546206
reward_max: -106.81372549019606
reward_min: -122.20588235294113
queue_len: 0.07576863636701366
wait_time: 0.7330744742636225
delay_time: 4.771355933661661
pressure: 0.9205349248452697
total_envstep_count: 453096
total_train_sample_count: 453096
total_episode_count: 3906
total_duration: 15286.92531466484
[2025-02-20 21:42:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.861209375709723
avg_train_sample_per_sec: 30.861209375709723
avg_episode_per_sec: 0.2660449084112907
collect_time: 22.55258345603943
reward_mean: -116.96626984126982
reward_std: 3.941187408129388
reward_max: -111.63375350140056
reward_min: -122.65196078431367
queue_len: 0.07756383941728769
wait_time: 0.7500707400555271
delay_time: 4.906461725372121
pressure: 0.9623121131741822
total_envstep_count: 453792
total_train_sample_count: 453792
total_episode_count: 3912
total_duration: 15309.47789812088
[2025-02-20 21:43:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.47423789627601
avg_train_sample_per_sec: 30.47423789627601
avg_episode_per_sec: 0.2627089473816897
collect_time: 22.838963270187378
reward_mean: -116.5590569561158
reward_std: 2.3535083025941788
reward_max: -113.5609243697479
reward_min: -120.3648459383754
queue_len: 0.0772938043475569
wait_time: 0.7460707536772446
delay_time: 4.843754433147364
pressure: 0.939102564102564
total_envstep_count: 454488
total_train_sample_count: 454488
total_episode_count: 3918
total_duration: 15332.316861391068
[2025-02-20 21:43:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.695590538264955
avg_train_sample_per_sec: 31.695590538264955
avg_episode_per_sec: 0.27323784946780133
collect_time: 21.958890438079834
reward_mean: -111.46545284780576
reward_std: 2.6368301212313736
reward_max: -105.92717086834735
reward_min: -114.17927170868344
queue_len: 0.07391608279032215
wait_time: 0.7075627001463713
delay_time: 4.653472469909418
pressure: 0.9080459770114944
total_envstep_count: 455184
total_train_sample_count: 455184
total_episode_count: 3924
total_duration: 15354.275751829147
[2025-02-20 21:43:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39318715490579
avg_train_sample_per_sec: 31.39318715490579
avg_episode_per_sec: 0.27063092374918785
collect_time: 22.17041540145874
reward_mean: -115.69199346405229
reward_std: 2.2228040730593808
reward_max: -112.41316526610646
reward_min: -118.61134453781516
queue_len: 0.07671882855706384
wait_time: 0.7355702670104293
delay_time: 4.905197693358847
pressure: 0.9393236074270558
total_envstep_count: 455880
total_train_sample_count: 455880
total_episode_count: 3930
total_duration: 15376.446167230606
[2025-02-20 21:44:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.339694681319706
avg_train_sample_per_sec: 31.339694681319706
avg_episode_per_sec: 0.2701697817355147
collect_time: 22.20825719833374
reward_mean: -111.40639589169001
reward_std: 1.0975433449000966
reward_max: -109.46428571428571
reward_min: -112.92086834733897
queue_len: 0.07387692035257958
wait_time: 0.7025631428521893
delay_time: 4.711621010916094
pressure: 0.9025198938992043
total_envstep_count: 456576
total_train_sample_count: 456576
total_episode_count: 3936
total_duration: 15398.65442442894
[2025-02-20 21:44:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.283197098628143
avg_train_sample_per_sec: 31.283197098628143
avg_episode_per_sec: 0.2696827336088633
collect_time: 22.24836540222168
reward_mean: -113.40266106442577
reward_std: 4.059633796828385
reward_max: -108.03921568627452
reward_min: -120.34173669467788
queue_len: 0.07520070362362452
wait_time: 0.72172425557314
delay_time: 4.779076236206156
pressure: 0.9288240495137047
total_envstep_count: 457272
total_train_sample_count: 457272
total_episode_count: 3942
total_duration: 15420.902789831161
[2025-02-20 21:45:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.319399717678237
avg_train_sample_per_sec: 31.319399717678237
avg_episode_per_sec: 0.2699948251523986
collect_time: 22.22264814376831
reward_mean: -113.55077030812322
reward_std: 5.024952201249619
reward_max: -104.8018207282913
reward_min: -121.29271708683471
queue_len: 0.075298919302469
wait_time: 0.7206989117486075
delay_time: 4.782786282057324
pressure: 0.9190981432360742
total_envstep_count: 457968
total_train_sample_count: 457968
total_episode_count: 3948
total_duration: 15443.12543797493
[2025-02-20 21:45:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.905868353849034
avg_train_sample_per_sec: 30.905868353849034
avg_episode_per_sec: 0.26642989960214686
collect_time: 22.519994974136353
reward_mean: -115.0903361344538
reward_std: 3.358175516536455
reward_max: -110.5098039215687
reward_min: -119.38935574229691
queue_len: 0.07631985154804628
wait_time: 0.7367664240762616
delay_time: 4.8709073019371205
pressure: 0.9335764809902742
total_envstep_count: 458664
total_train_sample_count: 458664
total_episode_count: 3954
total_duration: 15465.645432949066
[2025-02-20 21:45:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.908148121576808
avg_train_sample_per_sec: 30.908148121576808
avg_episode_per_sec: 0.2664495527722138
collect_time: 22.518333911895752
reward_mean: -115.95985060690941
reward_std: 1.8456016499369015
reward_max: -113.88305322128849
reward_min: -119.24299719887952
queue_len: 0.07689645265710174
wait_time: 0.7372667900051267
delay_time: 4.861451284737333
pressure: 0.9457338638373122
total_envstep_count: 459360
total_train_sample_count: 459360
total_episode_count: 3960
total_duration: 15488.163766860962
[2025-02-20 21:46:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61622546313464
avg_train_sample_per_sec: 31.61622546313464
avg_episode_per_sec: 0.27255366778564344
collect_time: 22.014013051986694
reward_mean: -112.99019607843134
reward_std: 3.634428909564825
reward_max: -107.83543417366941
reward_min: -118.05392156862744
queue_len: 0.07492718572840276
wait_time: 0.7181142682537205
delay_time: 4.724719204155882
pressure: 0.9211980548187445
total_envstep_count: 460056
total_train_sample_count: 460056
total_episode_count: 3966
total_duration: 15510.177779912949
[2025-02-20 21:46:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.35614393390233
avg_train_sample_per_sec: 31.35614393390233
avg_episode_per_sec: 0.27031158563708907
collect_time: 22.196606874465942
reward_mean: -114.55602240896359
reward_std: 4.834002182063846
reward_max: -106.80042016806719
reward_min: -121.52731092436976
queue_len: 0.07596553210143474
wait_time: 0.7303177017933611
delay_time: 4.827356888101268
pressure: 0.9294871794871794
total_envstep_count: 460752
total_train_sample_count: 460752
total_episode_count: 3972
total_duration: 15532.374386787415
[2025-02-20 21:46:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.408876484441887
avg_train_sample_per_sec: 31.408876484441887
avg_episode_per_sec: 0.2707661765900163
collect_time: 22.159340858459473
reward_mean: -114.27777777777779
reward_std: 2.9778053691665107
reward_max: -109.22268907563026
reward_min: -118.37955182072828
queue_len: 0.07578101974653699
wait_time: 0.7215899733014338
delay_time: 4.807851953127514
pressure: 0.9315870910698495
total_envstep_count: 461448
total_train_sample_count: 461448
total_episode_count: 3978
total_duration: 15554.533727645874
[2025-02-20 21:47:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.388828001555574
avg_train_sample_per_sec: 31.388828001555574
avg_episode_per_sec: 0.27059334484099634
collect_time: 22.173494338989258
reward_mean: -114.25746965452845
reward_std: 2.5960296055759433
reward_max: -109.34383753501399
reward_min: -116.66806722689077
queue_len: 0.07576755282130535
wait_time: 0.7289302989100149
delay_time: 4.788594436960149
pressure: 0.9291556145004422
total_envstep_count: 462144
total_train_sample_count: 462144
total_episode_count: 3984
total_duration: 15576.707221984863
[2025-02-20 21:47:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.409740950910354
avg_train_sample_per_sec: 31.409740950910354
avg_episode_per_sec: 0.2707736288871582
collect_time: 22.15873098373413
reward_mean: -114.29318394024274
reward_std: 1.3028601650415617
reward_max: -111.9887955182073
reward_min: -115.99299719887955
queue_len: 0.07579123603464373
wait_time: 0.7222787987874195
delay_time: 4.850810341226125
pressure: 0.9216401414677278
total_envstep_count: 462840
total_train_sample_count: 462840
total_episode_count: 3990
total_duration: 15598.865952968597
[2025-02-20 21:48:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.08127097510379
avg_train_sample_per_sec: 31.08127097510379
avg_episode_per_sec: 0.26794199116468786
collect_time: 22.392906665802002
reward_mean: -114.76528944911301
reward_std: 1.543341343412516
reward_max: -112.9572829131653
reward_min: -117.42226890756308
queue_len: 0.07610430334821817
wait_time: 0.7357724256811476
delay_time: 4.828397882606916
pressure: 0.9313660477453581
total_envstep_count: 463536
total_train_sample_count: 463536
total_episode_count: 3996
total_duration: 15621.2588596344
[2025-02-20 21:48:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4198970939877
avg_train_sample_per_sec: 31.4198970939877
avg_episode_per_sec: 0.2708611818447216
collect_time: 22.15156841278076
reward_mean: -112.6123949579832
reward_std: 2.809052982098011
reward_max: -107.984593837535
reward_min: -116.88655462184872
queue_len: 0.07467665448142122
wait_time: 0.7137581049218978
delay_time: 4.738881754695794
pressure: 0.9157824933687002
total_envstep_count: 464232
total_train_sample_count: 464232
total_episode_count: 4002
total_duration: 15643.41042804718
[2025-02-20 21:48:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.270102825453726
avg_train_sample_per_sec: 31.270102825453726
avg_episode_per_sec: 0.2695698519435666
collect_time: 22.257681846618652
reward_mean: -112.53699813258639
reward_std: 2.680986761132766
reward_max: -109.71008403361344
reward_min: -115.6673669467787
queue_len: 0.07462665658659574
wait_time: 0.7162369479179823
delay_time: 4.75837715482301
pressure: 0.9043987621573829
total_envstep_count: 464928
total_train_sample_count: 464928
total_episode_count: 4008
total_duration: 15665.668109893799
[2025-02-20 21:49:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6616532422257
avg_train_sample_per_sec: 31.6616532422257
avg_episode_per_sec: 0.2729452865709112
collect_time: 21.9824275970459
reward_mean: -117.25058356676004
reward_std: 2.447886516575106
reward_max: -114.63655462184876
reward_min: -121.67577030812325
queue_len: 0.07775237637053052
wait_time: 0.7437848592133581
delay_time: 4.941481075639268
pressure: 0.9525862068965517
total_envstep_count: 465624
total_train_sample_count: 465624
total_episode_count: 4014
total_duration: 15687.650537490845
[2025-02-20 21:49:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.97465646769141
avg_train_sample_per_sec: 30.97465646769141
avg_episode_per_sec: 0.2670229005835466
collect_time: 22.469982862472534
reward_mean: -116.18347338935571
reward_std: 4.436891822451897
reward_max: -109.54971988795519
reward_min: -121.26260504201677
queue_len: 0.07704474362689372
wait_time: 0.7380027497294229
delay_time: 4.872597076183553
pressure: 0.9448496905393458
total_envstep_count: 466320
total_train_sample_count: 466320
total_episode_count: 4020
total_duration: 15710.120520353317
[2025-02-20 21:49:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29115465300669
avg_train_sample_per_sec: 31.29115465300669
avg_episode_per_sec: 0.2697513332155749
collect_time: 22.24270749092102
reward_mean: -115.54528478057891
reward_std: 3.54845685348916
reward_max: -111.21918767507006
reward_min: -120.406862745098
queue_len: 0.07662154163168362
wait_time: 0.7337589655667749
delay_time: 4.8769036721814425
pressure: 0.9340185676392574
total_envstep_count: 467016
total_train_sample_count: 467016
total_episode_count: 4026
total_duration: 15732.363227844238
[2025-02-20 21:50:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.453567936680574
avg_train_sample_per_sec: 31.453567936680574
avg_episode_per_sec: 0.271151447730005
collect_time: 22.12785530090332
reward_mean: -113.68382352941175
reward_std: 3.844828179114851
reward_max: -109.10854341736696
reward_min: -120.55742296918767
queue_len: 0.07538715088157279
wait_time: 0.7229913074867436
delay_time: 4.812161101722455
pressure: 0.9155614500442087
total_envstep_count: 467712
total_train_sample_count: 467712
total_episode_count: 4032
total_duration: 15754.491083145142
[2025-02-20 21:50:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.587309773366954
avg_train_sample_per_sec: 31.587309773366954
avg_episode_per_sec: 0.272304394597991
collect_time: 22.034165143966675
reward_mean: -111.71615312791785
reward_std: 3.322879694755264
reward_max: -106.42436974789918
reward_min: -117.32282913165268
queue_len: 0.07408232966042295
wait_time: 0.7013294486671767
delay_time: 4.673364767959466
pressure: 0.902077807250221
total_envstep_count: 468408
total_train_sample_count: 468408
total_episode_count: 4038
total_duration: 15776.525248289108
[2025-02-20 21:51:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.093494490936244
avg_train_sample_per_sec: 31.093494490936244
avg_episode_per_sec: 0.2680473663011745
collect_time: 22.384103536605835
reward_mean: -114.37359943977593
reward_std: 4.6978847173951594
reward_max: -108.23949579831934
reward_min: -120.51260504201683
queue_len: 0.07584456196271615
wait_time: 0.7255982410647727
delay_time: 4.791958450311742
pressure: 0.9329133510167993
total_envstep_count: 469104
total_train_sample_count: 469104
total_episode_count: 4044
total_duration: 15798.909351825714
[2025-02-20 21:51:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.613137537282135
avg_train_sample_per_sec: 31.613137537282135
avg_episode_per_sec: 0.2725270477351908
collect_time: 22.01616334915161
reward_mean: -114.74416433239963
reward_std: 3.035653671346799
reward_max: -109.5238095238095
reward_min: -119.30182072829135
queue_len: 0.07609029465013238
wait_time: 0.7295937384679778
delay_time: 4.807122934670642
pressure: 0.9294871794871794
total_envstep_count: 469800
total_train_sample_count: 469800
total_episode_count: 4050
total_duration: 15820.925515174866
[2025-02-20 21:51:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.530555924708473
avg_train_sample_per_sec: 31.530555924708473
avg_episode_per_sec: 0.2718151372819696
collect_time: 22.07382583618164
reward_mean: -114.14670868347338
reward_std: 2.2093478976109635
reward_max: -109.93907563025206
reward_min: -116.56442577030815
queue_len: 0.07569410390150755
wait_time: 0.7237445265462507
delay_time: 4.897638758352179
pressure: 0.9176613616268788
total_envstep_count: 470496
total_train_sample_count: 470496
total_episode_count: 4056
total_duration: 15842.999341011047
[2025-02-20 21:52:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.025627268107574
avg_train_sample_per_sec: 31.025627268107574
avg_episode_per_sec: 0.2674623040354101
collect_time: 22.433067798614502
reward_mean: -114.90394491129784
reward_std: 2.4386869038254466
reward_max: -110.78991596638653
reward_min: -117.43347338935573
queue_len: 0.07619624994117895
wait_time: 0.7284334158066409
delay_time: 4.833042502678315
pressure: 0.9294871794871794
total_envstep_count: 471192
total_train_sample_count: 471192
total_episode_count: 4062
total_duration: 15865.432408809662
[2025-02-20 21:52:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71169217629665
avg_train_sample_per_sec: 31.71169217629665
avg_episode_per_sec: 0.2733766566922125
collect_time: 21.94774079322815
reward_mean: -114.07142857142856
reward_std: 3.4314625362159537
reward_max: -108.15056022408965
reward_min: -117.63655462184873
queue_len: 0.07564418340280409
wait_time: 0.7277023320380319
delay_time: 4.843975014485239
pressure: 0.9167771883289125
total_envstep_count: 471888
total_train_sample_count: 471888
total_episode_count: 4068
total_duration: 15887.38014960289
[2025-02-20 21:52:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.519577357765645
avg_train_sample_per_sec: 31.519577357765645
avg_episode_per_sec: 0.27172049446349694
collect_time: 22.081514358520508
reward_mean: -113.60562558356678
reward_std: 2.6613157903992244
reward_max: -109.15966386554626
reward_min: -118.14145658263308
queue_len: 0.0753352954798188
wait_time: 0.7251363410085521
delay_time: 4.727107033843917
pressure: 0.9245137046861185
total_envstep_count: 472584
total_train_sample_count: 472584
total_episode_count: 4074
total_duration: 15909.46166396141
[2025-02-20 21:53:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.400263820527176
avg_train_sample_per_sec: 31.400263820527176
avg_episode_per_sec: 0.27069192948730325
collect_time: 22.16541886329651
reward_mean: -114.70611577964519
reward_std: 3.444390208218142
reward_max: -110.62675070028008
reward_min: -119.91386554621852
queue_len: 0.07606506351435356
wait_time: 0.730999252043877
delay_time: 4.86718667710318
pressure: 0.9242926613616268
total_envstep_count: 473280
total_train_sample_count: 473280
total_episode_count: 4080
total_duration: 15931.627082824707
[2025-02-20 21:53:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.103233700671698
avg_train_sample_per_sec: 31.103233700671698
avg_episode_per_sec: 0.2681313250057905
collect_time: 22.377094507217407
reward_mean: -114.2075163398693
reward_std: 1.6787955240235237
reward_max: -111.00630252100841
reward_min: -116.2163865546219
queue_len: 0.07573442728108044
wait_time: 0.7214892035505627
delay_time: 4.807105630195754
pressure: 0.9187665782493369
total_envstep_count: 473976
total_train_sample_count: 473976
total_episode_count: 4086
total_duration: 15954.004177331924
[2025-02-20 21:54:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.004424300358092
avg_train_sample_per_sec: 31.004424300358092
avg_episode_per_sec: 0.2672795198306732
collect_time: 22.44840908050537
reward_mean: -114.7609710550887
reward_std: 2.133546520194774
reward_max: -111.95518207282916
reward_min: -117.62815126050417
queue_len: 0.07610143969170337
wait_time: 0.7291860156971718
delay_time: 4.804135884252513
pressure: 0.9231874447391687
total_envstep_count: 474672
total_train_sample_count: 474672
total_episode_count: 4092
total_duration: 15976.45258641243
[2025-02-20 21:54:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.032512783614038
avg_train_sample_per_sec: 31.032512783614038
avg_episode_per_sec: 0.2675216619277072
collect_time: 22.4280903339386
reward_mean: -115.05707282913164
reward_std: 2.8131778528863802
reward_max: -111.77380952380952
reward_min: -120.10644257703079
queue_len: 0.0762977936532703
wait_time: 0.7417502699576736
delay_time: 4.840332815461402
pressure: 0.934681697612732
total_envstep_count: 475368
total_train_sample_count: 475368
total_episode_count: 4098
total_duration: 15998.880676746368
[2025-02-20 21:54:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.03508644280371
avg_train_sample_per_sec: 31.03508644280371
avg_episode_per_sec: 0.2675438486448596
collect_time: 22.426230430603027
reward_mean: -115.6890756302521
reward_std: 4.876139441991141
reward_max: -110.32422969187674
reward_min: -124.79341736694674
queue_len: 0.07671689365401334
wait_time: 0.73750896247093
delay_time: 4.800746741165071
pressure: 0.9292661361626878
total_envstep_count: 476064
total_train_sample_count: 476064
total_episode_count: 4104
total_duration: 16021.306907176971
[2025-02-20 21:55:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.309614008603432
avg_train_sample_per_sec: 31.309614008603432
avg_episode_per_sec: 0.2699104655914089
collect_time: 22.229593753814697
reward_mean: -113.69339402427637
reward_std: 2.510787990081632
reward_max: -109.37815126050415
reward_min: -117.46918767507002
queue_len: 0.07539349736357849
wait_time: 0.7246621349689302
delay_time: 4.740382147514432
pressure: 0.9198717948717948
total_envstep_count: 476760
total_train_sample_count: 476760
total_episode_count: 4110
total_duration: 16043.536500930786
[2025-02-20 21:55:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.221356559320963
avg_train_sample_per_sec: 31.221356559320963
avg_episode_per_sec: 0.2691496255113876
collect_time: 22.29243302345276
reward_mean: -113.46486928104572
reward_std: 2.165483382308552
reward_max: -110.9516806722689
reward_min: -116.62394957983189
queue_len: 0.07524195575666162
wait_time: 0.7201353131880516
delay_time: 4.750971779787935
pressure: 0.9100353669319188
total_envstep_count: 477456
total_train_sample_count: 477456
total_episode_count: 4116
total_duration: 16065.828933954239
[2025-02-20 21:56:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.173304631575583
avg_train_sample_per_sec: 31.173304631575583
avg_episode_per_sec: 0.26873538475496195
collect_time: 22.32679557800293
reward_mean: -113.74661531279177
reward_std: 2.51543165005817
reward_max: -111.06652661064422
reward_min: -118.56022408963585
queue_len: 0.07542878999522003
wait_time: 0.7190377587816736
delay_time: 4.7846104294023055
pressure: 0.9281609195402298
total_envstep_count: 478152
total_train_sample_count: 478152
total_episode_count: 4122
total_duration: 16088.155729532242
[2025-02-20 21:56:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.157538104200267
avg_train_sample_per_sec: 31.157538104200267
avg_episode_per_sec: 0.2685994664155195
collect_time: 22.338093519210815
reward_mean: -116.0450513538749
reward_std: 2.969746956454988
reward_max: -113.39565826330538
reward_min: -122.51050420168069
queue_len: 0.07695295182617698
wait_time: 0.736470383909532
delay_time: 4.788593414971763
pressure: 0.9347922192749779
total_envstep_count: 478848
total_train_sample_count: 478848
total_episode_count: 4128
total_duration: 16110.493823051453
[2025-02-20 21:56:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.465200126906176
avg_train_sample_per_sec: 30.465200126906176
avg_episode_per_sec: 0.26263103557677736
collect_time: 22.845738649368286
reward_mean: -113.51984126984127
reward_std: 3.647248156596199
reward_max: -107.99859943977594
reward_min: -117.86554621848737
queue_len: 0.07527840933013345
wait_time: 0.726868698407745
delay_time: 4.706933591374498
pressure: 0.9228558797524316
total_envstep_count: 479544
total_train_sample_count: 479544
total_episode_count: 4134
total_duration: 16133.339561700821
[2025-02-20 21:57:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.20915911371174
avg_train_sample_per_sec: 31.20915911371174
avg_episode_per_sec: 0.2690444751182046
collect_time: 22.301145553588867
reward_mean: -111.62523342670401
reward_std: 2.4216351314348215
reward_max: -107.6330532212885
reward_min: -115.06582633053216
queue_len: 0.07402203808136872
wait_time: 0.709093131063212
delay_time: 4.623529652972263
pressure: 0.9120247568523431
total_envstep_count: 480240
total_train_sample_count: 480240
total_episode_count: 4140
total_duration: 16155.64070725441
[2025-02-20 21:57:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39971802338517
avg_train_sample_per_sec: 31.39971802338517
avg_episode_per_sec: 0.2706872243395273
collect_time: 22.165804147720337
reward_mean: -115.53046218487395
reward_std: 2.6066322450057173
reward_max: -111.5266106442577
reward_min: -119.17366946778714
queue_len: 0.07661171232418697
wait_time: 0.7380644344386739
delay_time: 4.8246307512186
pressure: 0.9311450044208666
total_envstep_count: 480936
total_train_sample_count: 480936
total_episode_count: 4146
total_duration: 16177.80651140213
[2025-02-20 21:57:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.713067943901738
avg_train_sample_per_sec: 30.713067943901738
avg_episode_per_sec: 0.26476782710260116
collect_time: 22.66136360168457
reward_mean: -113.63620448179272
reward_std: 2.8162984198327403
reward_max: -109.72128851540617
reward_min: -117.50280112044823
queue_len: 0.07535557326378828
wait_time: 0.7270747268845644
delay_time: 4.7579608773233835
pressure: 0.9262820512820512
total_envstep_count: 481632
total_train_sample_count: 481632
total_episode_count: 4152
total_duration: 16200.467875003815
[2025-02-20 21:58:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.55628033027386
avg_train_sample_per_sec: 30.55628033027386
avg_episode_per_sec: 0.2634162097437402
collect_time: 22.777641534805298
reward_mean: -114.27567693744163
reward_std: 4.723488101069739
reward_max: -105.16596638655459
reward_min: -120.03571428571429
queue_len: 0.07577962661634059
wait_time: 0.7292480099909108
delay_time: 4.758364894087238
pressure: 0.9308134394341292
total_envstep_count: 482328
total_train_sample_count: 482328
total_episode_count: 4158
total_duration: 16223.24551653862
[2025-02-20 21:58:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.221892500201818
avg_train_sample_per_sec: 31.221892500201818
avg_episode_per_sec: 0.269154245691395
collect_time: 22.2920503616333
reward_mean: -114.60550887021475
reward_std: 3.7182762645478333
reward_max: -107.5336134453782
reward_min: -119.90406162464983
queue_len: 0.07599834805717158
wait_time: 0.733533742851694
delay_time: 4.750533178099351
pressure: 0.9231874447391689
total_envstep_count: 483024
total_train_sample_count: 483024
total_episode_count: 4164
total_duration: 16245.537566900253
[2025-02-20 21:59:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.034192327448668
avg_train_sample_per_sec: 31.034192327448668
avg_episode_per_sec: 0.26753614075386783
collect_time: 22.426876544952393
reward_mean: -115.11041083099907
reward_std: 3.714906673939571
reward_max: -109.52100840336135
reward_min: -120.17717086834737
queue_len: 0.07633316368103386
wait_time: 0.7351750050152686
delay_time: 4.793828495128426
pressure: 0.9397656940760388
total_envstep_count: 483720
total_train_sample_count: 483720
total_episode_count: 4170
total_duration: 16267.964443445206
[2025-02-20 21:59:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30986754292042
avg_train_sample_per_sec: 31.30986754292042
avg_episode_per_sec: 0.2699126512320726
collect_time: 22.229413747787476
reward_mean: -114.90091036414566
reward_std: 4.459169414946356
reward_max: -109.86974789915965
reward_min: -123.45658263305324
queue_len: 0.0761942376420064
wait_time: 0.7309303694952782
delay_time: 4.8388408534677545
pressure: 0.9286030061892131
total_envstep_count: 484416
total_train_sample_count: 484416
total_episode_count: 4176
total_duration: 16290.193857192993
[2025-02-20 21:59:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.11416386404214
avg_train_sample_per_sec: 31.11416386404214
avg_episode_per_sec: 0.2682255505520874
collect_time: 22.36923360824585
reward_mean: -116.91223155929042
reward_std: 5.247780960236577
reward_max: -107.6155462184874
reward_min: -122.4173669467787
queue_len: 0.07752800501279206
wait_time: 0.7474446896353591
delay_time: 4.847220417127023
pressure: 0.9468390804597702
total_envstep_count: 485112
total_train_sample_count: 485112
total_episode_count: 4182
total_duration: 16312.563090801239
[2025-02-20 22:00:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.696570664390983
avg_train_sample_per_sec: 31.696570664390983
avg_episode_per_sec: 0.27324629883095675
collect_time: 21.958211421966553
reward_mean: -114.19117647058823
reward_std: 2.7905646109795934
reward_max: -111.37955182072828
reward_min: -117.40756302521012
queue_len: 0.0757235918239975
wait_time: 0.7305213309903981
delay_time: 4.717137825664316
pressure: 0.9320291777188329
total_envstep_count: 485808
total_train_sample_count: 485808
total_episode_count: 4188
total_duration: 16334.521302223206
[2025-02-20 22:00:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.32130066574656
avg_train_sample_per_sec: 31.32130066574656
avg_episode_per_sec: 0.2700112126357462
collect_time: 22.221299409866333
reward_mean: -112.6203314659197
reward_std: 2.893035284628267
reward_max: -108.42787114845937
reward_min: -117.07773109243693
queue_len: 0.07468191741771862
wait_time: 0.7155844986093464
delay_time: 4.689804072289083
pressure: 0.913240495137047
total_envstep_count: 486504
total_train_sample_count: 486504
total_episode_count: 4194
total_duration: 16356.742601633072
[2025-02-20 22:00:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.481062110552372
avg_train_sample_per_sec: 31.481062110552372
avg_episode_per_sec: 0.2713884664702791
collect_time: 22.108529806137085
reward_mean: -113.83345004668534
reward_std: 2.5794881826080815
reward_max: -109.84733893557424
reward_min: -117.7766106442577
queue_len: 0.07548637271000354
wait_time: 0.7229392972927456
delay_time: 4.778340420081552
pressure: 0.9226348364279399
total_envstep_count: 487200
total_train_sample_count: 487200
total_episode_count: 4200
total_duration: 16378.851131439209
[2025-02-20 22:01:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.205233179523937
avg_train_sample_per_sec: 31.205233179523937
avg_episode_per_sec: 0.269010630857965
collect_time: 22.303951263427734
reward_mean: -112.9423436041083
reward_std: 3.832436229890379
reward_max: -108.41246498599436
reward_min: -120.28361344537814
queue_len: 0.0748954533183742
wait_time: 0.7257090723115064
delay_time: 4.716470417158823
pressure: 0.9174403183023873
total_envstep_count: 487896
total_train_sample_count: 487896
total_episode_count: 4206
total_duration: 16401.155082702637
[2025-02-20 22:01:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.2954571936441
avg_train_sample_per_sec: 31.2954571936441
avg_episode_per_sec: 0.2697884240831388
collect_time: 22.239649534225464
reward_mean: -112.96160130718954
reward_std: 2.2319857935868064
reward_max: -109.25980392156866
reward_min: -116.00840336134455
queue_len: 0.07490822367850765
wait_time: 0.7202903376204595
delay_time: 4.7144159783169695
pressure: 0.9168877099911582
total_envstep_count: 488592
total_train_sample_count: 488592
total_episode_count: 4212
total_duration: 16423.394732236862
[2025-02-20 22:02:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.485461863348657
avg_train_sample_per_sec: 31.485461863348657
avg_episode_per_sec: 0.27142639537369534
collect_time: 22.105440378189087
reward_mean: -113.11986461251166
reward_std: 3.134763656746212
reward_max: -109.42156862745098
reward_min: -116.6050420168067
queue_len: 0.07501317281996794
wait_time: 0.7208660099760507
delay_time: 4.658683383305189
pressure: 0.9178824049513704
total_envstep_count: 489288
total_train_sample_count: 489288
total_episode_count: 4218
total_duration: 16445.50017261505
[2025-02-20 22:02:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.527950172103445
avg_train_sample_per_sec: 31.527950172103445
avg_episode_per_sec: 0.2717926738974435
collect_time: 22.075650215148926
reward_mean: -111.91269841269842
reward_std: 3.7749752355799893
reward_max: -106.68487394957984
reward_min: -118.17997198879551
queue_len: 0.0742126647299061
wait_time: 0.712037202148764
delay_time: 4.704823800845281
pressure: 0.9123563218390803
total_envstep_count: 489984
total_train_sample_count: 489984
total_episode_count: 4224
total_duration: 16467.5758228302
[2025-02-20 22:02:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.117478476309326
avg_train_sample_per_sec: 31.117478476309326
avg_episode_per_sec: 0.26825412479577004
collect_time: 22.36685085296631
reward_mean: -114.9625350140056
reward_std: 4.329667548438421
reward_max: -110.85714285714282
reward_min: -121.25420168067227
queue_len: 0.07623510279443342
wait_time: 0.7307718622373796
delay_time: 4.823900866529729
pressure: 0.9288240495137048
total_envstep_count: 490680
total_train_sample_count: 490680
total_episode_count: 4230
total_duration: 16489.942673683167
[2025-02-20 22:03:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.271558617742826
avg_train_sample_per_sec: 31.271558617742826
avg_episode_per_sec: 0.26958240187709337
collect_time: 22.256645679473877
reward_mean: -112.2010971055089
reward_std: 3.6104209972783936
reward_max: -106.08613445378147
reward_min: -117.3263305322129
queue_len: 0.07440391054741967
wait_time: 0.7129110817625017
delay_time: 4.639302701590519
pressure: 0.9133510167992926
total_envstep_count: 491376
total_train_sample_count: 491376
total_episode_count: 4236
total_duration: 16512.19931936264
[2025-02-20 22:03:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.40936447295574
avg_train_sample_per_sec: 31.40936447295574
avg_episode_per_sec: 0.2707703833875495
collect_time: 22.15899658203125
reward_mean: -114.49824929971992
reward_std: 2.172247564566835
reward_max: -110.73039215686278
reward_min: -116.55952380952382
queue_len: 0.07592722102103443
wait_time: 0.7282396159171007
delay_time: 4.8022243428950935
pressure: 0.9238505747126435
total_envstep_count: 492072
total_train_sample_count: 492072
total_episode_count: 4242
total_duration: 16534.35831594467
[2025-02-20 22:04:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.472775933245323
avg_train_sample_per_sec: 31.472775933245323
avg_episode_per_sec: 0.2713170339072873
collect_time: 22.11435055732727
reward_mean: -114.28069561157797
reward_std: 2.4548704429385375
reward_max: -110.50420168067228
reward_min: -117.89425770308122
queue_len: 0.07578295464958752
wait_time: 0.7282816420113579
delay_time: 4.778562002944041
pressure: 0.921529619805482
total_envstep_count: 492768
total_train_sample_count: 492768
total_episode_count: 4248
total_duration: 16556.472666502
[2025-02-20 22:04:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.467097870169535
avg_train_sample_per_sec: 31.467097870169535
avg_episode_per_sec: 0.2712680850876684
collect_time: 22.118340969085693
reward_mean: -114.14822595704948
reward_std: 1.9200262210710723
reward_max: -111.44747899159658
reward_min: -116.77380952380952
queue_len: 0.07569511005109382
wait_time: 0.7265845772438064
delay_time: 4.745383393001666
pressure: 0.9156719717064545
total_envstep_count: 493464
total_train_sample_count: 493464
total_episode_count: 4254
total_duration: 16578.591007471085
[2025-02-20 22:04:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.298362228517867
avg_train_sample_per_sec: 31.298362228517867
avg_episode_per_sec: 0.26981346748722296
collect_time: 22.237585306167603
reward_mean: -114.2735760971055
reward_std: 1.8379972575713646
reward_max: -112.40546218487395
reward_min: -118.03361344537814
queue_len: 0.07577823348614422
wait_time: 0.7246998268803543
delay_time: 4.800210212629676
pressure: 0.9179929266136163
total_envstep_count: 494160
total_train_sample_count: 494160
total_episode_count: 4260
total_duration: 16600.828592777252
[2025-02-20 22:05:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.258558765218886
avg_train_sample_per_sec: 31.258558765218886
avg_episode_per_sec: 0.26947033418292143
collect_time: 22.265901803970337
reward_mean: -111.15172735760969
reward_std: 2.7459375224920612
reward_max: -108.27521008403357
reward_min: -116.77450980392155
queue_len: 0.07370804201433004
wait_time: 0.7108288938917743
delay_time: 4.645102119448228
pressure: 0.899314765694076
total_envstep_count: 494856
total_train_sample_count: 494856
total_episode_count: 4266
total_duration: 16623.094494581223
[2025-02-20 22:05:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.112223647779135
avg_train_sample_per_sec: 31.112223647779135
avg_episode_per_sec: 0.26820882454982015
collect_time: 22.370628595352173
reward_mean: -114.47747432306255
reward_std: 3.599766999314006
reward_max: -109.54831932773108
reward_min: -120.28291316526612
queue_len: 0.07591344451131468
wait_time: 0.7277184304314123
delay_time: 4.866121932695896
pressure: 0.9266136162687886
total_envstep_count: 495552
total_train_sample_count: 495552
total_episode_count: 4272
total_duration: 16645.465123176575
[2025-02-20 22:05:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.283287613124322
avg_train_sample_per_sec: 31.283287613124322
avg_episode_per_sec: 0.2696835139062442
collect_time: 22.248301029205322
reward_mean: -114.66316526610642
reward_std: 1.7387205436563526
reward_max: -112.38865546218483
reward_min: -117.47478991596638
queue_len: 0.0760365817414499
wait_time: 0.725150968875614
delay_time: 4.783791609723534
pressure: 0.9279398762157381
total_envstep_count: 496248
total_train_sample_count: 496248
total_episode_count: 4278
total_duration: 16667.71342420578
[2025-02-20 22:06:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.163593355932854
avg_train_sample_per_sec: 31.163593355932854
avg_episode_per_sec: 0.2686516668614901
collect_time: 22.33375310897827
reward_mean: -112.93172268907564
reward_std: 3.1880321321204623
reward_max: -107.28291316526611
reward_min: -117.01750700280112
queue_len: 0.0748884102712703
wait_time: 0.7252467852746757
delay_time: 4.717098673712649
pressure: 0.9197612732095491
total_envstep_count: 496944
total_train_sample_count: 496944
total_episode_count: 4284
total_duration: 16690.04717731476
[2025-02-20 22:06:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6080452668639
avg_train_sample_per_sec: 31.6080452668639
avg_episode_per_sec: 0.272483148852275
collect_time: 22.019710302352905
reward_mean: -112.33286647992527
reward_std: 1.6112279555067
reward_max: -109.91946778711488
reward_min: -114.22829131652658
queue_len: 0.07449129076918123
wait_time: 0.7087827726139087
delay_time: 4.721101429762043
pressure: 0.9097038019451813
total_envstep_count: 497640
total_train_sample_count: 497640
total_episode_count: 4290
total_duration: 16712.06688761711
[2025-02-20 22:07:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.435322021077045
avg_train_sample_per_sec: 31.435322021077045
avg_episode_per_sec: 0.2709941553541125
collect_time: 22.14069890975952
reward_mean: -112.12021475256769
reward_std: 2.5548667388123474
reward_max: -108.43837535014003
reward_min: -115.9754901960784
queue_len: 0.0743502750348592
wait_time: 0.7158233430419029
delay_time: 4.687379061665259
pressure: 0.9024093722369585
total_envstep_count: 498336
total_train_sample_count: 498336
total_episode_count: 4296
total_duration: 16734.20758652687
[2025-02-20 22:07:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.34544431861942
avg_train_sample_per_sec: 31.34544431861942
avg_episode_per_sec: 0.2702193475743054
collect_time: 22.20418357849121
reward_mean: -113.21346872082165
reward_std: 4.153195656223109
reward_max: -107.24789915966386
reward_min: -119.80532212885151
queue_len: 0.07507524450982868
wait_time: 0.7178364161756657
delay_time: 4.735697453127357
pressure: 0.9147877984084881
total_envstep_count: 499032
total_train_sample_count: 499032
total_episode_count: 4302
total_duration: 16756.411770105362
[2025-02-20 22:07:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.437008211116794
avg_train_sample_per_sec: 31.437008211116794
avg_episode_per_sec: 0.2710086914751448
collect_time: 22.139511346817017
reward_mean: -111.74439775910365
reward_std: 2.0423972103886676
reward_max: -108.35784313725492
reward_min: -115.13795518207276
queue_len: 0.07410105952195202
wait_time: 0.7058262407527112
delay_time: 4.664471269143635
pressure: 0.902077807250221
total_envstep_count: 499728
total_train_sample_count: 499728
total_episode_count: 4308
total_duration: 16778.55128145218
[2025-02-20 22:08:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.38241737861236
avg_train_sample_per_sec: 31.38241737861236
avg_episode_per_sec: 0.27053808085010655
collect_time: 22.17802381515503
reward_mean: -112.8471055088702
reward_std: 1.6135956531022202
reward_max: -110.72408963585431
reward_min: -116.10154061624648
queue_len: 0.07483229808280517
wait_time: 0.7172586541247798
delay_time: 4.777327012834267
pressure: 0.9090406719717063
total_envstep_count: 500424
total_train_sample_count: 500424
total_episode_count: 4314
total_duration: 16800.729305267334
[2025-02-20 22:08:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.371567671065083
avg_train_sample_per_sec: 31.371567671065083
avg_episode_per_sec: 0.2704445488884921
collect_time: 22.185693979263306
reward_mean: -113.1295518207283
reward_std: 0.9858358935920132
reward_max: -111.93067226890753
reward_min: -114.56372549019606
queue_len: 0.0750195966980957
wait_time: 0.7210256007796576
delay_time: 4.687107519018118
pressure: 0.9197612732095491
total_envstep_count: 501120
total_train_sample_count: 501120
total_episode_count: 4320
total_duration: 16822.914999246597
[2025-02-20 22:08:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.514163064331118
avg_train_sample_per_sec: 31.514163064331118
avg_episode_per_sec: 0.27167381952009584
collect_time: 22.085308074951172
reward_mean: -110.44759570494865
reward_std: 2.1689617850173373
reward_max: -108.74579831932768
reward_min: -113.8340336134454
queue_len: 0.07324111121017816
wait_time: 0.6997453822377758
delay_time: 4.642346625463406
pressure: 0.89710433244916
total_envstep_count: 501816
total_train_sample_count: 501816
total_episode_count: 4326
total_duration: 16845.00030732155
[2025-02-20 22:09:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.251697376733965
avg_train_sample_per_sec: 31.251697376733965
avg_episode_per_sec: 0.26941118428218935
collect_time: 22.270790338516235
reward_mean: -110.17460317460318
reward_std: 2.1447776916551216
reward_max: -107.10504201680668
reward_min: -112.5042016806723
queue_len: 0.07306008168077134
wait_time: 0.7012121161461932
delay_time: 4.5702431098073815
pressure: 0.9018567639257294
total_envstep_count: 502512
total_train_sample_count: 502512
total_episode_count: 4332
total_duration: 16867.271097660065
[2025-02-20 22:09:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.332545743139903
avg_train_sample_per_sec: 31.332545743139903
avg_episode_per_sec: 0.27010815295810264
collect_time: 22.213324308395386
reward_mean: -113.14052287581698
reward_std: 3.144033695578603
reward_max: -107.749299719888
reward_min: -117.32983193277312
queue_len: 0.07502687193356565
wait_time: 0.7190630673135745
delay_time: 4.707047843320317
pressure: 0.9130194518125553
total_envstep_count: 503208
total_train_sample_count: 503208
total_episode_count: 4338
total_duration: 16889.48442196846
[2025-02-20 22:10:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.15465516132759
avg_train_sample_per_sec: 31.15465516132759
avg_episode_per_sec: 0.2685746134597206
collect_time: 22.340160608291626
reward_mean: -113.27275910364146
reward_std: 3.6816152646058495
reward_max: -108.95378151260499
reward_min: -120.09453781512607
queue_len: 0.07511456173981529
wait_time: 0.7276336042816774
delay_time: 4.704827040706317
pressure: 0.930371352785146
total_envstep_count: 503904
total_train_sample_count: 503904
total_episode_count: 4344
total_duration: 16911.82458257675
[2025-02-20 22:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.976150946497054
avg_train_sample_per_sec: 30.976150946497054
avg_episode_per_sec: 0.26703578402152633
collect_time: 22.46889877319336
reward_mean: -114.30520541549953
reward_std: 3.011662843120943
reward_max: -111.44327731092439
reward_min: -118.86064425770306
queue_len: 0.0757992078352119
wait_time: 0.7303924664472331
delay_time: 4.755631501272703
pressure: 0.93368700265252
total_envstep_count: 504600
total_train_sample_count: 504600
total_episode_count: 4350
total_duration: 16934.293481349945
[2025-02-20 22:10:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.782870106803088
avg_train_sample_per_sec: 30.782870106803088
avg_episode_per_sec: 0.2653695698862335
collect_time: 22.60997748374939
reward_mean: -112.81524276377218
reward_std: 4.641580644673782
reward_max: -105.23669467787116
reward_min: -120.28711484593836
queue_len: 0.07481116894149348
wait_time: 0.7137863545064356
delay_time: 4.714764812815932
pressure: 0.919871794871795
total_envstep_count: 505296
total_train_sample_count: 505296
total_episode_count: 4356
total_duration: 16956.903458833694
[2025-02-20 22:11:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.582350874039992
avg_train_sample_per_sec: 31.582350874039992
avg_episode_per_sec: 0.272261645465862
collect_time: 22.037624835968018
reward_mean: -113.93382352941175
reward_std: 2.628337527231551
reward_max: -110.39775910364145
reward_min: -117.75420168067227
queue_len: 0.07555293337494147
wait_time: 0.726482569154983
delay_time: 4.7764078670975465
pressure: 0.928050397877984
total_envstep_count: 505992
total_train_sample_count: 505992
total_episode_count: 4362
total_duration: 16978.941083669662
[2025-02-20 22:11:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67986106523081
avg_train_sample_per_sec: 31.67986106523081
avg_episode_per_sec: 0.27310225056233456
collect_time: 21.96979331970215
reward_mean: -111.91900093370684
reward_std: 2.424709267157326
reward_max: -108.40476190476193
reward_min: -115.41526610644257
queue_len: 0.07421684412049524
wait_time: 0.705876857816513
delay_time: 4.672246363891671
pressure: 0.9015251989389922
total_envstep_count: 506688
total_train_sample_count: 506688
total_episode_count: 4368
total_duration: 17000.910876989365
[2025-02-20 22:11:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.371147607004996
avg_train_sample_per_sec: 31.371147607004996
avg_episode_per_sec: 0.2704409276465948
collect_time: 22.185991048812866
reward_mean: -112.41514939309057
reward_std: 1.518639158688452
reward_max: -110.15266106442576
reward_min: -115.20658263305324
queue_len: 0.07454585503520594
wait_time: 0.7115138495716589
delay_time: 4.6867635353855315
pressure: 0.9150088417329797
total_envstep_count: 507384
total_train_sample_count: 507384
total_episode_count: 4374
total_duration: 17023.096868038177
[2025-02-20 22:12:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.452634296785494
avg_train_sample_per_sec: 31.452634296785494
avg_episode_per_sec: 0.2711433991102198
collect_time: 22.128512144088745
reward_mean: -110.67763772175535
reward_std: 2.4946568829259124
reward_max: -107.48459383753496
reward_min: -115.5567226890756
queue_len: 0.07339365896668128
wait_time: 0.7051038253497685
delay_time: 4.632184502737582
pressure: 0.8966622458001768
total_envstep_count: 508080
total_train_sample_count: 508080
total_episode_count: 4380
total_duration: 17045.225380182266
[2025-02-20 22:12:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.353745405298984
avg_train_sample_per_sec: 31.353745405298984
avg_episode_per_sec: 0.27029090866637057
collect_time: 22.198304891586304
reward_mean: -109.63993930905697
reward_std: 3.120173341187165
reward_max: -105.8578431372549
reward_min: -114.36624649859944
queue_len: 0.07270553004579373
wait_time: 0.6926983879316538
delay_time: 4.562774954102387
pressure: 0.8979885057471263
total_envstep_count: 508776
total_train_sample_count: 508776
total_episode_count: 4386
total_duration: 17067.423685073853
[2025-02-20 22:13:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.27059388059762
avg_train_sample_per_sec: 31.27059388059762
avg_episode_per_sec: 0.2695740851775657
collect_time: 22.25733232498169
reward_mean: -110.37885154061622
reward_std: 2.3710033388141256
reward_max: -107.36414565826327
reward_min: -113.85294117647058
queue_len: 0.07319552489430785
wait_time: 0.6981641794648895
delay_time: 4.594168639144422
pressure: 0.8934571175950486
total_envstep_count: 509472
total_train_sample_count: 509472
total_episode_count: 4392
total_duration: 17089.681017398834
[2025-02-20 22:13:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.50984813770292
avg_train_sample_per_sec: 31.50984813770292
avg_episode_per_sec: 0.2716366218767493
collect_time: 22.088332414627075
reward_mean: -110.16468253968257
reward_std: 1.3406007205983825
reward_max: -107.44677871148461
reward_min: -111.25000000000004
queue_len: 0.07305350301039958
wait_time: 0.6970413165266106
delay_time: 4.568551091636552
pressure: 0.9047303271441202
total_envstep_count: 510168
total_train_sample_count: 510168
total_episode_count: 4398
total_duration: 17111.76934981346
[2025-02-20 22:13:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.022815168199113
avg_train_sample_per_sec: 31.022815168199113
avg_episode_per_sec: 0.26743806179481994
collect_time: 22.43510127067566
reward_mean: -114.12453314659194
reward_std: 2.149768069851221
reward_max: -111.19397759103641
reward_min: -117.20938375350144
queue_len: 0.07567939863832358
wait_time: 0.7254717758013904
delay_time: 4.7824612222926985
pressure: 0.9250663129973474
total_envstep_count: 510864
total_train_sample_count: 510864
total_episode_count: 4404
total_duration: 17134.204451084137
[2025-02-20 22:14:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62414199084005
avg_train_sample_per_sec: 31.62414199084005
avg_episode_per_sec: 0.27262191371413835
collect_time: 22.00850224494934
reward_mean: -112.56174136321192
reward_std: 2.989486896942248
reward_max: -106.59313725490192
reward_min: -115.52380952380948
queue_len: 0.07464306456446415
wait_time: 0.7119937055281883
delay_time: 4.734476779678474
pressure: 0.9164456233421752
total_envstep_count: 511560
total_train_sample_count: 511560
total_episode_count: 4410
total_duration: 17156.212953329086
[2025-02-20 22:14:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49954505767674
avg_train_sample_per_sec: 31.49954505767674
avg_episode_per_sec: 0.2715478022213512
collect_time: 22.09555721282959
reward_mean: -111.60340802987861
reward_std: 3.9694956658403178
reward_max: -106.3235294117647
reward_min: -118.87114845938372
queue_len: 0.0740075650065508
wait_time: 0.7145028878041049
delay_time: 4.593843204521538
pressure: 0.9088196286472149
total_envstep_count: 512256
total_train_sample_count: 512256
total_episode_count: 4416
total_duration: 17178.308510541916
[2025-02-20 22:14:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.506458254144086
avg_train_sample_per_sec: 31.506458254144086
avg_episode_per_sec: 0.2716073987426214
collect_time: 22.09070897102356
reward_mean: -109.63328664799252
reward_std: 2.5275354046151914
reward_max: -107.20518207282907
reward_min: -113.4859943977591
queue_len: 0.07270111846683854
wait_time: 0.6901823947969993
delay_time: 4.62355841342531
pressure: 0.8854995579133509
total_envstep_count: 512952
total_train_sample_count: 512952
total_episode_count: 4422
total_duration: 17200.39921951294
[2025-02-20 22:15:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.23641431563939
avg_train_sample_per_sec: 31.23641431563939
avg_episode_per_sec: 0.269279433755512
collect_time: 22.281686782836914
reward_mean: -109.51575630252101
reward_std: 3.1894917820511157
reward_max: -106.19537815126048
reward_min: -115.56092436974788
queue_len: 0.07262318057196353
wait_time: 0.6954803141415716
delay_time: 4.607037840685149
pressure: 0.8863837312113173
total_envstep_count: 513648
total_train_sample_count: 513648
total_episode_count: 4428
total_duration: 17222.680906295776
[2025-02-20 22:15:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.765918416405135
avg_train_sample_per_sec: 31.765918416405135
avg_episode_per_sec: 0.2738441242793546
collect_time: 21.910274744033813
reward_mean: -112.12359943977594
reward_std: 2.624383559067381
reward_max: -108.2198879551821
reward_min: -116.60854341736697
queue_len: 0.07435251952239783
wait_time: 0.7123065406533967
delay_time: 4.628871794442499
pressure: 0.9178824049513703
total_envstep_count: 514344
total_train_sample_count: 514344
total_episode_count: 4434
total_duration: 17244.59118103981
[2025-02-20 22:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.433209207121823
avg_train_sample_per_sec: 31.433209207121823
avg_episode_per_sec: 0.27097594144070536
collect_time: 22.142187118530273
reward_mean: -112.06699346405226
reward_std: 4.589251590025413
reward_max: -105.28011204481788
reward_min: -117.69397759103643
queue_len: 0.07431498240321768
wait_time: 0.7133060341731742
delay_time: 4.74156320696828
pressure: 0.9101458885941645
total_envstep_count: 515040
total_train_sample_count: 515040
total_episode_count: 4440
total_duration: 17266.73336815834
[2025-02-20 22:16:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.853053859705184
avg_train_sample_per_sec: 30.853053859705184
avg_episode_per_sec: 0.2659746022388378
collect_time: 22.558544874191284
reward_mean: -113.04458450046685
reward_std: 1.8821263467435903
reward_max: -109.58473389355743
reward_min: -115.82212885154063
queue_len: 0.0749632523212645
wait_time: 0.719205398781971
delay_time: 4.746541774152509
pressure: 0.91710875331565
total_envstep_count: 515736
total_train_sample_count: 515736
total_episode_count: 4446
total_duration: 17289.29191303253
[2025-02-20 22:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.582767729339412
avg_train_sample_per_sec: 31.582767729339412
avg_episode_per_sec: 0.2722652390460294
collect_time: 22.037333965301514
reward_mean: -109.82574696545284
reward_std: 2.6872815188440855
reward_max: -104.07563025210084
reward_min: -112.56232492997196
queue_len: 0.07282874467205096
wait_time: 0.6972933956960327
delay_time: 4.6488848504580025
pressure: 0.887709991158267
total_envstep_count: 516432
total_train_sample_count: 516432
total_episode_count: 4452
total_duration: 17311.329246997833
[2025-02-20 22:17:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.495410149082318
avg_train_sample_per_sec: 31.495410149082318
avg_episode_per_sec: 0.2715121564576062
collect_time: 22.09845805168152
reward_mean: -113.9889122315593
reward_std: 4.488158218368252
reward_max: -107.15756302521011
reward_min: -119.29271708683474
queue_len: 0.07558946434453534
wait_time: 0.7250562360222603
delay_time: 4.753389731416918
pressure: 0.9221927497789567
total_envstep_count: 517128
total_train_sample_count: 517128
total_episode_count: 4458
total_duration: 17333.427705049515
[2025-02-20 22:17:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.517071756831957
avg_train_sample_per_sec: 31.517071756831957
avg_episode_per_sec: 0.2716988944554479
collect_time: 22.083269834518433
reward_mean: -112.18183940242763
reward_std: 3.828555634208557
reward_max: -107.0252100840336
reward_min: -119.1239495798319
queue_len: 0.07439114018728625
wait_time: 0.7084657580981112
delay_time: 4.748906855189123
pressure: 0.907161803713528
total_envstep_count: 517824
total_train_sample_count: 517824
total_episode_count: 4464
total_duration: 17355.510974884033
[2025-02-20 22:18:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52328493504789
avg_train_sample_per_sec: 31.52328493504789
avg_episode_per_sec: 0.27175245633661976
collect_time: 22.078917264938354
reward_mean: -111.04014939309059
reward_std: 3.029061703349185
reward_max: -106.38585434173673
reward_min: -115.3389355742297
queue_len: 0.0736340513216781
wait_time: 0.7043059487278555
delay_time: 4.658486283016125
pressure: 0.8929045092838196
total_envstep_count: 518520
total_train_sample_count: 518520
total_episode_count: 4470
total_duration: 17377.58989214897
[2025-02-20 22:18:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.342682641104613
avg_train_sample_per_sec: 31.342682641104613
avg_episode_per_sec: 0.2701955400095225
collect_time: 22.20614004135132
reward_mean: -111.85959383753503
reward_std: 3.8034034513240496
reward_max: -107.53501400560226
reward_min: -118.4075630252101
queue_len: 0.07417744949438661
wait_time: 0.7087083175445245
delay_time: 4.631737966586994
pressure: 0.9100353669319188
total_envstep_count: 519216
total_train_sample_count: 519216
total_episode_count: 4476
total_duration: 17399.796032190323
[2025-02-20 22:18:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.513797686950852
avg_train_sample_per_sec: 31.513797686950852
avg_episode_per_sec: 0.27167066971509357
collect_time: 22.085564136505127
reward_mean: -110.18300653594771
reward_std: 1.9891064144410968
reward_max: -107.33193277310929
reward_min: -113.11764705882348
queue_len: 0.07306565420155685
wait_time: 0.6977169846718528
delay_time: 4.588558426900219
pressure: 0.8888152077807251
total_envstep_count: 519912
total_train_sample_count: 519912
total_episode_count: 4482
total_duration: 17421.881596326828
[2025-02-20 22:19:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.193178983759946
avg_train_sample_per_sec: 31.193178983759946
avg_episode_per_sec: 0.2689067153772409
collect_time: 22.312570333480835
reward_mean: -112.25268440709614
reward_std: 4.790984685799399
reward_max: -107.19327731092437
reward_min: -121.18837535014005
queue_len: 0.07443811963335288
wait_time: 0.7167579012153048
delay_time: 4.678906229768542
pressure: 0.9166666666666666
total_envstep_count: 520608
total_train_sample_count: 520608
total_episode_count: 4488
total_duration: 17444.19416666031
[2025-02-20 22:19:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54118907969006
avg_train_sample_per_sec: 31.54118907969006
avg_episode_per_sec: 0.2719068024111212
collect_time: 22.066384315490723
reward_mean: -111.24346405228756
reward_std: 1.1410674718044012
reward_max: -109.52100840336135
reward_min: -113.22969187675066
queue_len: 0.07376887536623845
wait_time: 0.7024203470070609
delay_time: 4.694263040133328
pressure: 0.8986516357206012
total_envstep_count: 521304
total_train_sample_count: 521304
total_episode_count: 4494
total_duration: 17466.2605509758
[2025-02-20 22:19:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.201078796855235
avg_train_sample_per_sec: 31.201078796855235
avg_episode_per_sec: 0.2689748172142693
collect_time: 22.306921005249023
reward_mean: -109.71568627450979
reward_std: 2.950884366581372
reward_max: -104.43627450980392
reward_min: -113.7464985994398
queue_len: 0.07275576012898528
wait_time: 0.6932681781819713
delay_time: 4.628314910846952
pressure: 0.8891467727674623
total_envstep_count: 522000
total_train_sample_count: 522000
total_episode_count: 4500
total_duration: 17488.56747198105
[2025-02-20 22:20:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70140507337273
avg_train_sample_per_sec: 31.70140507337273
avg_episode_per_sec: 0.2732879747704546
collect_time: 21.95486283302307
reward_mean: -112.43090569561157
reward_std: 2.061179222427027
reward_max: -110.28291316526611
reward_min: -116.39425770308122
queue_len: 0.07455630351167876
wait_time: 0.7152296373898809
delay_time: 4.678981180626306
pressure: 0.9157824933687002
total_envstep_count: 522696
total_train_sample_count: 522696
total_episode_count: 4506
total_duration: 17510.52233481407
[2025-02-20 22:20:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.222141276520595
avg_train_sample_per_sec: 31.222141276520595
avg_episode_per_sec: 0.26915639031483274
collect_time: 22.29187273979187
reward_mean: -108.49638188608776
reward_std: 1.9427221983135547
reward_max: -104.39775910364146
reward_min: -109.99859943977589
queue_len: 0.07194720284223327
wait_time: 0.6928135533612205
delay_time: 4.578679265423204
pressure: 0.8818523430592395
total_envstep_count: 523392
total_train_sample_count: 523392
total_episode_count: 4512
total_duration: 17532.814207553864
[2025-02-20 22:21:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.526540548218172
avg_train_sample_per_sec: 31.526540548218172
avg_episode_per_sec: 0.27178052196739805
collect_time: 22.076637268066406
reward_mean: -110.33800186741365
reward_std: 2.811150682966196
reward_max: -106.65266106442576
reward_min: -115.5539215686275
queue_len: 0.07316843625160056
wait_time: 0.7019397944854334
delay_time: 4.6643489972306025
pressure: 0.8956675508399647
total_envstep_count: 524088
total_train_sample_count: 524088
total_episode_count: 4518
total_duration: 17554.89084482193
[2025-02-20 22:21:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.441075987701897
avg_train_sample_per_sec: 31.441075987701897
avg_episode_per_sec: 0.27104375851467155
collect_time: 22.13664698600769
reward_mean: -111.57457983193274
reward_std: 3.8941838829179236
reward_max: -106.85784313725486
reward_min: -117.8109243697479
queue_len: 0.07398844816441164
wait_time: 0.7051290564855472
delay_time: 4.648795195404629
pressure: 0.9103669319186559
total_envstep_count: 524784
total_train_sample_count: 524784
total_episode_count: 4524
total_duration: 17577.027491807938
[2025-02-20 22:21:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5760570132551
avg_train_sample_per_sec: 31.5760570132551
avg_episode_per_sec: 0.2722073880453026
collect_time: 22.042017459869385
reward_mean: -111.63176937441642
reward_std: 2.2431459521528594
reward_max: -108.39915966386555
reward_min: -114.50070028011206
queue_len: 0.07402637226420188
wait_time: 0.7081740521142142
delay_time: 4.670728403231634
pressure: 0.9052829354553492
total_envstep_count: 525480
total_train_sample_count: 525480
total_episode_count: 4530
total_duration: 17599.069509267807
[2025-02-20 22:22:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.390920001034882
avg_train_sample_per_sec: 31.390920001034882
avg_episode_per_sec: 0.2706113793192662
collect_time: 22.172016620635986
reward_mean: -112.01890756302521
reward_std: 2.3615600254115185
reward_max: -109.36204481792717
reward_min: -115.74649859943976
queue_len: 0.0742830952009451
wait_time: 0.705669204021131
delay_time: 4.678259267849742
pressure: 0.9093722369584438
total_envstep_count: 526176
total_train_sample_count: 526176
total_episode_count: 4536
total_duration: 17621.241525888443
[2025-02-20 22:22:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.05676321341876
avg_train_sample_per_sec: 31.05676321341876
avg_episode_per_sec: 0.2677307173570583
collect_time: 22.410577535629272
reward_mean: -112.20144724556486
reward_std: 2.964426209972852
reward_max: -108.18627450980398
reward_min: -116.13515406162462
queue_len: 0.07440414273578572
wait_time: 0.7143350930115636
delay_time: 4.726042159610812
pressure: 0.9156719717064545
total_envstep_count: 526872
total_train_sample_count: 526872
total_episode_count: 4542
total_duration: 17643.652103424072
[2025-02-20 22:22:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.07230717253722
avg_train_sample_per_sec: 31.07230717253722
avg_episode_per_sec: 0.2678647170046312
collect_time: 22.39936661720276
reward_mean: -111.75805322128853
reward_std: 1.6711922737568705
reward_max: -110.04761904761907
reward_min: -114.84173669467788
queue_len: 0.07411011486822848
wait_time: 0.7083415373222675
delay_time: 4.743491677318072
pressure: 0.9022988505747126
total_envstep_count: 527568
total_train_sample_count: 527568
total_episode_count: 4548
total_duration: 17666.051470041275
[2025-02-20 22:23:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.351395728501725
avg_train_sample_per_sec: 31.351395728501725
avg_episode_per_sec: 0.27027065283191143
collect_time: 22.199968576431274
reward_mean: -113.71195144724555
reward_std: 4.751000977225306
reward_max: -109.7051820728291
reward_min: -123.75980392156866
queue_len: 0.07540580334697981
wait_time: 0.7241818146356686
delay_time: 4.746221065982566
pressure: 0.9256189213085765
total_envstep_count: 528264
total_train_sample_count: 528264
total_episode_count: 4554
total_duration: 17688.251438617706
[2025-02-20 22:23:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.586629972723646
avg_train_sample_per_sec: 31.586629972723646
avg_episode_per_sec: 0.27229853424761763
collect_time: 22.034639358520508
reward_mean: -113.46498599439775
reward_std: 4.002877894065238
reward_max: -109.7892156862745
reward_min: -120.77871148459384
queue_len: 0.07524203315278366
wait_time: 0.7204811190612407
delay_time: 4.805594153231275
pressure: 0.9223032714412026
total_envstep_count: 528960
total_train_sample_count: 528960
total_episode_count: 4560
total_duration: 17710.286077976227
[2025-02-20 22:24:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89890486970207
avg_train_sample_per_sec: 31.89890486970207
avg_episode_per_sec: 0.27499055922156956
collect_time: 21.818930864334106
reward_mean: -112.21883753501402
reward_std: 3.1998092846076758
reward_max: -105.94887955182077
reward_min: -115.53571428571428
queue_len: 0.07441567475796686
wait_time: 0.7120777577167029
delay_time: 4.7008314385979695
pressure: 0.9148983200707339
total_envstep_count: 529656
total_train_sample_count: 529656
total_episode_count: 4566
total_duration: 17732.10500884056
[2025-02-20 22:24:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.485306589242672
avg_train_sample_per_sec: 30.485306589242672
avg_episode_per_sec: 0.26280436714864375
collect_time: 22.830670833587646
reward_mean: -110.17168534080298
reward_std: 3.982050919387971
reward_max: -104.39845938375346
reward_min: -114.55322128851543
queue_len: 0.07305814677772082
wait_time: 0.6956586348067079
delay_time: 4.681651499245906
pressure: 0.8980990274093722
total_envstep_count: 530352
total_train_sample_count: 530352
total_episode_count: 4572
total_duration: 17754.93567967415
[2025-02-20 22:24:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.103212822993424
avg_train_sample_per_sec: 31.103212822993424
avg_episode_per_sec: 0.2681311450258054
collect_time: 22.37710952758789
reward_mean: -113.02731092436973
reward_std: 2.905128059978225
reward_max: -106.7955182072829
reward_min: -115.84173669467785
queue_len: 0.0749517976952054
wait_time: 0.7194486547934824
delay_time: 4.665304507946911
pressure: 0.9209770114942528
total_envstep_count: 531048
total_train_sample_count: 531048
total_episode_count: 4578
total_duration: 17777.312789201736
[2025-02-20 22:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.661164594108698
avg_train_sample_per_sec: 31.661164594108698
avg_episode_per_sec: 0.27294107408714396
collect_time: 21.98276686668396
reward_mean: -111.60224089635854
reward_std: 4.122114201276477
reward_max: -105.44607843137256
reward_min: -117.49929971988794
queue_len: 0.07400679104533059
wait_time: 0.7086512766025951
delay_time: 4.6743113221259085
pressure: 0.9097038019451813
total_envstep_count: 531744
total_train_sample_count: 531744
total_episode_count: 4584
total_duration: 17799.29555606842
[2025-02-20 22:25:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81031866343632
avg_train_sample_per_sec: 31.81031866343632
avg_episode_per_sec: 0.27422688502962345
collect_time: 21.879692792892456
reward_mean: -108.87103174603175
reward_std: 2.5565772461216896
reward_max: -105.48179271708683
reward_min: -113.81022408963581
queue_len: 0.07219564439392025
wait_time: 0.6885090906389081
delay_time: 4.551981980480264
pressure: 0.8874889478337754
total_envstep_count: 532440
total_train_sample_count: 532440
total_episode_count: 4590
total_duration: 17821.175248861313
[2025-02-20 22:25:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.429397586044544
avg_train_sample_per_sec: 31.429397586044544
avg_episode_per_sec: 0.270943082638315
collect_time: 22.144872426986694
reward_mean: -110.69281045751633
reward_std: 1.6191000517056735
reward_max: -108.42226890756297
reward_min: -113.04131652661067
queue_len: 0.07340372046254398
wait_time: 0.7008879811871699
delay_time: 4.60085863138634
pressure: 0.9074933687002652
total_envstep_count: 533136
total_train_sample_count: 533136
total_episode_count: 4596
total_duration: 17843.3201212883
[2025-02-20 22:26:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44288640886277
avg_train_sample_per_sec: 31.44288640886277
avg_episode_per_sec: 0.2710593655936446
collect_time: 22.135372400283813
reward_mean: -113.03524743230626
reward_std: 3.1118722293564773
reward_max: -110.68207282913167
reward_min: -119.6988795518208
queue_len: 0.07495706063150283
wait_time: 0.7227124492591023
delay_time: 4.735595235630951
pressure: 0.9195402298850573
total_envstep_count: 533832
total_train_sample_count: 533832
total_episode_count: 4602
total_duration: 17865.455493688583
[2025-02-20 22:26:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.306732736880424
avg_train_sample_per_sec: 31.306732736880424
avg_episode_per_sec: 0.26988562704207264
collect_time: 22.231639623641968
reward_mean: -110.30088702147525
reward_std: 1.9952017088948097
reward_max: -107.86064425770307
reward_min: -113.44327731092437
queue_len: 0.07314382428479792
wait_time: 0.7045777639083927
delay_time: 4.687120325416139
pressure: 0.8929045092838196
total_envstep_count: 534528
total_train_sample_count: 534528
total_episode_count: 4608
total_duration: 17887.687133312225
[2025-02-20 22:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.303052759981032
avg_train_sample_per_sec: 31.303052759981032
avg_episode_per_sec: 0.2698539031032848
collect_time: 22.23425316810608
reward_mean: -110.64729225023343
reward_std: 3.4849380185951815
reward_max: -106.15616246498602
reward_min: -116.25280112044815
queue_len: 0.07337353597495587
wait_time: 0.7049309998092959
delay_time: 4.705808107142265
pressure: 0.9063881520778073
total_envstep_count: 535224
total_train_sample_count: 535224
total_episode_count: 4614
total_duration: 17909.92138648033
[2025-02-20 22:27:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.073027195507418
avg_train_sample_per_sec: 31.073027195507418
avg_episode_per_sec: 0.2678709240992019
collect_time: 22.398847579956055
reward_mean: -110.84010270774974
reward_std: 3.467144888394818
reward_max: -107.04761904761905
reward_min: -118.15406162464987
queue_len: 0.07350139436853433
wait_time: 0.7005702701062743
delay_time: 4.7331665894233135
pressure: 0.8997568523430592
total_envstep_count: 535920
total_train_sample_count: 535920
total_episode_count: 4620
total_duration: 17932.320234060287
[2025-02-20 22:27:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.556136057045517
avg_train_sample_per_sec: 31.556136057045517
avg_episode_per_sec: 0.27203565566418547
collect_time: 22.05593228340149
reward_mean: -109.06244164332396
reward_std: 1.7648458594920144
reward_max: -107.3473389355742
reward_min: -112.11274509803917
queue_len: 0.07232257403403448
wait_time: 0.688134029031595
delay_time: 4.608260070534812
pressure: 0.8829575596816976
total_envstep_count: 536616
total_train_sample_count: 536616
total_episode_count: 4626
total_duration: 17954.37616634369
[2025-02-20 22:28:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.533303464627636
avg_train_sample_per_sec: 31.533303464627636
avg_episode_per_sec: 0.2718388229709279
collect_time: 22.07190251350403
reward_mean: -111.94012605042019
reward_std: 5.639731649518256
reward_max: -104.70518207282912
reward_min: -118.39425770308127
queue_len: 0.07423085281858102
wait_time: 0.7062836518338546
delay_time: 4.701387241911874
pressure: 0.90263041556145
total_envstep_count: 537312
total_train_sample_count: 537312
total_episode_count: 4632
total_duration: 17976.448068857193
[2025-02-20 22:28:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.509008080517876
avg_train_sample_per_sec: 31.509008080517876
avg_episode_per_sec: 0.27162938000446446
collect_time: 22.088921308517456
reward_mean: -111.83286647992531
reward_std: 3.0416530677684785
reward_max: -108.91806722689073
reward_min: -118.40686274509802
queue_len: 0.07415972578244383
wait_time: 0.705168296319412
delay_time: 4.629822591130327
pressure: 0.9083775419982318
total_envstep_count: 538008
total_train_sample_count: 538008
total_episode_count: 4638
total_duration: 17998.53699016571
[2025-02-20 22:28:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.512319934147047
avg_train_sample_per_sec: 31.512319934147047
avg_episode_per_sec: 0.2716579304667849
collect_time: 22.086599826812744
reward_mean: -113.82761437908498
reward_std: 1.5549772800020587
reward_max: -112.33963585434178
reward_min: -116.65686274509805
queue_len: 0.0754825029039025
wait_time: 0.7210985853227233
delay_time: 4.746764214756689
pressure: 0.9276083112290009
total_envstep_count: 538704
total_train_sample_count: 538704
total_episode_count: 4644
total_duration: 18020.623589992523
[2025-02-20 22:29:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.325162750543253
avg_train_sample_per_sec: 31.325162750543253
avg_episode_per_sec: 0.27004450647020045
collect_time: 22.218559741973877
reward_mean: -114.45588235294117
reward_std: 3.2450365840418582
reward_max: -109.40476190476194
reward_min: -119.32142857142856
queue_len: 0.07589912622874084
wait_time: 0.7279345204040943
delay_time: 4.711868440201498
pressure: 0.9298187444739169
total_envstep_count: 539400
total_train_sample_count: 539400
total_episode_count: 4650
total_duration: 18042.842149734497
[2025-02-20 22:29:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.229999305164522
avg_train_sample_per_sec: 31.229999305164522
avg_episode_per_sec: 0.2692241319410735
collect_time: 22.286263704299927
reward_mean: -110.58391690009337
reward_std: 2.6273007735010014
reward_max: -106.74089635854338
reward_min: -113.44187675070029
queue_len: 0.07333150988069852
wait_time: 0.7014562235150469
delay_time: 4.597636448703141
pressure: 0.8924624226348364
total_envstep_count: 540096
total_train_sample_count: 540096
total_episode_count: 4656
total_duration: 18065.128413438797
[2025-02-20 22:30:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.136238206981552
avg_train_sample_per_sec: 31.136238206981552
avg_episode_per_sec: 0.2684158466119099
collect_time: 22.35337471961975
reward_mean: -111.4640522875817
reward_std: 1.188524081007246
reward_max: -110.109943977591
reward_min: -113.31512605042015
queue_len: 0.07391515403685787
wait_time: 0.7080381445239458
delay_time: 4.6461216552142925
pressure: 0.9049513704686118
total_envstep_count: 540792
total_train_sample_count: 540792
total_episode_count: 4662
total_duration: 18087.481788158417
[2025-02-20 22:30:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53558544130647
avg_train_sample_per_sec: 31.53558544130647
avg_episode_per_sec: 0.27185849518367644
collect_time: 22.070305347442627
reward_mean: -111.49031279178338
reward_std: 2.9934606689272374
reward_max: -107.30252100840333
reward_min: -116.77521008403362
queue_len: 0.07393256816431258
wait_time: 0.7002452837899087
delay_time: 4.647431522640557
pressure: 0.8958885941644562
total_envstep_count: 541488
total_train_sample_count: 541488
total_episode_count: 4668
total_duration: 18109.55209350586
[2025-02-20 22:30:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.396241038583426
avg_train_sample_per_sec: 31.396241038583426
avg_episode_per_sec: 0.27065725033261573
collect_time: 22.168258905410767
reward_mean: -111.94211017740429
reward_std: 1.8626639527032405
reward_max: -109.23389355742295
reward_min: -113.8564425770308
queue_len: 0.07423216855265535
wait_time: 0.7080080374324794
delay_time: 4.623814553593968
pressure: 0.9097038019451812
total_envstep_count: 542184
total_train_sample_count: 542184
total_episode_count: 4674
total_duration: 18131.72035241127
[2025-02-20 22:31:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.24635531688649
avg_train_sample_per_sec: 31.24635531688649
avg_episode_per_sec: 0.2693651320421249
collect_time: 22.274597883224487
reward_mean: -110.6155462184874
reward_std: 4.67956122988574
reward_max: -104.58123249299722
reward_min: -117.05952380952378
queue_len: 0.07335248422976616
wait_time: 0.6995080083315376
delay_time: 4.697436152373602
pressure: 0.8906940760389036
total_envstep_count: 542880
total_train_sample_count: 542880
total_episode_count: 4680
total_duration: 18153.994950294495
[2025-02-20 22:31:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.344003514368122
avg_train_sample_per_sec: 31.344003514368122
avg_episode_per_sec: 0.27020692684800107
collect_time: 22.205204248428345
reward_mean: -111.35410830999065
reward_std: 3.2530542282333905
reward_max: -108.17647058823528
reward_min: -118.14145658263305
queue_len: 0.07384224688991424
wait_time: 0.7043461947113062
delay_time: 4.693497812964449
pressure: 0.9066091954022988
total_envstep_count: 543576
total_train_sample_count: 543576
total_episode_count: 4686
total_duration: 18176.200154542923
[2025-02-20 22:32:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.701483220821878
avg_train_sample_per_sec: 31.701483220821878
avg_episode_per_sec: 0.273288648455361
collect_time: 21.954808712005615
reward_mean: -110.52147525676936
reward_std: 2.287022169037364
reward_max: -107.50210084033613
reward_min: -113.95798319327733
queue_len: 0.07329010295541734
wait_time: 0.6979281986888478
delay_time: 4.6735955764374095
pressure: 0.8963306808134394
total_envstep_count: 544272
total_train_sample_count: 544272
total_episode_count: 4692
total_duration: 18198.15496325493
[2025-02-20 22:32:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.158534788829318
avg_train_sample_per_sec: 31.158534788829318
avg_episode_per_sec: 0.2686080585243907
collect_time: 22.337378978729248
reward_mean: -112.04143323996264
reward_std: 3.4603217847082033
reward_max: -107.05112044817929
reward_min: -116.97338935574227
queue_len: 0.07429803265249511
wait_time: 0.7149865361706133
delay_time: 4.619436605493065
pressure: 0.9145667550839965
total_envstep_count: 544968
total_train_sample_count: 544968
total_episode_count: 4698
total_duration: 18220.492342233658
[2025-02-20 22:32:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.383990266179264
avg_train_sample_per_sec: 31.383990266179264
avg_episode_per_sec: 0.27055164022568334
collect_time: 22.176912307739258
reward_mean: -110.83496732026144
reward_std: 2.902142401580016
reward_max: -107.18557422969185
reward_min: -115.84313725490198
queue_len: 0.07349798893916541
wait_time: 0.7006887635690883
delay_time: 4.688098317099169
pressure: 0.8944518125552609
total_envstep_count: 545664
total_train_sample_count: 545664
total_episode_count: 4704
total_duration: 18242.669254541397
[2025-02-20 22:33:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.356152017180197
avg_train_sample_per_sec: 31.356152017180197
avg_episode_per_sec: 0.27031165532051893
collect_time: 22.196601152420044
reward_mean: -111.61052754435106
reward_std: 2.835252955674585
reward_max: -107.87745098039213
reward_min: -115.82002801120443
queue_len: 0.07401228616999407
wait_time: 0.7075681178749131
delay_time: 4.788771482123808
pressure: 0.8945623342175066
total_envstep_count: 546360
total_train_sample_count: 546360
total_episode_count: 4710
total_duration: 18264.865855693817
[2025-02-20 22:33:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49131267518191
avg_train_sample_per_sec: 31.49131267518191
avg_episode_per_sec: 0.2714768334067406
collect_time: 22.101333379745483
reward_mean: -110.64414098972922
reward_std: 3.4588141127606886
reward_max: -106.59803921568624
reward_min: -116.78011204481798
queue_len: 0.07337144627966129
wait_time: 0.7040914840737357
delay_time: 4.621864973508383
pressure: 0.8935676392572945
total_envstep_count: 547056
total_train_sample_count: 547056
total_episode_count: 4716
total_duration: 18286.967189073563
[2025-02-20 22:33:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.662466773497627
avg_train_sample_per_sec: 31.662466773497627
avg_episode_per_sec: 0.2729522997715313
collect_time: 21.981862783432007
reward_mean: -111.32539682539682
reward_std: 2.5057878293469167
reward_max: -107.09033613445379
reward_min: -114.09383753501405
queue_len: 0.0738232074438971
wait_time: 0.7021060413555343
delay_time: 4.639494894677126
pressure: 0.9080459770114943
total_envstep_count: 547752
total_train_sample_count: 547752
total_episode_count: 4722
total_duration: 18308.949051856995
[2025-02-20 22:34:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.468499808762633
avg_train_sample_per_sec: 31.468499808762633
avg_episode_per_sec: 0.2712801707651951
collect_time: 22.117355585098267
reward_mean: -110.89320728291318
reward_std: 1.8713381417266015
reward_max: -108.11974789915972
reward_min: -114.0035014005602
queue_len: 0.07353660960405382
wait_time: 0.7072517225280918
delay_time: 4.61286100078635
pressure: 0.9040671971706454
total_envstep_count: 548448
total_train_sample_count: 548448
total_episode_count: 4728
total_duration: 18331.066407442093
[2025-02-20 22:34:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.467190130374465
avg_train_sample_per_sec: 31.467190130374465
avg_episode_per_sec: 0.2712688804342626
collect_time: 22.118276119232178
reward_mean: -113.96043417366946
reward_std: 3.7353315066500787
reward_max: -108.05182072829135
reward_min: -117.5854341736695
queue_len: 0.07557057969076225
wait_time: 0.7278049592958314
delay_time: 4.715580981985806
pressure: 0.9291556145004422
total_envstep_count: 549144
total_train_sample_count: 549144
total_episode_count: 4734
total_duration: 18353.184683561325
[2025-02-20 22:35:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39428844280119
avg_train_sample_per_sec: 31.39428844280119
avg_episode_per_sec: 0.27064041761035507
collect_time: 22.16963768005371
reward_mean: -111.49428104575163
reward_std: 2.899915112895062
reward_max: -107.43627450980398
reward_min: -116.70378151260505
queue_len: 0.0739351996324613
wait_time: 0.7059540217501677
delay_time: 4.643828140874864
pressure: 0.9049513704686118
total_envstep_count: 549840
total_train_sample_count: 549840
total_episode_count: 4740
total_duration: 18375.35432124138
[2025-02-20 22:35:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.620432230398617
avg_train_sample_per_sec: 31.620432230398617
avg_episode_per_sec: 0.27258993302067774
collect_time: 22.01108431816101
reward_mean: -109.74451447245566
reward_std: 3.1349121899204384
reward_max: -103.29411764705884
reward_min: -112.78921568627453
queue_len: 0.07277487697112443
wait_time: 0.6940134254409104
delay_time: 4.710085919422066
pressure: 0.8812997347480107
total_envstep_count: 550536
total_train_sample_count: 550536
total_episode_count: 4746
total_duration: 18397.36540555954
[2025-02-20 22:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.651649093486004
avg_train_sample_per_sec: 31.651649093486004
avg_episode_per_sec: 0.2728590439093621
collect_time: 21.989375591278076
reward_mean: -109.43954248366013
reward_std: 2.551004778769952
reward_max: -104.48179271708686
reward_min: -112.84453781512603
queue_len: 0.0725726409042839
wait_time: 0.6916434787885093
delay_time: 4.594675467290698
pressure: 0.8817418213969938
total_envstep_count: 551232
total_train_sample_count: 551232
total_episode_count: 4752
total_duration: 18419.354781150818
[2025-02-20 22:36:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67977030406305
avg_train_sample_per_sec: 31.67977030406305
avg_episode_per_sec: 0.2731014681384746
collect_time: 21.96985626220703
reward_mean: -109.16118113912233
reward_std: 1.8754450344429985
reward_max: -106.25700280112045
reward_min: -111.52941176470587
queue_len: 0.07238805115326413
wait_time: 0.6840838125701207
delay_time: 4.629112111971009
pressure: 0.8795313881520777
total_envstep_count: 551928
total_train_sample_count: 551928
total_episode_count: 4758
total_duration: 18441.324637413025
[2025-02-20 22:36:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.232046462174004
avg_train_sample_per_sec: 31.232046462174004
avg_episode_per_sec: 0.26924177984632763
collect_time: 22.28480291366577
reward_mean: -111.6730859010271
reward_std: 1.9642970908572934
reward_max: -109.52450980392153
reward_min: -115.265406162465
queue_len: 0.07405377049139727
wait_time: 0.7108129502906378
delay_time: 4.645741194500164
pressure: 0.9139036251105216
total_envstep_count: 552624
total_train_sample_count: 552624
total_episode_count: 4764
total_duration: 18463.60944032669
[2025-02-20 22:36:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.449287204324204
avg_train_sample_per_sec: 31.449287204324204
avg_episode_per_sec: 0.2711145448648638
collect_time: 22.13086724281311
reward_mean: -111.23214285714285
reward_std: 3.105290983464697
reward_max: -108.21498599439772
reward_min: -117.62254901960786
queue_len: 0.07376136794240241
wait_time: 0.7023833516607351
delay_time: 4.60689441130867
pressure: 0.9099248452696728
total_envstep_count: 553320
total_train_sample_count: 553320
total_episode_count: 4770
total_duration: 18485.740307569504
[2025-02-20 22:37:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.279812232550526
avg_train_sample_per_sec: 31.279812232550526
avg_episode_per_sec: 0.26965355372888383
collect_time: 22.250772953033447
reward_mean: -112.37313258636789
reward_std: 3.4386561499689634
reward_max: -107.65406162464987
reward_min: -118.10924369747899
queue_len: 0.07451799243127845
wait_time: 0.7112795715103019
delay_time: 4.712238883439313
pressure: 0.9057250221043325
total_envstep_count: 554016
total_train_sample_count: 554016
total_episode_count: 4776
total_duration: 18507.991080522537
[2025-02-20 22:37:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.418657734715485
avg_train_sample_per_sec: 31.418657734715485
avg_episode_per_sec: 0.2708504977130645
collect_time: 22.15244221687317
reward_mean: -109.96626984126983
reward_std: 2.286256717335655
reward_max: -105.97058823529413
reward_min: -112.44397759103639
queue_len: 0.07292192960296408
wait_time: 0.6919566234982056
delay_time: 4.6474296272905775
pressure: 0.8881520778072503
total_envstep_count: 554712
total_train_sample_count: 554712
total_episode_count: 4782
total_duration: 18530.14352273941
[2025-02-20 22:38:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4039720957723
avg_train_sample_per_sec: 31.4039720957723
avg_episode_per_sec: 0.2707238973773474
collect_time: 22.162801504135132
reward_mean: -112.53443043884222
reward_std: 3.506297402509194
reward_max: -109.75140056022411
reward_min: -119.29341736694681
queue_len: 0.07462495387191129
wait_time: 0.7135288576084723
delay_time: 4.760621574814077
pressure: 0.9130194518125553
total_envstep_count: 555408
total_train_sample_count: 555408
total_episode_count: 4788
total_duration: 18552.306324243546
[2025-02-20 22:38:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.466186076579987
avg_train_sample_per_sec: 30.466186076579987
avg_episode_per_sec: 0.2626395351429309
collect_time: 22.844999313354492
reward_mean: -111.91643323996266
reward_std: 3.6542376447828446
reward_max: -106.7577030812325
reward_min: -118.42156862745101
queue_len: 0.07421514140581077
wait_time: 0.705680039478214
delay_time: 4.712645113474325
pressure: 0.9025198938992042
total_envstep_count: 556104
total_train_sample_count: 556104
total_episode_count: 4794
total_duration: 18575.1513235569
[2025-02-20 22:38:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44690929728304
avg_train_sample_per_sec: 31.44690929728304
avg_episode_per_sec: 0.2710940456662331
collect_time: 22.132540702819824
reward_mean: -109.38737161531282
reward_std: 2.546954433236023
reward_max: -104.06652661064426
reward_min: -111.75560224089638
queue_len: 0.07253804483774058
wait_time: 0.6944733131979582
delay_time: 4.668673046097577
pressure: 0.8908045977011493
total_envstep_count: 556800
total_train_sample_count: 556800
total_episode_count: 4800
total_duration: 18597.28386425972
[2025-02-20 22:39:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31729002622877
avg_train_sample_per_sec: 31.31729002622877
avg_episode_per_sec: 0.26997663815714457
collect_time: 22.22414517402649
reward_mean: -111.30147058823529
reward_std: 1.9800084988424551
reward_max: -109.31302521008402
reward_min: -115.07843137254903
queue_len: 0.07380734123888283
wait_time: 0.7074846074592526
delay_time: 4.626023405653538
pressure: 0.9101458885941645
total_envstep_count: 557496
total_train_sample_count: 557496
total_episode_count: 4806
total_duration: 18619.508009433746
[2025-02-20 22:39:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.63074429694891
avg_train_sample_per_sec: 31.63074429694891
avg_episode_per_sec: 0.27267883014611133
collect_time: 22.003908395767212
reward_mean: -112.7235060690943
reward_std: 2.6957973775399022
reward_max: -109.5189075630252
reward_min: -117.38375350140053
queue_len: 0.07475033558958508
wait_time: 0.714952172292436
delay_time: 4.743457741713989
pressure: 0.9121352785145889
total_envstep_count: 558192
total_train_sample_count: 558192
total_episode_count: 4812
total_duration: 18641.511917829514
[2025-02-20 22:39:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.258917243796343
avg_train_sample_per_sec: 31.258917243796343
avg_episode_per_sec: 0.2694734245154857
collect_time: 22.26564645767212
reward_mean: -113.51890756302521
reward_std: 2.7037184546171025
reward_max: -110.14425770308124
reward_min: -117.04481792717087
queue_len: 0.0752777901611573
wait_time: 0.7198047543509004
delay_time: 4.730306867461872
pressure: 0.9217506631299734
total_envstep_count: 558888
total_train_sample_count: 558888
total_episode_count: 4818
total_duration: 18663.777564287186
[2025-02-20 22:40:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69067877573383
avg_train_sample_per_sec: 31.69067877573383
avg_episode_per_sec: 0.2731955066873606
collect_time: 21.96229386329651
reward_mean: -111.91269841269839
reward_std: 2.238977304254697
reward_max: -108.65756302521004
reward_min: -114.26750700280108
queue_len: 0.0742126647299061
wait_time: 0.7114526292391404
delay_time: 4.682546124916453
pressure: 0.9076038903625109
total_envstep_count: 559584
total_train_sample_count: 559584
total_episode_count: 4824
total_duration: 18685.739858150482
[2025-02-20 22:40:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.50374224865709
avg_train_sample_per_sec: 31.50374224865709
avg_episode_per_sec: 0.2715839849022163
collect_time: 22.092613458633423
reward_mean: -111.51027077497666
reward_std: 2.721960950718768
reward_max: -107.80112044817928
reward_min: -115.75630252100837
queue_len: 0.07394580290117815
wait_time: 0.7104975610934027
delay_time: 4.617423540092655
pressure: 0.908819628647215
total_envstep_count: 560280
total_train_sample_count: 560280
total_episode_count: 4830
total_duration: 18707.832471609116
[2025-02-20 22:41:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.247782809405397
avg_train_sample_per_sec: 31.247782809405397
avg_episode_per_sec: 0.2693774380121155
collect_time: 22.273580312728882
reward_mean: -109.93779178338002
reward_std: 3.00012988075049
reward_max: -106.23039215686278
reward_min: -114.19607843137254
queue_len: 0.07290304494919099
wait_time: 0.7032045245153764
delay_time: 4.598921166893512
pressure: 0.892683465959328
total_envstep_count: 560976
total_train_sample_count: 560976
total_episode_count: 4836
total_duration: 18730.106051921844
[2025-02-20 22:41:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.201541007284025
avg_train_sample_per_sec: 31.201541007284025
avg_episode_per_sec: 0.26897880178693123
collect_time: 22.30659055709839
reward_mean: -111.49509803921568
reward_std: 3.4935989648896393
reward_max: -106.7485994397759
reward_min: -118.47549019607844
queue_len: 0.07393574140531543
wait_time: 0.712434631235341
delay_time: 4.6957225372987255
pressure: 0.9027409372236957
total_envstep_count: 561672
total_train_sample_count: 561672
total_episode_count: 4842
total_duration: 18752.412642478943
[2025-02-20 22:41:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.697511614968096
avg_train_sample_per_sec: 31.697511614968096
avg_episode_per_sec: 0.2732544104738629
collect_time: 21.95755958557129
reward_mean: -109.59803921568628
reward_std: 1.4112273516790692
reward_max: -106.6526610644258
reward_min: -110.98809523809526
queue_len: 0.07267774483798824
wait_time: 0.69490270688293
delay_time: 4.60598893844005
pressure: 0.8879310344827586
total_envstep_count: 562368
total_train_sample_count: 562368
total_episode_count: 4848
total_duration: 18774.370202064514
[2025-02-20 22:42:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.171868291321392
avg_train_sample_per_sec: 31.171868291321392
avg_episode_per_sec: 0.2687230025113913
collect_time: 22.327824354171753
reward_mean: -113.81991129785247
reward_std: 4.266740701778844
reward_max: -108.30742296918771
reward_min: -119.43487394957984
queue_len: 0.07547739475984912
wait_time: 0.7263777748057666
delay_time: 4.773353156259297
pressure: 0.9270557029177718
total_envstep_count: 563064
total_train_sample_count: 563064
total_episode_count: 4854
total_duration: 18796.698026418686
[2025-02-20 22:42:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.497388258302625
avg_train_sample_per_sec: 31.497388258302625
avg_episode_per_sec: 0.2715292091232985
collect_time: 22.09707021713257
reward_mean: -112.93370681605977
reward_std: 3.4629306039173464
reward_max: -108.4418767507003
reward_min: -118.62605042016804
queue_len: 0.07488972600534467
wait_time: 0.7221866974022145
delay_time: 4.75564583333095
pressure: 0.9213085764809903
total_envstep_count: 563760
total_train_sample_count: 563760
total_episode_count: 4860
total_duration: 18818.79509663582
[2025-02-20 22:42:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.571337580761323
avg_train_sample_per_sec: 31.571337580761323
avg_episode_per_sec: 0.2721667032824252
collect_time: 22.04531240463257
reward_mean: -111.66503267973859
reward_std: 2.121793065597705
reward_max: -107.23249299719892
reward_min: -113.93627450980394
queue_len: 0.07404843015897784
wait_time: 0.7067071634135528
delay_time: 4.663173426353392
pressure: 0.9037356321839081
total_envstep_count: 564456
total_train_sample_count: 564456
total_episode_count: 4866
total_duration: 18840.84040904045
[2025-02-20 22:43:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.537228914342833
avg_train_sample_per_sec: 31.537228914342833
avg_episode_per_sec: 0.2718726630546796
collect_time: 22.06915521621704
reward_mean: -111.56384220354806
reward_std: 2.443438389999959
reward_max: -107.28641456582632
reward_min: -114.69887955182072
queue_len: 0.07398132772118572
wait_time: 0.704719631000057
delay_time: 4.668989973011724
pressure: 0.9036251105216623
total_envstep_count: 565152
total_train_sample_count: 565152
total_episode_count: 4872
total_duration: 18862.909564256668
[2025-02-20 22:43:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.35760303307423
avg_train_sample_per_sec: 31.35760303307423
avg_episode_per_sec: 0.2703241640782261
collect_time: 22.195574045181274
reward_mean: -110.07446311858077
reward_std: 3.1959855929575363
reward_max: -103.95308123249296
reward_min: -113.5217086834734
queue_len: 0.07299367580807742
wait_time: 0.695644471316378
delay_time: 4.578997311409986
pressure: 0.8891467727674623
total_envstep_count: 565848
total_train_sample_count: 565848
total_episode_count: 4878
total_duration: 18885.10513830185
[2025-02-20 22:44:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.073187940148014
avg_train_sample_per_sec: 31.073187940148014
avg_episode_per_sec: 0.2678723098288622
collect_time: 22.39873170852661
reward_mean: -111.37756769374415
reward_std: 3.6854788578524764
reward_max: -106.46638655462183
reward_min: -115.73809523809527
queue_len: 0.07385780351044043
wait_time: 0.7030860310525625
delay_time: 4.687710879163534
pressure: 0.8995358090185678
total_envstep_count: 566544
total_train_sample_count: 566544
total_episode_count: 4884
total_duration: 18907.503870010376
[2025-02-20 22:44:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639253438906053
avg_train_sample_per_sec: 31.639253438906053
avg_episode_per_sec: 0.2727521848181556
collect_time: 21.997990608215332
reward_mean: -113.72257236227824
reward_std: 2.899848202626307
reward_max: -108.890756302521
reward_min: -118.10994397759103
queue_len: 0.0754128463940837
wait_time: 0.7246559432791684
delay_time: 4.742218994102519
pressure: 0.925950486295314
total_envstep_count: 567240
total_train_sample_count: 567240
total_episode_count: 4890
total_duration: 18929.50186061859
[2025-02-20 22:44:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.585664494197704
avg_train_sample_per_sec: 31.585664494197704
avg_episode_per_sec: 0.27229021115687674
collect_time: 22.03531289100647
reward_mean: -111.98074229691876
reward_std: 2.9018231063270115
reward_max: -107.00910364145656
reward_min: -114.98739495798324
queue_len: 0.07425778666904426
wait_time: 0.7126592347814458
delay_time: 4.699091333283557
pressure: 0.9113616268788683
total_envstep_count: 567936
total_train_sample_count: 567936
total_episode_count: 4896
total_duration: 18951.537173509598
[2025-02-20 22:45:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47555481566237
avg_train_sample_per_sec: 31.47555481566237
avg_episode_per_sec: 0.27134098979019283
collect_time: 22.112398147583008
reward_mean: -108.53034547152193
reward_std: 2.701971643336386
reward_max: -104.16666666666666
reward_min: -111.87324929971984
queue_len: 0.07196972511374133
wait_time: 0.6884227165667328
delay_time: 4.593915053654051
pressure: 0.8828470380194519
total_envstep_count: 568632
total_train_sample_count: 568632
total_episode_count: 4902
total_duration: 18973.64957165718
[2025-02-20 22:45:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.105548645663532
avg_train_sample_per_sec: 31.105548645663532
avg_episode_per_sec: 0.2681512814281339
collect_time: 22.375429153442383
reward_mean: -113.74276377217556
reward_std: 5.564151630633838
reward_max: -106.28991596638657
reward_min: -121.69397759103644
queue_len: 0.07542623592319332
wait_time: 0.7216437636062382
delay_time: 4.794747107206869
pressure: 0.9162245800176834
total_envstep_count: 569328
total_train_sample_count: 569328
total_episode_count: 4908
total_duration: 18996.025000810623
[2025-02-20 22:45:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.920911634902527
avg_train_sample_per_sec: 31.920911634902527
avg_episode_per_sec: 0.275180272714677
collect_time: 21.80388855934143
reward_mean: -109.6035247432306
reward_std: 2.914896245385062
reward_max: -106.51540616246503
reward_min: -114.24089635854337
queue_len: 0.07268138245572321
wait_time: 0.6927148733056442
delay_time: 4.588766718766945
pressure: 0.8894783377541997
total_envstep_count: 570024
total_train_sample_count: 570024
total_episode_count: 4914
total_duration: 19017.828889369965
[2025-02-20 22:46:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.529655168257403
avg_train_sample_per_sec: 31.529655168257403
avg_episode_per_sec: 0.27180737214015005
collect_time: 22.074456453323364
reward_mean: -112.7783613445378
reward_std: 3.1538212116363322
reward_max: -106.68417366946775
reward_min: -117.23809523809524
queue_len: 0.07478671176693488
wait_time: 0.7170798690829118
delay_time: 4.703064587863422
pressure: 0.9051724137931035
total_envstep_count: 570720
total_train_sample_count: 570720
total_episode_count: 4920
total_duration: 19039.903345823288
[2025-02-20 22:46:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.456580023300127
avg_train_sample_per_sec: 31.456580023300127
avg_episode_per_sec: 0.2711774139939666
collect_time: 22.125736474990845
reward_mean: -110.76295518207282
reward_std: 1.2256809742126051
reward_max: -108.29761904761905
reward_min: -111.90266106442577
queue_len: 0.07345023553187853
wait_time: 0.7018390247345624
delay_time: 4.6177719579952194
pressure: 0.8881520778072503
total_envstep_count: 571416
total_train_sample_count: 571416
total_episode_count: 4926
total_duration: 19062.02908229828
[2025-02-20 22:47:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54035041753558
avg_train_sample_per_sec: 31.54035041753558
avg_episode_per_sec: 0.2718995725649619
collect_time: 22.06697106361389
reward_mean: -110.35690943043882
reward_std: 3.3076565523880577
reward_max: -106.30462184873946
reward_min: -117.06372549019605
queue_len: 0.07318097442336793
wait_time: 0.6966558064428247
delay_time: 4.631564954698209
pressure: 0.8963306808134394
total_envstep_count: 572112
total_train_sample_count: 572112
total_episode_count: 4932
total_duration: 19084.096053361893
[2025-02-20 22:47:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.660232324186936
avg_train_sample_per_sec: 31.660232324186936
avg_episode_per_sec: 0.2729330372774736
collect_time: 21.98341417312622
reward_mean: -111.11671335200744
reward_std: 2.596008763430308
reward_max: -106.88445378151256
reward_min: -115.62114845938375
queue_len: 0.07368482317772378
wait_time: 0.7037984623557646
delay_time: 4.635456544564442
pressure: 0.8958885941644562
total_envstep_count: 572808
total_train_sample_count: 572808
total_episode_count: 4938
total_duration: 19106.07946753502
[2025-02-20 22:47:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59425744789392
avg_train_sample_per_sec: 31.59425744789392
avg_episode_per_sec: 0.27236428834391313
collect_time: 22.029319763183594
reward_mean: -112.90604575163398
reward_std: 3.239761972964392
reward_max: -106.45518207282913
reward_min: -116.95098039215682
queue_len: 0.07487138312442572
wait_time: 0.7196510456525669
delay_time: 4.666769880546304
pressure: 0.9262820512820514
total_envstep_count: 573504
total_train_sample_count: 573504
total_episode_count: 4944
total_duration: 19128.108787298203
[2025-02-20 22:48:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.826723439621833
avg_train_sample_per_sec: 31.826723439621833
avg_episode_per_sec: 0.2743683055139813
collect_time: 21.868415117263794
reward_mean: -110.04516806722688
reward_std: 2.4638589472478736
reward_max: -106.15966386554618
reward_min: -112.6596638655462
queue_len: 0.07297424938145018
wait_time: 0.6960694534223945
delay_time: 4.633695412369768
pressure: 0.8987621573828469
total_envstep_count: 574200
total_train_sample_count: 574200
total_episode_count: 4950
total_duration: 19149.977202415466
[2025-02-20 22:48:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.615701579140207
avg_train_sample_per_sec: 31.615701579140207
avg_episode_per_sec: 0.27254915154431214
collect_time: 22.01437783241272
reward_mean: -113.3563258636788
reward_std: 3.7649422415430105
reward_max: -107.57142857142853
reward_min: -117.98039215686272
queue_len: 0.07516997736318223
wait_time: 0.7203331376759369
delay_time: 4.70486958817083
pressure: 0.9215296198054818
total_envstep_count: 574896
total_train_sample_count: 574896
total_episode_count: 4956
total_duration: 19171.99158024788
[2025-02-20 22:48:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.495769663256475
avg_train_sample_per_sec: 31.495769663256475
avg_episode_per_sec: 0.2715152557177282
collect_time: 22.09820580482483
reward_mean: -113.28921568627453
reward_std: 2.5616333602729897
reward_max: -111.17717086834735
reward_min: -118.843837535014
queue_len: 0.07512547459302024
wait_time: 0.7157005153962558
delay_time: 4.741498369304414
pressure: 0.9183244916003536
total_envstep_count: 575592
total_train_sample_count: 575592
total_episode_count: 4962
total_duration: 19194.089786052704
[2025-02-20 22:49:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29751025722869
avg_train_sample_per_sec: 31.29751025722869
avg_episode_per_sec: 0.2698061229071439
collect_time: 22.23819065093994
reward_mean: -108.71078431372548
reward_std: 2.0224159954718517
reward_max: -105.78851540616246
reward_min: -111.28011204481794
queue_len: 0.0720893795183856
wait_time: 0.6919845634982552
delay_time: 4.460574570809687
pressure: 0.8829575596816976
total_envstep_count: 576288
total_train_sample_count: 576288
total_episode_count: 4968
total_duration: 19216.327976703644
[2025-02-20 22:49:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.239557118541693
avg_train_sample_per_sec: 31.239557118541693
avg_episode_per_sec: 0.2693065268839801
collect_time: 22.2794451713562
reward_mean: -112.32084500466853
reward_std: 4.624506058811419
reward_max: -102.97128851540617
reward_min: -117.36904761904759
queue_len: 0.07448331896861309
wait_time: 0.7175904512998832
delay_time: 4.689161983924973
pressure: 0.9040671971706455
total_envstep_count: 576984
total_train_sample_count: 576984
total_episode_count: 4974
total_duration: 19238.607421875
[2025-02-20 22:50:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.673128273520906
avg_train_sample_per_sec: 31.673128273520906
avg_episode_per_sec: 0.2730442092544906
collect_time: 21.97446346282959
reward_mean: -111.84862278244633
reward_std: 2.7902208111203204
reward_max: -107.31372549019606
reward_min: -115.8466386554622
queue_len: 0.07417017425891666
wait_time: 0.7108007990994807
delay_time: 4.630638870430637
pressure: 0.907161803713528
total_envstep_count: 577680
total_train_sample_count: 577680
total_episode_count: 4980
total_duration: 19260.58188533783
[2025-02-20 22:50:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.281814973813212
avg_train_sample_per_sec: 31.281814973813212
avg_episode_per_sec: 0.26967081873976906
collect_time: 22.249348402023315
reward_mean: -111.84722222222223
reward_std: 3.7184571376493474
reward_max: -107.02591036414567
reward_min: -117.14705882352942
queue_len: 0.07416924550545241
wait_time: 0.7092063615897287
delay_time: 4.729193972535348
pressure: 0.9073828470380195
total_envstep_count: 578376
total_train_sample_count: 578376
total_episode_count: 4986
total_duration: 19282.831233739853
[2025-02-20 22:50:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31517625197202
avg_train_sample_per_sec: 31.31517625197202
avg_episode_per_sec: 0.26995841596527603
collect_time: 22.225645303726196
reward_mean: -109.07621381886088
reward_std: 0.8821868791929073
reward_max: -107.30322128851542
reward_min: -109.98179271708678
queue_len: 0.07233170677643293
wait_time: 0.6861548553992773
delay_time: 4.5539705259296746
pressure: 0.8859416445623342
total_envstep_count: 579072
total_train_sample_count: 579072
total_episode_count: 4992
total_duration: 19305.05687904358
[2025-02-20 22:51:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.443607113385276
avg_train_sample_per_sec: 31.443607113385276
avg_episode_per_sec: 0.27106557856366614
collect_time: 22.134865045547485
reward_mean: -112.66223155929039
reward_std: 3.568486702040611
reward_max: -108.06022408963592
reward_min: -117.9152661064426
queue_len: 0.07470970262552415
wait_time: 0.712745918438109
delay_time: 4.680102387138164
pressure: 0.9127984084880637
total_envstep_count: 579768
total_train_sample_count: 579768
total_episode_count: 4998
total_duration: 19327.191744089127
[2025-02-20 22:51:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.196997199517998
avg_train_sample_per_sec: 31.196997199517998
avg_episode_per_sec: 0.2689396310303276
collect_time: 22.309839487075806
reward_mean: -110.71463585434172
reward_std: 1.9965187304469758
reward_max: -108.3081232492997
reward_min: -114.24019607843138
queue_len: 0.07341819353736187
wait_time: 0.7010125889436232
delay_time: 4.707311893998399
pressure: 0.8914677276746241
total_envstep_count: 580464
total_train_sample_count: 580464
total_episode_count: 5004
total_duration: 19349.501583576202
[2025-02-20 22:52:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.504148191669152
avg_train_sample_per_sec: 31.504148191669152
avg_episode_per_sec: 0.27158748441094094
collect_time: 22.092328786849976
reward_mean: -111.38865546218489
reward_std: 2.194783595853468
reward_max: -107.9901960784314
reward_min: -114.79411764705888
queue_len: 0.07386515614203241
wait_time: 0.7059478300604063
delay_time: 4.721853394264339
pressure: 0.8915782493368699
total_envstep_count: 581160
total_train_sample_count: 581160
total_episode_count: 5010
total_duration: 19371.593912363052
[2025-02-20 22:52:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.711759000131075
avg_train_sample_per_sec: 30.711759000131075
avg_episode_per_sec: 0.26475654310457825
collect_time: 22.66232943534851
reward_mean: -109.6109943977591
reward_std: 3.0659481799960604
reward_max: -106.9404761904762
reward_min: -116.03921568627452
queue_len: 0.07268633580753256
wait_time: 0.695525668269076
delay_time: 4.701122426529513
pressure: 0.8789787798408487
total_envstep_count: 581856
total_train_sample_count: 581856
total_episode_count: 5016
total_duration: 19394.2562417984
[2025-02-20 22:52:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.242764084453153
avg_train_sample_per_sec: 31.242764084453153
avg_episode_per_sec: 0.26933417314183755
collect_time: 22.27715826034546
reward_mean: -111.41818394024278
reward_std: 2.8105691891206597
reward_max: -106.98249299719893
reward_min: -115.37254901960785
queue_len: 0.0738847373609037
wait_time: 0.7043146170935218
delay_time: 4.645641038676129
pressure: 0.9064986737400531
total_envstep_count: 582552
total_train_sample_count: 582552
total_episode_count: 5022
total_duration: 19416.533400058746
[2025-02-20 22:53:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39157047460923
avg_train_sample_per_sec: 31.39157047460923
avg_episode_per_sec: 0.27061698685007957
collect_time: 22.171557188034058
reward_mean: -112.27007469654528
reward_std: 4.113689818533123
reward_max: -107.23529411764704
reward_min: -118.36624649859945
queue_len: 0.07444965165553401
wait_time: 0.7102687781567093
delay_time: 4.719170459188182
pressure: 0.9110300618921311
total_envstep_count: 583248
total_train_sample_count: 583248
total_episode_count: 5028
total_duration: 19438.70495724678
[2025-02-20 22:53:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8207168196196
avg_train_sample_per_sec: 31.8207168196196
avg_episode_per_sec: 0.27431652430706555
collect_time: 21.87254309654236
reward_mean: -109.63702147525679
reward_std: 3.7382238581652527
reward_max: -104.76120448179269
reward_min: -115.53851540616252
queue_len: 0.07270359514274323
wait_time: 0.7004908616850808
delay_time: 4.608927565909463
pressure: 0.8890362511052166
total_envstep_count: 583944
total_train_sample_count: 583944
total_episode_count: 5034
total_duration: 19460.577500343323
[2025-02-20 22:53:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.376867310358964
avg_train_sample_per_sec: 31.376867310358964
avg_episode_per_sec: 0.27049023543412903
collect_time: 22.181946754455566
reward_mean: -111.37441643323997
reward_std: 3.09597775474608
reward_max: -107.31932773109247
reward_min: -116.9502801120448
queue_len: 0.07385571381514587
wait_time: 0.7042685664009195
delay_time: 4.660526880732019
pressure: 0.8966622458001768
total_envstep_count: 584640
total_train_sample_count: 584640
total_episode_count: 5040
total_duration: 19482.75944709778
[2025-02-20 22:54:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.460030040556994
avg_train_sample_per_sec: 31.460030040556994
avg_episode_per_sec: 0.27120715552204305
collect_time: 22.123310089111328
reward_mean: -108.75653594771241
reward_std: 2.381440902080773
reward_max: -106.11554621848734
reward_min: -112.70588235294116
queue_len: 0.07211971879821778
wait_time: 0.6924663543578351
delay_time: 4.5765483708416195
pressure: 0.8811892130857647
total_envstep_count: 585336
total_train_sample_count: 585336
total_episode_count: 5046
total_duration: 19504.88275718689
[2025-02-20 22:54:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.493107142393637
avg_train_sample_per_sec: 31.493107142393637
avg_episode_per_sec: 0.2714923029516693
collect_time: 22.10007405281067
reward_mean: -110.63783846872082
reward_std: 2.9499176056579466
reward_max: -106.1197478991597
reward_min: -115.65406162464984
queue_len: 0.07336726688907215
wait_time: 0.6998312145370967
delay_time: 4.744487764389767
pressure: 0.8799734748010609
total_envstep_count: 586032
total_train_sample_count: 586032
total_episode_count: 5052
total_duration: 19526.9828312397
[2025-02-20 22:55:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61400540981467
avg_train_sample_per_sec: 31.61400540981467
avg_episode_per_sec: 0.27253452939495404
collect_time: 22.01555895805359
reward_mean: -110.093487394958
reward_std: 2.2661180110912724
reward_max: -106.66806722689077
reward_min: -113.43207282913166
queue_len: 0.07300629137596683
wait_time: 0.6992299240651169
delay_time: 4.600156255000978
pressure: 0.8863837312113175
total_envstep_count: 586728
total_train_sample_count: 586728
total_episode_count: 5058
total_duration: 19548.998390197754
[2025-02-20 22:55:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89945351871259
avg_train_sample_per_sec: 31.89945351871259
avg_episode_per_sec: 0.2749952889544189
collect_time: 21.8185555934906
reward_mean: -110.9751400560224
reward_std: 3.547259161276248
reward_max: -105.76400560224086
reward_min: -115.33193277310927
queue_len: 0.07359094168171247
wait_time: 0.702550372492056
delay_time: 4.621712079369229
pressure: 0.8945623342175066
total_envstep_count: 587424
total_train_sample_count: 587424
total_episode_count: 5064
total_duration: 19570.816945791245
[2025-02-20 22:55:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.218614699842163
avg_train_sample_per_sec: 31.218614699842163
avg_episode_per_sec: 0.2691259887917428
collect_time: 22.29439091682434
reward_mean: -112.49964985994399
reward_std: 4.37378059353515
reward_max: -107.65476190476191
reward_min: -118.49929971988793
queue_len: 0.07460188982754905
wait_time: 0.7101050853586353
delay_time: 4.793284598792325
pressure: 0.8947833775419981
total_envstep_count: 588120
total_train_sample_count: 588120
total_episode_count: 5070
total_duration: 19593.11133670807
[2025-02-20 22:56:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47637883555466
avg_train_sample_per_sec: 31.47637883555466
avg_episode_per_sec: 0.27134809340995397
collect_time: 22.11181926727295
reward_mean: -109.86986461251166
reward_std: 3.278105037997632
reward_max: -103.46428571428571
reward_min: -113.67156862745101
queue_len: 0.07285800040617485
wait_time: 0.6917803925283641
delay_time: 4.608525202543837
pressure: 0.8791998231653403
total_envstep_count: 588816
total_train_sample_count: 588816
total_episode_count: 5076
total_duration: 19615.22315597534
[2025-02-20 22:56:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.492628099520196
avg_train_sample_per_sec: 31.492628099520196
avg_episode_per_sec: 0.2714881732717258
collect_time: 22.100410223007202
reward_mean: -110.21918767507002
reward_std: 3.570626912462955
reward_max: -106.31092436974788
reward_min: -116.1225490196078
queue_len: 0.0730896469993833
wait_time: 0.7001056611857829
delay_time: 4.675967465650566
pressure: 0.8819628647214856
total_envstep_count: 589512
total_train_sample_count: 589512
total_episode_count: 5082
total_duration: 19637.32356619835
[2025-02-20 22:56:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.613562395159928
avg_train_sample_per_sec: 31.613562395159928
avg_episode_per_sec: 0.27253071030310283
collect_time: 22.015867471694946
reward_mean: -107.59220354808588
reward_std: 2.922289790778498
reward_max: -103.42857142857139
reward_min: -110.76750700280114
queue_len: 0.07134761508493759
wait_time: 0.6792097917858566
delay_time: 4.5818475997658314
pressure: 0.8653846153846154
total_envstep_count: 590208
total_train_sample_count: 590208
total_episode_count: 5088
total_duration: 19659.339433670044
[2025-02-20 22:57:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.14848340094271
avg_train_sample_per_sec: 31.14848340094271
avg_episode_per_sec: 0.26852140862881646
collect_time: 22.344587087631226
reward_mean: -109.48260971055089
reward_std: 1.9919007684869914
reward_max: -106.62815126050421
reward_min: -111.07983193277309
queue_len: 0.0726012000733096
wait_time: 0.6950598210106324
delay_time: 4.617700257824747
pressure: 0.8703580901856763
total_envstep_count: 590904
total_train_sample_count: 590904
total_episode_count: 5094
total_duration: 19681.684020757675
[2025-02-20 22:57:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.223781629830942
avg_train_sample_per_sec: 31.223781629830942
avg_episode_per_sec: 0.2691705312916461
collect_time: 22.290701627731323
reward_mean: -111.5420168067227
reward_std: 2.6634655182936307
reward_max: -108.10364145658265
reward_min: -115.67086834733885
queue_len: 0.07396685464636783
wait_time: 0.7103313916194239
delay_time: 4.688300372361497
pressure: 0.8915782493368699
total_envstep_count: 591600
total_train_sample_count: 591600
total_episode_count: 5100
total_duration: 19703.974722385406
[2025-02-20 22:58:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.216215133304456
avg_train_sample_per_sec: 31.216215133304456
avg_episode_per_sec: 0.2691053028733143
collect_time: 22.296104669570923
reward_mean: -113.94654528478058
reward_std: 3.556337062942891
reward_max: -109.84803921568623
reward_min: -119.37675070028017
queue_len: 0.07556136955224176
wait_time: 0.7212142925251445
delay_time: 4.7798840489829155
pressure: 0.9101458885941645
total_envstep_count: 592296
total_train_sample_count: 592296
total_episode_count: 5106
total_duration: 19726.270827054977
[2025-02-20 22:58:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.854670008031395
avg_train_sample_per_sec: 30.854670008031395
avg_episode_per_sec: 0.2659885345519948
collect_time: 22.557363271713257
reward_mean: -108.60889355742296
reward_std: 3.81054304308739
reward_max: -105.5287114845939
reward_min: -114.4859943977591
queue_len: 0.07202181270386136
wait_time: 0.6895196518041345
delay_time: 4.590724241382481
pressure: 0.8640583554376658
total_envstep_count: 592992
total_train_sample_count: 592992
total_episode_count: 5112
total_duration: 19748.82819032669
[2025-02-20 22:58:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.463520151814592
avg_train_sample_per_sec: 31.463520151814592
avg_episode_per_sec: 0.2712372426880568
collect_time: 22.120856046676636
reward_mean: -108.93954248366015
reward_std: 2.6105475374433778
reward_max: -105.8235294117647
reward_min: -112.46988795518206
queue_len: 0.07224107591754651
wait_time: 0.6907723854351643
delay_time: 4.683242470020013
pressure: 0.8656056587091069
total_envstep_count: 593688
total_train_sample_count: 593688
total_episode_count: 5118
total_duration: 19770.949046373367
[2025-02-20 22:59:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.666739786814453
avg_train_sample_per_sec: 31.666739786814453
avg_episode_per_sec: 0.27298913609322806
collect_time: 21.978896617889404
reward_mean: -110.23354341736696
reward_std: 2.929998258945276
reward_max: -106.27380952380952
reward_min: -113.12114845938376
queue_len: 0.07309916672239188
wait_time: 0.6995822312125557
delay_time: 4.690097594924016
pressure: 0.8868258178603007
total_envstep_count: 594384
total_train_sample_count: 594384
total_episode_count: 5124
total_duration: 19792.927942991257
[2025-02-20 22:59:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.647404853912505
avg_train_sample_per_sec: 31.647404853912505
avg_episode_per_sec: 0.2728224556371768
collect_time: 21.992324590682983
reward_mean: -109.89647525676939
reward_std: 3.1947552719031544
reward_max: -105.06372549019609
reward_min: -114.77450980392159
queue_len: 0.0728756467219956
wait_time: 0.6991245105469243
delay_time: 4.6388407064588035
pressure: 0.8840627763041556
total_envstep_count: 595080
total_train_sample_count: 595080
total_episode_count: 5130
total_duration: 19814.92026758194
[2025-02-20 22:59:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.658777200058648
avg_train_sample_per_sec: 31.658777200058648
avg_episode_per_sec: 0.2729204931039539
collect_time: 21.984424591064453
reward_mean: -110.55695611577964
reward_std: 3.225900913422743
reward_max: -103.94187675070023
reward_min: -114.26750700280112
queue_len: 0.07331363137651169
wait_time: 0.7021957434609565
delay_time: 4.5988769876859665
pressure: 0.8880415561450045
total_envstep_count: 595776
total_train_sample_count: 595776
total_episode_count: 5136
total_duration: 19836.904692173004
[2025-02-20 23:00:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.168506807238707
avg_train_sample_per_sec: 31.168506807238707
avg_episode_per_sec: 0.26869402420033367
collect_time: 22.33023238182068
reward_mean: -111.09640522875817
reward_std: 3.6535967472851385
reward_max: -105.45728291316527
reward_min: -117.50840336134453
queue_len: 0.07367135625249216
wait_time: 0.7019995442916335
delay_time: 4.646474107322601
pressure: 0.8859416445623342
total_envstep_count: 596472
total_train_sample_count: 596472
total_episode_count: 5142
total_duration: 19859.234924554825
[2025-02-20 23:00:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.401388573732046
avg_train_sample_per_sec: 31.401388573732046
avg_episode_per_sec: 0.27070162563562106
collect_time: 22.1646249294281
reward_mean: -108.98190943043885
reward_std: 1.8932012245443859
reward_max: -107.18417366946782
reward_min: -112.98319327731087
queue_len: 0.07226917070984008
wait_time: 0.6916114367939928
delay_time: 4.640178244394085
pressure: 0.8752210433244917
total_envstep_count: 597168
total_train_sample_count: 597168
total_episode_count: 5148
total_duration: 19881.399549484253
[2025-02-20 23:01:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.695144545881714
avg_train_sample_per_sec: 31.695144545881714
avg_episode_per_sec: 0.27323400470587683
collect_time: 21.95919942855835
reward_mean: -108.00735294117648
reward_std: 1.3037136838208458
reward_max: -105.72689075630255
reward_min: -109.5105042016807
queue_len: 0.07162291309096584
wait_time: 0.6759939055197677
delay_time: 4.56543220958683
pressure: 0.8737842617152962
total_envstep_count: 597864
total_train_sample_count: 597864
total_episode_count: 5154
total_duration: 19903.35874891281
[2025-02-20 23:01:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.37099758685261
avg_train_sample_per_sec: 31.37099758685261
avg_episode_per_sec: 0.27043963436941904
collect_time: 22.186097145080566
reward_mean: -109.26669000933707
reward_std: 3.9451033539760627
reward_max: -102.62675070028013
reward_min: -114.64145658263303
queue_len: 0.072458017247571
wait_time: 0.6927873934719777
delay_time: 4.630393605707653
pressure: 0.8826259946949603
total_envstep_count: 598560
total_train_sample_count: 598560
total_episode_count: 5160
total_duration: 19925.544846057892
[2025-02-20 23:01:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57053521267869
avg_train_sample_per_sec: 31.57053521267869
avg_episode_per_sec: 0.2721597863161956
collect_time: 22.045872688293457
reward_mean: -110.59593837535012
reward_std: 1.6697157356183048
reward_max: -107.67997198879553
reward_min: -112.39005602240891
queue_len: 0.07333948168126667
wait_time: 0.6973215678844481
delay_time: 4.652655062909695
pressure: 0.8999778956675507
total_envstep_count: 599256
total_train_sample_count: 599256
total_episode_count: 5166
total_duration: 19947.590718746185
[2025-02-20 23:02:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.414386160724014
avg_train_sample_per_sec: 31.414386160724014
avg_episode_per_sec: 0.27081367379934496
collect_time: 22.155454397201538
reward_mean: -109.80438842203546
reward_std: 3.418101819077091
reward_max: -105.83893557422964
reward_min: -115.42366946778706
queue_len: 0.07281458118172113
wait_time: 0.6907405756290137
delay_time: 4.552561013199486
pressure: 0.889367816091954
total_envstep_count: 599952
total_train_sample_count: 599952
total_episode_count: 5172
total_duration: 19969.746173143387
[2025-02-20 23:02:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.542218640210482
avg_train_sample_per_sec: 31.542218640210482
avg_episode_per_sec: 0.271915677932849
collect_time: 22.065664052963257
reward_mean: -109.71988795518207
reward_std: 1.0458385140897943
reward_max: -107.82983193277308
reward_min: -110.88655462184875
queue_len: 0.07275854638937802
wait_time: 0.6926359292611828
delay_time: 4.571111935640775
pressure: 0.8953359858532272
total_envstep_count: 600648
total_train_sample_count: 600648
total_episode_count: 5178
total_duration: 19991.81183719635
[2025-02-20 23:02:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.34931471675812
avg_train_sample_per_sec: 31.34931471675812
avg_episode_per_sec: 0.270252713075501
collect_time: 22.2014422416687
reward_mean: -107.88503734827263
reward_std: 1.9395721112636057
reward_max: -106.41316526610647
reward_min: -112.11414565826324
queue_len: 0.07154180195508796
wait_time: 0.6813501041442217
delay_time: 4.561604563310303
pressure: 0.8689213085764811
total_envstep_count: 601344
total_train_sample_count: 601344
total_episode_count: 5184
total_duration: 20014.01327943802
[2025-02-20 23:03:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54788157239071
avg_train_sample_per_sec: 31.54788157239071
avg_episode_per_sec: 0.271964496313713
collect_time: 22.061703205108643
reward_mean: -109.24894957983194
reward_std: 2.8373484955031207
reward_max: -105.54971988795523
reward_min: -113.12745098039217
queue_len: 0.07244625303702383
wait_time: 0.6862834103579539
delay_time: 4.666238441095764
pressure: 0.8757736516357205
total_envstep_count: 602040
total_train_sample_count: 602040
total_episode_count: 5190
total_duration: 20036.074982643127
[2025-02-20 23:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.774506330796203
avg_train_sample_per_sec: 31.774506330796203
avg_episode_per_sec: 0.2739181580241052
collect_time: 21.90435290336609
reward_mean: -110.83730158730158
reward_std: 2.156401362226616
reward_max: -107.61694677871151
reward_min: -114.2647058823529
queue_len: 0.07349953686160582
wait_time: 0.6959723212892585
delay_time: 4.6224805136151925
pressure: 0.8951149425287356
total_envstep_count: 602736
total_train_sample_count: 602736
total_episode_count: 5196
total_duration: 20057.979335546494
[2025-02-20 23:04:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.281995316909207
avg_train_sample_per_sec: 31.281995316909207
avg_episode_per_sec: 0.2696723734216311
collect_time: 22.24922013282776
reward_mean: -110.65336134453781
reward_std: 5.404900105032335
reward_max: -106.02170868347336
reward_min: -122.20448179271713
queue_len: 0.07337756057330096
wait_time: 0.7002182725433234
delay_time: 4.712593925783291
pressure: 0.888262599469496
total_envstep_count: 603432
total_train_sample_count: 603432
total_episode_count: 5202
total_duration: 20080.22855567932
[2025-02-20 23:04:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84170198585217
avg_train_sample_per_sec: 31.84170198585217
avg_episode_per_sec: 0.2744974309125187
collect_time: 21.8581280708313
reward_mean: -111.83788515406161
reward_std: 3.4084039183898613
reward_max: -108.12114845938375
reward_min: -118.10994397759102
queue_len: 0.07416305381569073
wait_time: 0.7110322909004451
delay_time: 4.674015110860736
pressure: 0.8972148541114059
total_envstep_count: 604128
total_train_sample_count: 604128
total_episode_count: 5208
total_duration: 20102.086683750153
[2025-02-20 23:04:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49875619087008
avg_train_sample_per_sec: 31.49875619087008
avg_episode_per_sec: 0.2715410016454317
collect_time: 22.096110582351685
reward_mean: -110.80929038281982
reward_std: 2.759776902537218
reward_max: -107.67366946778714
reward_min: -116.05882352941175
queue_len: 0.07348096179232085
wait_time: 0.7033427539893058
delay_time: 4.667550492483316
pressure: 0.8922413793103448
total_envstep_count: 604824
total_train_sample_count: 604824
total_episode_count: 5214
total_duration: 20124.182794332504
[2025-02-20 23:05:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.490129498666466
avg_train_sample_per_sec: 31.490129498666466
avg_episode_per_sec: 0.27146663360919365
collect_time: 22.102163791656494
reward_mean: -108.47887488328665
reward_std: 0.7328418732774004
reward_max: -107.14845938375346
reward_min: -109.44537815126051
queue_len: 0.07193559342393013
wait_time: 0.6894067308621062
delay_time: 4.519738305003695
pressure: 0.8736737400530504
total_envstep_count: 605520
total_train_sample_count: 605520
total_episode_count: 5220
total_duration: 20146.28495812416
[2025-02-20 23:05:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.834020539366772
avg_train_sample_per_sec: 31.834020539366772
avg_episode_per_sec: 0.27443121154626526
collect_time: 21.863402366638184
reward_mean: -108.54656862745098
reward_std: 1.3029609779453055
reward_max: -107.0532212885154
reward_min: -110.75280112044817
queue_len: 0.07198048317470224
wait_time: 0.6843794657562405
delay_time: 4.596170739617016
pressure: 0.8690318302387268
total_envstep_count: 606216
total_train_sample_count: 606216
total_episode_count: 5226
total_duration: 20168.1483604908
[2025-02-20 23:05:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.101290871085485
avg_train_sample_per_sec: 31.101290871085485
avg_episode_per_sec: 0.26811457647487486
collect_time: 22.37849235534668
reward_mean: -111.16479925303453
reward_std: 2.832871855889545
reward_max: -106.26890756302517
reward_min: -114.72408963585431
queue_len: 0.07371671037999637
wait_time: 0.7000593009086925
delay_time: 4.686131294019669
pressure: 0.8984305923961097
total_envstep_count: 606912
total_train_sample_count: 606912
total_episode_count: 5232
total_duration: 20190.526852846146
[2025-02-20 23:06:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.37170454830116
avg_train_sample_per_sec: 31.37170454830116
avg_episode_per_sec: 0.27044572886466517
collect_time: 22.18559718132019
reward_mean: -108.57819794584502
reward_std: 2.050889226620482
reward_max: -106.04341736694683
reward_min: -112.63235294117648
queue_len: 0.07200145752376991
wait_time: 0.6840979760604506
delay_time: 4.574859465046282
pressure: 0.8872679045092838
total_envstep_count: 607608
total_train_sample_count: 607608
total_episode_count: 5238
total_duration: 20212.712450027466
[2025-02-20 23:06:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4879291558706
avg_train_sample_per_sec: 31.4879291558706
avg_episode_per_sec: 0.2714476651368155
collect_time: 22.103708267211914
reward_mean: -107.8794351073763
reward_std: 4.126789725029262
reward_max: -103.97268907563021
reward_min: -114.60504201680672
queue_len: 0.07153808694123097
wait_time: 0.6816336061391842
delay_time: 4.567591753788753
pressure: 0.8650530503978779
total_envstep_count: 608304
total_train_sample_count: 608304
total_episode_count: 5244
total_duration: 20234.816158294678
[2025-02-20 23:07:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.862525661370466
avg_train_sample_per_sec: 31.862525661370466
avg_episode_per_sec: 0.27467694535664194
collect_time: 21.84384274482727
reward_mean: -106.05578898225959
reward_std: 3.759889127799147
reward_max: -98.91246498599442
reward_min: -110.97619047619047
queue_len: 0.0703287725346549
wait_time: 0.6680755856719346
delay_time: 4.517777470546556
pressure: 0.8615163572060124
total_envstep_count: 609000
total_train_sample_count: 609000
total_episode_count: 5250
total_duration: 20256.660001039505
[2025-02-20 23:07:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5817519200756
avg_train_sample_per_sec: 31.5817519200756
avg_episode_per_sec: 0.2722564820696172
collect_time: 22.038042783737183
reward_mean: -107.90791316526611
reward_std: 2.9277261743809957
reward_max: -103.65966386554618
reward_min: -112.20728291316529
queue_len: 0.07155697159500406
wait_time: 0.6805328784918036
delay_time: 4.579475619611031
pressure: 0.8648320070733865
total_envstep_count: 609696
total_train_sample_count: 609696
total_episode_count: 5256
total_duration: 20278.698043823242
[2025-02-20 23:07:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57040239908774
avg_train_sample_per_sec: 31.57040239908774
avg_episode_per_sec: 0.272158641371446
collect_time: 22.045965433120728
reward_mean: -107.09302054154995
reward_std: 1.8859229216829712
reward_max: -103.77240896358545
reward_min: -109.6596638655462
queue_len: 0.07101659187105434
wait_time: 0.6760058245225588
delay_time: 4.519774306116566
pressure: 0.8673740053050397
total_envstep_count: 610392
total_train_sample_count: 610392
total_episode_count: 5262
total_duration: 20300.744009256363
[2025-02-20 23:08:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03008667252042
avg_train_sample_per_sec: 32.03008667252042
avg_episode_per_sec: 0.2761214368320726
collect_time: 21.729569673538208
reward_mean: -107.86157796451913
reward_std: 2.031375717380141
reward_max: -105.43417366946778
reward_min: -111.34173669467785
queue_len: 0.07152624533456176
wait_time: 0.6779954466313494
delay_time: 4.518104623837412
pressure: 0.873894783377542
total_envstep_count: 611088
total_train_sample_count: 611088
total_episode_count: 5268
total_duration: 20322.4735789299
[2025-02-20 23:08:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.145048539092368
avg_train_sample_per_sec: 31.145048539092368
avg_episode_per_sec: 0.2684917977507963
collect_time: 22.34705138206482
reward_mean: -109.53162931839402
reward_std: 2.3122336788545956
reward_max: -106.65406162464987
reward_min: -112.8172268907563
queue_len: 0.07263370644455837
wait_time: 0.6926968400092132
delay_time: 4.604034357763448
pressure: 0.8845048629531388
total_envstep_count: 611784
total_train_sample_count: 611784
total_episode_count: 5274
total_duration: 20344.820630311966
[2025-02-20 23:08:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.539102219153726
avg_train_sample_per_sec: 31.539102219153726
avg_episode_per_sec: 0.27188881223408384
collect_time: 22.06784439086914
reward_mean: -110.672035480859
reward_std: 3.350166762064786
reward_max: -105.75700280112049
reward_min: -115.8879551820728
queue_len: 0.07338994395282428
wait_time: 0.6996664381933143
delay_time: 4.6432585282422805
pressure: 0.8923519009725908
total_envstep_count: 612480
total_train_sample_count: 612480
total_episode_count: 5280
total_duration: 20366.888474702835
[2025-02-20 23:09:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.49690432750667
avg_train_sample_per_sec: 31.49690432750667
avg_episode_per_sec: 0.271525037306092
collect_time: 22.09740972518921
reward_mean: -108.6311858076564
reward_std: 3.1642052229101636
reward_max: -104.95588235294115
reward_min: -114.60924369747902
queue_len: 0.07203659536316738
wait_time: 0.6848528978346423
delay_time: 4.666722803188391
pressure: 0.8726790450928382
total_envstep_count: 613176
total_train_sample_count: 613176
total_episode_count: 5286
total_duration: 20388.985884428024
[2025-02-20 23:09:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.686403427126276
avg_train_sample_per_sec: 31.686403427126276
avg_episode_per_sec: 0.27315865023384717
collect_time: 21.965257167816162
reward_mean: -107.47175536881419
reward_std: 1.2726343838824425
reward_max: -106.04481792717085
reward_min: -109.17086834733895
queue_len: 0.07126774228701206
wait_time: 0.6770972646352971
delay_time: 4.524308385936799
pressure: 0.8702475685234305
total_envstep_count: 613872
total_train_sample_count: 613872
total_episode_count: 5292
total_duration: 20410.95114159584
[2025-02-20 23:10:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.856758255985532
avg_train_sample_per_sec: 31.856758255985532
avg_episode_per_sec: 0.2746272263447029
collect_time: 21.847797393798828
reward_mean: -108.76960784313728
reward_std: 3.761688123345117
reward_max: -104.07913165266105
reward_min: -113.13795518207286
queue_len: 0.07212838716388413
wait_time: 0.6814396514574
delay_time: 4.578174153137835
pressure: 0.8764367816091955
total_envstep_count: 614568
total_train_sample_count: 614568
total_episode_count: 5298
total_duration: 20432.79893898964
[2025-02-20 23:10:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55268539241099
avg_train_sample_per_sec: 31.55268539241099
avg_episode_per_sec: 0.27200590855526713
collect_time: 22.05834436416626
reward_mean: -108.06325863678806
reward_std: 1.6075039244736902
reward_max: -105.38025210084035
reward_min: -110.28921568627453
queue_len: 0.07165998583341383
wait_time: 0.6806724236998071
delay_time: 4.592537545350427
pressure: 0.8632847038019452
total_envstep_count: 615264
total_train_sample_count: 615264
total_episode_count: 5304
total_duration: 20454.857283353806
[2025-02-20 23:10:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.717341694997017
avg_train_sample_per_sec: 31.717341694997017
avg_episode_per_sec: 0.2734253594396295
collect_time: 21.94383144378662
reward_mean: -108.26657329598505
reward_std: 2.1673981203954438
reward_max: -105.74929971988797
reward_min: -110.71008403361347
queue_len: 0.0717948098779742
wait_time: 0.680182196662927
delay_time: 4.570949333147717
pressure: 0.8729000884173299
total_envstep_count: 615960
total_train_sample_count: 615960
total_episode_count: 5310
total_duration: 20476.801114797592
[2025-02-20 23:11:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80330683249854
avg_train_sample_per_sec: 31.80330683249854
avg_episode_per_sec: 0.2741664382111943
collect_time: 21.884516716003418
reward_mean: -107.5233426704015
reward_std: 3.319159370685141
reward_max: -104.19607843137254
reward_min: -114.04131652661064
queue_len: 0.07130195137294529
wait_time: 0.6754991895078102
delay_time: 4.535812418057569
pressure: 0.8708001768346595
total_envstep_count: 616656
total_train_sample_count: 616656
total_episode_count: 5316
total_duration: 20498.685631513596
[2025-02-20 23:11:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.26479967579766
avg_train_sample_per_sec: 31.26479967579766
avg_episode_per_sec: 0.2695241351361867
collect_time: 22.261457204818726
reward_mean: -110.10329131652661
reward_std: 3.410994716924308
reward_max: -105.48879551820725
reward_min: -114.71708683473388
queue_len: 0.07301279265021658
wait_time: 0.6957658284357068
delay_time: 4.640626550258158
pressure: 0.8853890362511052
total_envstep_count: 617352
total_train_sample_count: 617352
total_episode_count: 5322
total_duration: 20520.947088718414
[2025-02-20 23:11:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.515721286442414
avg_train_sample_per_sec: 31.515721286442414
avg_episode_per_sec: 0.2716872524693312
collect_time: 22.084216117858887
reward_mean: -109.21136788048553
reward_std: 2.7030172031727306
reward_max: -104.93697478991598
reward_min: -112.21288515406162
queue_len: 0.07242133148573311
wait_time: 0.6871545037112988
delay_time: 4.612128820959728
pressure: 0.8839522546419097
total_envstep_count: 618048
total_train_sample_count: 618048
total_episode_count: 5328
total_duration: 20543.031304836273
[2025-02-20 23:12:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.634424596423266
avg_train_sample_per_sec: 31.634424596423266
avg_episode_per_sec: 0.27271055686571777
collect_time: 22.0013484954834
reward_mean: -107.67285247432305
reward_std: 3.618816701194216
reward_max: -101.71498599439774
reward_min: -111.76190476190474
queue_len: 0.07140109580525401
wait_time: 0.6785305634190015
delay_time: 4.5145014720589405
pressure: 0.8787577365163571
total_envstep_count: 618744
total_train_sample_count: 618744
total_episode_count: 5334
total_duration: 20565.032653331757
[2025-02-20 23:12:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88947412536411
avg_train_sample_per_sec: 31.88947412536411
avg_episode_per_sec: 0.2749092597014147
collect_time: 21.82538342475891
reward_mean: -108.61356209150328
reward_std: 1.7103726581360312
reward_max: -105.93697478991601
reward_min: -111.41526610644256
queue_len: 0.07202490854874223
wait_time: 0.6854514020462297
delay_time: 4.56748108706175
pressure: 0.8779840848806365
total_envstep_count: 619440
total_train_sample_count: 619440
total_episode_count: 5340
total_duration: 20586.858036756516
[2025-02-20 23:13:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.579841091034293
avg_train_sample_per_sec: 31.579841091034293
avg_episode_per_sec: 0.27224000940546805
collect_time: 22.039376258850098
reward_mean: -108.08321661998129
reward_std: 2.8550026373490294
reward_max: -104.03921568627449
reward_min: -112.32983193277306
queue_len: 0.0716732205702794
wait_time: 0.6803571892948161
delay_time: 4.574194150054292
pressure: 0.8687002652519894
total_envstep_count: 620136
total_train_sample_count: 620136
total_episode_count: 5346
total_duration: 20608.897413015366
[2025-02-20 23:13:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.51559709933514
avg_train_sample_per_sec: 31.51559709933514
avg_episode_per_sec: 0.27168618189082017
collect_time: 22.08430314064026
reward_mean: -109.45413165266105
reward_std: 3.895240497110182
reward_max: -103.63235294117646
reward_min: -115.33263305322129
queue_len: 0.07258231541953651
wait_time: 0.6924550545240201
delay_time: 4.55067481626585
pressure: 0.8893678160919539
total_envstep_count: 620832
total_train_sample_count: 620832
total_episode_count: 5352
total_duration: 20630.981716156006
[2025-02-20 23:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65674409584303
avg_train_sample_per_sec: 31.65674409584303
avg_episode_per_sec: 0.2729029663434744
collect_time: 21.985836505889893
reward_mean: -109.0721288515406
reward_std: 4.455423216414935
reward_max: -103.14635854341735
reward_min: -114.01190476190474
queue_len: 0.0723289979121622
wait_time: 0.6890955984515822
delay_time: 4.641576590473796
pressure: 0.8722369584438551
total_envstep_count: 621528
total_train_sample_count: 621528
total_episode_count: 5358
total_duration: 20652.967552661896
[2025-02-20 23:14:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.622262681153238
avg_train_sample_per_sec: 31.622262681153238
avg_episode_per_sec: 0.2726057127685624
collect_time: 22.009810209274292
reward_mean: -106.33718487394957
reward_std: 2.224309923234375
reward_max: -102.84453781512605
reward_min: -109.34313725490192
queue_len: 0.07051537458484719
wait_time: 0.6662693923723338
delay_time: 4.555261518375835
pressure: 0.8547745358090185
total_envstep_count: 622224
total_train_sample_count: 622224
total_episode_count: 5364
total_duration: 20674.97736287117
[2025-02-20 23:14:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.457301694690823
avg_train_sample_per_sec: 31.457301694690823
avg_episode_per_sec: 0.2711836352990588
collect_time: 22.125228881835938
reward_mean: -106.3206115779645
reward_std: 2.307543484235942
reward_max: -103.171568627451
reward_min: -109.22198879551821
queue_len: 0.07050438433552024
wait_time: 0.6651987718164186
delay_time: 4.520795081291257
pressure: 0.8536693191865604
total_envstep_count: 622920
total_train_sample_count: 622920
total_episode_count: 5370
total_duration: 20697.102591753006
[2025-02-20 23:15:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.538590428448344
avg_train_sample_per_sec: 31.538590428448344
avg_episode_per_sec: 0.27188440024524435
collect_time: 22.06820249557495
reward_mean: -107.60469187675068
reward_std: 3.6376863326490647
reward_max: -102.73249299719886
reward_min: -114.797619047619
queue_len: 0.07135589646999384
wait_time: 0.6781404095678943
delay_time: 4.57452267434694
pressure: 0.8651635720601237
total_envstep_count: 623616
total_train_sample_count: 623616
total_episode_count: 5376
total_duration: 20719.17079424858
[2025-02-20 23:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.500070197728405
avg_train_sample_per_sec: 31.500070197728405
avg_episode_per_sec: 0.2715523292907621
collect_time: 22.095188856124878
reward_mean: -106.81162464985994
reward_std: 3.888702248130984
reward_max: -102.67296918767506
reward_min: -114.44327731092442
queue_len: 0.07082998982086203
wait_time: 0.6778003310077346
delay_time: 4.56121496777053
pressure: 0.8658267020335986
total_envstep_count: 624312
total_train_sample_count: 624312
total_episode_count: 5382
total_duration: 20741.265983104706
[2025-02-20 23:15:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.793412773131053
avg_train_sample_per_sec: 31.793412773131053
avg_episode_per_sec: 0.27408114459595734
collect_time: 21.891327142715454
reward_mean: -110.54411764705884
reward_std: 4.095595145093903
reward_max: -104.06442577030813
reward_min: -115.16806722689077
queue_len: 0.0733051178030894
wait_time: 0.6954004413436463
delay_time: 4.625617089570218
pressure: 0.895446507515473
total_envstep_count: 625008
total_train_sample_count: 625008
total_episode_count: 5388
total_duration: 20763.15731024742
[2025-02-20 23:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47558230492194
avg_train_sample_per_sec: 31.47558230492194
avg_episode_per_sec: 0.2713412267665684
collect_time: 22.1123788356781
reward_mean: -106.82446311858074
reward_std: 2.7942396132623673
reward_max: -103.13305322128849
reward_min: -110.8550420168067
queue_len: 0.07083850339428431
wait_time: 0.6750151541606918
delay_time: 4.5626594518600365
pressure: 0.8742263483642794
total_envstep_count: 625704
total_train_sample_count: 625704
total_episode_count: 5394
total_duration: 20785.2696890831
[2025-02-20 23:16:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79854763276576
avg_train_sample_per_sec: 31.79854763276576
avg_episode_per_sec: 0.274125410627291
collect_time: 21.887792110443115
reward_mean: -107.2313258636788
reward_std: 3.165831100127541
reward_max: -101.17156862745097
reward_min: -110.66876750700283
queue_len: 0.07110830627564907
wait_time: 0.6802382314552698
delay_time: 4.566035965637098
pressure: 0.8666003536693192
total_envstep_count: 626400
total_train_sample_count: 626400
total_episode_count: 5400
total_duration: 20807.157481193542
[2025-02-20 23:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.985957555660114
avg_train_sample_per_sec: 31.985957555660114
avg_episode_per_sec: 0.27574101341086305
collect_time: 21.759548664093018
reward_mean: -106.27567693744162
reward_std: 2.6390280533737625
reward_max: -102.15266106442576
reward_min: -110.11134453781511
queue_len: 0.07047458682854219
wait_time: 0.670317364346269
delay_time: 4.529204147405879
pressure: 0.8618479221927499
total_envstep_count: 627096
total_train_sample_count: 627096
total_episode_count: 5406
total_duration: 20828.917029857635
[2025-02-20 23:17:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.827320270531978
avg_train_sample_per_sec: 31.827320270531978
avg_episode_per_sec: 0.2743734506080343
collect_time: 21.86800503730774
reward_mean: -107.23015873015873
reward_std: 1.9372730344100815
reward_max: -104.64635854341738
reward_min: -109.83053221288516
queue_len: 0.07110753231442887
wait_time: 0.6775766562150943
delay_time: 4.548136693801954
pressure: 0.8687002652519894
total_envstep_count: 627792
total_train_sample_count: 627792
total_episode_count: 5412
total_duration: 20850.785034894943
[2025-02-20 23:17:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.709783158106656
avg_train_sample_per_sec: 31.709783158106656
avg_episode_per_sec: 0.2733601996388505
collect_time: 21.94906210899353
reward_mean: -106.3501400560224
reward_std: 2.881507382605495
reward_max: -103.34733893557423
reward_min: -111.18277310924373
queue_len: 0.07052396555439151
wait_time: 0.6699912170880732
delay_time: 4.623850789863202
pressure: 0.8585322723253759
total_envstep_count: 628488
total_train_sample_count: 628488
total_episode_count: 5418
total_duration: 20872.734097003937
[2025-02-20 23:18:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.16576956386465
avg_train_sample_per_sec: 31.16576956386465
avg_episode_per_sec: 0.26867042727469526
collect_time: 22.332193613052368
reward_mean: -108.45028011204481
reward_std: 4.448929393084745
reward_max: -103.63235294117648
reward_min: -116.78011204481794
queue_len: 0.07191663137403503
wait_time: 0.6853914200516633
delay_time: 4.677629750252511
pressure: 0.8856100795755969
total_envstep_count: 629184
total_train_sample_count: 629184
total_episode_count: 5424
total_duration: 20895.06629061699
[2025-02-20 23:18:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85527493057633
avg_train_sample_per_sec: 31.85527493057633
avg_episode_per_sec: 0.27461443905669247
collect_time: 21.848814725875854
reward_mean: -108.74369747899158
reward_std: 4.505740702091183
reward_max: -103.86134453781509
reward_min: -115.90336134453784
queue_len: 0.07211120522479549
wait_time: 0.6904121838832792
delay_time: 4.577868290580141
pressure: 0.8779840848806365
total_envstep_count: 629880
total_train_sample_count: 629880
total_episode_count: 5430
total_duration: 20916.915105342865
[2025-02-20 23:18:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5987826174003
avg_train_sample_per_sec: 31.5987826174003
avg_episode_per_sec: 0.27240329842586464
collect_time: 22.026165008544922
reward_mean: -109.31512605042015
reward_std: 3.922815136359608
reward_max: -103.82422969187677
reward_min: -114.7121848739496
queue_len: 0.07249013663820965
wait_time: 0.6951444149720012
delay_time: 4.712545774094903
pressure: 0.8779840848806367
total_envstep_count: 630576
total_train_sample_count: 630576
total_episode_count: 5436
total_duration: 20938.94127035141
[2025-02-20 23:19:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.277547684152005
avg_train_sample_per_sec: 31.277547684152005
avg_episode_per_sec: 0.26963403175993106
collect_time: 22.252383947372437
reward_mean: -108.640989729225
reward_std: 1.4488601840817072
reward_max: -106.52310924369746
reward_min: -110.73739495798317
queue_len: 0.0720430966374171
wait_time: 0.6833589204912734
delay_time: 4.6198538259486845
pressure: 0.8843943412908931
total_envstep_count: 631272
total_train_sample_count: 631272
total_episode_count: 5442
total_duration: 20961.193654298782
[2025-02-20 23:19:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.56902960222275
avg_train_sample_per_sec: 31.56902960222275
avg_episode_per_sec: 0.27214680691571336
collect_time: 22.046924114227295
reward_mean: -106.42261904761904
reward_std: 3.303202353779648
reward_max: -102.44047619047616
reward_min: -112.17086834733895
queue_len: 0.07057202854616647
wait_time: 0.6704736271166292
delay_time: 4.563348931544998
pressure: 0.8597480106100795
total_envstep_count: 631968
total_train_sample_count: 631968
total_episode_count: 5448
total_duration: 20983.24057841301
[2025-02-20 23:19:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.751646036266802
avg_train_sample_per_sec: 30.751646036266802
avg_episode_per_sec: 0.265100396864369
collect_time: 22.63293480873108
reward_mean: -109.02929505135387
reward_std: 3.9445191853839
reward_max: -103.00840336134453
reward_min: -115.38935574229694
queue_len: 0.07230059353538056
wait_time: 0.686576509472047
delay_time: 4.6505381502979235
pressure: 0.877763041556145
total_envstep_count: 632664
total_train_sample_count: 632664
total_episode_count: 5454
total_duration: 21005.87351322174
[2025-02-20 23:20:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.526640988261317
avg_train_sample_per_sec: 31.526640988261317
avg_episode_per_sec: 0.27178138782983896
collect_time: 22.07656693458557
reward_mean: -103.63585434173667
reward_std: 2.4972372054874286
reward_max: -100.24579831932773
reward_min: -106.73669467787116
queue_len: 0.0687240413406742
wait_time: 0.6504713733415559
delay_time: 4.418004013528943
pressure: 0.8418435013262598
total_envstep_count: 633360
total_train_sample_count: 633360
total_episode_count: 5460
total_duration: 21027.950080156326
[2025-02-20 23:20:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.336103490406714
avg_train_sample_per_sec: 31.336103490406714
avg_episode_per_sec: 0.27013882319316135
collect_time: 22.21080231666565
reward_mean: -112.10259103641455
reward_std: 2.882209534159168
reward_max: -108.85504201680672
reward_min: -117.05462184873952
queue_len: 0.07433858822043406
wait_time: 0.7078986767120642
delay_time: 4.805573160954292
pressure: 0.905393457117595
total_envstep_count: 634056
total_train_sample_count: 634056
total_episode_count: 5466
total_duration: 21050.160882472992
[2025-02-20 23:21:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.608737626161634
avg_train_sample_per_sec: 31.608737626161634
avg_episode_per_sec: 0.2724891174669106
collect_time: 22.019227981567383
reward_mean: -109.02906162464986
reward_std: 3.6796412398305347
reward_max: -104.51190476190473
reward_min: -113.93627450980392
queue_len: 0.0723004387431365
wait_time: 0.6882721811094022
delay_time: 4.577930124136642
pressure: 0.8889257294429709
total_envstep_count: 634752
total_train_sample_count: 634752
total_episode_count: 5472
total_duration: 21072.18011045456
[2025-02-20 23:21:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.690001398850303
avg_train_sample_per_sec: 31.690001398850303
avg_episode_per_sec: 0.27318966723146815
collect_time: 21.96276330947876
reward_mean: -107.71055088702148
reward_std: 2.617478904598283
reward_max: -103.95798319327729
reward_min: -110.39705882352942
queue_len: 0.07142609475266677
wait_time: 0.6750530782604818
delay_time: 4.644153858363931
pressure: 0.8708001768346595
total_envstep_count: 635448
total_train_sample_count: 635448
total_episode_count: 5478
total_duration: 21094.142873764038
[2025-02-20 23:21:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70808790015237
avg_train_sample_per_sec: 31.70808790015237
avg_episode_per_sec: 0.2733455853461411
collect_time: 21.950235605239868
reward_mean: -107.88877217553689
reward_std: 3.692527724828365
reward_max: -103.99859943977592
reward_min: -115.59803921568633
queue_len: 0.07154427863099265
wait_time: 0.6807523738938546
delay_time: 4.579137046988356
pressure: 0.8696949602122016
total_envstep_count: 636144
total_train_sample_count: 636144
total_episode_count: 5484
total_duration: 21116.093109369278
[2025-02-20 23:22:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07135204380362
avg_train_sample_per_sec: 32.07135204380362
avg_episode_per_sec: 0.27647717279141054
collect_time: 21.701610803604126
reward_mean: -105.2233893557423
reward_std: 2.662417588040814
reward_max: -100.90896358543418
reward_min: -108.41246498599438
queue_len: 0.06977678339240205
wait_time: 0.6626349478783555
delay_time: 4.434976040646623
pressure: 0.847922192749779
total_envstep_count: 636840
total_train_sample_count: 636840
total_episode_count: 5490
total_duration: 21137.794720172882
[2025-02-20 23:22:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59324295090582
avg_train_sample_per_sec: 31.59324295090582
avg_episode_per_sec: 0.2723555426802226
collect_time: 22.030027151107788
reward_mean: -108.0093370681606
reward_std: 2.029052880360622
reward_max: -104.84593837535012
reward_min: -110.74999999999999
queue_len: 0.0716242288250402
wait_time: 0.6811005016507045
delay_time: 4.570501530745314
pressure: 0.8694739168877099
total_envstep_count: 637536
total_train_sample_count: 637536
total_episode_count: 5496
total_duration: 21159.82474732399
[2025-02-20 23:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.723290042379286
avg_train_sample_per_sec: 31.723290042379286
avg_episode_per_sec: 0.27347663829637314
collect_time: 21.939716815948486
reward_mean: -108.24801587301586
reward_std: 2.599191666971079
reward_max: -106.3984593837535
reward_min: -113.90966386554618
queue_len: 0.07178250389457286
wait_time: 0.6831230171113539
delay_time: 4.6006964240894845
pressure: 0.8806366047745358
total_envstep_count: 638232
total_train_sample_count: 638232
total_episode_count: 5502
total_duration: 21181.76446413994
[2025-02-20 23:23:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78381901055974
avg_train_sample_per_sec: 31.78381901055974
avg_episode_per_sec: 0.27399843974620464
collect_time: 21.897934913635254
reward_mean: -106.24439775910362
reward_std: 2.2806370152395363
reward_max: -102.60434173669468
reward_min: -109.4166666666666
queue_len: 0.0704538446678406
wait_time: 0.6682079330405902
delay_time: 4.479829999025365
pressure: 0.8667108753315649
total_envstep_count: 638928
total_train_sample_count: 638928
total_episode_count: 5508
total_duration: 21203.662399053574
[2025-02-20 23:23:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.655610587124176
avg_train_sample_per_sec: 31.655610587124176
avg_episode_per_sec: 0.2728931947165877
collect_time: 21.986623764038086
reward_mean: -109.59337068160598
reward_std: 3.3416571238565793
reward_max: -104.91246498599443
reward_min: -113.187675070028
queue_len: 0.0726746489931074
wait_time: 0.6933468900380664
delay_time: 4.638518135602421
pressure: 0.8818523430592397
total_envstep_count: 639624
total_train_sample_count: 639624
total_episode_count: 5514
total_duration: 21225.64902281761
[2025-02-20 23:24:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39725204042276
avg_train_sample_per_sec: 31.39725204042276
avg_episode_per_sec: 0.27066596586571345
collect_time: 22.167545080184937
reward_mean: -108.75758636788048
reward_std: 3.1777938465704367
reward_max: -103.8102240896358
reward_min: -113.046918767507
queue_len: 0.07212041536331595
wait_time: 0.6869637222705175
delay_time: 4.563508844486894
pressure: 0.882736516357206
total_envstep_count: 640320
total_train_sample_count: 640320
total_episode_count: 5520
total_duration: 21247.816567897797
[2025-02-20 23:24:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.621885544381584
avg_train_sample_per_sec: 31.621885544381584
avg_episode_per_sec: 0.2726024615894964
collect_time: 22.010072708129883
reward_mean: -108.41654995331466
reward_std: 2.7854149875159573
reward_max: -103.57142857142856
reward_min: -112.09803921568628
queue_len: 0.07189426389477101
wait_time: 0.6886155877028087
delay_time: 4.580045465442847
pressure: 0.8769893899204244
total_envstep_count: 641016
total_train_sample_count: 641016
total_episode_count: 5526
total_duration: 21269.826640605927
[2025-02-20 23:24:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.247335951425413
avg_train_sample_per_sec: 31.247335951425413
avg_episode_per_sec: 0.2693735857881501
collect_time: 22.27389883995056
reward_mean: -106.52672735760969
reward_std: 4.003080671766326
reward_max: -101.25070028011201
reward_min: -111.19607843137253
queue_len: 0.0706410658870091
wait_time: 0.6650500164698948
delay_time: 4.514846529506726
pressure: 0.8563218390804598
total_envstep_count: 641712
total_train_sample_count: 641712
total_episode_count: 5532
total_duration: 21292.100539445877
[2025-02-20 23:25:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.713776444523344
avg_train_sample_per_sec: 31.713776444523344
avg_episode_per_sec: 0.27339462452175295
collect_time: 21.946298360824585
reward_mean: -108.28781512605042
reward_std: 3.339488252374555
reward_max: -104.5343137254902
reward_min: -113.04831932773104
queue_len: 0.07180889597218197
wait_time: 0.681836616167245
delay_time: 4.551551898674459
pressure: 0.8741158267020337
total_envstep_count: 642408
total_train_sample_count: 642408
total_episode_count: 5538
total_duration: 21314.0468378067
[2025-02-20 23:25:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.870783148679486
avg_train_sample_per_sec: 31.870783148679486
avg_episode_per_sec: 0.27474813059206454
collect_time: 21.838183164596558
reward_mean: -108.59056956115784
reward_std: 3.87311193946236
reward_max: -103.99719887955186
reward_min: -115.43767507002799
queue_len: 0.07200966151270412
wait_time: 0.6850030463113629
delay_time: 4.5929747343595375
pressure: 0.8717948717948719
total_envstep_count: 643104
total_train_sample_count: 643104
total_episode_count: 5544
total_duration: 21335.8850209713
[2025-02-20 23:25:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.731148189101468
avg_train_sample_per_sec: 31.731148189101468
avg_episode_per_sec: 0.2735443809405299
collect_time: 21.93428349494934
reward_mean: -108.7014472455649
reward_std: 2.195534681801635
reward_max: -105.33613445378153
reward_min: -111.186974789916
queue_len: 0.07208318782862394
wait_time: 0.6834750146743046
delay_time: 4.554066705237622
pressure: 0.8818523430592395
total_envstep_count: 643800
total_train_sample_count: 643800
total_episode_count: 5550
total_duration: 21357.819304466248
[2025-02-20 23:26:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.552257053770628
avg_train_sample_per_sec: 31.552257053770628
avg_episode_per_sec: 0.2720022159807813
collect_time: 22.05864381790161
reward_mean: -106.91935107376285
reward_std: 4.3226493484497315
reward_max: -102.8466386554622
reward_min: -115.63935574229687
queue_len: 0.0709014264414873
wait_time: 0.6672748453935067
delay_time: 4.568347722217743
pressure: 0.8622900088417329
total_envstep_count: 644496
total_train_sample_count: 644496
total_episode_count: 5556
total_duration: 21379.87794828415
[2025-02-20 23:26:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.692618524980414
avg_train_sample_per_sec: 31.692618524980414
avg_episode_per_sec: 0.27321222866362427
collect_time: 21.960949659347534
reward_mean: -105.999883286648
reward_std: 2.2022959083312585
reward_max: -101.96778711484598
reward_min: -108.86694677871147
queue_len: 0.0702916997922069
wait_time: 0.6636472117582665
delay_time: 4.455834301233831
pressure: 0.8637267904509284
total_envstep_count: 645192
total_train_sample_count: 645192
total_episode_count: 5562
total_duration: 21401.838897943497
[2025-02-20 23:27:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929342949119693
avg_train_sample_per_sec: 31.929342949119693
avg_episode_per_sec: 0.2752529564579284
collect_time: 21.798130989074707
reward_mean: -105.90067693744163
reward_std: 4.664417210538447
reward_max: -101.10434173669469
reward_min: -115.02941176470588
queue_len: 0.07022591308848915
wait_time: 0.6647642699873937
delay_time: 4.407821212360867
pressure: 0.8608532272325377
total_envstep_count: 645888
total_train_sample_count: 645888
total_episode_count: 5568
total_duration: 21423.63702893257
[2025-02-20 23:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4642177243866
avg_train_sample_per_sec: 31.4642177243866
avg_episode_per_sec: 0.27124325624471207
collect_time: 22.120365619659424
reward_mean: -108.01563958916898
reward_std: 4.204461277761822
reward_max: -100.4327731092437
reward_min: -112.40266106442574
queue_len: 0.0716284082156293
wait_time: 0.6836408745637955
delay_time: 4.53161069946845
pressure: 0.8788682581786031
total_envstep_count: 646584
total_train_sample_count: 646584
total_episode_count: 5574
total_duration: 21445.75739455223
[2025-02-20 23:27:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.56988549513272
avg_train_sample_per_sec: 31.56988549513272
avg_episode_per_sec: 0.2721541853028683
collect_time: 22.046326398849487
reward_mean: -107.18242296918767
reward_std: 2.3567927864455345
reward_max: -103.71918767507005
reward_min: -111.6358543417367
queue_len: 0.07107587730052232
wait_time: 0.680787124752642
delay_time: 4.453737051239471
pressure: 0.8650530503978779
total_envstep_count: 647280
total_train_sample_count: 647280
total_episode_count: 5580
total_duration: 21467.80372095108
[2025-02-20 23:28:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.692832882185698
avg_train_sample_per_sec: 31.692832882185698
avg_episode_per_sec: 0.27321407657056634
collect_time: 21.960801124572754
reward_mean: -105.29936974789912
reward_std: 2.402544169639342
reward_max: -100.59033613445378
reward_min: -107.68487394957982
queue_len: 0.06982716826783762
wait_time: 0.6619706569630506
delay_time: 4.447611974316221
pressure: 0.8530061892130858
total_envstep_count: 647976
total_train_sample_count: 647976
total_episode_count: 5586
total_duration: 21489.764522075653
[2025-02-20 23:28:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76002870901006
avg_train_sample_per_sec: 31.76002870901006
avg_episode_per_sec: 0.27379335093974194
collect_time: 21.914337873458862
reward_mean: -104.8019374416433
reward_std: 3.2831674057160884
reward_max: -100.37815126050423
reward_min: -110.87535014005599
queue_len: 0.06949730599578467
wait_time: 0.6628790552472094
delay_time: 4.443864956564079
pressure: 0.8464854111405836
total_envstep_count: 648672
total_train_sample_count: 648672
total_episode_count: 5592
total_duration: 21511.678859949112
[2025-02-20 23:28:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.802571970063287
avg_train_sample_per_sec: 31.802571970063287
avg_episode_per_sec: 0.27416010319020073
collect_time: 21.885022401809692
reward_mean: -108.39344070961717
reward_std: 3.586242924602033
reward_max: -103.45658263305322
reward_min: -114.99999999999999
queue_len: 0.07187893946261086
wait_time: 0.6819967487437061
delay_time: 4.537886777979293
pressure: 0.8748894783377542
total_envstep_count: 649368
total_train_sample_count: 649368
total_episode_count: 5598
total_duration: 21533.56388235092
[2025-02-20 23:29:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.915654835831862
avg_train_sample_per_sec: 31.915654835831862
avg_episode_per_sec: 0.2751349554813092
collect_time: 21.807479858398438
reward_mean: -104.9735060690943
reward_std: 1.9170849646874466
reward_max: -101.24509803921565
reward_min: -107.66946778711481
queue_len: 0.06961107829515537
wait_time: 0.664042628545671
delay_time: 4.448793704908536
pressure: 0.8423961096374889
total_envstep_count: 650064
total_train_sample_count: 650064
total_episode_count: 5604
total_duration: 21555.37136220932
[2025-02-20 23:29:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07361036778024
avg_train_sample_per_sec: 32.07361036778024
avg_episode_per_sec: 0.2764966411015538
collect_time: 21.700082778930664
reward_mean: -104.72642390289451
reward_std: 1.0400571655474564
reward_max: -103.30112044817928
reward_min: -106.43697478991598
queue_len: 0.0694472307048372
wait_time: 0.6576673551825682
delay_time: 4.427284709776485
pressure: 0.8514588859416445
total_envstep_count: 650760
total_train_sample_count: 650760
total_episode_count: 5610
total_duration: 21577.07144498825
[2025-02-20 23:30:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.63538483030481
avg_train_sample_per_sec: 31.63538483030481
avg_episode_per_sec: 0.272718834744007
collect_time: 22.000680685043335
reward_mean: -108.61076097105509
reward_std: 3.483590803127
reward_max: -102.63795518207282
reward_min: -112.46988795518203
queue_len: 0.07202305104181372
wait_time: 0.6836896341206685
delay_time: 4.607271241472077
pressure: 0.8785366931918657
total_envstep_count: 651456
total_train_sample_count: 651456
total_episode_count: 5616
total_duration: 21599.072125673294
[2025-02-20 23:30:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68874063986182
avg_train_sample_per_sec: 31.68874063986182
avg_episode_per_sec: 0.27317879861949845
collect_time: 21.963637113571167
reward_mean: -110.36332866479925
reward_std: 2.545037194192607
reward_max: -106.55952380952378
reward_min: -113.74859943977587
queue_len: 0.07318523121007908
wait_time: 0.694624854804875
delay_time: 4.5742255459638494
pressure: 0.905393457117595
total_envstep_count: 652152
total_train_sample_count: 652152
total_episode_count: 5622
total_duration: 21621.035762786865
[2025-02-20 23:30:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81869754487276
avg_train_sample_per_sec: 31.81869754487276
avg_episode_per_sec: 0.2742991167661445
collect_time: 21.873931169509888
reward_mean: -105.11321195144724
reward_std: 2.9945701674564784
reward_max: -101.28151260504202
reward_min: -110.11554621848735
queue_len: 0.06970372145321435
wait_time: 0.6615650238875391
delay_time: 4.50246878745411
pressure: 0.850685234305924
total_envstep_count: 652848
total_train_sample_count: 652848
total_episode_count: 5628
total_duration: 21642.909693956375
[2025-02-20 23:31:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47563422920991
avg_train_sample_per_sec: 31.47563422920991
avg_episode_per_sec: 0.2713416743897406
collect_time: 22.112342357635498
reward_mean: -106.76085434173667
reward_std: 3.228181937046947
reward_max: -101.51190476190477
reward_min: -112.17086834733894
queue_len: 0.07079632250778295
wait_time: 0.6767231317814483
delay_time: 4.476641100734279
pressure: 0.8617374005305041
total_envstep_count: 653544
total_train_sample_count: 653544
total_episode_count: 5634
total_duration: 21665.02203631401
[2025-02-20 23:31:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.557098707795152
avg_train_sample_per_sec: 31.557098707795152
avg_episode_per_sec: 0.2720439543775444
collect_time: 22.055259466171265
reward_mean: -105.75536881419237
reward_std: 3.7126589994618784
reward_max: -102.32983193277315
reward_min: -112.15756302521007
queue_len: 0.07012955491657319
wait_time: 0.6650993951957441
delay_time: 4.456315297331827
pressure: 0.8533377541998233
total_envstep_count: 654240
total_train_sample_count: 654240
total_episode_count: 5640
total_duration: 21687.077295780182
[2025-02-20 23:31:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0522741712754
avg_train_sample_per_sec: 32.0522741712754
avg_episode_per_sec: 0.27631270837306376
collect_time: 21.71452784538269
reward_mean: -105.57749766573295
reward_std: 4.820664062375879
reward_max: -101.75980392156862
reward_min: -116.11204481792714
queue_len: 0.07001160322661337
wait_time: 0.6662063145328866
delay_time: 4.464456877498681
pressure: 0.8456012378426171
total_envstep_count: 654936
total_train_sample_count: 654936
total_episode_count: 5646
total_duration: 21708.791823625565
[2025-02-20 23:32:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.616308669837355
avg_train_sample_per_sec: 31.616308669837355
avg_episode_per_sec: 0.2725543850848048
collect_time: 22.013955116271973
reward_mean: -107.23867880485528
reward_std: 4.265531792098455
reward_max: -100.46498599439772
reward_min: -114.09733893557423
queue_len: 0.07111318223133639
wait_time: 0.6754368856295834
delay_time: 4.564080516443197
pressure: 0.8580901856763926
total_envstep_count: 655632
total_train_sample_count: 655632
total_episode_count: 5652
total_duration: 21730.805778741837
[2025-02-20 23:32:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.984888661030624
avg_train_sample_per_sec: 31.984888661030624
avg_episode_per_sec: 0.2757317988019881
collect_time: 21.760275840759277
reward_mean: -108.781162464986
reward_std: 4.862798878494704
reward_max: -103.57492997198881
reward_min: -116.88375350140055
queue_len: 0.07213604937996418
wait_time: 0.6853458337357933
delay_time: 4.5886350257356625
pressure: 0.8700265251989391
total_envstep_count: 656328
total_train_sample_count: 656328
total_episode_count: 5658
total_duration: 21752.566054582596
[2025-02-20 23:32:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68136076253996
avg_train_sample_per_sec: 31.68136076253996
avg_episode_per_sec: 0.27311517898741344
collect_time: 21.968753337860107
reward_mean: -107.49766573295985
reward_std: 2.7216700346011726
reward_max: -102.65686274509805
reward_min: -110.75840336134455
queue_len: 0.07128492422610071
wait_time: 0.6809526750576446
delay_time: 4.523841567373807
pressure: 0.8612953138815206
total_envstep_count: 657024
total_train_sample_count: 657024
total_episode_count: 5664
total_duration: 21774.534807920456
[2025-02-20 23:33:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.774682023850595
avg_train_sample_per_sec: 31.774682023850595
avg_episode_per_sec: 0.2739196726194017
collect_time: 21.904231786727905
reward_mean: -107.66048085901029
reward_std: 4.585614683975121
reward_max: -100.42997198879551
reward_min: -114.7387955182073
queue_len: 0.07139289181631982
wait_time: 0.6808331754452442
delay_time: 4.493069509579111
pressure: 0.872236958443855
total_envstep_count: 657720
total_train_sample_count: 657720
total_episode_count: 5670
total_duration: 21796.439039707184
[2025-02-20 23:33:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.804554396584788
avg_train_sample_per_sec: 30.804554396584788
avg_episode_per_sec: 0.26555650341883436
collect_time: 22.594061613082886
reward_mean: -107.8454715219421
reward_std: 1.3526976191305178
reward_max: -106.19187675070027
reward_min: -109.86064425770304
queue_len: 0.07151556466972288
wait_time: 0.6783165631416138
delay_time: 4.5293549772874035
pressure: 0.8627320954907164
total_envstep_count: 658416
total_train_sample_count: 658416
total_episode_count: 5676
total_duration: 21819.033101320267
[2025-02-20 23:34:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.501071581265997
avg_train_sample_per_sec: 31.501071581265997
avg_episode_per_sec: 0.2715609619074655
collect_time: 22.094486474990845
reward_mean: -105.72899159663866
reward_std: 2.9585428891621843
reward_max: -100.75070028011203
reward_min: -109.43067226890754
queue_len: 0.07011206339299646
wait_time: 0.666063363895514
delay_time: 4.479595115550762
pressure: 0.8568744473916889
total_envstep_count: 659112
total_train_sample_count: 659112
total_episode_count: 5682
total_duration: 21841.127587795258
[2025-02-20 23:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74771894354119
avg_train_sample_per_sec: 31.74771894354119
avg_episode_per_sec: 0.27368723227190683
collect_time: 21.922834873199463
reward_mean: -105.67635387488328
reward_std: 1.604674134932811
reward_max: -104.20238095238092
reward_min: -109.06652661064425
queue_len: 0.07007715774196503
wait_time: 0.6652270987970784
delay_time: 4.453768073783668
pressure: 0.8568744473916888
total_envstep_count: 659808
total_train_sample_count: 659808
total_episode_count: 5688
total_duration: 21863.050422668457
[2025-02-20 23:34:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.596418984839303
avg_train_sample_per_sec: 31.596418984839303
avg_episode_per_sec: 0.27238292228309746
collect_time: 22.027812719345093
reward_mean: -108.06092436974791
reward_std: 3.267519359484987
reward_max: -103.56162464985995
reward_min: -112.00490196078431
queue_len: 0.07165843791097341
wait_time: 0.6831618699646084
delay_time: 4.5133321667920105
pressure: 0.8826259946949602
total_envstep_count: 660504
total_train_sample_count: 660504
total_episode_count: 5694
total_duration: 21885.078235387802
[2025-02-20 23:35:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76942694407217
avg_train_sample_per_sec: 31.76942694407217
avg_episode_per_sec: 0.2738743702075187
collect_time: 21.90785503387451
reward_mean: -107.87570028011203
reward_std: 2.088217162764485
reward_max: -105.65476190476193
reward_min: -111.51680672268904
queue_len: 0.07153561026532627
wait_time: 0.6782403279614234
delay_time: 4.490198231577506
pressure: 0.8786472148541113
total_envstep_count: 661200
total_train_sample_count: 661200
total_episode_count: 5700
total_duration: 21906.986090421677
[2025-02-20 23:35:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69789124617787
avg_train_sample_per_sec: 31.69789124617787
avg_episode_per_sec: 0.2732576831567058
collect_time: 21.95729660987854
reward_mean: -106.63468720821663
reward_std: 2.3510708195094345
reward_max: -103.64775910364148
reward_min: -110.96218487394958
queue_len: 0.07071265729987841
wait_time: 0.6699797624620141
delay_time: 4.510754524292072
pressure: 0.8584217506631299
total_envstep_count: 661896
total_train_sample_count: 661896
total_episode_count: 5706
total_duration: 21928.943387031555
[2025-02-20 23:36:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.646465846603324
avg_train_sample_per_sec: 31.646465846603324
avg_episode_per_sec: 0.2728143607465804
collect_time: 21.992977142333984
reward_mean: -106.17156862745098
reward_std: 1.5410538063800658
reward_max: -103.33473389355741
reward_min: -107.46988795518206
queue_len: 0.07040554948769957
wait_time: 0.6660779143664539
delay_time: 4.473129102035597
pressure: 0.8584217506631301
total_envstep_count: 662592
total_train_sample_count: 662592
total_episode_count: 5712
total_duration: 21950.93636417389
[2025-02-20 23:36:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.551883972106364
avg_train_sample_per_sec: 31.551883972106364
avg_episode_per_sec: 0.2719989997595376
collect_time: 22.05890464782715
reward_mean: -107.39670868347338
reward_std: 5.781363230237391
reward_max: -103.06932773109244
reward_min: -119.86274509803923
queue_len: 0.07121797658055265
wait_time: 0.6739916678430876
delay_time: 4.460346850553758
pressure: 0.8699160035366932
total_envstep_count: 663288
total_train_sample_count: 663288
total_episode_count: 5718
total_duration: 21972.995268821716
[2025-02-20 23:36:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52643908740063
avg_train_sample_per_sec: 31.52643908740063
avg_episode_per_sec: 0.27177964730517784
collect_time: 22.07670831680298
reward_mean: -109.05497198879551
reward_std: 3.1898841598410406
reward_max: -104.23459383753502
reward_min: -114.35784313725489
queue_len: 0.07231762068222515
wait_time: 0.6926144905353832
delay_time: 4.593648904729869
pressure: 0.8851679929266135
total_envstep_count: 663984
total_train_sample_count: 663984
total_episode_count: 5724
total_duration: 21995.07197713852
[2025-02-20 23:37:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.672341684677885
avg_train_sample_per_sec: 31.672341684677885
avg_episode_per_sec: 0.27303742831618866
collect_time: 21.975009202957153
reward_mean: -105.6796218487395
reward_std: 3.406368476778604
reward_max: -102.83963585434172
reward_min: -113.11134453781514
queue_len: 0.07007932483338163
wait_time: 0.6657750633409862
delay_time: 4.488585160186251
pressure: 0.8666003536693191
total_envstep_count: 664680
total_train_sample_count: 664680
total_episode_count: 5730
total_duration: 22017.046986341476
[2025-02-20 23:37:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.313284108403828
avg_train_sample_per_sec: 31.313284108403828
avg_episode_per_sec: 0.2699421043827916
collect_time: 22.226988315582275
reward_mean: -108.74241363211952
reward_std: 3.846911325768332
reward_max: -101.10224089635852
reward_min: -112.9425770308123
queue_len: 0.07211035386745328
wait_time: 0.6887031227168143
delay_time: 4.556044159154025
pressure: 0.8892572944297082
total_envstep_count: 665376
total_train_sample_count: 665376
total_episode_count: 5736
total_duration: 22039.27397465706
[2025-02-20 23:37:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.552632190482363
avg_train_sample_per_sec: 31.552632190482363
avg_episode_per_sec: 0.2720054499179514
collect_time: 22.0583815574646
reward_mean: -107.42460317460315
reward_std: 2.159968217183047
reward_max: -104.23109243697478
reward_min: -110.68067226890756
queue_len: 0.07123647425371564
wait_time: 0.6726178092810953
delay_time: 4.438209004169841
pressure: 0.8706896551724138
total_envstep_count: 666072
total_train_sample_count: 666072
total_episode_count: 5742
total_duration: 22061.332356214523
[2025-02-20 23:38:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.847346853352043
avg_train_sample_per_sec: 31.847346853352043
avg_episode_per_sec: 0.27454609356337967
collect_time: 21.8542537689209
reward_mean: -107.62523342670401
reward_std: 3.7415732088991174
reward_max: -99.92086834733895
reward_min: -110.14915966386553
queue_len: 0.07136951818746949
wait_time: 0.6757352476799737
delay_time: 4.5719759419559205
pressure: 0.8734526967285587
total_envstep_count: 666768
total_train_sample_count: 666768
total_episode_count: 5748
total_duration: 22083.186609983444
[2025-02-20 23:38:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.585806321857998
avg_train_sample_per_sec: 31.585806321857998
avg_episode_per_sec: 0.2722914338091207
collect_time: 22.035213947296143
reward_mean: -104.76832399626515
reward_std: 6.13792424152715
reward_max: -96.48249299719885
reward_min: -112.84453781512606
queue_len: 0.06947501591264267
wait_time: 0.6637770824510175
delay_time: 4.515618571536728
pressure: 0.8436118479221927
total_envstep_count: 667464
total_train_sample_count: 667464
total_episode_count: 5754
total_duration: 22105.22182393074
[2025-02-20 23:39:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.618881787917225
avg_train_sample_per_sec: 31.618881787917225
avg_episode_per_sec: 0.27257656713721745
collect_time: 22.012163639068604
reward_mean: -104.55637254901961
reward_std: 3.6199864604798826
reward_max: -100.27310924369746
reward_min: -109.85364145658265
queue_len: 0.0693344645550528
wait_time: 0.6581033275379117
delay_time: 4.445453555938552
pressure: 0.8437223695844386
total_envstep_count: 668160
total_train_sample_count: 668160
total_episode_count: 5760
total_duration: 22127.23398756981
[2025-02-20 23:39:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.297204914493268
avg_train_sample_per_sec: 31.297204914493268
avg_episode_per_sec: 0.26980349064218334
collect_time: 22.238407611846924
reward_mean: -108.1373716153128
reward_std: 4.217517819046218
reward_max: -103.63585434173669
reward_min: -114.6421568627451
queue_len: 0.07170913237089709
wait_time: 0.681814790460835
delay_time: 4.4641416585357065
pressure: 0.8789787798408487
total_envstep_count: 668856
total_train_sample_count: 668856
total_episode_count: 5766
total_duration: 22149.472395181656
[2025-02-20 23:39:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.837766699938573
avg_train_sample_per_sec: 31.837766699938573
avg_episode_per_sec: 0.2744635060339532
collect_time: 21.860829830169678
reward_mean: -104.36612978524745
reward_std: 3.473170050470137
reward_max: -99.6491596638656
reward_min: -110.84523809523809
queue_len: 0.0692083088761588
wait_time: 0.6563511567314811
delay_time: 4.4350389262579055
pressure: 0.8597480106100797
total_envstep_count: 669552
total_train_sample_count: 669552
total_episode_count: 5772
total_duration: 22171.333225011826
[2025-02-20 23:40:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.569779999641828
avg_train_sample_per_sec: 31.569779999641828
avg_episode_per_sec: 0.27215327585898125
collect_time: 22.04640007019043
reward_mean: -108.97852474323064
reward_std: 3.4295609336392965
reward_max: -105.50700280112045
reward_min: -114.59173669467789
queue_len: 0.07226692622230148
wait_time: 0.6896205763472499
delay_time: 4.5173883116234235
pressure: 0.8820733863837312
total_envstep_count: 670248
total_train_sample_count: 670248
total_episode_count: 5778
total_duration: 22193.379625082016
[2025-02-20 23:40:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77272495445243
avg_train_sample_per_sec: 31.77272495445243
avg_episode_per_sec: 0.2739028013314865
collect_time: 21.90558099746704
reward_mean: -105.87885154061622
reward_std: 5.221008934360436
reward_max: -99.00140056022404
reward_min: -115.75910364145662
queue_len: 0.07021144001367124
wait_time: 0.6641080282687788
delay_time: 4.4497684446824115
pressure: 0.8647214854111406
total_envstep_count: 670944
total_train_sample_count: 670944
total_episode_count: 5784
total_duration: 22215.285206079483
[2025-02-20 23:40:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.572575014721323
avg_train_sample_per_sec: 31.572575014721323
avg_episode_per_sec: 0.2721773708165631
collect_time: 22.044448375701904
reward_mean: -108.49883286647996
reward_std: 4.279577705427573
reward_max: -101.11134453781511
reward_min: -115.19257703081234
queue_len: 0.07194882816079573
wait_time: 0.6872246245978498
delay_time: 4.595563368981675
pressure: 0.8815207780725021
total_envstep_count: 671640
total_train_sample_count: 671640
total_episode_count: 5790
total_duration: 22237.329654455185
[2025-02-20 23:41:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.844388345828982
avg_train_sample_per_sec: 31.844388345828982
avg_episode_per_sec: 0.2745205891881809
collect_time: 21.856284141540527
reward_mean: -106.12324929971989
reward_std: 2.405976008521459
reward_max: -101.41246498599443
reward_min: -108.63725490196079
queue_len: 0.07037350749318295
wait_time: 0.6747929498943698
delay_time: 4.454956674609782
pressure: 0.8636162687886827
total_envstep_count: 672336
total_train_sample_count: 672336
total_episode_count: 5796
total_duration: 22259.185938596725
[2025-02-20 23:41:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57524825779591
avg_train_sample_per_sec: 31.57524825779591
avg_episode_per_sec: 0.272200416015482
collect_time: 22.042582035064697
reward_mean: -108.20424836601308
reward_std: 2.5957879901272425
reward_max: -105.30392156862747
reward_min: -112.51960784313725
queue_len: 0.07175348034881503
wait_time: 0.6838845175559172
delay_time: 4.502808460828208
pressure: 0.876105216622458
total_envstep_count: 673032
total_train_sample_count: 673032
total_episode_count: 5802
total_duration: 22281.22852063179
[2025-02-20 23:42:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62959859850255
avg_train_sample_per_sec: 31.62959859850255
avg_episode_per_sec: 0.2726689534353668
collect_time: 22.00470542907715
reward_mean: -107.28956582633053
reward_std: 2.325863658306236
reward_max: -103.69397759103637
reward_min: -111.06372549019609
queue_len: 0.0711469269405375
wait_time: 0.6754784473471086
delay_time: 4.557328245282173
pressure: 0.8590848806366048
total_envstep_count: 673728
total_train_sample_count: 673728
total_episode_count: 5808
total_duration: 22303.233226060867
[2025-02-20 23:42:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.714505830858972
avg_train_sample_per_sec: 31.714505830858972
avg_episode_per_sec: 0.27340091233499114
collect_time: 21.945793628692627
reward_mean: -107.39122315592903
reward_std: 5.709311956611272
reward_max: -99.75420168067224
reward_min: -117.05882352941177
queue_len: 0.07121433896281765
wait_time: 0.6803402395440933
delay_time: 4.484135730242437
pressure: 0.8736737400530504
total_envstep_count: 674424
total_train_sample_count: 674424
total_episode_count: 5814
total_duration: 22325.17901968956
[2025-02-20 23:42:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73409121141949
avg_train_sample_per_sec: 31.73409121141949
avg_episode_per_sec: 0.2735697518225818
collect_time: 21.932249307632446
reward_mean: -107.45436507936508
reward_std: 4.135875910068134
reward_max: -100.92156862745094
reward_min: -114.03501400560222
queue_len: 0.07125621026483096
wait_time: 0.6760413493425664
delay_time: 4.501075391432759
pressure: 0.868921308576481
total_envstep_count: 675120
total_train_sample_count: 675120
total_episode_count: 5820
total_duration: 22347.111268997192
[2025-02-20 23:43:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87330667888855
avg_train_sample_per_sec: 31.87330667888855
avg_episode_per_sec: 0.2747698851628323
collect_time: 21.836454153060913
reward_mean: -109.95051353874885
reward_std: 3.471337810770213
reward_max: -105.84593837535016
reward_min: -115.62675070028011
queue_len: 0.07291148112649128
wait_time: 0.6976204717076927
delay_time: 4.639018921389437
pressure: 0.8873784261715296
total_envstep_count: 675816
total_train_sample_count: 675816
total_episode_count: 5826
total_duration: 22368.947723150253
[2025-02-20 23:43:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.58587433123607
avg_train_sample_per_sec: 31.58587433123607
avg_episode_per_sec: 0.27229202009686265
collect_time: 22.0351665019989
reward_mean: -107.9751400560224
reward_std: 2.833349682097879
reward_max: -104.9782913165266
reward_min: -113.21848739495795
queue_len: 0.07160155176128807
wait_time: 0.679469687963603
delay_time: 4.533110935993158
pressure: 0.8759946949602123
total_envstep_count: 676512
total_train_sample_count: 676512
total_episode_count: 5832
total_duration: 22390.982889652252
[2025-02-20 23:43:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.729151991034907
avg_train_sample_per_sec: 31.729151991034907
avg_episode_per_sec: 0.2735271723365078
collect_time: 21.93566346168518
reward_mean: -105.87710084033614
reward_std: 3.06042686902811
reward_max: -100.37394957983193
reward_min: -110.50070028011204
queue_len: 0.07021027907184094
wait_time: 0.6703954570333881
delay_time: 4.419196566584294
pressure: 0.8598585322723253
total_envstep_count: 677208
total_train_sample_count: 677208
total_episode_count: 5838
total_duration: 22412.918553113937
[2025-02-20 23:44:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.874112678135187
avg_train_sample_per_sec: 31.874112678135187
avg_episode_per_sec: 0.2747768334321999
collect_time: 21.835901975631714
reward_mean: -107.359126984127
reward_std: 2.2014861197648945
reward_max: -102.95868347338931
reward_min: -109.1477591036415
queue_len: 0.07119305502926195
wait_time: 0.6753433137180601
delay_time: 4.515936780383639
pressure: 0.8641688770999116
total_envstep_count: 677904
total_train_sample_count: 677904
total_episode_count: 5844
total_duration: 22434.75445508957
[2025-02-20 23:44:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929002454069177
avg_train_sample_per_sec: 31.929002454069177
avg_episode_per_sec: 0.27525002115576874
collect_time: 21.79836344718933
reward_mean: -106.93172268907561
reward_std: 2.6475922779329744
reward_max: -104.06232492997196
reward_min: -112.56442577030812
queue_len: 0.07090963043042149
wait_time: 0.6683201574175204
delay_time: 4.4998124869585885
pressure: 0.8736737400530504
total_envstep_count: 678600
total_train_sample_count: 678600
total_episode_count: 5850
total_duration: 22456.55281853676
[2025-02-20 23:45:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.63163404405219
avg_train_sample_per_sec: 31.63163404405219
avg_episode_per_sec: 0.2726865003797603
collect_time: 22.003289461135864
reward_mean: -106.1126283846872
reward_std: 4.641657224126699
reward_max: -98.04691876750701
reward_min: -111.79341736694681
queue_len: 0.07036646444607904
wait_time: 0.6699856445672875
delay_time: 4.462253017008843
pressure: 0.8611847922192749
total_envstep_count: 679296
total_train_sample_count: 679296
total_episode_count: 5856
total_duration: 22478.556107997894
[2025-02-20 23:45:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.625356501347397
avg_train_sample_per_sec: 31.625356501347397
avg_episode_per_sec: 0.27263238363230513
collect_time: 22.007657051086426
reward_mean: -106.38643790849672
reward_std: 2.994067128080574
reward_max: -101.34383753501406
reward_min: -109.57282913165264
queue_len: 0.07054803574834
wait_time: 0.6677075671117253
delay_time: 4.466578652897808
pressure: 0.8620689655172414
total_envstep_count: 679992
total_train_sample_count: 679992
total_episode_count: 5862
total_duration: 22500.56376504898
[2025-02-20 23:45:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.388535386878928
avg_train_sample_per_sec: 31.388535386878928
avg_episode_per_sec: 0.27059082230068043
collect_time: 22.17370104789734
reward_mean: -108.5514705882353
reward_std: 2.8277866087743324
reward_max: -105.6498599439776
reward_min: -112.77170868347339
queue_len: 0.07198373381182711
wait_time: 0.6855590600519607
delay_time: 4.599932892544914
pressure: 0.8812997347480106
total_envstep_count: 680688
total_train_sample_count: 680688
total_episode_count: 5868
total_duration: 22522.737466096878
[2025-02-20 23:46:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.857666326486115
avg_train_sample_per_sec: 31.857666326486115
avg_episode_per_sec: 0.2746350545386734
collect_time: 21.847174644470215
reward_mean: -107.06325863678806
reward_std: 1.7507779939178405
reward_max: -105.04201680672269
reward_min: -109.43067226890757
queue_len: 0.07099685585993903
wait_time: 0.6738717812500775
delay_time: 4.476113187174962
pressure: 0.8682581786030061
total_envstep_count: 681384
total_train_sample_count: 681384
total_episode_count: 5874
total_duration: 22544.58464074135
[2025-02-20 23:46:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.395633590836336
avg_train_sample_per_sec: 31.395633590836336
avg_episode_per_sec: 0.27065201371410635
collect_time: 22.16868782043457
reward_mean: -104.37826797385624
reward_std: 0.9504782904910091
reward_max: -102.91316526610645
reward_min: -105.78921568627456
queue_len: 0.06921635807284895
wait_time: 0.6541947459797358
delay_time: 4.368367335155406
pressure: 0.8467064544650752
total_envstep_count: 682080
total_train_sample_count: 682080
total_episode_count: 5880
total_duration: 22566.753328561783
[2025-02-20 23:46:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00437724031062
avg_train_sample_per_sec: 32.00437724031062
avg_episode_per_sec: 0.27589980379578116
collect_time: 21.74702525138855
reward_mean: -103.96195144724557
reward_std: 2.713611387083107
reward_max: -100.2738095238095
reward_min: -108.04341736694677
queue_len: 0.0689402861056005
wait_time: 0.6513816291326434
delay_time: 4.3621469752877315
pressure: 0.8449381078691424
total_envstep_count: 682776
total_train_sample_count: 682776
total_episode_count: 5886
total_duration: 22588.50035381317
[2025-02-20 23:47:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.901755680007653
avg_train_sample_per_sec: 31.901755680007653
avg_episode_per_sec: 0.2750151351724798
collect_time: 21.816981077194214
reward_mean: -106.54026610644259
reward_std: 1.6681487943980247
reward_max: -104.74719887955183
reward_min: -109.3452380952381
queue_len: 0.07065004383716351
wait_time: 0.6741939813060501
delay_time: 4.448577610590366
pressure: 0.8628426171529621
total_envstep_count: 683472
total_train_sample_count: 683472
total_episode_count: 5892
total_duration: 22610.317334890366
[2025-02-20 23:47:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.491673431515142
avg_train_sample_per_sec: 30.491673431515142
avg_episode_per_sec: 0.26285925371995816
collect_time: 22.82590365409851
reward_mean: -106.78326330532212
reward_std: 1.7919205578108164
reward_max: -104.49229691876755
reward_min: -109.74929971988794
queue_len: 0.07081118256321096
wait_time: 0.6710112979763081
delay_time: 4.484694288156458
pressure: 0.8630636604774535
total_envstep_count: 684168
total_train_sample_count: 684168
total_episode_count: 5898
total_duration: 22633.143238544464
[2025-02-20 23:48:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.606252734534955
avg_train_sample_per_sec: 31.606252734534955
avg_episode_per_sec: 0.2724676959873703
collect_time: 22.02095913887024
reward_mean: -105.3655462184874
reward_std: 2.3725395116533754
reward_max: -101.96988795518212
reward_min: -108.67016806722691
queue_len: 0.06987105186902348
wait_time: 0.6642123582412629
delay_time: 4.4295525207281035
pressure: 0.857869142351901
total_envstep_count: 684864
total_train_sample_count: 684864
total_episode_count: 5904
total_duration: 22655.164197683334
[2025-02-20 23:48:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.714132347788198
avg_train_sample_per_sec: 31.714132347788198
avg_episode_per_sec: 0.2733976926533465
collect_time: 21.946052074432373
reward_mean: -105.84337068160596
reward_std: 3.7921888804727932
reward_max: -98.4810924369748
reward_min: -109.83473389355736
queue_len: 0.0701879115925769
wait_time: 0.6647716226189857
delay_time: 4.453734170734834
pressure: 0.8641688770999116
total_envstep_count: 685560
total_train_sample_count: 685560
total_episode_count: 5910
total_duration: 22677.110249757767
[2025-02-20 23:48:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5451468309703
avg_train_sample_per_sec: 31.5451468309703
avg_episode_per_sec: 0.2719409209566405
collect_time: 22.063615798950195
reward_mean: -106.02521008403362
reward_std: 2.644186270824931
reward_max: -102.20728291316532
reward_min: -109.39565826330528
queue_len: 0.07030849475068542
wait_time: 0.6638094340300223
delay_time: 4.439823241571358
pressure: 0.8594164456233422
total_envstep_count: 686256
total_train_sample_count: 686256
total_episode_count: 5916
total_duration: 22699.173865556717
[2025-02-20 23:49:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.525281526986888
avg_train_sample_per_sec: 31.525281526986888
avg_episode_per_sec: 0.27176966833609384
collect_time: 22.077518939971924
reward_mean: -105.45226423902893
reward_std: 3.949960609857714
reward_max: -101.15266106442579
reward_min: -113.61064425770307
queue_len: 0.06992855718768497
wait_time: 0.6681677644532614
delay_time: 4.425049619371998
pressure: 0.8480327144120247
total_envstep_count: 686952
total_train_sample_count: 686952
total_episode_count: 5922
total_duration: 22721.25138449669
[2025-02-20 23:49:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.944231951165403
avg_train_sample_per_sec: 31.944231951165403
avg_episode_per_sec: 0.2753813099238397
collect_time: 21.787971019744873
reward_mean: -107.70168067226889
reward_std: 3.47021480783743
reward_max: -102.21008403361341
reward_min: -113.75420168067225
queue_len: 0.07142021264739316
wait_time: 0.6821399315694449
delay_time: 4.5086746324097895
pressure: 0.8624005305039789
total_envstep_count: 687648
total_train_sample_count: 687648
total_episode_count: 5928
total_duration: 22743.039355516434
[2025-02-20 23:49:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.657037612997367
avg_train_sample_per_sec: 31.657037612997367
avg_episode_per_sec: 0.2729054966637704
collect_time: 21.98563265800476
reward_mean: -107.22817460317458
reward_std: 3.192722449845289
reward_max: -102.83123249299715
reward_min: -111.34943977591034
queue_len: 0.0711062165803545
wait_time: 0.673606776928278
delay_time: 4.469180697373517
pressure: 0.8696949602122017
total_envstep_count: 688344
total_train_sample_count: 688344
total_episode_count: 5934
total_duration: 22765.02498817444
[2025-02-20 23:50:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6439547818688
avg_train_sample_per_sec: 31.6439547818688
avg_episode_per_sec: 0.27279271363679997
collect_time: 21.994722366333008
reward_mean: -107.36332866479927
reward_std: 3.9209299745201127
reward_max: -102.09243697478995
reward_min: -113.21078431372553
queue_len: 0.07119584128965468
wait_time: 0.6772885878489326
delay_time: 4.488702983401454
pressure: 0.8664898320070734
total_envstep_count: 689040
total_train_sample_count: 689040
total_episode_count: 5940
total_duration: 22787.01971054077
[2025-02-20 23:50:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.717671487570104
avg_train_sample_per_sec: 31.717671487570104
avg_episode_per_sec: 0.27342820247905264
collect_time: 21.94360327720642
reward_mean: -106.65721288515407
reward_std: 2.257131307082939
reward_max: -102.77170868347339
reward_min: -109.60784313725492
queue_len: 0.07072759475142842
wait_time: 0.6709862990288954
delay_time: 4.433881328648728
pressure: 0.8701370468611848
total_envstep_count: 689736
total_train_sample_count: 689736
total_episode_count: 5946
total_duration: 22808.963313817978
[2025-02-20 23:51:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.39331476800008
avg_train_sample_per_sec: 31.39331476800008
avg_episode_per_sec: 0.27063202386206964
collect_time: 22.17032527923584
reward_mean: -106.07387955182071
reward_std: 2.344125822278963
reward_max: -102.6435574229692
reward_min: -108.95588235294116
queue_len: 0.07034076893356811
wait_time: 0.6655377668308703
delay_time: 4.514075438939888
pressure: 0.8547745358090184
total_envstep_count: 690432
total_train_sample_count: 690432
total_episode_count: 5952
total_duration: 22831.133639097214
[2025-02-20 23:51:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.590711608573866
avg_train_sample_per_sec: 31.590711608573866
avg_episode_per_sec: 0.2723337207635678
collect_time: 22.031792402267456
reward_mean: -105.98972922502332
reward_std: 2.1945576786768695
reward_max: -101.56092436974787
reward_min: -108.60014005602241
queue_len: 0.07028496632959107
wait_time: 0.670583916590509
delay_time: 4.461966334532796
pressure: 0.8630636604774535
total_envstep_count: 691128
total_train_sample_count: 691128
total_episode_count: 5958
total_duration: 22853.16543149948
[2025-02-20 23:51:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.34850002928416
avg_train_sample_per_sec: 31.34850002928416
avg_episode_per_sec: 0.27024568990762204
collect_time: 22.202019214630127
reward_mean: -104.77836134453783
reward_std: 2.5412412600173915
reward_max: -101.58333333333334
reward_min: -107.57352941176474
queue_len: 0.06948167197913648
wait_time: 0.6596688962941499
delay_time: 4.43331381171653
pressure: 0.8444960212201592
total_envstep_count: 691824
total_train_sample_count: 691824
total_episode_count: 5964
total_duration: 22875.36745071411
[2025-02-20 23:52:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.644401735959153
avg_train_sample_per_sec: 31.644401735959153
avg_episode_per_sec: 0.272796566689303
collect_time: 21.99441170692444
reward_mean: -104.32539682539681
reward_std: 2.777343697693691
reward_max: -100.59803921568627
reward_min: -108.39845938375349
queue_len: 0.06918129762957348
wait_time: 0.658404785433183
delay_time: 4.380367382827408
pressure: 0.8467064544650751
total_envstep_count: 692520
total_train_sample_count: 692520
total_episode_count: 5970
total_duration: 22897.361862421036
[2025-02-20 23:52:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.709737002807906
avg_train_sample_per_sec: 31.709737002807906
avg_episode_per_sec: 0.273359801748344
collect_time: 21.94909405708313
reward_mean: -105.61426237161528
reward_std: 2.1924813922427364
reward_max: -103.27591036414563
reward_min: -109.83683473389358
queue_len: 0.07003598300504993
wait_time: 0.6627718616182104
delay_time: 4.461179277462171
pressure: 0.852343059239611
total_envstep_count: 693216
total_train_sample_count: 693216
total_episode_count: 5976
total_duration: 22919.31095647812
[2025-02-20 23:52:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.56165862235472
avg_train_sample_per_sec: 31.56165862235472
avg_episode_per_sec: 0.27208326398581656
collect_time: 22.052073001861572
reward_mean: -103.66269841269842
reward_std: 1.109094971316046
reward_max: -101.64705882352942
reward_min: -105.13375350140058
queue_len: 0.068741842448739
wait_time: 0.6558665022153866
delay_time: 4.323712702290567
pressure: 0.8441644562334217
total_envstep_count: 693912
total_train_sample_count: 693912
total_episode_count: 5982
total_duration: 22941.36302947998
[2025-02-20 23:53:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.799394193631244
avg_train_sample_per_sec: 31.799394193631244
avg_episode_per_sec: 0.2741327085657866
collect_time: 21.88720941543579
reward_mean: -106.34010270774975
reward_std: 2.4197222685187394
reward_max: -101.65686274509798
reward_min: -109.0574229691877
queue_len: 0.07051730948789771
wait_time: 0.6770286142750646
delay_time: 4.493938125896425
pressure: 0.8610742705570291
total_envstep_count: 694608
total_train_sample_count: 694608
total_episode_count: 5988
total_duration: 22963.250238895416
[2025-02-20 23:53:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.831722936972767
avg_train_sample_per_sec: 31.831722936972767
avg_episode_per_sec: 0.2744114046290756
collect_time: 21.864980459213257
reward_mean: -106.2298085901027
reward_std: 1.7085838535666271
reward_max: -103.38165266106442
reward_min: -108.34593837535019
queue_len: 0.07044417015258801
wait_time: 0.6660563208484099
delay_time: 4.542329159433145
pressure: 0.8547745358090185
total_envstep_count: 695304
total_train_sample_count: 695304
total_episode_count: 5994
total_duration: 22985.11521935463
[2025-02-20 23:54:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.696837387575293
avg_train_sample_per_sec: 31.696837387575293
avg_episode_per_sec: 0.2732485981687525
collect_time: 21.95802664756775
reward_mean: -106.68078898225957
reward_std: 0.9769128786007601
reward_max: -104.70938375350146
reward_min: -107.84103641456583
queue_len: 0.07074322876807665
wait_time: 0.6711307975887083
delay_time: 4.467010452625939
pressure: 0.8611847922192751
total_envstep_count: 696000
total_train_sample_count: 696000
total_episode_count: 6000
total_duration: 23007.073246002197
[2025-02-20 23:54:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.738448107307697
avg_train_sample_per_sec: 31.738448107307697
avg_episode_per_sec: 0.27360731126989396
collect_time: 21.92923855781555
reward_mean: -104.81314192343604
reward_std: 3.2575699424137396
reward_max: -100.13305322128848
reward_min: -110.88795518207283
queue_len: 0.0695047360234987
wait_time: 0.6652702084370441
delay_time: 4.4082413005758045
pressure: 0.8524535809018569
total_envstep_count: 696696
total_train_sample_count: 696696
total_episode_count: 6006
total_duration: 23029.002484560013
[2025-02-20 23:54:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.686514862554905
avg_train_sample_per_sec: 31.686514862554905
avg_episode_per_sec: 0.273159610884094
collect_time: 21.965179920196533
reward_mean: -107.49089635854341
reward_std: 1.4871025414114536
reward_max: -106.0049019607843
reward_min: -110.34243697478988
queue_len: 0.0712804352510235
wait_time: 0.6746702770409666
delay_time: 4.524695646902799
pressure: 0.8632847038019452
total_envstep_count: 697392
total_train_sample_count: 697392
total_episode_count: 6012
total_duration: 23050.96766448021
[2025-02-20 23:55:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67244958489818
avg_train_sample_per_sec: 31.67244958489818
avg_episode_per_sec: 0.27303835849050156
collect_time: 21.974934339523315
reward_mean: -107.22724089635852
reward_std: 3.5535865625199987
reward_max: -101.52801120448181
reward_min: -112.11554621848737
queue_len: 0.07110559741137834
wait_time: 0.669160834094911
delay_time: 4.479136081882792
pressure: 0.8706896551724137
total_envstep_count: 698088
total_train_sample_count: 698088
total_episode_count: 6018
total_duration: 23072.942598819733
[2025-02-20 23:55:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55873998877339
avg_train_sample_per_sec: 31.55873998877339
avg_episode_per_sec: 0.2720581033514947
collect_time: 22.054112434387207
reward_mean: -108.26715686274508
reward_std: 2.564905606291084
reward_max: -103.12254901960787
reward_min: -111.06302521008406
queue_len: 0.07179519685858428
wait_time: 0.6878183302498719
delay_time: 4.5573145824236905
pressure: 0.8742263483642794
total_envstep_count: 698784
total_train_sample_count: 698784
total_episode_count: 6024
total_duration: 23094.99671125412
[2025-02-20 23:55:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54287130937669
avg_train_sample_per_sec: 31.54287130937669
avg_episode_per_sec: 0.27192130439117834
collect_time: 22.065207481384277
reward_mean: -108.00735294117646
reward_std: 3.6041927239749283
reward_max: -102.54691876750698
reward_min: -112.32002801120446
queue_len: 0.07162291309096581
wait_time: 0.6789132872423947
delay_time: 4.556587182974767
pressure: 0.8745579133510168
total_envstep_count: 699480
total_train_sample_count: 699480
total_episode_count: 6030
total_duration: 23117.061918735504
[2025-02-20 23:56:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.601745951365235
avg_train_sample_per_sec: 31.601745951365235
avg_episode_per_sec: 0.272428844408321
collect_time: 22.024099588394165
reward_mean: -106.93767507002799
reward_std: 4.633240001225298
reward_max: -101.31092436974791
reward_min: -115.25630252100834
queue_len: 0.07091357763264457
wait_time: 0.6746914835784003
delay_time: 4.456761651093555
pressure: 0.873894783377542
total_envstep_count: 700176
total_train_sample_count: 700176
total_episode_count: 6036
total_duration: 23139.0860183239
[2025-02-20 23:56:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.434957792579574
avg_train_sample_per_sec: 31.434957792579574
avg_episode_per_sec: 0.2709910154532722
collect_time: 22.140955448150635
reward_mean: -107.61041083099907
reward_std: 3.3520718726988674
reward_max: -102.05252100840339
reward_min: -111.75350140056024
queue_len: 0.07135968887997286
wait_time: 0.6766176408671337
delay_time: 4.5055696634050495
pressure: 0.8737842617152963
total_envstep_count: 700872
total_train_sample_count: 700872
total_episode_count: 6042
total_duration: 23161.22697377205
[2025-02-20 23:57:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80355040825807
avg_train_sample_per_sec: 31.80355040825807
avg_episode_per_sec: 0.27416853800222474
collect_time: 21.88434910774231
reward_mean: -105.8985760971055
reward_std: 1.0421861698122519
reward_max: -104.15826330532214
reward_min: -107.11064425770309
queue_len: 0.07022451995829278
wait_time: 0.6639979709832651
delay_time: 4.475387034651772
pressure: 0.8543324491600354
total_envstep_count: 701568
total_train_sample_count: 701568
total_episode_count: 6048
total_duration: 23183.11132287979
[2025-02-20 23:57:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61599878701401
avg_train_sample_per_sec: 31.61599878701401
avg_episode_per_sec: 0.27255171368115527
collect_time: 22.01417088508606
reward_mean: -108.16666666666667
reward_std: 2.5084731212027367
reward_max: -103.3193277310924
reward_min: -111.02380952380953
queue_len: 0.07172855879752431
wait_time: 0.6774974799822671
delay_time: 4.538114378271193
pressure: 0.8736737400530504
total_envstep_count: 702264
total_train_sample_count: 702264
total_episode_count: 6054
total_duration: 23205.125493764877
[2025-02-20 23:57:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.492021332801137
avg_train_sample_per_sec: 31.492021332801137
avg_episode_per_sec: 0.27148294252414773
collect_time: 22.100836038589478
reward_mean: -107.91643323996266
reward_std: 0.8199863149389406
reward_max: -106.53081232492997
reward_min: -109.0490196078431
queue_len: 0.07156262151191158
wait_time: 0.6777750224758338
delay_time: 4.539196959084325
pressure: 0.8681476569407603
total_envstep_count: 702960
total_train_sample_count: 702960
total_episode_count: 6060
total_duration: 23227.226329803467
[2025-02-20 23:58:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.573966219382918
avg_train_sample_per_sec: 31.573966219382918
avg_episode_per_sec: 0.27218936396019755
collect_time: 22.043477058410645
reward_mean: -107.96848739495799
reward_std: 3.3216147957353095
reward_max: -104.79201680672267
reward_min: -115.04411764705883
queue_len: 0.07159714018233287
wait_time: 0.6747196557668159
delay_time: 4.508521145970825
pressure: 0.8837312113174182
total_envstep_count: 703656
total_train_sample_count: 703656
total_episode_count: 6066
total_duration: 23249.269806861877
[2025-02-20 23:58:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.777057286568212
avg_train_sample_per_sec: 30.777057286568212
avg_episode_per_sec: 0.2653194593669673
collect_time: 22.614247798919678
reward_mean: -106.0046685340803
reward_std: 1.1380416304638603
reward_max: -104.1421568627451
reward_min: -108.06862745098042
queue_len: 0.07029487303320976
wait_time: 0.6636467473815344
delay_time: 4.402854963492691
pressure: 0.8643899204244031
total_envstep_count: 704352
total_train_sample_count: 704352
total_episode_count: 6072
total_duration: 23271.884054660797
[2025-02-20 23:58:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.615589271628785
avg_train_sample_per_sec: 31.615589271628785
avg_episode_per_sec: 0.2725481833761102
collect_time: 22.014456033706665
reward_mean: -106.81454248366015
reward_std: 2.4058434324354554
reward_max: -102.70098039215686
reward_min: -109.90266106442581
queue_len: 0.07083192472391257
wait_time: 0.6708390142086897
delay_time: 4.467110415480885
pressure: 0.8659372236958444
total_envstep_count: 705048
total_train_sample_count: 705048
total_episode_count: 6078
total_duration: 23293.898510694504
[2025-02-20 23:59:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.247949380994253
avg_train_sample_per_sec: 31.247949380994253
avg_episode_per_sec: 0.2693788739740884
collect_time: 22.27346158027649
reward_mean: -106.28501400560224
reward_std: 2.9641743202857453
reward_max: -102.75000000000001
reward_min: -110.47969187675069
queue_len: 0.07048077851830388
wait_time: 0.6645463225077828
delay_time: 4.4375448553453305
pressure: 0.8619584438549958
total_envstep_count: 705744
total_train_sample_count: 705744
total_episode_count: 6084
total_duration: 23316.17197227478
[2025-02-20 23:59:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57900276343195
avg_train_sample_per_sec: 31.57900276343195
avg_episode_per_sec: 0.2722327824433789
collect_time: 22.039961338043213
reward_mean: -108.18860877684408
reward_std: 4.242815135756723
reward_max: -101.44817927170868
reward_min: -115.72829131652661
queue_len: 0.07174310926846424
wait_time: 0.6798010207619742
delay_time: 4.552454955040516
pressure: 0.8822944297082228
total_envstep_count: 706440
total_train_sample_count: 706440
total_episode_count: 6090
total_duration: 23338.211933612823
[2025-02-21 00:00:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.468265408687284
avg_train_sample_per_sec: 31.468265408687284
avg_episode_per_sec: 0.27127815007489037
collect_time: 22.117520332336426
reward_mean: -109.23482726423903
reward_std: 2.083066176668331
reward_max: -105.99579831932775
reward_min: -111.7359943977591
queue_len: 0.07243688810625931
wait_time: 0.6830345533438839
delay_time: 4.590616125853305
pressure: 0.8785366931918656
total_envstep_count: 707136
total_train_sample_count: 707136
total_episode_count: 6096
total_duration: 23360.32945394516
[2025-02-21 00:00:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.645780066829325
avg_train_sample_per_sec: 31.645780066829325
avg_episode_per_sec: 0.2728084488519769
collect_time: 21.99345374107361
reward_mean: -105.50898692810459
reward_std: 2.7416508186542345
reward_max: -101.95028011204482
reward_min: -109.06092436974788
queue_len: 0.06996617170298709
wait_time: 0.6569765947935319
delay_time: 4.48875028075993
pressure: 0.8536693191865607
total_envstep_count: 707832
total_train_sample_count: 707832
total_episode_count: 6102
total_duration: 23382.322907686234
[2025-02-21 00:00:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.516059148375252
avg_train_sample_per_sec: 31.516059148375252
avg_episode_per_sec: 0.27169016507220045
collect_time: 22.08397936820984
reward_mean: -104.60830999066292
reward_std: 3.2272353732471992
reward_max: -100.37885154061622
reward_min: -110.16666666666666
queue_len: 0.06936890582935208
wait_time: 0.6539898784447465
delay_time: 4.4097789479192535
pressure: 0.8513483642793988
total_envstep_count: 708528
total_train_sample_count: 708528
total_episode_count: 6108
total_duration: 23404.406887054443
[2025-02-21 00:01:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968200044727777
avg_train_sample_per_sec: 31.968200044727777
avg_episode_per_sec: 0.27558793142006704
collect_time: 21.77163553237915
reward_mean: -106.16666666666664
reward_std: 3.8435005845967423
reward_max: -102.29411764705883
reward_min: -113.3207282913165
queue_len: 0.07040229885057471
wait_time: 0.6688575186927115
delay_time: 4.536812521228479
pressure: 0.8610742705570292
total_envstep_count: 709224
total_train_sample_count: 709224
total_episode_count: 6114
total_duration: 23426.178522586823
[2025-02-21 00:01:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.51941859543532
avg_train_sample_per_sec: 30.51941859543532
avg_episode_per_sec: 0.26309843616754586
collect_time: 22.805152654647827
reward_mean: -104.69327731092436
reward_std: 2.3164889642843645
reward_max: -100.72268907563027
reward_min: -106.61624649859941
queue_len: 0.06942525020618327
wait_time: 0.6563494540167968
delay_time: 4.4285038082159005
pressure: 0.8511273209549071
total_envstep_count: 709920
total_train_sample_count: 709920
total_episode_count: 6120
total_duration: 23448.98367524147
[2025-02-21 00:01:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.661279629377525
avg_train_sample_per_sec: 31.661279629377525
avg_episode_per_sec: 0.2729420657704959
collect_time: 21.98268699645996
reward_mean: -107.53092903828195
reward_std: 2.9705227357835744
reward_max: -104.18627450980394
reward_min: -112.55042016806723
queue_len: 0.07130698212087663
wait_time: 0.6740820665136081
delay_time: 4.618318060114505
pressure: 0.8724580017683464
total_envstep_count: 710616
total_train_sample_count: 710616
total_episode_count: 6126
total_duration: 23470.96636223793
[2025-02-21 00:02:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.63795008220489
avg_train_sample_per_sec: 31.63795008220489
avg_episode_per_sec: 0.2727409489845249
collect_time: 21.998896837234497
reward_mean: -105.72408963585433
reward_std: 2.7594402826570574
reward_max: -101.77310924369749
reward_min: -110.29831932773106
queue_len: 0.07010881275587157
wait_time: 0.6626707048867292
delay_time: 4.45054952708929
pressure: 0.8577586206896551
total_envstep_count: 711312
total_train_sample_count: 711312
total_episode_count: 6132
total_duration: 23492.965259075165
[2025-02-21 00:02:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4730830148293
avg_train_sample_per_sec: 31.4730830148293
avg_episode_per_sec: 0.2713196811623215
collect_time: 22.114134788513184
reward_mean: -103.68300653594771
reward_std: 1.8506293156673783
reward_max: -100.9166666666667
reward_min: -106.20518207282919
queue_len: 0.06875530937397063
wait_time: 0.6495241222041425
delay_time: 4.429941308173577
pressure: 0.8400751547303272
total_envstep_count: 712008
total_train_sample_count: 712008
total_episode_count: 6138
total_duration: 23515.079393863678
[2025-02-21 00:03:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.48825011910691
avg_train_sample_per_sec: 31.48825011910691
avg_episode_per_sec: 0.27145043206126646
collect_time: 22.103482961654663
reward_mean: -104.29271708683474
reward_std: 4.02504469611046
reward_max: -97.5434173669468
reward_min: -109.58823529411765
queue_len: 0.06915962671540765
wait_time: 0.6540169670874539
delay_time: 4.388394604914418
pressure: 0.8488063660477453
total_envstep_count: 712704
total_train_sample_count: 712704
total_episode_count: 6144
total_duration: 23537.182876825333
[2025-02-21 00:03:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54855152338622
avg_train_sample_per_sec: 31.54855152338622
avg_episode_per_sec: 0.2719702717533295
collect_time: 22.061234712600708
reward_mean: -105.6825396825397
reward_std: 3.5624883218585675
reward_max: -101.19187675070027
reward_min: -111.71498599439778
queue_len: 0.07008125973643214
wait_time: 0.663819650318129
delay_time: 4.440599744488356
pressure: 0.8572060123784263
total_envstep_count: 713400
total_train_sample_count: 713400
total_episode_count: 6150
total_duration: 23559.244111537933
[2025-02-21 00:03:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.253251499745947
avg_train_sample_per_sec: 31.253251499745947
avg_episode_per_sec: 0.26942458189436164
collect_time: 22.26968288421631
reward_mean: -106.61379551820727
reward_std: 3.7317794173477967
reward_max: -101.00980392156862
reward_min: -112.70938375350138
queue_len: 0.07069880339403666
wait_time: 0.6695359730983462
delay_time: 4.532464864104471
pressure: 0.8584217506631299
total_envstep_count: 714096
total_train_sample_count: 714096
total_episode_count: 6156
total_duration: 23581.51379442215
[2025-02-21 00:04:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.703094108030278
avg_train_sample_per_sec: 31.703094108030278
avg_episode_per_sec: 0.27330253541405414
collect_time: 21.953693151474
reward_mean: -104.54423436041084
reward_std: 2.8046135262831657
reward_max: -100.64915966386556
reward_min: -108.52240896358543
queue_len: 0.06932641535836263
wait_time: 0.6583879904747044
delay_time: 4.364239877988367
pressure: 0.8569849690539346
total_envstep_count: 714792
total_train_sample_count: 714792
total_episode_count: 6162
total_duration: 23603.467487573624
[2025-02-21 00:04:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.502136938331553
avg_train_sample_per_sec: 31.502136938331553
avg_episode_per_sec: 0.2715701460200996
collect_time: 22.09373927116394
reward_mean: -108.34628851540616
reward_std: 3.9224527929424235
reward_max: -102.08263305322127
reward_min: -115.10154061624647
queue_len: 0.07184767142931443
wait_time: 0.6865299944027127
delay_time: 4.583205155241038
pressure: 0.8826259946949602
total_envstep_count: 715488
total_train_sample_count: 715488
total_episode_count: 6168
total_duration: 23625.561226844788
[2025-02-21 00:04:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.658398505167465
avg_train_sample_per_sec: 31.658398505167465
avg_episode_per_sec: 0.272917228492823
collect_time: 21.984687566757202
reward_mean: -105.77941176470587
reward_std: 3.601292770557885
reward_max: -100.33193277310926
reward_min: -110.27170868347335
queue_len: 0.07014549851770947
wait_time: 0.6666111736471777
delay_time: 4.506479467828533
pressure: 0.8657161803713529
total_envstep_count: 716184
total_train_sample_count: 716184
total_episode_count: 6174
total_duration: 23647.545914411545
[2025-02-21 00:05:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.706569141553693
avg_train_sample_per_sec: 31.706569141553693
avg_episode_per_sec: 0.2733324925996008
collect_time: 21.951287031173706
reward_mean: -107.33391690009334
reward_std: 4.9114392225382515
reward_max: -101.24159663865547
reward_min: -116.49299719887954
queue_len: 0.07117633746690542
wait_time: 0.678558193834563
delay_time: 4.5175202327179
pressure: 0.8741158267020336
total_envstep_count: 716880
total_train_sample_count: 716880
total_episode_count: 6180
total_duration: 23669.49720144272
[2025-02-21 00:05:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.587080435641038
avg_train_sample_per_sec: 31.587080435641038
avg_episode_per_sec: 0.2723024175486296
collect_time: 22.034325122833252
reward_mean: -106.21171802054154
reward_std: 2.8595879187361994
reward_max: -102.16876750700281
reward_min: -109.45448179271709
queue_len: 0.07043217375367476
wait_time: 0.6658456486042692
delay_time: 4.567146169583817
pressure: 0.8629531388152077
total_envstep_count: 717576
total_train_sample_count: 717576
total_episode_count: 6186
total_duration: 23691.53152656555
[2025-02-21 00:06:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.3936874851997
avg_train_sample_per_sec: 31.3936874851997
avg_episode_per_sec: 0.2706352369413767
collect_time: 22.17006206512451
reward_mean: -105.57294584500465
reward_std: 3.131544438791926
reward_max: -99.78011204481793
reward_min: -108.4390756302521
queue_len: 0.07000858477785456
wait_time: 0.662802742670897
delay_time: 4.456680160613665
pressure: 0.8546640141467727
total_envstep_count: 718272
total_train_sample_count: 718272
total_episode_count: 6192
total_duration: 23713.701588630676
[2025-02-21 00:06:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.626669099813284
avg_train_sample_per_sec: 31.626669099813284
avg_episode_per_sec: 0.2726436991363214
collect_time: 22.006743669509888
reward_mean: -103.75291783380021
reward_std: 2.6285572043004444
reward_max: -99.10364145658265
reward_min: -108.15266106442574
queue_len: 0.06880166965106113
wait_time: 0.6526062679713794
delay_time: 4.381059576351059
pressure: 0.854553492484527
total_envstep_count: 718968
total_train_sample_count: 718968
total_episode_count: 6198
total_duration: 23735.708332300186
[2025-02-21 00:06:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.835723388145574
avg_train_sample_per_sec: 31.835723388145574
avg_episode_per_sec: 0.27444589127711705
collect_time: 21.86223292350769
reward_mean: -102.75058356676004
reward_std: 2.318636066696317
reward_max: -99.36344537815128
reward_min: -105.58753501400558
queue_len: 0.06813699175514591
wait_time: 0.6457926229731504
delay_time: 4.34363340597528
pressure: 0.8421750663129973
total_envstep_count: 719664
total_train_sample_count: 719664
total_episode_count: 6204
total_duration: 23757.570565223694
[2025-02-21 00:07:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.36951735256794
avg_train_sample_per_sec: 31.36951735256794
avg_episode_per_sec: 0.27042687372903396
collect_time: 22.1871440410614
reward_mean: -104.7706582633053
reward_std: 2.124053312880284
reward_max: -101.2317927170868
reward_min: -107.58193277310926
queue_len: 0.06947656383508309
wait_time: 0.6580291820530157
delay_time: 4.448810473152849
pressure: 0.8541114058355438
total_envstep_count: 720360
total_train_sample_count: 720360
total_episode_count: 6210
total_duration: 23779.757709264755
[2025-02-21 00:07:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.688237396279874
avg_train_sample_per_sec: 31.688237396279874
avg_episode_per_sec: 0.27317446031275755
collect_time: 21.963985919952393
reward_mean: -105.8483893557423
reward_std: 1.9174213703204932
reward_max: -102.99159663865547
reward_min: -108.31932773109246
queue_len: 0.07019123962582381
wait_time: 0.663915776301679
delay_time: 4.501452093446618
pressure: 0.8512378426171531
total_envstep_count: 721056
total_train_sample_count: 721056
total_episode_count: 6216
total_duration: 23801.721695184708
[2025-02-21 00:07:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.367959397598533
avg_train_sample_per_sec: 31.367959397598533
avg_episode_per_sec: 0.270413443082746
collect_time: 22.18824601173401
reward_mean: -105.80438842203547
reward_std: 1.8651479603011591
reward_max: -103.86274509803928
reward_min: -108.90896358543415
queue_len: 0.07016206128782194
wait_time: 0.6715879764814856
delay_time: 4.458975641216143
pressure: 0.8579796640141467
total_envstep_count: 721752
total_train_sample_count: 721752
total_episode_count: 6222
total_duration: 23823.90994119644
[2025-02-21 00:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.457335592705142
avg_train_sample_per_sec: 31.457335592705142
avg_episode_per_sec: 0.2711839275233202
collect_time: 22.125205039978027
reward_mean: -104.25326797385623
reward_std: 1.8877054468913228
reward_max: -101.74159663865547
reward_min: -107.15616246498598
queue_len: 0.0691334668261646
wait_time: 0.6540428173922089
delay_time: 4.3925547939609375
pressure: 0.8391909814323607
total_envstep_count: 722448
total_train_sample_count: 722448
total_episode_count: 6228
total_duration: 23846.03514623642
[2025-02-21 00:08:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.576034471367684
avg_train_sample_per_sec: 31.576034471367684
avg_episode_per_sec: 0.2722071937186869
collect_time: 22.042033195495605
reward_mean: -103.68277310924371
reward_std: 2.599098920390417
reward_max: -100.51890756302522
reward_min: -107.48179271708688
queue_len: 0.06875515458172658
wait_time: 0.6516234146178365
delay_time: 4.394733941593606
pressure: 0.8433908045977012
total_envstep_count: 723144
total_train_sample_count: 723144
total_episode_count: 6234
total_duration: 23868.077179431915
[2025-02-21 00:09:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.603492810265962
avg_train_sample_per_sec: 31.603492810265962
avg_episode_per_sec: 0.2724439035367755
collect_time: 22.022882223129272
reward_mean: -107.11706349206351
reward_std: 3.7015935318240647
reward_max: -102.8067226890756
reward_min: -114.10294117647062
queue_len: 0.07103253547219064
wait_time: 0.6759274222509517
delay_time: 4.518237692203123
pressure: 0.8635057471264368
total_envstep_count: 723840
total_train_sample_count: 723840
total_episode_count: 6240
total_duration: 23890.100061655045
[2025-02-21 00:09:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55130117754674
avg_train_sample_per_sec: 31.55130117754674
avg_episode_per_sec: 0.2719939756685064
collect_time: 22.059312105178833
reward_mean: -107.51353874883284
reward_std: 3.2588769445105648
reward_max: -104.04691876750697
reward_min: -113.54481792717083
queue_len: 0.07129545009869552
wait_time: 0.6753811604217282
delay_time: 4.463514103004852
pressure: 0.8763262599469495
total_envstep_count: 724536
total_train_sample_count: 724536
total_episode_count: 6246
total_duration: 23912.159373760223
[2025-02-21 00:09:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.561295213839603
avg_train_sample_per_sec: 31.561295213839603
avg_episode_per_sec: 0.27208013115378965
collect_time: 22.052326917648315
reward_mean: -104.37173202614377
reward_std: 2.5475344921297185
reward_max: -99.82843137254902
reward_min: -107.00700280112042
queue_len: 0.06921202389001578
wait_time: 0.6512728101850821
delay_time: 4.444044318085493
pressure: 0.8467064544650751
total_envstep_count: 725232
total_train_sample_count: 725232
total_episode_count: 6252
total_duration: 23934.21170067787
[2025-02-21 00:10:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.717023281089105
avg_train_sample_per_sec: 31.717023281089105
avg_episode_per_sec: 0.27342261449214744
collect_time: 21.94405174255371
reward_mean: -106.85375816993464
reward_std: 4.953630024090337
reward_max: -99.64355742296924
reward_min: -113.61554621848741
queue_len: 0.07085792982091156
wait_time: 0.672398081690678
delay_time: 4.511539430383313
pressure: 0.872236958443855
total_envstep_count: 725928
total_train_sample_count: 725928
total_episode_count: 6258
total_duration: 23956.155752420425
[2025-02-21 00:10:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.600487757845098
avg_train_sample_per_sec: 31.600487757845098
avg_episode_per_sec: 0.27241799791245774
collect_time: 22.0249764919281
reward_mean: -106.86589635854342
reward_std: 3.368978666247878
reward_max: -103.55322128851549
reward_min: -113.0084033613445
queue_len: 0.07086597901760174
wait_time: 0.6736787553217574
delay_time: 4.476117708024964
pressure: 0.8648320070733863
total_envstep_count: 726624
total_train_sample_count: 726624
total_episode_count: 6264
total_duration: 23978.180728912354
[2025-02-21 00:10:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.848249175517115
avg_train_sample_per_sec: 31.848249175517115
avg_episode_per_sec: 0.27455387220273375
collect_time: 21.85363459587097
reward_mean: -104.0169234360411
reward_std: 2.7073824593310207
reward_max: -100.85434173669465
reward_min: -107.8228291316527
queue_len: 0.06897673967907234
wait_time: 0.6547274634876055
delay_time: 4.364016152143594
pressure: 0.847922192749779
total_envstep_count: 727320
total_train_sample_count: 727320
total_episode_count: 6270
total_duration: 24000.034363508224
[2025-02-21 00:11:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65733594185792
avg_train_sample_per_sec: 31.65733594185792
avg_episode_per_sec: 0.27290806846429244
collect_time: 21.98542547225952
reward_mean: -105.92775443510736
reward_std: 2.6053715360106184
reward_max: -101.8095238095238
reward_min: -110.27240896358542
queue_len: 0.07024386898879799
wait_time: 0.6708546482253378
delay_time: 4.439180724830125
pressure: 0.8614058355437666
total_envstep_count: 728016
total_train_sample_count: 728016
total_episode_count: 6276
total_duration: 24022.019788980484
[2025-02-21 00:11:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7489888888159
avg_train_sample_per_sec: 31.7489888888159
avg_episode_per_sec: 0.27369818007599916
collect_time: 21.921957969665527
reward_mean: -107.37254901960785
reward_std: 2.4013142482438226
reward_max: -103.031512605042
reward_min: -110.17647058823526
queue_len: 0.07120195558329433
wait_time: 0.6797365497923308
delay_time: 4.51449241551386
pressure: 0.8674845269672855
total_envstep_count: 728712
total_train_sample_count: 728712
total_episode_count: 6282
total_duration: 24043.94174695015
[2025-02-21 00:12:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.719776876820955
avg_train_sample_per_sec: 31.719776876820955
avg_episode_per_sec: 0.27344635238638754
collect_time: 21.94214677810669
reward_mean: -106.35749299719889
reward_std: 1.9757438689427784
reward_max: -103.92296918767505
reward_min: -109.21848739495798
queue_len: 0.07052884151007884
wait_time: 0.6681953174727008
delay_time: 4.5008058733027685
pressure: 0.8585322723253759
total_envstep_count: 729408
total_train_sample_count: 729408
total_episode_count: 6288
total_duration: 24065.883893728256
[2025-02-21 00:12:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.544695518084186
avg_train_sample_per_sec: 31.544695518084186
avg_episode_per_sec: 0.27193703032831196
collect_time: 22.063931465148926
reward_mean: -104.9076797385621
reward_std: 1.6889349304462293
reward_max: -102.32072829131656
reward_min: -107.78221288515402
queue_len: 0.0695674268823356
wait_time: 0.660103707707663
delay_time: 4.42464402111448
pressure: 0.8557692307692308
total_envstep_count: 730104
total_train_sample_count: 730104
total_episode_count: 6294
total_duration: 24087.947825193405
[2025-02-21 00:12:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.707520328892215
avg_train_sample_per_sec: 31.707520328892215
avg_episode_per_sec: 0.2733406924904501
collect_time: 21.950628519058228
reward_mean: -104.18382352941177
reward_std: 1.6285998172308929
reward_max: -102.34803921568626
reward_min: -106.25840336134456
queue_len: 0.06908741613356217
wait_time: 0.6530193310746047
delay_time: 4.385214689175377
pressure: 0.84394341290893
total_envstep_count: 730800
total_train_sample_count: 730800
total_episode_count: 6300
total_duration: 24109.898453712463
[2025-02-21 00:13:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.910768120932204
avg_train_sample_per_sec: 31.910768120932204
avg_episode_per_sec: 0.2750928286287259
collect_time: 21.810819387435913
reward_mean: -107.43370681605977
reward_std: 2.17452083726194
reward_max: -105.55672268907567
reward_min: -112.10714285714286
queue_len: 0.07124251115123327
wait_time: 0.67779824131244
delay_time: 4.537379673411813
pressure: 0.8724580017683466
total_envstep_count: 731496
total_train_sample_count: 731496
total_episode_count: 6306
total_duration: 24131.7092730999
[2025-02-21 00:13:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.552195327584524
avg_train_sample_per_sec: 31.552195327584524
avg_episode_per_sec: 0.2720016838584873
collect_time: 22.05868697166443
reward_mean: -104.41561624649859
reward_std: 2.485110071075729
reward_max: -101.32422969187677
reward_min: -107.4978991596638
queue_len: 0.06924112483189561
wait_time: 0.6568074068707942
delay_time: 4.355662310922244
pressure: 0.8519009725906277
total_envstep_count: 732192
total_train_sample_count: 732192
total_episode_count: 6312
total_duration: 24153.767960071564
[2025-02-21 00:13:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.841888147721523
avg_train_sample_per_sec: 31.841888147721523
avg_episode_per_sec: 0.27449903575622003
collect_time: 21.8580002784729
reward_mean: -105.4829598506069
reward_std: 2.7880690537350232
reward_max: -101.86624649859945
reward_min: -110.82492997198878
queue_len: 0.06994891236777646
wait_time: 0.6632948272147053
delay_time: 4.391875198802707
pressure: 0.857869142351901
total_envstep_count: 732888
total_train_sample_count: 732888
total_episode_count: 6318
total_duration: 24175.625960350037
[2025-02-21 00:14:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52261197204534
avg_train_sample_per_sec: 31.52261197204534
avg_episode_per_sec: 0.27174665493142536
collect_time: 22.07938861846924
reward_mean: -107.1465919701214
reward_std: 3.2860833763492554
reward_max: -101.73809523809526
reward_min: -110.2752100840336
queue_len: 0.07105211669106194
wait_time: 0.6742187480650969
delay_time: 4.4421648181662405
pressure: 0.8754420866489832
total_envstep_count: 733584
total_train_sample_count: 733584
total_episode_count: 6324
total_duration: 24197.705348968506
[2025-02-21 00:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.893461927649376
avg_train_sample_per_sec: 31.893461927649376
avg_episode_per_sec: 0.2749436373073222
collect_time: 21.822654485702515
reward_mean: -105.98074229691876
reward_std: 3.1760357073138152
reward_max: -101.06232492997194
reward_min: -110.08543417366955
queue_len: 0.07027900682819548
wait_time: 0.6690350653966273
delay_time: 4.454961233151212
pressure: 0.8652740937223696
total_envstep_count: 734280
total_train_sample_count: 734280
total_episode_count: 6330
total_duration: 24219.52800345421
[2025-02-21 00:15:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.461259781557928
avg_train_sample_per_sec: 31.461259781557928
avg_episode_per_sec: 0.2712177567375683
collect_time: 22.122445344924927
reward_mean: -105.60235760971052
reward_std: 4.018369909786008
reward_max: -99.93207282913163
reward_min: -112.19187675070026
queue_len: 0.0700280886006038
wait_time: 0.661193677294083
delay_time: 4.476135373108279
pressure: 0.8462643678160919
total_envstep_count: 734976
total_train_sample_count: 734976
total_episode_count: 6336
total_duration: 24241.650448799133
[2025-02-21 00:15:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.799025504208938
avg_train_sample_per_sec: 30.799025504208938
avg_episode_per_sec: 0.26550884055352536
collect_time: 22.59811758995056
reward_mean: -105.73506069094304
reward_std: 2.7883159917397666
reward_max: -100.19607843137254
reward_min: -108.49789915966383
queue_len: 0.07011608799134154
wait_time: 0.6677852728182342
delay_time: 4.442937356902694
pressure: 0.8510167992926613
total_envstep_count: 735672
total_train_sample_count: 735672
total_episode_count: 6342
total_duration: 24264.248566389084
[2025-02-21 00:15:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.44132657602925
avg_train_sample_per_sec: 31.44132657602925
avg_episode_per_sec: 0.27104591875887285
collect_time: 22.136470556259155
reward_mean: -105.87278244631186
reward_std: 2.3450000446081436
reward_max: -103.03711484593839
reward_min: -108.50280112044817
queue_len: 0.07020741541532616
wait_time: 0.6654859888252384
delay_time: 4.478874801809088
pressure: 0.862290008841733
total_envstep_count: 736368
total_train_sample_count: 736368
total_episode_count: 6348
total_duration: 24286.385036945343
[2025-02-21 00:16:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77487086146522
avg_train_sample_per_sec: 31.77487086146522
avg_episode_per_sec: 0.2739213005298726
collect_time: 21.904101610183716
reward_mean: -104.81640989729225
reward_std: 3.1284548629148543
reward_max: -101.64285714285711
reward_min: -111.13165266106442
queue_len: 0.06950690311491527
wait_time: 0.6598845218901
delay_time: 4.487705886714671
pressure: 0.8436118479221927
total_envstep_count: 737064
total_train_sample_count: 737064
total_episode_count: 6354
total_duration: 24308.289138555527
[2025-02-21 00:16:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.437139227633192
avg_train_sample_per_sec: 31.437139227633192
avg_episode_per_sec: 0.27100982092787235
collect_time: 22.139419078826904
reward_mean: -105.14542483660132
reward_std: 1.3697038425420387
reward_max: -102.82703081232492
reward_min: -107.02100840336136
queue_len: 0.06972508278289212
wait_time: 0.6618527052730907
delay_time: 4.425866542046488
pressure: 0.8531167108753316
total_envstep_count: 737760
total_train_sample_count: 737760
total_episode_count: 6360
total_duration: 24330.428557634354
[2025-02-21 00:16:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.700304853268154
avg_train_sample_per_sec: 31.700304853268154
avg_episode_per_sec: 0.27327849011438066
collect_time: 21.95562481880188
reward_mean: -105.98039215686272
reward_std: 2.0271487689722107
reward_max: -102.59663865546212
reward_min: -108.67507002801122
queue_len: 0.0702787746398294
wait_time: 0.6676519966961144
delay_time: 4.488332731845552
pressure: 0.8611847922192749
total_envstep_count: 738456
total_train_sample_count: 738456
total_episode_count: 6366
total_duration: 24352.384182453156
[2025-02-21 00:17:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.45483411548516
avg_train_sample_per_sec: 31.45483411548516
avg_episode_per_sec: 0.27116236306452723
collect_time: 22.126964569091797
reward_mean: -104.86753034547151
reward_std: 1.4669131425421789
reward_max: -103.08543417366947
reward_min: -106.84943977591034
queue_len: 0.06954080261636043
wait_time: 0.659721525657124
delay_time: 4.4622174487101764
pressure: 0.8510167992926613
total_envstep_count: 739152
total_train_sample_count: 739152
total_episode_count: 6372
total_duration: 24374.511147022247
[2025-02-21 00:17:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.36136761054366
avg_train_sample_per_sec: 31.36136761054366
avg_episode_per_sec: 0.27035661733227295
collect_time: 22.192909717559814
reward_mean: -109.0655929038282
reward_std: 2.67933545387424
reward_max: -103.514705882353
reward_min: -111.80322128851543
queue_len: 0.07232466372932905
wait_time: 0.6881216456520717
delay_time: 4.575644912356776
pressure: 0.8809681697612732
total_envstep_count: 739848
total_train_sample_count: 739848
total_episode_count: 6378
total_duration: 24396.704056739807
[2025-02-21 00:18:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78372626854195
avg_train_sample_per_sec: 31.78372626854195
avg_episode_per_sec: 0.2739976402460513
collect_time: 21.897998809814453
reward_mean: -104.78559757236228
reward_std: 3.1177390863278283
reward_max: -101.46288515406167
reward_min: -109.33683473389354
queue_len: 0.06948647053870177
wait_time: 0.6581979829951432
delay_time: 4.4232038726698235
pressure: 0.8538903625110522
total_envstep_count: 740544
total_train_sample_count: 740544
total_episode_count: 6384
total_duration: 24418.60205554962
[2025-02-21 00:18:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.732059115522897
avg_train_sample_per_sec: 31.732059115522897
avg_episode_per_sec: 0.2735522337545077
collect_time: 21.933653831481934
reward_mean: -106.15161064425769
reward_std: 3.5782850724550523
reward_max: -101.63445378151258
reward_min: -111.10014005602241
queue_len: 0.07039231475083402
wait_time: 0.6714187111626261
delay_time: 4.430141988381353
pressure: 0.86394783377542
total_envstep_count: 741240
total_train_sample_count: 741240
total_episode_count: 6390
total_duration: 24440.535709381104
[2025-02-21 00:18:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.48345571148081
avg_train_sample_per_sec: 31.48345571148081
avg_episode_per_sec: 0.2714091009610415
collect_time: 22.10684895515442
reward_mean: -105.97257236227823
reward_std: 2.498054491787528
reward_max: -101.60364145658261
reward_min: -109.96918767507002
queue_len: 0.07027358909965399
wait_time: 0.6682158274450365
delay_time: 4.471466540384495
pressure: 0.8565428824049514
total_envstep_count: 741936
total_train_sample_count: 741936
total_episode_count: 6396
total_duration: 24462.642558336258
[2025-02-21 00:19:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.689422090857608
avg_train_sample_per_sec: 31.689422090857608
avg_episode_per_sec: 0.2731846731970483
collect_time: 21.963164806365967
reward_mean: -104.46510270774978
reward_std: 3.3413905335300913
reward_max: -99.93207282913164
reward_min: -108.60994397759106
queue_len: 0.06927394078763248
wait_time: 0.6618417150237637
delay_time: 4.415331029330889
pressure: 0.8460433244916002
total_envstep_count: 742632
total_train_sample_count: 742632
total_episode_count: 6402
total_duration: 24484.605723142624
[2025-02-21 00:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.607305026979244
avg_train_sample_per_sec: 31.607305026979244
avg_episode_per_sec: 0.272476767473959
collect_time: 22.020226001739502
reward_mean: -105.1830065359477
reward_std: 1.3151045885778754
reward_max: -103.08963585434175
reward_min: -106.75840336134449
queue_len: 0.06975000433418284
wait_time: 0.6668238581904912
delay_time: 4.374856717428898
pressure: 0.8595269672855879
total_envstep_count: 743328
total_train_sample_count: 743328
total_episode_count: 6408
total_duration: 24506.625949144363
[2025-02-21 00:19:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.900717504963307
avg_train_sample_per_sec: 31.900717504963307
avg_episode_per_sec: 0.27500618538761473
collect_time: 21.81769108772278
reward_mean: -107.30462184873949
reward_std: 1.5450209717804995
reward_max: -105.25560224089637
reward_min: -109.312324929972
queue_len: 0.07115691104027817
wait_time: 0.6773598696773139
delay_time: 4.525763588933087
pressure: 0.8643899204244031
total_envstep_count: 744024
total_train_sample_count: 744024
total_episode_count: 6414
total_duration: 24528.443640232086
[2025-02-21 00:20:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62080179722509
avg_train_sample_per_sec: 31.62080179722509
avg_episode_per_sec: 0.2725931189415956
collect_time: 22.01082706451416
reward_mean: -105.60515873015873
reward_std: 3.813916423331294
reward_max: -98.87535014005606
reward_min: -110.03431372549021
queue_len: 0.07002994610753231
wait_time: 0.6733522984790733
delay_time: 4.4510356581448915
pressure: 0.8566534040671971
total_envstep_count: 744720
total_train_sample_count: 744720
total_episode_count: 6420
total_duration: 24550.4544672966
[2025-02-21 00:20:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71118028058773
avg_train_sample_per_sec: 31.71118028058773
avg_episode_per_sec: 0.2733722437981701
collect_time: 21.948095083236694
reward_mean: -105.10784313725492
reward_std: 1.139547833268529
reward_max: -103.84313725490199
reward_min: -107.12815126050418
queue_len: 0.06970016123160139
wait_time: 0.6600846682616458
delay_time: 4.438773146081087
pressure: 0.8479221927497789
total_envstep_count: 745416
total_train_sample_count: 745416
total_episode_count: 6426
total_duration: 24572.402562379837
[2025-02-21 00:21:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.566763946233824
avg_train_sample_per_sec: 31.566763946233824
avg_episode_per_sec: 0.27212727539856746
collect_time: 22.048506498336792
reward_mean: -104.94514472455649
reward_std: 5.012625711662074
reward_max: -97.58753501400562
reward_min: -111.81932773109241
queue_len: 0.0695922710375043
wait_time: 0.6601211218351178
delay_time: 4.4544954703974495
pressure: 0.8524535809018566
total_envstep_count: 746112
total_train_sample_count: 746112
total_episode_count: 6432
total_duration: 24594.451068878174
[2025-02-21 00:21:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86301428474255
avg_train_sample_per_sec: 31.86301428474255
avg_episode_per_sec: 0.27468115762709094
collect_time: 21.843507766723633
reward_mean: -104.86834733893558
reward_std: 2.785592053815827
reward_max: -101.22478991596637
reward_min: -108.65966386554624
queue_len: 0.06954134438921458
wait_time: 0.660949028152375
delay_time: 4.3991064229648345
pressure: 0.855658709106985
total_envstep_count: 746808
total_train_sample_count: 746808
total_episode_count: 6438
total_duration: 24616.294576644897
[2025-02-21 00:21:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.573477200727385
avg_train_sample_per_sec: 31.573477200727385
avg_episode_per_sec: 0.27218514828213264
collect_time: 22.043818473815918
reward_mean: -105.42075163398692
reward_std: 2.0902139598299723
reward_max: -102.72128851540616
reward_min: -107.81652661064427
queue_len: 0.06990766023473936
wait_time: 0.6668168151433872
delay_time: 4.4180645140569945
pressure: 0.8565428824049514
total_envstep_count: 747504
total_train_sample_count: 747504
total_episode_count: 6444
total_duration: 24638.338395118713
[2025-02-21 00:22:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.45615666268125
avg_train_sample_per_sec: 31.45615666268125
avg_episode_per_sec: 0.271173764333459
collect_time: 22.126034259796143
reward_mean: -106.11344537815125
reward_std: 3.4603613850110513
reward_max: -101.41246498599443
reward_min: -111.29691876750695
queue_len: 0.0703670062189332
wait_time: 0.6664079314307508
delay_time: 4.444872508816574
pressure: 0.8549955791335102
total_envstep_count: 748200
total_train_sample_count: 748200
total_episode_count: 6450
total_duration: 24660.46442937851
[2025-02-21 00:22:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.752144510784404
avg_train_sample_per_sec: 31.752144510784404
avg_episode_per_sec: 0.2737253837136587
collect_time: 21.919779300689697
reward_mean: -108.36776377217554
reward_std: 2.6661453721879407
reward_max: -104.98739495798314
reward_min: -113.50350140056024
queue_len: 0.07186191231576627
wait_time: 0.6934957227807127
delay_time: 4.4887215339117565
pressure: 0.8775419982316534
total_envstep_count: 748896
total_train_sample_count: 748896
total_episode_count: 6456
total_duration: 24682.3842086792
[2025-02-21 00:22:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.520815842752867
avg_train_sample_per_sec: 31.520815842752867
avg_episode_per_sec: 0.27173117105821437
collect_time: 22.080646753311157
reward_mean: -107.73961251167133
reward_std: 3.6412106776274706
reward_max: -102.76050420168065
reward_min: -112.6589635854342
queue_len: 0.07144536638704996
wait_time: 0.6773039896772147
delay_time: 4.5125996265365265
pressure: 0.8746684350132625
total_envstep_count: 749592
total_train_sample_count: 749592
total_episode_count: 6462
total_duration: 24704.46485543251
[2025-02-21 00:23:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.486395755160967
avg_train_sample_per_sec: 31.486395755160967
avg_episode_per_sec: 0.27143444616518075
collect_time: 22.104784727096558
reward_mean: -106.27672735760969
reward_std: 2.659735570972648
reward_max: -102.68837535014008
reward_min: -110.12885154061625
queue_len: 0.07047528339364038
wait_time: 0.6698930788053508
delay_time: 4.4852992014776865
pressure: 0.8663793103448275
total_envstep_count: 750288
total_train_sample_count: 750288
total_episode_count: 6468
total_duration: 24726.569640159607
[2025-02-21 00:23:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52175081193542
avg_train_sample_per_sec: 31.52175081193542
avg_episode_per_sec: 0.2717392311373743
collect_time: 22.079991817474365
reward_mean: -105.56174136321194
reward_std: 3.441006489013182
reward_max: -99.49299719887954
reward_min: -109.46708683473393
queue_len: 0.07000115475014054
wait_time: 0.6674147775821203
delay_time: 4.459668575746059
pressure: 0.8530061892130858
total_envstep_count: 750984
total_train_sample_count: 750984
total_episode_count: 6474
total_duration: 24748.64963197708
[2025-02-21 00:24:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.572197013428998
avg_train_sample_per_sec: 31.572197013428998
avg_episode_per_sec: 0.27217411218473275
collect_time: 22.04471230506897
reward_mean: -107.6234827264239
reward_std: 3.2778548349468237
reward_max: -102.42997198879551
reward_min: -111.8214285714286
queue_len: 0.07136835724563921
wait_time: 0.6810554571076882
delay_time: 4.5356182678002925
pressure: 0.8787577365163571
total_envstep_count: 751680
total_train_sample_count: 751680
total_episode_count: 6480
total_duration: 24770.69434428215
[2025-02-21 00:24:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.992662030139808
avg_train_sample_per_sec: 31.992662030139808
avg_episode_per_sec: 0.2757988106046535
collect_time: 21.75498867034912
reward_mean: -105.12675070028013
reward_std: 1.7771013522246455
reward_max: -101.51610644257698
reward_min: -107.26470588235297
queue_len: 0.06971269940336877
wait_time: 0.6652250091017841
delay_time: 4.3939434647607145
pressure: 0.8538903625110522
total_envstep_count: 752376
total_train_sample_count: 752376
total_episode_count: 6486
total_duration: 24792.4493329525
[2025-02-21 00:24:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.806352317498487
avg_train_sample_per_sec: 31.806352317498487
avg_episode_per_sec: 0.2741926923922283
collect_time: 21.882421255111694
reward_mean: -106.10667600373483
reward_std: 2.822146363315934
reward_max: -101.78221288515407
reward_min: -109.0098039215686
queue_len: 0.07036251724385599
wait_time: 0.6708526359261654
delay_time: 4.4771084278514905
pressure: 0.860632183908046
total_envstep_count: 753072
total_train_sample_count: 753072
total_episode_count: 6492
total_duration: 24814.33175420761
[2025-02-21 00:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52586131794486
avg_train_sample_per_sec: 31.52586131794486
avg_episode_per_sec: 0.2717746665340074
collect_time: 22.077112913131714
reward_mean: -104.99474789915966
reward_std: 3.4905788123739505
reward_max: -102.44817927170868
reward_min: -112.47338935574233
queue_len: 0.06962516438936317
wait_time: 0.6667891847278256
delay_time: 4.422952923804327
pressure: 0.854553492484527
total_envstep_count: 753768
total_train_sample_count: 753768
total_episode_count: 6498
total_duration: 24836.408867120743
[2025-02-21 00:25:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.64556771783841
avg_train_sample_per_sec: 31.64556771783841
avg_episode_per_sec: 0.2728066182572277
collect_time: 21.993601322174072
reward_mean: -103.6628151260504
reward_std: 1.9263861060258598
reward_max: -101.34173669467782
reward_min: -107.31232492997198
queue_len: 0.06874191984486101
wait_time: 0.6512039276364834
delay_time: 4.3504914320016645
pressure: 0.8356542882404954
total_envstep_count: 754464
total_train_sample_count: 754464
total_episode_count: 6504
total_duration: 24858.402468442917
[2025-02-21 00:25:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.810280534116345
avg_train_sample_per_sec: 31.810280534116345
avg_episode_per_sec: 0.27422655632858917
collect_time: 21.879719018936157
reward_mean: -103.82446311858077
reward_std: 3.628457407067125
reward_max: -98.78151260504205
reward_min: -110.95658263305323
queue_len: 0.06884911347385993
wait_time: 0.6535102546765832
delay_time: 4.377535284825794
pressure: 0.8358753315649867
total_envstep_count: 755160
total_train_sample_count: 755160
total_episode_count: 6510
total_duration: 24880.282187461853
[2025-02-21 00:26:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.426603165147434
avg_train_sample_per_sec: 31.426603165147434
avg_episode_per_sec: 0.27091899280299514
collect_time: 22.146841526031494
reward_mean: -105.67763772175535
reward_std: 3.0436969362053614
reward_max: -102.2142857142857
reward_min: -111.30952380952382
queue_len: 0.07007800909930727
wait_time: 0.6671212140912953
delay_time: 4.426561452745915
pressure: 0.853448275862069
total_envstep_count: 755856
total_train_sample_count: 755856
total_episode_count: 6516
total_duration: 24902.429028987885
[2025-02-21 00:26:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.463851808616447
avg_train_sample_per_sec: 31.463851808616447
avg_episode_per_sec: 0.2712401017984177
collect_time: 22.120622873306274
reward_mean: -104.9968487394958
reward_std: 3.188489389068093
reward_max: -100.98459383753496
reward_min: -109.12745098039217
queue_len: 0.06962655751955954
wait_time: 0.6681926860045523
delay_time: 4.462135020739463
pressure: 0.851790450928382
total_envstep_count: 756552
total_train_sample_count: 756552
total_episode_count: 6522
total_duration: 24924.54965186119
[2025-02-21 00:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.698254365227065
avg_train_sample_per_sec: 31.698254365227065
avg_episode_per_sec: 0.27326081349333675
collect_time: 21.957045078277588
reward_mean: -105.34267040149393
reward_std: 2.9773054336725617
reward_max: -100.22549019607847
reward_min: -107.74929971988793
queue_len: 0.06985588222910738
wait_time: 0.6670999301577395
delay_time: 4.420560864826162
pressure: 0.8502431476569408
total_envstep_count: 757248
total_train_sample_count: 757248
total_episode_count: 6528
total_duration: 24946.50669693947
[2025-02-21 00:27:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.736064915072927
avg_train_sample_per_sec: 31.736064915072927
avg_episode_per_sec: 0.27358676650924935
collect_time: 21.930885314941406
reward_mean: -104.58181605975726
reward_std: 2.037747359654138
reward_max: -101.53711484593836
reward_min: -107.03921568627455
queue_len: 0.06935133690965334
wait_time: 0.6543107627666451
delay_time: 4.427980844446382
pressure: 0.8427276746242264
total_envstep_count: 757944
total_train_sample_count: 757944
total_episode_count: 6534
total_duration: 24968.43758225441
[2025-02-21 00:27:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639539087593448
avg_train_sample_per_sec: 31.639539087593448
avg_episode_per_sec: 0.27275464730684007
collect_time: 21.99779200553894
reward_mean: -102.92180205415498
reward_std: 1.9917645472356167
reward_max: -98.70868347338936
reward_min: -104.57212885154064
queue_len: 0.06825053186615053
wait_time: 0.6460630450234911
delay_time: 4.38726922504686
pressure: 0.8315649867374005
total_envstep_count: 758640
total_train_sample_count: 758640
total_episode_count: 6540
total_duration: 24990.43537425995
[2025-02-21 00:28:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78105705303006
avg_train_sample_per_sec: 31.78105705303006
avg_episode_per_sec: 0.27397462976750053
collect_time: 21.899837970733643
reward_mean: -104.36694677871147
reward_std: 2.100567014588788
reward_max: -101.74929971988796
reward_min: -108.27661064425769
queue_len: 0.06920885064901292
wait_time: 0.6587237348520308
delay_time: 4.459153148612591
pressure: 0.8461538461538461
total_envstep_count: 759336
total_train_sample_count: 759336
total_episode_count: 6546
total_duration: 25012.335212230682
[2025-02-21 00:28:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.821779972602123
avg_train_sample_per_sec: 31.821779972602123
avg_episode_per_sec: 0.27432568941898383
collect_time: 21.871812343597412
reward_mean: -107.59313725490195
reward_std: 4.547141763092985
reward_max: -100.53011204481794
reward_min: -115.11834733893554
queue_len: 0.07134823425391378
wait_time: 0.6806800085197651
delay_time: 4.510604974497536
pressure: 0.8693633952254641
total_envstep_count: 760032
total_train_sample_count: 760032
total_episode_count: 6552
total_duration: 25034.20702457428
[2025-02-21 00:28:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.531556182252118
avg_train_sample_per_sec: 31.531556182252118
avg_episode_per_sec: 0.2718237601918286
collect_time: 22.07312560081482
reward_mean: -102.91736694677871
reward_std: 2.9921078988971455
reward_max: -98.15756302521008
reward_min: -107.74789915966386
queue_len: 0.06824759081351374
wait_time: 0.6506027145606254
delay_time: 4.372465818178032
pressure: 0.8358753315649867
total_envstep_count: 760728
total_train_sample_count: 760728
total_episode_count: 6558
total_duration: 25056.280150175095
[2025-02-21 00:29:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.794075170636464
avg_train_sample_per_sec: 30.794075170636464
avg_episode_per_sec: 0.26546616526410743
collect_time: 22.601750373840332
reward_mean: -106.38912231559293
reward_std: 1.9828370745266277
reward_max: -103.19747899159665
reward_min: -110.02450980392157
queue_len: 0.0705498158591465
wait_time: 0.6744733813065457
delay_time: 4.499167830332371
pressure: 0.8586427939876216
total_envstep_count: 761424
total_train_sample_count: 761424
total_episode_count: 6564
total_duration: 25078.881900548935
[2025-02-21 00:29:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5018823202783
avg_train_sample_per_sec: 31.5018823202783
avg_episode_per_sec: 0.27156795103688186
collect_time: 22.093917846679688
reward_mean: -103.92763772175537
reward_std: 4.267604154292973
reward_max: -97.23739495798316
reward_min: -109.37044817927173
queue_len: 0.06891753164572637
wait_time: 0.6520952987737977
delay_time: 4.308666001122457
pressure: 0.8409593280282937
total_envstep_count: 762120
total_train_sample_count: 762120
total_episode_count: 6570
total_duration: 25100.975818395615
[2025-02-21 00:30:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.441547029333467
avg_train_sample_per_sec: 31.441547029333467
avg_episode_per_sec: 0.271047819218392
collect_time: 22.13631534576416
reward_mean: -103.7516339869281
reward_std: 4.261669519645116
reward_max: -96.86134453781513
reward_min: -108.3361344537815
queue_len: 0.06880081829371891
wait_time: 0.6515545320692379
delay_time: 4.440176264647346
pressure: 0.8401856763925729
total_envstep_count: 762816
total_train_sample_count: 762816
total_episode_count: 6576
total_duration: 25123.11213374138
[2025-02-21 00:30:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6681334623721
avg_train_sample_per_sec: 31.6681334623721
avg_episode_per_sec: 0.27300115053769053
collect_time: 21.97792935371399
reward_mean: -103.63060224089635
reward_std: 2.150706186836253
reward_max: -100.06862745098042
reward_min: -106.00070028011206
queue_len: 0.06872055851518327
wait_time: 0.6576860076479752
delay_time: 4.34157397247851
pressure: 0.8450486295313882
total_envstep_count: 763512
total_train_sample_count: 763512
total_episode_count: 6582
total_duration: 25145.090063095093
[2025-02-21 00:30:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.788005422798623
avg_train_sample_per_sec: 31.788005422798623
avg_episode_per_sec: 0.27403452950688467
collect_time: 21.89505100250244
reward_mean: -104.90336134453783
reward_std: 2.1928436175739434
reward_max: -100.81442577030815
reward_min: -107.25980392156865
queue_len: 0.06956456322582083
wait_time: 0.6595540404490708
delay_time: 4.440721359226804
pressure: 0.8482537577365163
total_envstep_count: 764208
total_train_sample_count: 764208
total_episode_count: 6588
total_duration: 25166.985114097595
[2025-02-21 00:31:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65061443586747
avg_train_sample_per_sec: 31.65061443586747
avg_episode_per_sec: 0.27285012444713336
collect_time: 21.990094423294067
reward_mean: -106.16876750700278
reward_std: 4.5522974145283035
reward_max: -100.49089635854344
reward_min: -113.20028011204485
queue_len: 0.07040369198077108
wait_time: 0.6692174106601083
delay_time: 4.418101851935396
pressure: 0.8603006189213085
total_envstep_count: 764904
total_train_sample_count: 764904
total_episode_count: 6594
total_duration: 25188.97520852089
[2025-02-21 00:31:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.500901960227424
avg_train_sample_per_sec: 31.500901960227424
avg_episode_per_sec: 0.27155949965713294
collect_time: 22.094605445861816
reward_mean: -104.99323062558356
reward_std: 2.5973440542998376
reward_max: -101.93487394957981
reward_min: -108.66036414565826
queue_len: 0.0696241582397769
wait_time: 0.6612579934714823
delay_time: 4.404274935850343
pressure: 0.8474801061007958
total_envstep_count: 765600
total_train_sample_count: 765600
total_episode_count: 6600
total_duration: 25211.06981396675
[2025-02-21 00:31:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75284975959844
avg_train_sample_per_sec: 31.75284975959844
avg_episode_per_sec: 0.27373146344481414
collect_time: 21.919292449951172
reward_mean: -104.09465452847807
reward_std: 1.8487262955005515
reward_max: -100.28361344537818
reward_min: -105.94747899159665
queue_len: 0.06902828549633824
wait_time: 0.6621119822818605
delay_time: 4.390917886527126
pressure: 0.8512378426171531
total_envstep_count: 766296
total_train_sample_count: 766296
total_episode_count: 6606
total_duration: 25232.989106416702
[2025-02-21 00:32:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.515891747599778
avg_train_sample_per_sec: 31.515891747599778
avg_episode_per_sec: 0.27168872196206706
collect_time: 22.084096670150757
reward_mean: -104.50816993464052
reward_std: 1.8511696772406656
reward_max: -100.81092436974795
reward_min: -106.80602240896359
queue_len: 0.06930249995665817
wait_time: 0.6620865963538378
delay_time: 4.389419233291334
pressure: 0.8514588859416445
total_envstep_count: 766992
total_train_sample_count: 766992
total_episode_count: 6612
total_duration: 25255.073203086853
[2025-02-21 00:32:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.922141716900615
avg_train_sample_per_sec: 31.922141716900615
avg_episode_per_sec: 0.2751908768698329
collect_time: 21.803048372268677
reward_mean: -103.5031512605042
reward_std: 3.6926031877467382
reward_max: -99.61974789915965
reward_min: -109.53501400560218
queue_len: 0.06863604194993646
wait_time: 0.654959574457546
delay_time: 4.381176498174598
pressure: 0.8313439434129091
total_envstep_count: 767688
total_train_sample_count: 767688
total_episode_count: 6618
total_duration: 25276.87625145912
[2025-02-21 00:33:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.957482091132363
avg_train_sample_per_sec: 31.957482091132363
avg_episode_per_sec: 0.27549553526838244
collect_time: 21.778937339782715
reward_mean: -104.52976190476191
reward_std: 2.5719597260136506
reward_max: -101.9803921568627
reward_min: -108.78431372549021
queue_len: 0.06931681823923204
wait_time: 0.6663732579680856
delay_time: 4.360073490855519
pressure: 0.8542219274977896
total_envstep_count: 768384
total_train_sample_count: 768384
total_episode_count: 6624
total_duration: 25298.655188798904
[2025-02-21 00:33:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.915577722476726
avg_train_sample_per_sec: 31.915577722476726
avg_episode_per_sec: 0.27513429071100626
collect_time: 21.80753254890442
reward_mean: -102.65266106442577
reward_std: 2.581153015237118
reward_max: -99.98039215686272
reward_min: -106.57703081232492
queue_len: 0.06807205640877038
wait_time: 0.6532317060334302
delay_time: 4.387591213067018
pressure: 0.831343943412909
total_envstep_count: 769080
total_train_sample_count: 769080
total_episode_count: 6630
total_duration: 25320.46272134781
[2025-02-21 00:33:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.705586675231444
avg_train_sample_per_sec: 31.705586675231444
avg_episode_per_sec: 0.27332402306234005
collect_time: 21.951967239379883
reward_mean: -103.37628384687207
reward_std: 1.8483802873498056
reward_max: -101.10784313725487
reward_min: -106.33753501400561
queue_len: 0.0685519123652998
wait_time: 0.6489590531172681
delay_time: 4.380754856545129
pressure: 0.8436118479221927
total_envstep_count: 769776
total_train_sample_count: 769776
total_episode_count: 6636
total_duration: 25342.41468858719
[2025-02-21 00:34:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.897251019760997
avg_train_sample_per_sec: 31.897251019760997
avg_episode_per_sec: 0.27497630189449135
collect_time: 21.820062160491943
reward_mean: -101.4333566760037
reward_std: 2.382574467251065
reward_max: -98.12535014005599
reward_min: -105.24369747899155
queue_len: 0.06726349912201837
wait_time: 0.6361151666679049
delay_time: 4.333626649754113
pressure: 0.8242705570291777
total_envstep_count: 770472
total_train_sample_count: 770472
total_episode_count: 6642
total_duration: 25364.23475074768
[2025-02-21 00:34:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.800822780702294
avg_train_sample_per_sec: 31.800822780702294
avg_episode_per_sec: 0.27414502397157153
collect_time: 21.886226177215576
reward_mean: -102.8949579831933
reward_std: 2.7906567517418597
reward_max: -97.87745098039214
reward_min: -106.17717086834735
queue_len: 0.06823273075808572
wait_time: 0.646462331616997
delay_time: 4.355126631270016
pressure: 0.8404067197170644
total_envstep_count: 771168
total_train_sample_count: 771168
total_episode_count: 6648
total_duration: 25386.120976924896
[2025-02-21 00:34:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.023892393485816
avg_train_sample_per_sec: 32.023892393485816
avg_episode_per_sec: 0.27606803787487777
collect_time: 21.73377275466919
reward_mean: -102.78478057889822
reward_std: 4.997455617252583
reward_max: -94.95658263305322
reward_min: -110.67226890756307
queue_len: 0.06815966881889803
wait_time: 0.6467155717282491
delay_time: 4.39975857769798
pressure: 0.8356542882404953
total_envstep_count: 771864
total_train_sample_count: 771864
total_episode_count: 6654
total_duration: 25407.854749679565
[2025-02-21 00:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67702227466938
avg_train_sample_per_sec: 31.67702227466938
avg_episode_per_sec: 0.2730777782299084
collect_time: 21.97176218032837
reward_mean: -102.3081232492997
reward_std: 2.411857661328087
reward_max: -98.96638655462183
reward_min: -105.1470588235294
queue_len: 0.0678435830565648
wait_time: 0.6434328152127341
delay_time: 4.307593604928472
pressure: 0.8262599469496021
total_envstep_count: 772560
total_train_sample_count: 772560
total_episode_count: 6660
total_duration: 25429.826511859894
[2025-02-21 00:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73914515603456
avg_train_sample_per_sec: 31.73914515603456
avg_episode_per_sec: 0.2736133203106428
collect_time: 21.928756952285767
reward_mean: -105.00630252100841
reward_std: 2.4062499304747123
reward_max: -101.57352941176467
reward_min: -108.52731092436977
queue_len: 0.06963282660544325
wait_time: 0.6668555906005196
delay_time: 4.487603517791874
pressure: 0.8449381078691424
total_envstep_count: 773256
total_train_sample_count: 773256
total_episode_count: 6666
total_duration: 25451.75526881218
[2025-02-21 00:36:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12580342967604
avg_train_sample_per_sec: 32.12580342967604
avg_episode_per_sec: 0.2769465812903107
collect_time: 21.664827823638916
reward_mean: -105.7113678804855
reward_std: 2.8897588481110588
reward_max: -101.88165266106441
reward_min: -109.98179271708688
queue_len: 0.07010037657857131
wait_time: 0.6676217348124043
delay_time: 4.481936523773598
pressure: 0.8495800176834661
total_envstep_count: 773952
total_train_sample_count: 773952
total_episode_count: 6672
total_duration: 25473.42009663582
[2025-02-21 00:36:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77911995532079
avg_train_sample_per_sec: 31.77911995532079
avg_episode_per_sec: 0.27395793064931717
collect_time: 21.901172876358032
reward_mean: -105.18790849673202
reward_std: 3.4797898607203264
reward_max: -101.26540616246498
reward_min: -111.44747899159661
queue_len: 0.0697532549713077
wait_time: 0.6584988217214383
delay_time: 4.461760191204763
pressure: 0.8467064544650752
total_envstep_count: 774648
total_train_sample_count: 774648
total_episode_count: 6678
total_duration: 25495.321269512177
[2025-02-21 00:36:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71519700446706
avg_train_sample_per_sec: 31.71519700446706
avg_episode_per_sec: 0.27340687072816433
collect_time: 21.94531536102295
reward_mean: -106.14950980392156
reward_std: 4.49703721447782
reward_max: -100.8046218487395
reward_min: -114.75280112044821
queue_len: 0.07039092162063765
wait_time: 0.6756665199236194
delay_time: 4.4567117264971365
pressure: 0.8654951370468612
total_envstep_count: 775344
total_train_sample_count: 775344
total_episode_count: 6684
total_duration: 25517.2665848732
[2025-02-21 00:37:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.671004332784033
avg_train_sample_per_sec: 31.671004332784033
avg_episode_per_sec: 0.273025899420552
collect_time: 21.975937128067017
reward_mean: -102.36939775910366
reward_std: 2.840493323364514
reward_max: -98.21498599439776
reward_min: -107.26750700280114
queue_len: 0.06788421602062576
wait_time: 0.6491579611508618
delay_time: 4.316768433901949
pressure: 0.8347701149425287
total_envstep_count: 776040
total_train_sample_count: 776040
total_episode_count: 6690
total_duration: 25539.242522001266
[2025-02-21 00:37:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.50031187000414
avg_train_sample_per_sec: 31.50031187000414
avg_episode_per_sec: 0.2715544126724495
collect_time: 22.095019340515137
reward_mean: -104.72478991596638
reward_std: 3.2517718951144836
reward_max: -99.70798319327726
reward_min: -107.90686274509808
queue_len: 0.0694461471591289
wait_time: 0.6632096140843605
delay_time: 4.425175836893515
pressure: 0.8471485411140582
total_envstep_count: 776736
total_train_sample_count: 776736
total_episode_count: 6696
total_duration: 25561.33754134178
[2025-02-21 00:37:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83802747108838
avg_train_sample_per_sec: 31.83802747108838
avg_episode_per_sec: 0.27446575406110674
collect_time: 21.860650777816772
reward_mean: -105.10667600373483
reward_std: 2.9955692126425864
reward_max: -100.5483193277311
reward_min: -109.96918767507002
queue_len: 0.06969938727038118
wait_time: 0.6666802883841423
delay_time: 4.400447915460085
pressure: 0.8511273209549072
total_envstep_count: 777432
total_train_sample_count: 777432
total_episode_count: 6702
total_duration: 25583.1981921196
[2025-02-21 00:38:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54458132842671
avg_train_sample_per_sec: 31.54458132842671
avg_episode_per_sec: 0.271936045934713
collect_time: 22.064011335372925
reward_mean: -104.0143557422969
reward_std: 2.9098726991094668
reward_max: -100.71918767507003
reward_min: -107.98529411764707
queue_len: 0.06897503696438786
wait_time: 0.6537042867544898
delay_time: 4.397372127864778
pressure: 0.8464854111405836
total_envstep_count: 778128
total_train_sample_count: 778128
total_episode_count: 6708
total_duration: 25605.26220345497
[2025-02-21 00:38:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.15114041321774
avg_train_sample_per_sec: 32.15114041321774
avg_episode_per_sec: 0.2771650035622219
collect_time: 21.647754669189453
reward_mean: -103.43032212885153
reward_std: 3.044661180164558
reward_max: -97.67717086834733
reward_min: -108.07633053221286
queue_len: 0.06858774676979544
wait_time: 0.6494040808188881
delay_time: 4.365967861371547
pressure: 0.8376436781609197
total_envstep_count: 778824
total_train_sample_count: 778824
total_episode_count: 6714
total_duration: 25626.90995812416
[2025-02-21 00:39:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00773333900852
avg_train_sample_per_sec: 32.00773333900852
avg_episode_per_sec: 0.27592873568110793
collect_time: 21.744745016098022
reward_mean: -102.86764705882354
reward_std: 2.0840182790742308
reward_max: -99.87745098039214
reward_min: -106.07492997198877
queue_len: 0.06821462006553285
wait_time: 0.6516392808228509
delay_time: 4.383321069114376
pressure: 0.8321175950486294
total_envstep_count: 779520
total_train_sample_count: 779520
total_episode_count: 6720
total_duration: 25648.65470314026
[2025-02-21 00:39:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5930918248103
avg_train_sample_per_sec: 31.5930918248103
avg_episode_per_sec: 0.2723542398690543
collect_time: 22.03013253211975
reward_mean: -102.90289449112977
reward_std: 3.01007097275353
reward_max: -98.88375350140055
reward_min: -107.61974789915966
queue_len: 0.06823799369438314
wait_time: 0.6532648315736551
delay_time: 4.34464135406884
pressure: 0.8333333333333334
total_envstep_count: 780216
total_train_sample_count: 780216
total_episode_count: 6726
total_duration: 25670.68483567238
[2025-02-21 00:39:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6464850584707
avg_train_sample_per_sec: 31.6464850584707
avg_episode_per_sec: 0.27281452636612674
collect_time: 21.992963790893555
reward_mean: -105.27100840336136
reward_std: 3.4147018774947604
reward_max: -100.67927170868349
reward_min: -111.68627450980397
queue_len: 0.06980836101018657
wait_time: 0.6632653392922156
delay_time: 4.45432621551102
pressure: 0.8481432360742706
total_envstep_count: 780912
total_train_sample_count: 780912
total_episode_count: 6732
total_duration: 25692.677799463272
[2025-02-21 00:40:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.943050498314047
avg_train_sample_per_sec: 31.943050498314047
avg_episode_per_sec: 0.27537112498546595
collect_time: 21.788776874542236
reward_mean: -102.33893557422971
reward_std: 2.368848028393004
reward_max: -100.64775910364143
reward_min: -107.50630252100841
queue_len: 0.06786401563277832
wait_time: 0.6405184642380383
delay_time: 4.355172305307868
pressure: 0.8261494252873565
total_envstep_count: 781608
total_train_sample_count: 781608
total_episode_count: 6738
total_duration: 25714.466576337814
[2025-02-21 00:40:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97185634766188
avg_train_sample_per_sec: 31.97185634766188
avg_episode_per_sec: 0.27561945127294724
collect_time: 21.769145727157593
reward_mean: -102.47397292250236
reward_std: 3.517524439278812
reward_max: -97.99299719887958
reward_min: -107.87184873949579
queue_len: 0.06795356294595646
wait_time: 0.6444944578184945
delay_time: 4.368327093535414
pressure: 0.829575596816976
total_envstep_count: 782304
total_train_sample_count: 782304
total_episode_count: 6744
total_duration: 25736.235722064972
[2025-02-21 00:40:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.795388668347435
avg_train_sample_per_sec: 31.795388668347435
avg_episode_per_sec: 0.27409817817540894
collect_time: 21.8899667263031
reward_mean: -102.3409197012138
reward_std: 3.2453359508557207
reward_max: -98.22549019607838
reward_min: -108.43417366946778
queue_len: 0.06786533136685266
wait_time: 0.6470192741110591
delay_time: 4.36926809972984
pressure: 0.8272546419098142
total_envstep_count: 783000
total_train_sample_count: 783000
total_episode_count: 6750
total_duration: 25758.125688791275
[2025-02-21 00:41:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.66726295899303
avg_train_sample_per_sec: 31.66726295899303
avg_episode_per_sec: 0.2729936461982158
collect_time: 21.978533506393433
reward_mean: -103.98704481792714
reward_std: 2.989206112898842
reward_max: -98.07352941176468
reward_min: -107.96148459383751
queue_len: 0.06895692627183497
wait_time: 0.6590883479828714
delay_time: 4.397422430414443
pressure: 0.8381962864721485
total_envstep_count: 783696
total_train_sample_count: 783696
total_episode_count: 6756
total_duration: 25780.10422229767
[2025-02-21 00:41:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.811609914823034
avg_train_sample_per_sec: 31.811609914823034
avg_episode_per_sec: 0.2742380165070951
collect_time: 21.878804683685303
reward_mean: -102.6281512605042
reward_std: 1.706434017008402
reward_max: -100.79201680672264
reward_min: -104.7689075630252
queue_len: 0.06805580322314603
wait_time: 0.6446205361012662
delay_time: 4.340051267757921
pressure: 0.8257073386383732
total_envstep_count: 784392
total_train_sample_count: 784392
total_episode_count: 6762
total_duration: 25801.983026981354
[2025-02-21 00:42:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.705188953813092
avg_train_sample_per_sec: 31.705188953813092
avg_episode_per_sec: 0.2733205944294232
collect_time: 21.952242612838745
reward_mean: -105.85259103641458
reward_std: 3.2604221741741504
reward_max: -99.421568627451
reward_min: -110.08683473389348
queue_len: 0.07019402588621655
wait_time: 0.6690133944824614
delay_time: 4.501937989395732
pressure: 0.848474801061008
total_envstep_count: 785088
total_train_sample_count: 785088
total_episode_count: 6768
total_duration: 25823.935269594193
[2025-02-21 00:42:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.606433758066135
avg_train_sample_per_sec: 31.606433758066135
avg_episode_per_sec: 0.2724692565350529
collect_time: 22.020833015441895
reward_mean: -105.27731092436973
reward_std: 4.24433919983094
reward_max: -100.30252100840337
reward_min: -112.8200280112045
queue_len: 0.06981254040077571
wait_time: 0.6677478904912982
delay_time: 4.442247531632922
pressure: 0.8563218390804598
total_envstep_count: 785784
total_train_sample_count: 785784
total_episode_count: 6774
total_duration: 25845.956102609634
[2025-02-21 00:42:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.678662990936107
avg_train_sample_per_sec: 31.678662990936107
avg_episode_per_sec: 0.2730919223356561
collect_time: 21.970624208450317
reward_mean: -103.63340336134452
reward_std: 2.7389576094858405
reward_max: -98.13725490196077
reward_min: -106.33193277310924
queue_len: 0.06872241602211175
wait_time: 0.6533888201611325
delay_time: 4.401246148001969
pressure: 0.842948717948718
total_envstep_count: 786480
total_train_sample_count: 786480
total_episode_count: 6780
total_duration: 25867.926726818085
[2025-02-21 00:43:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.976535846621157
avg_train_sample_per_sec: 30.976535846621157
avg_episode_per_sec: 0.2670391021260445
collect_time: 22.46861958503723
reward_mean: -101.25525210084034
reward_std: 2.829315954085557
reward_max: -98.18417366946782
reward_min: -106.56722689075627
queue_len: 0.06714539263981455
wait_time: 0.6369400545364033
delay_time: 4.332428163837917
pressure: 0.8112290008841733
total_envstep_count: 787176
total_train_sample_count: 787176
total_episode_count: 6786
total_duration: 25890.395346403122
[2025-02-21 00:43:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68428664678261
avg_train_sample_per_sec: 31.68428664678261
avg_episode_per_sec: 0.2731404021274363
collect_time: 21.966724634170532
reward_mean: -103.95378151260502
reward_std: 2.547029990945387
reward_max: -99.546918767507
reward_min: -107.45308123249296
queue_len: 0.06893486837705902
wait_time: 0.6585843444362715
delay_time: 4.364903206760227
pressure: 0.8391909814323607
total_envstep_count: 787872
total_train_sample_count: 787872
total_episode_count: 6792
total_duration: 25912.362071037292
[2025-02-21 00:43:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0287034774956
avg_train_sample_per_sec: 32.0287034774956
avg_episode_per_sec: 0.276109512737031
collect_time: 21.73050808906555
reward_mean: -101.16690009337067
reward_std: 3.3882736721631246
reward_max: -94.38655462184873
reward_min: -104.12955182072828
queue_len: 0.06708680377544475
wait_time: 0.6365651477213343
delay_time: 4.315004397779325
pressure: 0.8190760389036251
total_envstep_count: 788568
total_train_sample_count: 788568
total_episode_count: 6798
total_duration: 25934.092579126358
[2025-02-21 00:44:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.741121904287528
avg_train_sample_per_sec: 31.741121904287528
avg_episode_per_sec: 0.273630361243858
collect_time: 21.927391290664673
reward_mean: -103.93954248366015
reward_std: 2.3823612663941796
reward_max: -100.21358543417365
reward_min: -107.5546218487395
queue_len: 0.0689254260501725
wait_time: 0.658004415293969
delay_time: 4.378404777895269
pressure: 0.8408488063660479
total_envstep_count: 789264
total_train_sample_count: 789264
total_episode_count: 6804
total_duration: 25956.019970417023
[2025-02-21 00:44:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.674456869218616
avg_train_sample_per_sec: 31.674456869218616
avg_episode_per_sec: 0.2730556626656777
collect_time: 21.973541736602783
reward_mean: -103.8703314659197
reward_std: 3.142857959867826
reward_max: -98.9075630252101
reward_min: -107.47549019607844
queue_len: 0.06887953014981414
wait_time: 0.6549454883633382
delay_time: 4.373646722684561
pressure: 0.837312113174182
total_envstep_count: 789960
total_train_sample_count: 789960
total_episode_count: 6810
total_duration: 25977.993512153625
[2025-02-21 00:45:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.705778136026208
avg_train_sample_per_sec: 31.705778136026208
avg_episode_per_sec: 0.27332567358643284
collect_time: 21.951834678649902
reward_mean: -105.55964052287582
reward_std: 2.91872769920831
reward_max: -101.5546218487395
reward_min: -110.81512605042016
queue_len: 0.06999976161994417
wait_time: 0.6711302558158542
delay_time: 4.461506631112523
pressure: 0.8521220159151194
total_envstep_count: 790656
total_train_sample_count: 790656
total_episode_count: 6816
total_duration: 25999.945346832275
[2025-02-21 00:45:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.631682714251355
avg_train_sample_per_sec: 31.631682714251355
avg_episode_per_sec: 0.2726869199504427
collect_time: 22.003255605697632
reward_mean: -103.85037348272643
reward_std: 3.055786744457873
reward_max: -99.03431372549021
reward_min: -108.07072829131656
queue_len: 0.06886629541294857
wait_time: 0.6650609293230996
delay_time: 4.432621255023906
pressure: 0.8422855879752431
total_envstep_count: 791352
total_train_sample_count: 791352
total_episode_count: 6822
total_duration: 26021.948602437973
[2025-02-21 00:45:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639123475604222
avg_train_sample_per_sec: 31.639123475604222
avg_episode_per_sec: 0.27275106444486397
collect_time: 21.99808096885681
reward_mean: -105.2093837535014
reward_std: 2.5876433229929447
reward_max: -102.22619047619045
reward_min: -109.11764705882351
queue_len: 0.06976749585775954
wait_time: 0.662224903223889
delay_time: 4.448523161115132
pressure: 0.8580901856763926
total_envstep_count: 792048
total_train_sample_count: 792048
total_episode_count: 6828
total_duration: 26043.94668340683
[2025-02-21 00:46:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.791010240910452
avg_train_sample_per_sec: 31.791010240910452
avg_episode_per_sec: 0.274060433111297
collect_time: 21.89298152923584
reward_mean: -103.19456115779646
reward_std: 2.467693133526748
reward_max: -100.03501400560225
reward_min: -107.19117647058822
queue_len: 0.0684314066033133
wait_time: 0.6548430158977827
delay_time: 4.334068595627792
pressure: 0.8372015915119363
total_envstep_count: 792744
total_train_sample_count: 792744
total_episode_count: 6834
total_duration: 26065.839664936066
[2025-02-21 00:46:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.802743469573834
avg_train_sample_per_sec: 31.802743469573834
avg_episode_per_sec: 0.2741615816342572
collect_time: 21.884904384613037
reward_mean: -103.69911297852472
reward_std: 3.9205987585079227
reward_max: -98.0686274509804
reward_min: -109.39425770308125
queue_len: 0.0687659900388095
wait_time: 0.6562245366758552
delay_time: 4.363382894034995
pressure: 0.8422855879752432
total_envstep_count: 793440
total_train_sample_count: 793440
total_episode_count: 6840
total_duration: 26087.72456932068
[2025-02-21 00:46:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.610337047607334
avg_train_sample_per_sec: 31.610337047607334
avg_episode_per_sec: 0.27250290558282186
collect_time: 22.01811385154724
reward_mean: -102.57994864612512
reward_std: 2.4332990491884456
reward_max: -99.00490196078428
reward_min: -105.83823529411764
queue_len: 0.0680238386247514
wait_time: 0.6459111938320863
delay_time: 4.38094608420561
pressure: 0.8295755968169761
total_envstep_count: 794136
total_train_sample_count: 794136
total_episode_count: 6846
total_duration: 26109.742683172226
[2025-02-21 00:47:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.555275451972573
avg_train_sample_per_sec: 31.555275451972573
avg_episode_per_sec: 0.272028236654936
collect_time: 22.056533813476562
reward_mean: -103.36659663865545
reward_std: 2.4926336151928576
reward_max: -100.27310924369748
reward_min: -107.5049019607843
queue_len: 0.06854548848717205
wait_time: 0.6533550754519314
delay_time: 4.3730417623367375
pressure: 0.8376436781609194
total_envstep_count: 794832
total_train_sample_count: 794832
total_episode_count: 6852
total_duration: 26131.799216985703
[2025-02-21 00:47:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.620598688530208
avg_train_sample_per_sec: 31.620598688530208
avg_episode_per_sec: 0.2725913680045708
collect_time: 22.010968446731567
reward_mean: -104.27229225023343
reward_std: 2.375002087750818
reward_max: -101.22689075630254
reward_min: -106.8564425770308
queue_len: 0.069146082394054
wait_time: 0.6597856870422792
delay_time: 4.430319026100882
pressure: 0.8440539345711758
total_envstep_count: 795528
total_train_sample_count: 795528
total_episode_count: 6858
total_duration: 26153.810185432434
[2025-02-21 00:48:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.864916754792958
avg_train_sample_per_sec: 31.864916754792958
avg_episode_per_sec: 0.27469755823097375
collect_time: 21.842203617095947
reward_mean: -102.56430905695613
reward_std: 6.0104107597887175
reward_max: -96.85574229691879
reward_min: -111.57492997198878
queue_len: 0.06801346754440062
wait_time: 0.6484334560526245
delay_time: 4.412951141786338
pressure: 0.8293545534924845
total_envstep_count: 796224
total_train_sample_count: 796224
total_episode_count: 6864
total_duration: 26175.65238904953
[2025-02-21 00:48:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.994614378628803
avg_train_sample_per_sec: 31.994614378628803
avg_episode_per_sec: 0.2758156411950759
collect_time: 21.753661155700684
reward_mean: -103.77310924369749
reward_std: 2.7493374151288608
reward_max: -100.28641456582635
reward_min: -108.16316526610646
queue_len: 0.06881505918017075
wait_time: 0.6592374903100056
delay_time: 4.394237937502988
pressure: 0.8380857648099026
total_envstep_count: 796920
total_train_sample_count: 796920
total_episode_count: 6870
total_duration: 26197.40605020523
[2025-02-21 00:48:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7175956725784
avg_train_sample_per_sec: 31.7175956725784
avg_episode_per_sec: 0.2734275489015379
collect_time: 21.943655729293823
reward_mean: -102.55380485527543
reward_std: 2.8892704383621814
reward_max: -96.63025210084035
reward_min: -105.296918767507
queue_len: 0.06800650189341872
wait_time: 0.6438876722218507
delay_time: 4.315954529258197
pressure: 0.836759504862953
total_envstep_count: 797616
total_train_sample_count: 797616
total_episode_count: 6876
total_duration: 26219.349705934525
[2025-02-21 00:49:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.682411185300285
avg_train_sample_per_sec: 31.682411185300285
avg_episode_per_sec: 0.27312423435603694
collect_time: 21.968024969100952
reward_mean: -104.13655462184875
reward_std: 4.410311348209837
reward_max: -99.22899159663868
reward_min: -110.55392156862747
queue_len: 0.06905607070414373
wait_time: 0.6573174473149118
delay_time: 4.4014840780082185
pressure: 0.8380857648099026
total_envstep_count: 798312
total_train_sample_count: 798312
total_episode_count: 6882
total_duration: 26241.317730903625
[2025-02-21 00:49:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.896562343787473
avg_train_sample_per_sec: 31.896562343787473
avg_episode_per_sec: 0.27497036503265065
collect_time: 21.820533275604248
reward_mean: -103.17542016806722
reward_std: 3.5152664000976297
reward_max: -98.9565826330532
reward_min: -108.84873949579833
queue_len: 0.06841871363930188
wait_time: 0.651139224478474
delay_time: 4.38463690474639
pressure: 0.8338859416445623
total_envstep_count: 799008
total_train_sample_count: 799008
total_episode_count: 6888
total_duration: 26263.13826417923
[2025-02-21 00:49:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69771812220455
avg_train_sample_per_sec: 31.69771812220455
avg_episode_per_sec: 0.2732561907086599
collect_time: 21.957416534423828
reward_mean: -104.062441643324
reward_std: 2.0362519078222587
reward_max: -101.73879551820725
reward_min: -107.6358543417367
queue_len: 0.06900692416666047
wait_time: 0.653906058444598
delay_time: 4.407780977465512
pressure: 0.8377541998231653
total_envstep_count: 799704
total_train_sample_count: 799704
total_episode_count: 6894
total_duration: 26285.095680713654
[2025-02-21 00:50:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47646198658111
avg_train_sample_per_sec: 31.47646198658111
avg_episode_per_sec: 0.27134881022914753
collect_time: 22.11176085472107
reward_mean: -105.08076563958916
reward_std: 2.8306769506811813
reward_max: -101.01050420168066
reward_min: -110.31372549019606
queue_len: 0.06968220533129255
wait_time: 0.6604957190656987
delay_time: 4.45053879928021
pressure: 0.8516799292661362
total_envstep_count: 800400
total_train_sample_count: 800400
total_episode_count: 6900
total_duration: 26307.207441568375
[2025-02-21 00:50:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.768023301722113
avg_train_sample_per_sec: 31.768023301722113
avg_episode_per_sec: 0.273862269842432
collect_time: 21.908823013305664
reward_mean: -105.05718954248367
reward_std: 2.113641773337041
reward_max: -101.45728291316526
reward_min: -107.22549019607841
queue_len: 0.06966657131464433
wait_time: 0.6605514442735538
delay_time: 4.419216840257744
pressure: 0.847259062776304
total_envstep_count: 801096
total_train_sample_count: 801096
total_episode_count: 6906
total_duration: 26329.11626458168
[2025-02-21 00:51:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.769476730709084
avg_train_sample_per_sec: 31.769476730709084
avg_episode_per_sec: 0.2738747994026645
collect_time: 21.90782070159912
reward_mean: -103.90172735760972
reward_std: 3.2393784436851125
reward_max: -99.87535014005603
reward_min: -108.65826330532215
queue_len: 0.06890034970663773
wait_time: 0.657993115460154
delay_time: 4.352166949013321
pressure: 0.8364279398762159
total_envstep_count: 801792
total_train_sample_count: 801792
total_episode_count: 6912
total_duration: 26351.02408528328
[2025-02-21 00:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83300065316177
avg_train_sample_per_sec: 31.83300065316177
avg_episode_per_sec: 0.27442241942380835
collect_time: 21.864102840423584
reward_mean: -106.04481792717087
reward_std: 2.3908858323719864
reward_max: -103.1932773109244
reward_min: -110.96148459383751
queue_len: 0.07032149729918492
wait_time: 0.6722152720504647
delay_time: 4.460538191627807
pressure: 0.8547745358090185
total_envstep_count: 802488
total_train_sample_count: 802488
total_episode_count: 6918
total_duration: 26372.888188123703
[2025-02-21 00:51:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.623422921251098
avg_train_sample_per_sec: 31.623422921251098
avg_episode_per_sec: 0.27261571483837155
collect_time: 22.009002685546875
reward_mean: -104.00070028011204
reward_std: 2.2631853555350023
reward_max: -102.41456582633053
reward_min: -108.83263305322124
queue_len: 0.06896598161811143
wait_time: 0.6613764869342963
delay_time: 4.412388047543838
pressure: 0.8389699381078691
total_envstep_count: 803184
total_train_sample_count: 803184
total_episode_count: 6924
total_duration: 26394.89719080925
[2025-02-21 00:52:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.542798031857988
avg_train_sample_per_sec: 31.542798031857988
avg_episode_per_sec: 0.27192067268843095
collect_time: 22.065258741378784
reward_mean: -104.15371148459383
reward_std: 1.618329448008052
reward_max: -101.06162464985997
reward_min: -105.7549019607843
queue_len: 0.06906744793408079
wait_time: 0.6553461680870404
delay_time: 4.427455939785424
pressure: 0.8359858532272324
total_envstep_count: 803880
total_train_sample_count: 803880
total_episode_count: 6930
total_duration: 26416.96244955063
[2025-02-21 00:52:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68942415486274
avg_train_sample_per_sec: 31.68942415486274
avg_episode_per_sec: 0.27318469099019604
collect_time: 21.963163375854492
reward_mean: -103.57563025210084
reward_std: 3.2233066943462023
reward_max: -99.33053221288513
reward_min: -109.40056022408966
queue_len: 0.06868410494171144
wait_time: 0.6532697075293424
delay_time: 4.411913293963841
pressure: 0.8367595048629531
total_envstep_count: 804576
total_train_sample_count: 804576
total_episode_count: 6936
total_duration: 26438.925612926483
[2025-02-21 00:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5659993564689
avg_train_sample_per_sec: 31.5659993564689
avg_episode_per_sec: 0.2721206841074905
collect_time: 22.04904055595398
reward_mean: -102.14600840336135
reward_std: 3.423469498720654
reward_max: -96.12254901960783
reward_min: -107.51820728291314
queue_len: 0.06773607984307782
wait_time: 0.6450724520577461
delay_time: 4.351513447002098
pressure: 0.833001768346596
total_envstep_count: 805272
total_train_sample_count: 805272
total_episode_count: 6942
total_duration: 26460.974653482437
[2025-02-21 00:53:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62265798221195
avg_train_sample_per_sec: 31.62265798221195
avg_episode_per_sec: 0.2726091205363099
collect_time: 22.00953507423401
reward_mean: -106.53186274509805
reward_std: 3.198720235916486
reward_max: -102.08543417366948
reward_min: -110.77450980392152
queue_len: 0.07064447131637801
wait_time: 0.6734829431330446
delay_time: 4.4767663646144715
pressure: 0.8591954022988505
total_envstep_count: 805968
total_train_sample_count: 805968
total_episode_count: 6948
total_duration: 26482.98418855667
[2025-02-21 00:53:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.023012057978235
avg_train_sample_per_sec: 32.023012057978235
avg_episode_per_sec: 0.2760604487756744
collect_time: 21.734370231628418
reward_mean: -103.22222222222223
reward_std: 2.3022283071676557
reward_max: -100.2247899159664
reward_min: -106.5609243697479
queue_len: 0.06844974948423226
wait_time: 0.6492999056386481
delay_time: 4.419494027759686
pressure: 0.8307913351016799
total_envstep_count: 806664
total_train_sample_count: 806664
total_episode_count: 6954
total_duration: 26504.7185587883
[2025-02-21 00:54:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.756722624335215
avg_train_sample_per_sec: 31.756722624335215
avg_episode_per_sec: 0.2737648502097863
collect_time: 21.916619300842285
reward_mean: -102.94444444444444
reward_std: 1.9453179730710703
reward_max: -100.29411764705884
reward_min: -105.31022408963587
queue_len: 0.06826554671382258
wait_time: 0.6497936155010192
delay_time: 4.34532603888179
pressure: 0.8311229000884174
total_envstep_count: 807360
total_train_sample_count: 807360
total_episode_count: 6960
total_duration: 26526.635178089142
[2025-02-21 00:54:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02326884677543
avg_train_sample_per_sec: 32.02326884677543
avg_episode_per_sec: 0.27606266247220196
collect_time: 21.734195947647095
reward_mean: -102.4861111111111
reward_std: 2.728580490785226
reward_max: -99.1218487394958
reward_min: -106.61414565826331
queue_len: 0.06796161214264662
wait_time: 0.6443685343279663
delay_time: 4.32415679963011
pressure: 0.8344385499557913
total_envstep_count: 808056
total_train_sample_count: 808056
total_episode_count: 6966
total_duration: 26548.36937403679
[2025-02-21 00:54:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.56278950764984
avg_train_sample_per_sec: 31.56278950764984
avg_episode_per_sec: 0.27209301299698135
collect_time: 22.05128288269043
reward_mean: -101.63597105508869
reward_std: 2.031136296024694
reward_max: -98.8515406162465
reward_min: -104.31582633053223
queue_len: 0.0673978587898466
wait_time: 0.6426856330507446
delay_time: 4.308485744262371
pressure: 0.8216180371352785
total_envstep_count: 808752
total_train_sample_count: 808752
total_episode_count: 6972
total_duration: 26570.42065691948
[2025-02-21 00:55:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69077407180882
avg_train_sample_per_sec: 31.69077407180882
avg_episode_per_sec: 0.2731963282052485
collect_time: 21.962227821350098
reward_mean: -103.96860410830998
reward_std: 3.6533308386827184
reward_max: -97.93067226890756
reward_min: -108.61834733893556
queue_len: 0.06894469768455569
wait_time: 0.6598875403388587
delay_time: 4.420864196853396
pressure: 0.8336648983200708
total_envstep_count: 809448
total_train_sample_count: 809448
total_episode_count: 6978
total_duration: 26592.38288474083
[2025-02-21 00:55:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.446524475357243
avg_train_sample_per_sec: 31.446524475357243
avg_episode_per_sec: 0.2710907282358383
collect_time: 22.132811546325684
reward_mean: -104.78513071895424
reward_std: 3.9422705254204886
reward_max: -97.17226890756305
reward_min: -108.796918767507
queue_len: 0.06948616095421369
wait_time: 0.6623145279331891
delay_time: 4.486850751094273
pressure: 0.8408488063660479
total_envstep_count: 810144
total_train_sample_count: 810144
total_episode_count: 6984
total_duration: 26614.515696287155
[2025-02-21 00:55:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.767781998364576
avg_train_sample_per_sec: 31.767781998364576
avg_episode_per_sec: 0.27386018964107395
collect_time: 21.908989429473877
reward_mean: -104.27556022408965
reward_std: 3.076120870108361
reward_max: -99.21358543417365
reward_min: -108.46988795518206
queue_len: 0.06914824948547059
wait_time: 0.6563394699170562
delay_time: 4.431561188331093
pressure: 0.8454907161803714
total_envstep_count: 810840
total_train_sample_count: 810840
total_episode_count: 6990
total_duration: 26636.42468571663
[2025-02-21 00:56:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.604744399799475
avg_train_sample_per_sec: 31.604744399799475
avg_episode_per_sec: 0.2724546931017196
collect_time: 22.02201008796692
reward_mean: -102.69596171802054
reward_std: 1.9170210133728374
reward_max: -101.20238095238088
reward_min: -106.27450980392157
queue_len: 0.06810077037004016
wait_time: 0.6485965296817223
delay_time: 4.334335020923091
pressure: 0.8367595048629531
total_envstep_count: 811536
total_train_sample_count: 811536
total_episode_count: 6996
total_duration: 26658.446695804596
[2025-02-21 00:56:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.616337432750036
avg_train_sample_per_sec: 31.616337432750036
avg_episode_per_sec: 0.27255463304094857
collect_time: 22.013935089111328
reward_mean: -103.89157329598508
reward_std: 2.251572970524343
reward_max: -100.95378151260509
reward_min: -108.2065826330532
queue_len: 0.06889361624402192
wait_time: 0.6576383316368103
delay_time: 4.392892703834435
pressure: 0.8453801945181256
total_envstep_count: 812232
total_train_sample_count: 812232
total_episode_count: 7002
total_duration: 26680.460630893707
[2025-02-21 00:57:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.717613439730673
avg_train_sample_per_sec: 30.717613439730673
avg_episode_per_sec: 0.2648070124114713
collect_time: 22.658010244369507
reward_mean: -103.57819794584499
reward_std: 3.6750443337853205
reward_max: -98.14005602240896
reward_min: -108.5021008403361
queue_len: 0.06868580765639588
wait_time: 0.6525110707412939
delay_time: 4.482257092150338
pressure: 0.8321175950486294
total_envstep_count: 812928
total_train_sample_count: 812928
total_episode_count: 7008
total_duration: 26703.118641138077
[2025-02-21 00:57:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.513132953185433
avg_train_sample_per_sec: 31.513132953185433
avg_episode_per_sec: 0.27166493925159857
collect_time: 22.08603000640869
reward_mean: -103.53127917833798
reward_std: 1.9366773998064837
reward_max: -101.1757703081232
reward_min: -106.34593837535014
queue_len: 0.06865469441534348
wait_time: 0.6548050144018703
delay_time: 4.378356700287855
pressure: 0.836759504862953
total_envstep_count: 813624
total_train_sample_count: 813624
total_episode_count: 7014
total_duration: 26725.204671144485
[2025-02-21 00:57:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53967672571151
avg_train_sample_per_sec: 31.53967672571151
avg_episode_per_sec: 0.2718937648768234
collect_time: 22.067442417144775
reward_mean: -104.86612978524742
reward_std: 2.859165156194343
reward_max: -100.27871148459381
reward_min: -109.88095238095235
queue_len: 0.06953987386289617
wait_time: 0.6561726812741012
delay_time: 4.495381376615593
pressure: 0.8440539345711761
total_envstep_count: 814320
total_train_sample_count: 814320
total_episode_count: 7020
total_duration: 26747.27211356163
[2025-02-21 00:58:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.960735983102094
avg_train_sample_per_sec: 31.960735983102094
avg_episode_per_sec: 0.27552358606122496
collect_time: 21.77672004699707
reward_mean: -103.02661064425769
reward_std: 2.6636331218724085
reward_max: -99.68977591036415
reward_min: -106.58193277310924
queue_len: 0.06832003358372525
wait_time: 0.6471206630309064
delay_time: 4.416027827643048
pressure: 0.8353227232537578
total_envstep_count: 815016
total_train_sample_count: 815016
total_episode_count: 7026
total_duration: 26769.048833608627
[2025-02-21 00:58:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.07561684193167
avg_train_sample_per_sec: 31.07561684193167
avg_episode_per_sec: 0.267893248637342
collect_time: 22.39698100090027
reward_mean: -103.015639589169
reward_std: 1.5213468272678303
reward_max: -100.86834733893559
reward_min: -104.71358543417367
queue_len: 0.0683127583482553
wait_time: 0.6479580890711722
delay_time: 4.42929392819001
pressure: 0.8283598585322722
total_envstep_count: 815712
total_train_sample_count: 815712
total_episode_count: 7032
total_duration: 26791.445814609528
[2025-02-21 00:58:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.746391099634952
avg_train_sample_per_sec: 31.746391099634952
avg_episode_per_sec: 0.27367578534168063
collect_time: 21.923751831054688
reward_mean: -103.37418300653594
reward_std: 1.6189994421014908
reward_max: -101.27450980392157
reward_min: -105.70658263305324
queue_len: 0.06855051923510341
wait_time: 0.6528760708527442
delay_time: 4.359765737031776
pressure: 0.8362068965517242
total_envstep_count: 816408
total_train_sample_count: 816408
total_episode_count: 7038
total_duration: 26813.369566440582
[2025-02-21 00:59:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.776227722269837
avg_train_sample_per_sec: 31.776227722269837
avg_episode_per_sec: 0.27393299760577444
collect_time: 21.9031662940979
reward_mean: -101.86297852474321
reward_std: 3.1952147961381425
reward_max: -98.22268907563026
reward_min: -107.56582633053223
queue_len: 0.06754839424717722
wait_time: 0.6445316079570643
delay_time: 4.321911624617827
pressure: 0.8316755083996464
total_envstep_count: 817104
total_train_sample_count: 817104
total_episode_count: 7044
total_duration: 26835.27273273468
[2025-02-21 00:59:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.727671559217153
avg_train_sample_per_sec: 31.727671559217153
avg_episode_per_sec: 0.27351440999325133
collect_time: 21.936686992645264
reward_mean: -101.26365546218487
reward_std: 2.67782459548146
reward_max: -97.27521008403363
reward_min: -106.12324929971984
queue_len: 0.06715096516060004
wait_time: 0.6332396685464635
delay_time: 4.284060774621919
pressure: 0.8222811671087533
total_envstep_count: 817800
total_train_sample_count: 817800
total_episode_count: 7050
total_duration: 26857.209419727325
[2025-02-21 01:00:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78569646068646
avg_train_sample_per_sec: 31.78569646068646
avg_episode_per_sec: 0.27401462466109017
collect_time: 21.896641492843628
reward_mean: -103.10947712418299
reward_std: 3.7279752885056867
reward_max: -98.71078431372545
reward_min: -108.45938375350138
queue_len: 0.06837498483036007
wait_time: 0.6512512940631602
delay_time: 4.365242238178604
pressure: 0.8318965517241379
total_envstep_count: 818496
total_train_sample_count: 818496
total_episode_count: 7056
total_duration: 26879.10606122017
[2025-02-21 01:00:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.66252824505613
avg_train_sample_per_sec: 31.66252824505613
avg_episode_per_sec: 0.2729528296987597
collect_time: 21.981820106506348
reward_mean: -104.08566760037347
reward_std: 3.571917902497459
reward_max: -98.20098039215681
reward_min: -107.68837535014009
queue_len: 0.06902232599494261
wait_time: 0.655720455733133
delay_time: 4.392707388675361
pressure: 0.8437223695844386
total_envstep_count: 819192
total_train_sample_count: 819192
total_episode_count: 7062
total_duration: 26901.087881326675
[2025-02-21 01:00:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5112933449331
avg_train_sample_per_sec: 31.5112933449331
avg_episode_per_sec: 0.2716490805597681
collect_time: 22.087319374084473
reward_mean: -103.17203548085904
reward_std: 4.030321508237854
reward_max: -96.3382352941177
reward_min: -108.06092436974788
queue_len: 0.06841646915176329
wait_time: 0.6457632124467824
delay_time: 4.403409755922444
pressure: 0.8294650751547303
total_envstep_count: 819888
total_train_sample_count: 819888
total_episode_count: 7068
total_duration: 26923.17520070076
[2025-02-21 01:01:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.705155896897594
avg_train_sample_per_sec: 31.705155896897594
avg_episode_per_sec: 0.2733203094560137
collect_time: 21.95226550102234
reward_mean: -102.42075163398691
reward_std: 2.081844182793549
reward_max: -100.1554621848739
reward_min: -105.34243697478986
queue_len: 0.06791827031431492
wait_time: 0.648268911897208
delay_time: 4.3243525704877515
pressure: 0.8281388152077808
total_envstep_count: 820584
total_train_sample_count: 820584
total_episode_count: 7074
total_duration: 26945.127466201782
[2025-02-21 01:01:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.654250621100832
avg_train_sample_per_sec: 31.654250621100832
avg_episode_per_sec: 0.2728814708715589
collect_time: 21.987568378448486
reward_mean: -101.56676003734826
reward_std: 2.9071035753214622
reward_max: -98.74299719887955
reward_min: -106.88305322128852
queue_len: 0.06735196288948825
wait_time: 0.6407984834075098
delay_time: 4.2980076923863
pressure: 0.8219496021220158
total_envstep_count: 821280
total_train_sample_count: 821280
total_episode_count: 7080
total_duration: 26967.11503458023
[2025-02-21 01:01:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16329552972881
avg_train_sample_per_sec: 32.16329552972881
avg_episode_per_sec: 0.2772697890493863
collect_time: 21.639573574066162
reward_mean: -102.60690943043886
reward_std: 2.698255655825828
reward_max: -98.67016806722695
reward_min: -106.43837535014005
queue_len: 0.06804171712893824
wait_time: 0.6440117382054501
delay_time: 4.349510204311255
pressure: 0.8285809018567639
total_envstep_count: 821976
total_train_sample_count: 821976
total_episode_count: 7086
total_duration: 26988.754608154297
[2025-02-21 01:02:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.597406325309734
avg_train_sample_per_sec: 31.597406325309734
avg_episode_per_sec: 0.27239143383887704
collect_time: 22.027124404907227
reward_mean: -104.98412698412697
reward_std: 2.2782082655980873
reward_max: -102.45518207282907
reward_min: -109.766106442577
queue_len: 0.06961812134225927
wait_time: 0.6587315518603551
delay_time: 4.464715398624814
pressure: 0.8480327144120249
total_envstep_count: 822672
total_train_sample_count: 822672
total_episode_count: 7092
total_duration: 27010.781732559204
[2025-02-21 01:02:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95732746028629
avg_train_sample_per_sec: 31.95732746028629
avg_episode_per_sec: 0.27549420224384735
collect_time: 21.779042720794678
reward_mean: -102.41549953314659
reward_std: 2.7750978940136575
reward_max: -98.66876750700278
reward_min: -105.70378151260503
queue_len: 0.067914787488824
wait_time: 0.6446293592591767
delay_time: 4.337895880049892
pressure: 0.8257073386383732
total_envstep_count: 823368
total_train_sample_count: 823368
total_episode_count: 7098
total_duration: 27032.56077528
[2025-02-21 01:03:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.528461277020824
avg_train_sample_per_sec: 31.528461277020824
avg_episode_per_sec: 0.27179707997431746
collect_time: 22.075292348861694
reward_mean: -101.36204481792718
reward_std: 2.9050842273226216
reward_max: -97.87745098039215
reward_min: -107.14705882352943
queue_len: 0.06721621009146365
wait_time: 0.6367001265581387
delay_time: 4.3540689852312395
pressure: 0.8207338638373121
total_envstep_count: 824064
total_train_sample_count: 824064
total_episode_count: 7104
total_duration: 27054.63606762886
[2025-02-21 01:03:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.703788571757606
avg_train_sample_per_sec: 31.703788571757606
avg_episode_per_sec: 0.2733085221703242
collect_time: 21.95321226119995
reward_mean: -102.68288982259571
reward_std: 1.9983887973351218
reward_max: -98.57282913165268
reward_min: -104.69887955182071
queue_len: 0.06809210200437381
wait_time: 0.6535208579453001
delay_time: 4.313233934480538
pressure: 0.8312334217506631
total_envstep_count: 824760
total_train_sample_count: 824760
total_episode_count: 7110
total_duration: 27076.58927989006
[2025-02-21 01:03:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.745358178797353
avg_train_sample_per_sec: 31.745358178797353
avg_episode_per_sec: 0.2736668808517013
collect_time: 21.92446517944336
reward_mean: -103.76867413632118
reward_std: 2.100907665691501
reward_max: -100.35574229691876
reward_min: -107.0497198879552
queue_len: 0.06881211812753395
wait_time: 0.6587810079823265
delay_time: 4.39561046815067
pressure: 0.8443854995579132
total_envstep_count: 825456
total_train_sample_count: 825456
total_episode_count: 7116
total_duration: 27098.513745069504
[2025-02-21 01:04:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61170180072318
avg_train_sample_per_sec: 31.61170180072318
avg_episode_per_sec: 0.27251467069588947
collect_time: 22.017163276672363
reward_mean: -105.23926237161528
reward_std: 3.5621931326845933
reward_max: -100.33963585434171
reward_min: -109.50280112044814
queue_len: 0.06978730926499689
wait_time: 0.6627979441113315
delay_time: 4.445256928346175
pressure: 0.8558797524314765
total_envstep_count: 826152
total_train_sample_count: 826152
total_episode_count: 7122
total_duration: 27120.530908346176
[2025-02-21 01:04:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.904833300370946
avg_train_sample_per_sec: 31.904833300370946
avg_episode_per_sec: 0.27504166638250815
collect_time: 21.814876556396484
reward_mean: -102.30625583566761
reward_std: 3.0536878296647956
reward_max: -97.5686274509804
reward_min: -108.03921568627452
queue_len: 0.06784234471861246
wait_time: 0.6441606483442183
delay_time: 4.361912727111279
pressure: 0.8233863837312113
total_envstep_count: 826848
total_train_sample_count: 826848
total_episode_count: 7128
total_duration: 27142.345784902573
[2025-02-21 01:04:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01776968944348
avg_train_sample_per_sec: 32.01776968944348
avg_episode_per_sec: 0.2760152559434783
collect_time: 21.737928867340088
reward_mean: -103.16339869281046
reward_std: 4.4295501819854906
reward_max: -96.44747899159665
reward_min: -108.94117647058827
queue_len: 0.06841074183873373
wait_time: 0.6507495350040989
delay_time: 4.290658334258469
pressure: 0.8405172413793104
total_envstep_count: 827544
total_train_sample_count: 827544
total_episode_count: 7134
total_duration: 27164.083713769913
[2025-02-21 01:05:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.269444648171568
avg_train_sample_per_sec: 31.269444648171568
avg_episode_per_sec: 0.269564178001479
collect_time: 22.258150339126587
reward_mean: -103.39985994397757
reward_std: 3.031022714478962
reward_max: -99.3102240896359
reward_min: -109.3809523809524
queue_len: 0.068567546381948
wait_time: 0.6492284690180227
delay_time: 4.365739020287968
pressure: 0.8368700265251988
total_envstep_count: 828240
total_train_sample_count: 828240
total_episode_count: 7140
total_duration: 27186.34186410904
[2025-02-21 01:05:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68124695659654
avg_train_sample_per_sec: 31.68124695659654
avg_episode_per_sec: 0.2731141979016943
collect_time: 21.96883225440979
reward_mean: -105.14904295051353
reward_std: 2.4288157946738482
reward_max: -102.04551820728288
reward_min: -108.76400560224091
queue_len: 0.06972748206267476
wait_time: 0.6661254355853746
delay_time: 4.4098574405322895
pressure: 0.856211317418214
total_envstep_count: 828936
total_train_sample_count: 828936
total_episode_count: 7146
total_duration: 27208.31069636345
[2025-02-21 01:06:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.960335333753108
avg_train_sample_per_sec: 31.960335333753108
avg_episode_per_sec: 0.2755201321875268
collect_time: 21.77699303627014
reward_mean: -103.47117180205417
reward_std: 1.8351787053488258
reward_max: -101.28781512605042
reward_min: -106.61274509803924
queue_len: 0.06861483541250277
wait_time: 0.6512609685784129
delay_time: 4.331361925120169
pressure: 0.8381962864721486
total_envstep_count: 829632
total_train_sample_count: 829632
total_episode_count: 7152
total_duration: 27230.08768939972
[2025-02-21 01:06:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.858266056866377
avg_train_sample_per_sec: 31.858266056866377
avg_episode_per_sec: 0.2746402246281584
collect_time: 21.846763372421265
reward_mean: -104.26038748832862
reward_std: 3.0784808456740924
reward_max: -99.44117647058818
reward_min: -109.71008403361341
queue_len: 0.06913818798960784
wait_time: 0.6591802945758322
delay_time: 4.471029667476196
pressure: 0.841180371352785
total_envstep_count: 830328
total_train_sample_count: 830328
total_episode_count: 7158
total_duration: 27251.93445277214
[2025-02-21 01:06:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.981658580236317
avg_train_sample_per_sec: 31.981658580236317
avg_episode_per_sec: 0.27570395327789926
collect_time: 21.762473583221436
reward_mean: -103.13982259570497
reward_std: 1.8370176335507193
reward_max: -99.73039215686275
reward_min: -105.31022408963587
queue_len: 0.06839510782208551
wait_time: 0.6470789465211371
delay_time: 4.3889559692262825
pressure: 0.8396330680813439
total_envstep_count: 831024
total_train_sample_count: 831024
total_episode_count: 7164
total_duration: 27273.696926355362
[2025-02-21 01:07:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94199250805715
avg_train_sample_per_sec: 31.94199250805715
avg_episode_per_sec: 0.275362004379803
collect_time: 21.789498567581177
reward_mean: -102.32317927170868
reward_std: 2.1182694289289645
reward_max: -98.99509803921566
reward_min: -105.10294117647057
queue_len: 0.06785356715630549
wait_time: 0.6445291312811597
delay_time: 4.363444414473873
pressure: 0.8336648983200706
total_envstep_count: 831720
total_train_sample_count: 831720
total_episode_count: 7170
total_duration: 27295.486424922943
[2025-02-21 01:07:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.924998078803895
avg_train_sample_per_sec: 31.924998078803895
avg_episode_per_sec: 0.2752155006793439
collect_time: 21.801097631454468
reward_mean: -103.45786647992531
reward_std: 2.565147284217884
reward_max: -99.6232492997199
reward_min: -107.54481792717084
queue_len: 0.06860601225459237
wait_time: 0.6506591363335784
delay_time: 4.392050210879246
pressure: 0.8378647214854111
total_envstep_count: 832416
total_train_sample_count: 832416
total_episode_count: 7176
total_duration: 27317.287522554398
[2025-02-21 01:07:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.647639528673174
avg_train_sample_per_sec: 31.647639528673174
avg_episode_per_sec: 0.2728244786954584
collect_time: 21.992161512374878
reward_mean: -103.95529878618112
reward_std: 1.5600957634061803
reward_max: -101.6785714285714
reward_min: -106.12815126050423
queue_len: 0.06893587452664532
wait_time: 0.6564617557898491
delay_time: 4.423157952781466
pressure: 0.84736958443855
total_envstep_count: 833112
total_train_sample_count: 833112
total_episode_count: 7182
total_duration: 27339.279684066772
[2025-02-21 01:08:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.671483663552696
avg_train_sample_per_sec: 31.671483663552696
avg_episode_per_sec: 0.27303003158235084
collect_time: 21.97560453414917
reward_mean: -104.16106442577029
reward_std: 3.4941733301305886
reward_max: -99.42016806722685
reward_min: -108.30322128851539
queue_len: 0.0690723238897681
wait_time: 0.6503634057513369
delay_time: 4.4146838174102685
pressure: 0.8457117595048631
total_envstep_count: 833808
total_train_sample_count: 833808
total_episode_count: 7188
total_duration: 27361.25528860092
[2025-02-21 01:08:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.712893094752705
avg_train_sample_per_sec: 31.712893094752705
avg_episode_per_sec: 0.2733870094375233
collect_time: 21.9469096660614
reward_mean: -103.81314192343605
reward_std: 2.128255198394186
reward_max: -99.77521008403366
reward_min: -106.80392156862747
queue_len: 0.0688416060500239
wait_time: 0.6519717745630526
delay_time: 4.4242597216328
pressure: 0.8394120247568524
total_envstep_count: 834504
total_train_sample_count: 834504
total_episode_count: 7194
total_duration: 27383.202198266983
[2025-02-21 01:09:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.699215380143254
avg_train_sample_per_sec: 31.699215380143254
avg_episode_per_sec: 0.27326909810468325
collect_time: 21.956379413604736
reward_mean: -106.3516573295985
reward_std: 4.887768444109703
reward_max: -100.09803921568628
reward_min: -112.61274509803921
queue_len: 0.07052497170397777
wait_time: 0.665302637412171
delay_time: 4.518115238384609
pressure: 0.8601900972590628
total_envstep_count: 835200
total_train_sample_count: 835200
total_episode_count: 7200
total_duration: 27405.158577680588
[2025-02-21 01:09:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.50267814284566
avg_train_sample_per_sec: 31.50267814284566
avg_episode_per_sec: 0.2715748115762557
collect_time: 22.09335970878601
reward_mean: -105.36414565826333
reward_std: 1.997605534257089
reward_max: -101.32563025210086
reward_min: -107.27801120448176
queue_len: 0.06987012311555922
wait_time: 0.6655421010137035
delay_time: 4.439078203379204
pressure: 0.857316534040672
total_envstep_count: 835896
total_train_sample_count: 835896
total_episode_count: 7206
total_duration: 27427.251937389374
[2025-02-21 01:09:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.765356031633523
avg_train_sample_per_sec: 31.765356031633523
avg_episode_per_sec: 0.2738392761347717
collect_time: 21.91066265106201
reward_mean: -103.67121848739494
reward_std: 4.573830053583797
reward_max: -98.77380952380955
reward_min: -112.37815126050417
queue_len: 0.06874749236564652
wait_time: 0.6518897346737104
delay_time: 4.386879353214652
pressure: 0.8368700265251988
total_envstep_count: 836592
total_train_sample_count: 836592
total_episode_count: 7212
total_duration: 27449.162600040436
[2025-02-21 01:10:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.58787031476152
avg_train_sample_per_sec: 31.58787031476152
avg_episode_per_sec: 0.2723092268513924
collect_time: 22.03377413749695
reward_mean: -105.12686741363211
reward_std: 0.8978780320108046
reward_max: -104.08123249299722
reward_min: -106.70098039215688
queue_len: 0.0697127767994908
wait_time: 0.6674583515988183
delay_time: 4.466438885119471
pressure: 0.8425066312997348
total_envstep_count: 837288
total_train_sample_count: 837288
total_episode_count: 7218
total_duration: 27471.196374177933
[2025-02-21 01:10:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.354294993597914
avg_train_sample_per_sec: 31.354294993597914
avg_episode_per_sec: 0.27029564649653376
collect_time: 22.19791579246521
reward_mean: -102.79470121381887
reward_std: 2.6198084988223522
reward_max: -100.40406162464986
reward_min: -107.5861344537815
queue_len: 0.06816624748926982
wait_time: 0.640235813600418
delay_time: 4.462409611708664
pressure: 0.825154730327144
total_envstep_count: 837984
total_train_sample_count: 837984
total_episode_count: 7224
total_duration: 27493.394289970398
[2025-02-21 01:10:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.86383138099319
avg_train_sample_per_sec: 30.86383138099319
avg_episode_per_sec: 0.2660675119051137
collect_time: 22.55066752433777
reward_mean: -103.968954248366
reward_std: 1.2727069534847866
reward_max: -101.8984593837535
reward_min: -105.17086834733894
queue_len: 0.06894492987292176
wait_time: 0.6604757508662173
delay_time: 4.42870162457201
pressure: 0.8421750663129974
total_envstep_count: 838680
total_train_sample_count: 838680
total_episode_count: 7230
total_duration: 27515.944957494736
[2025-02-21 01:11:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.773310078758144
avg_train_sample_per_sec: 31.773310078758144
avg_episode_per_sec: 0.27390784550653574
collect_time: 21.9051775932312
reward_mean: -101.83916900093372
reward_std: 0.6903750551718416
reward_max: -101.17577030812323
reward_min: -103.00280112044821
queue_len: 0.06753260543828497
wait_time: 0.6330295380751769
delay_time: 4.30723000029356
pressure: 0.8267020335985853
total_envstep_count: 839376
total_train_sample_count: 839376
total_episode_count: 7236
total_duration: 27537.850135087967
[2025-02-21 01:11:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.809614672273977
avg_train_sample_per_sec: 31.809614672273977
avg_episode_per_sec: 0.2742208161402929
collect_time: 21.88017702102661
reward_mean: -104.11169467787117
reward_std: 4.811535958955356
reward_max: -100.27941176470586
reward_min: -114.60014005602247
queue_len: 0.06903958533015331
wait_time: 0.6508478280790654
delay_time: 4.44722837572082
pressure: 0.8450486295313882
total_envstep_count: 840072
total_train_sample_count: 840072
total_episode_count: 7242
total_duration: 27559.730312108994
[2025-02-21 01:12:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8976779719749
avg_train_sample_per_sec: 31.8976779719749
avg_episode_per_sec: 0.274979982517025
collect_time: 21.819770097732544
reward_mean: -103.91188141923438
reward_std: 3.0210905782012167
reward_max: -101.03641456582635
reward_min: -108.59033613445379
queue_len: 0.06890708316925356
wait_time: 0.6551830944579423
delay_time: 4.404704038585684
pressure: 0.8438328912466844
total_envstep_count: 840768
total_train_sample_count: 840768
total_episode_count: 7248
total_duration: 27581.550082206726
[2025-02-21 01:12:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.745213188605113
avg_train_sample_per_sec: 31.745213188605113
avg_episode_per_sec: 0.27366563093625096
collect_time: 21.924565315246582
reward_mean: -102.19035947712416
reward_std: 1.7217212413715635
reward_max: -99.4824929971989
reward_min: -105.34383753501396
queue_len: 0.06776549036944574
wait_time: 0.6406303790304805
delay_time: 4.361907761554463
pressure: 0.8274756852343059
total_envstep_count: 841464
total_train_sample_count: 841464
total_episode_count: 7254
total_duration: 27603.474647521973
[2025-02-21 01:12:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99276335845704
avg_train_sample_per_sec: 31.99276335845704
avg_episode_per_sec: 0.2757996841246297
collect_time: 21.75491976737976
reward_mean: -103.64297385620915
reward_std: 2.7388477243789016
reward_max: -99.95588235294119
reward_min: -108.79061624649859
queue_len: 0.06872876250411747
wait_time: 0.6530929347866469
delay_time: 4.286982065379417
pressure: 0.8520114942528737
total_envstep_count: 842160
total_train_sample_count: 842160
total_episode_count: 7260
total_duration: 27625.229567289352
[2025-02-21 01:13:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.736426839127272
avg_train_sample_per_sec: 31.736426839127272
avg_episode_per_sec: 0.27358988654420063
collect_time: 21.93063521385193
reward_mean: -102.65511204481794
reward_std: 3.2240100028515677
reward_max: -95.70168067226892
reward_min: -105.6855742296919
queue_len: 0.06807368172733284
wait_time: 0.6483584592103863
delay_time: 4.376862075379842
pressure: 0.8336648983200706
total_envstep_count: 842856
total_train_sample_count: 842856
total_episode_count: 7266
total_duration: 27647.160202503204
[2025-02-21 01:13:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30754760518841
avg_train_sample_per_sec: 31.30754760518841
avg_episode_per_sec: 0.2698926517688656
collect_time: 22.23106098175049
reward_mean: -103.84208683473388
reward_std: 2.6372318675535276
reward_max: -100.87675070028006
reward_min: -109.21078431372544
queue_len: 0.06886080028828506
wait_time: 0.6507858337853266
delay_time: 4.362992471548225
pressure: 0.8358753315649868
total_envstep_count: 843552
total_train_sample_count: 843552
total_episode_count: 7272
total_duration: 27669.391263484955
[2025-02-21 01:13:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.561565124904302
avg_train_sample_per_sec: 31.561565124904302
avg_episode_per_sec: 0.27208245797331293
collect_time: 22.052138328552246
reward_mean: -102.89542483660131
reward_std: 1.9535779299284508
reward_max: -100.30532212885154
reward_min: -105.54621848739492
queue_len: 0.0682330403425738
wait_time: 0.6462981744421907
delay_time: 4.331706019861466
pressure: 0.8408488063660476
total_envstep_count: 844248
total_train_sample_count: 844248
total_episode_count: 7278
total_duration: 27691.443401813507
[2025-02-21 01:14:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.539427293247215
avg_train_sample_per_sec: 31.539427293247215
avg_episode_per_sec: 0.27189161459695876
collect_time: 22.067616939544678
reward_mean: -103.2469654528478
reward_std: 1.7594034217870693
reward_max: -100.34523809523806
reward_min: -106.17857142857147
queue_len: 0.06846615746210066
wait_time: 0.6449162666835082
delay_time: 4.44572337822821
pressure: 0.8352122015915121
total_envstep_count: 844944
total_train_sample_count: 844944
total_episode_count: 7284
total_duration: 27713.51101875305
[2025-02-21 01:14:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.530607008847063
avg_train_sample_per_sec: 31.530607008847063
avg_episode_per_sec: 0.27181557766247466
collect_time: 22.073790073394775
reward_mean: -103.67612044817928
reward_std: 0.9931231022167543
reward_max: -102.05742296918768
reward_min: -105.0861344537815
queue_len: 0.06875074300277141
wait_time: 0.6513859633154765
delay_time: 4.39968335122061
pressure: 0.8339964633068081
total_envstep_count: 845640
total_train_sample_count: 845640
total_episode_count: 7290
total_duration: 27735.584808826447
[2025-02-21 01:15:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79242180144631
avg_train_sample_per_sec: 31.79242180144631
avg_episode_per_sec: 0.27407260173660614
collect_time: 21.892009496688843
reward_mean: -104.68860877684408
reward_std: 3.810552650404799
reward_max: -100.13095238095238
reward_min: -111.67296918767511
queue_len: 0.06942215436130243
wait_time: 0.6584016895883021
delay_time: 4.417929948789063
pressure: 0.8520114942528735
total_envstep_count: 846336
total_train_sample_count: 846336
total_episode_count: 7296
total_duration: 27757.476818323135
[2025-02-21 01:15:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.56037325156912
avg_train_sample_per_sec: 31.56037325156912
avg_episode_per_sec: 0.27207218320318205
collect_time: 22.052971124649048
reward_mean: -104.32749766573296
reward_std: 2.233820552455211
reward_max: -101.98949579831935
reward_min: -108.3515406162465
queue_len: 0.06918269075976986
wait_time: 0.6566488996128955
delay_time: 4.405572976116234
pressure: 0.8421750663129974
total_envstep_count: 847032
total_train_sample_count: 847032
total_episode_count: 7302
total_duration: 27779.529789447784
[2025-02-21 01:15:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.793696364447335
avg_train_sample_per_sec: 31.793696364447335
avg_episode_per_sec: 0.27408358934868393
collect_time: 21.89113187789917
reward_mean: -102.6205648926237
reward_std: 1.8611694778508279
reward_max: -99.22829131652658
reward_min: -105.06652661064425
queue_len: 0.06805077247521467
wait_time: 0.6403699410798801
delay_time: 4.397677301624305
pressure: 0.8274756852343059
total_envstep_count: 847728
total_train_sample_count: 847728
total_episode_count: 7308
total_duration: 27801.420921325684
[2025-02-21 01:16:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7630071584711
avg_train_sample_per_sec: 31.7630071584711
avg_episode_per_sec: 0.2738190272281992
collect_time: 21.912282943725586
reward_mean: -101.30765639589168
reward_std: 2.561802606547123
reward_max: -97.83053221288516
reward_min: -105.36414565826333
queue_len: 0.06718014349860192
wait_time: 0.6341668740882737
delay_time: 4.294010486819807
pressure: 0.8237179487179488
total_envstep_count: 848424
total_train_sample_count: 848424
total_episode_count: 7314
total_duration: 27823.33320426941
[2025-02-21 01:16:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.643989426362232
avg_train_sample_per_sec: 31.643989426362232
avg_episode_per_sec: 0.27279301229622616
collect_time: 21.99469828605652
reward_mean: -104.61227824463118
reward_std: 3.0432509308387754
reward_max: -99.83963585434174
reward_min: -108.0203081232493
queue_len: 0.06937153729750078
wait_time: 0.6610500300916121
delay_time: 4.3939918609043
pressure: 0.8377541998231653
total_envstep_count: 849120
total_train_sample_count: 849120
total_episode_count: 7320
total_duration: 27845.327902555466
[2025-02-21 01:16:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.493643619761396
avg_train_sample_per_sec: 31.493643619761396
avg_episode_per_sec: 0.27149692775656376
collect_time: 22.099697589874268
reward_mean: -102.57504668534081
reward_std: 2.5926644460272645
reward_max: -98.53151260504202
reward_min: -107.3970588235294
queue_len: 0.06802058798762652
wait_time: 0.6415044908325841
delay_time: 4.407623681018497
pressure: 0.8232758620689654
total_envstep_count: 849816
total_train_sample_count: 849816
total_episode_count: 7326
total_duration: 27867.42760014534
[2025-02-21 01:17:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92379500707303
avg_train_sample_per_sec: 31.92379500707303
avg_episode_per_sec: 0.2752051293713192
collect_time: 21.80191922187805
reward_mean: -103.15592903828197
reward_std: 2.919669674543158
reward_max: -97.6127450980392
reward_min: -106.47128851540614
queue_len: 0.06840578848692437
wait_time: 0.6469359184876428
delay_time: 4.332795090853861
pressure: 0.8435013262599469
total_envstep_count: 850512
total_train_sample_count: 850512
total_episode_count: 7332
total_duration: 27889.229519367218
[2025-02-21 01:17:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83217278134003
avg_train_sample_per_sec: 31.83217278134003
avg_episode_per_sec: 0.2744152825977589
collect_time: 21.86467146873474
reward_mean: -102.0794817927171
reward_std: 2.9783987729253205
reward_max: -99.4355742296919
reward_min: -108.46778711484598
queue_len: 0.06769196405352591
wait_time: 0.639052581686963
delay_time: 4.345112666886809
pressure: 0.8215075154730327
total_envstep_count: 851208
total_train_sample_count: 851208
total_episode_count: 7338
total_duration: 27911.094190835953
[2025-02-21 01:18:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.851862798442273
avg_train_sample_per_sec: 31.851862798442273
avg_episode_per_sec: 0.27458502412450236
collect_time: 21.851155281066895
reward_mean: -103.29703548085901
reward_std: 3.2878458372212163
reward_max: -96.49579831932772
reward_min: -107.25350140056022
queue_len: 0.06849936039844762
wait_time: 0.6513597260301115
delay_time: 4.3902290782445865
pressure: 0.8327807250221043
total_envstep_count: 851904
total_train_sample_count: 851904
total_episode_count: 7344
total_duration: 27932.94534611702
[2025-02-21 01:18:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.758533301933472
avg_train_sample_per_sec: 31.758533301933472
avg_episode_per_sec: 0.2737804594994265
collect_time: 21.915369749069214
reward_mean: -104.6441409897292
reward_std: 4.255105251851978
reward_max: -97.83683473389357
reward_min: -110.36064425770304
queue_len: 0.06939266643881248
wait_time: 0.656516784432606
delay_time: 4.424938232850823
pressure: 0.8425066312997348
total_envstep_count: 852600
total_train_sample_count: 852600
total_episode_count: 7350
total_duration: 27954.86071586609
[2025-02-21 01:18:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.393185129309483
avg_train_sample_per_sec: 31.393185129309483
avg_episode_per_sec: 0.2706309062871507
collect_time: 22.170416831970215
reward_mean: -102.46650326797385
reward_std: 3.1186757969028647
reward_max: -97.21358543417364
reward_min: -106.45518207282915
queue_len: 0.06794860959414713
wait_time: 0.6439382118895304
delay_time: 4.3834914065376305
pressure: 0.829686118479222
total_envstep_count: 853296
total_train_sample_count: 853296
total_episode_count: 7356
total_duration: 27977.03113269806
[2025-02-21 01:19:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.712002559872186
avg_train_sample_per_sec: 31.712002559872186
avg_episode_per_sec: 0.27337933241269124
collect_time: 21.94752597808838
reward_mean: -103.26622315592903
reward_std: 2.068461122498902
reward_max: -100.76540616246498
reward_min: -106.58263305322126
queue_len: 0.0684789278222341
wait_time: 0.6481998745563654
delay_time: 4.4038221549876635
pressure: 0.8417329796640142
total_envstep_count: 853992
total_train_sample_count: 853992
total_episode_count: 7362
total_duration: 27998.978658676147
[2025-02-21 01:19:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78708885863921
avg_train_sample_per_sec: 31.78708885863921
avg_episode_per_sec: 0.2740266280917173
collect_time: 21.895682334899902
reward_mean: -103.1141456582633
reward_std: 3.8799482255927447
reward_max: -98.04201680672269
reward_min: -108.86484593837535
queue_len: 0.06837808067524093
wait_time: 0.644845991004713
delay_time: 4.31949580052602
pressure: 0.8352122015915121
total_envstep_count: 854688
total_train_sample_count: 854688
total_episode_count: 7368
total_duration: 28020.874341011047
[2025-02-21 01:19:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.588450359331556
avg_train_sample_per_sec: 31.588450359331556
avg_episode_per_sec: 0.2723142272356169
collect_time: 22.033369541168213
reward_mean: -105.17401960784314
reward_std: 3.6718004607539902
reward_max: -100.39775910364143
reward_min: -112.6190476190476
queue_len: 0.06974404483278723
wait_time: 0.664509172369213
delay_time: 4.4574867157101385
pressure: 0.8548850574712644
total_envstep_count: 855384
total_train_sample_count: 855384
total_episode_count: 7374
total_duration: 28042.907710552216
[2025-02-21 01:20:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.114820569208234
avg_train_sample_per_sec: 32.114820569208234
avg_episode_per_sec: 0.27685190145869165
collect_time: 21.672236919403076
reward_mean: -104.75571895424837
reward_std: 3.3907962532676463
reward_max: -99.44887955182071
reward_min: -108.41176470588233
queue_len: 0.06946665713146442
wait_time: 0.6534138191085451
delay_time: 4.49814016186414
pressure: 0.8488063660477453
total_envstep_count: 856080
total_train_sample_count: 856080
total_episode_count: 7380
total_duration: 28064.57994747162
[2025-02-21 01:20:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78921420529327
avg_train_sample_per_sec: 31.78921420529327
avg_episode_per_sec: 0.2740449500456316
collect_time: 21.89421844482422
reward_mean: -101.18090569561156
reward_std: 2.261404886858252
reward_max: -98.06722689075629
reward_min: -104.15196078431372
queue_len: 0.06709609131008723
wait_time: 0.6349743478293174
delay_time: 4.335752397261895
pressure: 0.8192970822281166
total_envstep_count: 856776
total_train_sample_count: 856776
total_episode_count: 7386
total_duration: 28086.474165916443
[2025-02-21 01:21:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.486849816395463
avg_train_sample_per_sec: 31.486849816395463
avg_episode_per_sec: 0.27143836048616776
collect_time: 22.1044659614563
reward_mean: -103.44747899159664
reward_std: 2.5723846676232536
reward_max: -99.7843137254902
reward_min: -107.38865546218489
queue_len: 0.06859912399973253
wait_time: 0.6485668869669884
delay_time: 4.421993713025885
pressure: 0.8343280282935455
total_envstep_count: 857472
total_train_sample_count: 857472
total_episode_count: 7392
total_duration: 28108.5786318779
[2025-02-21 01:21:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.814431273841187
avg_train_sample_per_sec: 31.814431273841187
avg_episode_per_sec: 0.27426233856759646
collect_time: 21.876864433288574
reward_mean: -102.44747899159661
reward_std: 1.390314002594987
reward_max: -100.47549019607835
reward_min: -104.33683473389355
queue_len: 0.0679359940262577
wait_time: 0.638778057642155
delay_time: 4.3476286901929955
pressure: 0.8311229000884174
total_envstep_count: 858168
total_train_sample_count: 858168
total_episode_count: 7398
total_duration: 28130.455496311188
[2025-02-21 01:21:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.846586329635446
avg_train_sample_per_sec: 31.846586329635446
avg_episode_per_sec: 0.27453953732444347
collect_time: 21.85477566719055
reward_mean: -104.0500700280112
reward_std: 2.6689574006189014
reward_max: -98.63795518207283
reward_min: -107.0693277310925
queue_len: 0.06899872017772625
wait_time: 0.6551990380590786
delay_time: 4.393857049013289
pressure: 0.8352122015915119
total_envstep_count: 858864
total_train_sample_count: 858864
total_episode_count: 7404
total_duration: 28152.31027197838
[2025-02-21 01:22:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16317504577016
avg_train_sample_per_sec: 32.16317504577016
avg_episode_per_sec: 0.27726875039457033
collect_time: 21.639654636383057
reward_mean: -105.05415499533144
reward_std: 4.484841011280645
reward_max: -100.06512605042018
reward_min: -112.50700280112041
queue_len: 0.06966455901547179
wait_time: 0.6627930681556441
delay_time: 4.425434601503965
pressure: 0.8502431476569408
total_envstep_count: 859560
total_train_sample_count: 859560
total_episode_count: 7410
total_duration: 28173.94992661476
[2025-02-21 01:22:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.719473923421287
avg_train_sample_per_sec: 31.719473923421287
avg_episode_per_sec: 0.273443740719149
collect_time: 21.94235634803772
reward_mean: -105.11683006535947
reward_std: 3.4384037657224704
reward_max: -100.08333333333336
reward_min: -109.76960784313728
queue_len: 0.06970612073299699
wait_time: 0.6595639471526896
delay_time: 4.448708315739879
pressure: 0.8521220159151195
total_envstep_count: 860256
total_train_sample_count: 860256
total_episode_count: 7416
total_duration: 28195.8922829628
[2025-02-21 01:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.475793057507165
avg_train_sample_per_sec: 31.475793057507165
avg_episode_per_sec: 0.2713430435991997
collect_time: 22.11223077774048
reward_mean: -101.96311858076562
reward_std: 2.2021594147196097
reward_max: -99.91596638655463
reward_min: -106.06792717086833
queue_len: 0.0676148001198711
wait_time: 0.634713832482595
delay_time: 4.384586824570131
pressure: 0.8184129089301502
total_envstep_count: 860952
total_train_sample_count: 860952
total_episode_count: 7422
total_duration: 28218.00451374054
[2025-02-21 01:23:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.312777497758766
avg_train_sample_per_sec: 32.312777497758766
avg_episode_per_sec: 0.27855842670481695
collect_time: 21.539466857910156
reward_mean: -101.59278711484593
reward_std: 1.8740569020131803
reward_max: -98.40686274509807
reward_min: -103.30252100840337
queue_len: 0.06736922222469892
wait_time: 0.6362489071667571
delay_time: 4.32599068623315
pressure: 0.8238284703801945
total_envstep_count: 861648
total_train_sample_count: 861648
total_episode_count: 7428
total_duration: 28239.54398059845
[2025-02-21 01:23:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.861074138403488
avg_train_sample_per_sec: 31.861074138403488
avg_episode_per_sec: 0.2746644322276163
collect_time: 21.84483790397644
reward_mean: -101.33590102707751
reward_std: 3.0505071570356814
reward_max: -98.55532212885154
reward_min: -107.6015406162465
queue_len: 0.06719887336013096
wait_time: 0.6364895317101199
delay_time: 4.363162075258066
pressure: 0.8196286472148541
total_envstep_count: 862344
total_train_sample_count: 862344
total_episode_count: 7434
total_duration: 28261.388818502426
[2025-02-21 01:24:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57539101651704
avg_train_sample_per_sec: 31.57539101651704
avg_episode_per_sec: 0.27220164669411245
collect_time: 22.042482376098633
reward_mean: -103.05847338935575
reward_std: 1.3703975896303218
reward_max: -101.24369747899159
reward_min: -105.25280112044817
queue_len: 0.06834116272503697
wait_time: 0.6433675702818705
delay_time: 4.439153816040529
pressure: 0.8343280282935456
total_envstep_count: 863040
total_train_sample_count: 863040
total_episode_count: 7440
total_duration: 28283.431300878525
[2025-02-21 01:24:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54588927558091
avg_train_sample_per_sec: 31.54588927558091
avg_episode_per_sec: 0.27194732134121474
collect_time: 22.063096523284912
reward_mean: -102.70191409897292
reward_std: 3.775808794168281
reward_max: -98.19957983193278
reward_min: -106.78851540616246
queue_len: 0.0681047175722632
wait_time: 0.645623667238779
delay_time: 4.354961303640649
pressure: 0.8280282935455349
total_envstep_count: 863736
total_train_sample_count: 863736
total_episode_count: 7446
total_duration: 28305.49439740181
[2025-02-21 01:24:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.809640767049384
avg_train_sample_per_sec: 30.809640767049384
avg_episode_per_sec: 0.26560035144008093
collect_time: 22.590331554412842
reward_mean: -102.7483660130719
reward_std: 3.3886226276020452
reward_max: -99.21778711484598
reward_min: -109.28011204481794
queue_len: 0.06813552122882753
wait_time: 0.6376853791914643
delay_time: 4.439401835971774
pressure: 0.8292440318302389
total_envstep_count: 864432
total_train_sample_count: 864432
total_episode_count: 7452
total_duration: 28328.084728956223
[2025-02-21 01:25:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.611836331300957
avg_train_sample_per_sec: 31.611836331300957
avg_episode_per_sec: 0.27251583044224964
collect_time: 22.017069578170776
reward_mean: -103.58660130718955
reward_std: 2.104310651744273
reward_max: -99.69187675070029
reward_min: -105.9089635854342
queue_len: 0.06869138017718139
wait_time: 0.6551680796102702
delay_time: 4.447306535929791
pressure: 0.8386383731211318
total_envstep_count: 865128
total_train_sample_count: 865128
total_episode_count: 7458
total_duration: 28350.101798534393
[2025-02-21 01:25:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.515634865721733
avg_train_sample_per_sec: 31.515634865721733
avg_episode_per_sec: 0.2716865074631184
collect_time: 22.08427667617798
reward_mean: -105.41795051353876
reward_std: 3.426991606275264
reward_max: -101.327731092437
reward_min: -112.17787114845942
queue_len: 0.06990580272781084
wait_time: 0.6651425048357099
delay_time: 4.506004805289579
pressure: 0.8523430592396112
total_envstep_count: 865824
total_train_sample_count: 865824
total_episode_count: 7464
total_duration: 28372.18607521057
[2025-02-21 01:25:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89381804237034
avg_train_sample_per_sec: 31.89381804237034
avg_episode_per_sec: 0.2749467072618133
collect_time: 21.822410821914673
reward_mean: -103.31279178338002
reward_std: 2.1562285219371127
reward_max: -100.43347338935575
reward_min: -105.83893557422965
queue_len: 0.06850980887492043
wait_time: 0.6489380787682005
delay_time: 4.4273227584760715
pressure: 0.8384173297966403
total_envstep_count: 866520
total_train_sample_count: 866520
total_episode_count: 7470
total_duration: 28394.008486032486
[2025-02-21 01:26:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92729659589521
avg_train_sample_per_sec: 31.92729659589521
avg_episode_per_sec: 0.27523531548185526
collect_time: 21.799528121948242
reward_mean: -102.69187675070027
reward_std: 4.222191824246734
reward_max: -97.74369747899158
reward_min: -110.10504201680673
queue_len: 0.06809806150576943
wait_time: 0.6434852123873421
delay_time: 4.319344839923349
pressure: 0.8338859416445624
total_envstep_count: 867216
total_train_sample_count: 867216
total_episode_count: 7476
total_duration: 28415.808014154434
[2025-02-21 01:26:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07957501366953
avg_train_sample_per_sec: 32.07957501366953
avg_episode_per_sec: 0.2765480604626684
collect_time: 21.69604802131653
reward_mean: -102.04341736694676
reward_std: 1.7174071477854072
reward_max: -100.41946778711483
reward_min: -105.37114845938376
queue_len: 0.06766804865182147
wait_time: 0.6394171948178033
delay_time: 4.372544782578054
pressure: 0.8229442970822282
total_envstep_count: 867912
total_train_sample_count: 867912
total_episode_count: 7482
total_duration: 28437.50406217575
[2025-02-21 01:27:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.454692444804703
avg_train_sample_per_sec: 31.454692444804703
avg_episode_per_sec: 0.2711611417655578
collect_time: 22.12706422805786
reward_mean: -103.87138188608776
reward_std: 2.695212541984797
reward_max: -99.38235294117645
reward_min: -106.77100840336134
queue_len: 0.0688802267149123
wait_time: 0.6545541735704007
delay_time: 4.377089842424276
pressure: 0.8351016799292661
total_envstep_count: 868608
total_train_sample_count: 868608
total_episode_count: 7488
total_duration: 28459.63112640381
[2025-02-21 01:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74318139395537
avg_train_sample_per_sec: 31.74318139395537
avg_episode_per_sec: 0.2736481154651325
collect_time: 21.925968647003174
reward_mean: -103.2686741363212
reward_std: 2.5847945947496713
reward_max: -99.14005602240898
reward_min: -105.91526610644259
queue_len: 0.06848055314079655
wait_time: 0.6516165263629766
delay_time: 4.395729431364161
pressure: 0.8388594164456232
total_envstep_count: 869304
total_train_sample_count: 869304
total_episode_count: 7494
total_duration: 28481.55709505081
[2025-02-21 01:27:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8439933870632
avg_train_sample_per_sec: 31.8439933870632
avg_episode_per_sec: 0.27451718437123446
collect_time: 21.856555223464966
reward_mean: -101.59372082166199
reward_std: 2.790382968688557
reward_max: -96.98319327731092
reward_min: -104.64425770308122
queue_len: 0.06736984139367506
wait_time: 0.6332916013443398
delay_time: 4.331440169424023
pressure: 0.8185234305923962
total_envstep_count: 870000
total_train_sample_count: 870000
total_episode_count: 7500
total_duration: 28503.413650274277
[2025-02-21 01:28:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.52336867448777
avg_train_sample_per_sec: 31.52336867448777
avg_episode_per_sec: 0.27175317822834283
collect_time: 22.078858613967896
reward_mean: -103.63702147525674
reward_std: 2.985508636545671
reward_max: -100.14705882352939
reward_min: -109.68137254901958
queue_len: 0.0687248153018944
wait_time: 0.6489959710674721
delay_time: 4.468386633069653
pressure: 0.8356542882404953
total_envstep_count: 870696
total_train_sample_count: 870696
total_episode_count: 7506
total_duration: 28525.492508888245
[2025-02-21 01:28:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.789067083380917
avg_train_sample_per_sec: 31.789067083380917
avg_episode_per_sec: 0.27404368175328375
collect_time: 21.894319772720337
reward_mean: -102.21475256769376
reward_std: 2.8992882900268637
reward_max: -98.6106442577031
reward_min: -107.58403361344538
queue_len: 0.0677816661589481
wait_time: 0.6400017677274269
delay_time: 4.379762451741971
pressure: 0.8297966401414678
total_envstep_count: 871392
total_train_sample_count: 871392
total_episode_count: 7512
total_duration: 28547.386828660965
[2025-02-21 01:28:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.787392758874027
avg_train_sample_per_sec: 31.787392758874027
avg_episode_per_sec: 0.2740292479213278
collect_time: 21.89547300338745
reward_mean: -102.63235294117646
reward_std: 2.3536060707451765
reward_max: -100.17507002801118
reward_min: -106.90966386554625
queue_len: 0.06805858948353878
wait_time: 0.6447997855198667
delay_time: 4.402850282989313
pressure: 0.8383068081343943
total_envstep_count: 872088
total_train_sample_count: 872088
total_episode_count: 7518
total_duration: 28569.282301664352
[2025-02-21 01:29:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.590550250963368
avg_train_sample_per_sec: 31.590550250963368
avg_episode_per_sec: 0.2723323297496842
collect_time: 22.031904935836792
reward_mean: -101.72549019607847
reward_std: 3.060728906692379
reward_max: -97.52240896358549
reward_min: -105.27661064425773
queue_len: 0.06745722161543664
wait_time: 0.6362246821805645
delay_time: 4.3282603725582
pressure: 0.8274756852343059
total_envstep_count: 872784
total_train_sample_count: 872784
total_episode_count: 7524
total_duration: 28591.31420660019
[2025-02-21 01:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.595883787963466
avg_train_sample_per_sec: 31.595883787963466
avg_episode_per_sec: 0.2723783085169264
collect_time: 22.028185844421387
reward_mean: -104.96218487394957
reward_std: 4.9525460844978015
reward_max: -97.78011204481794
reward_min: -110.69117647058823
queue_len: 0.06960357087131934
wait_time: 0.6580864551833111
delay_time: 4.454529691364804
pressure: 0.8509062776304156
total_envstep_count: 873480
total_train_sample_count: 873480
total_episode_count: 7530
total_duration: 28613.34239244461
[2025-02-21 01:30:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91805565517374
avg_train_sample_per_sec: 31.91805565517374
avg_episode_per_sec: 0.2751556521997736
collect_time: 21.80583953857422
reward_mean: -103.64880952380952
reward_std: 3.4143119665499766
reward_max: -99.29691876750702
reward_min: -108.05392156862743
queue_len: 0.06873263231021852
wait_time: 0.6446483213090719
delay_time: 4.453299476363495
pressure: 0.8333333333333335
total_envstep_count: 874176
total_train_sample_count: 874176
total_episode_count: 7536
total_duration: 28635.148231983185
[2025-02-21 01:30:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.453761110475767
avg_train_sample_per_sec: 31.453761110475767
avg_episode_per_sec: 0.2711531130213428
collect_time: 22.127719402313232
reward_mean: -101.88422035480859
reward_std: 2.340359172014808
reward_max: -99.70868347338937
reward_min: -106.46498599439776
queue_len: 0.067562480341385
wait_time: 0.6375189001329975
delay_time: 4.380940567442887
pressure: 0.8188549955791334
total_envstep_count: 874872
total_train_sample_count: 874872
total_episode_count: 7542
total_duration: 28657.275951385498
[2025-02-21 01:30:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.819616626471348
avg_train_sample_per_sec: 31.819616626471348
avg_episode_per_sec: 0.2743070398833737
collect_time: 21.87329936027527
reward_mean: -103.17413632119514
reward_std: 3.8959238996844174
reward_max: -98.51260504201683
reward_min: -110.70308123249302
queue_len: 0.06841786228195965
wait_time: 0.6442023648539875
delay_time: 4.35118707066676
pressure: 0.8405172413793104
total_envstep_count: 875568
total_train_sample_count: 875568
total_episode_count: 7548
total_duration: 28679.149250745773
[2025-02-21 01:31:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865733460622973
avg_train_sample_per_sec: 31.865733460622973
avg_episode_per_sec: 0.2747045987984739
collect_time: 21.841643810272217
reward_mean: -102.2670401493931
reward_std: 3.1160772902441174
reward_max: -98.5077030812325
reward_min: -107.00070028011203
queue_len: 0.06781633962161347
wait_time: 0.639876231217509
delay_time: 4.38239252075271
pressure: 0.8255968169761273
total_envstep_count: 876264
total_train_sample_count: 876264
total_episode_count: 7554
total_duration: 28700.990894556046
[2025-02-21 01:31:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.834977306186545
avg_train_sample_per_sec: 31.834977306186545
avg_episode_per_sec: 0.2744394595360909
collect_time: 21.86274528503418
reward_mean: -103.55345471521942
reward_std: 3.5098487172892994
reward_max: -97.68417366946778
reward_min: -109.50630252100837
queue_len: 0.06866939967852746
wait_time: 0.6461774364918381
delay_time: 4.442716901641958
pressure: 0.8366489832007074
total_envstep_count: 876960
total_train_sample_count: 876960
total_episode_count: 7560
total_duration: 28722.85363984108
[2025-02-21 01:31:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.717355823900807
avg_train_sample_per_sec: 31.717355823900807
avg_episode_per_sec: 0.2734254812405242
collect_time: 21.943821668624878
reward_mean: -101.29738562091505
reward_std: 4.39559572567592
reward_max: -96.24929971988796
reward_min: -110.125350140056
queue_len: 0.06717333263986408
wait_time: 0.6372747153680217
delay_time: 4.294328622178609
pressure: 0.8218390804597702
total_envstep_count: 877656
total_train_sample_count: 877656
total_episode_count: 7566
total_duration: 28744.797461509705
[2025-02-21 01:32:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.845449259828143
avg_train_sample_per_sec: 31.845449259828143
avg_episode_per_sec: 0.27452973499851846
collect_time: 21.85555601119995
reward_mean: -103.26528944911298
reward_std: 2.63484926231238
reward_max: -99.1827731092437
reward_min: -108.02450980392159
queue_len: 0.06847830865325795
wait_time: 0.645037855991203
delay_time: 4.359864728910481
pressure: 0.8345490716180372
total_envstep_count: 878352
total_train_sample_count: 878352
total_episode_count: 7572
total_duration: 28766.653017520905
[2025-02-21 01:32:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.908177621276977
avg_train_sample_per_sec: 31.908177621276977
avg_episode_per_sec: 0.27507049673514633
collect_time: 21.8125901222229
reward_mean: -101.67588702147525
reward_std: 2.6460634054562244
reward_max: -98.33893557422964
reward_min: -105.57983193277312
queue_len: 0.06742432826357775
wait_time: 0.6331570094881455
delay_time: 4.290798791820139
pressure: 0.8317860300618922
total_envstep_count: 879048
total_train_sample_count: 879048
total_episode_count: 7578
total_duration: 28788.465607643127
[2025-02-21 01:33:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.996071081180666
avg_train_sample_per_sec: 31.996071081180666
avg_episode_per_sec: 0.2758281989756954
collect_time: 21.752670764923096
reward_mean: -102.36216153127917
reward_std: 2.9053632600207946
reward_max: -97.51470588235293
reward_min: -107.1547619047619
queue_len: 0.06787941746106047
wait_time: 0.6460703976550831
delay_time: 4.3384532781909
pressure: 0.8294650751547303
total_envstep_count: 879744
total_train_sample_count: 879744
total_episode_count: 7584
total_duration: 28810.21827840805
[2025-02-21 01:33:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.786803654592894
avg_train_sample_per_sec: 31.786803654592894
avg_episode_per_sec: 0.27402416943614566
collect_time: 21.895878791809082
reward_mean: -102.37196545284782
reward_std: 3.399435287998843
reward_max: -97.66106442577033
reward_min: -106.20658263305324
queue_len: 0.06788591873531023
wait_time: 0.6402446367583284
delay_time: 4.336153751779943
pressure: 0.8400751547303272
total_envstep_count: 880440
total_train_sample_count: 880440
total_episode_count: 7590
total_duration: 28832.11415719986
[2025-02-21 01:33:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.843908630258362
avg_train_sample_per_sec: 31.843908630258362
avg_episode_per_sec: 0.2745164537091238
collect_time: 21.856613397598267
reward_mean: -102.89367413632118
reward_std: 2.6749795710878934
reward_max: -98.46988795518209
reward_min: -106.9817927170868
queue_len: 0.06823187940074349
wait_time: 0.6415914840737356
delay_time: 4.361150392165909
pressure: 0.8367595048629531
total_envstep_count: 881136
total_train_sample_count: 881136
total_episode_count: 7596
total_duration: 28853.970770597458
[2025-02-21 01:34:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03848223469597
avg_train_sample_per_sec: 32.03848223469597
avg_episode_per_sec: 0.27619381236806867
collect_time: 21.723875522613525
reward_mean: -105.55205415499535
reward_std: 2.6442193032029246
reward_max: -103.00350140056025
reward_min: -110.39705882352942
queue_len: 0.06999473087201283
wait_time: 0.662825884111381
delay_time: 4.460901223629366
pressure: 0.8515694076038903
total_envstep_count: 881832
total_train_sample_count: 881832
total_episode_count: 7602
total_duration: 28875.69464612007
[2025-02-21 01:34:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.626521765400135
avg_train_sample_per_sec: 31.626521765400135
avg_episode_per_sec: 0.27264242901207014
collect_time: 22.0068461894989
reward_mean: -103.50548552754434
reward_std: 3.546076889345991
reward_max: -100.48949579831933
reward_min: -111.12394957983189
queue_len: 0.06863758987237688
wait_time: 0.6477823224780629
delay_time: 4.433946642487027
pressure: 0.834106984969054
total_envstep_count: 882528
total_train_sample_count: 882528
total_episode_count: 7608
total_duration: 28897.70149230957
[2025-02-21 01:34:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.981134428176464
avg_train_sample_per_sec: 31.981134428176464
avg_episode_per_sec: 0.27569943472565916
collect_time: 21.76283025741577
reward_mean: -102.66923436041083
reward_std: 3.8755937597455126
reward_max: -98.83823529411767
reward_min: -109.88165266106444
queue_len: 0.06808304665809738
wait_time: 0.6384088007439935
delay_time: 4.398519814198843
pressure: 0.83289124668435
total_envstep_count: 883224
total_train_sample_count: 883224
total_episode_count: 7614
total_duration: 28919.464322566986
[2025-02-21 01:35:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.591322868030772
avg_train_sample_per_sec: 31.591322868030772
avg_episode_per_sec: 0.2723389902416446
collect_time: 22.031366109848022
reward_mean: -101.83064892623713
reward_std: 1.2389996617833101
reward_max: -99.32843137254902
reward_min: -103.15126050420166
queue_len: 0.06752695552137743
wait_time: 0.6358039568612591
delay_time: 4.400949039153506
pressure: 0.8168656056587092
total_envstep_count: 883920
total_train_sample_count: 883920
total_episode_count: 7620
total_duration: 28941.495688676834
[2025-02-21 01:35:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.744227290420515
avg_train_sample_per_sec: 31.744227290420515
avg_episode_per_sec: 0.27365713181396994
collect_time: 21.925246238708496
reward_mean: -99.2093837535014
reward_std: 1.6498230371780287
reward_max: -96.92507002801116
reward_min: -101.30672268907564
queue_len: 0.06578871601691073
wait_time: 0.6182117409297937
delay_time: 4.339090035483085
pressure: 0.8072502210433244
total_envstep_count: 884616
total_train_sample_count: 884616
total_episode_count: 7626
total_duration: 28963.420934915543
[2025-02-21 01:35:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1460960147872
avg_train_sample_per_sec: 32.1460960147872
avg_episode_per_sec: 0.27712151736885515
collect_time: 21.651151657104492
reward_mean: -100.35866013071895
reward_std: 3.009203605764492
reward_max: -96.24159663865545
reward_min: -105.96148459383755
queue_len: 0.06655083563045024
wait_time: 0.629068868926881
delay_time: 4.303968564282812
pressure: 0.818081343943413
total_envstep_count: 885312
total_train_sample_count: 885312
total_episode_count: 7632
total_duration: 28985.072086572647
[2025-02-21 01:36:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.741293431937457
avg_train_sample_per_sec: 31.741293431937457
avg_episode_per_sec: 0.27363183993049534
collect_time: 21.92727279663086
reward_mean: -99.6111111111111
reward_std: 3.034970827997537
reward_max: -96.1379551820728
reward_min: -103.72829131652662
queue_len: 0.06605511346890658
wait_time: 0.6209559752282877
delay_time: 4.293839249932128
pressure: 0.8089080459770116
total_envstep_count: 886008
total_train_sample_count: 886008
total_episode_count: 7638
total_duration: 29006.999359369278
[2025-02-21 01:36:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.687957059043033
avg_train_sample_per_sec: 31.687957059043033
avg_episode_per_sec: 0.27317204361243996
collect_time: 21.96418023109436
reward_mean: -103.10539215686272
reward_std: 2.887986475741541
reward_max: -99.99789915966389
reward_min: -108.55952380952381
queue_len: 0.06837227596608936
wait_time: 0.6486985377705458
delay_time: 4.412115589454909
pressure: 0.834106984969054
total_envstep_count: 886704
total_train_sample_count: 886704
total_episode_count: 7644
total_duration: 29028.963539600372
[2025-02-21 01:37:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.645080252178904
avg_train_sample_per_sec: 31.645080252178904
avg_episode_per_sec: 0.2728024159670595
collect_time: 21.993940114974976
reward_mean: -102.87605042016806
reward_std: 3.970723122349631
reward_max: -97.968487394958
reward_min: -110.58053221288513
queue_len: 0.06822019258631834
wait_time: 0.6456347348842276
delay_time: 4.380996530459319
pressure: 0.8439434129089302
total_envstep_count: 887400
total_train_sample_count: 887400
total_episode_count: 7650
total_duration: 29050.957479715347
[2025-02-21 01:37:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.901200328135122
avg_train_sample_per_sec: 31.901200328135122
avg_episode_per_sec: 0.27501034765633725
collect_time: 21.817360877990723
reward_mean: -102.82843137254905
reward_std: 2.6532216483158266
reward_max: -97.78011204481797
reward_min: -105.91246498599442
queue_len: 0.06818861496853383
wait_time: 0.6407594757620113
delay_time: 4.437049484096758
pressure: 0.8352122015915119
total_envstep_count: 888096
total_train_sample_count: 888096
total_episode_count: 7656
total_duration: 29072.774840593338
[2025-02-21 01:37:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.744039852420723
avg_train_sample_per_sec: 31.744039852420723
avg_episode_per_sec: 0.27365551596914417
collect_time: 21.92537569999695
reward_mean: -102.80030345471523
reward_std: 1.6934697668048388
reward_max: -101.2836134453782
reward_min: -106.35084033613447
queue_len: 0.0681699625031268
wait_time: 0.6415157906663992
delay_time: 4.405132890654797
pressure: 0.8352122015915119
total_envstep_count: 888792
total_train_sample_count: 888792
total_episode_count: 7662
total_duration: 29094.700216293335
[2025-02-21 01:38:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77259769622741
avg_train_sample_per_sec: 31.77259769622741
avg_episode_per_sec: 0.2739017042778225
collect_time: 21.90566873550415
reward_mean: -103.9724556489262
reward_std: 1.9763735888331484
reward_max: -101.28571428571429
reward_min: -107.64985994397755
queue_len: 0.06894725175658235
wait_time: 0.6519835387735997
delay_time: 4.377739214011993
pressure: 0.8427276746242264
total_envstep_count: 889488
total_train_sample_count: 889488
total_episode_count: 7668
total_duration: 29116.60588502884
[2025-02-21 01:38:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.896385420978653
avg_train_sample_per_sec: 30.896385420978653
avg_episode_per_sec: 0.26634815018085045
collect_time: 22.526906967163086
reward_mean: -102.09348739495799
reward_std: 3.6314581129700905
reward_max: -97.24439775910363
reward_min: -108.7780112044818
queue_len: 0.06770125158816843
wait_time: 0.6355854676087942
delay_time: 4.373248383608074
pressure: 0.8260389036251105
total_envstep_count: 890184
total_train_sample_count: 890184
total_episode_count: 7674
total_duration: 29139.132791996002
[2025-02-21 01:38:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.660346322571744
avg_train_sample_per_sec: 31.660346322571744
avg_episode_per_sec: 0.2729340200221702
collect_time: 21.98333501815796
reward_mean: -100.38036881419232
reward_std: 1.9681798064011842
reward_max: -97.52661064425767
reward_min: -103.08193277310924
queue_len: 0.06656523130914611
wait_time: 0.63021433153279
delay_time: 4.293520438601644
pressure: 0.8188549955791337
total_envstep_count: 890880
total_train_sample_count: 890880
total_episode_count: 7680
total_duration: 29161.11612701416
[2025-02-21 01:39:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.774378020757716
avg_train_sample_per_sec: 31.774378020757716
avg_episode_per_sec: 0.27391705190308374
collect_time: 21.904441356658936
reward_mean: -102.63316993464053
reward_std: 2.2130909964313488
reward_max: -98.95868347338939
reward_min: -105.45378151260505
queue_len: 0.06805913125639293
wait_time: 0.6392171258423794
delay_time: 4.372215117978418
pressure: 0.8293545534924845
total_envstep_count: 891576
total_train_sample_count: 891576
total_episode_count: 7686
total_duration: 29183.02056837082
[2025-02-21 01:39:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.121577412107456
avg_train_sample_per_sec: 32.121577412107456
avg_episode_per_sec: 0.2769101501043746
collect_time: 21.667678117752075
reward_mean: -102.7406629318394
reward_std: 3.2218513967140083
reward_max: -97.9593837535014
reward_min: -107.86414565826331
queue_len: 0.06813041308477415
wait_time: 0.6457604261863897
delay_time: 4.365234497183689
pressure: 0.8390804597701149
total_envstep_count: 892272
total_train_sample_count: 892272
total_episode_count: 7692
total_duration: 29204.68824648857
[2025-02-21 01:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.737544405058323
avg_train_sample_per_sec: 31.737544405058323
avg_episode_per_sec: 0.27359952073326144
collect_time: 21.92986297607422
reward_mean: -100.0673436041083
reward_std: 1.901565628890068
reward_max: -96.98529411764702
reward_min: -102.66246498599438
queue_len: 0.06635765490988613
wait_time: 0.6221789113523394
delay_time: 4.230634087142376
pressure: 0.8210654288240495
total_envstep_count: 892968
total_train_sample_count: 892968
total_episode_count: 7698
total_duration: 29226.618109464645
[2025-02-21 01:40:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.796032462926465
avg_train_sample_per_sec: 31.796032462926465
avg_episode_per_sec: 0.27410372812867645
collect_time: 21.88952350616455
reward_mean: -100.69957983193278
reward_std: 2.11171829714648
reward_max: -98.06792717086834
reward_min: -104.12535014005604
queue_len: 0.06677690970287319
wait_time: 0.6294971016700227
delay_time: 4.299517760819595
pressure: 0.8133289124668434
total_envstep_count: 893664
total_train_sample_count: 893664
total_episode_count: 7704
total_duration: 29248.50763297081
[2025-02-21 01:40:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02018940908948
avg_train_sample_per_sec: 32.02018940908948
avg_episode_per_sec: 0.276036115595599
collect_time: 21.736286163330078
reward_mean: -102.12266573295985
reward_std: 4.871160245080211
reward_max: -95.68837535014006
reward_min: -111.36904761904765
queue_len: 0.06772060061867365
wait_time: 0.6371343188026758
delay_time: 4.363886580241258
pressure: 0.833001768346596
total_envstep_count: 894360
total_train_sample_count: 894360
total_episode_count: 7710
total_duration: 29270.24391913414
[2025-02-21 01:41:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.631959314635942
avg_train_sample_per_sec: 31.631959314635942
avg_episode_per_sec: 0.27268930443651673
collect_time: 22.003063201904297
reward_mean: -100.66981792717087
reward_std: 3.134356668814917
reward_max: -95.8172268907563
reward_min: -105.4453781512605
queue_len: 0.06675717369175786
wait_time: 0.6270934877045424
delay_time: 4.290417125433071
pressure: 0.8158709106984969
total_envstep_count: 895056
total_train_sample_count: 895056
total_episode_count: 7716
total_duration: 29292.246982336044
[2025-02-21 01:41:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7637194566133
avg_train_sample_per_sec: 31.7637194566133
avg_episode_per_sec: 0.273825167729425
collect_time: 21.911791563034058
reward_mean: -102.15873015873018
reward_std: 3.6018149869416662
reward_max: -97.32422969187681
reward_min: -107.3186274509804
queue_len: 0.0677445160203781
wait_time: 0.6422949374267833
delay_time: 4.352564040642612
pressure: 0.826923076923077
total_envstep_count: 895752
total_train_sample_count: 895752
total_episode_count: 7722
total_duration: 29314.15877389908
[2025-02-21 01:41:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88946402299037
avg_train_sample_per_sec: 31.88946402299037
avg_episode_per_sec: 0.27490917261198594
collect_time: 21.825390338897705
reward_mean: -101.74346405228756
reward_std: 2.392187806161052
reward_max: -97.44187675070025
reward_min: -105.34453781512609
queue_len: 0.06746914061822784
wait_time: 0.639438091770749
delay_time: 4.340344187580849
pressure: 0.8222811671087533
total_envstep_count: 896448
total_train_sample_count: 896448
total_episode_count: 7728
total_duration: 29335.984164237976
[2025-02-21 01:42:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91801971001162
avg_train_sample_per_sec: 31.91801971001162
avg_episode_per_sec: 0.27515534232768635
collect_time: 21.805864095687866
reward_mean: -102.36181139122316
reward_std: 2.736812155242798
reward_max: -99.34453781512603
reward_min: -108.11834733893552
queue_len: 0.0678791852726944
wait_time: 0.6377148671139543
delay_time: 4.363277060072343
pressure: 0.837422634836428
total_envstep_count: 897144
total_train_sample_count: 897144
total_episode_count: 7734
total_duration: 29357.790028333664
[2025-02-21 01:42:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01323852784017
avg_train_sample_per_sec: 32.01323852784017
avg_episode_per_sec: 0.2759761942055187
collect_time: 21.741005659103394
reward_mean: -101.74311391223155
reward_std: 1.7481975302431536
reward_max: -99.27661064425767
reward_min: -105.02100840336136
queue_len: 0.06746890842986177
wait_time: 0.6410619398068689
delay_time: 4.351836001325845
pressure: 0.8202917771883289
total_envstep_count: 897840
total_train_sample_count: 897840
total_episode_count: 7740
total_duration: 29379.531033992767
[2025-02-21 01:43:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.757590452439192
avg_train_sample_per_sec: 31.757590452439192
avg_episode_per_sec: 0.2737723314865448
collect_time: 21.916020393371582
reward_mean: -102.49521475256769
reward_std: 3.1456980530742595
reward_max: -96.39285714285714
reward_min: -105.95098039215685
queue_len: 0.06796764904016425
wait_time: 0.6439122841886534
delay_time: 4.386285274270551
pressure: 0.8242705570291777
total_envstep_count: 898536
total_train_sample_count: 898536
total_episode_count: 7746
total_duration: 29401.44705438614
[2025-02-21 01:43:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96983255084384
avg_train_sample_per_sec: 31.96983255084384
avg_episode_per_sec: 0.27560200474865376
collect_time: 21.7705237865448
reward_mean: -102.27334267040152
reward_std: 4.4649305051768
reward_max: -97.61764705882352
reward_min: -108.58123249299722
queue_len: 0.06782051901220258
wait_time: 0.6396333621866076
delay_time: 4.3446026756108695
pressure: 0.8354332449160035
total_envstep_count: 899232
total_train_sample_count: 899232
total_episode_count: 7752
total_duration: 29423.217578172684
[2025-02-21 01:43:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.64646070057138
avg_train_sample_per_sec: 31.64646070057138
avg_episode_per_sec: 0.27281431638423603
collect_time: 21.99298071861267
reward_mean: -104.67798786181139
reward_std: 1.8573646264096728
reward_max: -102.39705882352943
reward_min: -108.14285714285708
queue_len: 0.06941511131419853
wait_time: 0.6516665242578022
delay_time: 4.458957094350584
pressure: 0.8458222811671088
total_envstep_count: 899928
total_train_sample_count: 899928
total_episode_count: 7758
total_duration: 29445.210558891296
[2025-02-21 01:44:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.874717900392763
avg_train_sample_per_sec: 31.874717900392763
avg_episode_per_sec: 0.2747820508654549
collect_time: 21.835487365722656
reward_mean: -104.07411297852472
reward_std: 2.2543672058415445
reward_max: -99.86484593837534
reward_min: -106.92156862745095
queue_len: 0.06901466377886255
wait_time: 0.6481831569940089
delay_time: 4.429543297941388
pressure: 0.8446065428824049
total_envstep_count: 900624
total_train_sample_count: 900624
total_episode_count: 7764
total_duration: 29467.04604625702
[2025-02-21 01:44:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.781738674202913
avg_train_sample_per_sec: 31.781738674202913
avg_episode_per_sec: 0.2739805058120941
collect_time: 21.899368286132812
reward_mean: -101.97537348272641
reward_std: 2.6551217003688907
reward_max: -97.74649859943979
reward_min: -104.92016806722685
queue_len: 0.0676229267126833
wait_time: 0.63534747453358
delay_time: 4.397360694330923
pressure: 0.8237179487179486
total_envstep_count: 901320
total_train_sample_count: 901320
total_episode_count: 7770
total_duration: 29488.945414543152
[2025-02-21 01:44:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85999896995408
avg_train_sample_per_sec: 31.85999896995408
avg_episode_per_sec: 0.2746551635340869
collect_time: 21.845575094223022
reward_mean: -103.22560690943044
reward_std: 2.24453666068849
reward_max: -99.92156862745101
reward_min: -105.19187675070029
queue_len: 0.06845199397177085
wait_time: 0.6468221461882718
delay_time: 4.43335838997358
pressure: 0.8393015030946066
total_envstep_count: 902016
total_train_sample_count: 902016
total_episode_count: 7776
total_duration: 29510.790989637375
[2025-02-21 01:45:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.702810409241998
avg_train_sample_per_sec: 31.702810409241998
avg_episode_per_sec: 0.2733000897348448
collect_time: 21.95388960838318
reward_mean: -102.41911764705883
reward_std: 2.1549722497345916
reward_max: -97.81232492997201
reward_min: -104.68907563025216
queue_len: 0.06791718676860665
wait_time: 0.6423454770944629
delay_time: 4.352454371630936
pressure: 0.8292440318302386
total_envstep_count: 902712
total_train_sample_count: 902712
total_episode_count: 7782
total_duration: 29532.744879245758
[2025-02-21 01:45:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.658592143127713
avg_train_sample_per_sec: 31.658592143127713
avg_episode_per_sec: 0.27291889778558376
collect_time: 21.98455309867859
reward_mean: -102.06722689075629
reward_std: 1.7200504242796395
reward_max: -100.17647058823529
reward_min: -105.4047619047619
queue_len: 0.06768383746071371
wait_time: 0.6374101585815583
delay_time: 4.300216332137938
pressure: 0.8325596816976127
total_envstep_count: 903408
total_train_sample_count: 903408
total_episode_count: 7788
total_duration: 29554.729432344437
[2025-02-21 01:46:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.164614533741954
avg_train_sample_per_sec: 32.164614533741954
avg_episode_per_sec: 0.27728115977363754
collect_time: 21.638686180114746
reward_mean: -103.46918767507003
reward_std: 2.7810469761736747
reward_max: -99.0798319327731
reward_min: -108.46428571428572
queue_len: 0.06861351967842841
wait_time: 0.6475263735025397
delay_time: 4.423787004711677
pressure: 0.8309018567639258
total_envstep_count: 904104
total_train_sample_count: 904104
total_episode_count: 7794
total_duration: 29576.36811852455
[2025-02-21 01:46:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.867581638204502
avg_train_sample_per_sec: 31.867581638204502
avg_episode_per_sec: 0.2747205313638319
collect_time: 21.84037709236145
reward_mean: -101.45389822595702
reward_std: 3.5041528029222597
reward_max: -97.57212885154063
reward_min: -107.51680672268907
queue_len: 0.06727712083949405
wait_time: 0.6391941391941393
delay_time: 4.325388311585745
pressure: 0.8225022104332448
total_envstep_count: 904800
total_train_sample_count: 904800
total_episode_count: 7800
total_duration: 29598.208495616913
[2025-02-21 01:46:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.836964968259668
avg_train_sample_per_sec: 31.836964968259668
avg_episode_per_sec: 0.27445659455396265
collect_time: 21.861380338668823
reward_mean: -102.02672735760969
reward_std: 2.2915777048163624
reward_max: -97.92997198879549
reward_min: -104.85714285714279
queue_len: 0.06765698100637248
wait_time: 0.6361345156984102
delay_time: 4.380924754157277
pressure: 0.8233863837312114
total_envstep_count: 905496
total_train_sample_count: 905496
total_episode_count: 7806
total_duration: 29620.06987595558
[2025-02-21 01:47:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.710820998920834
avg_train_sample_per_sec: 31.710820998920834
avg_episode_per_sec: 0.27336914654242095
collect_time: 21.948343753814697
reward_mean: -101.5406162464986
reward_std: 3.286596755964171
reward_max: -98.5266106442577
reward_min: -108.23179271708688
queue_len: 0.06733462615815557
wait_time: 0.6335568378545051
delay_time: 4.3230345079868435
pressure: 0.8231653404067196
total_envstep_count: 906192
total_train_sample_count: 906192
total_episode_count: 7812
total_duration: 29642.018219709396
[2025-02-21 01:47:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.646482656986002
avg_train_sample_per_sec: 31.646482656986002
avg_episode_per_sec: 0.27281450566367244
collect_time: 21.99296545982361
reward_mean: -102.34932306255833
reward_std: 3.38738252939911
reward_max: -97.3256302521008
reward_min: -107.99089635854341
queue_len: 0.06787090388763815
wait_time: 0.640661801856021
delay_time: 4.41061120563586
pressure: 0.8276967285587974
total_envstep_count: 906888
total_train_sample_count: 906888
total_episode_count: 7818
total_duration: 29664.01118516922
[2025-02-21 01:47:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.939181327754184
avg_train_sample_per_sec: 31.939181327754184
avg_episode_per_sec: 0.2753377700668464
collect_time: 21.79141640663147
reward_mean: -102.98646125116711
reward_std: 3.0241935524836627
reward_max: -100.57002801120443
reward_min: -109.45588235294116
queue_len: 0.06829340931775008
wait_time: 0.6449997770991686
delay_time: 4.385950516902704
pressure: 0.8267020335985853
total_envstep_count: 907584
total_train_sample_count: 907584
total_episode_count: 7824
total_duration: 29685.80260157585
[2025-02-21 01:48:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.710722137608585
avg_train_sample_per_sec: 31.710722137608585
avg_episode_per_sec: 0.27336829428972914
collect_time: 21.9484121799469
reward_mean: -104.68113912231559
reward_std: 3.247698532995937
reward_max: -99.40406162464981
reward_min: -108.54201680672267
queue_len: 0.06941720100949308
wait_time: 0.6577877835484327
delay_time: 4.482835347119637
pressure: 0.8406277630415562
total_envstep_count: 908280
total_train_sample_count: 908280
total_episode_count: 7830
total_duration: 29707.7510137558
[2025-02-21 01:48:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.627412302930754
avg_train_sample_per_sec: 31.627412302930754
avg_episode_per_sec: 0.2726501060597479
collect_time: 22.006226539611816
reward_mean: -102.42927170868347
reward_std: 2.030562341740887
reward_max: -98.77871148459387
reward_min: -104.91386554621849
queue_len: 0.06792392023122246
wait_time: 0.6416283246278175
delay_time: 4.407217746015234
pressure: 0.8246021220159151
total_envstep_count: 908976
total_train_sample_count: 908976
total_episode_count: 7836
total_duration: 29729.75724029541
[2025-02-21 01:49:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.846047835492776
avg_train_sample_per_sec: 31.846047835492776
avg_episode_per_sec: 0.2745348951335584
collect_time: 21.85514521598816
reward_mean: -103.10410830999065
reward_std: 3.0645278038883297
reward_max: -99.93347338935574
reward_min: -107.51750700280114
queue_len: 0.06837142460874712
wait_time: 0.6441126627485655
delay_time: 4.395167113778818
pressure: 0.8288019451812555
total_envstep_count: 909672
total_train_sample_count: 909672
total_episode_count: 7842
total_duration: 29751.6123855114
[2025-02-21 01:49:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26595345542629
avg_train_sample_per_sec: 32.26595345542629
avg_episode_per_sec: 0.27815477116746806
collect_time: 21.570724725723267
reward_mean: -101.2063492063492
reward_std: 2.0240568548473594
reward_max: -98.80812324929968
reward_min: -104.57282913165267
queue_len: 0.06711296366468779
wait_time: 0.6373424369747899
delay_time: 4.371981271140043
pressure: 0.8257073386383732
total_envstep_count: 910368
total_train_sample_count: 910368
total_episode_count: 7848
total_duration: 29773.18311023712
[2025-02-21 01:49:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69143118308928
avg_train_sample_per_sec: 31.69143118308928
avg_episode_per_sec: 0.27320199295766623
collect_time: 21.961772441864014
reward_mean: -101.32119514472457
reward_std: 2.511710882926704
reward_max: -97.1015406162465
reward_min: -105.21288515406162
queue_len: 0.06718912144875633
wait_time: 0.6325139251102742
delay_time: 4.351959869887247
pressure: 0.8276967285587976
total_envstep_count: 911064
total_train_sample_count: 911064
total_episode_count: 7854
total_duration: 29795.144882678986
[2025-02-21 01:50:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.820964477621665
avg_train_sample_per_sec: 31.820964477621665
avg_episode_per_sec: 0.27431865928984195
collect_time: 21.87237286567688
reward_mean: -99.99673202614379
reward_std: 1.9558118834955696
reward_max: -96.72338935574227
reward_min: -102.88025210084035
queue_len: 0.06631083025606353
wait_time: 0.6237707947900647
delay_time: 4.259537128396972
pressure: 0.8128868258178602
total_envstep_count: 911760
total_train_sample_count: 911760
total_episode_count: 7860
total_duration: 29817.017255544662
[2025-02-21 01:50:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.709751124937288
avg_train_sample_per_sec: 31.709751124937288
avg_episode_per_sec: 0.27335992349083865
collect_time: 21.949084281921387
reward_mean: -101.84080298786182
reward_std: 3.5255417686725283
reward_max: -98.28291316526607
reward_min: -107.87535014005604
queue_len: 0.06753368898399326
wait_time: 0.6385747380296064
delay_time: 4.358600166467257
pressure: 0.8282493368700266
total_envstep_count: 912456
total_train_sample_count: 912456
total_episode_count: 7866
total_duration: 29838.966339826584
[2025-02-21 01:50:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.637936709725036
avg_train_sample_per_sec: 31.637936709725036
avg_episode_per_sec: 0.2727408337045262
collect_time: 21.998906135559082
reward_mean: -102.97759103641455
reward_std: 2.666812646309594
reward_max: -100.11064425770307
reward_min: -106.90756302521007
queue_len: 0.06828752721247651
wait_time: 0.6444792881785782
delay_time: 4.4031474031084334
pressure: 0.8299071618037136
total_envstep_count: 913152
total_train_sample_count: 913152
total_episode_count: 7872
total_duration: 29860.965245962143
[2025-02-21 01:51:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92143660722392
avg_train_sample_per_sec: 31.92143660722392
avg_episode_per_sec: 0.27518479833813725
collect_time: 21.803529977798462
reward_mean: -101.8860877684407
reward_std: 2.2594454224360994
reward_max: -98.98179271708688
reward_min: -104.22338935574227
queue_len: 0.06756371867933733
wait_time: 0.6347795417901909
delay_time: 4.389353581373155
pressure: 0.82183908045977
total_envstep_count: 913848
total_train_sample_count: 913848
total_episode_count: 7878
total_duration: 29882.76877593994
[2025-02-21 01:51:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.755704230506183
avg_train_sample_per_sec: 31.755704230506183
avg_episode_per_sec: 0.2737560709526395
collect_time: 21.917322158813477
reward_mean: -101.01704014939308
reward_std: 2.8894110905611274
reward_max: -96.4705882352941
reward_min: -104.94607843137256
queue_len: 0.06698742715476995
wait_time: 0.6341333615674386
delay_time: 4.337059927033025
pressure: 0.8212864721485412
total_envstep_count: 914544
total_train_sample_count: 914544
total_episode_count: 7884
total_duration: 29904.686098098755
[2025-02-21 01:52:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04141044982214
avg_train_sample_per_sec: 32.04141044982214
avg_episode_per_sec: 0.27621905560191495
collect_time: 21.721890211105347
reward_mean: -100.60866013071897
reward_std: 4.355160500485494
reward_max: -94.75210084033617
reward_min: -107.5707282913165
queue_len: 0.06671661812381895
wait_time: 0.6316435283220273
delay_time: 4.279022786085403
pressure: 0.8187444739168878
total_envstep_count: 915240
total_train_sample_count: 915240
total_episode_count: 7890
total_duration: 29926.40798830986
[2025-02-21 01:52:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.783927691299684
avg_train_sample_per_sec: 30.783927691299684
avg_episode_per_sec: 0.2653786869939628
collect_time: 22.609200716018677
reward_mean: -102.65476190476188
reward_std: 3.894579748097506
reward_max: -98.63375350140055
reward_min: -108.94117647058823
queue_len: 0.06807344953896678
wait_time: 0.6444464722228413
delay_time: 4.398313689235363
pressure: 0.8303492484526968
total_envstep_count: 915936
total_train_sample_count: 915936
total_episode_count: 7896
total_duration: 29949.01718902588
[2025-02-21 01:52:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.959700263881082
avg_train_sample_per_sec: 31.959700263881082
avg_episode_per_sec: 0.27551465744725073
collect_time: 21.77742576599121
reward_mean: -100.42623716153128
reward_std: 1.9609514429017476
reward_max: -96.9467787114846
reward_min: -102.99789915966385
queue_len: 0.06659564798510033
wait_time: 0.6295496536368749
delay_time: 4.325950536593203
pressure: 0.8131078691423519
total_envstep_count: 916632
total_train_sample_count: 916632
total_episode_count: 7902
total_duration: 29970.79461479187
[2025-02-21 01:53:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.879373903368148
avg_train_sample_per_sec: 31.879373903368148
avg_episode_per_sec: 0.2748221888221392
collect_time: 21.832298278808594
reward_mean: -103.06967787114847
reward_std: 3.596362149402688
reward_max: -99.78011204481795
reward_min: -110.1974789915966
queue_len: 0.06834859275275097
wait_time: 0.6405169937117198
delay_time: 4.418613383990711
pressure: 0.8332228116710877
total_envstep_count: 917328
total_train_sample_count: 917328
total_episode_count: 7908
total_duration: 29992.62691307068
[2025-02-21 01:53:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.830625800444558
avg_train_sample_per_sec: 31.830625800444558
avg_episode_per_sec: 0.27440194655555655
collect_time: 21.865734100341797
reward_mean: -99.84208683473389
reward_std: 1.9419448813978246
reward_max: -95.80812324929974
reward_min: -101.69887955182071
queue_len: 0.06620828039438587
wait_time: 0.6156301932797875
delay_time: 4.342159064133903
pressure: 0.8122236958443856
total_envstep_count: 918024
total_train_sample_count: 918024
total_episode_count: 7914
total_duration: 30014.49264717102
[2025-02-21 01:53:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.741151930120562
avg_train_sample_per_sec: 31.741151930120562
avg_episode_per_sec: 0.2736306200872462
collect_time: 21.92737054824829
reward_mean: -103.24638188608778
reward_std: 4.946186722870963
reward_max: -96.77100840336134
reward_min: -111.98249299719892
queue_len: 0.06846577048149056
wait_time: 0.6394484628510998
delay_time: 4.447838491547402
pressure: 0.8352122015915118
total_envstep_count: 918720
total_train_sample_count: 918720
total_episode_count: 7920
total_duration: 30036.42001771927
[2025-02-21 01:54:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.817563159251065
avg_train_sample_per_sec: 31.817563159251065
avg_episode_per_sec: 0.27428933757975055
collect_time: 21.87471103668213
reward_mean: -101.57924836601308
reward_std: 1.8591744338113647
reward_max: -98.92156862745097
reward_min: -105.01330532212887
queue_len: 0.06736024427454447
wait_time: 0.635232773480745
delay_time: 4.3291727155285775
pressure: 0.8238284703801945
total_envstep_count: 919416
total_train_sample_count: 919416
total_episode_count: 7926
total_duration: 30058.29472875595
[2025-02-21 01:54:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73792672107334
avg_train_sample_per_sec: 31.73792672107334
avg_episode_per_sec: 0.27360281656097707
collect_time: 21.929598808288574
reward_mean: -105.3565592903828
reward_std: 4.162117333308929
reward_max: -98.14705882352939
reward_min: -111.01610644257704
queue_len: 0.06986509236762786
wait_time: 0.6558504812181284
delay_time: 4.481629744142544
pressure: 0.8477011494252874
total_envstep_count: 920112
total_train_sample_count: 920112
total_episode_count: 7932
total_duration: 30080.22432756424
[2025-02-21 01:55:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19241708654126
avg_train_sample_per_sec: 32.19241708654126
avg_episode_per_sec: 0.27752083695294194
collect_time: 21.61999821662903
reward_mean: -103.4184173669468
reward_std: 2.4395408224682025
reward_max: -100.344537815126
reward_min: -106.94607843137257
queue_len: 0.06857985236534933
wait_time: 0.6442363417515548
delay_time: 4.435004968389457
pressure: 0.8302387267904509
total_envstep_count: 920808
total_train_sample_count: 920808
total_episode_count: 7938
total_duration: 30101.84432578087
[2025-02-21 01:55:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.897512069185463
avg_train_sample_per_sec: 31.897512069185463
avg_episode_per_sec: 0.27497855232056434
collect_time: 21.819883584976196
reward_mean: -102.30578898225956
reward_std: 0.8241197803015817
reward_max: -100.9817927170868
reward_min: -103.41806722689076
queue_len: 0.06784203513412437
wait_time: 0.6380165571975916
delay_time: 4.416777261503545
pressure: 0.8278072502210433
total_envstep_count: 921504
total_train_sample_count: 921504
total_episode_count: 7944
total_duration: 30123.664209365845
[2025-02-21 01:55:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74791056825272
avg_train_sample_per_sec: 31.74791056825272
avg_episode_per_sec: 0.27368888420907517
collect_time: 21.92270255088806
reward_mean: -106.27731092436976
reward_std: 3.670417163058379
reward_max: -101.37955182072827
reward_min: -111.34593837535017
queue_len: 0.0704756703742505
wait_time: 0.6682867996889295
delay_time: 4.539754313707498
pressure: 0.8631741821396992
total_envstep_count: 922200
total_train_sample_count: 922200
total_episode_count: 7950
total_duration: 30145.586911916733
[2025-02-21 01:56:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98904373266037
avg_train_sample_per_sec: 31.98904373266037
avg_episode_per_sec: 0.2757676183850032
collect_time: 21.75744938850403
reward_mean: -102.59278711484596
reward_std: 2.7321697505907747
reward_max: -98.37394957983197
reward_min: -105.90966386554625
queue_len: 0.0680323521981737
wait_time: 0.6436492921660265
delay_time: 4.405503036966752
pressure: 0.8317860300618922
total_envstep_count: 922896
total_train_sample_count: 922896
total_episode_count: 7956
total_duration: 30167.344361305237
[2025-02-21 01:56:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.972190403813855
avg_train_sample_per_sec: 31.972190403813855
avg_episode_per_sec: 0.2756223310673608
collect_time: 21.76891827583313
reward_mean: -101.25840336134452
reward_std: 2.7316022172602716
reward_max: -95.56232492997198
reward_min: -103.64285714285711
queue_len: 0.0671474823351091
wait_time: 0.633945211594806
delay_time: 4.351785153893304
pressure: 0.816865605658709
total_envstep_count: 923592
total_train_sample_count: 923592
total_episode_count: 7962
total_duration: 30189.11327958107
[2025-02-21 01:56:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.986750336113182
avg_train_sample_per_sec: 31.986750336113182
avg_episode_per_sec: 0.2757478477251136
collect_time: 21.75900936126709
reward_mean: -103.60819327731095
reward_std: 2.263594839031857
reward_max: -101.57142857142858
reward_min: -108.44327731092434
queue_len: 0.06870569845975526
wait_time: 0.6463371046915671
delay_time: 4.395142933166256
pressure: 0.8349911582670204
total_envstep_count: 924288
total_train_sample_count: 924288
total_episode_count: 7968
total_duration: 30210.872288942337
[2025-02-21 01:57:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78745644713125
avg_train_sample_per_sec: 31.78745644713125
avg_episode_per_sec: 0.27402979695802804
collect_time: 21.895429134368896
reward_mean: -101.73529411764706
reward_std: 3.6330751780902375
reward_max: -97.00980392156858
reward_min: -105.83753501400558
queue_len: 0.06746372288968637
wait_time: 0.6388847868944217
delay_time: 4.389165703246712
pressure: 0.8183023872679045
total_envstep_count: 924984
total_train_sample_count: 924984
total_episode_count: 7974
total_duration: 30232.767718076706
[2025-02-21 01:57:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.912071028810242
avg_train_sample_per_sec: 31.912071028810242
avg_episode_per_sec: 0.27510406059319176
collect_time: 21.80992889404297
reward_mean: -102.20343137254902
reward_std: 1.7213630028387952
reward_max: -99.70308123249299
reward_min: -104.70868347338933
queue_len: 0.06777415873511208
wait_time: 0.6401978121045058
delay_time: 4.371747187711673
pressure: 0.8232758620689656
total_envstep_count: 925680
total_train_sample_count: 925680
total_episode_count: 7980
total_duration: 30254.57764697075
[2025-02-21 01:58:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01825957412658
avg_train_sample_per_sec: 32.01825957412658
avg_episode_per_sec: 0.2760194790872981
collect_time: 21.73759627342224
reward_mean: -101.54049953314656
reward_std: 3.0255250698580096
reward_max: -97.20868347338934
reward_min: -106.49789915966387
queue_len: 0.06733454876203353
wait_time: 0.6374871677229689
delay_time: 4.373056078792126
pressure: 0.8190760389036251
total_envstep_count: 926376
total_train_sample_count: 926376
total_episode_count: 7986
total_duration: 30276.31524324417
[2025-02-21 01:58:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.796167528034736
avg_train_sample_per_sec: 31.796167528034736
avg_episode_per_sec: 0.2741048924830581
collect_time: 21.8894305229187
reward_mean: -104.3719654528478
reward_std: 3.363798644492497
reward_max: -100.11344537815125
reward_min: -108.37114845938376
queue_len: 0.0692121786822598
wait_time: 0.6587895989518707
delay_time: 4.477947500312147
pressure: 0.8486958443854995
total_envstep_count: 927072
total_train_sample_count: 927072
total_episode_count: 7992
total_duration: 30298.20467376709
[2025-02-21 01:58:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.088152410343955
avg_train_sample_per_sec: 31.088152410343955
avg_episode_per_sec: 0.2680013138822755
collect_time: 22.38794994354248
reward_mean: -105.91900093370681
reward_std: 2.6126329703161195
reward_max: -101.27450980392156
reward_min: -108.8340336134454
queue_len: 0.07023806427964643
wait_time: 0.6607286813929817
delay_time: 4.548451277827303
pressure: 0.8473695844385499
total_envstep_count: 927768
total_train_sample_count: 927768
total_episode_count: 7998
total_duration: 30320.592623710632
[2025-02-21 01:59:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.66952829131558
avg_train_sample_per_sec: 31.66952829131558
avg_episode_per_sec: 0.27301317492513427
collect_time: 21.976961374282837
reward_mean: -102.64449112978525
reward_std: 1.8800437729910708
reward_max: -100.5224089635854
reward_min: -105.27731092436971
queue_len: 0.06806663868022894
wait_time: 0.6389529728779222
delay_time: 4.403327445923938
pressure: 0.8252652519893898
total_envstep_count: 928464
total_train_sample_count: 928464
total_episode_count: 8004
total_duration: 30342.569585084915
[2025-02-21 01:59:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.747713419259487
avg_train_sample_per_sec: 31.747713419259487
avg_episode_per_sec: 0.27368718464878866
collect_time: 21.92283868789673
reward_mean: -103.81851073762836
reward_std: 2.973353742746718
reward_max: -100.73039215686272
reward_min: -108.65756302521005
queue_len: 0.06884516627163685
wait_time: 0.6547238258698704
delay_time: 4.390018282350745
pressure: 0.838527851458886
total_envstep_count: 929160
total_train_sample_count: 929160
total_episode_count: 8010
total_duration: 30364.492423772812
[2025-02-21 01:59:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.856643534069573
avg_train_sample_per_sec: 31.856643534069573
avg_episode_per_sec: 0.2746262373626687
collect_time: 21.84787607192993
reward_mean: -100.88562091503267
reward_std: 2.416060217756852
reward_max: -97.75490196078434
reward_min: -104.5490196078431
queue_len: 0.06690027912137446
wait_time: 0.6277565402818951
delay_time: 4.371979406200708
pressure: 0.8155393457117595
total_envstep_count: 929856
total_train_sample_count: 929856
total_episode_count: 8016
total_duration: 30386.340299844742
[2025-02-21 02:00:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.830531743857147
avg_train_sample_per_sec: 31.830531743857147
avg_episode_per_sec: 0.2744011357229064
collect_time: 21.865798711776733
reward_mean: -104.19782913165267
reward_std: 3.6273839878867054
reward_max: -98.93627450980391
reward_min: -109.16386554621853
queue_len: 0.06909670366820468
wait_time: 0.6520638759482572
delay_time: 4.431718066701785
pressure: 0.8431697612732094
total_envstep_count: 930552
total_train_sample_count: 930552
total_episode_count: 8022
total_duration: 30408.20609855652
[2025-02-21 02:00:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.883518667314874
avg_train_sample_per_sec: 31.883518667314874
avg_episode_per_sec: 0.27485791954581784
collect_time: 21.82946014404297
reward_mean: -104.17787114845936
reward_std: 2.4536032384748836
reward_max: -101.22829131652661
reward_min: -108.29971988795516
queue_len: 0.0690834689313391
wait_time: 0.648335085581536
delay_time: 4.436262716908581
pressure: 0.8440539345711761
total_envstep_count: 931248
total_train_sample_count: 931248
total_episode_count: 8028
total_duration: 30430.03555870056
[2025-02-21 02:01:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.671336942127816
avg_train_sample_per_sec: 31.671336942127816
avg_episode_per_sec: 0.27302876674248117
collect_time: 21.975706338882446
reward_mean: -101.80310457516339
reward_std: 1.2397954857144025
reward_max: -99.95588235294115
reward_min: -103.91386554621843
queue_len: 0.0675086900365805
wait_time: 0.6346824096570546
delay_time: 4.382455162156625
pressure: 0.8154288240495138
total_envstep_count: 931944
total_train_sample_count: 931944
total_episode_count: 8034
total_duration: 30452.011265039444
[2025-02-21 02:01:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.743043672130412
avg_train_sample_per_sec: 31.743043672130412
avg_episode_per_sec: 0.2736469282080208
collect_time: 21.926063776016235
reward_mean: -102.44176003734826
reward_std: 2.7486820274801436
reward_max: -97.44467787114843
reward_min: -105.37184873949582
queue_len: 0.06793220161627868
wait_time: 0.6343765401828282
delay_time: 4.383199992031129
pressure: 0.8274756852343059
total_envstep_count: 932640
total_train_sample_count: 932640
total_episode_count: 8040
total_duration: 30473.93732881546
[2025-02-21 02:01:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82529564720036
avg_train_sample_per_sec: 31.82529564720036
avg_episode_per_sec: 0.2743559969586238
collect_time: 21.869396209716797
reward_mean: -103.44152661064426
reward_std: 1.4966608942911326
reward_max: -101.72549019607847
reward_min: -105.79061624649863
queue_len: 0.06859517679750947
wait_time: 0.6430051242424469
delay_time: 4.40719240394987
pressure: 0.8315649867374005
total_envstep_count: 933336
total_train_sample_count: 933336
total_episode_count: 8046
total_duration: 30495.806725025177
[2025-02-21 02:02:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.820314817148674
avg_train_sample_per_sec: 31.820314817148674
avg_episode_per_sec: 0.274313058768523
collect_time: 21.872819423675537
reward_mean: -104.69199346405229
reward_std: 4.550718666714367
reward_max: -98.46778711484596
reward_min: -111.36764705882352
queue_len: 0.06942439884884104
wait_time: 0.6551183912999329
delay_time: 4.426044775127217
pressure: 0.8416224580017685
total_envstep_count: 934032
total_train_sample_count: 934032
total_episode_count: 8052
total_duration: 30517.679544448853
[2025-02-21 02:02:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81766684935008
avg_train_sample_per_sec: 31.81766684935008
avg_episode_per_sec: 0.27429023145991444
collect_time: 21.874639749526978
reward_mean: -103.26528944911301
reward_std: 2.2371888979816026
reward_max: -99.9579831932773
reward_min: -106.172268907563
queue_len: 0.06847830865325796
wait_time: 0.6483791239749658
delay_time: 4.401094862862821
pressure: 0.8336648983200708
total_envstep_count: 934728
total_train_sample_count: 934728
total_episode_count: 8058
total_duration: 30539.55418419838
[2025-02-21 02:02:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.852138397338255
avg_train_sample_per_sec: 31.852138397338255
avg_episode_per_sec: 0.2745873999770539
collect_time: 21.850966215133667
reward_mean: -101.84663865546219
reward_std: 1.4713021809707707
reward_max: -99.52240896358542
reward_min: -104.15476190476188
queue_len: 0.06753755879009428
wait_time: 0.6384752066166872
delay_time: 4.410617319655707
pressure: 0.8206233421750663
total_envstep_count: 935424
total_train_sample_count: 935424
total_episode_count: 8064
total_duration: 30561.405150413513
[2025-02-21 02:03:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.901584505460765
avg_train_sample_per_sec: 31.901584505460765
avg_episode_per_sec: 0.27501365952983414
collect_time: 21.817098140716553
reward_mean: -104.66795051353874
reward_std: 3.185144740161445
reward_max: -100.75420168067222
reward_min: -109.76050420168069
queue_len: 0.06940845524770473
wait_time: 0.6531467250914513
delay_time: 4.505470962490741
pressure: 0.8365384615384616
total_envstep_count: 936120
total_train_sample_count: 936120
total_episode_count: 8070
total_duration: 30583.22224855423
[2025-02-21 02:03:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.746366587700102
avg_train_sample_per_sec: 31.746366587700102
avg_episode_per_sec: 0.2736755740318974
collect_time: 21.923768758773804
reward_mean: -102.71556956115779
reward_std: 3.325761964692404
reward_max: -96.40546218487394
reward_min: -105.95868347338936
queue_len: 0.06811377291853964
wait_time: 0.6404022926588849
delay_time: 4.3537548763711955
pressure: 0.8305702917771883
total_envstep_count: 936816
total_train_sample_count: 936816
total_episode_count: 8076
total_duration: 30605.146017313004
[2025-02-21 02:04:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.815146227024893
avg_train_sample_per_sec: 31.815146227024893
avg_episode_per_sec: 0.27426850195711117
collect_time: 21.876372814178467
reward_mean: -104.82889822595705
reward_std: 2.520054696493603
reward_max: -100.81652661064423
reward_min: -107.71638655462188
queue_len: 0.0695151844999715
wait_time: 0.6523719899100223
delay_time: 4.414070706853499
pressure: 0.8469274977895668
total_envstep_count: 937512
total_train_sample_count: 937512
total_episode_count: 8082
total_duration: 30627.022390127182
[2025-02-21 02:04:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68380314573828
avg_train_sample_per_sec: 31.68380314573828
avg_episode_per_sec: 0.27313623401498516
collect_time: 21.96705985069275
reward_mean: -100.9139822595705
reward_std: 2.762417685339772
reward_max: -97.07913165266108
reward_min: -105.25770308123249
queue_len: 0.06691908637902554
wait_time: 0.6292899122513727
delay_time: 4.328953891441235
pressure: 0.8155393457117596
total_envstep_count: 938208
total_train_sample_count: 938208
total_episode_count: 8088
total_duration: 30648.989449977875
[2025-02-21 02:04:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.711415213174817
avg_train_sample_per_sec: 31.711415213174817
avg_episode_per_sec: 0.27337426907909324
collect_time: 21.947932481765747
reward_mean: -100.81209150326798
reward_std: 1.0453654968128818
reward_max: -99.4138655462185
reward_min: -102.59103641456582
queue_len: 0.06685151956450132
wait_time: 0.6275910673730146
delay_time: 4.29402509127003
pressure: 0.8144341290893015
total_envstep_count: 938904
total_train_sample_count: 938904
total_episode_count: 8094
total_duration: 30670.93738245964
[2025-02-21 02:05:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.659079681815378
avg_train_sample_per_sec: 31.659079681815378
avg_episode_per_sec: 0.272923100705305
collect_time: 21.984214544296265
reward_mean: -101.8155929038282
reward_std: 2.5342105121060765
reward_max: -99.36974789915965
reward_min: -106.47198879551819
queue_len: 0.06751697142163675
wait_time: 0.6388102544289157
delay_time: 4.343709376531898
pressure: 0.8221706454465075
total_envstep_count: 939600
total_train_sample_count: 939600
total_episode_count: 8100
total_duration: 30692.921597003937
[2025-02-21 02:05:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55336407378105
avg_train_sample_per_sec: 31.55336407378105
avg_episode_per_sec: 0.2720117592567332
collect_time: 22.057869911193848
reward_mean: -104.02089169000935
reward_std: 2.6330518994680716
reward_max: -100.19117647058827
reward_min: -107.25630252100842
queue_len: 0.06897937114722104
wait_time: 0.6513231950605177
delay_time: 4.478901209018109
pressure: 0.8406277630415562
total_envstep_count: 940296
total_train_sample_count: 940296
total_episode_count: 8106
total_duration: 30714.97946691513
[2025-02-21 02:05:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80040915621009
avg_train_sample_per_sec: 31.80040915621009
avg_episode_per_sec: 0.2741414582431904
collect_time: 21.886510848999023
reward_mean: -102.67728758169933
reward_std: 1.4733937611470187
reward_max: -100.39635854341735
reward_min: -104.73109243697479
queue_len: 0.06808838699051682
wait_time: 0.6420505978695634
delay_time: 4.321749562133681
pressure: 0.8364279398762157
total_envstep_count: 940992
total_train_sample_count: 940992
total_episode_count: 8112
total_duration: 30736.86597776413
[2025-02-21 02:06:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.872188813832672
avg_train_sample_per_sec: 30.872188813832672
avg_episode_per_sec: 0.26613955873993683
collect_time: 22.544562816619873
reward_mean: -102.13503734827265
reward_std: 1.5371913280587555
reward_max: -99.76120448179272
reward_min: -104.86414565826337
queue_len: 0.06772880460760784
wait_time: 0.6338127868300282
delay_time: 4.371222427421874
pressure: 0.8263704686118478
total_envstep_count: 941688
total_train_sample_count: 941688
total_episode_count: 8118
total_duration: 30759.41054058075
[2025-02-21 02:06:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.681622759994838
avg_train_sample_per_sec: 31.681622759994838
avg_episode_per_sec: 0.2731174375861624
collect_time: 21.968571662902832
reward_mean: -104.18160597572358
reward_std: 2.049797349811773
reward_max: -101.1050420168067
reward_min: -106.48739495798318
queue_len: 0.06908594560724378
wait_time: 0.6546342011605705
delay_time: 4.42945322368217
pressure: 0.8372015915119363
total_envstep_count: 942384
total_train_sample_count: 942384
total_episode_count: 8124
total_duration: 30781.379112243652
[2025-02-21 02:07:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.514771365020767
avg_train_sample_per_sec: 31.514771365020767
avg_episode_per_sec: 0.27167906349155835
collect_time: 22.08488178253174
reward_mean: -105.10212418300654
reward_std: 3.368940690760623
reward_max: -99.6267507002801
reward_min: -110.08403361344536
queue_len: 0.06969636882162238
wait_time: 0.6564184913576393
delay_time: 4.419903240624951
pressure: 0.848474801061008
total_envstep_count: 943080
total_train_sample_count: 943080
total_episode_count: 8130
total_duration: 30803.463994026184
[2025-02-21 02:07:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.883290231564754
avg_train_sample_per_sec: 31.883290231564754
avg_episode_per_sec: 0.27485595027210996
collect_time: 21.82961654663086
reward_mean: -101.37173202614379
reward_std: 1.7079002341810594
reward_max: -99.61484593837535
reward_min: -103.94047619047618
queue_len: 0.06722263396959138
wait_time: 0.6259922182843075
delay_time: 4.29196826173748
pressure: 0.8232758620689656
total_envstep_count: 943776
total_train_sample_count: 943776
total_episode_count: 8136
total_duration: 30825.293610572815
[2025-02-21 02:07:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73350339118333
avg_train_sample_per_sec: 31.73350339118333
avg_episode_per_sec: 0.27356468440675286
collect_time: 21.932655572891235
reward_mean: -106.69421101774043
reward_std: 4.420671146121875
reward_max: -97.71918767507006
reward_min: -112.03011204481791
queue_len: 0.07075212932210904
wait_time: 0.6661695513749266
delay_time: 4.436299957809862
pressure: 0.8702475685234305
total_envstep_count: 944472
total_train_sample_count: 944472
total_episode_count: 8142
total_duration: 30847.226266145706
[2025-02-21 02:08:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76391507634764
avg_train_sample_per_sec: 31.76391507634764
avg_episode_per_sec: 0.2738268541064452
collect_time: 21.911656618118286
reward_mean: -102.69677871148461
reward_std: 3.5886090580444687
reward_max: -97.86274509803924
reward_min: -108.43417366946781
queue_len: 0.06810131214289429
wait_time: 0.6474030040840385
delay_time: 4.364200680558965
pressure: 0.8311229000884173
total_envstep_count: 945168
total_train_sample_count: 945168
total_episode_count: 8148
total_duration: 30869.137922763824
[2025-02-21 02:08:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.840480873530197
avg_train_sample_per_sec: 31.840480873530197
avg_episode_per_sec: 0.27448690408215687
collect_time: 21.85896635055542
reward_mean: -103.24439775910362
reward_std: 3.744259324511982
reward_max: -98.65056022408963
reward_min: -109.38025210084031
queue_len: 0.06846445474741618
wait_time: 0.6459512076271711
delay_time: 4.3630380375684314
pressure: 0.833996463306808
total_envstep_count: 945864
total_train_sample_count: 945864
total_episode_count: 8154
total_duration: 30890.99688911438
[2025-02-21 02:08:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.904778206897692
avg_train_sample_per_sec: 31.904778206897692
avg_episode_per_sec: 0.2750411914387732
collect_time: 21.814914226531982
reward_mean: -104.06022408963584
reward_std: 3.032037594422618
reward_max: -98.98739495798321
reward_min: -107.55462184873947
queue_len: 0.06900545364034207
wait_time: 0.6564729782275421
delay_time: 4.448238933214921
pressure: 0.842948717948718
total_envstep_count: 946560
total_train_sample_count: 946560
total_episode_count: 8160
total_duration: 30912.811803340912
[2025-02-21 02:09:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.927822476646174
avg_train_sample_per_sec: 31.927822476646174
avg_episode_per_sec: 0.27523984893660497
collect_time: 21.799169063568115
reward_mean: -103.14262371615314
reward_std: 2.1904925954564636
reward_max: -100.38445378151258
reward_min: -106.83613445378151
queue_len: 0.06839696532901403
wait_time: 0.6492856647521962
delay_time: 4.31297321605548
pressure: 0.8378647214854112
total_envstep_count: 947256
total_train_sample_count: 947256
total_episode_count: 8166
total_duration: 30934.61097240448
[2025-02-21 02:09:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30191993634353
avg_train_sample_per_sec: 31.30191993634353
avg_episode_per_sec: 0.2698441373822718
collect_time: 22.235057830810547
reward_mean: -101.83450046685338
reward_std: 2.1980105222891013
reward_max: -99.78431372549021
reward_min: -106.50350140056015
queue_len: 0.0675295095934041
wait_time: 0.6339651023981653
delay_time: 4.345856079570089
pressure: 0.8208443854995578
total_envstep_count: 947952
total_train_sample_count: 947952
total_episode_count: 8172
total_duration: 30956.84603023529
[2025-02-21 02:09:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08565225971542
avg_train_sample_per_sec: 32.08565225971542
avg_episode_per_sec: 0.2766004505147881
collect_time: 21.691938638687134
reward_mean: -101.54178338001867
reward_std: 1.0245475908012194
reward_max: -99.95168067226889
reward_min: -102.81792717086837
queue_len: 0.06733540011937578
wait_time: 0.6409696062332979
delay_time: 4.298263635731278
pressure: 0.8222811671087532
total_envstep_count: 948648
total_train_sample_count: 948648
total_episode_count: 8178
total_duration: 30978.537968873978
[2025-02-21 02:10:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72192666801897
avg_train_sample_per_sec: 31.72192666801897
avg_episode_per_sec: 0.273464885069129
collect_time: 21.940659761428833
reward_mean: -102.71346872082165
reward_std: 2.7287785996867817
reward_max: -97.80672268907563
reward_min: -106.85364145658264
queue_len: 0.06811237978834327
wait_time: 0.6391158143186542
delay_time: 4.362924096150889
pressure: 0.8321175950486296
total_envstep_count: 949344
total_train_sample_count: 949344
total_episode_count: 8184
total_duration: 31000.478628635406
[2025-02-21 02:10:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.883183327543893
avg_train_sample_per_sec: 31.883183327543893
avg_episode_per_sec: 0.2748550286857232
collect_time: 21.829689741134644
reward_mean: -101.21475256769374
reward_std: 2.1249689576242523
reward_max: -98.62745098039214
reward_min: -105.10294117647058
queue_len: 0.0671185361854733
wait_time: 0.6339784919272748
delay_time: 4.327969480370716
pressure: 0.8242705570291777
total_envstep_count: 950040
total_train_sample_count: 950040
total_episode_count: 8190
total_duration: 31022.30831837654
[2025-02-21 02:11:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.383694030344152
avg_train_sample_per_sec: 31.383694030344152
avg_episode_per_sec: 0.2705490864684841
collect_time: 22.17712163925171
reward_mean: -102.59733893557423
reward_std: 3.0869271394066584
reward_max: -97.74509803921572
reward_min: -106.17156862745097
queue_len: 0.06803537064693252
wait_time: 0.6337648786304974
delay_time: 4.392298228625964
pressure: 0.8150972590627763
total_envstep_count: 950736
total_train_sample_count: 950736
total_episode_count: 8196
total_duration: 31044.485440015793
[2025-02-21 02:11:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.960926338801833
avg_train_sample_per_sec: 31.960926338801833
avg_episode_per_sec: 0.2755252270586365
collect_time: 21.77659034729004
reward_mean: -103.66993464052287
reward_std: 3.520934949940005
reward_max: -100.1281512605042
reward_min: -108.74229691876751
queue_len: 0.06874664100830431
wait_time: 0.6426862522197209
delay_time: 4.403333014319929
pressure: 0.8395225464190982
total_envstep_count: 951432
total_train_sample_count: 951432
total_episode_count: 8202
total_duration: 31066.262030363083
[2025-02-21 02:11:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.985377890493183
avg_train_sample_per_sec: 31.985377890493183
avg_episode_per_sec: 0.275736016297355
collect_time: 21.75994300842285
reward_mean: -102.12114845938375
reward_std: 2.1986262618245913
reward_max: -99.00000000000003
reward_min: -106.19747899159661
queue_len: 0.06771959446908736
wait_time: 0.6375296581939583
delay_time: 4.361184386391015
pressure: 0.8210654288240496
total_envstep_count: 952128
total_train_sample_count: 952128
total_episode_count: 8208
total_duration: 31088.021973371506
[2025-02-21 02:12:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84190655563657
avg_train_sample_per_sec: 31.84190655563657
avg_episode_per_sec: 0.2744991944451428
collect_time: 21.857987642288208
reward_mean: -105.77999533146591
reward_std: 2.8712083644961566
reward_max: -100.62184873949583
reward_min: -108.74159663865552
queue_len: 0.07014588549831957
wait_time: 0.6536043683609607
delay_time: 4.546571147317123
pressure: 0.8601900972590628
total_envstep_count: 952824
total_train_sample_count: 952824
total_episode_count: 8214
total_duration: 31109.879961013794
[2025-02-21 02:12:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.864063919284046
avg_train_sample_per_sec: 31.864063919284046
avg_episode_per_sec: 0.27469020620072454
collect_time: 21.842788219451904
reward_mean: -102.47117180205417
reward_std: 2.7257396074772253
reward_max: -99.3046218487395
reward_min: -106.38375350140056
queue_len: 0.06795170543902795
wait_time: 0.6381201906049775
delay_time: 4.365478072608169
pressure: 0.83289124668435
total_envstep_count: 953520
total_train_sample_count: 953520
total_episode_count: 8220
total_duration: 31131.722749233246
[2025-02-21 02:12:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94306098419757
avg_train_sample_per_sec: 31.94306098419757
avg_episode_per_sec: 0.2753712153810135
collect_time: 21.788769721984863
reward_mean: -104.29026610644259
reward_std: 2.3560332209856236
reward_max: -101.62745098039213
reward_min: -108.98739495798317
queue_len: 0.0691580013968452
wait_time: 0.6438125205873685
delay_time: 4.474516918074652
pressure: 0.8416224580017683
total_envstep_count: 954216
total_train_sample_count: 954216
total_episode_count: 8226
total_duration: 31153.51151895523
[2025-02-21 02:13:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.927754034346066
avg_train_sample_per_sec: 31.927754034346066
avg_episode_per_sec: 0.2752392589167764
collect_time: 21.79921579360962
reward_mean: -102.95144724556492
reward_std: 2.0367888195434443
reward_max: -100.54621848739495
reward_min: -105.66666666666669
queue_len: 0.06827019048114384
wait_time: 0.6362171747567286
delay_time: 4.420590435556762
pressure: 0.8394120247568523
total_envstep_count: 954912
total_train_sample_count: 954912
total_episode_count: 8232
total_duration: 31175.31073474884
[2025-02-21 02:13:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.60923971685474
avg_train_sample_per_sec: 31.60923971685474
avg_episode_per_sec: 0.27249344583495466
collect_time: 22.01887822151184
reward_mean: -104.99299719887954
reward_std: 4.3088432566355985
reward_max: -98.57142857142853
reward_min: -111.5812324929972
queue_len: 0.06962400344753285
wait_time: 0.6539341532368916
delay_time: 4.509214935993156
pressure: 0.848916887709991
total_envstep_count: 955608
total_train_sample_count: 955608
total_episode_count: 8238
total_duration: 31197.329612970352
[2025-02-21 02:14:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.831524398595484
avg_train_sample_per_sec: 31.831524398595484
avg_episode_per_sec: 0.2744096930913404
collect_time: 21.865116834640503
reward_mean: -101.5639589169001
reward_std: 1.2463621204008504
reward_max: -99.93907563025208
reward_min: -103.00630252100844
queue_len: 0.06735010538255974
wait_time: 0.62861958443855
delay_time: 4.31565530715021
pressure: 0.8279177718832892
total_envstep_count: 956304
total_train_sample_count: 956304
total_episode_count: 8244
total_duration: 31219.194729804993
[2025-02-21 02:14:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.688803933419283
avg_train_sample_per_sec: 31.688803933419283
avg_episode_per_sec: 0.2731793442536145
collect_time: 21.963593244552612
reward_mean: -102.43720821662
reward_std: 2.4241008967200983
reward_max: -98.42086834733897
reward_min: -106.52871148459391
queue_len: 0.06792918316751989
wait_time: 0.6389795971438973
delay_time: 4.439990333535317
pressure: 0.8259283819628647
total_envstep_count: 957000
total_train_sample_count: 957000
total_episode_count: 8250
total_duration: 31241.158323049545
[2025-02-21 02:14:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.840817052107244
avg_train_sample_per_sec: 31.840817052107244
avg_episode_per_sec: 0.27448980217333835
collect_time: 21.85873556137085
reward_mean: -100.84442110177402
reward_std: 2.7179922175656737
reward_max: -96.75700280112046
reward_min: -105.02661064425769
queue_len: 0.06687295829030108
wait_time: 0.6227808209932957
delay_time: 4.286391723825946
pressure: 0.8149867374005305
total_envstep_count: 957696
total_train_sample_count: 957696
total_episode_count: 8256
total_duration: 31263.017058610916
[2025-02-21 02:15:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.923995047248074
avg_train_sample_per_sec: 31.923995047248074
avg_episode_per_sec: 0.27520685385558685
collect_time: 21.801782608032227
reward_mean: -103.01972455648924
reward_std: 3.742795852923707
reward_max: -96.74719887955182
reward_min: -108.03641456582633
queue_len: 0.06831546721252603
wait_time: 0.6465983166033876
delay_time: 4.447332272526658
pressure: 0.8345490716180372
total_envstep_count: 958392
total_train_sample_count: 958392
total_episode_count: 8262
total_duration: 31284.81884121895
[2025-02-21 02:15:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87444852318566
avg_train_sample_per_sec: 31.87444852318566
avg_episode_per_sec: 0.27477972864815225
collect_time: 21.83567190170288
reward_mean: -101.01003734827265
reward_std: 2.352569806497639
reward_max: -98.39425770308121
reward_min: -105.25000000000004
queue_len: 0.06698278338744872
wait_time: 0.6313873471581383
delay_time: 4.288060115360791
pressure: 0.8179708222811671
total_envstep_count: 959088
total_train_sample_count: 959088
total_episode_count: 8268
total_duration: 31306.65451312065
[2025-02-21 02:15:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.961970536134718
avg_train_sample_per_sec: 31.961970536134718
avg_episode_per_sec: 0.27553422875978206
collect_time: 21.77587890625
reward_mean: -103.83543417366947
reward_std: 2.327120865663568
reward_max: -99.4936974789916
reward_min: -107.18137254901963
queue_len: 0.06885638870932989
wait_time: 0.6552408319649698
delay_time: 4.383176712309445
pressure: 0.8450486295313882
total_envstep_count: 959784
total_train_sample_count: 959784
total_episode_count: 8274
total_duration: 31328.4303920269
[2025-02-21 02:16:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.47598005612537
avg_train_sample_per_sec: 31.47598005612537
avg_episode_per_sec: 0.2713446556562532
collect_time: 22.112099409103394
reward_mean: -104.7763772175537
reward_std: 2.3018578215575123
reward_max: -101.28851540616247
reward_min: -107.67997198879551
queue_len: 0.06948035624506213
wait_time: 0.654086855785639
delay_time: 4.371368039649127
pressure: 0.853448275862069
total_envstep_count: 960480
total_train_sample_count: 960480
total_episode_count: 8280
total_duration: 31350.542491436005
[2025-02-21 02:16:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1406550934781
avg_train_sample_per_sec: 32.1406550934781
avg_episode_per_sec: 0.2770746128748112
collect_time: 21.65481686592102
reward_mean: -103.5988562091503
reward_std: 3.3638169404919376
reward_max: -98.05462184873947
reward_min: -108.7927170868347
queue_len: 0.06869950676999358
wait_time: 0.6456501367125099
delay_time: 4.346646573569089
pressure: 0.8426171529619805
total_envstep_count: 961176
total_train_sample_count: 961176
total_episode_count: 8286
total_duration: 31372.197308301926
[2025-02-21 02:17:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.228264121315455
avg_train_sample_per_sec: 32.228264121315455
avg_episode_per_sec: 0.2778298631147884
collect_time: 21.595950603485107
reward_mean: -101.53361344537814
reward_std: 2.444236252929501
reward_max: -98.9705882352941
reward_min: -106.25210084033611
queue_len: 0.06732998239083432
wait_time: 0.6267257013326992
delay_time: 4.319826739486173
pressure: 0.821396993810787
total_envstep_count: 961872
total_train_sample_count: 961872
total_episode_count: 8292
total_duration: 31393.79325890541
[2025-02-21 02:17:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03665109753275
avg_train_sample_per_sec: 32.03665109753275
avg_episode_per_sec: 0.2761780267028685
collect_time: 21.725117206573486
reward_mean: -102.07679738562092
reward_std: 2.831982836653191
reward_max: -98.72549019607844
reward_min: -105.67226890756302
queue_len: 0.06769018394271943
wait_time: 0.638003167668482
delay_time: 4.276711254444572
pressure: 0.8313439434129091
total_envstep_count: 962568
total_train_sample_count: 962568
total_episode_count: 8298
total_duration: 31415.518376111984
[2025-02-21 02:17:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.586392442443962
avg_train_sample_per_sec: 31.586392442443962
avg_episode_per_sec: 0.2722964865727928
collect_time: 22.034805059432983
reward_mean: -101.78174603174601
reward_std: 1.387150832088462
reward_max: -99.79551820728285
reward_min: -103.46708683473388
queue_len: 0.06749452654625067
wait_time: 0.6348252055021831
delay_time: 4.352780627736567
pressure: 0.8262599469496021
total_envstep_count: 963264
total_train_sample_count: 963264
total_episode_count: 8304
total_duration: 31437.553181171417
[2025-02-21 02:18:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92791990267134
avg_train_sample_per_sec: 31.92791990267134
avg_episode_per_sec: 0.2752406888161323
collect_time: 21.799102544784546
reward_mean: -101.57306255835668
reward_std: 3.5672700489268605
reward_max: -97.28781512605042
reward_min: -107.33053221288515
queue_len: 0.06735614228007737
wait_time: 0.6324332783511283
delay_time: 4.310202419097262
pressure: 0.8221706454465076
total_envstep_count: 963960
total_train_sample_count: 963960
total_episode_count: 8310
total_duration: 31459.3522837162
[2025-02-21 02:18:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.984814016303925
avg_train_sample_per_sec: 31.984814016303925
avg_episode_per_sec: 0.2757311553129649
collect_time: 21.760326623916626
reward_mean: -101.13503734827265
reward_std: 2.285319250422968
reward_max: -97.21638655462188
reward_min: -104.38655462184873
queue_len: 0.06706567463413304
wait_time: 0.6312632037784166
delay_time: 4.236975496397846
pressure: 0.8215075154730327
total_envstep_count: 964656
total_train_sample_count: 964656
total_episode_count: 8316
total_duration: 31481.11261034012
[2025-02-21 02:18:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.90053170037356
avg_train_sample_per_sec: 31.90053170037356
avg_episode_per_sec: 0.27500458362391
collect_time: 21.81781816482544
reward_mean: -101.24603174603175
reward_std: 2.723454439139472
reward_max: -96.30252100840339
reward_min: -105.39005602240894
queue_len: 0.0671392783461749
wait_time: 0.6279240254899484
delay_time: 4.274265124649247
pressure: 0.8231653404067197
total_envstep_count: 965352
total_train_sample_count: 965352
total_episode_count: 8322
total_duration: 31502.930428504944
[2025-02-21 02:19:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21992599551123
avg_train_sample_per_sec: 32.21992599551123
avg_episode_per_sec: 0.2777579827199244
collect_time: 21.601539373397827
reward_mean: -99.94922969187677
reward_std: 1.6771083317288367
reward_max: -96.75700280112048
reward_min: -102.063025210084
queue_len: 0.06627933003440103
wait_time: 0.6240812306354903
delay_time: 4.261645216764918
pressure: 0.8101237842617154
total_envstep_count: 966048
total_train_sample_count: 966048
total_episode_count: 8328
total_duration: 31524.53196787834
[2025-02-21 02:19:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.858799053598283
avg_train_sample_per_sec: 31.858799053598283
avg_episode_per_sec: 0.2746448194275714
collect_time: 21.846397876739502
reward_mean: -100.42612044817925
reward_std: 2.2853831716257194
reward_max: -97.90686274509802
reward_min: -104.14985994397757
queue_len: 0.06659557058897829
wait_time: 0.6311777584597057
delay_time: 4.31084578881584
pressure: 0.8174182139699381
total_envstep_count: 966744
total_train_sample_count: 966744
total_episode_count: 8334
total_duration: 31546.37836575508
[2025-02-21 02:20:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.186982956423282
avg_train_sample_per_sec: 31.186982956423282
avg_episode_per_sec: 0.26885330134847657
collect_time: 22.31700325012207
reward_mean: -99.4779411764706
reward_std: 2.2755073531710392
reward_max: -96.27801120448179
reward_min: -102.90896358543418
queue_len: 0.06596680449368077
wait_time: 0.6228513288604566
delay_time: 4.249733179826827
pressure: 0.8068081343943413
total_envstep_count: 967440
total_train_sample_count: 967440
total_episode_count: 8340
total_duration: 31568.695369005203
[2025-02-21 02:20:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81096063625766
avg_train_sample_per_sec: 31.81096063625766
avg_episode_per_sec: 0.2742324192780833
collect_time: 21.87925124168396
reward_mean: -104.25140056022411
reward_std: 3.319847384931848
reward_max: -99.49719887955187
reward_min: -109.48949579831934
queue_len: 0.06913222848821227
wait_time: 0.6519540508511096
delay_time: 4.452863211523589
pressure: 0.8427276746242263
total_envstep_count: 968136
total_train_sample_count: 968136
total_episode_count: 8346
total_duration: 31590.574620246887
[2025-02-21 02:20:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.930581364663947
avg_train_sample_per_sec: 31.930581364663947
avg_episode_per_sec: 0.27526363245399954
collect_time: 21.797285556793213
reward_mean: -102.41386554621846
reward_std: 1.6558526151031734
reward_max: -99.24019607843135
reward_min: -104.56162464985992
queue_len: 0.06791370394311569
wait_time: 0.6382580330982969
delay_time: 4.327223059710119
pressure: 0.8357648099027409
total_envstep_count: 968832
total_train_sample_count: 968832
total_episode_count: 8352
total_duration: 31612.37190580368
[2025-02-21 02:21:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.069389966828275
avg_train_sample_per_sec: 32.069389966828275
avg_episode_per_sec: 0.2764602583347265
collect_time: 21.702938556671143
reward_mean: -101.33473389355743
reward_std: 2.5802540178705415
reward_max: -98.62324929971984
reward_min: -106.1806722689076
queue_len: 0.06719809939891076
wait_time: 0.6273904566247365
delay_time: 4.287390510050598
pressure: 0.8174182139699381
total_envstep_count: 969528
total_train_sample_count: 969528
total_episode_count: 8358
total_duration: 31634.07484436035
[2025-02-21 02:21:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.842517154767027
avg_train_sample_per_sec: 31.842517154767027
avg_episode_per_sec: 0.2745044582307502
collect_time: 21.857568502426147
reward_mean: -105.55123716153126
reward_std: 3.3654610117238843
reward_max: -99.80042016806722
reward_min: -111.27450980392155
queue_len: 0.06999418909915867
wait_time: 0.6600830429430836
delay_time: 4.497265987192235
pressure: 0.8533377541998233
total_envstep_count: 970224
total_train_sample_count: 970224
total_episode_count: 8364
total_duration: 31655.932412862778
[2025-02-21 02:21:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.159634283581
avg_train_sample_per_sec: 32.159634283581
avg_episode_per_sec: 0.2772382265825948
collect_time: 21.64203715324402
reward_mean: -100.9361577964519
reward_std: 2.898123927422992
reward_max: -97.19187675070026
reward_min: -106.17647058823532
queue_len: 0.06693379164220949
wait_time: 0.6263072978970546
delay_time: 4.35078490640887
pressure: 0.8082449160035368
total_envstep_count: 970920
total_train_sample_count: 970920
total_episode_count: 8370
total_duration: 31677.57445001602
[2025-02-21 02:22:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03460537983211
avg_train_sample_per_sec: 32.03460537983211
avg_episode_per_sec: 0.2761603912054492
collect_time: 21.72650456428528
reward_mean: -99.93825863678808
reward_std: 2.4706975827209146
reward_max: -96.04201680672271
reward_min: -102.26470588235296
queue_len: 0.06627205479893107
wait_time: 0.6241502679763329
delay_time: 4.294668692497873
pressure: 0.8127763041556145
total_envstep_count: 971616
total_train_sample_count: 971616
total_episode_count: 8376
total_duration: 31699.300954580307
[2025-02-21 02:22:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.629033148257207
avg_train_sample_per_sec: 31.629033148257207
avg_episode_per_sec: 0.27266407886428623
collect_time: 22.005098819732666
reward_mean: -102.32119514472454
reward_std: 2.605944056935988
reward_max: -97.11414565826333
reward_min: -104.88375350140055
queue_len: 0.06785225142223114
wait_time: 0.6394260179757135
delay_time: 4.308569716935822
pressure: 0.837422634836428
total_envstep_count: 972312
total_train_sample_count: 972312
total_episode_count: 8382
total_duration: 31721.30605340004
[2025-02-21 02:23:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.500637504617078
avg_train_sample_per_sec: 31.500637504617078
avg_episode_per_sec: 0.2715572198673886
collect_time: 22.094790935516357
reward_mean: -103.49626517273578
reward_std: 3.772496073306268
reward_max: -95.86554621848738
reward_min: -106.99579831932776
queue_len: 0.06863147557873726
wait_time: 0.6448281898966483
delay_time: 4.472412336905289
pressure: 0.8261494252873564
total_envstep_count: 973008
total_train_sample_count: 973008
total_episode_count: 8388
total_duration: 31743.400844335556
[2025-02-21 02:23:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968519320820484
avg_train_sample_per_sec: 31.968519320820484
avg_episode_per_sec: 0.2755906838001766
collect_time: 21.77141809463501
reward_mean: -102.47852474323061
reward_std: 3.3529199122119833
reward_max: -95.47338935574227
reward_min: -105.58613445378151
queue_len: 0.06795658139471528
wait_time: 0.6402683973677888
delay_time: 4.357190097616385
pressure: 0.829686118479222
total_envstep_count: 973704
total_train_sample_count: 973704
total_episode_count: 8394
total_duration: 31765.17226243019
[2025-02-21 02:23:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.094388542891515
avg_train_sample_per_sec: 32.094388542891515
avg_episode_per_sec: 0.2766757633007889
collect_time: 21.686033964157104
reward_mean: -102.05660597572363
reward_std: 1.7737600554886845
reward_max: -98.99999999999996
reward_min: -104.01120448179272
queue_len: 0.06767679441360984
wait_time: 0.6361992188564197
delay_time: 4.358556955393068
pressure: 0.8234969053934571
total_envstep_count: 974400
total_train_sample_count: 974400
total_episode_count: 8400
total_duration: 31786.858296394348
[2025-02-21 02:24:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.915103186955122
avg_train_sample_per_sec: 31.915103186955122
avg_episode_per_sec: 0.27513019988754417
collect_time: 21.807856798171997
reward_mean: -98.83986928104575
reward_std: 2.019401709175777
reward_max: -96.76960784313724
reward_min: -101.86974789915969
queue_len: 0.06554367989459269
wait_time: 0.615995038598994
delay_time: 4.234220247919892
pressure: 0.8024977895667552
total_envstep_count: 975096
total_train_sample_count: 975096
total_episode_count: 8406
total_duration: 31808.66615319252
[2025-02-21 02:24:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.197064100747525
avg_train_sample_per_sec: 32.197064100747525
avg_episode_per_sec: 0.27756089742023726
collect_time: 21.616877794265747
reward_mean: -103.4328898225957
reward_std: 1.6924444454646177
reward_max: -100.52871148459383
reward_min: -105.57072829131648
queue_len: 0.06858944948447991
wait_time: 0.6472927146101588
delay_time: 4.396604139984653
pressure: 0.8333333333333334
total_envstep_count: 975792
total_train_sample_count: 975792
total_episode_count: 8412
total_duration: 31830.283030986786
[2025-02-21 02:24:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.974044297202656
avg_train_sample_per_sec: 31.974044297202656
avg_episode_per_sec: 0.2756383129069194
collect_time: 21.767656087875366
reward_mean: -101.57457983193278
reward_std: 2.9020182602824542
reward_max: -98.50280112044821
reward_min: -106.9936974789916
queue_len: 0.06735714842966363
wait_time: 0.6349977988542898
delay_time: 4.312947150227749
pressure: 0.8228337754199823
total_envstep_count: 976488
total_train_sample_count: 976488
total_episode_count: 8418
total_duration: 31852.05068707466
[2025-02-21 02:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.813576978131504
avg_train_sample_per_sec: 31.813576978131504
avg_episode_per_sec: 0.2742549739494095
collect_time: 21.87745189666748
reward_mean: -102.86776377217552
reward_std: 4.415810255471187
reward_max: -97.46848739495799
reward_min: -110.8802521008403
queue_len: 0.06821469746165486
wait_time: 0.6431297319989003
delay_time: 4.41240220317414
pressure: 0.8292440318302386
total_envstep_count: 977184
total_train_sample_count: 977184
total_episode_count: 8424
total_duration: 31873.92813897133
[2025-02-21 02:25:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.635344719404458
avg_train_sample_per_sec: 31.635344719404458
avg_episode_per_sec: 0.27271848896038325
collect_time: 22.00070858001709
reward_mean: -103.18592436974791
reward_std: 1.5729054014073451
reward_max: -101.18837535014006
reward_min: -106.14215686274511
queue_len: 0.06842567929028374
wait_time: 0.6459568575440787
delay_time: 4.433740117865592
pressure: 0.8326702033598585
total_envstep_count: 977880
total_train_sample_count: 977880
total_episode_count: 8430
total_duration: 31895.928847551346
[2025-02-21 02:26:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94728665651469
avg_train_sample_per_sec: 31.94728665651469
avg_episode_per_sec: 0.2754076435906439
collect_time: 21.785887718200684
reward_mean: -101.01505602240896
reward_std: 1.789992666328905
reward_max: -97.88515406162465
reward_min: -104.01680672268907
queue_len: 0.06698611142069559
wait_time: 0.6341076660549276
delay_time: 4.291281584540269
pressure: 0.8202917771883289
total_envstep_count: 978576
total_train_sample_count: 978576
total_episode_count: 8436
total_duration: 31917.714735269547
[2025-02-21 02:26:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.2230582002798
avg_train_sample_per_sec: 32.2230582002798
avg_episode_per_sec: 0.27778498448517075
collect_time: 21.59943962097168
reward_mean: -101.48085901027075
reward_std: 2.644262823709744
reward_max: -97.49159663865545
reward_min: -105.82282913165264
queue_len: 0.06729499934368088
wait_time: 0.6298203852717038
delay_time: 4.282299563388535
pressure: 0.826259946949602
total_envstep_count: 979272
total_train_sample_count: 979272
total_episode_count: 8442
total_duration: 31939.31417489052
[2025-02-21 02:26:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86215633464544
avg_train_sample_per_sec: 31.86215633464544
avg_episode_per_sec: 0.27467376150556416
collect_time: 21.844095945358276
reward_mean: -104.2593370681606
reward_std: 3.70606718123054
reward_max: -99.81372549019609
reward_min: -111.72689075630248
queue_len: 0.06913749142450967
wait_time: 0.6541709853702754
delay_time: 4.387015567616093
pressure: 0.8442749778956675
total_envstep_count: 979968
total_train_sample_count: 979968
total_episode_count: 8448
total_duration: 31961.158270835876
[2025-02-21 02:27:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8644249427731
avg_train_sample_per_sec: 31.8644249427731
avg_episode_per_sec: 0.27469331847218187
collect_time: 21.842540740966797
reward_mean: -102.29773576097104
reward_std: 0.977081446192742
reward_max: -101.02310924369748
reward_min: -103.55462184873949
queue_len: 0.06783669480170494
wait_time: 0.6395390937099862
delay_time: 4.354059729699233
pressure: 0.822391688770999
total_envstep_count: 980664
total_train_sample_count: 980664
total_episode_count: 8454
total_duration: 31983.000811576843
[2025-02-21 02:27:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.251826688185005
avg_train_sample_per_sec: 32.251826688185005
avg_episode_per_sec: 0.27803298869125004
collect_time: 21.580173015594482
reward_mean: -100.23541083099907
reward_std: 1.7341333507980279
reward_max: -97.45658263305323
reward_min: -102.40476190476198
queue_len: 0.0664691053255962
wait_time: 0.621328482763574
delay_time: 4.354046039517077
pressure: 0.8048187444739169
total_envstep_count: 981360
total_train_sample_count: 981360
total_episode_count: 8460
total_duration: 32004.580984592438
[2025-02-21 02:27:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.789839055882908
avg_train_sample_per_sec: 31.789839055882908
avg_episode_per_sec: 0.27405033668864576
collect_time: 21.89378809928894
reward_mean: -101.15242763772176
reward_std: 2.5742447942946645
reward_max: -96.72478991596638
reward_min: -104.7205882352941
queue_len: 0.06707720665631416
wait_time: 0.6306985216721525
delay_time: 4.3619938292375435
pressure: 0.8133289124668436
total_envstep_count: 982056
total_train_sample_count: 982056
total_episode_count: 8466
total_duration: 32026.474772691727
[2025-02-21 02:28:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02849509490103
avg_train_sample_per_sec: 32.02849509490103
avg_episode_per_sec: 0.27610771633535375
collect_time: 21.73064947128296
reward_mean: -104.01353874883286
reward_std: 1.7904857741407794
reward_max: -101.19397759103641
reward_min: -105.9264705882353
queue_len: 0.06897449519153372
wait_time: 0.6502761029256973
delay_time: 4.420665968500034
pressure: 0.8470380194518126
total_envstep_count: 982752
total_train_sample_count: 982752
total_episode_count: 8472
total_duration: 32048.20542216301
[2025-02-21 02:28:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93451866946524
avg_train_sample_per_sec: 31.93451866946524
avg_episode_per_sec: 0.27529757473676936
collect_time: 21.79459810256958
reward_mean: -100.43499066293181
reward_std: 1.9837415489032162
reward_max: -97.91456582633052
reward_min: -103.72969187675069
queue_len: 0.06660145269425188
wait_time: 0.6276543000047057
delay_time: 4.301854362139172
pressure: 0.8092396109637489
total_envstep_count: 983448
total_train_sample_count: 983448
total_episode_count: 8478
total_duration: 32070.00002026558
[2025-02-21 02:28:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.766546499641727
avg_train_sample_per_sec: 31.766546499641727
avg_episode_per_sec: 0.2738495387900149
collect_time: 21.909841537475586
reward_mean: -101.20564892623717
reward_std: 0.9609559373474036
reward_max: -99.5889355742297
reward_min: -102.4334733893558
queue_len: 0.0671124992879557
wait_time: 0.6332063882139947
delay_time: 4.3359257623701914
pressure: 0.8174182139699382
total_envstep_count: 984144
total_train_sample_count: 984144
total_episode_count: 8484
total_duration: 32091.909861803055
[2025-02-21 02:29:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.684094757688822
avg_train_sample_per_sec: 31.684094757688822
avg_episode_per_sec: 0.27313874791111054
collect_time: 21.96685767173767
reward_mean: -101.79084967320263
reward_std: 3.180993835368327
reward_max: -96.38305322128853
reward_min: -105.80182072829133
queue_len: 0.06750056344376831
wait_time: 0.6362920942028447
delay_time: 4.333589682750067
pressure: 0.8198496905393458
total_envstep_count: 984840
total_train_sample_count: 984840
total_episode_count: 8490
total_duration: 32113.876719474792
[2025-02-21 02:29:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08986600709561
avg_train_sample_per_sec: 32.08986600709561
avg_episode_per_sec: 0.276636775923238
collect_time: 21.689090251922607
reward_mean: -101.69642857142856
reward_std: 3.28513133264573
reward_max: -98.17857142857144
reward_min: -106.78711484593835
queue_len: 0.06743794998105342
wait_time: 0.6307329629464516
delay_time: 4.351483959011893
pressure: 0.8189655172413791
total_envstep_count: 985536
total_train_sample_count: 985536
total_episode_count: 8496
total_duration: 32135.565809726715
[2025-02-21 02:30:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.925554957851826
avg_train_sample_per_sec: 31.925554957851826
avg_episode_per_sec: 0.2752203013607916
collect_time: 21.8007173538208
reward_mean: -99.79948646125115
reward_std: 2.763804094088503
reward_max: -96.53221288515407
reward_min: -104.95728291316517
queue_len: 0.06618003080984824
wait_time: 0.6189134915681569
delay_time: 4.22706543774965
pressure: 0.8073607427055703
total_envstep_count: 986232
total_train_sample_count: 986232
total_episode_count: 8502
total_duration: 32157.366527080536
[2025-02-21 02:30:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06503542949906
avg_train_sample_per_sec: 32.06503542949906
avg_episode_per_sec: 0.2764227192198195
collect_time: 21.705885887145996
reward_mean: -103.01692343604107
reward_std: 5.9398666634066375
reward_max: -97.48599439775914
reward_min: -113.98809523809521
queue_len: 0.06831360970559754
wait_time: 0.6499140438668836
delay_time: 4.430165099847263
pressure: 0.8333333333333334
total_envstep_count: 986928
total_train_sample_count: 986928
total_episode_count: 8508
total_duration: 32179.072412967682
[2025-02-21 02:30:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97021803287123
avg_train_sample_per_sec: 31.97021803287123
avg_episode_per_sec: 0.2756053278695796
collect_time: 21.77026128768921
reward_mean: -99.7830298786181
reward_std: 1.9913860763365985
reward_max: -97.29061624649857
reward_min: -102.47969187675069
queue_len: 0.06616911795664332
wait_time: 0.6266815081470253
delay_time: 4.306165199560467
pressure: 0.8043766578249337
total_envstep_count: 987624
total_train_sample_count: 987624
total_episode_count: 8514
total_duration: 32200.84267425537
[2025-02-21 02:31:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83410906218427
avg_train_sample_per_sec: 31.83410906218427
avg_episode_per_sec: 0.2744319746740023
collect_time: 21.863341569900513
reward_mean: -100.7299253034547
reward_std: 2.6983426190099506
reward_max: -97.12114845938372
reward_min: -105.57422969187678
queue_len: 0.06679703269459862
wait_time: 0.6270944938541286
delay_time: 4.273402935658624
pressure: 0.8144341290893015
total_envstep_count: 988320
total_train_sample_count: 988320
total_episode_count: 8520
total_duration: 32222.70601582527
[2025-02-21 02:31:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03132483179316
avg_train_sample_per_sec: 32.03132483179316
avg_episode_per_sec: 0.2761321106189065
collect_time: 21.728729724884033
reward_mean: -99.13211951447245
reward_std: 2.3887995331906553
reward_max: -96.30672268907564
reward_min: -102.79551820728287
queue_len: 0.06573747978413291
wait_time: 0.6165884346665279
delay_time: 4.278566833961809
pressure: 0.8058134394341291
total_envstep_count: 989016
total_train_sample_count: 989016
total_episode_count: 8526
total_duration: 32244.434745550156
[2025-02-21 02:31:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.773926695836746
avg_train_sample_per_sec: 31.773926695836746
avg_episode_per_sec: 0.27391316117100645
collect_time: 21.904752492904663
reward_mean: -101.67040149393091
reward_std: 3.1921073694547557
reward_max: -98.54691876750705
reward_min: -105.97549019607837
queue_len: 0.06742069064584277
wait_time: 0.6326589654429412
delay_time: 4.350712502851404
pressure: 0.8220601237842619
total_envstep_count: 989712
total_train_sample_count: 989712
total_episode_count: 8532
total_duration: 32266.33949804306
[2025-02-21 02:32:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97925764222038
avg_train_sample_per_sec: 31.97925764222038
avg_episode_per_sec: 0.27568325553638257
collect_time: 21.76410746574402
reward_mean: -100.92530345471522
reward_std: 3.307305158185458
reward_max: -96.44117647058827
reward_min: -105.29831932773106
queue_len: 0.06692659380286155
wait_time: 0.6284866952970402
delay_time: 4.320011163577701
pressure: 0.8155393457117596
total_envstep_count: 990408
total_train_sample_count: 990408
total_episode_count: 8538
total_duration: 32288.103605508804
[2025-02-21 02:32:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.937084098588155
avg_train_sample_per_sec: 31.937084098588155
avg_episode_per_sec: 0.2753196905050703
collect_time: 21.792847394943237
reward_mean: -101.42682072829132
reward_std: 2.8838257094432573
reward_max: -96.78921568627452
reward_min: -105.66596638655466
queue_len: 0.06725916493918523
wait_time: 0.6280590043267528
delay_time: 4.3494336532002125
pressure: 0.8241600353669317
total_envstep_count: 991104
total_train_sample_count: 991104
total_episode_count: 8544
total_duration: 32309.896452903748
[2025-02-21 02:33:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71903725333349
avg_train_sample_per_sec: 31.71903725333349
avg_episode_per_sec: 0.2734399763218404
collect_time: 21.94265842437744
reward_mean: -99.718954248366
reward_std: 1.6894802396925197
reward_max: -96.21988795518207
reward_min: -101.46988795518206
queue_len: 0.06612662748565386
wait_time: 0.6196681037578603
delay_time: 4.240358806832822
pressure: 0.8087975243147657
total_envstep_count: 991800
total_train_sample_count: 991800
total_episode_count: 8550
total_duration: 32331.839111328125
[2025-02-21 02:33:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.955636414269257
avg_train_sample_per_sec: 31.955636414269257
avg_episode_per_sec: 0.27547962426094186
collect_time: 21.780195236206055
reward_mean: -100.24568160597575
reward_std: 2.091535744905279
reward_max: -97.36064425770311
reward_min: -103.50910364145656
queue_len: 0.06647591618433404
wait_time: 0.6191541935076418
delay_time: 4.293481406994043
pressure: 0.8104553492484529
total_envstep_count: 992496
total_train_sample_count: 992496
total_episode_count: 8556
total_duration: 32353.61930656433
[2025-02-21 02:33:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.83191962945706
avg_train_sample_per_sec: 30.83191962945706
avg_episode_per_sec: 0.26579241059876774
collect_time: 22.574007987976074
reward_mean: -99.55252100840335
reward_std: 1.9590593235905913
reward_max: -95.40056022408962
reward_min: -101.26960784313727
queue_len: 0.06601626061565209
wait_time: 0.6196633825944171
delay_time: 4.255719020405752
pressure: 0.8131078691423519
total_envstep_count: 993192
total_train_sample_count: 993192
total_episode_count: 8562
total_duration: 32376.193314552307
[2025-02-21 02:34:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.996529089698882
avg_train_sample_per_sec: 31.996529089698882
avg_episode_per_sec: 0.2758321473249904
collect_time: 21.75235939025879
reward_mean: -101.00875350140056
reward_std: 3.09897208952617
reward_max: -95.96708683473389
reward_min: -104.95658263305319
queue_len: 0.06698193203010647
wait_time: 0.6286259309205557
delay_time: 4.315403135227335
pressure: 0.8270335985853228
total_envstep_count: 993888
total_train_sample_count: 993888
total_episode_count: 8568
total_duration: 32397.945673942566
[2025-02-21 02:34:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23695827907981
avg_train_sample_per_sec: 32.23695827907981
avg_episode_per_sec: 0.27790481275068796
collect_time: 21.590126276016235
reward_mean: -101.01225490196077
reward_std: 3.9328744579804216
reward_max: -96.0672268907563
reward_min: -107.51050420168065
queue_len: 0.0669842539137671
wait_time: 0.6282585315293224
delay_time: 4.338820244893255
pressure: 0.8276967285587974
total_envstep_count: 994584
total_train_sample_count: 994584
total_episode_count: 8574
total_duration: 32419.535800218582
[2025-02-21 02:34:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07095178738501
avg_train_sample_per_sec: 32.07095178738501
avg_episode_per_sec: 0.2764737223050432
collect_time: 21.701881647109985
reward_mean: -99.18872549019606
reward_std: 2.691300462381332
reward_max: -94.9922969187675
reward_min: -104.07002801120444
queue_len: 0.06577501690331304
wait_time: 0.6184011292403787
delay_time: 4.234266624556331
pressure: 0.8027188328912467
total_envstep_count: 995280
total_train_sample_count: 995280
total_episode_count: 8580
total_duration: 32441.237681865692
[2025-02-21 02:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03345484434149
avg_train_sample_per_sec: 32.03345484434149
avg_episode_per_sec: 0.2761504727960474
collect_time: 21.727284908294678
reward_mean: -98.86006069094303
reward_std: 1.3711949184188355
reward_max: -97.08123249299715
reward_min: -100.76400560224091
queue_len: 0.06555706942370228
wait_time: 0.6117487777604411
delay_time: 4.263435721436452
pressure: 0.8022767462422635
total_envstep_count: 995976
total_train_sample_count: 995976
total_episode_count: 8586
total_duration: 32462.964966773987
[2025-02-21 02:35:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.34715475880494
avg_train_sample_per_sec: 32.34715475880494
avg_episode_per_sec: 0.2788547824034908
collect_time: 21.516575574874878
reward_mean: -99.72852474323061
reward_std: 3.059327286315414
reward_max: -96.10994397759106
reward_min: -104.72128851540614
queue_len: 0.06613297396765956
wait_time: 0.6204451608229499
delay_time: 4.235973187161799
pressure: 0.8105658709106985
total_envstep_count: 996672
total_train_sample_count: 996672
total_episode_count: 8592
total_duration: 32484.48154234886
[2025-02-21 02:36:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.033260811669834
avg_train_sample_per_sec: 32.033260811669834
avg_episode_per_sec: 0.276148800100602
collect_time: 21.727416515350342
reward_mean: -100.74929971988796
reward_std: 2.815475239757902
reward_max: -96.73949579831931
reward_min: -104.84453781512606
queue_len: 0.06680988045085408
wait_time: 0.628048865434768
delay_time: 4.318326813555708
pressure: 0.8158709106984968
total_envstep_count: 997368
total_train_sample_count: 997368
total_episode_count: 8598
total_duration: 32506.208958864212
[2025-02-21 02:36:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.077970759470766
avg_train_sample_per_sec: 32.077970759470766
avg_episode_per_sec: 0.2765342306850928
collect_time: 21.69713306427002
reward_mean: -99.9439775910364
reward_std: 3.9825230014679085
reward_max: -93.33193277310919
reward_min: -105.77591036414567
queue_len: 0.06627584720891007
wait_time: 0.6262916638804064
delay_time: 4.271149349233823
pressure: 0.812555260831123
total_envstep_count: 998064
total_train_sample_count: 998064
total_episode_count: 8604
total_duration: 32527.906091928482
[2025-02-21 02:36:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21658142910426
avg_train_sample_per_sec: 32.21658142910426
avg_episode_per_sec: 0.2777291502508988
collect_time: 21.603781938552856
reward_mean: -101.88853874883286
reward_std: 1.7304321826400757
reward_max: -100.17226890756305
reward_min: -105.41386554621843
queue_len: 0.06756534399789979
wait_time: 0.6379198120450656
delay_time: 4.361394660132619
pressure: 0.822391688770999
total_envstep_count: 998760
total_train_sample_count: 998760
total_episode_count: 8610
total_duration: 32549.509873867035
[2025-02-21 02:37:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81301637150533
avg_train_sample_per_sec: 31.81301637150533
avg_episode_per_sec: 0.27425014113366664
collect_time: 21.877837419509888
reward_mean: -98.86029411764706
reward_std: 1.3093880373949998
reward_max: -96.32282913165265
reward_min: -100.28991596638652
queue_len: 0.06555722421594633
wait_time: 0.6122776254622097
delay_time: 4.260964654007464
pressure: 0.7945402298850576
total_envstep_count: 999456
total_train_sample_count: 999456
total_episode_count: 8616
total_duration: 32571.387711286545
[2025-02-21 02:37:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.709643659293462
avg_train_sample_per_sec: 31.709643659293462
avg_episode_per_sec: 0.27335899706287464
collect_time: 21.949158668518066
reward_mean: -99.85784313725492
reward_std: 3.546720406869743
reward_max: -94.52801120448177
reward_min: -104.9222689075631
queue_len: 0.0662187288708587
wait_time: 0.6176493033110682
delay_time: 4.312078817120962
pressure: 0.8112290008841733
total_envstep_count: 1000152
total_train_sample_count: 1000152
total_episode_count: 8622
total_duration: 32593.336869955063
[2025-02-21 02:37:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.737798361239758
avg_train_sample_per_sec: 31.737798361239758
avg_episode_per_sec: 0.27360171001068756
collect_time: 21.9296875
reward_mean: -101.96685340802988
reward_std: 5.106565797868937
reward_max: -92.87955182072832
reward_min: -108.71638655462183
queue_len: 0.06761727679577578
wait_time: 0.6407151277840933
delay_time: 4.353599566265032
pressure: 0.8283598585322723
total_envstep_count: 1000848
total_train_sample_count: 1000848
total_episode_count: 8628
total_duration: 32615.266557455063
[2025-02-21 02:38:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.615848470351796
avg_train_sample_per_sec: 31.615848470351796
avg_episode_per_sec: 0.2725504178478603
collect_time: 22.014275550842285
reward_mean: -100.38702147525674
reward_std: 3.0785568094119595
reward_max: -96.84243697478989
reward_min: -105.15406162464987
queue_len: 0.0665696428881013
wait_time: 0.6232349814373142
delay_time: 4.368628679553049
pressure: 0.8041556145004422
total_envstep_count: 1001544
total_train_sample_count: 1001544
total_episode_count: 8634
total_duration: 32637.280833005905
[2025-02-21 02:38:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.996559600686226
avg_train_sample_per_sec: 31.996559600686226
avg_episode_per_sec: 0.2758324103507433
collect_time: 21.752338647842407
reward_mean: -99.89810924369749
reward_std: 3.47775486251917
reward_max: -95.25910364145665
reward_min: -106.13935574229694
queue_len: 0.06624543053295591
wait_time: 0.6194000035911799
delay_time: 4.302035216276322
pressure: 0.8048187444739168
total_envstep_count: 1002240
total_train_sample_count: 1002240
total_episode_count: 8640
total_duration: 32659.033171653748
[2025-02-21 02:39:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.986453126457985
avg_train_sample_per_sec: 31.986453126457985
avg_episode_per_sec: 0.27574528557291367
collect_time: 21.759211540222168
reward_mean: -101.05275443510737
reward_std: 2.967178139880246
reward_max: -96.72338935574228
reward_min: -105.2864145658263
queue_len: 0.06701111036810832
wait_time: 0.6271167839372708
delay_time: 4.293095933465616
pressure: 0.8275862068965516
total_envstep_count: 1002936
total_train_sample_count: 1002936
total_episode_count: 8646
total_duration: 32680.79238319397
[2025-02-21 02:39:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07352685099498
avg_train_sample_per_sec: 32.07352685099498
avg_episode_per_sec: 0.2764959211292671
collect_time: 21.70013928413391
reward_mean: -101.59873949579831
reward_std: 2.878177357605012
reward_max: -98.35784313725487
reward_min: -107.1806722689076
queue_len: 0.06737316942692197
wait_time: 0.6377585959228961
delay_time: 4.317350473830864
pressure: 0.8210654288240495
total_envstep_count: 1003632
total_train_sample_count: 1003632
total_episode_count: 8652
total_duration: 32702.492522478104
[2025-02-21 02:39:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07720834553255
avg_train_sample_per_sec: 32.07720834553255
avg_episode_per_sec: 0.27652765815114266
collect_time: 21.697648763656616
reward_mean: -99.14472455648927
reward_std: 1.5687607104316061
reward_max: -96.48109243697476
reward_min: -101.3032212885154
queue_len: 0.06574583856531117
wait_time: 0.6226770327936656
delay_time: 4.236213219967591
pressure: 0.8039345711759505
total_envstep_count: 1004328
total_train_sample_count: 1004328
total_episode_count: 8658
total_duration: 32724.19017124176
[2025-02-21 02:40:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96813387975632
avg_train_sample_per_sec: 31.96813387975632
avg_episode_per_sec: 0.27558736103238207
collect_time: 21.7716805934906
reward_mean: -100.45273109243696
reward_std: 3.4559837336145622
reward_max: -94.97338935574228
reward_min: -104.98879551820724
queue_len: 0.06661321690479904
wait_time: 0.6297449240527334
delay_time: 4.276946013352317
pressure: 0.8174182139699381
total_envstep_count: 1005024
total_train_sample_count: 1005024
total_episode_count: 8664
total_duration: 32745.96185183525
[2025-02-21 02:40:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19783151262801
avg_train_sample_per_sec: 32.19783151262801
avg_episode_per_sec: 0.27756751303989663
collect_time: 21.61636257171631
reward_mean: -99.79668534080298
reward_std: 2.2605767546653572
reward_max: -95.63375350140058
reward_min: -102.39985994397762
queue_len: 0.06617817330291975
wait_time: 0.6240185397766534
delay_time: 4.21456516141384
pressure: 0.8139920424403183
total_envstep_count: 1005720
total_train_sample_count: 1005720
total_episode_count: 8670
total_duration: 32767.578214406967
[2025-02-21 02:40:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87002324489848
avg_train_sample_per_sec: 31.87002324489848
avg_episode_per_sec: 0.2747415796974007
collect_time: 21.838703870773315
reward_mean: -100.38655462184873
reward_std: 2.625975131195853
reward_max: -97.00840336134455
reward_min: -104.92086834733891
queue_len: 0.06656933330361323
wait_time: 0.6291256002843224
delay_time: 4.275601341351505
pressure: 0.8078028293545535
total_envstep_count: 1006416
total_train_sample_count: 1006416
total_episode_count: 8676
total_duration: 32789.41691827774
[2025-02-21 02:41:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.859922820736138
avg_train_sample_per_sec: 31.859922820736138
avg_episode_per_sec: 0.2746545070753115
collect_time: 21.845627307891846
reward_mean: -98.6968954248366
reward_std: 2.1164700039372937
reward_max: -95.09173669467788
reward_min: -101.86974789915963
queue_len: 0.06544886964511709
wait_time: 0.6096432162608633
delay_time: 4.21342619004868
pressure: 0.7939876215738284
total_envstep_count: 1007112
total_train_sample_count: 1007112
total_episode_count: 8682
total_duration: 32811.26254558563
[2025-02-21 02:41:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95400850553848
avg_train_sample_per_sec: 31.95400850553848
avg_episode_per_sec: 0.2754655905649869
collect_time: 21.781304836273193
reward_mean: -101.8738328664799
reward_std: 2.3551860184487694
reward_max: -99.02941176470587
reward_min: -106.43067226890754
queue_len: 0.06755559208652513
wait_time: 0.6342682630081211
delay_time: 4.294951146785878
pressure: 0.8270335985853228
total_envstep_count: 1007808
total_train_sample_count: 1007808
total_episode_count: 8688
total_duration: 32833.043850421906
[2025-02-21 02:42:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.875954866591606
avg_train_sample_per_sec: 31.875954866591606
avg_episode_per_sec: 0.274792714367169
collect_time: 21.83464002609253
reward_mean: -102.39670868347338
reward_std: 3.110462055257252
reward_max: -99.13935574229689
reward_min: -108.21148459383753
queue_len: 0.06790232671317864
wait_time: 0.6387091750935565
delay_time: 4.341260195763044
pressure: 0.8271441202475684
total_envstep_count: 1008504
total_train_sample_count: 1008504
total_episode_count: 8694
total_duration: 32854.878490448
[2025-02-21 02:42:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93675217320046
avg_train_sample_per_sec: 31.93675217320046
avg_episode_per_sec: 0.2753168290793143
collect_time: 21.793073892593384
reward_mean: -102.59010270774975
reward_std: 1.212685246879167
reward_max: -100.79201680672267
reward_min: -104.46918767506999
queue_len: 0.0680305720873672
wait_time: 0.6401384492789157
delay_time: 4.383088301427384
pressure: 0.8343280282935456
total_envstep_count: 1009200
total_train_sample_count: 1009200
total_episode_count: 8700
total_duration: 32876.67156434059
[2025-02-21 02:42:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.935301565527247
avg_train_sample_per_sec: 31.935301565527247
avg_episode_per_sec: 0.27530432384075215
collect_time: 21.794063806533813
reward_mean: -101.41409897292247
reward_std: 2.6242009567846103
reward_max: -98.03291316526608
reward_min: -105.29971988795518
queue_len: 0.06725072876188494
wait_time: 0.635777719575894
delay_time: 4.269220571639628
pressure: 0.8156498673740051
total_envstep_count: 1009896
total_train_sample_count: 1009896
total_episode_count: 8706
total_duration: 32898.465628147125
[2025-02-21 02:43:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95510332060618
avg_train_sample_per_sec: 31.95510332060618
avg_episode_per_sec: 0.27547502862591533
collect_time: 21.780558586120605
reward_mean: -101.65511204481793
reward_std: 1.6176700350226245
reward_max: -99.0609243697479
reward_min: -103.70868347338936
queue_len: 0.06741055175385803
wait_time: 0.6358729168059797
delay_time: 4.279352509368713
pressure: 0.8264809902740938
total_envstep_count: 1010592
total_train_sample_count: 1010592
total_episode_count: 8712
total_duration: 32920.246186733246
[2025-02-21 02:43:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12180856826035
avg_train_sample_per_sec: 32.12180856826035
avg_episode_per_sec: 0.2769121428298306
collect_time: 21.667522192001343
reward_mean: -102.44444444444444
reward_std: 2.2863606113298176
reward_max: -99.67577030812319
reward_min: -107.08543417366946
queue_len: 0.06793398172708516
wait_time: 0.6444864086218042
delay_time: 4.378350672380294
pressure: 0.8251547303271441
total_envstep_count: 1011288
total_train_sample_count: 1011288
total_episode_count: 8718
total_duration: 32941.91370892525
[2025-02-21 02:43:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17942123538348
avg_train_sample_per_sec: 32.17942123538348
avg_episode_per_sec: 0.27740880375330584
collect_time: 21.628729581832886
reward_mean: -102.23844537815125
reward_std: 2.4567095821598532
reward_max: -98.89565826330531
reward_min: -106.33683473389357
queue_len: 0.06779737757171835
wait_time: 0.6346638345877696
delay_time: 4.35215588450412
pressure: 0.8263704686118478
total_envstep_count: 1011984
total_train_sample_count: 1011984
total_episode_count: 8724
total_duration: 32963.54243850708
[2025-02-21 02:44:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.871810676939532
avg_train_sample_per_sec: 31.871810676939532
avg_episode_per_sec: 0.2747569885943063
collect_time: 21.83747911453247
reward_mean: -101.12266573295985
reward_std: 0.9360711268465994
reward_max: -99.24649859943975
reward_min: -101.94467787114844
queue_len: 0.06705747064519885
wait_time: 0.6309628294288538
delay_time: 4.282345906449022
pressure: 0.8100132625994695
total_envstep_count: 1012680
total_train_sample_count: 1012680
total_episode_count: 8730
total_duration: 32985.37991762161
[2025-02-21 02:44:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95772488557069
avg_train_sample_per_sec: 31.95772488557069
avg_episode_per_sec: 0.27549762832388525
collect_time: 21.77877187728882
reward_mean: -103.74626517273578
reward_std: 2.883275630503183
reward_max: -99.76890756302524
reward_min: -106.72689075630255
queue_len: 0.06879725807210595
wait_time: 0.6460083259652225
delay_time: 4.407990346617144
pressure: 0.8375331564986737
total_envstep_count: 1013376
total_train_sample_count: 1013376
total_episode_count: 8736
total_duration: 33007.1586894989
[2025-02-21 02:44:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05982295312573
avg_train_sample_per_sec: 32.05982295312573
avg_episode_per_sec: 0.2763777840786701
collect_time: 21.709414958953857
reward_mean: -99.15487861811391
reward_std: 2.8446730700045975
reward_max: -95.0329131652661
reward_min: -102.59313725490196
queue_len: 0.06575257202792699
wait_time: 0.6198209610988515
delay_time: 4.259885110352452
pressure: 0.8048187444739171
total_envstep_count: 1014072
total_train_sample_count: 1014072
total_episode_count: 8742
total_duration: 33028.868104457855
[2025-02-21 02:45:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91389039411152
avg_train_sample_per_sec: 31.91389039411152
avg_episode_per_sec: 0.27511974477682344
collect_time: 21.808685541152954
reward_mean: -102.11869747899159
reward_std: 2.6506769888323127
reward_max: -99.41456582633057
reward_min: -106.98319327731092
queue_len: 0.06771796915052493
wait_time: 0.6451382387614638
delay_time: 4.329737922919142
pressure: 0.829133510167993
total_envstep_count: 1014768
total_train_sample_count: 1014768
total_episode_count: 8748
total_duration: 33050.67678999901
[2025-02-21 02:45:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79111687392497
avg_train_sample_per_sec: 31.79111687392497
avg_episode_per_sec: 0.27406135236142215
collect_time: 21.892908096313477
reward_mean: -100.17226890756304
reward_std: 1.6582060319872045
reward_max: -97.96008403361344
reward_min: -101.81652661064425
queue_len: 0.0664272340235829
wait_time: 0.6295015132489777
delay_time: 4.277563789674422
pressure: 0.8022767462422635
total_envstep_count: 1015464
total_train_sample_count: 1015464
total_episode_count: 8754
total_duration: 33072.56969809532
[2025-02-21 02:46:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.036234128199474
avg_train_sample_per_sec: 32.036234128199474
avg_episode_per_sec: 0.27617443213965065
collect_time: 21.7253999710083
reward_mean: -100.81010737628384
reward_std: 1.5836409299452654
reward_max: -99.31162464985995
reward_min: -103.25420168067225
queue_len: 0.06685020383042696
wait_time: 0.6329915365792648
delay_time: 4.314961503450719
pressure: 0.8263704686118479
total_envstep_count: 1016160
total_train_sample_count: 1016160
total_episode_count: 8760
total_duration: 33094.29509806633
[2025-02-21 02:46:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.930459474607932
avg_train_sample_per_sec: 31.930459474607932
avg_episode_per_sec: 0.2752625816776546
collect_time: 21.79736876487732
reward_mean: -101.48681139122316
reward_std: 2.410237168788808
reward_max: -98.22198879551821
reward_min: -105.64005602240894
queue_len: 0.06729894654590395
wait_time: 0.6303534123640614
delay_time: 4.3166699193758635
pressure: 0.8213969938107869
total_envstep_count: 1016856
total_train_sample_count: 1016856
total_episode_count: 8766
total_duration: 33116.09246683121
[2025-02-21 02:46:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.794209196267065
avg_train_sample_per_sec: 31.794209196267065
avg_episode_per_sec: 0.2740880103126471
collect_time: 21.89077877998352
reward_mean: -99.50887021475256
reward_std: 3.2488033148401025
reward_max: -95.94747899159661
reward_min: -104.12254901960787
queue_len: 0.06598731446601629
wait_time: 0.6155305844707467
delay_time: 4.286385901489344
pressure: 0.8022767462422634
total_envstep_count: 1017552
total_train_sample_count: 1017552
total_episode_count: 8772
total_duration: 33137.98324561119
[2025-02-21 02:47:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.973276659806785
avg_train_sample_per_sec: 31.973276659806785
avg_episode_per_sec: 0.27563169534316195
collect_time: 21.768178701400757
reward_mean: -99.11601307189541
reward_std: 1.9831060151260673
reward_max: -96.76680672268908
reward_min: -102.07843137254905
queue_len: 0.06572679911929405
wait_time: 0.6205953866957923
delay_time: 4.2669667858961615
pressure: 0.8060344827586207
total_envstep_count: 1018248
total_train_sample_count: 1018248
total_episode_count: 8778
total_duration: 33159.75142431259
[2025-02-21 02:47:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.368669255768157
avg_train_sample_per_sec: 31.368669255768157
avg_episode_per_sec: 0.2704195625497255
collect_time: 22.18774390220642
reward_mean: -102.03046218487395
reward_std: 3.1688131538463216
reward_max: -96.59103641456585
reward_min: -106.71218487394955
queue_len: 0.06765945768227717
wait_time: 0.6417277786446142
delay_time: 4.380313734171593
pressure: 0.8321175950486296
total_envstep_count: 1018944
total_train_sample_count: 1018944
total_episode_count: 8784
total_duration: 33181.9391682148
[2025-02-21 02:47:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.31162728497038
avg_train_sample_per_sec: 31.31162728497038
avg_episode_per_sec: 0.26992782142215843
collect_time: 22.228164434432983
reward_mean: -101.38515406162465
reward_std: 3.533986741851671
reward_max: -95.17507002801118
reward_min: -106.57352941176471
queue_len: 0.06723153452362378
wait_time: 0.6381525421839823
delay_time: 4.309698197480768
pressure: 0.8229442970822282
total_envstep_count: 1019640
total_train_sample_count: 1019640
total_episode_count: 8790
total_duration: 33204.16733264923
[2025-02-21 02:48:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.975439586559713
avg_train_sample_per_sec: 31.975439586559713
avg_episode_per_sec: 0.2756503412634458
collect_time: 21.766706228256226
reward_mean: -100.43720821661998
reward_std: 2.4277550607281158
reward_max: -98.01120448179273
reward_min: -104.39005602240894
queue_len: 0.06660292322057028
wait_time: 0.6274760567356916
delay_time: 4.350988339030877
pressure: 0.8086870026525199
total_envstep_count: 1020336
total_train_sample_count: 1020336
total_episode_count: 8796
total_duration: 33225.93403887749
[2025-02-21 02:48:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.716370966067558
avg_train_sample_per_sec: 31.716370966067558
avg_episode_per_sec: 0.2734169910867893
collect_time: 21.94450306892395
reward_mean: -100.26692343604107
reward_std: 1.73360407927453
reward_max: -97.15546218487388
reward_min: -102.62184873949582
queue_len: 0.06649000227854183
wait_time: 0.625589603657555
delay_time: 4.309752497746303
pressure: 0.8153183023872678
total_envstep_count: 1021032
total_train_sample_count: 1021032
total_episode_count: 8802
total_duration: 33247.87854194641
[2025-02-21 02:49:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00893256752303
avg_train_sample_per_sec: 32.00893256752303
avg_episode_per_sec: 0.2759390738579572
collect_time: 21.743930339813232
reward_mean: -101.17355275443511
reward_std: 3.987294629494497
reward_max: -95.79271708683476
reward_min: -108.41386554621843
queue_len: 0.06709121535439994
wait_time: 0.6330066288230589
delay_time: 4.347584321983601
pressure: 0.8171971706454465
total_envstep_count: 1021728
total_train_sample_count: 1021728
total_episode_count: 8808
total_duration: 33269.622472286224
[2025-02-21 02:49:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10624547727807
avg_train_sample_per_sec: 32.10624547727807
avg_episode_per_sec: 0.27677797825239714
collect_time: 21.678025245666504
reward_mean: -101.86052754435106
reward_std: 2.375118402397208
reward_max: -98.8032212885154
reward_min: -105.69047619047618
queue_len: 0.06754676892861476
wait_time: 0.6358514780801798
delay_time: 4.33496642519415
pressure: 0.8268125552608311
total_envstep_count: 1022424
total_train_sample_count: 1022424
total_episode_count: 8814
total_duration: 33291.30049753189
[2025-02-21 02:49:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.771022268503003
avg_train_sample_per_sec: 31.771022268503003
avg_episode_per_sec: 0.27388812300433624
collect_time: 21.906754970550537
reward_mean: -103.28618113912229
reward_std: 3.582193974836663
reward_max: -97.19677871148455
reward_min: -106.99159663865545
queue_len: 0.06849216255909966
wait_time: 0.6427675955439648
delay_time: 4.37193248046575
pressure: 0.8370910698496905
total_envstep_count: 1023120
total_train_sample_count: 1023120
total_episode_count: 8820
total_duration: 33313.20725250244
[2025-02-21 02:50:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.250432470575184
avg_train_sample_per_sec: 32.250432470575184
avg_episode_per_sec: 0.27802096957392397
collect_time: 21.581105947494507
reward_mean: -102.70751633986929
reward_std: 4.281483773399971
reward_max: -95.85574229691876
reward_min: -107.94467787114849
queue_len: 0.0681084325861202
wait_time: 0.6428494032449409
delay_time: 4.374221653155144
pressure: 0.830128205128205
total_envstep_count: 1023816
total_train_sample_count: 1023816
total_episode_count: 8826
total_duration: 33334.788358449936
[2025-02-21 02:50:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.928387835235647
avg_train_sample_per_sec: 31.928387835235647
avg_episode_per_sec: 0.2752447227175487
collect_time: 21.79878306388855
reward_mean: -99.18195611577964
reward_std: 2.216963129015246
reward_max: -95.2275910364146
reward_min: -101.79621848739494
queue_len: 0.06577052792823584
wait_time: 0.6191143345048012
delay_time: 4.277292462378163
pressure: 0.8015030946065428
total_envstep_count: 1024512
total_train_sample_count: 1024512
total_episode_count: 8832
total_duration: 33356.587141513824
[2025-02-21 02:50:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82021249717508
avg_train_sample_per_sec: 31.82021249717508
avg_episode_per_sec: 0.2743121766997852
collect_time: 21.872889757156372
reward_mean: -103.90266106442577
reward_std: 4.041600422727321
reward_max: -99.67016806722691
reward_min: -110.22408963585437
queue_len: 0.06890096887561391
wait_time: 0.6479176882954772
delay_time: 4.350912663001043
pressure: 0.8378647214854111
total_envstep_count: 1025208
total_train_sample_count: 1025208
total_episode_count: 8838
total_duration: 33378.46003127098
[2025-02-21 02:51:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.679735924968647
avg_train_sample_per_sec: 31.679735924968647
avg_episode_per_sec: 0.2731011717669711
collect_time: 21.96988010406494
reward_mean: -99.95891690009336
reward_std: 2.8456245664671846
reward_max: -96.36974789915966
reward_min: -105.23179271708686
queue_len: 0.06628575391252876
wait_time: 0.6200639075258751
delay_time: 4.347993856472162
pressure: 0.8008399646330681
total_envstep_count: 1025904
total_train_sample_count: 1025904
total_episode_count: 8844
total_duration: 33400.429911375046
[2025-02-21 02:51:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.923304168679756
avg_train_sample_per_sec: 31.923304168679756
avg_episode_per_sec: 0.27520089800585995
collect_time: 21.80225443840027
reward_mean: -101.23552754435106
reward_std: 3.1599189760112534
reward_max: -95.48389355742297
reward_min: -105.05952380952378
queue_len: 0.067132312695193
wait_time: 0.631964877020658
delay_time: 4.337941243776053
pressure: 0.8194076038903625
total_envstep_count: 1026600
total_train_sample_count: 1026600
total_episode_count: 8850
total_duration: 33422.232165813446
[2025-02-21 02:52:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11840659657732
avg_train_sample_per_sec: 32.11840659657732
avg_episode_per_sec: 0.2768828154877355
collect_time: 21.669817209243774
reward_mean: -99.01318860877684
reward_std: 1.8767339952443418
reward_max: -96.83263305322127
reward_min: -102.34103641456585
queue_len: 0.06565861313579366
wait_time: 0.6145795409233542
delay_time: 4.225000004203051
pressure: 0.8058134394341292
total_envstep_count: 1027296
total_train_sample_count: 1027296
total_episode_count: 8856
total_duration: 33443.90198302269
[2025-02-21 02:52:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.672585320295855
avg_train_sample_per_sec: 31.672585320295855
avg_episode_per_sec: 0.27303952862324016
collect_time: 21.97484016418457
reward_mean: -98.65266106442577
reward_std: 3.915575569341101
reward_max: -94.23949579831933
reward_min: -105.88305322128849
queue_len: 0.06541953651487119
wait_time: 0.6153769531685354
delay_time: 4.255651433067438
pressure: 0.8070291777188329
total_envstep_count: 1027992
total_train_sample_count: 1027992
total_episode_count: 8862
total_duration: 33465.876823186874
[2025-02-21 02:52:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0052123392009
avg_train_sample_per_sec: 32.0052123392009
avg_episode_per_sec: 0.2759070029241457
collect_time: 21.746457815170288
reward_mean: -102.0016339869281
reward_std: 1.7675422692413432
reward_max: -99.77310924369749
reward_min: -104.42927170868344
queue_len: 0.067640340840138
wait_time: 0.638896783293335
delay_time: 4.2870166387795425
pressure: 0.8286914235190097
total_envstep_count: 1028688
total_train_sample_count: 1028688
total_episode_count: 8868
total_duration: 33487.623281002045
[2025-02-21 02:53:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.933185284262322
avg_train_sample_per_sec: 31.933185284262322
avg_episode_per_sec: 0.27528608003674415
collect_time: 21.79550814628601
reward_mean: -101.95109710550885
reward_std: 3.4933376215830463
reward_max: -96.54061624649863
reward_min: -106.18277310924366
queue_len: 0.06760682831930297
wait_time: 0.6347772199065302
delay_time: 4.341957940512187
pressure: 0.8294650751547303
total_envstep_count: 1029384
total_train_sample_count: 1029384
total_episode_count: 8874
total_duration: 33509.41878914833
[2025-02-21 02:53:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.934654214987134
avg_train_sample_per_sec: 31.934654214987134
avg_episode_per_sec: 0.2752987432326477
collect_time: 21.79450559616089
reward_mean: -101.82726423902893
reward_std: 3.3184485382248643
reward_max: -96.29061624649862
reward_min: -106.62394957983192
queue_len: 0.06752471103383882
wait_time: 0.6401212673398272
delay_time: 4.340590951388807
pressure: 0.8303492484526966
total_envstep_count: 1030080
total_train_sample_count: 1030080
total_episode_count: 8880
total_duration: 33531.21329474449
[2025-02-21 02:53:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23998626658707
avg_train_sample_per_sec: 32.23998626658707
avg_episode_per_sec: 0.2779309160912678
collect_time: 21.588098526000977
reward_mean: -99.73155929038283
reward_std: 1.6192722295539896
reward_max: -98.10644257703082
reward_min: -102.87815126050417
queue_len: 0.06613498626683212
wait_time: 0.6208399584413784
delay_time: 4.231872856157961
pressure: 0.8082449160035367
total_envstep_count: 1030776
total_train_sample_count: 1030776
total_episode_count: 8886
total_duration: 33552.80139327049
[2025-02-21 02:54:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.115326500702686
avg_train_sample_per_sec: 32.115326500702686
avg_episode_per_sec: 0.2768562629370921
collect_time: 21.671895503997803
reward_mean: -102.47478991596638
reward_std: 2.9606018675783647
reward_max: -98.37394957983192
reward_min: -107.46078431372547
queue_len: 0.0679541047188106
wait_time: 0.6419431720521983
delay_time: 4.342924400277901
pressure: 0.8306808134394341
total_envstep_count: 1031472
total_train_sample_count: 1031472
total_episode_count: 8892
total_duration: 33574.47328877449
[2025-02-21 02:54:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81782255916286
avg_train_sample_per_sec: 31.81782255916286
avg_episode_per_sec: 0.2742915737858867
collect_time: 21.87453269958496
reward_mean: -101.04318394024277
reward_std: 2.9332344548463083
reward_max: -97.40546218487397
reward_min: -105.21218487394957
queue_len: 0.06700476388610262
wait_time: 0.6309467310354734
delay_time: 4.284826353662868
pressure: 0.8254862953138815
total_envstep_count: 1032168
total_train_sample_count: 1032168
total_episode_count: 8898
total_duration: 33596.347821474075
[2025-02-21 02:55:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.985129418931663
avg_train_sample_per_sec: 31.985129418931663
avg_episode_per_sec: 0.27573387430113505
collect_time: 21.760112047195435
reward_mean: -100.55718954248367
reward_std: 1.7544702017798872
reward_max: -97.77310924369748
reward_min: -103.14075630252105
queue_len: 0.06668248643400773
wait_time: 0.6257959417188627
delay_time: 4.240012284787066
pressure: 0.8236074270557029
total_envstep_count: 1032864
total_train_sample_count: 1032864
total_episode_count: 8904
total_duration: 33618.10793352127
[2025-02-21 02:55:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.131276104073464
avg_train_sample_per_sec: 32.131276104073464
avg_episode_per_sec: 0.2769937595178747
collect_time: 21.66113781929016
reward_mean: -101.74486461251166
reward_std: 1.7671010798045774
reward_max: -98.54201680672267
reward_min: -103.6687675070028
queue_len: 0.06747006937169207
wait_time: 0.6335926722590007
delay_time: 4.3011111609798185
pressure: 0.8290229885057471
total_envstep_count: 1033560
total_train_sample_count: 1033560
total_episode_count: 8910
total_duration: 33639.76907134056
[2025-02-21 02:55:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16381893669795
avg_train_sample_per_sec: 32.16381893669795
avg_episode_per_sec: 0.2772743011784306
collect_time: 21.63922142982483
reward_mean: -99.8699813258637
reward_std: 4.770799240957706
reward_max: -93.42647058823533
reward_min: -107.08123249299717
queue_len: 0.06622677806754887
wait_time: 0.6250046437673212
delay_time: 4.290514651006272
pressure: 0.818081343943413
total_envstep_count: 1034256
total_train_sample_count: 1034256
total_episode_count: 8916
total_duration: 33661.408292770386
[2025-02-21 02:56:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83799413658876
avg_train_sample_per_sec: 31.83799413658876
avg_episode_per_sec: 0.2744654666947307
collect_time: 21.860673666000366
reward_mean: -101.69934640522875
reward_std: 1.7969891610480797
reward_max: -99.28361344537815
reward_min: -103.95098039215685
queue_len: 0.06743988488410393
wait_time: 0.6375322896621071
delay_time: 4.296863647778526
pressure: 0.8294650751547303
total_envstep_count: 1034952
total_train_sample_count: 1034952
total_episode_count: 8922
total_duration: 33683.268966436386
[2025-02-21 02:56:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74814846232928
avg_train_sample_per_sec: 31.74814846232928
avg_episode_per_sec: 0.27369093502007996
collect_time: 21.92253828048706
reward_mean: -101.47292250233427
reward_std: 2.0619039923776596
reward_max: -98.04971988795518
reward_min: -104.08543417366946
queue_len: 0.06728973640738346
wait_time: 0.6382425538738926
delay_time: 4.309652528736578
pressure: 0.819628647214854
total_envstep_count: 1035648
total_train_sample_count: 1035648
total_episode_count: 8928
total_duration: 33705.19150471687
[2025-02-21 02:56:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.635229529691998
avg_train_sample_per_sec: 31.635229529691998
avg_episode_per_sec: 0.27271749594562067
collect_time: 22.000788688659668
reward_mean: -99.53863211951447
reward_std: 3.306341542319543
reward_max: -94.60784313725493
reward_min: -105.03361344537814
queue_len: 0.06600705047713161
wait_time: 0.6214171787194099
delay_time: 4.263756387735111
pressure: 0.8053713527851459
total_envstep_count: 1036344
total_train_sample_count: 1036344
total_episode_count: 8934
total_duration: 33727.19229340553
[2025-02-21 02:57:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.36050636790955
avg_train_sample_per_sec: 32.36050636790955
avg_episode_per_sec: 0.2789698824819789
collect_time: 21.50769805908203
reward_mean: -99.15627917833798
reward_std: 3.061386820260577
reward_max: -93.39775910364146
reward_min: -102.95938375350138
queue_len: 0.06575350078139124
wait_time: 0.6174720661916401
delay_time: 4.230607080344401
pressure: 0.8044871794871794
total_envstep_count: 1037040
total_train_sample_count: 1037040
total_episode_count: 8940
total_duration: 33748.699991464615
[2025-02-21 02:57:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10753614586217
avg_train_sample_per_sec: 32.10753614586217
avg_episode_per_sec: 0.27678910470570833
collect_time: 21.677153825759888
reward_mean: -99.67705415499533
reward_std: 2.256578110575323
reward_max: -96.82633053221289
reward_min: -103.55182072829132
queue_len: 0.06609884227784836
wait_time: 0.6202502773877016
delay_time: 4.309068428140727
pressure: 0.808134394341291
total_envstep_count: 1037736
total_train_sample_count: 1037736
total_episode_count: 8946
total_duration: 33770.377145290375
[2025-02-21 02:57:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03618736924619
avg_train_sample_per_sec: 32.03618736924619
avg_episode_per_sec: 0.2761740290452258
collect_time: 21.72543168067932
reward_mean: -98.55182072829132
reward_std: 2.8295646722817076
reward_max: -95.29691876750697
reward_min: -103.60504201680675
queue_len: 0.06535266626544516
wait_time: 0.6154644881825408
delay_time: 4.220430166882394
pressure: 0.8015030946065429
total_envstep_count: 1038432
total_train_sample_count: 1038432
total_episode_count: 8952
total_duration: 33792.102576971054
[2025-02-21 02:58:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91482440391658
avg_train_sample_per_sec: 31.91482440391658
avg_episode_per_sec: 0.27512779658548775
collect_time: 21.8080472946167
reward_mean: -101.50501867413634
reward_std: 1.7029726461016164
reward_max: -99.19467787114849
reward_min: -104.08473389355743
queue_len: 0.06731102034093922
wait_time: 0.6344365995735163
delay_time: 4.346508024155917
pressure: 0.818633952254642
total_envstep_count: 1039128
total_train_sample_count: 1039128
total_episode_count: 8958
total_duration: 33813.91062426567
[2025-02-21 02:58:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.810400815099985
avg_train_sample_per_sec: 31.810400815099985
avg_episode_per_sec: 0.27422759323362056
collect_time: 21.87963628768921
reward_mean: -99.17623716153129
reward_std: 2.2486638353519077
reward_max: -96.35294117647058
reward_min: -102.921568627451
queue_len: 0.06576673551825683
wait_time: 0.6201854194374479
delay_time: 4.2122105644989665
pressure: 0.8032714412024756
total_envstep_count: 1039824
total_train_sample_count: 1039824
total_episode_count: 8964
total_duration: 33835.79026055336
[2025-02-21 02:59:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.03552857053918
avg_train_sample_per_sec: 31.03552857053918
avg_episode_per_sec: 0.267547660090855
collect_time: 22.42591094970703
reward_mean: -102.05847338935574
reward_std: 2.8217506155632375
reward_max: -98.78781512605045
reward_min: -107.578431372549
queue_len: 0.06767803275156216
wait_time: 0.63524368633395
delay_time: 4.382843272588214
pressure: 0.8271441202475686
total_envstep_count: 1040520
total_train_sample_count: 1040520
total_episode_count: 8970
total_duration: 33858.21617150307
[2025-02-21 02:59:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73879904335955
avg_train_sample_per_sec: 31.73879904335955
avg_episode_per_sec: 0.2736103365806858
collect_time: 21.928996086120605
reward_mean: -100.62394957983194
reward_std: 2.926649297480689
reward_max: -97.72128851540614
reward_min: -106.1050420168067
queue_len: 0.06672675701580366
wait_time: 0.6306773925308408
delay_time: 4.2776373888061885
pressure: 0.8192970822281168
total_envstep_count: 1041216
total_train_sample_count: 1041216
total_episode_count: 8976
total_duration: 33880.14516758919
[2025-02-21 02:59:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.736413383271117
avg_train_sample_per_sec: 31.736413383271117
avg_episode_per_sec: 0.27358977054544065
collect_time: 21.930644512176514
reward_mean: -102.4764239028945
reward_std: 3.1741695463033293
reward_max: -99.02450980392156
reward_min: -108.35504201680675
queue_len: 0.06795518826451889
wait_time: 0.6445315305609425
delay_time: 4.351422764816992
pressure: 0.8332228116710875
total_envstep_count: 1041912
total_train_sample_count: 1041912
total_episode_count: 8982
total_duration: 33902.075812101364
[2025-02-21 03:00:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.934483385897
avg_train_sample_per_sec: 31.934483385897
avg_episode_per_sec: 0.27529727056807757
collect_time: 21.79462218284607
reward_mean: -102.66631652661067
reward_std: 3.6083955974339137
reward_max: -99.85574229691878
reward_min: -110.47899159663869
queue_len: 0.06808111175504686
wait_time: 0.6411035789205161
delay_time: 4.429119608646563
pressure: 0.8358753315649867
total_envstep_count: 1042608
total_train_sample_count: 1042608
total_episode_count: 8988
total_duration: 33923.87043428421
[2025-02-21 03:00:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.934765656626055
avg_train_sample_per_sec: 31.934765656626055
avg_episode_per_sec: 0.2752997039364315
collect_time: 21.794429540634155
reward_mean: -98.86006069094304
reward_std: 2.969073696146487
reward_max: -93.12535014005601
reward_min: -101.80252100840337
queue_len: 0.06555706942370228
wait_time: 0.615690949235574
delay_time: 4.220027051774398
pressure: 0.8045977011494251
total_envstep_count: 1043304
total_train_sample_count: 1043304
total_episode_count: 8994
total_duration: 33945.664863824844
[2025-02-21 03:00:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00301135106402
avg_train_sample_per_sec: 32.00301135106402
avg_episode_per_sec: 0.2758880288884829
collect_time: 21.747953414916992
reward_mean: -100.953548085901
reward_std: 1.7375132981242725
reward_max: -98.31932773109246
reward_min: -103.17927170868344
queue_len: 0.06694532366439059
wait_time: 0.6336130274390923
delay_time: 4.315996750525509
pressure: 0.8239389920424403
total_envstep_count: 1044000
total_train_sample_count: 1044000
total_episode_count: 9000
total_duration: 33967.41281723976
[2025-02-21 03:01:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.736864678211226
avg_train_sample_per_sec: 31.736864678211226
avg_episode_per_sec: 0.2735936610190623
collect_time: 21.93033266067505
reward_mean: -100.11041083099906
reward_std: 3.073340645367163
reward_max: -94.34873949579834
reward_min: -103.1155462184874
queue_len: 0.06638621407891183
wait_time: 0.6250773187258988
delay_time: 4.292794316940881
pressure: 0.808023872679045
total_envstep_count: 1044696
total_train_sample_count: 1044696
total_episode_count: 9006
total_duration: 33989.34314990044
[2025-02-21 03:01:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.247907236207567
avg_train_sample_per_sec: 31.247907236207567
avg_episode_per_sec: 0.2693785106569618
collect_time: 22.273491621017456
reward_mean: -100.07142857142856
reward_std: 3.6100582212875243
reward_max: -96.81792717086833
reward_min: -106.59803921568626
queue_len: 0.06636036377415687
wait_time: 0.6217928594956992
delay_time: 4.30489182680718
pressure: 0.8081343943412908
total_envstep_count: 1045392
total_train_sample_count: 1045392
total_episode_count: 9012
total_duration: 34011.616641521454
[2025-02-21 03:02:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16254783503696
avg_train_sample_per_sec: 32.16254783503696
avg_episode_per_sec: 0.2772633434054911
collect_time: 21.640076637268066
reward_mean: -100.73949579831935
reward_std: 1.9044029344695
reward_max: -98.96148459383754
reward_min: -104.57843137254903
queue_len: 0.06680337917660434
wait_time: 0.632929232701038
delay_time: 4.284442389858983
pressure: 0.8189655172413793
total_envstep_count: 1046088
total_train_sample_count: 1046088
total_episode_count: 9018
total_duration: 34033.25671815872
[2025-02-21 03:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.545009117814246
avg_train_sample_per_sec: 31.545009117814246
avg_episode_per_sec: 0.27193973377426073
collect_time: 22.063712120056152
reward_mean: -100.84628851540617
reward_std: 4.302340211937187
reward_max: -95.62605042016807
reward_min: -107.42226890756301
queue_len: 0.06687419662825343
wait_time: 0.6302459865466966
delay_time: 4.296459306489386
pressure: 0.8186339522546419
total_envstep_count: 1046784
total_train_sample_count: 1046784
total_episode_count: 9024
total_duration: 34055.32043027878
[2025-02-21 03:02:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74332187835142
avg_train_sample_per_sec: 31.74332187835142
avg_episode_per_sec: 0.2736493265375123
collect_time: 21.92587161064148
reward_mean: -102.12651727357608
reward_std: 1.535902285774712
reward_max: -99.92997198879553
reward_min: -103.9334733893557
queue_len: 0.06772315469070031
wait_time: 0.6413629333254081
delay_time: 4.292152962851446
pressure: 0.8290229885057471
total_envstep_count: 1047480
total_train_sample_count: 1047480
total_episode_count: 9030
total_duration: 34077.24630188942
[2025-02-21 03:03:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11493751145426
avg_train_sample_per_sec: 32.11493751145426
avg_episode_per_sec: 0.2768529095815022
collect_time: 21.672158002853394
reward_mean: -98.73155929038283
reward_std: 2.5523749817875134
reward_max: -94.28711484593838
reward_min: -101.65196078431374
queue_len: 0.06547185629335732
wait_time: 0.6126154595348307
delay_time: 4.235347233981835
pressure: 0.7970822281167109
total_envstep_count: 1048176
total_train_sample_count: 1048176
total_episode_count: 9036
total_duration: 34098.91845989227
[2025-02-21 03:03:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.662915624391115
avg_train_sample_per_sec: 31.662915624391115
avg_episode_per_sec: 0.27295616917578547
collect_time: 21.98155117034912
reward_mean: -99.22385620915031
reward_std: 2.2084559804182353
reward_max: -96.91386554621846
reward_min: -103.57773109243696
queue_len: 0.06579831313604133
wait_time: 0.6165896730044803
delay_time: 4.301668151326599
pressure: 0.8015030946065429
total_envstep_count: 1048872
total_train_sample_count: 1048872
total_episode_count: 9042
total_duration: 34120.90001106262
[2025-02-21 03:03:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.900551919154548
avg_train_sample_per_sec: 31.900551919154548
avg_episode_per_sec: 0.2750047579237461
collect_time: 21.81780433654785
reward_mean: -100.42600373482725
reward_std: 1.581041163875188
reward_max: -98.83123249299719
reward_min: -103.06162464985991
queue_len: 0.06659549319285628
wait_time: 0.630352251422231
delay_time: 4.315266196980416
pressure: 0.8107869142351901
total_envstep_count: 1049568
total_train_sample_count: 1049568
total_episode_count: 9048
total_duration: 34142.71781539917
[2025-02-21 03:04:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.467225745671836
avg_train_sample_per_sec: 31.467225745671836
avg_episode_per_sec: 0.27126918746268824
collect_time: 22.118251085281372
reward_mean: -101.15873015873017
reward_std: 1.4145134006487898
reward_max: -99.33263305322129
reward_min: -103.80882352941175
queue_len: 0.0670813860469033
wait_time: 0.6333044491005954
delay_time: 4.325185147524541
pressure: 0.8183023872679045
total_envstep_count: 1050264
total_train_sample_count: 1050264
total_episode_count: 9054
total_duration: 34164.83606648445
[2025-02-21 03:04:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0122836539313
avg_train_sample_per_sec: 32.0122836539313
avg_episode_per_sec: 0.2759679625338905
collect_time: 21.74165415763855
reward_mean: -101.44666199813258
reward_std: 2.7212062626858247
reward_max: -97.41806722689077
reward_min: -104.31092436974785
queue_len: 0.06727232227992876
wait_time: 0.6366653756993514
delay_time: 4.332422636688364
pressure: 0.8303492484526968
total_envstep_count: 1050960
total_train_sample_count: 1050960
total_episode_count: 9060
total_duration: 34186.57772064209
[2025-02-21 03:05:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98818634311538
avg_train_sample_per_sec: 31.98818634311538
avg_episode_per_sec: 0.27576022709582226
collect_time: 21.75803256034851
reward_mean: -100.51342203548087
reward_std: 2.4809173909686546
reward_max: -97.3235294117647
reward_min: -104.0672268907563
queue_len: 0.06665346288824991
wait_time: 0.6271001437710362
delay_time: 4.326013768242587
pressure: 0.8084659593280284
total_envstep_count: 1051656
total_train_sample_count: 1051656
total_episode_count: 9066
total_duration: 34208.33575320244
[2025-02-21 03:05:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.537213241941924
avg_train_sample_per_sec: 31.537213241941924
avg_episode_per_sec: 0.2718725279477752
collect_time: 22.06916618347168
reward_mean: -100.51143790849672
reward_std: 2.282423764035306
reward_max: -96.65616246498598
reward_min: -103.67927170868344
queue_len: 0.06665214715417554
wait_time: 0.6291816350766654
delay_time: 4.286951736707771
pressure: 0.8195181255526083
total_envstep_count: 1052352
total_train_sample_count: 1052352
total_episode_count: 9072
total_duration: 34230.40491938591
[2025-02-21 03:05:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10523914559313
avg_train_sample_per_sec: 32.10523914559313
avg_episode_per_sec: 0.2767693029792511
collect_time: 21.678704738616943
reward_mean: -100.82574696545286
reward_std: 1.6655705942766545
reward_max: -98.34663865546214
reward_min: -103.73109243697476
queue_len: 0.06686057491077778
wait_time: 0.6325976677143006
delay_time: 4.284014829535814
pressure: 0.8189655172413793
total_envstep_count: 1053048
total_train_sample_count: 1053048
total_episode_count: 9078
total_duration: 34252.08362412453
[2025-02-21 03:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.165132667544945
avg_train_sample_per_sec: 32.165132667544945
avg_episode_per_sec: 0.277285626444353
collect_time: 21.6383376121521
reward_mean: -101.17390289449112
reward_std: 2.7926895667755285
reward_max: -96.9362745098039
reward_min: -105.23389355742295
queue_len: 0.06709144754276598
wait_time: 0.6278366452681868
delay_time: 4.29953942464119
pressure: 0.817970822281167
total_envstep_count: 1053744
total_train_sample_count: 1053744
total_episode_count: 9084
total_duration: 34273.72196173668
[2025-02-21 03:06:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.715906470723308
avg_train_sample_per_sec: 31.715906470723308
avg_episode_per_sec: 0.2734129868165802
collect_time: 21.94482445716858
reward_mean: -102.49859943977593
reward_std: 3.264018973792572
reward_max: -96.67647058823528
reward_min: -106.98669467787116
queue_len: 0.06796989352770286
wait_time: 0.6394463731558052
delay_time: 4.387737719947114
pressure: 0.8317860300618921
total_envstep_count: 1054440
total_train_sample_count: 1054440
total_episode_count: 9090
total_duration: 34295.66678619385
[2025-02-21 03:06:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.939251915732736
avg_train_sample_per_sec: 31.939251915732736
avg_episode_per_sec: 0.2753383785839029
collect_time: 21.79136824607849
reward_mean: -100.75350140056021
reward_std: 3.938768553234492
reward_max: -96.0196078431373
reward_min: -104.95868347338936
queue_len: 0.06681266671124683
wait_time: 0.6305131579599127
delay_time: 4.272378171677499
pressure: 0.8243810786914235
total_envstep_count: 1055136
total_train_sample_count: 1055136
total_episode_count: 9096
total_duration: 34317.458154439926
[2025-02-21 03:07:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.849517794228262
avg_train_sample_per_sec: 31.849517794228262
avg_episode_per_sec: 0.2745648085709333
collect_time: 21.852764129638672
reward_mean: -102.49171335200748
reward_std: 3.6465814377384946
reward_max: -98.96358543417367
reward_min: -109.11694677871151
queue_len: 0.06796532715650364
wait_time: 0.6377145575294664
delay_time: 4.304202873876202
pressure: 0.8393015030946066
total_envstep_count: 1055832
total_train_sample_count: 1055832
total_episode_count: 9102
total_duration: 34339.310918569565
[2025-02-21 03:07:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00436180191789
avg_train_sample_per_sec: 32.00436180191789
avg_episode_per_sec: 0.2758996707061887
collect_time: 21.74703574180603
reward_mean: -102.00606909430438
reward_std: 3.278276601712423
reward_max: -97.1652661064426
reward_min: -106.52801120448184
queue_len: 0.0676432818927748
wait_time: 0.6313727192910762
delay_time: 4.361205515164058
pressure: 0.8265915119363396
total_envstep_count: 1056528
total_train_sample_count: 1056528
total_episode_count: 9108
total_duration: 34361.05795431137
[2025-02-21 03:08:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.872700118254663
avg_train_sample_per_sec: 31.872700118254663
avg_episode_per_sec: 0.27476465619185053
collect_time: 21.836869716644287
reward_mean: -102.4109477124183
reward_std: 2.872755050739986
reward_max: -97.24019607843135
reward_min: -106.56092436974792
queue_len: 0.06791176904006518
wait_time: 0.6371135766419741
delay_time: 4.335026333499254
pressure: 0.8270335985853227
total_envstep_count: 1057224
total_train_sample_count: 1057224
total_episode_count: 9114
total_duration: 34382.894824028015
[2025-02-21 03:08:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.920493833499826
avg_train_sample_per_sec: 31.920493833499826
avg_episode_per_sec: 0.2751766709784468
collect_time: 21.804173946380615
reward_mean: -101.72875816993464
reward_std: 2.2105193976087563
reward_max: -99.4264705882353
reward_min: -106.20238095238093
queue_len: 0.06745938870685321
wait_time: 0.6367997353671796
delay_time: 4.359010860605127
pressure: 0.8192970822281168
total_envstep_count: 1057920
total_train_sample_count: 1057920
total_episode_count: 9120
total_duration: 34404.698997974396
[2025-02-21 03:08:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.127221542170815
avg_train_sample_per_sec: 32.127221542170815
avg_episode_per_sec: 0.2769588063980243
collect_time: 21.66387152671814
reward_mean: -102.10714285714285
reward_std: 2.0163816062355444
reward_max: -99.093837535014
reward_min: -105.73739495798316
queue_len: 0.06771030693444487
wait_time: 0.6417620651266697
delay_time: 4.277906238397427
pressure: 0.8299071618037136
total_envstep_count: 1058616
total_train_sample_count: 1058616
total_episode_count: 9126
total_duration: 34426.362869501114
[2025-02-21 03:09:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86777853932359
avg_train_sample_per_sec: 31.86777853932359
avg_episode_per_sec: 0.27472222878727237
collect_time: 21.84024214744568
reward_mean: -101.23937908496733
reward_std: 2.011774167761597
reward_max: -98.82703081232494
reward_min: -103.95868347338933
queue_len: 0.0671348667672197
wait_time: 0.6318750201229917
delay_time: 4.29641997008192
pressure: 0.8216180371352785
total_envstep_count: 1059312
total_train_sample_count: 1059312
total_episode_count: 9132
total_duration: 34448.20311164856
[2025-02-21 03:09:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.661482917627787
avg_train_sample_per_sec: 31.661482917627787
avg_episode_per_sec: 0.272943818255412
collect_time: 21.982545852661133
reward_mean: -100.45856676003734
reward_std: 1.2137930770532213
reward_max: -98.54411764705885
reward_min: -102.22969187675069
queue_len: 0.0666170867109001
wait_time: 0.6285282570145654
delay_time: 4.240492780653706
pressure: 0.8219496021220158
total_envstep_count: 1060008
total_train_sample_count: 1060008
total_episode_count: 9138
total_duration: 34470.18565750122
[2025-02-21 03:09:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.660949291538497
avg_train_sample_per_sec: 31.660949291538497
avg_episode_per_sec: 0.2729392180305043
collect_time: 21.982916355133057
reward_mean: -99.69070961718018
reward_std: 2.9819807919720596
reward_max: -95.94607843137256
reward_min: -103.70798319327727
queue_len: 0.06610789762412479
wait_time: 0.6205036722911976
delay_time: 4.262678397617671
pressure: 0.8058134394341291
total_envstep_count: 1060704
total_train_sample_count: 1060704
total_episode_count: 9144
total_duration: 34492.168573856354
[2025-02-21 03:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01615580982504
avg_train_sample_per_sec: 32.01615580982504
avg_episode_per_sec: 0.27600134318814684
collect_time: 21.73902463912964
reward_mean: -100.15499533146591
reward_std: 3.146039108933478
reward_max: -96.03361344537812
reward_min: -104.8221288515406
queue_len: 0.06641577939752381
wait_time: 0.6267959770114943
delay_time: 4.261770683740693
pressure: 0.815318302387268
total_envstep_count: 1061400
total_train_sample_count: 1061400
total_episode_count: 9150
total_duration: 34513.90759849548
[2025-02-21 03:10:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.107425613956295
avg_train_sample_per_sec: 32.107425613956295
avg_episode_per_sec: 0.27678815184445077
collect_time: 21.677228450775146
reward_mean: -100.36402894491131
reward_std: 1.4996005177883145
reward_max: -97.44607843137258
reward_min: -102.07563025210086
queue_len: 0.0665543958520632
wait_time: 0.6270218188955511
delay_time: 4.274444943154045
pressure: 0.8123342175066313
total_envstep_count: 1062096
total_train_sample_count: 1062096
total_episode_count: 9156
total_duration: 34535.58482694626
[2025-02-21 03:11:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.011450643181945
avg_train_sample_per_sec: 32.011450643181945
avg_episode_per_sec: 0.2759607814067409
collect_time: 21.742219924926758
reward_mean: -99.7516339869281
reward_std: 3.0401282978676054
reward_max: -95.7976190476191
reward_min: -103.16456582633054
queue_len: 0.06614829839981971
wait_time: 0.6231133147334973
delay_time: 4.247892151274642
pressure: 0.8011715296198055
total_envstep_count: 1062792
total_train_sample_count: 1062792
total_episode_count: 9162
total_duration: 34557.327046871185
[2025-02-21 03:11:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.418457573421634
avg_train_sample_per_sec: 32.418457573421634
avg_episode_per_sec: 0.27946946183984167
collect_time: 21.469250917434692
reward_mean: -97.99019607843137
reward_std: 2.3448138601162354
reward_max: -95.37535014005601
reward_min: -101.17647058823529
queue_len: 0.06498023612628075
wait_time: 0.6073766708274821
delay_time: 4.1982546639969565
pressure: 0.7997347480106102
total_envstep_count: 1063488
total_train_sample_count: 1063488
total_episode_count: 9168
total_duration: 34578.79629778862
[2025-02-21 03:11:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.105604595594244
avg_train_sample_per_sec: 32.105604595594244
avg_episode_per_sec: 0.2767724534102952
collect_time: 21.678457975387573
reward_mean: -101.42880485527543
reward_std: 2.6351019128096334
reward_max: -96.5609243697479
reward_min: -103.73529411764706
queue_len: 0.06726048067325958
wait_time: 0.6345791632302787
delay_time: 4.30489566528687
pressure: 0.8314544650751547
total_envstep_count: 1064184
total_train_sample_count: 1064184
total_episode_count: 9174
total_duration: 34600.47475576401
[2025-02-21 03:12:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02864619836716
avg_train_sample_per_sec: 32.02864619836716
avg_episode_per_sec: 0.2761090189514411
collect_time: 21.730546951293945
reward_mean: -100.03793183940245
reward_std: 3.020607520688458
reward_max: -95.08823529411767
reward_min: -103.79341736694681
queue_len: 0.0663381510871369
wait_time: 0.6230796474204182
delay_time: 4.281991469519568
pressure: 0.8141025641025642
total_envstep_count: 1064880
total_train_sample_count: 1064880
total_episode_count: 9180
total_duration: 34622.2053027153
[2025-02-21 03:12:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.39516434158846
avg_train_sample_per_sec: 32.39516434158846
avg_episode_per_sec: 0.2792686581171419
collect_time: 21.48468804359436
reward_mean: -99.30403828197944
reward_std: 3.830539198965908
reward_max: -94.8529411764706
reward_min: -105.63445378151258
queue_len: 0.06585148427186967
wait_time: 0.6166968666334792
delay_time: 4.210471482037668
pressure: 0.8229442970822282
total_envstep_count: 1065576
total_train_sample_count: 1065576
total_episode_count: 9186
total_duration: 34643.689990758896
[2025-02-21 03:12:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.943519224031434
avg_train_sample_per_sec: 31.943519224031434
avg_episode_per_sec: 0.2753751657244089
collect_time: 21.78845715522766
reward_mean: -102.10130718954245
reward_std: 3.271577394972488
reward_max: -97.02731092436974
reward_min: -106.04411764705881
queue_len: 0.0677064371283438
wait_time: 0.639463942075504
delay_time: 4.314187381180104
pressure: 0.8290229885057471
total_envstep_count: 1066272
total_train_sample_count: 1066272
total_episode_count: 9192
total_duration: 34665.47844791412
[2025-02-21 03:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.018310143721656
avg_train_sample_per_sec: 32.018310143721656
avg_episode_per_sec: 0.27601991503208323
collect_time: 21.73756194114685
reward_mean: -101.33695144724554
reward_std: 2.5097766128620798
reward_max: -97.65266106442574
reward_min: -105.47899159663862
queue_len: 0.06719956992522914
wait_time: 0.6323743025061482
delay_time: 4.33075217062042
pressure: 0.8198496905393456
total_envstep_count: 1066968
total_train_sample_count: 1066968
total_episode_count: 9198
total_duration: 34687.21600985527
[2025-02-21 03:13:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.020551871740345
avg_train_sample_per_sec: 32.020551871740345
avg_episode_per_sec: 0.27603924027362364
collect_time: 21.736040115356445
reward_mean: -100.28174603174602
reward_std: 2.547832499847924
reward_max: -96.56512605042013
reward_min: -104.16596638655462
queue_len: 0.06649983158603848
wait_time: 0.6275584836056438
delay_time: 4.2789996700965744
pressure: 0.8094606542882404
total_envstep_count: 1067664
total_train_sample_count: 1067664
total_episode_count: 9204
total_duration: 34708.95204997063
[2025-02-21 03:13:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.868085028062286
avg_train_sample_per_sec: 31.868085028062286
avg_episode_per_sec: 0.27472487093157144
collect_time: 21.84003210067749
reward_mean: -99.32189542483661
reward_std: 1.2658772987271163
reward_max: -97.99299719887955
reward_min: -101.44957983193277
queue_len: 0.06586332587853887
wait_time: 0.6219181638172511
delay_time: 4.218735559630114
pressure: 0.8111184792219275
total_envstep_count: 1068360
total_train_sample_count: 1068360
total_episode_count: 9210
total_duration: 34730.792082071304
[2025-02-21 03:14:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.881308967334483
avg_train_sample_per_sec: 31.881308967334483
avg_episode_per_sec: 0.2748388704080559
collect_time: 21.830973148345947
reward_mean: -100.53583099906626
reward_std: 3.23524499198422
reward_max: -97.03851540616247
reward_min: -106.94817927170864
queue_len: 0.0666683229436779
wait_time: 0.6263445254317466
delay_time: 4.3037551266900165
pressure: 0.812444739168877
total_envstep_count: 1069056
total_train_sample_count: 1069056
total_episode_count: 9216
total_duration: 34752.62305521965
[2025-02-21 03:14:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.587474515785726
avg_train_sample_per_sec: 31.587474515785726
avg_episode_per_sec: 0.27230581479125626
collect_time: 22.034050226211548
reward_mean: -100.51563958916898
reward_std: 2.4812452719651414
reward_max: -96.65196078431374
reward_min: -103.09803921568628
queue_len: 0.0666549334145683
wait_time: 0.6301936667682103
delay_time: 4.29978164443454
pressure: 0.8118921308576481
total_envstep_count: 1069752
total_train_sample_count: 1069752
total_episode_count: 9222
total_duration: 34774.65710544586
[2025-02-21 03:15:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.773825711479525
avg_train_sample_per_sec: 31.773825711479525
avg_episode_per_sec: 0.2739122906162028
collect_time: 21.90482211112976
reward_mean: -101.83928571428571
reward_std: 1.8109778400117997
reward_max: -98.88445378151258
reward_min: -104.30392156862743
queue_len: 0.06753268283440696
wait_time: 0.6361101359199736
delay_time: 4.329769906144455
pressure: 0.8198496905393456
total_envstep_count: 1070448
total_train_sample_count: 1070448
total_episode_count: 9228
total_duration: 34796.56192755699
[2025-02-21 03:15:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.150755225872448
avg_train_sample_per_sec: 31.150755225872448
avg_episode_per_sec: 0.2685409933264866
collect_time: 22.342957496643066
reward_mean: -99.72607376283845
reward_std: 2.663422324346415
reward_max: -95.0609243697479
reward_min: -103.17086834733894
queue_len: 0.06613134864909712
wait_time: 0.6212880045917571
delay_time: 4.288467872882653
pressure: 0.8037135278514588
total_envstep_count: 1071144
total_train_sample_count: 1071144
total_episode_count: 9234
total_duration: 34818.904885053635
[2025-02-21 03:15:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25096655604929
avg_train_sample_per_sec: 32.25096655604929
avg_episode_per_sec: 0.27802557375904563
collect_time: 21.580748558044434
reward_mean: -101.0969887955182
reward_std: 3.2366505060355406
reward_max: -97.26610644257704
reward_min: -107.3725490196078
queue_len: 0.06704044349835424
wait_time: 0.6277356433289497
delay_time: 4.311056582053328
pressure: 0.8226127320954908
total_envstep_count: 1071840
total_train_sample_count: 1071840
total_episode_count: 9240
total_duration: 34840.48563361168
[2025-02-21 03:16:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.660141332089413
avg_train_sample_per_sec: 31.660141332089413
avg_episode_per_sec: 0.2729322528628398
collect_time: 21.983477354049683
reward_mean: -101.59337068160596
reward_std: 2.9518386579536107
reward_max: -99.20028011204481
reward_min: -107.89565826330531
queue_len: 0.067369609205309
wait_time: 0.6319681276577828
delay_time: 4.31877265683236
pressure: 0.8178603006189213
total_envstep_count: 1072536
total_train_sample_count: 1072536
total_episode_count: 9246
total_duration: 34862.46911096573
[2025-02-21 03:16:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.851095456150528
avg_train_sample_per_sec: 31.851095456150528
avg_episode_per_sec: 0.2745784091047459
collect_time: 21.85168170928955
reward_mean: -97.82633053221288
reward_std: 1.5108004200172882
reward_max: -95.90756302521011
reward_min: -99.85504201680673
queue_len: 0.06487157197096345
wait_time: 0.6104557981459604
delay_time: 4.194035176945268
pressure: 0.7938770999115827
total_envstep_count: 1073232
total_train_sample_count: 1073232
total_episode_count: 9252
total_duration: 34884.32079267502
[2025-02-21 03:16:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.2114361496557
avg_train_sample_per_sec: 32.2114361496557
avg_episode_per_sec: 0.27768479439358357
collect_time: 21.607232809066772
reward_mean: -99.64717553688143
reward_std: 1.213354168618196
reward_max: -98.40826330532215
reward_min: -101.98949579831933
queue_len: 0.06607902887061103
wait_time: 0.6183691646419841
delay_time: 4.242062398063223
pressure: 0.812444739168877
total_envstep_count: 1073928
total_train_sample_count: 1073928
total_episode_count: 9258
total_duration: 34905.928025484085
[2025-02-21 03:17:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.779621938148804
avg_train_sample_per_sec: 31.779621938148804
avg_episode_per_sec: 0.2739622580874897
collect_time: 21.900826930999756
reward_mean: -100.44246031746032
reward_std: 2.3893333168316686
reward_max: -97.16106442577029
reward_min: -103.43417366946778
queue_len: 0.0666064060460612
wait_time: 0.6218871279723206
delay_time: 4.282835578538009
pressure: 0.8191865605658708
total_envstep_count: 1074624
total_train_sample_count: 1074624
total_episode_count: 9264
total_duration: 34927.828852415085
[2025-02-21 03:17:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.981203449891925
avg_train_sample_per_sec: 31.981203449891925
avg_episode_per_sec: 0.2757000297404476
collect_time: 21.76278328895569
reward_mean: -101.14379084967318
reward_std: 4.0437025236851145
reward_max: -96.8578431372549
reward_min: -109.47268907563021
queue_len: 0.06707147934328461
wait_time: 0.6303401002310737
delay_time: 4.347859361337725
pressure: 0.821949602122016
total_envstep_count: 1075320
total_train_sample_count: 1075320
total_episode_count: 9270
total_duration: 34949.59163570404
[2025-02-21 03:18:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.110273907351306
avg_train_sample_per_sec: 32.110273907351306
avg_episode_per_sec: 0.2768127060978561
collect_time: 21.675305604934692
reward_mean: -100.6296685340803
reward_std: 0.6151107351452881
reward_max: -99.26680672268903
reward_min: -101.06442577030812
queue_len: 0.06673054942578269
wait_time: 0.6234949550111821
delay_time: 4.2939859011088215
pressure: 0.8152077807250221
total_envstep_count: 1076016
total_train_sample_count: 1076016
total_episode_count: 9276
total_duration: 34971.266941308975
[2025-02-21 03:18:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73118819840277
avg_train_sample_per_sec: 31.73118819840277
avg_episode_per_sec: 0.27354472584829975
collect_time: 21.934255838394165
reward_mean: -101.41783380018673
reward_std: 3.142051297859054
reward_max: -98.6015406162465
reward_min: -107.17086834733894
queue_len: 0.0672532054377896
wait_time: 0.6267780985073074
delay_time: 4.2998047733724665
pressure: 0.8289124668435014
total_envstep_count: 1076712
total_train_sample_count: 1076712
total_episode_count: 9282
total_duration: 34993.20119714737
[2025-02-21 03:18:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.884561295213906
avg_train_sample_per_sec: 31.884561295213906
avg_episode_per_sec: 0.2748669077173613
collect_time: 21.82874631881714
reward_mean: -99.2783613445378
reward_std: 2.7764188848104507
reward_max: -94.93837535014009
reward_min: -103.67927170868347
queue_len: 0.06583445712502507
wait_time: 0.6156719097895569
delay_time: 4.244697442675224
pressure: 0.7992926613616268
total_envstep_count: 1077408
total_train_sample_count: 1077408
total_episode_count: 9288
total_duration: 35015.02994346619
[2025-02-21 03:19:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07699862637136
avg_train_sample_per_sec: 32.07699862637136
avg_episode_per_sec: 0.27652585022733933
collect_time: 21.69779062271118
reward_mean: -102.47292250233424
reward_std: 3.641752005062695
reward_max: -97.90266106442577
reward_min: -108.5483193277311
queue_len: 0.06795286638085826
wait_time: 0.6420520683958818
delay_time: 4.3870615261765336
pressure: 0.8248231653404067
total_envstep_count: 1078104
total_train_sample_count: 1078104
total_episode_count: 9294
total_duration: 35036.7277340889
[2025-02-21 03:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08108106474526
avg_train_sample_per_sec: 32.08108106474526
avg_episode_per_sec: 0.2765610436615971
collect_time: 21.695029497146606
reward_mean: -101.6435574229692
reward_std: 2.3425022217043026
reward_max: -98.36274509803924
reward_min: -105.13795518207283
queue_len: 0.06740288953777797
wait_time: 0.6346775337013674
delay_time: 4.322480096684004
pressure: 0.8249336870026526
total_envstep_count: 1078800
total_train_sample_count: 1078800
total_episode_count: 9300
total_duration: 35058.422763586044
[2025-02-21 03:19:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.681107708744776
avg_train_sample_per_sec: 31.681107708744776
avg_episode_per_sec: 0.2731129974891791
collect_time: 21.968928813934326
reward_mean: -99.75245098039215
reward_std: 2.0925765242289756
reward_max: -95.67086834733895
reward_min: -101.69467787114846
queue_len: 0.06614884017267385
wait_time: 0.62393874437485
delay_time: 4.2027200177158255
pressure: 0.8134394341290894
total_envstep_count: 1079496
total_train_sample_count: 1079496
total_episode_count: 9306
total_duration: 35080.39169239998
[2025-02-21 03:20:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10581257037221
avg_train_sample_per_sec: 32.10581257037221
avg_episode_per_sec: 0.27677424629631214
collect_time: 21.678317546844482
reward_mean: -101.70681605975722
reward_std: 2.2311642246665464
reward_max: -97.79551820728291
reward_min: -104.4243697478992
queue_len: 0.06744483823591328
wait_time: 0.6319589949153843
delay_time: 4.338264212377559
pressure: 0.8122236958443856
total_envstep_count: 1080192
total_train_sample_count: 1080192
total_episode_count: 9312
total_duration: 35102.07000994682
[2025-02-21 03:20:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.975983866476966
avg_train_sample_per_sec: 31.975983866476966
avg_episode_per_sec: 0.275655033331698
collect_time: 21.7663357257843
reward_mean: -100.80765639589168
reward_std: 3.1340376866137203
reward_max: -96.52661064425766
reward_min: -104.70308123249302
queue_len: 0.0668485785118645
wait_time: 0.6317347009537678
delay_time: 4.234655286721947
pressure: 0.8189655172413793
total_envstep_count: 1080888
total_train_sample_count: 1080888
total_episode_count: 9318
total_duration: 35123.83634567261
[2025-02-21 03:21:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.838128863953784
avg_train_sample_per_sec: 31.838128863953784
avg_episode_per_sec: 0.27446662813753264
collect_time: 21.860581159591675
reward_mean: -98.46171802054153
reward_std: 1.9695878577174557
reward_max: -96.18907563025212
reward_min: -102.18277310924367
queue_len: 0.06529291645924505
wait_time: 0.610757488229598
delay_time: 4.2326085879106765
pressure: 0.7971927497789566
total_envstep_count: 1081584
total_train_sample_count: 1081584
total_episode_count: 9324
total_duration: 35145.6969268322
[2025-02-21 03:21:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.925431709592264
avg_train_sample_per_sec: 31.925431709592264
avg_episode_per_sec: 0.27521923887579536
collect_time: 21.800801515579224
reward_mean: -101.19456115779643
reward_std: 2.8810508910301413
reward_max: -97.19677871148458
reward_min: -106.63865546218486
queue_len: 0.06710514665636368
wait_time: 0.6322832072705298
delay_time: 4.351090441034781
pressure: 0.8166445623342176
total_envstep_count: 1082280
total_train_sample_count: 1082280
total_episode_count: 9330
total_duration: 35167.49772834778
[2025-02-21 03:21:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.2081505575433
avg_train_sample_per_sec: 32.2081505575433
avg_episode_per_sec: 0.27765647032364915
collect_time: 21.609436988830566
reward_mean: -101.72303921568626
reward_std: 1.6059419009925646
reward_max: -99.33403361344534
reward_min: -104.55882352941177
queue_len: 0.06745559629687418
wait_time: 0.6372549019607842
delay_time: 4.237039767153192
pressure: 0.8274756852343059
total_envstep_count: 1082976
total_train_sample_count: 1082976
total_episode_count: 9336
total_duration: 35189.10716533661
[2025-02-21 03:22:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80793159765462
avg_train_sample_per_sec: 31.80793159765462
avg_episode_per_sec: 0.2742063068763329
collect_time: 21.88133478164673
reward_mean: -102.98366013071897
reward_std: 1.52721693360485
reward_max: -99.95448179271709
reward_min: -104.7626050420168
queue_len: 0.0682915518108216
wait_time: 0.6518983256432547
delay_time: 4.345359269059435
pressure: 0.8390804597701149
total_envstep_count: 1083672
total_train_sample_count: 1083672
total_episode_count: 9342
total_duration: 35210.988500118256
[2025-02-21 03:22:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929658306397936
avg_train_sample_per_sec: 31.929658306397936
avg_episode_per_sec: 0.2752556750551546
collect_time: 21.79791569709778
reward_mean: -100.38702147525679
reward_std: 3.063779929266009
reward_max: -95.8340336134454
reward_min: -104.64145658263303
queue_len: 0.06656964288810131
wait_time: 0.6366860404639308
delay_time: 4.2764571137871625
pressure: 0.8116710875331564
total_envstep_count: 1084368
total_train_sample_count: 1084368
total_episode_count: 9348
total_duration: 35232.78641581535
[2025-02-21 03:22:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.734496902875
avg_train_sample_per_sec: 31.734496902875
avg_episode_per_sec: 0.2735732491627155
collect_time: 21.931968927383423
reward_mean: -99.9578664799253
reward_std: 3.1927675302138843
reward_max: -96.34943977591035
reward_min: -104.7850140056022
queue_len: 0.06628505734743058
wait_time: 0.627384497123341
delay_time: 4.27422334791054
pressure: 0.8062555260831124
total_envstep_count: 1085064
total_train_sample_count: 1085064
total_episode_count: 9354
total_duration: 35254.71838474274
[2025-02-21 03:23:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76011232881264
avg_train_sample_per_sec: 31.76011232881264
avg_episode_per_sec: 0.27379407180010895
collect_time: 21.91428017616272
reward_mean: -99.04505135387488
reward_std: 1.8231707503663177
reward_max: -96.61904761904762
reward_min: -101.266106442577
queue_len: 0.06567974227710537
wait_time: 0.6201210258639266
delay_time: 4.222280888055741
pressure: 0.802497789566755
total_envstep_count: 1085760
total_train_sample_count: 1085760
total_episode_count: 9360
total_duration: 35276.6326649189
[2025-02-21 03:23:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78477345426266
avg_train_sample_per_sec: 31.78477345426266
avg_episode_per_sec: 0.2740066677091608
collect_time: 21.897277355194092
reward_mean: -100.36192810457517
reward_std: 3.3112912612602425
reward_max: -97.22689075630255
reward_min: -107.19117647058826
queue_len: 0.06655300272186682
wait_time: 0.6238291514660683
delay_time: 4.272197759649566
pressure: 0.8141025641025642
total_envstep_count: 1086456
total_train_sample_count: 1086456
total_episode_count: 9366
total_duration: 35298.52994227409
[2025-02-21 03:24:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.674710160458467
avg_train_sample_per_sec: 31.674710160458467
avg_episode_per_sec: 0.27305784621084883
collect_time: 21.973366022109985
reward_mean: -101.7485994397759
reward_std: 1.9094222489146175
reward_max: -99.50770308123248
reward_min: -105.0952380952381
queue_len: 0.06747254604759677
wait_time: 0.639663778862562
delay_time: 4.373569995241315
pressure: 0.8260389036251107
total_envstep_count: 1087152
total_train_sample_count: 1087152
total_episode_count: 9372
total_duration: 35320.5033082962
[2025-02-21 03:24:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85656114338518
avg_train_sample_per_sec: 31.85656114338518
avg_episode_per_sec: 0.2746255270981481
collect_time: 21.84793257713318
reward_mean: -99.43814192343604
reward_std: 1.490229022531558
reward_max: -96.85644257703083
reward_min: -101.22408963585438
queue_len: 0.06594041241607164
wait_time: 0.6210377055331416
delay_time: 4.2140859980266105
pressure: 0.8036030061892131
total_envstep_count: 1087848
total_train_sample_count: 1087848
total_episode_count: 9378
total_duration: 35342.35124087334
[2025-02-21 03:24:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06959571116351
avg_train_sample_per_sec: 32.06959571116351
avg_episode_per_sec: 0.27646203199278885
collect_time: 21.702799320220947
reward_mean: -97.95413165266105
reward_std: 3.03088930811163
reward_max: -94.25840336134452
reward_min: -102.55882352941177
queue_len: 0.0649563207245763
wait_time: 0.6107973472324385
delay_time: 4.184282872593134
pressure: 0.7961980548187445
total_envstep_count: 1088544
total_train_sample_count: 1088544
total_episode_count: 9384
total_duration: 35364.05404019356
[2025-02-21 03:25:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.988982388872845
avg_train_sample_per_sec: 31.988982388872845
avg_episode_per_sec: 0.27576708955924867
collect_time: 21.75749111175537
reward_mean: -100.39950980392159
reward_std: 3.5452037784509187
reward_max: -94.41596638655466
reward_min: -104.63865546218487
queue_len: 0.06657792427315755
wait_time: 0.6246408819938232
delay_time: 4.252862907077639
pressure: 0.8175287356321839
total_envstep_count: 1089240
total_train_sample_count: 1089240
total_episode_count: 9390
total_duration: 35385.81153130531
[2025-02-21 03:25:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26845185345243
avg_train_sample_per_sec: 32.26845185345243
avg_episode_per_sec: 0.2781763090814865
collect_time: 21.56905460357666
reward_mean: -102.72817460317458
reward_std: 2.3605015181399835
reward_max: -98.67156862745098
reward_min: -106.20098039215686
queue_len: 0.06812213169971791
wait_time: 0.6431225341595526
delay_time: 4.371531883213515
pressure: 0.8414014146772767
total_envstep_count: 1089936
total_train_sample_count: 1089936
total_episode_count: 9396
total_duration: 35407.38058590889
[2025-02-21 03:25:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.237034817318005
avg_train_sample_per_sec: 32.237034817318005
avg_episode_per_sec: 0.27790547256308623
collect_time: 21.59007501602173
reward_mean: -98.38783846872083
reward_std: 2.252923614135958
reward_max: -95.35224089635855
reward_min: -102.51610644257703
queue_len: 0.06524392471400586
wait_time: 0.6145147603692229
delay_time: 4.191511018190218
pressure: 0.7990716180371353
total_envstep_count: 1090632
total_train_sample_count: 1090632
total_episode_count: 9402
total_duration: 35428.97066092491
[2025-02-21 03:26:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.666647726788284
avg_train_sample_per_sec: 31.666647726788284
avg_episode_per_sec: 0.2729883424723128
collect_time: 21.978960514068604
reward_mean: -100.01120448179272
reward_std: 3.2158131266114034
reward_max: -95.4775910364146
reward_min: -105.93487394957982
queue_len: 0.06632042737519413
wait_time: 0.6288007687602007
delay_time: 4.2368586720623425
pressure: 0.8142130857648099
total_envstep_count: 1091328
total_train_sample_count: 1091328
total_episode_count: 9408
total_duration: 35450.94962143898
[2025-02-21 03:26:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70225783091174
avg_train_sample_per_sec: 31.70225783091174
avg_episode_per_sec: 0.27329532612854945
collect_time: 21.954272270202637
reward_mean: -101.93464052287582
reward_std: 1.9535283941716015
reward_max: -98.8977591036414
reward_min: -104.44957983193274
queue_len: 0.06759591546609801
wait_time: 0.63831484185186
delay_time: 4.290320446246164
pressure: 0.8284703801945182
total_envstep_count: 1092024
total_train_sample_count: 1092024
total_episode_count: 9414
total_duration: 35472.90389370918
[2025-02-21 03:27:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865529628075556
avg_train_sample_per_sec: 31.865529628075556
avg_episode_per_sec: 0.274702841621341
collect_time: 21.84178352355957
reward_mean: -101.75081699346406
reward_std: 1.9177907176168607
reward_max: -98.60224089635855
reward_min: -103.42366946778711
queue_len: 0.06747401657391516
wait_time: 0.6391087712715503
delay_time: 4.340899740991657
pressure: 0.8208443854995578
total_envstep_count: 1092720
total_train_sample_count: 1092720
total_episode_count: 9420
total_duration: 35494.74567723274
[2025-02-21 03:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.614682623136318
avg_train_sample_per_sec: 31.614682623136318
avg_episode_per_sec: 0.2725403674408303
collect_time: 22.015087366104126
reward_mean: -101.29458450046684
reward_std: 2.690471623604219
reward_max: -99.01960784313724
reward_min: -106.82563025210082
queue_len: 0.06717147513293557
wait_time: 0.6358214483848358
delay_time: 4.281934254395128
pressure: 0.8188549955791334
total_envstep_count: 1093416
total_train_sample_count: 1093416
total_episode_count: 9426
total_duration: 35516.76076459885
[2025-02-21 03:27:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.90853685489457
avg_train_sample_per_sec: 31.90853685489457
avg_episode_per_sec: 0.2750735935766773
collect_time: 21.812344551086426
reward_mean: -100.75863678804855
reward_std: 2.9015479115025617
reward_max: -95.66316526610645
reward_min: -104.73389355742295
queue_len: 0.06681607214061576
wait_time: 0.6335462345857884
delay_time: 4.321768810926336
pressure: 0.8174182139699381
total_envstep_count: 1094112
total_train_sample_count: 1094112
total_episode_count: 9432
total_duration: 35538.57310914993
[2025-02-21 03:28:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.894068581856356
avg_train_sample_per_sec: 31.894068581856356
avg_episode_per_sec: 0.2749488670849686
collect_time: 21.8222393989563
reward_mean: -99.18253968253968
reward_std: 0.9042029774863701
reward_max: -97.45448179271709
reward_min: -100.43347338935578
queue_len: 0.06577091490884594
wait_time: 0.6235492870888409
delay_time: 4.2130466936455715
pressure: 0.8099027409372237
total_envstep_count: 1094808
total_train_sample_count: 1094808
total_episode_count: 9438
total_duration: 35560.39534854889
[2025-02-21 03:28:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.878529344914035
avg_train_sample_per_sec: 31.878529344914035
avg_episode_per_sec: 0.27481490814581067
collect_time: 21.832876682281494
reward_mean: -100.39787581699348
reward_std: 1.5215362847387444
reward_max: -98.34523809523809
reward_min: -102.85014005602245
queue_len: 0.06657684072744927
wait_time: 0.6286536387322391
delay_time: 4.3550116228835005
pressure: 0.8104553492484526
total_envstep_count: 1095504
total_train_sample_count: 1095504
total_episode_count: 9444
total_duration: 35582.22822523117
[2025-02-21 03:28:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.556878336777338
avg_train_sample_per_sec: 31.556878336777338
avg_episode_per_sec: 0.27204205462739084
collect_time: 22.055413484573364
reward_mean: -100.10294117647057
reward_std: 2.876632166167042
reward_max: -96.6974789915966
reward_min: -105.89635854341736
queue_len: 0.0663812607271025
wait_time: 0.6256844913031525
delay_time: 4.230840030334231
pressure: 0.8180813439434128
total_envstep_count: 1096200
total_train_sample_count: 1096200
total_episode_count: 9450
total_duration: 35604.283638715744
[2025-02-21 03:29:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.998911982459365
avg_train_sample_per_sec: 30.998911982459365
avg_episode_per_sec: 0.26723199984878765
collect_time: 22.45240092277527
reward_mean: -99.7155695611578
reward_std: 2.0503254326112312
reward_max: -97.73949579831931
reward_min: -103.75490196078432
queue_len: 0.06612438299811525
wait_time: 0.6246260993345172
delay_time: 4.238520900395431
pressure: 0.8177497789566756
total_envstep_count: 1096896
total_train_sample_count: 1096896
total_episode_count: 9456
total_duration: 35626.73603963852
[2025-02-21 03:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.913792007019723
avg_train_sample_per_sec: 31.913792007019723
avg_episode_per_sec: 0.275118896612239
collect_time: 21.80875277519226
reward_mean: -99.79248366013071
reward_std: 2.5222737664561548
reward_max: -96.87324929971989
reward_min: -104.54761904761908
queue_len: 0.066175387042527
wait_time: 0.626613631748013
delay_time: 4.259275812966196
pressure: 0.8037135278514588
total_envstep_count: 1097592
total_train_sample_count: 1097592
total_episode_count: 9462
total_duration: 35648.54479241371
[2025-02-21 03:30:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.605931072128605
avg_train_sample_per_sec: 31.605931072128605
avg_episode_per_sec: 0.2724649230355914
collect_time: 22.021183252334595
reward_mean: -99.81209150326795
reward_std: 3.3384833201595447
reward_max: -94.27661064425767
reward_min: -104.94187675070029
queue_len: 0.06618838959102649
wait_time: 0.6264086094207798
delay_time: 4.242671693654919
pressure: 0.8099027409372237
total_envstep_count: 1098288
total_train_sample_count: 1098288
total_episode_count: 9468
total_duration: 35670.565975666046
[2025-02-21 03:30:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95785013255909
avg_train_sample_per_sec: 31.95785013255909
avg_episode_per_sec: 0.2754987080393025
collect_time: 21.7786865234375
reward_mean: -101.05100373482726
reward_std: 4.615904904942945
reward_max: -95.93837535014006
reward_min: -108.13655462184876
queue_len: 0.06700994942627803
wait_time: 0.6360434204627917
delay_time: 4.315055524611613
pressure: 0.8265915119363395
total_envstep_count: 1098984
total_train_sample_count: 1098984
total_episode_count: 9474
total_duration: 35692.344662189484
[2025-02-21 03:30:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.873769183834657
avg_train_sample_per_sec: 31.873769183834657
avg_episode_per_sec: 0.2747738722744367
collect_time: 21.836137294769287
reward_mean: -98.3080065359477
reward_std: 2.649316523961789
reward_max: -95.63725490196083
reward_min: -103.31932773109243
queue_len: 0.06519098576654359
wait_time: 0.6220452482496093
delay_time: 4.192139646314631
pressure: 0.7963085764809903
total_envstep_count: 1099680
total_train_sample_count: 1099680
total_episode_count: 9480
total_duration: 35714.18079948425
[2025-02-21 03:31:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.014749591768116
avg_train_sample_per_sec: 32.014749591768116
avg_episode_per_sec: 0.27598922061869063
collect_time: 21.73997950553894
reward_mean: -98.58368347338937
reward_std: 1.8228356219437072
reward_max: -96.52941176470591
reward_min: -102.2738095238095
queue_len: 0.06537379540675688
wait_time: 0.6151653521709303
delay_time: 4.1712013413683104
pressure: 0.8029398762157381
total_envstep_count: 1100376
total_train_sample_count: 1100376
total_episode_count: 9486
total_duration: 35735.92077898979
[2025-02-21 03:31:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.937228400934764
avg_train_sample_per_sec: 31.937228400934764
avg_episode_per_sec: 0.2753209344908169
collect_time: 21.79274892807007
reward_mean: -99.6343370681606
reward_std: 1.546886665278267
reward_max: -98.03291316526612
reward_min: -102.06162464985997
queue_len: 0.06607051529718873
wait_time: 0.6309285429467985
delay_time: 4.224180954392746
pressure: 0.8058134394341292
total_envstep_count: 1101072
total_train_sample_count: 1101072
total_episode_count: 9492
total_duration: 35757.71352791786
[2025-02-21 03:31:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.760943713280597
avg_train_sample_per_sec: 31.760943713280597
avg_episode_per_sec: 0.27380123890759134
collect_time: 21.9137065410614
reward_mean: -98.65989729225022
reward_std: 3.1530549841057574
reward_max: -95.20658263305323
reward_min: -104.76260504201679
queue_len: 0.0654243350744365
wait_time: 0.6207590020977444
delay_time: 4.170551649307215
pressure: 0.8061450044208666
total_envstep_count: 1101768
total_train_sample_count: 1101768
total_episode_count: 9498
total_duration: 35779.62723445892
[2025-02-21 03:32:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.982149462818295
avg_train_sample_per_sec: 31.982149462818295
avg_episode_per_sec: 0.27570818502429567
collect_time: 21.762139558792114
reward_mean: -99.61928104575163
reward_std: 4.062410229146809
reward_max: -95.29831932773111
reward_min: -107.88935574229696
queue_len: 0.06606053119744804
wait_time: 0.6255216498624206
delay_time: 4.227944961678059
pressure: 0.8104553492484526
total_envstep_count: 1102464
total_train_sample_count: 1102464
total_episode_count: 9504
total_duration: 35801.389374017715
[2025-02-21 03:32:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97286834215875
avg_train_sample_per_sec: 31.97286834215875
avg_episode_per_sec: 0.2756281753634375
collect_time: 21.76845669746399
reward_mean: -100.41503267973856
reward_std: 3.4965361323324213
reward_max: -96.61554621848741
reward_min: -107.03571428571426
queue_len: 0.06658821795738631
wait_time: 0.6255223464275188
delay_time: 4.297631055590439
pressure: 0.8132183908045979
total_envstep_count: 1103160
total_train_sample_count: 1103160
total_episode_count: 9510
total_duration: 35823.15783071518
[2025-02-21 03:32:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0497063895348
avg_train_sample_per_sec: 32.0497063895348
avg_episode_per_sec: 0.27629057232357584
collect_time: 21.716267585754395
reward_mean: -98.59547152194212
reward_std: 2.0140559907200024
reward_max: -95.92016806722692
reward_min: -102.1155462184874
queue_len: 0.06538161241508099
wait_time: 0.6139235313931054
delay_time: 4.192039941152252
pressure: 0.7999557913351016
total_envstep_count: 1103856
total_train_sample_count: 1103856
total_episode_count: 9516
total_duration: 35844.874098300934
[2025-02-21 03:33:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.944014878866287
avg_train_sample_per_sec: 31.944014878866287
avg_episode_per_sec: 0.27537943861091624
collect_time: 21.788119077682495
reward_mean: -100.88398692810455
reward_std: 4.432003428801901
reward_max: -97.63235294117648
reward_min: -110.60084033613443
queue_len: 0.06689919557566613
wait_time: 0.6304934993449192
delay_time: 4.2849571107622895
pressure: 0.8233863837312113
total_envstep_count: 1104552
total_train_sample_count: 1104552
total_episode_count: 9522
total_duration: 35866.662217378616
[2025-02-21 03:33:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.997309768436434
avg_train_sample_per_sec: 31.997309768436434
avg_episode_per_sec: 0.27583887731410717
collect_time: 21.75182867050171
reward_mean: -101.29119981325867
reward_std: 1.5276272868212848
reward_max: -98.936974789916
reward_min: -103.32843137254906
queue_len: 0.06716923064539698
wait_time: 0.6346622092692072
delay_time: 4.31196199702308
pressure: 0.824049513704686
total_envstep_count: 1105248
total_train_sample_count: 1105248
total_episode_count: 9528
total_duration: 35888.41404604912
[2025-02-21 03:34:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08197869895557
avg_train_sample_per_sec: 32.08197869895557
avg_episode_per_sec: 0.27656878188754797
collect_time: 21.694422483444214
reward_mean: -98.60924369747902
reward_std: 1.9508592763010248
reward_max: -95.68557422969192
reward_min: -101.4761904761905
queue_len: 0.06539074515747945
wait_time: 0.619125324754128
delay_time: 4.223457008079214
pressure: 0.8072502210433244
total_envstep_count: 1105944
total_train_sample_count: 1105944
total_episode_count: 9534
total_duration: 35910.10846853256
[2025-02-21 03:34:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.031355057712574
avg_train_sample_per_sec: 32.031355057712574
avg_episode_per_sec: 0.2761323711871774
collect_time: 21.72870922088623
reward_mean: -100.32469654528478
reward_std: 3.82377872701242
reward_max: -96.12394957983192
reward_min: -106.65686274509805
queue_len: 0.06652831335894216
wait_time: 0.6306128441650753
delay_time: 4.272084205352464
pressure: 0.818081343943413
total_envstep_count: 1106640
total_train_sample_count: 1106640
total_episode_count: 9540
total_duration: 35931.83717775345
[2025-02-21 03:34:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968459105981708
avg_train_sample_per_sec: 31.968459105981708
avg_episode_per_sec: 0.27559016470673886
collect_time: 21.771459102630615
reward_mean: -99.52637721755367
reward_std: 3.3485006829457316
reward_max: -96.07072829131654
reward_min: -104.21778711484592
queue_len: 0.06599892388431942
wait_time: 0.6263874028833462
delay_time: 4.248980939377941
pressure: 0.8132183908045977
total_envstep_count: 1107336
total_train_sample_count: 1107336
total_episode_count: 9546
total_duration: 35953.60863685608
[2025-02-21 03:35:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89021196430966
avg_train_sample_per_sec: 31.89021196430966
avg_episode_per_sec: 0.2749156203819798
collect_time: 21.824878454208374
reward_mean: -99.76108776844073
reward_std: 2.032748096079844
reward_max: -95.73949579831934
reward_min: -101.94467787114853
queue_len: 0.06615456748570339
wait_time: 0.6200659198250477
delay_time: 4.281827804538843
pressure: 0.8065870910698497
total_envstep_count: 1108032
total_train_sample_count: 1108032
total_episode_count: 9552
total_duration: 35975.43351531029
[2025-02-21 03:35:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.860438834432927
avg_train_sample_per_sec: 31.860438834432927
avg_episode_per_sec: 0.27465895546924934
collect_time: 21.84527349472046
reward_mean: -100.08099906629316
reward_std: 2.2844964689155414
reward_max: -97.64425770308125
reward_min: -104.21918767507003
queue_len: 0.06636671025616257
wait_time: 0.6253694116904057
delay_time: 4.313387153548777
pressure: 0.818081343943413
total_envstep_count: 1108728
total_train_sample_count: 1108728
total_episode_count: 9558
total_duration: 35997.27878880501
[2025-02-21 03:35:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.191031550310974
avg_train_sample_per_sec: 32.191031550310974
avg_episode_per_sec: 0.2775088926750946
collect_time: 21.62092876434326
reward_mean: -98.07971521942109
reward_std: 2.77145827267842
reward_max: -95.08893557422972
reward_min: -102.92436974789916
queue_len: 0.06503959895187075
wait_time: 0.6080560539865815
delay_time: 4.1872881614712325
pressure: 0.7973032714412024
total_envstep_count: 1109424
total_train_sample_count: 1109424
total_episode_count: 9564
total_duration: 36018.89971756935
[2025-02-21 03:36:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14541814394913
avg_train_sample_per_sec: 32.14541814394913
avg_episode_per_sec: 0.2771156736547339
collect_time: 21.65160822868347
reward_mean: -100.42460317460319
reward_std: 2.1507173563517776
reward_max: -97.41246498599442
reward_min: -103.562324929972
queue_len: 0.06659456443939203
wait_time: 0.6321265575195595
delay_time: 4.283384164891749
pressure: 0.8152077807250221
total_envstep_count: 1110120
total_train_sample_count: 1110120
total_episode_count: 9570
total_duration: 36040.551325798035
[2025-02-21 03:36:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.33449677915033
avg_train_sample_per_sec: 32.33449677915033
avg_episode_per_sec: 0.27874566188922695
collect_time: 21.524998664855957
reward_mean: -98.07913165266105
reward_std: 1.294851192258159
reward_max: -96.2093837535014
reward_min: -100.47829131652658
queue_len: 0.06503921197126065
wait_time: 0.6082821280590044
delay_time: 4.204610516141563
pressure: 0.7997347480106102
total_envstep_count: 1110816
total_train_sample_count: 1110816
total_episode_count: 9576
total_duration: 36062.07632446289
[2025-02-21 03:37:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93860091071167
avg_train_sample_per_sec: 31.93860091071167
avg_episode_per_sec: 0.27533276647165233
collect_time: 21.791812419891357
reward_mean: -98.82212885154063
reward_std: 2.164305348444374
reward_max: -96.44467787114844
reward_min: -102.22969187675072
queue_len: 0.0655319156840455
wait_time: 0.6156978374904338
delay_time: 4.242670993404592
pressure: 0.8026083112290009
total_envstep_count: 1111512
total_train_sample_count: 1111512
total_episode_count: 9582
total_duration: 36083.86813688278
[2025-02-21 03:37:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.3145348135775
avg_train_sample_per_sec: 32.3145348135775
avg_episode_per_sec: 0.2785735759791164
collect_time: 21.53829550743103
reward_mean: -99.87009803921569
reward_std: 0.7598180937720361
reward_max: -98.64705882352945
reward_min: -101.20868347338931
queue_len: 0.06622685546367087
wait_time: 0.6282429749087964
delay_time: 4.2825196489347475
pressure: 0.8073607427055703
total_envstep_count: 1112208
total_train_sample_count: 1112208
total_episode_count: 9588
total_duration: 36105.40643239021
[2025-02-21 03:37:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.927600738626282
avg_train_sample_per_sec: 31.927600738626282
avg_episode_per_sec: 0.27523793740195074
collect_time: 21.799320459365845
reward_mean: -99.03828197945846
reward_std: 1.980761893468831
reward_max: -95.64285714285718
reward_min: -101.26540616246498
queue_len: 0.06567525330202816
wait_time: 0.6154384056894199
delay_time: 4.279900465792715
pressure: 0.802497789566755
total_envstep_count: 1112904
total_train_sample_count: 1112904
total_episode_count: 9594
total_duration: 36127.20575284958
[2025-02-21 03:38:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.720109477376603
avg_train_sample_per_sec: 31.720109477376603
avg_episode_per_sec: 0.2734492196325569
collect_time: 21.941916704177856
reward_mean: -98.58345004668536
reward_std: 1.362406876231031
reward_max: -96.07352941176475
reward_min: -100.63725490196082
queue_len: 0.06537364061451284
wait_time: 0.6149386589295313
delay_time: 4.220129423903736
pressure: 0.803050397877984
total_envstep_count: 1113600
total_train_sample_count: 1113600
total_episode_count: 9600
total_duration: 36149.14766955376
[2025-02-21 03:38:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.28536160375247
avg_train_sample_per_sec: 32.28536160375247
avg_episode_per_sec: 0.2783220827909696
collect_time: 21.55775761604309
reward_mean: -101.77987861811391
reward_std: 3.330983027369951
reward_max: -96.27310924369753
reward_min: -105.91246498599438
queue_len: 0.06749328820829835
wait_time: 0.636260052208328
delay_time: 4.345712074171783
pressure: 0.8265915119363395
total_envstep_count: 1114296
total_train_sample_count: 1114296
total_episode_count: 9606
total_duration: 36170.7054271698
[2025-02-21 03:38:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.612502497039966
avg_train_sample_per_sec: 31.612502497039966
avg_episode_per_sec: 0.27252157325034454
collect_time: 22.016605615615845
reward_mean: -99.4044117647059
reward_std: 2.1613953561563646
reward_max: -96.44397759103643
reward_min: -102.3970588235294
queue_len: 0.06591804493680763
wait_time: 0.6172859285181801
delay_time: 4.319756809989599
pressure: 0.8069186560565872
total_envstep_count: 1114992
total_train_sample_count: 1114992
total_episode_count: 9612
total_duration: 36192.722032785416
[2025-02-21 03:39:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.877224301160272
avg_train_sample_per_sec: 31.877224301160272
avg_episode_per_sec: 0.27480365776862303
collect_time: 21.833770513534546
reward_mean: -98.53139589169
reward_std: 4.236649562936764
reward_max: -94.06022408963584
reward_min: -106.82002801120447
queue_len: 0.06533912194409151
wait_time: 0.6124150035787967
delay_time: 4.226743498657545
pressure: 0.8034924845269673
total_envstep_count: 1115688
total_train_sample_count: 1115688
total_episode_count: 9618
total_duration: 36214.55580329895
[2025-02-21 03:39:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91558435211705
avg_train_sample_per_sec: 31.91558435211705
avg_episode_per_sec: 0.27513434786307805
collect_time: 21.807528018951416
reward_mean: -99.4423436041083
reward_std: 2.480204810908194
reward_max: -95.31932773109243
reward_min: -103.87885154061617
queue_len: 0.06594319867646438
wait_time: 0.6240494208293398
delay_time: 4.274554980479455
pressure: 0.8079133510167993
total_envstep_count: 1116384
total_train_sample_count: 1116384
total_episode_count: 9624
total_duration: 36236.3633313179
[2025-02-21 03:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8457410756813
avg_train_sample_per_sec: 31.8457410756813
avg_episode_per_sec: 0.27453225065242504
collect_time: 21.855355739593506
reward_mean: -97.1905929038282
reward_std: 2.2547510771480765
reward_max: -93.48949579831934
reward_min: -101.2640056022409
queue_len: 0.06444999529431579
wait_time: 0.6029195829525443
delay_time: 4.160345635413545
pressure: 0.7896772767462422
total_envstep_count: 1117080
total_train_sample_count: 1117080
total_episode_count: 9630
total_duration: 36258.218687057495
[2025-02-21 03:40:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85488039692321
avg_train_sample_per_sec: 31.85488039692321
avg_episode_per_sec: 0.2746110379045104
collect_time: 21.849085330963135
reward_mean: -97.687908496732
reward_std: 1.872174166658825
reward_max: -95.74789915966386
reward_min: -101.2254901960784
queue_len: 0.06477978017024669
wait_time: 0.6092697025759907
delay_time: 4.164398594778238
pressure: 0.793656056587091
total_envstep_count: 1117776
total_train_sample_count: 1117776
total_episode_count: 9636
total_duration: 36280.06777238846
[2025-02-21 03:40:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.926765145697996
avg_train_sample_per_sec: 31.926765145697996
avg_episode_per_sec: 0.2752307340146379
collect_time: 21.799890995025635
reward_mean: -98.90884687208215
reward_std: 2.1360178649142054
reward_max: -95.56862745098039
reward_min: -102.39215686274504
queue_len: 0.06558942100270698
wait_time: 0.6165744259684421
delay_time: 4.1847887663931305
pressure: 0.8039345711759505
total_envstep_count: 1118472
total_train_sample_count: 1118472
total_episode_count: 9642
total_duration: 36301.867663383484
[2025-02-21 03:41:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23406255275293
avg_train_sample_per_sec: 32.23406255275293
avg_episode_per_sec: 0.2778798495926977
collect_time: 21.592065811157227
reward_mean: -98.74358076563958
reward_std: 2.647356438711449
reward_max: -95.40196078431374
reward_min: -102.88305322128848
queue_len: 0.06547982809392545
wait_time: 0.6187799058615487
delay_time: 4.226098791968796
pressure: 0.7942086648983201
total_envstep_count: 1119168
total_train_sample_count: 1119168
total_episode_count: 9648
total_duration: 36323.45972919464
[2025-02-21 03:41:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74957728289316
avg_train_sample_per_sec: 31.74957728289316
avg_episode_per_sec: 0.2737032524387341
collect_time: 21.92155170440674
reward_mean: -99.16281512605043
reward_std: 3.001248190424883
reward_max: -94.36344537815127
reward_min: -103.60434173669472
queue_len: 0.06575783496422442
wait_time: 0.6217080333459644
delay_time: 4.2211623657200805
pressure: 0.8045977011494253
total_envstep_count: 1119864
total_train_sample_count: 1119864
total_episode_count: 9654
total_duration: 36345.38128089905
[2025-02-21 03:41:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01193787724488
avg_train_sample_per_sec: 32.01193787724488
avg_episode_per_sec: 0.2759649817003869
collect_time: 21.741888999938965
reward_mean: -99.49323062558356
reward_std: 1.9867326357459156
reward_max: -97.27871148459386
reward_min: -103.21008403361343
queue_len: 0.0659769433856655
wait_time: 0.619774678217883
delay_time: 4.272226424231756
pressure: 0.8003978779840848
total_envstep_count: 1120560
total_train_sample_count: 1120560
total_episode_count: 9660
total_duration: 36367.12316989899
[2025-02-21 03:42:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.822479645803288
avg_train_sample_per_sec: 31.822479645803288
avg_episode_per_sec: 0.2743317210845111
collect_time: 21.871331453323364
reward_mean: -98.61671335200747
reward_std: 2.699087158739017
reward_max: -94.687675070028
reward_min: -102.859243697479
queue_len: 0.06539569850928877
wait_time: 0.6150008080155138
delay_time: 4.230233963872216
pressure: 0.79973474801061
total_envstep_count: 1121256
total_train_sample_count: 1121256
total_episode_count: 9666
total_duration: 36388.99450135231
[2025-02-21 03:42:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865085101291683
avg_train_sample_per_sec: 31.865085101291683
avg_episode_per_sec: 0.2746990094938938
collect_time: 21.842088222503662
reward_mean: -99.76517273576098
reward_std: 2.823408923113662
reward_max: -95.55742296918771
reward_min: -103.29271708683471
queue_len: 0.06615727634997412
wait_time: 0.6256245867047084
delay_time: 4.235106956717218
pressure: 0.8116710875331564
total_envstep_count: 1121952
total_train_sample_count: 1121952
total_episode_count: 9672
total_duration: 36410.836589574814
[2025-02-21 03:43:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.126161371143155
avg_train_sample_per_sec: 31.126161371143155
avg_episode_per_sec: 0.268328977337441
collect_time: 22.36061143875122
reward_mean: -99.54341736694677
reward_std: 3.2662805320175394
reward_max: -96.29901960784316
reward_min: -106.05042016806719
queue_len: 0.06601022371813446
wait_time: 0.6224840068653456
delay_time: 4.255070543874156
pressure: 0.8026083112290009
total_envstep_count: 1122648
total_train_sample_count: 1122648
total_episode_count: 9678
total_duration: 36433.197201013565
[2025-02-21 03:43:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.473417587884338
avg_train_sample_per_sec: 31.473417587884338
avg_episode_per_sec: 0.27132256541279604
collect_time: 22.11389970779419
reward_mean: -98.00968720821663
reward_std: 1.2165190789862237
reward_max: -96.32212885154067
reward_min: -99.48739495798316
queue_len: 0.06499316127865824
wait_time: 0.6129939265715127
delay_time: 4.212449459154892
pressure: 0.7950928381962864
total_envstep_count: 1123344
total_train_sample_count: 1123344
total_episode_count: 9684
total_duration: 36455.31110072136
[2025-02-21 03:43:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.673601482747422
avg_train_sample_per_sec: 31.673601482747422
avg_episode_per_sec: 0.27304828864437436
collect_time: 21.974135160446167
reward_mean: -97.98412698412699
reward_std: 3.044514469860568
reward_max: -93.906162464986
reward_min: -102.81582633053223
queue_len: 0.06497621152793566
wait_time: 0.6143163941084834
delay_time: 4.2070852609476805
pressure: 0.7979664014146772
total_envstep_count: 1124040
total_train_sample_count: 1124040
total_episode_count: 9690
total_duration: 36477.285235881805
[2025-02-21 03:44:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.020234716472075
avg_train_sample_per_sec: 32.020234716472075
avg_episode_per_sec: 0.2760365061764834
collect_time: 21.736255407333374
reward_mean: -99.94070961718022
reward_std: 3.130221699519049
reward_max: -97.23389355742297
reward_min: -105.78291316526607
queue_len: 0.0662736801174935
wait_time: 0.6236255222690315
delay_time: 4.222620058340879
pressure: 0.8094606542882404
total_envstep_count: 1124736
total_train_sample_count: 1124736
total_episode_count: 9696
total_duration: 36499.02149128914
[2025-02-21 03:44:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.984297820757718
avg_train_sample_per_sec: 31.984297820757718
avg_episode_per_sec: 0.2757267053513596
collect_time: 21.760677814483643
reward_mean: -97.77135854341736
reward_std: 3.528627029116047
reward_max: -92.93487394957981
reward_min: -101.32913165266106
queue_len: 0.06483511839749162
wait_time: 0.6088216564256118
delay_time: 4.250488940529837
pressure: 0.7940981432360742
total_envstep_count: 1125432
total_train_sample_count: 1125432
total_episode_count: 9702
total_duration: 36520.78216910362
[2025-02-21 03:44:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.694371315684176
avg_train_sample_per_sec: 31.694371315684176
avg_episode_per_sec: 0.27322733892831186
collect_time: 21.95973515510559
reward_mean: -99.55975723622782
reward_std: 1.909035070667029
reward_max: -96.67717086834735
reward_min: -102.45938375350141
queue_len: 0.0660210591752174
wait_time: 0.62306362642316
delay_time: 4.2469333645699665
pressure: 0.8211759504862952
total_envstep_count: 1126128
total_train_sample_count: 1126128
total_episode_count: 9708
total_duration: 36542.74190425873
[2025-02-21 03:45:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.674126943692112
avg_train_sample_per_sec: 31.674126943692112
avg_episode_per_sec: 0.27305281848010443
collect_time: 21.97377061843872
reward_mean: -99.15406162464986
reward_std: 3.0176279662224825
reward_max: -94.44397759103644
reward_min: -102.56932773109244
queue_len: 0.06575203025507285
wait_time: 0.6176935738928641
delay_time: 4.261189075771659
pressure: 0.8127763041556144
total_envstep_count: 1126824
total_train_sample_count: 1126824
total_episode_count: 9714
total_duration: 36564.71567487717
[2025-02-21 03:45:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.51819502532945
avg_train_sample_per_sec: 31.51819502532945
avg_episode_per_sec: 0.2717085778045642
collect_time: 22.08248281478882
reward_mean: -100.52229225023342
reward_std: 4.477428000129254
reward_max: -95.31092436974794
reward_min: -108.77030812324932
queue_len: 0.0666593449935235
wait_time: 0.6303424221147345
delay_time: 4.287361564044765
pressure: 0.8120026525198939
total_envstep_count: 1127520
total_train_sample_count: 1127520
total_episode_count: 9720
total_duration: 36586.798157691956
[2025-02-21 03:46:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.758476985056312
avg_train_sample_per_sec: 31.758476985056312
avg_episode_per_sec: 0.27377997400910614
collect_time: 21.915408611297607
reward_mean: -97.81967787114847
reward_std: 0.9735567494392984
reward_max: -96.32843137254902
reward_min: -98.86904761904762
queue_len: 0.06486716039200827
wait_time: 0.6098046645713987
delay_time: 4.190972571372115
pressure: 0.8006189213085765
total_envstep_count: 1128216
total_train_sample_count: 1128216
total_episode_count: 9726
total_duration: 36608.71356630325
[2025-02-21 03:46:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0018076547518
avg_train_sample_per_sec: 32.0018076547518
avg_episode_per_sec: 0.2758776521961362
collect_time: 21.74877142906189
reward_mean: -98.82271241830064
reward_std: 1.8004538705669322
reward_max: -96.71708683473388
reward_min: -101.87324929971987
queue_len: 0.0655323026646556
wait_time: 0.6249612245428676
delay_time: 4.270012745610231
pressure: 0.811450044208665
total_envstep_count: 1128912
total_train_sample_count: 1128912
total_episode_count: 9732
total_duration: 36630.462337732315
[2025-02-21 03:46:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82904843044918
avg_train_sample_per_sec: 31.82904843044918
avg_episode_per_sec: 0.27438834853835503
collect_time: 21.866817712783813
reward_mean: -99.23506069094303
reward_std: 1.063278110187673
reward_max: -97.61064425770306
reward_min: -100.71918767507003
queue_len: 0.06580574316375533
wait_time: 0.619870494616945
delay_time: 4.252157958837464
pressure: 0.8069186560565872
total_envstep_count: 1129608
total_train_sample_count: 1129608
total_episode_count: 9738
total_duration: 36652.3291554451
[2025-02-21 03:47:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94571518271097
avg_train_sample_per_sec: 31.94571518271097
avg_episode_per_sec: 0.27539409640268075
collect_time: 21.786959409713745
reward_mean: -97.26575630252103
reward_std: 1.9387540728471027
reward_max: -94.67927170868347
reward_min: -100.45588235294119
queue_len: 0.06449983839689723
wait_time: 0.6053824823474926
delay_time: 4.183253128332381
pressure: 0.793656056587091
total_envstep_count: 1130304
total_train_sample_count: 1130304
total_episode_count: 9744
total_duration: 36674.11611485481
[2025-02-21 03:47:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07320935022417
avg_train_sample_per_sec: 32.07320935022417
avg_episode_per_sec: 0.27649318405365664
collect_time: 21.70035409927368
reward_mean: -98.84313725490199
reward_std: 1.9517144254616887
reward_max: -95.97969187675072
reward_min: -101.80812324929973
queue_len: 0.06554584698600925
wait_time: 0.6199215760574787
delay_time: 4.204971311514153
pressure: 0.812444739168877
total_envstep_count: 1131000
total_train_sample_count: 1131000
total_episode_count: 9750
total_duration: 36695.816468954086
[2025-02-21 03:47:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.140264782701124
avg_train_sample_per_sec: 32.140264782701124
avg_episode_per_sec: 0.2770712481267338
collect_time: 21.65507984161377
reward_mean: -100.23260971055088
reward_std: 2.4549643963289265
reward_max: -96.78361344537812
reward_min: -104.2612044817927
queue_len: 0.06646724781866768
wait_time: 0.6273621296440769
delay_time: 4.253571631168339
pressure: 0.8118921308576481
total_envstep_count: 1131696
total_train_sample_count: 1131696
total_episode_count: 9756
total_duration: 36717.4715487957
[2025-02-21 03:48:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.999983864277173
avg_train_sample_per_sec: 31.999983864277173
avg_episode_per_sec: 0.2758619298644584
collect_time: 21.75001096725464
reward_mean: -99.94491129785247
reward_std: 2.8751776420604265
reward_max: -97.24019607843135
reward_min: -105.49019607843135
queue_len: 0.06627646637788626
wait_time: 0.6239532174496677
delay_time: 4.292281077087514
pressure: 0.8089080459770116
total_envstep_count: 1132392
total_train_sample_count: 1132392
total_episode_count: 9762
total_duration: 36739.221559762955
[2025-02-21 03:48:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09560980024728
avg_train_sample_per_sec: 32.09560980024728
avg_episode_per_sec: 0.27668629138144213
collect_time: 21.685208797454834
reward_mean: -98.94549486461251
reward_std: 1.914319893567123
reward_max: -96.7640056022409
reward_min: -101.15826330532212
queue_len: 0.06561372338502157
wait_time: 0.6172421223131163
delay_time: 4.263171626084543
pressure: 0.8085764809902741
total_envstep_count: 1133088
total_train_sample_count: 1133088
total_episode_count: 9768
total_duration: 36760.90676856041
[2025-02-21 03:48:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83063794801483
avg_train_sample_per_sec: 31.83063794801483
avg_episode_per_sec: 0.27440205127598993
collect_time: 21.86572575569153
reward_mean: -99.13200280112045
reward_std: 2.294109265842028
reward_max: -95.85364145658264
reward_min: -103.10224089635855
queue_len: 0.0657374023880109
wait_time: 0.6167809188219939
delay_time: 4.245839105952466
pressure: 0.8102343059239611
total_envstep_count: 1133784
total_train_sample_count: 1133784
total_episode_count: 9774
total_duration: 36782.7724943161
[2025-02-21 03:49:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.721723636957773
avg_train_sample_per_sec: 31.721723636957773
avg_episode_per_sec: 0.27346313480136014
collect_time: 21.940800189971924
reward_mean: -97.74311391223154
reward_std: 2.800800297316728
reward_max: -93.703781512605
reward_min: -100.79621848739494
queue_len: 0.06481638853596257
wait_time: 0.6126178588146134
delay_time: 4.212200452497393
pressure: 0.7939876215738285
total_envstep_count: 1134480
total_train_sample_count: 1134480
total_episode_count: 9780
total_duration: 36804.71329450607
[2025-02-21 03:49:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.815775911727425
avg_train_sample_per_sec: 31.815775911727425
avg_episode_per_sec: 0.27427393027351227
collect_time: 21.87593984603882
reward_mean: -98.4519140989729
reward_std: 1.128694319002871
reward_max: -96.98879551820725
reward_min: -100.35224089635854
queue_len: 0.06528641518499531
wait_time: 0.6111405216374791
delay_time: 4.176491581940237
pressure: 0.7994031830238727
total_envstep_count: 1135176
total_train_sample_count: 1135176
total_episode_count: 9786
total_duration: 36826.58923435211
[2025-02-21 03:50:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98253874587161
avg_train_sample_per_sec: 31.98253874587161
avg_episode_per_sec: 0.2757115409126863
collect_time: 21.761874675750732
reward_mean: -99.59675536881419
reward_std: 2.214676806663907
reward_max: -97.12114845938376
reward_min: -102.59453781512607
queue_len: 0.06604559374589801
wait_time: 0.6217810178890301
delay_time: 4.262515000710476
pressure: 0.8033819628647215
total_envstep_count: 1135872
total_train_sample_count: 1135872
total_episode_count: 9792
total_duration: 36848.35110902786
[2025-02-21 03:50:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.912512332305166
avg_train_sample_per_sec: 31.912512332305166
avg_episode_per_sec: 0.27510786493366524
collect_time: 21.809627294540405
reward_mean: -99.87721755368813
reward_std: 2.216951267133733
reward_max: -97.40266106442576
reward_min: -104.2100840336134
queue_len: 0.06623157662711414
wait_time: 0.6260266595586067
delay_time: 4.2464284610793435
pressure: 0.8101237842617154
total_envstep_count: 1136568
total_train_sample_count: 1136568
total_episode_count: 9798
total_duration: 36870.1607363224
[2025-02-21 03:50:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.040933220098246
avg_train_sample_per_sec: 32.040933220098246
avg_episode_per_sec: 0.2762149415525711
collect_time: 21.722213745117188
reward_mean: -102.344070961718
reward_std: 3.513931397691495
reward_max: -96.68067226890757
reward_min: -108.43907563025209
queue_len: 0.06786742106214723
wait_time: 0.638600046561507
delay_time: 4.334435304388428
pressure: 0.8391909814323607
total_envstep_count: 1137264
total_train_sample_count: 1137264
total_episode_count: 9804
total_duration: 36891.88295006752
[2025-02-21 03:51:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.144182474899665
avg_train_sample_per_sec: 32.144182474899665
avg_episode_per_sec: 0.27710502133534193
collect_time: 21.652440547943115
reward_mean: -97.5235760971055
reward_std: 2.4478101635030605
reward_max: -93.01400560224091
reward_min: -100.43767507002804
queue_len: 0.06467080643044132
wait_time: 0.61121025554342
delay_time: 4.152291665817608
pressure: 0.8018346595932803
total_envstep_count: 1137960
total_train_sample_count: 1137960
total_episode_count: 9810
total_duration: 36913.53539061546
[2025-02-21 03:51:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.648326418368885
avg_train_sample_per_sec: 31.648326418368885
avg_episode_per_sec: 0.27283040015835247
collect_time: 21.991684198379517
reward_mean: -99.90056022408963
reward_std: 3.16616991198959
reward_max: -96.8109243697479
reward_min: -106.03571428571429
queue_len: 0.06624705585151831
wait_time: 0.6276105711957639
delay_time: 4.234148532661209
pressure: 0.8112290008841733
total_envstep_count: 1138656
total_train_sample_count: 1138656
total_episode_count: 9816
total_duration: 36935.52707481384
[2025-02-21 03:51:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10661095018958
avg_train_sample_per_sec: 32.10661095018958
avg_episode_per_sec: 0.2767811288809446
collect_time: 21.677778482437134
reward_mean: -100.33578431372548
reward_std: 1.6532064980673655
reward_max: -97.47198879551821
reward_min: -103.02380952380949
queue_len: 0.06653566599053413
wait_time: 0.6301195212833144
delay_time: 4.24635769272897
pressure: 0.8186339522546421
total_envstep_count: 1139352
total_train_sample_count: 1139352
total_episode_count: 9822
total_duration: 36957.20485329628
[2025-02-21 03:52:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23437505969614
avg_train_sample_per_sec: 32.23437505969614
avg_episode_per_sec: 0.27788254361807013
collect_time: 21.591856479644775
reward_mean: -98.14997665732959
reward_std: 2.7566170424829073
reward_max: -94.95098039215688
reward_min: -103.46568627450974
queue_len: 0.06508619141732731
wait_time: 0.6135988546612279
delay_time: 4.1603488909887
pressure: 0.798076923076923
total_envstep_count: 1140048
total_train_sample_count: 1140048
total_episode_count: 9828
total_duration: 36978.796709775925
[2025-02-21 03:52:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.770495662338686
avg_train_sample_per_sec: 31.770495662338686
avg_episode_per_sec: 0.27388358329602314
collect_time: 21.90711808204651
reward_mean: -98.86671335200747
reward_std: 2.951284946405014
reward_max: -93.41316526610643
reward_min: -101.890756302521
queue_len: 0.06556148100265748
wait_time: 0.6223486410479312
delay_time: 4.217571998692661
pressure: 0.8054818744473917
total_envstep_count: 1140744
total_train_sample_count: 1140744
total_episode_count: 9834
total_duration: 37000.70382785797
[2025-02-21 03:53:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87790239538135
avg_train_sample_per_sec: 31.87790239538135
avg_episode_per_sec: 0.27480950340845994
collect_time: 21.833306074142456
reward_mean: -98.97268907563027
reward_std: 2.3587381626042814
reward_max: -95.85504201680672
reward_min: -102.75910364145659
queue_len: 0.06563175668145242
wait_time: 0.6192760150037027
delay_time: 4.252545803556922
pressure: 0.8085764809902741
total_envstep_count: 1141440
total_train_sample_count: 1141440
total_episode_count: 9840
total_duration: 37022.537133932114
[2025-02-21 03:53:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.844711406457247
avg_train_sample_per_sec: 31.844711406457247
avg_episode_per_sec: 0.27452337419359696
collect_time: 21.856062412261963
reward_mean: -99.53606442577029
reward_std: 3.32519983608214
reward_max: -92.9663865546218
reward_min: -103.47619047619047
queue_len: 0.06600534776244715
wait_time: 0.621598982210037
delay_time: 4.233132613689499
pressure: 0.8123342175066313
total_envstep_count: 1142136
total_train_sample_count: 1142136
total_episode_count: 9846
total_duration: 37044.393196344376
[2025-02-21 03:53:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.24893612783441
avg_train_sample_per_sec: 32.24893612783441
avg_episode_per_sec: 0.278008070067538
collect_time: 21.582107305526733
reward_mean: -101.04598506069094
reward_std: 2.2674831289436645
reward_max: -97.10924369747899
reward_min: -104.41736694677867
queue_len: 0.06700662139303114
wait_time: 0.636007431266052
delay_time: 4.354838512327222
pressure: 0.8247126436781609
total_envstep_count: 1142832
total_train_sample_count: 1142832
total_episode_count: 9852
total_duration: 37065.9753036499
[2025-02-21 03:54:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.986241438043212
avg_train_sample_per_sec: 31.986241438043212
avg_episode_per_sec: 0.2757434606727863
collect_time: 21.759355545043945
reward_mean: -99.35130718954248
reward_std: 2.175326085891308
reward_max: -96.593837535014
reward_min: -102.41036414565824
queue_len: 0.06588282970128813
wait_time: 0.6220439325155349
delay_time: 4.262032955798214
pressure: 0.8148762157382848
total_envstep_count: 1143528
total_train_sample_count: 1143528
total_episode_count: 9858
total_duration: 37087.734659194946
[2025-02-21 03:54:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13588071885962
avg_train_sample_per_sec: 32.13588071885962
avg_episode_per_sec: 0.2770334544729277
collect_time: 21.658034086227417
reward_mean: -99.83123249299719
reward_std: 1.3400476128732883
reward_max: -97.75700280112046
reward_min: -101.56092436974791
queue_len: 0.06620108255503793
wait_time: 0.6277359529134378
delay_time: 4.271983417572541
pressure: 0.8197391688771
total_envstep_count: 1144224
total_train_sample_count: 1144224
total_episode_count: 9864
total_duration: 37109.392693281174
[2025-02-21 03:54:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.656318076533854
avg_train_sample_per_sec: 31.656318076533854
avg_episode_per_sec: 0.27289929376322286
collect_time: 21.986132383346558
reward_mean: -99.95611577964519
reward_std: 1.0808759948740856
reward_max: -97.87885154061625
reward_min: -101.18837535014002
queue_len: 0.06628389640560026
wait_time: 0.6257843323005595
delay_time: 4.2522618196433095
pressure: 0.8138815207780725
total_envstep_count: 1144920
total_train_sample_count: 1144920
total_episode_count: 9870
total_duration: 37131.37882566452
[2025-02-21 03:55:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.033728321917046
avg_train_sample_per_sec: 32.033728321917046
avg_episode_per_sec: 0.27615283036135385
collect_time: 21.727099418640137
reward_mean: -101.50910364145658
reward_std: 2.2552425060799863
reward_max: -97.71008403361344
reward_min: -105.40966386554618
queue_len: 0.06731372920520992
wait_time: 0.6356154973041382
delay_time: 4.251185316276818
pressure: 0.8325596816976127
total_envstep_count: 1145616
total_train_sample_count: 1145616
total_episode_count: 9876
total_duration: 37153.10592508316
[2025-02-21 03:55:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.023381610325565
avg_train_sample_per_sec: 32.023381610325565
avg_episode_per_sec: 0.27606363457177213
collect_time: 21.734119415283203
reward_mean: -98.39787581699345
reward_std: 2.89257364962873
reward_max: -93.97338935574231
reward_min: -103.28501400560222
queue_len: 0.06525058078049963
wait_time: 0.6117729253505114
delay_time: 4.17392037232869
pressure: 0.8083554376657824
total_envstep_count: 1146312
total_train_sample_count: 1146312
total_episode_count: 9882
total_duration: 37174.84004449844
[2025-02-21 03:56:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.64788312750083
avg_train_sample_per_sec: 31.64788312750083
avg_episode_per_sec: 0.272826578685352
collect_time: 21.991992235183716
reward_mean: -100.50326797385621
reward_std: 2.9078195096664117
reward_max: -97.83333333333331
reward_min: -106.54481792717088
queue_len: 0.06664672942563409
wait_time: 0.6338641004589279
delay_time: 4.282463231398505
pressure: 0.812555260831123
total_envstep_count: 1147008
total_train_sample_count: 1147008
total_episode_count: 9888
total_duration: 37196.83203673363
[2025-02-21 03:56:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.930988602946147
avg_train_sample_per_sec: 31.930988602946147
avg_episode_per_sec: 0.2752671431288461
collect_time: 21.79700756072998
reward_mean: -102.06162464985994
reward_std: 2.5822324054627823
reward_max: -97.56162464985992
reward_min: -105.9208683473389
queue_len: 0.06768012244685673
wait_time: 0.6414877732702277
delay_time: 4.306246596195453
pressure: 0.8283598585322723
total_envstep_count: 1147704
total_train_sample_count: 1147704
total_episode_count: 9894
total_duration: 37218.62904429436
[2025-02-21 03:56:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.890688895374055
avg_train_sample_per_sec: 31.890688895374055
avg_episode_per_sec: 0.2749197318566729
collect_time: 21.824552059173584
reward_mean: -100.11519607843137
reward_std: 2.1763202883181934
reward_max: -96.13865546218484
reward_min: -102.68977591036416
queue_len: 0.06638938731991469
wait_time: 0.6305862198991002
delay_time: 4.229624624647019
pressure: 0.8185234305923962
total_envstep_count: 1148400
total_train_sample_count: 1148400
total_episode_count: 9900
total_duration: 37240.45359635353
[2025-02-21 03:57:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.156796867588984
avg_train_sample_per_sec: 31.156796867588984
avg_episode_per_sec: 0.2685930764447326
collect_time: 22.338624954223633
reward_mean: -100.05030345471518
reward_std: 2.9687378931660775
reward_max: -97.10364145658264
reward_min: -104.54761904761901
queue_len: 0.06634635507607108
wait_time: 0.6290622128603872
delay_time: 4.3285192554217895
pressure: 0.8137709991158267
total_envstep_count: 1149096
total_train_sample_count: 1149096
total_episode_count: 9906
total_duration: 37262.792221307755
[2025-02-21 03:57:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93450923721659
avg_train_sample_per_sec: 31.93450923721659
avg_episode_per_sec: 0.27529749342428095
collect_time: 21.794604539871216
reward_mean: -99.96136788048551
reward_std: 2.6850104287890786
reward_max: -94.74999999999997
reward_min: -102.66876750700278
queue_len: 0.0662873792310912
wait_time: 0.6256134416631373
delay_time: 4.283016658142605
pressure: 0.8082449160035367
total_envstep_count: 1149792
total_train_sample_count: 1149792
total_episode_count: 9912
total_duration: 37284.586825847626
[2025-02-21 03:57:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70763397927726
avg_train_sample_per_sec: 31.70763397927726
avg_episode_per_sec: 0.2733416722351488
collect_time: 21.950549840927124
reward_mean: -101.46907096171803
reward_std: 4.512285308130336
reward_max: -95.00070028011204
reward_min: -107.85994397759104
queue_len: 0.06728718233535678
wait_time: 0.6371279723206701
delay_time: 4.311006312006661
pressure: 0.8257073386383732
total_envstep_count: 1150488
total_train_sample_count: 1150488
total_episode_count: 9918
total_duration: 37306.53737568855
[2025-02-21 03:58:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.332965446671192
avg_train_sample_per_sec: 31.332965446671192
avg_episode_per_sec: 0.270111771091993
collect_time: 22.213026762008667
reward_mean: -101.43709150326795
reward_std: 3.298787719340144
reward_max: -95.22899159663864
reward_min: -105.87254901960786
queue_len: 0.06726597579792305
wait_time: 0.6358945103240236
delay_time: 4.31355866451398
pressure: 0.821949602122016
total_envstep_count: 1151184
total_train_sample_count: 1151184
total_episode_count: 9924
total_duration: 37328.75040245056
[2025-02-21 03:58:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.880419045483144
avg_train_sample_per_sec: 31.880419045483144
avg_episode_per_sec: 0.27483119866795813
collect_time: 21.83158254623413
reward_mean: -98.68475723622782
reward_std: 1.8072468015209344
reward_max: -96.7703081232493
reward_min: -100.72268907563026
queue_len: 0.06544082044842693
wait_time: 0.6180793161650159
delay_time: 4.254836198122963
pressure: 0.7981874447391689
total_envstep_count: 1151880
total_train_sample_count: 1151880
total_episode_count: 9930
total_duration: 37350.581984996796
[2025-02-21 03:59:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.814800881901807
avg_train_sample_per_sec: 31.814800881901807
avg_episode_per_sec: 0.2742655248439811
collect_time: 21.876610279083252
reward_mean: -98.93137254901963
reward_std: 2.147824023748833
reward_max: -96.24369747899158
reward_min: -102.07703081232496
queue_len: 0.06560435845425702
wait_time: 0.6200315559468702
delay_time: 4.2639978066426165
pressure: 0.8122236958443855
total_envstep_count: 1152576
total_train_sample_count: 1152576
total_episode_count: 9936
total_duration: 37372.45859527588
[2025-02-21 03:59:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.410590594110435
avg_train_sample_per_sec: 31.410590594110435
avg_episode_per_sec: 0.27078095339750374
collect_time: 22.15813159942627
reward_mean: -102.13398692810456
reward_std: 2.840819425504098
reward_max: -98.3550420168067
reward_min: -107.26610644257704
queue_len: 0.06772810804250967
wait_time: 0.6431599164864884
delay_time: 4.375717030897622
pressure: 0.8347701149425287
total_envstep_count: 1153272
total_train_sample_count: 1153272
total_episode_count: 9942
total_duration: 37394.616726875305
[2025-02-21 03:59:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.008095519711794
avg_train_sample_per_sec: 32.008095519711794
avg_episode_per_sec: 0.27593185792854996
collect_time: 21.74449896812439
reward_mean: -101.76633986928103
reward_std: 2.435734887022548
reward_max: -98.25840336134452
reward_min: -105.47549019607845
queue_len: 0.06748431025814393
wait_time: 0.6407909759836737
delay_time: 4.313097943185087
pressure: 0.821286472148541
total_envstep_count: 1153968
total_train_sample_count: 1153968
total_episode_count: 9948
total_duration: 37416.36122584343
[2025-02-21 04:00:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71447068724307
avg_train_sample_per_sec: 31.71447068724307
avg_episode_per_sec: 0.2734006093727851
collect_time: 21.945817947387695
reward_mean: -99.87441643323996
reward_std: 2.241248829461668
reward_max: -96.82002801120447
reward_min: -102.40546218487394
queue_len: 0.06622971912018565
wait_time: 0.6242267353448896
delay_time: 4.2833630308712385
pressure: 0.809681697612732
total_envstep_count: 1154664
total_train_sample_count: 1154664
total_episode_count: 9954
total_duration: 37438.30704379082
[2025-02-21 04:00:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.253146549321094
avg_train_sample_per_sec: 32.253146549321094
avg_episode_per_sec: 0.2780443668044922
collect_time: 21.57928991317749
reward_mean: -101.5078197945845
reward_std: 4.630897587595196
reward_max: -95.14145658263308
reward_min: -107.91456582633056
queue_len: 0.0673128778478677
wait_time: 0.6371735586365403
delay_time: 4.294491415348362
pressure: 0.8248231653404067
total_envstep_count: 1155360
total_train_sample_count: 1155360
total_episode_count: 9960
total_duration: 37459.886333703995
[2025-02-21 04:00:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12923278249004
avg_train_sample_per_sec: 32.12923278249004
avg_episode_per_sec: 0.27697614467663834
collect_time: 21.66251540184021
reward_mean: -98.21685340802988
reward_std: 1.8721386301619936
reward_max: -95.9075630252101
reward_min: -101.9299719887955
queue_len: 0.06513053939524527
wait_time: 0.6106785441851365
delay_time: 4.245758922534667
pressure: 0.7976348364279399
total_envstep_count: 1156056
total_train_sample_count: 1156056
total_episode_count: 9966
total_duration: 37481.548849105835
[2025-02-21 04:01:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.30654741661771
avg_train_sample_per_sec: 32.30654741661771
avg_episode_per_sec: 0.27850471910877334
collect_time: 21.543620586395264
reward_mean: -98.44316059757234
reward_std: 3.8902986949200073
reward_max: -94.08683473389357
reward_min: -104.79901960784316
queue_len: 0.06528061047584373
wait_time: 0.6176143202639145
delay_time: 4.1960859080233055
pressure: 0.800950486295314
total_envstep_count: 1156752
total_train_sample_count: 1156752
total_episode_count: 9972
total_duration: 37503.09246969223
[2025-02-21 04:01:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67077343453797
avg_train_sample_per_sec: 31.67077343453797
avg_episode_per_sec: 0.27302390891843076
collect_time: 21.976097345352173
reward_mean: -100.2438141923436
reward_std: 1.9375909357451035
reward_max: -97.72619047619047
reward_min: -102.72899159663864
queue_len: 0.0664746778463817
wait_time: 0.6261963118580766
delay_time: 4.294803378770591
pressure: 0.8074712643678161
total_envstep_count: 1157448
total_train_sample_count: 1157448
total_episode_count: 9978
total_duration: 37525.06856703758
[2025-02-21 04:02:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12141977541578
avg_train_sample_per_sec: 32.12141977541578
avg_episode_per_sec: 0.27690879116737743
collect_time: 21.667784452438354
reward_mean: -98.45086367880486
reward_std: 1.5559811971888797
reward_max: -95.67436974789915
reward_min: -100.21568627450984
queue_len: 0.06528571861989711
wait_time: 0.6158332033078483
delay_time: 4.211249077773833
pressure: 0.7977453580901858
total_envstep_count: 1158144
total_train_sample_count: 1158144
total_episode_count: 9984
total_duration: 37546.73635149002
[2025-02-21 04:02:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.24417547527658
avg_train_sample_per_sec: 32.24417547527658
avg_episode_per_sec: 0.27796702995928085
collect_time: 21.585293769836426
reward_mean: -98.22584033613445
reward_std: 1.8325919667173152
reward_max: -94.80602240896363
reward_min: -100.2675070028011
queue_len: 0.06513649889664087
wait_time: 0.6174449775489329
delay_time: 4.256308198459159
pressure: 0.7992926613616268
total_envstep_count: 1158840
total_train_sample_count: 1158840
total_episode_count: 9990
total_duration: 37568.32164525986
[2025-02-21 04:02:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06995436085422
avg_train_sample_per_sec: 32.06995436085422
avg_episode_per_sec: 0.2764651238004674
collect_time: 21.702556610107422
reward_mean: -99.51505602240896
reward_std: 3.0479085309882965
reward_max: -95.74859943977592
reward_min: -103.31162464985995
queue_len: 0.0659914164604834
wait_time: 0.6203063121800444
delay_time: 4.216430251795561
pressure: 0.8062555260831124
total_envstep_count: 1159536
total_train_sample_count: 1159536
total_episode_count: 9996
total_duration: 37590.024201869965
[2025-02-21 04:03:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.229424779347276
avg_train_sample_per_sec: 32.229424779347276
avg_episode_per_sec: 0.2778398687874765
collect_time: 21.595172882080078
reward_mean: -97.60620915032679
reward_std: 1.8034876321328535
reward_max: -95.10434173669465
reward_min: -99.96288515406167
queue_len: 0.0647256028848321
wait_time: 0.611978489450599
delay_time: 4.151789895841781
pressure: 0.7895667550839964
total_envstep_count: 1160232
total_train_sample_count: 1160232
total_episode_count: 10002
total_duration: 37611.619374752045
[2025-02-21 04:03:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.69083393317428
avg_train_sample_per_sec: 31.69083393317428
avg_episode_per_sec: 0.27319684425150237
collect_time: 21.962186336517334
reward_mean: -100.0353641456583
reward_std: 3.5885898298538494
reward_max: -95.77380952380952
reward_min: -106.12675070028011
queue_len: 0.06633644837245244
wait_time: 0.6258243460956443
delay_time: 4.271273384107147
pressure: 0.8065870910698498
total_envstep_count: 1160928
total_train_sample_count: 1160928
total_episode_count: 10008
total_duration: 37633.58156108856
[2025-02-21 04:03:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.711155822996464
avg_train_sample_per_sec: 31.711155822996464
avg_episode_per_sec: 0.2733720329568661
collect_time: 21.94811201095581
reward_mean: -99.24778244631183
reward_std: 2.7503659692433517
reward_max: -94.61554621848738
reward_min: -103.38235294117644
queue_len: 0.0658141793410556
wait_time: 0.6214632294120123
delay_time: 4.264563144680204
pressure: 0.8068081343943413
total_envstep_count: 1161624
total_train_sample_count: 1161624
total_episode_count: 10014
total_duration: 37655.52967309952
[2025-02-21 04:04:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93934137421324
avg_train_sample_per_sec: 31.93934137421324
avg_episode_per_sec: 0.2753391497777003
collect_time: 21.79130721092224
reward_mean: -98.78979925303456
reward_std: 3.1403251339763845
reward_max: -94.73739495798318
reward_min: -103.6470588235294
queue_len: 0.06551047695824573
wait_time: 0.617200483199469
delay_time: 4.280593976890369
pressure: 0.8010610079575597
total_envstep_count: 1162320
total_train_sample_count: 1162320
total_episode_count: 10020
total_duration: 37677.32098031044
[2025-02-21 04:04:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98962668565098
avg_train_sample_per_sec: 31.98962668565098
avg_episode_per_sec: 0.27577264384181877
collect_time: 21.757052898406982
reward_mean: -98.79960317460319
reward_std: 1.4315810314290005
reward_max: -97.21848739495799
reward_min: -101.19747899159667
queue_len: 0.06551697823249548
wait_time: 0.6228918844283955
delay_time: 4.215711495662897
pressure: 0.8018346595932803
total_envstep_count: 1163016
total_train_sample_count: 1163016
total_episode_count: 10026
total_duration: 37699.07803320885
[2025-02-21 04:04:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.966456041621587
avg_train_sample_per_sec: 31.966456041621587
avg_episode_per_sec: 0.27557289691053094
collect_time: 21.772823333740234
reward_mean: -99.72315592903828
reward_std: 2.357126583329537
reward_max: -95.10224089635852
reward_min: -102.44607843137251
queue_len: 0.06612941374604661
wait_time: 0.6292769870989953
delay_time: 4.2695581005151935
pressure: 0.8058134394341291
total_envstep_count: 1163712
total_train_sample_count: 1163712
total_episode_count: 10032
total_duration: 37720.85085654259
[2025-02-21 04:05:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82438074769224
avg_train_sample_per_sec: 31.82438074769224
avg_episode_per_sec: 0.27434810989389863
collect_time: 21.870024919509888
reward_mean: -102.81430905695612
reward_std: 2.812992273791995
reward_max: -97.77941176470587
reward_min: -105.39915966386557
queue_len: 0.06817925003776933
wait_time: 0.6460722551620118
delay_time: 4.363227255363878
pressure: 0.8299071618037136
total_envstep_count: 1164408
total_train_sample_count: 1164408
total_episode_count: 10038
total_duration: 37742.7208814621
[2025-02-21 04:05:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.874411632087995
avg_train_sample_per_sec: 31.874411632087995
avg_episode_per_sec: 0.27477941062144823
collect_time: 21.835697174072266
reward_mean: -99.43172268907563
reward_std: 3.549847714288902
reward_max: -93.86204481792717
reward_min: -104.1694677871149
queue_len: 0.0659361556293605
wait_time: 0.6217945622103837
delay_time: 4.251890136230846
pressure: 0.8147656940760388
total_envstep_count: 1165104
total_train_sample_count: 1165104
total_episode_count: 10044
total_duration: 37764.55657863617
[2025-02-21 04:06:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.912733163062743
avg_train_sample_per_sec: 31.912733163062743
avg_episode_per_sec: 0.27510976864709263
collect_time: 21.809476375579834
reward_mean: -100.82061157796454
reward_std: 3.9757843722621766
reward_max: -96.40826330532217
reward_min: -108.14075630252103
queue_len: 0.06685716948140885
wait_time: 0.6348409943110754
delay_time: 4.291504897226538
pressure: 0.8200707338638372
total_envstep_count: 1165800
total_train_sample_count: 1165800
total_episode_count: 10050
total_duration: 37786.36605501175
[2025-02-21 04:06:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05994407237728
avg_train_sample_per_sec: 32.05994407237728
avg_episode_per_sec: 0.2763788282101489
collect_time: 21.709332942962646
reward_mean: -101.28944911297852
reward_std: 4.2355986781136306
reward_max: -95.78431372549018
reward_min: -106.8417366946779
queue_len: 0.06716806970356666
wait_time: 0.6342523194069848
delay_time: 4.340325028296307
pressure: 0.8218390804597702
total_envstep_count: 1166496
total_train_sample_count: 1166496
total_episode_count: 10056
total_duration: 37808.07538795471
[2025-02-21 04:06:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.676154032254075
avg_train_sample_per_sec: 31.676154032254075
avg_episode_per_sec: 0.27307029338150063
collect_time: 21.97236442565918
reward_mean: -100.03711484593835
reward_std: 2.1054750463618808
reward_max: -96.8424369747899
reward_min: -103.66946778711478
queue_len: 0.06633760931428274
wait_time: 0.6285719858235072
delay_time: 4.335549307491371
pressure: 0.8003978779840848
total_envstep_count: 1167192
total_train_sample_count: 1167192
total_episode_count: 10062
total_duration: 37830.04775238037
[2025-02-21 04:07:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.864325817011952
avg_train_sample_per_sec: 31.864325817011952
avg_episode_per_sec: 0.2746924639397582
collect_time: 21.84260869026184
reward_mean: -100.7469654528478
reward_std: 1.8946023608444016
reward_max: -98.16386554621849
reward_min: -103.15126050420164
queue_len: 0.06680833252841366
wait_time: 0.6350583226217101
delay_time: 4.306342762054809
pressure: 0.8160919540229884
total_envstep_count: 1167888
total_train_sample_count: 1167888
total_episode_count: 10068
total_duration: 37851.89036107063
[2025-02-21 04:07:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05956170483273
avg_train_sample_per_sec: 32.05956170483273
avg_episode_per_sec: 0.27637553193821324
collect_time: 21.70959186553955
reward_mean: -99.02450980392155
reward_std: 3.4021421680759776
reward_max: -92.98669467787114
reward_min: -103.31372549019609
queue_len: 0.06566612055962967
wait_time: 0.6197136900737307
delay_time: 4.238040438113194
pressure: 0.8051503094606542
total_envstep_count: 1168584
total_train_sample_count: 1168584
total_episode_count: 10074
total_duration: 37873.59995293617
[2025-02-21 04:07:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80994742639937
avg_train_sample_per_sec: 31.80994742639937
avg_episode_per_sec: 0.27422368471033937
collect_time: 21.879948139190674
reward_mean: -99.11286181139123
reward_std: 1.9939038962503688
reward_max: -96.80742296918768
reward_min: -102.82002801120449
queue_len: 0.0657247094239995
wait_time: 0.6225406608266649
delay_time: 4.285889711373808
pressure: 0.7968611847922192
total_envstep_count: 1169280
total_train_sample_count: 1169280
total_episode_count: 10080
total_duration: 37895.47990107536
[2025-02-21 04:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.127238867181305
avg_train_sample_per_sec: 32.127238867181305
avg_episode_per_sec: 0.276958955751563
collect_time: 21.663859844207764
reward_mean: -100.6076097105509
reward_std: 2.327050083002216
reward_max: -97.75420168067228
reward_min: -104.04201680672267
queue_len: 0.06671592155872075
wait_time: 0.6320482326440743
delay_time: 4.338259260678903
pressure: 0.8175287356321839
total_envstep_count: 1169976
total_train_sample_count: 1169976
total_episode_count: 10086
total_duration: 37917.14376091957
[2025-02-21 04:08:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03323374570498
avg_train_sample_per_sec: 32.03323374570498
avg_episode_per_sec: 0.27614856677331884
collect_time: 21.727434873580933
reward_mean: -98.41923436041083
reward_std: 3.2040253300627377
reward_max: -95.96498599439776
reward_min: -105.39145658263307
queue_len: 0.06526474427082947
wait_time: 0.614467393942546
delay_time: 4.244819115678419
pressure: 0.7937665782493369
total_envstep_count: 1170672
total_train_sample_count: 1170672
total_episode_count: 10092
total_duration: 37938.87119579315
[2025-02-21 04:09:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.85335658073356
avg_train_sample_per_sec: 31.85335658073356
avg_episode_per_sec: 0.2745979015580479
collect_time: 21.850130558013916
reward_mean: -100.27731092436977
reward_std: 3.7653885154169155
reward_max: -95.38445378151263
reward_min: -106.47969187675076
queue_len: 0.0664968905334017
wait_time: 0.6310333372960147
delay_time: 4.3126335692962146
pressure: 0.8163129973474801
total_envstep_count: 1171368
total_train_sample_count: 1171368
total_episode_count: 10098
total_duration: 37960.721326351166
[2025-02-21 04:09:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.741245804355792
avg_train_sample_per_sec: 31.741245804355792
avg_episode_per_sec: 0.27363142934789475
collect_time: 21.927305698394775
reward_mean: -102.01248832866482
reward_std: 2.8252798131135926
reward_max: -98.77661064425769
reward_min: -107.21148459383754
queue_len: 0.06764753867948595
wait_time: 0.640468853323823
delay_time: 4.401830100690866
pressure: 0.8241600353669319
total_envstep_count: 1172064
total_train_sample_count: 1172064
total_episode_count: 10104
total_duration: 37982.64863204956
[2025-02-21 04:09:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02302224514345
avg_train_sample_per_sec: 32.02302224514345
avg_episode_per_sec: 0.2760605365960642
collect_time: 21.734363317489624
reward_mean: -99.59488795518206
reward_std: 2.5801348105368156
reward_max: -96.36694677871145
reward_min: -104.17857142857144
queue_len: 0.06604435540794566
wait_time: 0.6253156987817231
delay_time: 4.274635939172481
pressure: 0.8034924845269673
total_envstep_count: 1172760
total_train_sample_count: 1172760
total_episode_count: 10110
total_duration: 38004.38299536705
[2025-02-21 04:10:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.645252115556662
avg_train_sample_per_sec: 31.645252115556662
avg_episode_per_sec: 0.27280389754790224
collect_time: 21.993820667266846
reward_mean: -99.08718487394958
reward_std: 2.7207951194941105
reward_max: -93.74089635854342
reward_min: -102.29971988795519
queue_len: 0.0657076822771549
wait_time: 0.6196769269157707
delay_time: 4.224821232590219
pressure: 0.8043766578249336
total_envstep_count: 1173456
total_train_sample_count: 1173456
total_episode_count: 10116
total_duration: 38026.37681603432
[2025-02-21 04:10:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65734830082729
avg_train_sample_per_sec: 31.65734830082729
avg_episode_per_sec: 0.2729081750071318
collect_time: 21.985416889190674
reward_mean: -101.50443510737625
reward_std: 3.4385283735487517
reward_max: -97.39425770308118
reward_min: -108.25070028011204
queue_len: 0.06731063336032908
wait_time: 0.6326873698197227
delay_time: 4.352529991609152
pressure: 0.8223916887709991
total_envstep_count: 1174152
total_train_sample_count: 1174152
total_episode_count: 10122
total_duration: 38048.36223292351
[2025-02-21 04:10:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.912188197274876
avg_train_sample_per_sec: 30.912188197274876
avg_episode_per_sec: 0.2664843810109903
collect_time: 22.515390872955322
reward_mean: -99.53081232492995
reward_std: 2.8942650170710817
reward_max: -96.23109243697472
reward_min: -103.66036414565826
queue_len: 0.0660018649369562
wait_time: 0.6269781674827314
delay_time: 4.266413078384162
pressure: 0.8094606542882404
total_envstep_count: 1174848
total_train_sample_count: 1174848
total_episode_count: 10128
total_duration: 38070.87762379646
[2025-02-21 04:11:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13510069242416
avg_train_sample_per_sec: 32.13510069242416
avg_episode_per_sec: 0.2770267301071048
collect_time: 21.658559799194336
reward_mean: -101.29948646125116
reward_std: 3.208818617235018
reward_max: -97.21778711484595
reward_min: -105.74089635854338
queue_len: 0.06717472577006046
wait_time: 0.6351210908766689
delay_time: 4.286414801325016
pressure: 0.8295755968169761
total_envstep_count: 1175544
total_train_sample_count: 1175544
total_episode_count: 10134
total_duration: 38092.53618359566
[2025-02-21 04:11:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.776615121587504
avg_train_sample_per_sec: 31.776615121587504
avg_episode_per_sec: 0.27393633725506467
collect_time: 21.902899265289307
reward_mean: -99.84792250233427
reward_std: 4.080054163219805
reward_max: -94.14775910364148
reward_min: -106.75770308123248
queue_len: 0.06621215020048692
wait_time: 0.627625895627924
delay_time: 4.254837973109922
pressure: 0.8006189213085765
total_envstep_count: 1176240
total_train_sample_count: 1176240
total_episode_count: 10140
total_duration: 38114.43908286095
[2025-02-21 04:12:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.27231737531354
avg_train_sample_per_sec: 32.27231737531354
avg_episode_per_sec: 0.2782096325458064
collect_time: 21.566471099853516
reward_mean: -99.84290382819795
reward_std: 2.8865655418788725
reward_max: -95.92997198879556
reward_min: -104.79621848739495
queue_len: 0.06620882216724001
wait_time: 0.6284668044936809
delay_time: 4.23888654117255
pressure: 0.8185234305923962
total_envstep_count: 1176936
total_train_sample_count: 1176936
total_episode_count: 10146
total_duration: 38136.0055539608
[2025-02-21 04:12:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84426363923245
avg_train_sample_per_sec: 31.84426363923245
avg_episode_per_sec: 0.27451951413131426
collect_time: 21.856369733810425
reward_mean: -99.0514705882353
reward_std: 2.4007379006548555
reward_max: -96.10924369747899
reward_min: -103.9761904761905
queue_len: 0.0656839990638165
wait_time: 0.6241926036550781
delay_time: 4.2511808074954605
pressure: 0.8027188328912467
total_envstep_count: 1177632
total_train_sample_count: 1177632
total_episode_count: 10152
total_duration: 38157.86192369461
[2025-02-21 04:12:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.087519334907434
avg_train_sample_per_sec: 32.087519334907434
avg_episode_per_sec: 0.27661654599058133
collect_time: 21.69067645072937
reward_mean: -99.92238562091502
reward_std: 4.380084713653201
reward_max: -92.27100840336135
reward_min: -106.07142857142856
queue_len: 0.06626152892633623
wait_time: 0.6312505882105274
delay_time: 4.304644462856758
pressure: 0.8149867374005306
total_envstep_count: 1178328
total_train_sample_count: 1178328
total_episode_count: 10158
total_duration: 38179.55260014534
[2025-02-21 04:13:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.975898055349745
avg_train_sample_per_sec: 31.975898055349745
avg_episode_per_sec: 0.27565429358060123
collect_time: 21.76639413833618
reward_mean: -98.83823529411764
reward_std: 4.502067037088754
reward_max: -94.8305322128852
reward_min: -108.15686274509801
queue_len: 0.06554259634888437
wait_time: 0.6244292809962181
delay_time: 4.246863491381344
pressure: 0.8034924845269673
total_envstep_count: 1179024
total_train_sample_count: 1179024
total_episode_count: 10164
total_duration: 38201.318994283676
[2025-02-21 04:13:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.892381088026696
avg_train_sample_per_sec: 31.892381088026696
avg_episode_per_sec: 0.27493431972436805
collect_time: 21.823394060134888
reward_mean: -100.61624649859944
reward_std: 2.2817068682595827
reward_max: -97.22198879551827
reward_min: -103.84943977591038
queue_len: 0.06672164887175029
wait_time: 0.6319297391812606
delay_time: 4.293920557030332
pressure: 0.8138815207780725
total_envstep_count: 1179720
total_train_sample_count: 1179720
total_episode_count: 10170
total_duration: 38223.14238834381
[2025-02-21 04:13:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.782316864116478
avg_train_sample_per_sec: 31.782316864116478
avg_episode_per_sec: 0.27398549020790064
collect_time: 21.898969888687134
reward_mean: -101.06722689075632
reward_std: 4.682409044381719
reward_max: -97.67927170868349
reward_min: -110.8347338935574
queue_len: 0.06702070748723891
wait_time: 0.6391873283354014
delay_time: 4.280940188550313
pressure: 0.8196286472148541
total_envstep_count: 1180416
total_train_sample_count: 1180416
total_episode_count: 10176
total_duration: 38245.0413582325
[2025-02-21 04:14:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84680972319512
avg_train_sample_per_sec: 31.84680972319512
avg_episode_per_sec: 0.2745414631309924
collect_time: 21.85462236404419
reward_mean: -100.03676470588236
reward_std: 2.2371660766896984
reward_max: -96.81722689075632
reward_min: -103.093137254902
queue_len: 0.06633737712591668
wait_time: 0.6295013584567338
delay_time: 4.309047110964243
pressure: 0.8111184792219275
total_envstep_count: 1181112
total_train_sample_count: 1181112
total_episode_count: 10182
total_duration: 38266.89598059654
[2025-02-21 04:14:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95384236603803
avg_train_sample_per_sec: 31.95384236603803
avg_episode_per_sec: 0.2754641583279141
collect_time: 21.781418085098267
reward_mean: -98.79049953314659
reward_std: 2.3586427123029226
reward_max: -96.41106442577032
reward_min: -103.10574229691875
queue_len: 0.06551094133497785
wait_time: 0.6214946522375528
delay_time: 4.22724723400768
pressure: 0.8003978779840849
total_envstep_count: 1181808
total_train_sample_count: 1181808
total_episode_count: 10188
total_duration: 38288.67739868164
[2025-02-21 04:15:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.856497177915635
avg_train_sample_per_sec: 31.856497177915635
avg_episode_per_sec: 0.27462497567168653
collect_time: 21.847976446151733
reward_mean: -100.11181139122316
reward_std: 3.24103976719602
reward_max: -93.0700280112045
reward_min: -102.92436974789919
queue_len: 0.06638714283237611
wait_time: 0.6323797202346897
delay_time: 4.2823721712994285
pressure: 0.8085764809902739
total_envstep_count: 1182504
total_train_sample_count: 1182504
total_episode_count: 10194
total_duration: 38310.52537512779
[2025-02-21 04:15:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.935564286239156
avg_train_sample_per_sec: 31.935564286239156
avg_episode_per_sec: 0.2753065886744755
collect_time: 21.79388451576233
reward_mean: -96.82399626517274
reward_std: 2.3095305570414926
reward_max: -93.85014005602243
reward_min: -100.29481792717087
queue_len: 0.06420689407504825
wait_time: 0.6078747922688084
delay_time: 4.164191396488633
pressure: 0.7908930150309462
total_envstep_count: 1183200
total_train_sample_count: 1183200
total_episode_count: 10200
total_duration: 38332.319259643555
[2025-02-21 04:15:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.833164844178764
avg_train_sample_per_sec: 31.833164844178764
avg_episode_per_sec: 0.27442383486361005
collect_time: 21.86399006843567
reward_mean: -101.93557422969188
reward_std: 2.3417042701998114
reward_max: -99.13025210084031
reward_min: -105.53641456582632
queue_len: 0.06759653463507419
wait_time: 0.6489507717322118
delay_time: 4.351642728856002
pressure: 0.8191865605658708
total_envstep_count: 1183896
total_train_sample_count: 1183896
total_episode_count: 10206
total_duration: 38354.18324971199
[2025-02-21 04:16:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.636951634797764
avg_train_sample_per_sec: 31.636951634797764
avg_episode_per_sec: 0.27273234167929106
collect_time: 21.99959111213684
reward_mean: -102.0860177404295
reward_std: 1.9738859014055365
reward_max: -99.7906162464986
reward_min: -105.71428571428571
queue_len: 0.06769629823635909
wait_time: 0.6399153936552516
delay_time: 4.348544492432157
pressure: 0.8265915119363395
total_envstep_count: 1184592
total_train_sample_count: 1184592
total_episode_count: 10212
total_duration: 38376.18284082413
[2025-02-21 04:16:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82843765369488
avg_train_sample_per_sec: 31.82843765369488
avg_episode_per_sec: 0.27438308322150756
collect_time: 21.867237329483032
reward_mean: -100.5014005602241
reward_std: 2.363341354006351
reward_max: -95.98319327731095
reward_min: -102.90756302521008
queue_len: 0.06664549108768177
wait_time: 0.629851188928268
delay_time: 4.318682796347361
pressure: 0.8141025641025642
total_envstep_count: 1185288
total_train_sample_count: 1185288
total_episode_count: 10218
total_duration: 38398.05007815361
[2025-02-21 04:16:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.874438082300298
avg_train_sample_per_sec: 31.874438082300298
avg_episode_per_sec: 0.2747796386405198
collect_time: 21.835679054260254
reward_mean: -99.75070028011203
reward_std: 2.3554628483175706
reward_max: -97.00980392156866
reward_min: -103.54271708683476
queue_len: 0.06614767923084353
wait_time: 0.6313581688201363
delay_time: 4.286044563723441
pressure: 0.8073607427055703
total_envstep_count: 1185984
total_train_sample_count: 1185984
total_episode_count: 10224
total_duration: 38419.88575720787
[2025-02-21 04:17:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10750895423647
avg_train_sample_per_sec: 32.10750895423647
avg_episode_per_sec: 0.276788870295142
collect_time: 21.67717218399048
reward_mean: -97.36379551820728
reward_std: 2.1718673249657607
reward_max: -93.69537815126048
reward_min: -100.14775910364146
queue_len: 0.06456485113939475
wait_time: 0.6136014861293765
delay_time: 4.171440930448513
pressure: 0.7901193633952254
total_envstep_count: 1186680
total_train_sample_count: 1186680
total_episode_count: 10230
total_duration: 38441.56292939186
[2025-02-21 04:17:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09114407018852
avg_train_sample_per_sec: 32.09114407018852
avg_episode_per_sec: 0.2766477937085217
collect_time: 21.688226461410522
reward_mean: -99.63480392156862
reward_std: 3.5898121211011667
reward_max: -93.70238095238099
reward_min: -104.72128851540613
queue_len: 0.0660708248816768
wait_time: 0.6288219752976345
delay_time: 4.273311871783456
pressure: 0.8080238726790451
total_envstep_count: 1187376
total_train_sample_count: 1187376
total_episode_count: 10236
total_duration: 38463.25115585327
[2025-02-21 04:17:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04853014016527
avg_train_sample_per_sec: 32.04853014016527
avg_episode_per_sec: 0.276280432242804
collect_time: 21.71706461906433
reward_mean: -98.22724089635854
reward_std: 1.848936560653251
reward_max: -95.25350140056025
reward_min: -100.90336134453783
queue_len: 0.06513742765010515
wait_time: 0.6153589198721044
delay_time: 4.150939742034319
pressure: 0.7994031830238727
total_envstep_count: 1188072
total_train_sample_count: 1188072
total_episode_count: 10242
total_duration: 38484.968220472336
[2025-02-21 04:18:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70327727547928
avg_train_sample_per_sec: 31.70327727547928
avg_episode_per_sec: 0.2733041144437869
collect_time: 21.953566312789917
reward_mean: -99.48821195144723
reward_std: 1.9241381087790004
reward_max: -95.93067226890759
reward_min: -101.43907563025209
queue_len: 0.0659736153524186
wait_time: 0.6236636785571875
delay_time: 4.2563466019712335
pressure: 0.8123342175066312
total_envstep_count: 1188768
total_train_sample_count: 1188768
total_episode_count: 10248
total_duration: 38506.921786785126
[2025-02-21 04:18:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.678034253052193
avg_train_sample_per_sec: 31.678034253052193
avg_episode_per_sec: 0.2730865021814844
collect_time: 21.971060276031494
reward_mean: -98.8703314659197
reward_std: 2.84883335315211
reward_max: -96.16596638655462
reward_min: -104.08823529411762
queue_len: 0.0655638802824401
wait_time: 0.6173389448617642
delay_time: 4.246211633494711
pressure: 0.800950486295314
total_envstep_count: 1189464
total_train_sample_count: 1189464
total_episode_count: 10254
total_duration: 38528.89284706116
[2025-02-21 04:19:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03478220333714
avg_train_sample_per_sec: 32.03478220333714
avg_episode_per_sec: 0.27616191554600983
collect_time: 21.72638463973999
reward_mean: -98.72152194211016
reward_std: 2.6884994685855728
reward_max: -94.47899159663864
reward_min: -102.70868347338936
queue_len: 0.0654652002268635
wait_time: 0.6230053471432783
delay_time: 4.229346917462639
pressure: 0.8007294429708223
total_envstep_count: 1190160
total_train_sample_count: 1190160
total_episode_count: 10260
total_duration: 38550.6192317009
[2025-02-21 04:19:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.986060944339684
avg_train_sample_per_sec: 31.986060944339684
avg_episode_per_sec: 0.2757419046925835
collect_time: 21.759478330612183
reward_mean: -100.5255602240896
reward_std: 2.7722612843911225
reward_max: -97.5287114845938
reward_min: -105.29341736694674
queue_len: 0.06666151208494007
wait_time: 0.6261310669272131
delay_time: 4.36679465529368
pressure: 0.8167550839964633
total_envstep_count: 1190856
total_train_sample_count: 1190856
total_episode_count: 10266
total_duration: 38572.37871003151
[2025-02-21 04:19:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.009023118715405
avg_train_sample_per_sec: 32.009023118715405
avg_episode_per_sec: 0.2759398544716845
collect_time: 21.743868827819824
reward_mean: -97.54073295985063
reward_std: 0.6859513779210732
reward_max: -96.7934173669468
reward_min: -98.71848739495796
queue_len: 0.0646821836603784
wait_time: 0.6115237872337265
delay_time: 4.237430006129717
pressure: 0.7885720601237843
total_envstep_count: 1191552
total_train_sample_count: 1191552
total_episode_count: 10272
total_duration: 38594.12257885933
[2025-02-21 04:20:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99864395451241
avg_train_sample_per_sec: 31.99864395451241
avg_episode_per_sec: 0.2758503789182104
collect_time: 21.750921726226807
reward_mean: -99.05742296918766
reward_std: 2.7436496672095236
reward_max: -94.7282913165266
reward_min: -103.52661064425769
queue_len: 0.06568794626603956
wait_time: 0.6176948122308163
delay_time: 4.212731841881307
pressure: 0.8110079575596818
total_envstep_count: 1192248
total_train_sample_count: 1192248
total_episode_count: 10278
total_duration: 38615.873500585556
[2025-02-21 04:20:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01055484519326
avg_train_sample_per_sec: 32.01055484519326
avg_episode_per_sec: 0.27595305901028677
collect_time: 21.742828369140625
reward_mean: -99.65954715219421
reward_std: 3.2837787519446575
reward_max: -95.87535014005601
reward_min: -105.7717086834734
queue_len: 0.06608723285954524
wait_time: 0.6280850868198737
delay_time: 4.282314651447295
pressure: 0.8062555260831124
total_envstep_count: 1192944
total_train_sample_count: 1192944
total_episode_count: 10284
total_duration: 38637.6163289547
[2025-02-21 04:20:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.38947599399568
avg_train_sample_per_sec: 32.38947599399568
avg_episode_per_sec: 0.2792196206378938
collect_time: 21.48846125602722
reward_mean: -97.85842670401495
reward_std: 2.5248393128269604
reward_max: -92.77521008403362
reward_min: -100.42857142857143
queue_len: 0.0648928559045192
wait_time: 0.6134317564337849
delay_time: 4.211303910570507
pressure: 0.7971927497789567
total_envstep_count: 1193640
total_train_sample_count: 1193640
total_episode_count: 10290
total_duration: 38659.104790210724
[2025-02-21 04:21:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10470281423126
avg_train_sample_per_sec: 32.10470281423126
avg_episode_per_sec: 0.27676467943302807
collect_time: 21.6790668964386
reward_mean: -97.35667600373479
reward_std: 1.9622179327350069
reward_max: -93.58403361344534
reward_min: -99.9341736694678
queue_len: 0.06456012997595147
wait_time: 0.6079937501083547
delay_time: 4.20344044074423
pressure: 0.7984084880636605
total_envstep_count: 1194336
total_train_sample_count: 1194336
total_episode_count: 10296
total_duration: 38680.78385710716
[2025-02-21 04:21:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.953400618254424
avg_train_sample_per_sec: 31.953400618254424
avg_episode_per_sec: 0.27546035015736575
collect_time: 21.781719207763672
reward_mean: -98.11846405228759
reward_std: 1.5832258778655597
reward_max: -95.4516806722689
reward_min: -99.86974789915965
queue_len: 0.06506529446438168
wait_time: 0.6163183995967972
delay_time: 4.219359653852547
pressure: 0.7966401414677277
total_envstep_count: 1195032
total_train_sample_count: 1195032
total_episode_count: 10302
total_duration: 38702.565576314926
[2025-02-21 04:22:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.910193968262007
avg_train_sample_per_sec: 31.910193968262007
avg_episode_per_sec: 0.2750878790367415
collect_time: 21.811211824417114
reward_mean: -98.99007936507935
reward_std: 1.7838574139760666
reward_max: -96.90336134453781
reward_min: -101.52240896358539
queue_len: 0.06564328870363352
wait_time: 0.6221026761721488
delay_time: 4.244013742761168
pressure: 0.8111184792219275
total_envstep_count: 1195728
total_train_sample_count: 1195728
total_episode_count: 10308
total_duration: 38724.37678813934
[2025-02-21 04:22:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97764764262641
avg_train_sample_per_sec: 31.97764764262641
avg_episode_per_sec: 0.275669376229538
collect_time: 21.76520323753357
reward_mean: -98.18172268907561
reward_std: 3.5234370686188123
reward_max: -94.56302521008402
reward_min: -103.9768907563025
queue_len: 0.06510724316251698
wait_time: 0.6118089145472513
delay_time: 4.226177251562528
pressure: 0.8013925729442971
total_envstep_count: 1196424
total_train_sample_count: 1196424
total_episode_count: 10314
total_duration: 38746.14199137688
[2025-02-21 04:22:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07385915875617
avg_train_sample_per_sec: 32.07385915875617
avg_episode_per_sec: 0.27649878585134635
collect_time: 21.69991445541382
reward_mean: -99.82679738562092
reward_std: 1.8006459389400646
reward_max: -96.4516806722689
reward_min: -101.48249299719886
queue_len: 0.06619814150240114
wait_time: 0.6258147489765137
delay_time: 4.289613350188884
pressure: 0.8066976127320955
total_envstep_count: 1197120
total_train_sample_count: 1197120
total_episode_count: 10320
total_duration: 38767.84190583229
[2025-02-21 04:23:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02762645332964
avg_train_sample_per_sec: 32.02762645332964
avg_episode_per_sec: 0.2761002280459452
collect_time: 21.731238842010498
reward_mean: -98.81570961718022
reward_std: 3.1435117257240774
reward_max: -95.39915966386555
reward_min: -105.1736694677871
queue_len: 0.06552765889733436
wait_time: 0.6201301586063249
delay_time: 4.2616267554777245
pressure: 0.8044871794871794
total_envstep_count: 1197816
total_train_sample_count: 1197816
total_episode_count: 10326
total_duration: 38789.5731446743
[2025-02-21 04:23:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.9673994319592
avg_train_sample_per_sec: 31.9673994319592
avg_episode_per_sec: 0.2755810295858552
collect_time: 21.772180795669556
reward_mean: -98.94934640522877
reward_std: 1.980933374782766
reward_max: -95.36764705882356
reward_min: -101.90406162464986
queue_len: 0.06561627745704825
wait_time: 0.6184902121768246
delay_time: 4.270401473990977
pressure: 0.8095711759504863
total_envstep_count: 1198512
total_train_sample_count: 1198512
total_episode_count: 10332
total_duration: 38811.34532546997
[2025-02-21 04:23:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.999267244127722
avg_train_sample_per_sec: 31.999267244127722
avg_episode_per_sec: 0.2758557521045493
collect_time: 21.750498056411743
reward_mean: -99.26283846872083
reward_std: 3.088395609816378
reward_max: -93.70238095238093
reward_min: -102.83263305322126
queue_len: 0.06582416344079631
wait_time: 0.6218267589971446
delay_time: 4.322810867872339
pressure: 0.7987400530503979
total_envstep_count: 1199208
total_train_sample_count: 1199208
total_episode_count: 10338
total_duration: 38833.09582352638
[2025-02-21 04:24:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.601589270364983
avg_train_sample_per_sec: 31.601589270364983
avg_episode_per_sec: 0.27242749371004293
collect_time: 22.024208784103394
reward_mean: -99.69479458450046
reward_std: 2.4920439477478964
reward_max: -95.20588235294116
reward_min: -102.4894957983193
queue_len: 0.06611060648839552
wait_time: 0.6187968556122715
delay_time: 4.278006736507225
pressure: 0.8122236958443855
total_envstep_count: 1199904
total_train_sample_count: 1199904
total_episode_count: 10344
total_duration: 38855.120032310486
[2025-02-21 04:24:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.89354831264199
avg_train_sample_per_sec: 30.89354831264199
avg_episode_per_sec: 0.26632369235036196
collect_time: 22.52897572517395
reward_mean: -97.96078431372551
reward_std: 2.3777858330294945
reward_max: -93.92577030812325
reward_min: -101.27450980392159
queue_len: 0.0649607323035315
wait_time: 0.6107814810274242
delay_time: 4.240547806258404
pressure: 0.794761273209549
total_envstep_count: 1200600
total_train_sample_count: 1200600
total_episode_count: 10350
total_duration: 38877.64900803566
[2025-02-21 04:25:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98307030248273
avg_train_sample_per_sec: 31.98307030248273
avg_episode_per_sec: 0.2757161232972649
collect_time: 21.761512994766235
reward_mean: -97.11624649859944
reward_std: 1.9873768216818928
reward_max: -94.8935574229692
reward_min: -100.625350140056
queue_len: 0.06440069396458849
wait_time: 0.6005781954691691
delay_time: 4.178553949224927
pressure: 0.7892351900972591
total_envstep_count: 1201296
total_train_sample_count: 1201296
total_episode_count: 10356
total_duration: 38899.410521030426
[2025-02-21 04:25:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.680009240830586
avg_train_sample_per_sec: 31.680009240830586
avg_episode_per_sec: 0.2731035279381947
collect_time: 21.969690561294556
reward_mean: -101.50828664799252
reward_std: 4.00058422733092
reward_max: -95.90336134453781
reward_min: -106.75210084033611
queue_len: 0.06731318743235579
wait_time: 0.6374977709916857
delay_time: 4.349565660013548
pressure: 0.825707338638373
total_envstep_count: 1201992
total_train_sample_count: 1201992
total_episode_count: 10362
total_duration: 38921.38021159172
[2025-02-21 04:25:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.638873496424
avg_train_sample_per_sec: 31.638873496424
avg_episode_per_sec: 0.27274890945193103
collect_time: 21.998254776000977
reward_mean: -98.58940242763772
reward_std: 3.3128672613212435
reward_max: -93.24929971988797
reward_min: -103.59733893557421
queue_len: 0.06537758781673587
wait_time: 0.6161574156629938
delay_time: 4.2973722370568845
pressure: 0.805923961096375
total_envstep_count: 1202688
total_train_sample_count: 1202688
total_episode_count: 10368
total_duration: 38943.37846636772
[2025-02-21 04:26:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.15209721480897
avg_train_sample_per_sec: 32.15209721480897
avg_episode_per_sec: 0.2771732518518014
collect_time: 21.64711046218872
reward_mean: -100.64589169000935
reward_std: 3.2100578256217247
reward_max: -95.03291316526612
reward_min: -104.84453781512609
queue_len: 0.0667413074867436
wait_time: 0.6321943565224498
delay_time: 4.315653027403189
pressure: 0.8237179487179486
total_envstep_count: 1203384
total_train_sample_count: 1203384
total_episode_count: 10374
total_duration: 38965.02557682991
[2025-02-21 04:26:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.972047886341763
avg_train_sample_per_sec: 31.972047886341763
avg_episode_per_sec: 0.2756211024684635
collect_time: 21.769015312194824
reward_mean: -99.06162464985995
reward_std: 1.5521132214649336
reward_max: -96.20658263305322
reward_min: -101.17436974789914
queue_len: 0.06569073252643233
wait_time: 0.6175890117320137
delay_time: 4.220254500343472
pressure: 0.8118921308576481
total_envstep_count: 1204080
total_train_sample_count: 1204080
total_episode_count: 10380
total_duration: 38986.794592142105
[2025-02-21 04:26:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.787376144588027
avg_train_sample_per_sec: 31.787376144588027
avg_episode_per_sec: 0.27402910469472436
collect_time: 21.895484447479248
reward_mean: -100.87990196078432
reward_std: 2.9888100321391544
reward_max: -95.00700280112046
reward_min: -104.22058823529417
queue_len: 0.06689648671139543
wait_time: 0.6314262000113927
delay_time: 4.306174028551694
pressure: 0.8209549071618037
total_envstep_count: 1204776
total_train_sample_count: 1204776
total_episode_count: 10386
total_duration: 39008.690076589584
[2025-02-21 04:27:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.994021776405415
avg_train_sample_per_sec: 31.994021776405415
avg_episode_per_sec: 0.2758105325552191
collect_time: 21.754064083099365
reward_mean: -100.77112511671335
reward_std: 2.356120072906374
reward_max: -97.43837535014005
reward_min: -103.82563025210085
queue_len: 0.066824353525672
wait_time: 0.6318970006216457
delay_time: 4.333641481199915
pressure: 0.8166445623342176
total_envstep_count: 1205472
total_train_sample_count: 1205472
total_episode_count: 10392
total_duration: 39030.444140672684
[2025-02-21 04:27:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.792446384552875
avg_train_sample_per_sec: 31.792446384552875
avg_episode_per_sec: 0.2740728136599386
collect_time: 21.891992568969727
reward_mean: -99.03139589169001
reward_std: 3.455466332109224
reward_max: -94.27380952380952
reward_min: -105.34313725490192
queue_len: 0.0656706869308289
wait_time: 0.6183860369965847
delay_time: 4.2756231008144985
pressure: 0.809681697612732
total_envstep_count: 1206168
total_train_sample_count: 1206168
total_episode_count: 10398
total_duration: 39052.33613324165
[2025-02-21 04:28:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93876060191839
avg_train_sample_per_sec: 31.93876060191839
avg_episode_per_sec: 0.2753341431199861
collect_time: 21.791703462600708
reward_mean: -98.50245098039215
reward_std: 3.3619262245192614
reward_max: -93.10084033613444
reward_min: -103.52871148459386
queue_len: 0.06531992770583034
wait_time: 0.6148165278489822
delay_time: 4.233347439218833
pressure: 0.8012820512820512
total_envstep_count: 1206864
total_train_sample_count: 1206864
total_episode_count: 10404
total_duration: 39074.127836704254
[2025-02-21 04:28:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.614604218288946
avg_train_sample_per_sec: 31.614604218288946
avg_episode_per_sec: 0.27253969153697366
collect_time: 22.01514196395874
reward_mean: -101.09138655462185
reward_std: 3.867324012654902
reward_max: -95.39145658263304
reward_min: -105.09243697478995
queue_len: 0.06703672848449725
wait_time: 0.6341856813459248
delay_time: 4.256041771659482
pressure: 0.8306808134394341
total_envstep_count: 1207560
total_train_sample_count: 1207560
total_episode_count: 10410
total_duration: 39096.14297866821
[2025-02-21 04:28:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26955726390962
avg_train_sample_per_sec: 32.26955726390962
avg_episode_per_sec: 0.2781858384819795
collect_time: 21.568315744400024
reward_mean: -101.4436274509804
reward_std: 3.184065726397008
reward_max: -97.73809523809521
reward_min: -106.23879551820727
queue_len: 0.06727030998075623
wait_time: 0.6373740145925745
delay_time: 4.276717875429498
pressure: 0.8300176834659595
total_envstep_count: 1208256
total_train_sample_count: 1208256
total_episode_count: 10416
total_duration: 39117.71129441261
[2025-02-21 04:29:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04315947584651
avg_train_sample_per_sec: 32.04315947584651
avg_episode_per_sec: 0.27623413341246994
collect_time: 21.720704555511475
reward_mean: -98.14647525676936
reward_std: 2.289212916309255
reward_max: -94.61974789915966
reward_min: -101.67787114845935
queue_len: 0.0650838695336667
wait_time: 0.6161362865216821
delay_time: 4.241335373036242
pressure: 0.7986295313881521
total_envstep_count: 1208952
total_train_sample_count: 1208952
total_episode_count: 10422
total_duration: 39139.431998968124
[2025-02-21 04:29:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0458342054022
avg_train_sample_per_sec: 32.0458342054022
avg_episode_per_sec: 0.27625719142588107
collect_time: 21.718891620635986
reward_mean: -101.40849673202614
reward_std: 1.0948831714295935
reward_max: -100.11274509803921
reward_min: -103.38235294117642
queue_len: 0.06724701374802794
wait_time: 0.63829224218423
delay_time: 4.300357730329733
pressure: 0.8294650751547303
total_envstep_count: 1209648
total_train_sample_count: 1209648
total_episode_count: 10428
total_duration: 39161.15089058876
[2025-02-21 04:29:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21272000497088
avg_train_sample_per_sec: 32.21272000497088
avg_episode_per_sec: 0.27769586211181796
collect_time: 21.606371641159058
reward_mean: -100.08648459383754
reward_std: 2.625349167185161
reward_max: -96.01610644257697
reward_min: -103.84803921568628
queue_len: 0.06637034787389758
wait_time: 0.6275337168465971
delay_time: 4.289418989156287
pressure: 0.8210654288240494
total_envstep_count: 1210344
total_train_sample_count: 1210344
total_episode_count: 10434
total_duration: 39182.75726222992
[2025-02-21 04:30:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13740232157536
avg_train_sample_per_sec: 32.13740232157536
avg_episode_per_sec: 0.27704657173771857
collect_time: 21.6570086479187
reward_mean: -99.65697945845004
reward_std: 2.716236300956263
reward_max: -95.24789915966389
reward_min: -103.32282913165265
queue_len: 0.06608553014486077
wait_time: 0.6208156560590637
delay_time: 4.319916489463393
pressure: 0.8112290008841733
total_envstep_count: 1211040
total_train_sample_count: 1211040
total_episode_count: 10440
total_duration: 39204.41427087784
[2025-02-21 04:30:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.988318138355176
avg_train_sample_per_sec: 31.988318138355176
avg_episode_per_sec: 0.27576136326168255
collect_time: 21.75794291496277
reward_mean: -100.32166199813257
reward_std: 2.533822755150393
reward_max: -96.1190476190476
reward_min: -104.03501400560222
queue_len: 0.0665263010597696
wait_time: 0.6282250190084877
delay_time: 4.254365318667237
pressure: 0.8169761273209547
total_envstep_count: 1211736
total_train_sample_count: 1211736
total_episode_count: 10446
total_duration: 39226.1722137928
[2025-02-21 04:30:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03933036684125
avg_train_sample_per_sec: 32.03933036684125
avg_episode_per_sec: 0.27620112385207973
collect_time: 21.723300457000732
reward_mean: -98.7483660130719
reward_std: 2.8452734757577764
reward_max: -94.77030812324927
reward_min: -103.37184873949576
queue_len: 0.0654830013349283
wait_time: 0.6152045920047948
delay_time: 4.231520507059694
pressure: 0.8060344827586207
total_envstep_count: 1212432
total_train_sample_count: 1212432
total_episode_count: 10452
total_duration: 39247.8955142498
[2025-02-21 04:31:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.638996942439057
avg_train_sample_per_sec: 31.638996942439057
avg_episode_per_sec: 0.272749973641716
collect_time: 21.9981689453125
reward_mean: -100.16293183940242
reward_std: 1.9113416551148923
reward_max: -98.29901960784315
reward_min: -104.1995798319328
queue_len: 0.06642104233382123
wait_time: 0.6282246320278774
delay_time: 4.295483017492841
pressure: 0.8107869142351901
total_envstep_count: 1213128
total_train_sample_count: 1213128
total_episode_count: 10458
total_duration: 39269.893683195114
[2025-02-21 04:31:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.418416299295124
avg_train_sample_per_sec: 31.418416299295124
avg_episode_per_sec: 0.2708484163732338
collect_time: 22.152612447738647
reward_mean: -98.68417366946778
reward_std: 3.404507439981077
reward_max: -94.9299719887955
reward_min: -105.1120448179272
queue_len: 0.06544043346781685
wait_time: 0.6184597955008707
delay_time: 4.251646865509734
pressure: 0.8015030946065428
total_envstep_count: 1213824
total_train_sample_count: 1213824
total_episode_count: 10464
total_duration: 39292.04629564285
[2025-02-21 04:32:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14641389826964
avg_train_sample_per_sec: 32.14641389826964
avg_episode_per_sec: 0.27712425774370386
collect_time: 21.65093755722046
reward_mean: -100.12686741363213
reward_std: 1.5946350177610302
reward_max: -97.30182072829132
reward_min: -102.06442577030812
queue_len: 0.06639712693211679
wait_time: 0.6244113250959092
delay_time: 4.256921959176371
pressure: 0.8221706454465075
total_envstep_count: 1214520
total_train_sample_count: 1214520
total_episode_count: 10470
total_duration: 39313.69723320007
[2025-02-21 04:32:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.762314936204298
avg_train_sample_per_sec: 31.762314936204298
avg_episode_per_sec: 0.27381305979486464
collect_time: 21.912760496139526
reward_mean: -100.26132119514472
reward_std: 1.818839042480358
reward_max: -97.22969187675068
reward_min: -102.34103641456585
queue_len: 0.06648628726468482
wait_time: 0.6261367168441204
delay_time: 4.30059862694534
pressure: 0.8190760389036251
total_envstep_count: 1215216
total_train_sample_count: 1215216
total_episode_count: 10476
total_duration: 39335.60999369621
[2025-02-21 04:32:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59703149117987
avg_train_sample_per_sec: 31.59703149117987
avg_episode_per_sec: 0.27238820251017126
collect_time: 22.027385711669922
reward_mean: -99.3049719887955
reward_std: 2.694253682695517
reward_max: -96.34033613445374
reward_min: -104.65336134453784
queue_len: 0.06585210344084583
wait_time: 0.618439904697511
delay_time: 4.274852366218834
pressure: 0.8059239610963749
total_envstep_count: 1215912
total_train_sample_count: 1215912
total_episode_count: 10482
total_duration: 39357.63737940788
[2025-02-21 04:33:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25826844804425
avg_train_sample_per_sec: 32.25826844804425
avg_episode_per_sec: 0.27808852110382976
collect_time: 21.57586359977722
reward_mean: -101.39624183006538
reward_std: 2.889623735425322
reward_max: -96.48179271708683
reward_min: -105.69187675070029
queue_len: 0.06723888715521577
wait_time: 0.6358375467782161
delay_time: 4.3602360415417225
pressure: 0.8250442086648982
total_envstep_count: 1216608
total_train_sample_count: 1216608
total_episode_count: 10488
total_duration: 39379.21324300766
[2025-02-21 04:33:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.078230897900184
avg_train_sample_per_sec: 32.078230897900184
avg_episode_per_sec: 0.2765364732577602
collect_time: 21.696957111358643
reward_mean: -98.25303454715218
reward_std: 1.025518057917699
reward_max: -96.76610644257703
reward_min: -99.99439775910365
queue_len: 0.06515453219307173
wait_time: 0.6159193451916577
delay_time: 4.250310138389264
pressure: 0.8038240495137047
total_envstep_count: 1217304
total_train_sample_count: 1217304
total_episode_count: 10494
total_duration: 39400.91020011902
[2025-02-21 04:33:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.816577963632827
avg_train_sample_per_sec: 31.816577963632827
avg_episode_per_sec: 0.2742808445140761
collect_time: 21.875388383865356
reward_mean: -98.34757236227824
reward_std: 1.3088148284409649
reward_max: -96.59663865546219
reward_min: -100.62815126050423
queue_len: 0.06521722305190866
wait_time: 0.6147346427518842
delay_time: 4.236664523859394
pressure: 0.8043766578249337
total_envstep_count: 1218000
total_train_sample_count: 1218000
total_episode_count: 10500
total_duration: 39422.785588502884
[2025-02-21 04:34:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07850232054235
avg_train_sample_per_sec: 32.07850232054235
avg_episode_per_sec: 0.2765388131081237
collect_time: 21.696773529052734
reward_mean: -98.7529178338002
reward_std: 1.0719924168180472
reward_max: -97.12044817927172
reward_min: -100.48669467787114
queue_len: 0.06548601978368711
wait_time: 0.619506810239569
delay_time: 4.222924430816685
pressure: 0.8015030946065429
total_envstep_count: 1218696
total_train_sample_count: 1218696
total_episode_count: 10506
total_duration: 39444.48236203194
[2025-02-21 04:34:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.885119202275323
avg_train_sample_per_sec: 31.885119202275323
avg_episode_per_sec: 0.2748717172609942
collect_time: 21.828364372253418
reward_mean: -96.89612511671335
reward_std: 2.5061573235229777
reward_max: -93.2626050420168
reward_min: -100.76750700280115
queue_len: 0.06425472487845714
wait_time: 0.6028411032848152
delay_time: 4.169314718669199
pressure: 0.7934350132625995
total_envstep_count: 1219392
total_train_sample_count: 1219392
total_episode_count: 10512
total_duration: 39466.31072640419
[2025-02-21 04:35:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.050038907627396
avg_train_sample_per_sec: 32.050038907627396
avg_episode_per_sec: 0.2762934388588569
collect_time: 21.716042280197144
reward_mean: -97.2484827264239
reward_std: 2.9288707156738885
reward_max: -92.25350140056027
reward_min: -101.54551820728291
queue_len: 0.06448838377083814
wait_time: 0.603325835197032
delay_time: 4.225093927359668
pressure: 0.7961980548187445
total_envstep_count: 1220088
total_train_sample_count: 1220088
total_episode_count: 10518
total_duration: 39488.02676868439
[2025-02-21 04:35:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0398736591602
avg_train_sample_per_sec: 32.0398736591602
avg_episode_per_sec: 0.2762058074065534
collect_time: 21.72293210029602
reward_mean: -99.10130718954247
reward_std: 1.664706626008448
reward_max: -97.67577030812322
reward_min: -102.62675070028011
queue_len: 0.06571704720791942
wait_time: 0.6210959074169012
delay_time: 4.2411395827858955
pressure: 0.8127763041556145
total_envstep_count: 1220784
total_train_sample_count: 1220784
total_episode_count: 10524
total_duration: 39509.74970078468
[2025-02-21 04:35:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.875605067596
avg_train_sample_per_sec: 31.875605067596
avg_episode_per_sec: 0.2747896988585862
collect_time: 21.834879636764526
reward_mean: -98.21486928104575
reward_std: 2.304287303516095
reward_max: -93.99579831932773
reward_min: -100.7247899159664
queue_len: 0.06512922366117092
wait_time: 0.6115724693944776
delay_time: 4.217814890874013
pressure: 0.8011715296198055
total_envstep_count: 1221480
total_train_sample_count: 1221480
total_episode_count: 10530
total_duration: 39531.58458042145
[2025-02-21 04:36:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.769392370110562
avg_train_sample_per_sec: 31.769392370110562
avg_episode_per_sec: 0.2738740721561255
collect_time: 21.907878875732422
reward_mean: -97.30018674136319
reward_std: 1.5527750335088149
reward_max: -94.66176470588235
reward_min: -98.88795518207283
queue_len: 0.06452267025289336
wait_time: 0.6081439759811971
delay_time: 4.149096259441128
pressure: 0.7999557913351016
total_envstep_count: 1222176
total_train_sample_count: 1222176
total_episode_count: 10536
total_duration: 39553.49245929718
[2025-02-21 04:36:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.18582452000051
avg_train_sample_per_sec: 32.18582452000051
avg_episode_per_sec: 0.277464004482763
collect_time: 21.62442660331726
reward_mean: -99.32259570494864
reward_std: 2.9674844562018405
reward_max: -95.35504201680672
reward_min: -103.30742296918767
queue_len: 0.06586379025527099
wait_time: 0.6221429995517217
delay_time: 4.238964278225915
pressure: 0.8157603890362511
total_envstep_count: 1222872
total_train_sample_count: 1222872
total_episode_count: 10542
total_duration: 39575.1168859005
[2025-02-21 04:36:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09475551019677
avg_train_sample_per_sec: 32.09475551019677
avg_episode_per_sec: 0.27667892681204115
collect_time: 21.68578600883484
reward_mean: -101.57446311858077
reward_std: 2.845887820175708
reward_max: -97.66176470588239
reward_min: -104.53921568627452
queue_len: 0.06735707103354163
wait_time: 0.6380050251754105
delay_time: 4.3332326528974905
pressure: 0.8285809018567639
total_envstep_count: 1223568
total_train_sample_count: 1223568
total_episode_count: 10548
total_duration: 39596.80267190933
[2025-02-21 04:37:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.876695560848617
avg_train_sample_per_sec: 31.876695560848617
avg_episode_per_sec: 0.2747990996624881
collect_time: 21.8341326713562
reward_mean: -98.86052754435109
reward_std: 1.0982275499246121
reward_max: -97.1358543417367
reward_min: -100.51050420168065
queue_len: 0.06555737900819038
wait_time: 0.6201803112933945
delay_time: 4.186197666012611
pressure: 0.8118921308576481
total_envstep_count: 1224264
total_train_sample_count: 1224264
total_episode_count: 10554
total_duration: 39618.63680458069
[2025-02-21 04:37:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.46541798960817
avg_train_sample_per_sec: 32.46541798960817
avg_episode_per_sec: 0.2798742930138635
collect_time: 21.438196182250977
reward_mean: -98.01540616246497
reward_std: 2.894819160427943
reward_max: -95.69677871148458
reward_min: -103.9768907563025
queue_len: 0.06499695368863725
wait_time: 0.6139508522241789
delay_time: 4.233390315174204
pressure: 0.8006189213085765
total_envstep_count: 1224960
total_train_sample_count: 1224960
total_episode_count: 10560
total_duration: 39640.07500076294
[2025-02-21 04:38:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.224891855797665
avg_train_sample_per_sec: 32.224891855797665
avg_episode_per_sec: 0.2778007918603247
collect_time: 21.59821057319641
reward_mean: -96.3794351073763
reward_std: 4.003256583229331
reward_max: -92.14215686274513
reward_min: -103.5749299719888
queue_len: 0.06391209224627074
wait_time: 0.6019170709840082
delay_time: 4.158572033125087
pressure: 0.7913351016799294
total_envstep_count: 1225656
total_train_sample_count: 1225656
total_episode_count: 10566
total_duration: 39661.673211336136
[2025-02-21 04:38:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.246534582450206
avg_train_sample_per_sec: 31.246534582450206
avg_episode_per_sec: 0.26936667743491555
collect_time: 22.27447009086609
reward_mean: -98.85994397759104
reward_std: 3.1664395294853716
reward_max: -93.88445378151259
reward_min: -102.97198879551817
queue_len: 0.06555699202758025
wait_time: 0.6179353593780572
delay_time: 4.271109284043864
pressure: 0.803050397877984
total_envstep_count: 1226352
total_train_sample_count: 1226352
total_episode_count: 10572
total_duration: 39683.947681427
[2025-02-21 04:38:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81068644275189
avg_train_sample_per_sec: 31.81068644275189
avg_episode_per_sec: 0.2742300555409646
collect_time: 21.87943983078003
reward_mean: -98.41946778711484
reward_std: 1.9745877680274029
reward_max: -95.890756302521
reward_min: -101.87394957983193
queue_len: 0.06526489906307349
wait_time: 0.6074717906614457
delay_time: 4.227266071981389
pressure: 0.8042661361626878
total_envstep_count: 1227048
total_train_sample_count: 1227048
total_episode_count: 10578
total_duration: 39705.82712125778
[2025-02-21 04:39:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.998863874412525
avg_train_sample_per_sec: 31.998863874412525
avg_episode_per_sec: 0.2758522747794183
collect_time: 21.75077223777771
reward_mean: -97.69386087768443
reward_std: 1.903433716461652
reward_max: -94.26120448179269
reward_min: -99.92156862745101
queue_len: 0.06478372737246978
wait_time: 0.6138537974871646
delay_time: 4.246611307204589
pressure: 0.7900088417329796
total_envstep_count: 1227744
total_train_sample_count: 1227744
total_episode_count: 10584
total_duration: 39727.57789349556
[2025-02-21 04:39:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.870243488006718
avg_train_sample_per_sec: 31.870243488006718
avg_episode_per_sec: 0.2747434783448855
collect_time: 21.838552951812744
reward_mean: -99.71160130718955
reward_std: 3.8700802500592797
reward_max: -94.5448179271709
reward_min: -105.24649859943976
queue_len: 0.06612175152996656
wait_time: 0.6273136796716918
delay_time: 4.237213291889531
pressure: 0.8111184792219276
total_envstep_count: 1228440
total_train_sample_count: 1228440
total_episode_count: 10590
total_duration: 39749.41644644737
[2025-02-21 04:39:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80952905853648
avg_train_sample_per_sec: 31.80952905853648
avg_episode_per_sec: 0.2742200780908317
collect_time: 21.88023591041565
reward_mean: -101.04143323996264
reward_std: 3.643225267530731
reward_max: -94.88305322128849
reward_min: -105.45658263305319
queue_len: 0.06700360294427231
wait_time: 0.637323939301627
delay_time: 4.270883093193031
pressure: 0.8239389920424404
total_envstep_count: 1229136
total_train_sample_count: 1229136
total_episode_count: 10596
total_duration: 39771.29668235779
[2025-02-21 04:40:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83134495257763
avg_train_sample_per_sec: 31.83134495257763
avg_episode_per_sec: 0.2744081461429106
collect_time: 21.8652400970459
reward_mean: -99.0238095238095
reward_std: 2.168031601883058
reward_max: -95.60434173669468
reward_min: -101.9334733893557
queue_len: 0.06566565618289755
wait_time: 0.6187556034792343
delay_time: 4.25197133810368
pressure: 0.8061450044208666
total_envstep_count: 1229832
total_train_sample_count: 1229832
total_episode_count: 10602
total_duration: 39793.161922454834
[2025-02-21 04:40:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08752356728541
avg_train_sample_per_sec: 32.08752356728541
avg_episode_per_sec: 0.27661658247659837
collect_time: 21.69067358970642
reward_mean: -98.26365546218487
reward_std: 2.2729648306073336
reward_max: -95.35014005602241
reward_min: -102.57843137254899
queue_len: 0.06516157524017563
wait_time: 0.6167251936141388
delay_time: 4.217167133190379
pressure: 0.8032714412024756
total_envstep_count: 1230528
total_train_sample_count: 1230528
total_episode_count: 10608
total_duration: 39814.85259604454
[2025-02-21 04:41:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05871813429496
avg_train_sample_per_sec: 32.05871813429496
avg_episode_per_sec: 0.27636825977840485
collect_time: 21.710163116455078
reward_mean: -99.6765873015873
reward_std: 3.4490927909894085
reward_max: -94.65966386554621
reward_min: -103.0595238095238
queue_len: 0.06609853269336029
wait_time: 0.6214407071405043
delay_time: 4.232504020616621
pressure: 0.8128868258178604
total_envstep_count: 1231224
total_train_sample_count: 1231224
total_episode_count: 10614
total_duration: 39836.562759160995
[2025-02-21 04:41:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.9156632101553
avg_train_sample_per_sec: 31.9156632101553
avg_episode_per_sec: 0.2751350276737526
collect_time: 21.80747413635254
reward_mean: -97.25711951447244
reward_std: 1.1374717364702027
reward_max: -95.76750700280108
reward_min: -99.25560224089635
queue_len: 0.06449411108386766
wait_time: 0.6103968996971025
delay_time: 4.150970580648824
pressure: 0.7996242263483643
total_envstep_count: 1231920
total_train_sample_count: 1231920
total_episode_count: 10620
total_duration: 39858.37023329735
[2025-02-21 04:41:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.913150412457572
avg_train_sample_per_sec: 31.913150412457572
avg_episode_per_sec: 0.27511336562463423
collect_time: 21.80919122695923
reward_mean: -98.3531746031746
reward_std: 2.76545308581936
reward_max: -95.85994397759104
reward_min: -103.43207282913164
queue_len: 0.06522093806576565
wait_time: 0.6179653116772793
delay_time: 4.265952065348691
pressure: 0.799845269672856
total_envstep_count: 1232616
total_train_sample_count: 1232616
total_episode_count: 10626
total_duration: 39880.17942452431
[2025-02-21 04:42:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.986836555985366
avg_train_sample_per_sec: 31.986836555985366
avg_episode_per_sec: 0.2757485909998738
collect_time: 21.75895071029663
reward_mean: -100.11006069094303
reward_std: 1.5946783783823213
reward_max: -98.71008403361343
reward_min: -103.2878151260504
queue_len: 0.06638598189054577
wait_time: 0.6259845560682274
delay_time: 4.303957910286622
pressure: 0.8159814323607427
total_envstep_count: 1233312
total_train_sample_count: 1233312
total_episode_count: 10632
total_duration: 39901.938375234604
[2025-02-21 04:42:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16358256867897
avg_train_sample_per_sec: 32.16358256867897
avg_episode_per_sec: 0.27727226352309453
collect_time: 21.63938045501709
reward_mean: -98.18265639589168
reward_std: 3.710410596697125
reward_max: -92.55532212885156
reward_min: -105.12675070028014
queue_len: 0.06510786233149317
wait_time: 0.6195135437021847
delay_time: 4.163084309458848
pressure: 0.8018346595932803
total_envstep_count: 1234008
total_train_sample_count: 1234008
total_episode_count: 10638
total_duration: 39923.57775568962
[2025-02-21 04:42:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.954531069250905
avg_train_sample_per_sec: 31.954531069250905
avg_episode_per_sec: 0.27547009542457673
collect_time: 21.780948638916016
reward_mean: -100.2175536881419
reward_std: 2.4835471004797838
reward_max: -96.41246498599438
reward_min: -103.15476190476188
queue_len: 0.066457263718927
wait_time: 0.6244792788910435
delay_time: 4.268411662677603
pressure: 0.8146551724137931
total_envstep_count: 1234704
total_train_sample_count: 1234704
total_episode_count: 10644
total_duration: 39945.35870432854
[2025-02-21 04:43:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865132753412887
avg_train_sample_per_sec: 31.865132753412887
avg_episode_per_sec: 0.2746994202880421
collect_time: 21.842055559158325
reward_mean: -98.83018207282912
reward_std: 1.662595005188803
reward_max: -96.1841736694678
reward_min: -100.83123249299717
queue_len: 0.06553725601646493
wait_time: 0.6197541682455476
delay_time: 4.258123752048641
pressure: 0.8050397877984085
total_envstep_count: 1235400
total_train_sample_count: 1235400
total_episode_count: 10650
total_duration: 39967.200759887695
[2025-02-21 04:43:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74072398108375
avg_train_sample_per_sec: 31.74072398108375
avg_episode_per_sec: 0.27362693087141166
collect_time: 21.927666187286377
reward_mean: -97.65908029878618
reward_std: 2.1889226735415614
reward_max: -93.89425770308122
reward_min: -100.78151260504202
queue_len: 0.06476066332810754
wait_time: 0.6133648861843588
delay_time: 4.190397092937973
pressure: 0.7998452696728559
total_envstep_count: 1236096
total_train_sample_count: 1236096
total_episode_count: 10656
total_duration: 39989.12842607498
[2025-02-21 04:44:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10896818551718
avg_train_sample_per_sec: 32.10896818551718
avg_episode_per_sec: 0.2768014498751481
collect_time: 21.67618703842163
reward_mean: -98.03209617180204
reward_std: 2.0674623764477977
reward_max: -94.796918767507
reward_min: -101.22478991596638
queue_len: 0.06500802133408624
wait_time: 0.616695937880015
delay_time: 4.171044310343312
pressure: 0.806918656056587
total_envstep_count: 1236792
total_train_sample_count: 1236792
total_episode_count: 10662
total_duration: 40010.8046131134
[2025-02-21 04:44:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92927415107278
avg_train_sample_per_sec: 31.92927415107278
avg_episode_per_sec: 0.2752523633713171
collect_time: 21.79817795753479
reward_mean: -100.00816993464052
reward_std: 1.7500270725555767
reward_max: -97.97198879551817
reward_min: -102.83263305322126
queue_len: 0.06631841507602156
wait_time: 0.6253756807762892
delay_time: 4.315577608773972
pressure: 0.8176392572944297
total_envstep_count: 1237488
total_train_sample_count: 1237488
total_episode_count: 10668
total_duration: 40032.60279107094
[2025-02-21 04:44:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94308719893649
avg_train_sample_per_sec: 31.94308719893649
avg_episode_per_sec: 0.27537144137014213
collect_time: 21.78875184059143
reward_mean: -99.27719421101774
reward_std: 1.0942547256144477
reward_max: -97.86134453781514
reward_min: -100.88515406162462
queue_len: 0.06583368316380488
wait_time: 0.6180091952784651
delay_time: 4.281638190776425
pressure: 0.8094606542882404
total_envstep_count: 1238184
total_train_sample_count: 1238184
total_episode_count: 10674
total_duration: 40054.39154291153
[2025-02-21 04:45:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.994186931386622
avg_train_sample_per_sec: 31.994186931386622
avg_episode_per_sec: 0.27581195630505706
collect_time: 21.75395178794861
reward_mean: -102.58426704014938
reward_std: 4.127473884713377
reward_max: -97.09103641456582
reward_min: -109.41036414565828
queue_len: 0.06802670228126619
wait_time: 0.6443591693972018
delay_time: 4.402181889981757
pressure: 0.8346595932802828
total_envstep_count: 1238880
total_train_sample_count: 1238880
total_episode_count: 10680
total_duration: 40076.14549469948
[2025-02-21 04:45:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02285889999968
avg_train_sample_per_sec: 32.02285889999968
avg_episode_per_sec: 0.27605912844827313
collect_time: 21.734474182128906
reward_mean: -97.73097572362276
reward_std: 1.4344687515951196
reward_max: -96.3172268907563
reward_min: -100.2521008403361
queue_len: 0.0648083393392724
wait_time: 0.6093369598060266
delay_time: 4.1737910266731575
pressure: 0.7970822281167109
total_envstep_count: 1239576
total_train_sample_count: 1239576
total_episode_count: 10686
total_duration: 40097.87996888161
[2025-02-21 04:45:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92709337172004
avg_train_sample_per_sec: 31.92709337172004
avg_episode_per_sec: 0.27523356354931067
collect_time: 21.79966688156128
reward_mean: -100.06676003734829
reward_std: 1.536867503621339
reward_max: -98.8655462184874
reward_min: -103.26820728291317
queue_len: 0.06635726792927606
wait_time: 0.6256628203889867
delay_time: 4.280395263376456
pressure: 0.8132183908045976
total_envstep_count: 1240272
total_train_sample_count: 1240272
total_episode_count: 10692
total_duration: 40119.67963576317
[2025-02-21 04:46:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.660507020484353
avg_train_sample_per_sec: 31.660507020484353
avg_episode_per_sec: 0.27293540534900307
collect_time: 21.98322343826294
reward_mean: -100.28046218487395
reward_std: 1.1206463373733941
reward_max: -98.2675070028011
reward_min: -101.59803921568626
queue_len: 0.06649898022869626
wait_time: 0.6347005977457295
delay_time: 4.274072288893883
pressure: 0.8213969938107869
total_envstep_count: 1240968
total_train_sample_count: 1240968
total_episode_count: 10698
total_duration: 40141.66285920143
[2025-02-21 04:46:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.100275852060214
avg_train_sample_per_sec: 32.100275852060214
avg_episode_per_sec: 0.27672651596603637
collect_time: 21.682056665420532
reward_mean: -98.9095471521942
reward_std: 1.4305718574336754
reward_max: -96.7093837535014
reward_min: -100.60504201680672
queue_len: 0.06558988537943912
wait_time: 0.6178431805967303
delay_time: 4.2165298878621025
pressure: 0.8112290008841733
total_envstep_count: 1241664
total_train_sample_count: 1241664
total_episode_count: 10704
total_duration: 40163.34491586685
[2025-02-21 04:46:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95672889209182
avg_train_sample_per_sec: 31.95672889209182
avg_episode_per_sec: 0.27548904217320536
collect_time: 21.77945065498352
reward_mean: -101.01692343604111
reward_std: 3.073995735624298
reward_max: -97.51050420168067
reward_min: -106.17857142857146
queue_len: 0.06698734975864794
wait_time: 0.6326590428390632
delay_time: 4.340843479942866
pressure: 0.8201812555260831
total_envstep_count: 1242360
total_train_sample_count: 1242360
total_episode_count: 10710
total_duration: 40185.124366521835
[2025-02-21 04:47:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.801816701299597
avg_train_sample_per_sec: 31.801816701299597
avg_episode_per_sec: 0.27415359225258273
collect_time: 21.885542154312134
reward_mean: -98.89460784313725
reward_std: 2.2051937385739158
reward_max: -95.28851540616247
reward_min: -101.7282913165266
queue_len: 0.06557997867582045
wait_time: 0.6198649994922815
delay_time: 4.240700278285292
pressure: 0.8060344827586209
total_envstep_count: 1243056
total_train_sample_count: 1243056
total_episode_count: 10716
total_duration: 40207.00990867615
[2025-02-21 04:47:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.183514885598214
avg_train_sample_per_sec: 32.183514885598214
avg_episode_per_sec: 0.2774440938413639
collect_time: 21.625978469848633
reward_mean: -99.04201680672269
reward_std: 2.0070941416967196
reward_max: -96.95028011204482
reward_min: -102.58123249299719
queue_len: 0.06567772997793281
wait_time: 0.6180198759433039
delay_time: 4.2646141430892
pressure: 0.8060344827586207
total_envstep_count: 1243752
total_train_sample_count: 1243752
total_episode_count: 10722
total_duration: 40228.635887145996
[2025-02-21 04:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00062930588311
avg_train_sample_per_sec: 32.00062930588311
avg_episode_per_sec: 0.27586749401623367
collect_time: 21.749572277069092
reward_mean: -100.72432306255835
reward_std: 3.125752469689667
reward_max: -95.2408963585434
reward_min: -106.04201680672266
queue_len: 0.0667933176807416
wait_time: 0.6333679139206522
delay_time: 4.281523125647936
pressure: 0.8253757736516357
total_envstep_count: 1244448
total_train_sample_count: 1244448
total_episode_count: 10728
total_duration: 40250.385459423065
[2025-02-21 04:48:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.901857130555165
avg_train_sample_per_sec: 31.901857130555165
avg_episode_per_sec: 0.2750160097461652
collect_time: 21.816911697387695
reward_mean: -99.7546685340803
reward_std: 2.056266342359804
reward_max: -96.71008403361347
reward_min: -103.15406162464983
queue_len: 0.06615031069899223
wait_time: 0.629075989370107
delay_time: 4.287653160591762
pressure: 0.8160919540229886
total_envstep_count: 1245144
total_train_sample_count: 1245144
total_episode_count: 10734
total_duration: 40272.20237112045
[2025-02-21 04:48:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.859695418388924
avg_train_sample_per_sec: 31.859695418388924
avg_episode_per_sec: 0.27465254671024936
collect_time: 21.845783233642578
reward_mean: -99.57656395891689
reward_std: 2.850903599363598
reward_max: -96.3312324929972
reward_min: -104.43487394957982
queue_len: 0.06603220421678839
wait_time: 0.6206573809895312
delay_time: 4.302745488677163
pressure: 0.8150972590627763
total_envstep_count: 1245840
total_train_sample_count: 1245840
total_episode_count: 10740
total_duration: 40294.048154354095
[2025-02-21 04:49:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21398298907909
avg_train_sample_per_sec: 32.21398298907909
avg_episode_per_sec: 0.27770674990585426
collect_time: 21.60552453994751
reward_mean: -98.51622315592904
reward_std: 3.025020484186203
reward_max: -95.16036414565822
reward_min: -103.0427170868347
queue_len: 0.0653290604482288
wait_time: 0.6174397146126356
delay_time: 4.179759125524498
pressure: 0.81421308576481
total_envstep_count: 1246536
total_train_sample_count: 1246536
total_episode_count: 10746
total_duration: 40315.65367889404
[2025-02-21 04:49:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.904853175911164
avg_train_sample_per_sec: 31.904853175911164
avg_episode_per_sec: 0.2750418377233721
collect_time: 21.814862966537476
reward_mean: -99.49789915966387
reward_std: 2.826462713644261
reward_max: -95.15826330532214
reward_min: -103.8564425770308
queue_len: 0.06598003923054634
wait_time: 0.6242819961760125
delay_time: 4.233227909480979
pressure: 0.8202917771883289
total_envstep_count: 1247232
total_train_sample_count: 1247232
total_episode_count: 10752
total_duration: 40337.46854186058
[2025-02-21 04:49:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.996636053760664
avg_train_sample_per_sec: 31.996636053760664
avg_episode_per_sec: 0.27583306942897123
collect_time: 21.752286672592163
reward_mean: -99.86776377217554
reward_std: 2.8239628104592316
reward_max: -96.20798319327733
reward_min: -104.23739495798317
queue_len: 0.06622530754123047
wait_time: 0.6295036803403944
delay_time: 4.269397297174612
pressure: 0.8170866489832007
total_envstep_count: 1247928
total_train_sample_count: 1247928
total_episode_count: 10758
total_duration: 40359.22082853317
[2025-02-21 04:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.049830951059675
avg_train_sample_per_sec: 32.049830951059675
avg_episode_per_sec: 0.27629164612982476
collect_time: 21.716183185577393
reward_mean: -98.23214285714285
reward_std: 1.8983691773865845
reward_max: -96.51120448179269
reward_min: -101.6638655462185
queue_len: 0.06514067828723001
wait_time: 0.618220718879948
delay_time: 4.217709674416798
pressure: 0.8048187444739169
total_envstep_count: 1248624
total_train_sample_count: 1248624
total_episode_count: 10764
total_duration: 40380.93701171875
[2025-02-21 04:50:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.834567305815895
avg_train_sample_per_sec: 31.834567305815895
avg_episode_per_sec: 0.27443592505013703
collect_time: 21.8630268573761
reward_mean: -99.01458916900093
reward_std: 1.375763650626094
reward_max: -96.84173669467783
reward_min: -100.43697478991592
queue_len: 0.06565954188925792
wait_time: 0.6224254953970978
delay_time: 4.204662609045512
pressure: 0.8137709991158267
total_envstep_count: 1249320
total_train_sample_count: 1249320
total_episode_count: 10770
total_duration: 40402.800038576126
[2025-02-21 04:51:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01476960449191
avg_train_sample_per_sec: 32.01476960449191
avg_episode_per_sec: 0.27598939314217164
collect_time: 21.73996591567993
reward_mean: -98.21195144724555
reward_std: 3.619659537034379
reward_max: -93.2563025210084
reward_min: -102.08333333333334
queue_len: 0.0651272887581204
wait_time: 0.617741714280761
delay_time: 4.220712435898558
pressure: 0.8034924845269673
total_envstep_count: 1250016
total_train_sample_count: 1250016
total_episode_count: 10776
total_duration: 40424.540004491806
[2025-02-21 04:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.896080358000074
avg_train_sample_per_sec: 31.896080358000074
avg_episode_per_sec: 0.2749662099827593
collect_time: 21.820863008499146
reward_mean: -99.05462184873949
reward_std: 2.3212214708070222
reward_max: -95.33823529411764
reward_min: -101.81932773109243
queue_len: 0.06568608875911107
wait_time: 0.6184495792127637
delay_time: 4.237546489141768
pressure: 0.8154288240495138
total_envstep_count: 1250712
total_train_sample_count: 1250712
total_episode_count: 10782
total_duration: 40446.360867500305
[2025-02-21 04:51:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.921954266387385
avg_train_sample_per_sec: 31.921954266387385
avg_episode_per_sec: 0.27518926091713264
collect_time: 21.803176403045654
reward_mean: -101.57306255835668
reward_std: 5.2871086263755185
reward_max: -93.18347338935573
reward_min: -109.38165266106442
queue_len: 0.06735614228007737
wait_time: 0.6358306585233563
delay_time: 4.3796047628681345
pressure: 0.8248231653404067
total_envstep_count: 1251408
total_train_sample_count: 1251408
total_episode_count: 10788
total_duration: 40468.16404390335
[2025-02-21 04:52:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.889421175062562
avg_train_sample_per_sec: 31.889421175062562
avg_episode_per_sec: 0.27490880323329797
collect_time: 21.825419664382935
reward_mean: -98.92927170868347
reward_std: 2.5473182956827496
reward_max: -93.79341736694677
reward_min: -102.26050420168065
queue_len: 0.06560296532406067
wait_time: 0.6240868031562758
delay_time: 4.1864430952103335
pressure: 0.8186339522546419
total_envstep_count: 1252104
total_train_sample_count: 1252104
total_episode_count: 10794
total_duration: 40489.989463567734
[2025-02-21 04:52:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.89055188242085
avg_train_sample_per_sec: 30.89055188242085
avg_episode_per_sec: 0.2662978610553522
collect_time: 22.531161069869995
reward_mean: -98.687558356676
reward_std: 3.461354877766479
reward_max: -95.23879551820728
reward_min: -103.89705882352946
queue_len: 0.06544267795535545
wait_time: 0.6140100602575247
delay_time: 4.196522795794995
pressure: 0.8079133510167994
total_envstep_count: 1252800
total_train_sample_count: 1252800
total_episode_count: 10800
total_duration: 40512.520624637604
[2025-02-21 04:52:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.64113819824861
avg_train_sample_per_sec: 31.64113819824861
avg_episode_per_sec: 0.27276843274352247
collect_time: 21.99668025970459
reward_mean: -99.7330765639589
reward_std: 2.410517523440109
reward_max: -95.12675070028007
reward_min: -101.91946778711485
queue_len: 0.06613599241641838
wait_time: 0.6240334772282033
delay_time: 4.264095925956565
pressure: 0.8159814323607426
total_envstep_count: 1253496
total_train_sample_count: 1253496
total_episode_count: 10806
total_duration: 40534.51730489731
[2025-02-21 04:53:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.892847282593085
avg_train_sample_per_sec: 31.892847282593085
avg_episode_per_sec: 0.27493833864304384
collect_time: 21.82307505607605
reward_mean: -102.15441176470587
reward_std: 2.43209315222544
reward_max: -99.03081232492997
reward_min: -106.50700280112044
queue_len: 0.0677416523638633
wait_time: 0.639900843184312
delay_time: 4.326942231934201
pressure: 0.8366489832007074
total_envstep_count: 1254192
total_train_sample_count: 1254192
total_episode_count: 10812
total_duration: 40556.340379953384
[2025-02-21 04:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.900171949796874
avg_train_sample_per_sec: 31.900171949796874
avg_episode_per_sec: 0.27500148232583516
collect_time: 21.818064212799072
reward_mean: -99.18930905695613
reward_std: 2.6987940797916914
reward_max: -96.08123249299717
reward_min: -103.31512605042018
queue_len: 0.06577540388392317
wait_time: 0.61830198480807
delay_time: 4.262786574473224
pressure: 0.8050397877984085
total_envstep_count: 1254888
total_train_sample_count: 1254888
total_episode_count: 10818
total_duration: 40578.15844416618
[2025-02-21 04:54:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91834845421876
avg_train_sample_per_sec: 31.91834845421876
avg_episode_per_sec: 0.27515817632947204
collect_time: 21.805639505386353
reward_mean: -99.34290382819795
reward_std: 2.2172287097862236
reward_max: -97.28361344537814
reward_min: -103.96358543417368
queue_len: 0.06587725718050261
wait_time: 0.618702819324016
delay_time: 4.338733112268407
pressure: 0.8049292661361626
total_envstep_count: 1255584
total_train_sample_count: 1255584
total_episode_count: 10824
total_duration: 40599.96408367157
[2025-02-21 04:54:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.788340494188986
avg_train_sample_per_sec: 31.788340494188986
avg_episode_per_sec: 0.2740374180533533
collect_time: 21.89482021331787
reward_mean: -99.04901960784314
reward_std: 3.118342725963391
reward_max: -93.53501400560222
reward_min: -103.76330532212884
queue_len: 0.06568237374525408
wait_time: 0.6188081554460866
delay_time: 4.243736496806238
pressure: 0.8100132625994695
total_envstep_count: 1256280
total_train_sample_count: 1256280
total_episode_count: 10830
total_duration: 40621.85890388489
[2025-02-21 04:54:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.501392812486728
avg_train_sample_per_sec: 31.501392812486728
avg_episode_per_sec: 0.27156373114212695
collect_time: 22.094261169433594
reward_mean: -100.54084967320262
reward_std: 2.742938161212088
reward_max: -96.43207282913167
reward_min: -105.69397759103637
queue_len: 0.06667165097692482
wait_time: 0.6256121259290631
delay_time: 4.316939039498548
pressure: 0.8199602122015915
total_envstep_count: 1256976
total_train_sample_count: 1256976
total_episode_count: 10836
total_duration: 40643.95316505432
[2025-02-21 04:55:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.862863001171583
avg_train_sample_per_sec: 31.862863001171583
avg_episode_per_sec: 0.2746798534583757
collect_time: 21.843611478805542
reward_mean: -98.3104575163399
reward_std: 3.3587286951083444
reward_max: -91.16946778711483
reward_min: -101.57633053221294
queue_len: 0.06519261108510603
wait_time: 0.6125389921662742
delay_time: 4.238751670625331
pressure: 0.8002873563218391
total_envstep_count: 1257672
total_train_sample_count: 1257672
total_episode_count: 10842
total_duration: 40665.79677653313
[2025-02-21 04:55:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74388624466052
avg_train_sample_per_sec: 31.74388624466052
avg_episode_per_sec: 0.2736541917643148
collect_time: 21.92548179626465
reward_mean: -99.92145191409895
reward_std: 3.1834455181229413
reward_max: -94.96988795518205
reward_min: -103.25210084033615
queue_len: 0.06626090975736006
wait_time: 0.6251098250971476
delay_time: 4.3159804757647064
pressure: 0.8146551724137931
total_envstep_count: 1258368
total_train_sample_count: 1258368
total_episode_count: 10848
total_duration: 40687.72225832939
[2025-02-21 04:55:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.817860359770467
avg_train_sample_per_sec: 31.817860359770467
avg_episode_per_sec: 0.27429189965319367
collect_time: 21.87450671195984
reward_mean: -100.44269374416432
reward_std: 1.7523543734310532
reward_max: -97.38515406162466
reward_min: -102.38515406162463
queue_len: 0.06660656083830525
wait_time: 0.6304056547464256
delay_time: 4.288433040462881
pressure: 0.8178603006189212
total_envstep_count: 1259064
total_train_sample_count: 1259064
total_episode_count: 10854
total_duration: 40709.59676504135
[2025-02-21 04:56:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.873720113824653
avg_train_sample_per_sec: 31.873720113824653
avg_episode_per_sec: 0.2747734492571091
collect_time: 21.83617091178894
reward_mean: -100.16713352007469
reward_std: 3.318503584910241
reward_max: -96.58823529411764
reward_min: -105.203081232493
queue_len: 0.06642382859421399
wait_time: 0.6278403602820438
delay_time: 4.3477739177440515
pressure: 0.8106763925729443
total_envstep_count: 1259760
total_train_sample_count: 1259760
total_episode_count: 10860
total_duration: 40731.43293595314
[2025-02-21 04:56:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.778474769807534
avg_train_sample_per_sec: 31.778474769807534
avg_episode_per_sec: 0.27395236870523737
collect_time: 21.901617527008057
reward_mean: -98.21556956115779
reward_std: 1.7610985974015798
reward_max: -96.57913165266106
reward_min: -101.84103641456585
queue_len: 0.06512968803790305
wait_time: 0.6126404584822436
delay_time: 4.196588852562051
pressure: 0.8013925729442971
total_envstep_count: 1260456
total_train_sample_count: 1260456
total_episode_count: 10866
total_duration: 40753.33455348015
[2025-02-21 04:57:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91424731407909
avg_train_sample_per_sec: 31.91424731407909
avg_episode_per_sec: 0.2751228216730956
collect_time: 21.808441638946533
reward_mean: -100.43323996265173
reward_std: 2.0281192769839826
reward_max: -97.26540616246496
reward_min: -102.71148459383753
queue_len: 0.06660029175242158
wait_time: 0.6293587174038492
delay_time: 4.301708291231308
pressure: 0.8101237842617154
total_envstep_count: 1261152
total_train_sample_count: 1261152
total_episode_count: 10872
total_duration: 40775.142995119095
[2025-02-21 04:57:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.947291900846277
avg_train_sample_per_sec: 31.947291900846277
avg_episode_per_sec: 0.27540768880039895
collect_time: 21.785884141921997
reward_mean: -99.29493464052287
reward_std: 1.9287676113081054
reward_max: -96.88515406162465
reward_min: -102.1624649859944
queue_len: 0.06584544737435204
wait_time: 0.6242306051509906
delay_time: 4.27443173988132
pressure: 0.8049292661361628
total_envstep_count: 1261848
total_train_sample_count: 1261848
total_episode_count: 10878
total_duration: 40796.92887926102
[2025-02-21 04:57:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95996618538411
avg_train_sample_per_sec: 31.95996618538411
avg_episode_per_sec: 0.275516949874001
collect_time: 21.777244567871094
reward_mean: -100.85924369747897
reward_std: 2.1794399089353282
reward_max: -97.91946778711481
reward_min: -104.45588235294116
queue_len: 0.06688278759779773
wait_time: 0.6261978597805169
delay_time: 4.36750052823157
pressure: 0.8103448275862069
total_envstep_count: 1262544
total_train_sample_count: 1262544
total_episode_count: 10884
total_duration: 40818.70612382889
[2025-02-21 04:58:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.266862178418386
avg_train_sample_per_sec: 32.266862178418386
avg_episode_per_sec: 0.2781626049863654
collect_time: 21.570117235183716
reward_mean: -100.35959383753503
reward_std: 3.2641313214593106
reward_max: -97.16106442577032
reward_min: -105.28571428571428
queue_len: 0.0665514547994264
wait_time: 0.6285493861558772
delay_time: 4.287019624139719
pressure: 0.8200707338638372
total_envstep_count: 1263240
total_train_sample_count: 1263240
total_episode_count: 10890
total_duration: 40840.27624106407
[2025-02-21 04:58:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.977759734823564
avg_train_sample_per_sec: 31.977759734823564
avg_episode_per_sec: 0.27567034254158246
collect_time: 21.765126943588257
reward_mean: -98.40347805788984
reward_std: 2.4454644286022185
reward_max: -94.93347338935574
reward_min: -102.70798319327734
queue_len: 0.06525429579435665
wait_time: 0.6156257043047103
delay_time: 4.246326771704314
pressure: 0.8008399646330681
total_envstep_count: 1263936
total_train_sample_count: 1263936
total_episode_count: 10896
total_duration: 40862.04136800766
[2025-02-21 04:58:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76840185807191
avg_train_sample_per_sec: 31.76840185807191
avg_episode_per_sec: 0.2738655332592406
collect_time: 21.908561944961548
reward_mean: -99.32703081232494
reward_std: 3.0302978849695927
reward_max: -93.1393557422969
reward_min: -102.26960784313725
queue_len: 0.06586673130790778
wait_time: 0.6226282732367925
delay_time: 4.281340840876273
pressure: 0.8105658709106985
total_envstep_count: 1264632
total_train_sample_count: 1264632
total_episode_count: 10902
total_duration: 40883.94992995262
[2025-02-21 04:59:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.648642425090813
avg_train_sample_per_sec: 31.648642425090813
avg_episode_per_sec: 0.2728331243542312
collect_time: 21.991464614868164
reward_mean: -99.12383286647992
reward_std: 1.8314959568543465
reward_max: -95.95728291316526
reward_min: -102.05812324929971
queue_len: 0.06573198465946944
wait_time: 0.6186193089083557
delay_time: 4.208415421542147
pressure: 0.8079133510167993
total_envstep_count: 1265328
total_train_sample_count: 1265328
total_episode_count: 10908
total_duration: 40905.94139456749
[2025-02-21 04:59:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7628554406746
avg_train_sample_per_sec: 31.7628554406746
avg_episode_per_sec: 0.27381771931616034
collect_time: 21.91238760948181
reward_mean: -100.79493464052287
reward_std: 2.063175252860823
reward_max: -97.8795518207283
reward_min: -104.09873949579831
queue_len: 0.06684014233456424
wait_time: 0.6310846509249145
delay_time: 4.33185096206542
pressure: 0.8166445623342174
total_envstep_count: 1266024
total_train_sample_count: 1266024
total_episode_count: 10914
total_duration: 40927.85378217697
[2025-02-21 05:00:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.868430487249285
avg_train_sample_per_sec: 31.868430487249285
avg_episode_per_sec: 0.27472784902801106
collect_time: 21.839795351028442
reward_mean: -98.73879551820728
reward_std: 2.6497480090673147
reward_max: -95.00980392156863
reward_min: -103.37815126050418
queue_len: 0.0654766548529226
wait_time: 0.6161417816463455
delay_time: 4.253273091565535
pressure: 0.8023872679045093
total_envstep_count: 1266720
total_train_sample_count: 1266720
total_episode_count: 10920
total_duration: 40949.693577528
[2025-02-21 05:00:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.876729324518042
avg_train_sample_per_sec: 31.876729324518042
avg_episode_per_sec: 0.2747993907286038
collect_time: 21.83410954475403
reward_mean: -100.40592903828197
reward_std: 3.074274586753288
reward_max: -96.79271708683476
reward_min: -106.18277310924373
queue_len: 0.06658218105986868
wait_time: 0.6328743588505252
delay_time: 4.307253807381858
pressure: 0.8173076923076924
total_envstep_count: 1267416
total_train_sample_count: 1267416
total_episode_count: 10926
total_duration: 40971.527687072754
[2025-02-21 05:00:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.708799114910367
avg_train_sample_per_sec: 31.708799114910367
avg_episode_per_sec: 0.273351716507848
collect_time: 21.949743270874023
reward_mean: -100.50490196078435
reward_std: 1.9142931911668535
reward_max: -97.92717086834737
reward_min: -102.87605042016807
queue_len: 0.06664781297134238
wait_time: 0.630822819844118
delay_time: 4.324886868126775
pressure: 0.8120026525198938
total_envstep_count: 1268112
total_train_sample_count: 1268112
total_episode_count: 10932
total_duration: 40993.47743034363
[2025-02-21 05:01:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96833202540952
avg_train_sample_per_sec: 31.96833202540952
avg_episode_per_sec: 0.2755890691845648
collect_time: 21.77154564857483
reward_mean: -100.01517273576097
reward_std: 2.8129247269162923
reward_max: -95.7724089635854
reward_min: -103.3669467787115
queue_len: 0.06632305884334282
wait_time: 0.6214944974453087
delay_time: 4.286065960336422
pressure: 0.813549955791335
total_envstep_count: 1268808
total_train_sample_count: 1268808
total_episode_count: 10938
total_duration: 41015.2489759922
[2025-02-21 05:01:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.133781278126484
avg_train_sample_per_sec: 32.133781278126484
avg_episode_per_sec: 0.27701535584591797
collect_time: 21.659449100494385
reward_mean: -98.89495798319327
reward_std: 2.5403188802777437
reward_max: -96.53851540616242
reward_min: -104.32352941176468
queue_len: 0.06558021086418651
wait_time: 0.6140085897312063
delay_time: 4.2523423798341495
pressure: 0.8083554376657824
total_envstep_count: 1269504
total_train_sample_count: 1269504
total_episode_count: 10944
total_duration: 41036.9084250927
[2025-02-21 05:01:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10630939029804
avg_train_sample_per_sec: 32.10630939029804
avg_episode_per_sec: 0.2767785292267072
collect_time: 21.677982091903687
reward_mean: -97.96416900093374
reward_std: 2.6644717305998515
reward_max: -94.84103641456588
reward_min: -103.41876750700277
queue_len: 0.06496297679107012
wait_time: 0.6134312920570527
delay_time: 4.189522799567556
pressure: 0.7905614500442087
total_envstep_count: 1270200
total_train_sample_count: 1270200
total_episode_count: 10950
total_duration: 41058.5864071846
[2025-02-21 05:02:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25177181508797
avg_train_sample_per_sec: 32.25177181508797
avg_episode_per_sec: 0.2780325156473101
collect_time: 21.580209732055664
reward_mean: -99.18977591036412
reward_std: 1.692066930602024
reward_max: -96.67436974789914
reward_min: -102.23249299719888
queue_len: 0.06577571346841123
wait_time: 0.6135949074590049
delay_time: 4.300344682128897
pressure: 0.8057029177718834
total_envstep_count: 1270896
total_train_sample_count: 1270896
total_episode_count: 10956
total_duration: 41080.16661691666
[2025-02-21 05:02:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26852996806469
avg_train_sample_per_sec: 32.26852996806469
avg_episode_per_sec: 0.2781769824833163
collect_time: 21.569002389907837
reward_mean: -99.75887021475258
reward_std: 1.53789185235851
reward_max: -97.7135854341737
reward_min: -101.94747899159664
queue_len: 0.066153096959385
wait_time: 0.6250543320776587
delay_time: 4.248389187665547
pressure: 0.8141025641025642
total_envstep_count: 1271592
total_train_sample_count: 1271592
total_episode_count: 10962
total_duration: 41101.735619306564
[2025-02-21 05:02:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.816898032814994
avg_train_sample_per_sec: 31.816898032814994
avg_episode_per_sec: 0.2742836037311637
collect_time: 21.875168323516846
reward_mean: -98.44666199813258
reward_std: 1.9321454792539587
reward_max: -96.20238095238096
reward_min: -101.6799719887955
queue_len: 0.06528293235950436
wait_time: 0.6113178361530288
delay_time: 4.16104673962488
pressure: 0.8039345711759505
total_envstep_count: 1272288
total_train_sample_count: 1272288
total_episode_count: 10968
total_duration: 41123.61078763008
[2025-02-21 05:03:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78451874576717
avg_train_sample_per_sec: 31.78451874576717
avg_episode_per_sec: 0.2740044719462687
collect_time: 21.89745283126831
reward_mean: -98.93067226890754
reward_std: 2.3070021960135065
reward_max: -96.41036414565824
reward_min: -103.09733893557421
queue_len: 0.06560389407752489
wait_time: 0.6197626818189699
delay_time: 4.247922481254079
pressure: 0.795313881520778
total_envstep_count: 1272984
total_train_sample_count: 1272984
total_episode_count: 10974
total_duration: 41145.50824046135
[2025-02-21 05:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.927235139514366
avg_train_sample_per_sec: 31.927235139514366
avg_episode_per_sec: 0.27523478568546866
collect_time: 21.799570083618164
reward_mean: -100.5480859010271
reward_std: 1.539382499095003
reward_max: -98.69047619047619
reward_min: -103.13865546218489
queue_len: 0.0666764495364901
wait_time: 0.6238325568954374
delay_time: 4.263669596985835
pressure: 0.8177497789566756
total_envstep_count: 1273680
total_train_sample_count: 1273680
total_episode_count: 10980
total_duration: 41167.30781054497
[2025-02-21 05:04:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.811377308510227
avg_train_sample_per_sec: 31.811377308510227
avg_episode_per_sec: 0.2742360112802606
collect_time: 21.87896466255188
reward_mean: -99.2110177404295
reward_std: 2.2645025331092223
reward_max: -96.88865546218484
reward_min: -103.29411764705885
queue_len: 0.06578979956261903
wait_time: 0.6231696591103286
delay_time: 4.269552237243979
pressure: 0.8029398762157384
total_envstep_count: 1274376
total_train_sample_count: 1274376
total_episode_count: 10986
total_duration: 41189.18677520752
[2025-02-21 05:04:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.893654967323222
avg_train_sample_per_sec: 31.893654967323222
avg_episode_per_sec: 0.27494530144244156
collect_time: 21.822522401809692
reward_mean: -100.391106442577
reward_std: 2.3570388582588686
reward_max: -96.62184873949577
reward_min: -103.70308123249295
queue_len: 0.06657235175237201
wait_time: 0.630337081782315
delay_time: 4.2403949272255925
pressure: 0.8191865605658708
total_envstep_count: 1275072
total_train_sample_count: 1275072
total_episode_count: 10992
total_duration: 41211.00929760933
[2025-02-21 05:04:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.965680017916856
avg_train_sample_per_sec: 31.965680017916856
avg_episode_per_sec: 0.2755662070510074
collect_time: 21.773351907730103
reward_mean: -97.69666199813258
reward_std: 2.9568490386737585
reward_max: -93.49579831932772
reward_min: -100.79761904761904
queue_len: 0.06478558487939827
wait_time: 0.6066582026267625
delay_time: 4.225480010023067
pressure: 0.7957559681697614
total_envstep_count: 1275768
total_train_sample_count: 1275768
total_episode_count: 10998
total_duration: 41232.78264951706
[2025-02-21 05:05:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96269143603451
avg_train_sample_per_sec: 31.96269143603451
avg_episode_per_sec: 0.2755404434140906
collect_time: 21.77538776397705
reward_mean: -100.15371148459383
reward_std: 3.4332320689380733
reward_max: -96.96428571428572
reward_min: -106.49789915966386
queue_len: 0.06641492804018158
wait_time: 0.6316966994578556
delay_time: 4.268426530104172
pressure: 0.8124447391688773
total_envstep_count: 1276464
total_train_sample_count: 1276464
total_episode_count: 11004
total_duration: 41254.55803728104
[2025-02-21 05:05:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21577934843851
avg_train_sample_per_sec: 32.21577934843851
avg_episode_per_sec: 0.2777222357624009
collect_time: 21.60431981086731
reward_mean: -99.5505368814192
reward_std: 3.7836073195243185
reward_max: -94.92717086834736
reward_min: -106.21358543417364
queue_len: 0.06601494488157773
wait_time: 0.623237999886073
delay_time: 4.2307956071022295
pressure: 0.8020557029177718
total_envstep_count: 1277160
total_train_sample_count: 1277160
total_episode_count: 11010
total_duration: 41276.162357091904
[2025-02-21 05:05:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12892337171287
avg_train_sample_per_sec: 32.12892337171287
avg_episode_per_sec: 0.27697347734235234
collect_time: 21.662724018096924
reward_mean: -97.63888888888891
reward_std: 1.624520396872307
reward_max: -95.70728291316529
reward_min: -100.93417366946782
queue_len: 0.06474727379899795
wait_time: 0.607657541354296
delay_time: 4.148822376170963
pressure: 0.7911140583554377
total_envstep_count: 1277856
total_train_sample_count: 1277856
total_episode_count: 11016
total_duration: 41297.82508111
[2025-02-21 05:06:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.98016870996529
avg_train_sample_per_sec: 30.98016870996529
avg_episode_per_sec: 0.2670704199134939
collect_time: 22.46598482131958
reward_mean: -100.95868347338937
reward_std: 4.3750177147998315
reward_max: -95.48669467787118
reward_min: -106.82422969187675
queue_len: 0.06694872909375953
wait_time: 0.6333504997931976
delay_time: 4.283456805719639
pressure: 0.8146551724137931
total_envstep_count: 1278552
total_train_sample_count: 1278552
total_episode_count: 11022
total_duration: 41320.29106593132
[2025-02-21 05:06:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.886699696684634
avg_train_sample_per_sec: 31.886699696684634
avg_episode_per_sec: 0.2748853422127986
collect_time: 21.827282428741455
reward_mean: -97.89332399626518
reward_std: 2.4211116426701293
reward_max: -93.38025210084035
reward_min: -100.9873949579832
queue_len: 0.06491599734500343
wait_time: 0.6124253746591475
delay_time: 4.181799637474205
pressure: 0.786472148541114
total_envstep_count: 1279248
total_train_sample_count: 1279248
total_episode_count: 11028
total_duration: 41342.11834836006
[2025-02-21 05:07:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95431070897489
avg_train_sample_per_sec: 31.95431070897489
avg_episode_per_sec: 0.2754681957670249
collect_time: 21.78109884262085
reward_mean: -100.59010270774975
reward_std: 2.2631208795908617
reward_max: -97.5126050420168
reward_min: -104.29481792717084
queue_len: 0.06670431214041761
wait_time: 0.6315513495407005
delay_time: 4.290256775419394
pressure: 0.8192970822281166
total_envstep_count: 1279944
total_train_sample_count: 1279944
total_episode_count: 11034
total_duration: 41363.89944720268
[2025-02-21 05:07:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79372683609856
avg_train_sample_per_sec: 31.79372683609856
avg_episode_per_sec: 0.2740838520353324
collect_time: 21.89111089706421
reward_mean: -99.51727357609714
reward_std: 3.0256560384580284
reward_max: -95.85994397759103
reward_min: -103.63725490196079
queue_len: 0.06599288698680181
wait_time: 0.6182092642538889
delay_time: 4.267828130939077
pressure: 0.8101237842617154
total_envstep_count: 1280640
total_train_sample_count: 1280640
total_episode_count: 11040
total_duration: 41385.79055809975
[2025-02-21 05:07:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98544307549128
avg_train_sample_per_sec: 31.98544307549128
avg_episode_per_sec: 0.27573657823699377
collect_time: 21.75989866256714
reward_mean: -99.20576563958917
reward_std: 2.8340752693564153
reward_max: -94.59663865546219
reward_min: -103.85014005602247
queue_len: 0.0657863167371281
wait_time: 0.6234033953988316
delay_time: 4.263253839692101
pressure: 0.8045977011494253
total_envstep_count: 1281336
total_train_sample_count: 1281336
total_episode_count: 11046
total_duration: 41407.550456762314
[2025-02-21 05:08:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.9464098284834
avg_train_sample_per_sec: 31.9464098284834
avg_episode_per_sec: 0.2754000847283052
collect_time: 21.78648567199707
reward_mean: -101.09348739495799
reward_std: 2.311552829902616
reward_max: -97.97689075630251
reward_min: -105.37885154061625
queue_len: 0.06703812161469362
wait_time: 0.6397917146522624
delay_time: 4.2323845764784975
pressure: 0.8250442086648984
total_envstep_count: 1282032
total_train_sample_count: 1282032
total_episode_count: 11052
total_duration: 41429.33694243431
[2025-02-21 05:08:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00268331642466
avg_train_sample_per_sec: 32.00268331642466
avg_episode_per_sec: 0.2758852010036609
collect_time: 21.748176336288452
reward_mean: -100.1841736694678
reward_std: 2.3837420837626935
reward_max: -96.84103641456582
reward_min: -103.43697478991595
queue_len: 0.06643512842802904
wait_time: 0.6289272340235829
delay_time: 4.302031129795892
pressure: 0.8179708222811671
total_envstep_count: 1282728
total_train_sample_count: 1282728
total_episode_count: 11058
total_duration: 41451.0851187706
[2025-02-21 05:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02916382639698
avg_train_sample_per_sec: 32.02916382639698
avg_episode_per_sec: 0.27611348126204294
collect_time: 21.73019576072693
reward_mean: -101.67752100840336
reward_std: 2.2942369847824104
reward_max: -98.484593837535
reward_min: -105.31652661064426
queue_len: 0.06742541180928606
wait_time: 0.6379411733747432
delay_time: 4.298485332528287
pressure: 0.8263704686118479
total_envstep_count: 1283424
total_train_sample_count: 1283424
total_episode_count: 11064
total_duration: 41472.815314531326
[2025-02-21 05:09:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59263606187917
avg_train_sample_per_sec: 31.59263606187917
avg_episode_per_sec: 0.27235031087826866
collect_time: 22.030450344085693
reward_mean: -99.97502334267041
reward_std: 2.947044318541884
reward_max: -96.46148459383753
reward_min: -104.87885154061624
queue_len: 0.06629643457736765
wait_time: 0.6274000537438672
delay_time: 4.274276573458706
pressure: 0.8152077807250221
total_envstep_count: 1284120
total_train_sample_count: 1284120
total_episode_count: 11070
total_duration: 41494.84576487541
[2025-02-21 05:09:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79684079276688
avg_train_sample_per_sec: 31.79684079276688
avg_episode_per_sec: 0.27411069648936964
collect_time: 21.888967037200928
reward_mean: -97.91118113912232
reward_std: 1.3879781722143454
reward_max: -95.68207282913161
reward_min: -99.3515406162465
queue_len: 0.06492783895167263
wait_time: 0.6116581469015546
delay_time: 4.216317400962041
pressure: 0.7868037135278515
total_envstep_count: 1284816
total_train_sample_count: 1284816
total_episode_count: 11076
total_duration: 41516.73473191261
[2025-02-21 05:10:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10821030102246
avg_train_sample_per_sec: 32.10821030102246
avg_episode_per_sec: 0.27679491638812465
collect_time: 21.676698684692383
reward_mean: -98.09768907563027
reward_std: 1.3921726993887662
reward_max: -95.79481792717094
reward_min: -99.8088235294118
queue_len: 0.06505151795466198
wait_time: 0.6137376259080113
delay_time: 4.226007932593087
pressure: 0.7874668435013262
total_envstep_count: 1285512
total_train_sample_count: 1285512
total_episode_count: 11082
total_duration: 41538.411430597305
[2025-02-21 05:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.799489798263714
avg_train_sample_per_sec: 31.799489798263714
avg_episode_per_sec: 0.2741335327436527
collect_time: 21.88714361190796
reward_mean: -101.21650326797385
reward_std: 5.076551321841864
reward_max: -96.27941176470586
reward_min: -111.85854341736693
queue_len: 0.06711969712730363
wait_time: 0.6366322501591265
delay_time: 4.316304278790196
pressure: 0.8190760389036251
total_envstep_count: 1286208
total_train_sample_count: 1286208
total_episode_count: 11088
total_duration: 41560.29857420921
[2025-02-21 05:10:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.763719110997524
avg_train_sample_per_sec: 31.763719110997524
avg_episode_per_sec: 0.27382516474997864
collect_time: 21.911791801452637
reward_mean: -103.42238562091505
reward_std: 2.5819734947846644
reward_max: -100.38725490196077
reward_min: -107.72338935574231
queue_len: 0.06858248383349803
wait_time: 0.6438406927757842
delay_time: 4.370460794006118
pressure: 0.8504641909814324
total_envstep_count: 1286904
total_train_sample_count: 1286904
total_episode_count: 11094
total_duration: 41582.210366010666
[2025-02-21 05:11:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.913196464062683
avg_train_sample_per_sec: 31.913196464062683
avg_episode_per_sec: 0.27511376262123005
collect_time: 21.809159755706787
reward_mean: -98.87289915966387
reward_std: 1.74267393293846
reward_max: -96.11064425770311
reward_min: -101.75980392156862
queue_len: 0.06556558299712457
wait_time: 0.6190702961113711
delay_time: 4.267974753512816
pressure: 0.7988505747126436
total_envstep_count: 1287600
total_train_sample_count: 1287600
total_episode_count: 11100
total_duration: 41604.01952576637
[2025-02-21 05:11:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.715528475280212
avg_train_sample_per_sec: 31.715528475280212
avg_episode_per_sec: 0.27340972823517423
collect_time: 21.945086002349854
reward_mean: -101.51739028944911
reward_std: 2.9478639740121233
reward_max: -97.41736694677873
reward_min: -106.33963585434171
queue_len: 0.0673192243298734
wait_time: 0.6336576076053764
delay_time: 4.407826875525191
pressure: 0.8160919540229884
total_envstep_count: 1288296
total_train_sample_count: 1288296
total_episode_count: 11106
total_duration: 41625.96461176872
[2025-02-21 05:11:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.62359797520011
avg_train_sample_per_sec: 31.62359797520011
avg_episode_per_sec: 0.2726172239241389
collect_time: 22.008880853652954
reward_mean: -100.47782446311857
reward_std: 2.3927998500448937
reward_max: -97.26890756302521
reward_min: -104.28361344537817
queue_len: 0.06662985707103354
wait_time: 0.6325531649441386
delay_time: 4.260640673062603
pressure: 0.8117816091954021
total_envstep_count: 1288992
total_train_sample_count: 1288992
total_episode_count: 11112
total_duration: 41647.973492622375
[2025-02-21 05:12:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10864009412847
avg_train_sample_per_sec: 32.10864009412847
avg_episode_per_sec: 0.27679862150110746
collect_time: 21.676408529281616
reward_mean: -99.01680672268908
reward_std: 2.277417406663637
reward_max: -95.80812324929973
reward_min: -101.55042016806725
queue_len: 0.06566101241557631
wait_time: 0.6170850081854139
delay_time: 4.1891897217801555
pressure: 0.8037135278514588
total_envstep_count: 1289688
total_train_sample_count: 1289688
total_episode_count: 11118
total_duration: 41669.64990115166
[2025-02-21 05:12:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.782467383792852
avg_train_sample_per_sec: 31.782467383792852
avg_episode_per_sec: 0.2739867877913177
collect_time: 21.898866176605225
reward_mean: -99.87371615312793
reward_std: 2.21826344973509
reward_max: -97.03151260504207
reward_min: -103.66456582633053
queue_len: 0.06622925474345354
wait_time: 0.6260244924671902
delay_time: 4.299402531050723
pressure: 0.8152077807250221
total_envstep_count: 1290384
total_train_sample_count: 1290384
total_episode_count: 11124
total_duration: 41691.54876732826
[2025-02-21 05:13:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.967942037895327
avg_train_sample_per_sec: 31.967942037895327
avg_episode_per_sec: 0.27558570722323555
collect_time: 21.77181124687195
reward_mean: -99.52801120448179
reward_std: 3.5875004531998558
reward_max: -96.30112044817926
reward_min: -107.35714285714285
queue_len: 0.06600000743002772
wait_time: 0.6250937267037673
delay_time: 4.257255245535183
pressure: 0.8128868258178604
total_envstep_count: 1291080
total_train_sample_count: 1291080
total_episode_count: 11130
total_duration: 41713.320578575134
[2025-02-21 05:13:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1237130822656
avg_train_sample_per_sec: 32.1237130822656
avg_episode_per_sec: 0.2769285610540138
collect_time: 21.666237592697144
reward_mean: -98.88013538748832
reward_std: 3.2569043904451402
reward_max: -95.29131652661064
reward_min: -104.58053221288513
queue_len: 0.06557038155668986
wait_time: 0.6182049300710557
delay_time: 4.297246208178783
pressure: 0.7958664898320071
total_envstep_count: 1291776
total_train_sample_count: 1291776
total_episode_count: 11136
total_duration: 41734.98681616783
[2025-02-21 05:13:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.714207112606452
avg_train_sample_per_sec: 31.714207112606452
avg_episode_per_sec: 0.27339833717764184
collect_time: 21.946000337600708
reward_mean: -101.19689542483661
reward_std: 2.500640776076345
reward_max: -98.21218487394955
reward_min: -105.48669467787118
queue_len: 0.06710669457880412
wait_time: 0.6366351138156413
delay_time: 4.311918873978725
pressure: 0.8275862068965517
total_envstep_count: 1292472
total_train_sample_count: 1292472
total_episode_count: 11142
total_duration: 41756.93281650543
[2025-02-21 05:14:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.912958183329117
avg_train_sample_per_sec: 31.912958183329117
avg_episode_per_sec: 0.27511170847697514
collect_time: 21.809322595596313
reward_mean: -98.2080999066293
reward_std: 2.186279759156956
reward_max: -94.6330532212885
reward_min: -100.81162464985992
queue_len: 0.0651247346860937
wait_time: 0.6122140832460304
delay_time: 4.262040630174709
pressure: 0.8008399646330681
total_envstep_count: 1293168
total_train_sample_count: 1293168
total_episode_count: 11148
total_duration: 41778.74213910103
[2025-02-21 05:14:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.471755990349656
avg_train_sample_per_sec: 31.471755990349656
avg_episode_per_sec: 0.27130824129611775
collect_time: 22.11506724357605
reward_mean: -101.81010737628385
reward_std: 3.166114499243787
reward_max: -96.34663865546219
reward_min: -106.59313725490193
queue_len: 0.06751333380390176
wait_time: 0.6403743526588355
delay_time: 4.393878587969093
pressure: 0.8275862068965517
total_envstep_count: 1293864
total_train_sample_count: 1293864
total_episode_count: 11154
total_duration: 41800.857206344604
[2025-02-21 05:14:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.162409639350656
avg_train_sample_per_sec: 32.162409639350656
avg_episode_per_sec: 0.27726215206336774
collect_time: 21.640169620513916
reward_mean: -97.47934173669468
reward_std: 1.412045968042913
reward_max: -96.16106442577033
reward_min: -100.45518207282916
queue_len: 0.0646414733001954
wait_time: 0.6054797692728725
delay_time: 4.188570643669009
pressure: 0.7960875331564986
total_envstep_count: 1294560
total_train_sample_count: 1294560
total_episode_count: 11160
total_duration: 41822.49737596512
[2025-02-21 05:15:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.923923130247296
avg_train_sample_per_sec: 31.923923130247296
avg_episode_per_sec: 0.2752062338814422
collect_time: 21.80183172225952
reward_mean: -101.01423902894489
reward_std: 1.7139233624010115
reward_max: -97.75630252100838
reward_min: -102.9614845938375
queue_len: 0.06698556964784143
wait_time: 0.6346639893800137
delay_time: 4.3297766162766855
pressure: 0.82183908045977
total_envstep_count: 1295256
total_train_sample_count: 1295256
total_episode_count: 11166
total_duration: 41844.29920768738
[2025-02-21 05:15:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.15947485601369
avg_train_sample_per_sec: 32.15947485601369
avg_episode_per_sec: 0.27723685220701455
collect_time: 21.642144441604614
reward_mean: -96.203431372549
reward_std: 1.8317803947247082
reward_max: -94.59383753501402
reward_min: -99.89915966386553
queue_len: 0.06379537889426327
wait_time: 0.5947877272040558
delay_time: 4.116200326501002
pressure: 0.7872458001768347
total_envstep_count: 1295952
total_train_sample_count: 1295952
total_episode_count: 11172
total_duration: 41865.94135212898
[2025-02-21 05:16:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.736099071518424
avg_train_sample_per_sec: 31.736099071518424
avg_episode_per_sec: 0.27358706096136576
collect_time: 21.930861711502075
reward_mean: -99.62640056022407
reward_std: 2.3372448122627407
reward_max: -96.58823529411765
reward_min: -103.70308123249296
queue_len: 0.0660652523608913
wait_time: 0.6231754638194801
delay_time: 4.2152601367929785
pressure: 0.8177497789566756
total_envstep_count: 1296648
total_train_sample_count: 1296648
total_episode_count: 11178
total_duration: 41887.872213840485
[2025-02-21 05:16:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.909391723922678
avg_train_sample_per_sec: 31.909391723922678
avg_episode_per_sec: 0.2750809631372645
collect_time: 21.811760187149048
reward_mean: -100.54948646125115
reward_std: 1.583539370700184
reward_max: -97.58473389355744
reward_min: -102.6813725490196
queue_len: 0.06667737828995435
wait_time: 0.6320881690430372
delay_time: 4.241385452535373
pressure: 0.8233863837312113
total_envstep_count: 1297344
total_train_sample_count: 1297344
total_episode_count: 11184
total_duration: 41909.683974027634
[2025-02-21 05:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.817959890240274
avg_train_sample_per_sec: 31.817959890240274
avg_episode_per_sec: 0.27429275767448513
collect_time: 21.874438285827637
reward_mean: -98.07259570494863
reward_std: 1.6903083966325885
reward_max: -95.68837535014002
reward_min: -100.78081232492993
queue_len: 0.06503487778842748
wait_time: 0.612772186681923
delay_time: 4.228147859287375
pressure: 0.8003978779840848
total_envstep_count: 1298040
total_train_sample_count: 1298040
total_episode_count: 11190
total_duration: 41931.55841231346
[2025-02-21 05:17:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.713960769031143
avg_train_sample_per_sec: 31.713960769031143
avg_episode_per_sec: 0.2733962135261305
collect_time: 21.946170806884766
reward_mean: -98.85515873015873
reward_std: 2.840688911935896
reward_max: -96.43977591036415
reward_min: -105.08053221288515
queue_len: 0.06555381878657741
wait_time: 0.6142451122801021
delay_time: 4.286082308287075
pressure: 0.8063660477453581
total_envstep_count: 1298736
total_train_sample_count: 1298736
total_episode_count: 11196
total_duration: 41953.504583120346
[2025-02-21 05:17:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04582400371794
avg_train_sample_per_sec: 32.04582400371794
avg_episode_per_sec: 0.27625710348032706
collect_time: 21.71889853477478
reward_mean: -101.47864145658264
reward_std: 4.974177441214043
reward_max: -97.17717086834732
reward_min: -110.03781512605038
queue_len: 0.06729352881736249
wait_time: 0.6343283997949313
delay_time: 4.359902302482317
pressure: 0.8164235190097259
total_envstep_count: 1299432
total_train_sample_count: 1299432
total_episode_count: 11202
total_duration: 41975.22348165512
[2025-02-21 05:17:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95996233648869
avg_train_sample_per_sec: 31.95996233648869
avg_episode_per_sec: 0.275516916693868
collect_time: 21.777247190475464
reward_mean: -98.76715686274513
reward_std: 2.359910928779163
reward_max: -95.26750700280112
reward_min: -101.97478991596637
queue_len: 0.06549546211057368
wait_time: 0.6206948407125892
delay_time: 4.203970654934076
pressure: 0.8040450928381963
total_envstep_count: 1300128
total_train_sample_count: 1300128
total_episode_count: 11208
total_duration: 41997.000728845596
[2025-02-21 05:18:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82175152843268
avg_train_sample_per_sec: 31.82175152843268
avg_episode_per_sec: 0.27432544421062655
collect_time: 21.8718318939209
reward_mean: -97.20611577964519
reward_std: 3.095874557665406
reward_max: -92.40826330532214
reward_min: -102.0175070028011
queue_len: 0.06446028897854456
wait_time: 0.6050731300477751
delay_time: 4.237245908632606
pressure: 0.7891246684350133
total_envstep_count: 1300824
total_train_sample_count: 1300824
total_episode_count: 11214
total_duration: 42018.87256073952
[2025-02-21 05:18:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02807236417318
avg_train_sample_per_sec: 32.02807236417318
avg_episode_per_sec: 0.27610407210494115
collect_time: 21.730936288833618
reward_mean: -99.55532212885156
reward_std: 4.40013452665096
reward_max: -94.23039215686272
reward_min: -106.90826330532207
queue_len: 0.06601811812258059
wait_time: 0.6208814427627815
delay_time: 4.24992072931758
pressure: 0.8065870910698497
total_envstep_count: 1301520
total_train_sample_count: 1301520
total_episode_count: 11220
total_duration: 42040.60349702835
[2025-02-21 05:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04715485068483
avg_train_sample_per_sec: 32.04715485068483
avg_episode_per_sec: 0.2762685762990071
collect_time: 21.71799659729004
reward_mean: -100.09220354808589
reward_std: 3.464841530700673
reward_max: -97.57633053221292
reward_min: -107.5140056022409
queue_len: 0.06637414028387659
wait_time: 0.6244728550129158
delay_time: 4.318428035108873
pressure: 0.8131078691423519
total_envstep_count: 1302216
total_train_sample_count: 1302216
total_episode_count: 11226
total_duration: 42062.32149362564
[2025-02-21 05:19:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.828423425652154
avg_train_sample_per_sec: 31.828423425652154
avg_episode_per_sec: 0.27438296056596684
collect_time: 21.867247104644775
reward_mean: -97.56209150326798
reward_std: 2.23587171073718
reward_max: -93.72408963585434
reward_min: -99.8515406162465
queue_len: 0.06469634715070821
wait_time: 0.609927801801534
delay_time: 4.233104576871386
pressure: 0.7918877099911583
total_envstep_count: 1302912
total_train_sample_count: 1302912
total_episode_count: 11232
total_duration: 42084.188740730286
[2025-02-21 05:19:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.831575421333614
avg_train_sample_per_sec: 31.831575421333614
avg_episode_per_sec: 0.27441013294253114
collect_time: 21.865081787109375
reward_mean: -98.906045751634
reward_std: 3.243792330300716
reward_max: -94.640756302521
reward_min: -102.77100840336132
queue_len: 0.06558756349577852
wait_time: 0.6207694505742173
delay_time: 4.2037218940255
pressure: 0.8099027409372237
total_envstep_count: 1303608
total_train_sample_count: 1303608
total_episode_count: 11238
total_duration: 42106.053822517395
[2025-02-21 05:20:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.102533328492292
avg_train_sample_per_sec: 30.102533328492292
avg_episode_per_sec: 0.2595045976594163
collect_time: 23.120977640151978
reward_mean: -98.96790382819792
reward_std: 1.7109687336541173
reward_max: -96.281512605042
reward_min: -100.92647058823529
queue_len: 0.06562858344044956
wait_time: 0.619284683369369
delay_time: 4.225753922266672
pressure: 0.8129973474801062
total_envstep_count: 1304304
total_train_sample_count: 1304304
total_episode_count: 11244
total_duration: 42129.17480015755
[2025-02-21 05:20:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.614061900211112
avg_train_sample_per_sec: 31.614061900211112
avg_episode_per_sec: 0.2725350163811303
collect_time: 22.015519618988037
reward_mean: -99.23459383753503
reward_std: 2.0382778760416924
reward_max: -96.60224089635857
reward_min: -103.19887955182074
queue_len: 0.06580543357926726
wait_time: 0.6154257901215304
delay_time: 4.249187501240034
pressure: 0.810344827586207
total_envstep_count: 1305000
total_train_sample_count: 1305000
total_episode_count: 11250
total_duration: 42151.190319776535
[2025-02-21 05:20:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.770360815241986
avg_train_sample_per_sec: 31.770360815241986
avg_episode_per_sec: 0.27388242082105163
collect_time: 21.90721106529236
reward_mean: -97.40371148459383
reward_std: 4.31911319780587
reward_max: -93.66946778711487
reward_min: -106.6498599439776
queue_len: 0.06459132061312589
wait_time: 0.6066012390809551
delay_time: 4.171588568362035
pressure: 0.7925508399646332
total_envstep_count: 1305696
total_train_sample_count: 1305696
total_episode_count: 11256
total_duration: 42173.09753084183
[2025-02-21 05:21:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93630670523424
avg_train_sample_per_sec: 31.93630670523424
avg_episode_per_sec: 0.2753129888382262
collect_time: 21.79337787628174
reward_mean: -98.8018207282913
reward_std: 2.3095192797106794
reward_max: -96.31722689075629
reward_min: -102.17016806722691
queue_len: 0.06551844875881387
wait_time: 0.6192460627044806
delay_time: 4.166897496131116
pressure: 0.8062555260831124
total_envstep_count: 1306392
total_train_sample_count: 1306392
total_episode_count: 11262
total_duration: 42194.89090871811
[2025-02-21 05:21:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.922148000196177
avg_train_sample_per_sec: 31.922148000196177
avg_episode_per_sec: 0.2751909310361739
collect_time: 21.803044080734253
reward_mean: -98.81139122315595
reward_std: 4.4042070948283465
reward_max: -92.8872549019608
reward_min: -107.1610644257703
queue_len: 0.0655247952408196
wait_time: 0.6162642223113824
delay_time: 4.212400690720265
pressure: 0.7986295313881522
total_envstep_count: 1307088
total_train_sample_count: 1307088
total_episode_count: 11268
total_duration: 42216.69395279884
[2025-02-21 05:21:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88061436445085
avg_train_sample_per_sec: 31.88061436445085
avg_episode_per_sec: 0.2748328824521625
collect_time: 21.831448793411255
reward_mean: -97.55707282913166
reward_std: 2.7609326725289534
reward_max: -94.32002801120449
reward_min: -101.92296918767508
queue_len: 0.06469301911746131
wait_time: 0.6070431709376942
delay_time: 4.216453951209299
pressure: 0.7872458001768347
total_envstep_count: 1307784
total_train_sample_count: 1307784
total_episode_count: 11274
total_duration: 42238.525401592255
[2025-02-21 05:22:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00641067697689
avg_train_sample_per_sec: 32.00641067697689
avg_episode_per_sec: 0.2759173334222146
collect_time: 21.745643615722656
reward_mean: -97.0673436041083
reward_std: 1.7232413551812906
reward_max: -95.14915966386555
reward_min: -100.69257703081232
queue_len: 0.06436826498946174
wait_time: 0.6017674642801417
delay_time: 4.164067784540506
pressure: 0.7892351900972591
total_envstep_count: 1308480
total_train_sample_count: 1308480
total_episode_count: 11280
total_duration: 42260.27104520798
[2025-02-21 05:22:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.895280565570115
avg_train_sample_per_sec: 31.895280565570115
avg_episode_per_sec: 0.27495931522043204
collect_time: 21.821410179138184
reward_mean: -98.45063025210084
reward_std: 3.1620245859800042
reward_max: -95.59173669467788
reward_min: -104.09033613445384
queue_len: 0.06528556382765308
wait_time: 0.618395169738983
delay_time: 4.270861161472453
pressure: 0.7932139699381079
total_envstep_count: 1309176
total_train_sample_count: 1309176
total_episode_count: 11286
total_duration: 42282.092455387115
[2025-02-21 05:23:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.784364399942426
avg_train_sample_per_sec: 31.784364399942426
avg_episode_per_sec: 0.274003141378814
collect_time: 21.89755916595459
reward_mean: -98.48249299719889
reward_std: 0.9555348858695007
reward_max: -97.09943977591035
reward_min: -99.7450980392157
queue_len: 0.06530669296896477
wait_time: 0.612200538924677
delay_time: 4.19735788762599
pressure: 0.7984084880636604
total_envstep_count: 1309872
total_train_sample_count: 1309872
total_episode_count: 11292
total_duration: 42303.99001455307
[2025-02-21 05:23:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17971459260396
avg_train_sample_per_sec: 32.17971459260396
avg_episode_per_sec: 0.27741133269486173
collect_time: 21.62853240966797
reward_mean: -96.98330999066293
reward_std: 1.6002728747314885
reward_max: -95.35714285714288
reward_min: -99.15126050420172
queue_len: 0.06431253978160673
wait_time: 0.6056794512676866
delay_time: 4.213629401449739
pressure: 0.7873563218390803
total_envstep_count: 1310568
total_train_sample_count: 1310568
total_episode_count: 11298
total_duration: 42325.61854696274
[2025-02-21 05:23:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82654543566654
avg_train_sample_per_sec: 31.82654543566654
avg_episode_per_sec: 0.2743667709971253
collect_time: 21.868537425994873
reward_mean: -101.00653594771241
reward_std: 3.4184664265296325
reward_max: -96.23809523809523
reward_min: -105.02030812324927
queue_len: 0.06698046150378807
wait_time: 0.632629400124329
delay_time: 4.329772760586948
pressure: 0.8241600353669317
total_envstep_count: 1311264
total_train_sample_count: 1311264
total_episode_count: 11304
total_duration: 42347.48708438873
[2025-02-21 05:24:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.892057059473473
avg_train_sample_per_sec: 31.892057059473473
avg_episode_per_sec: 0.2749315263747713
collect_time: 21.823615789413452
reward_mean: -97.1984126984127
reward_std: 3.120716107330903
reward_max: -93.60714285714288
reward_min: -103.18977591036415
queue_len: 0.06445518083449119
wait_time: 0.6097353176460681
delay_time: 4.211025376505588
pressure: 0.7847038019451813
total_envstep_count: 1311960
total_train_sample_count: 1311960
total_episode_count: 11310
total_duration: 42369.31070017815
[2025-02-21 05:24:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23879956949049
avg_train_sample_per_sec: 32.23879956949049
avg_episode_per_sec: 0.2779206859438835
collect_time: 21.588893175125122
reward_mean: -97.47782446311858
reward_std: 2.3784305748495806
reward_max: -94.22128851540616
reward_min: -100.90406162464984
queue_len: 0.06464046715060914
wait_time: 0.6073893637914934
delay_time: 4.24217321060073
pressure: 0.7911140583554377
total_envstep_count: 1312656
total_train_sample_count: 1312656
total_episode_count: 11316
total_duration: 42390.89959335327
[2025-02-21 05:24:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.804404512056525
avg_train_sample_per_sec: 31.804404512056525
avg_episode_per_sec: 0.2741759009660045
collect_time: 21.883761405944824
reward_mean: -97.67915499533147
reward_std: 2.9120518553169097
reward_max: -94.04691876750702
reward_min: -101.95938375350141
queue_len: 0.06477397546109513
wait_time: 0.6076094783625209
delay_time: 4.205708090789302
pressure: 0.7998452696728559
total_envstep_count: 1313352
total_train_sample_count: 1313352
total_episode_count: 11322
total_duration: 42412.783354759216
[2025-02-21 05:25:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.943708326071167
avg_train_sample_per_sec: 31.943708326071167
avg_episode_per_sec: 0.2753767959144066
collect_time: 21.788328170776367
reward_mean: -98.32247899159664
reward_std: 3.8457620633796323
reward_max: -94.50560224089637
reward_min: -104.60224089635851
queue_len: 0.06520058288567417
wait_time: 0.611789101140014
delay_time: 4.218140443517064
pressure: 0.8034924845269673
total_envstep_count: 1314048
total_train_sample_count: 1314048
total_episode_count: 11328
total_duration: 42434.57168292999
[2025-02-21 05:25:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.140775054905205
avg_train_sample_per_sec: 32.140775054905205
avg_episode_per_sec: 0.27707564702504484
collect_time: 21.654736042022705
reward_mean: -99.16234827264238
reward_std: 3.2265927389235105
reward_max: -96.60014005602235
reward_min: -106.14215686274514
queue_len: 0.06575752537973632
wait_time: 0.6177102914552206
delay_time: 4.253502257157115
pressure: 0.8079133510167993
total_envstep_count: 1314744
total_train_sample_count: 1314744
total_episode_count: 11334
total_duration: 42456.226418972015
[2025-02-21 05:26:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.878220218464485
avg_train_sample_per_sec: 31.878220218464485
avg_episode_per_sec: 0.2748122432626249
collect_time: 21.833088397979736
reward_mean: -98.39122315592903
reward_std: 2.1813459339665977
reward_max: -94.45028011204482
reward_min: -101.70028011204484
queue_len: 0.06524616920154444
wait_time: 0.6145930852447079
delay_time: 4.231793452631893
pressure: 0.7974137931034484
total_envstep_count: 1315440
total_train_sample_count: 1315440
total_episode_count: 11340
total_duration: 42478.059507369995
[2025-02-21 05:26:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.810341887703277
avg_train_sample_per_sec: 31.810341887703277
avg_episode_per_sec: 0.27422708523882133
collect_time: 21.879676818847656
reward_mean: -98.08648459383754
reward_std: 2.8604036137921063
reward_max: -94.07983193277315
reward_min: -101.76260504201683
queue_len: 0.06504408792694798
wait_time: 0.6071759826830821
delay_time: 4.205205457004724
pressure: 0.8022767462422635
total_envstep_count: 1316136
total_train_sample_count: 1316136
total_episode_count: 11346
total_duration: 42499.93918418884
[2025-02-21 05:26:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.896633440537727
avg_train_sample_per_sec: 31.896633440537727
avg_episode_per_sec: 0.27497097793567005
collect_time: 21.82048463821411
reward_mean: -95.42191876750697
reward_std: 1.4899393061313093
reward_max: -93.41596638655459
reward_min: -97.53361344537814
queue_len: 0.06327713446121153
wait_time: 0.5877390301832492
delay_time: 4.170084398192115
pressure: 0.7745358090185678
total_envstep_count: 1316832
total_train_sample_count: 1316832
total_episode_count: 11352
total_duration: 42521.75966882706
[2025-02-21 05:27:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.302594695979046
avg_train_sample_per_sec: 32.302594695979046
avg_episode_per_sec: 0.27847064393085386
collect_time: 21.54625678062439
reward_mean: -98.53419701213818
reward_std: 2.1703858314647464
reward_max: -95.32633053221288
reward_min: -101.3242296918768
queue_len: 0.06534097945102002
wait_time: 0.6172128665789922
delay_time: 4.2572054404617665
pressure: 0.7989610963748893
total_envstep_count: 1317528
total_train_sample_count: 1317528
total_episode_count: 11358
total_duration: 42543.30592560768
[2025-02-21 05:27:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02751225436214
avg_train_sample_per_sec: 32.02751225436214
avg_episode_per_sec: 0.2760992435720874
collect_time: 21.731316328048706
reward_mean: -98.91970121381887
reward_std: 3.1071282493071215
reward_max: -94.72128851540614
reward_min: -103.51190476190476
queue_len: 0.06559661884205496
wait_time: 0.6158054954961648
delay_time: 4.230598843631407
pressure: 0.8093501326259948
total_envstep_count: 1318224
total_train_sample_count: 1318224
total_episode_count: 11364
total_duration: 42565.03724193573
[2025-02-21 05:27:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.840480873530197
avg_train_sample_per_sec: 31.840480873530197
avg_episode_per_sec: 0.27448690408215687
collect_time: 21.85896635055542
reward_mean: -97.74299719887954
reward_std: 2.0809294953318394
reward_max: -95.40406162464987
reward_min: -100.86064425770303
queue_len: 0.06481631113984054
wait_time: 0.6119235382039642
delay_time: 4.202856081562634
pressure: 0.7879089301503094
total_envstep_count: 1318920
total_train_sample_count: 1318920
total_episode_count: 11370
total_duration: 42586.896208286285
[2025-02-21 05:28:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.870559070720326
avg_train_sample_per_sec: 31.870559070720326
avg_episode_per_sec: 0.27474619888552004
collect_time: 21.8383367061615
reward_mean: -100.59302054154995
reward_std: 3.5169324142777194
reward_max: -96.95938375350143
reward_min: -105.00350140056025
queue_len: 0.06670624704346814
wait_time: 0.6308622144702266
delay_time: 4.28540860576427
pressure: 0.8218390804597702
total_envstep_count: 1319616
total_train_sample_count: 1319616
total_episode_count: 11376
total_duration: 42608.73454499245
[2025-02-21 05:28:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.752547555609546
avg_train_sample_per_sec: 31.752547555609546
avg_episode_per_sec: 0.2737288582380133
collect_time: 21.919501066207886
reward_mean: -99.40277777777777
reward_std: 2.2577645292762214
reward_max: -96.281512605042
reward_min: -102.41316526610645
queue_len: 0.06591696139109933
wait_time: 0.6214246087471239
delay_time: 4.24189796584236
pressure: 0.8081343943412908
total_envstep_count: 1320312
total_train_sample_count: 1320312
total_episode_count: 11382
total_duration: 42630.654046058655
[2025-02-21 05:29:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.818370156555
avg_train_sample_per_sec: 31.818370156555
avg_episode_per_sec: 0.27429629445306036
collect_time: 21.87415623664856
reward_mean: -99.94677871148458
reward_std: 3.3543918329075813
reward_max: -95.65966386554622
reward_min: -105.76680672268903
queue_len: 0.06627770471583858
wait_time: 0.6262114041018706
delay_time: 4.313281610840513
pressure: 0.8091290893015031
total_envstep_count: 1321008
total_train_sample_count: 1321008
total_episode_count: 11388
total_duration: 42652.5282022953
[2025-02-21 05:29:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75512597217614
avg_train_sample_per_sec: 31.75512597217614
avg_episode_per_sec: 0.2737510859670357
collect_time: 21.917721271514893
reward_mean: -98.75863678804855
reward_std: 2.563087764701053
reward_max: -94.95098039215685
reward_min: -102.30952380952381
queue_len: 0.06548981219366616
wait_time: 0.6213302628743805
delay_time: 4.24515618771504
pressure: 0.8050397877984085
total_envstep_count: 1321704
total_train_sample_count: 1321704
total_episode_count: 11394
total_duration: 42674.44592356682
[2025-02-21 05:29:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94206905009458
avg_train_sample_per_sec: 31.94206905009458
avg_episode_per_sec: 0.27536266422495326
collect_time: 21.789446353912354
reward_mean: -96.73109243697479
reward_std: 2.002092389928695
reward_max: -93.7009803921569
reward_min: -99.44957983193275
queue_len: 0.0641452867619196
wait_time: 0.6060210777502867
delay_time: 4.198029437416473
pressure: 0.7910035366931919
total_envstep_count: 1322400
total_train_sample_count: 1322400
total_episode_count: 11400
total_duration: 42696.23536992073
[2025-02-21 05:30:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77046834706511
avg_train_sample_per_sec: 31.77046834706511
avg_episode_per_sec: 0.2738833478195268
collect_time: 21.907136917114258
reward_mean: -97.93814192343605
reward_std: 1.8778398105004035
reward_max: -94.45728291316527
reward_min: -100.52030812324932
queue_len: 0.06494571745585945
wait_time: 0.6098777265105866
delay_time: 4.193132152798909
pressure: 0.7959770114942528
total_envstep_count: 1323096
total_train_sample_count: 1323096
total_episode_count: 11406
total_duration: 42718.142506837845
[2025-02-21 05:30:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06639393794365
avg_train_sample_per_sec: 32.06639393794365
avg_episode_per_sec: 0.2764344304995142
collect_time: 21.7049663066864
reward_mean: -97.81816059757237
reward_std: 1.631018812832706
reward_max: -95.41596638655464
reward_min: -100.52310924369749
queue_len: 0.06486615424242198
wait_time: 0.6147812352173406
delay_time: 4.196895855283794
pressure: 0.8006189213085765
total_envstep_count: 1323792
total_train_sample_count: 1323792
total_episode_count: 11412
total_duration: 42739.84747314453
[2025-02-21 05:30:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94812751967237
avg_train_sample_per_sec: 31.94812751967237
avg_episode_per_sec: 0.27541489241096867
collect_time: 21.785314321517944
reward_mean: -96.8453548085901
reward_std: 2.2060484285543027
reward_max: -94.8984593837535
reward_min: -100.93557422969187
queue_len: 0.06422105756537805
wait_time: 0.6052951021257309
delay_time: 4.162048702010195
pressure: 0.7925508399646332
total_envstep_count: 1324488
total_train_sample_count: 1324488
total_episode_count: 11418
total_duration: 42761.63278746605
[2025-02-21 05:31:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.96931613853654
avg_train_sample_per_sec: 31.96931613853654
avg_episode_per_sec: 0.2755975529184185
collect_time: 21.770875453948975
reward_mean: -98.64554154995331
reward_std: 2.76080483371411
reward_max: -93.84873949579834
reward_min: -102.7745098039216
queue_len: 0.06541481535142794
wait_time: 0.6132513460733543
delay_time: 4.26969293748845
pressure: 0.8027188328912467
total_envstep_count: 1325184
total_train_sample_count: 1325184
total_episode_count: 11424
total_duration: 42783.40366292
[2025-02-21 05:31:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.79326249602276
avg_train_sample_per_sec: 31.79326249602276
avg_episode_per_sec: 0.27407984910364447
collect_time: 21.891430616378784
reward_mean: -98.31454248366013
reward_std: 2.820609588229836
reward_max: -94.85434173669466
reward_min: -102.73669467787111
queue_len: 0.06519531994937676
wait_time: 0.6154851529471205
delay_time: 4.204395774899058
pressure: 0.8032714412024758
total_envstep_count: 1325880
total_train_sample_count: 1325880
total_episode_count: 11430
total_duration: 42805.29509353638
[2025-02-21 05:32:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.780814167677676
avg_train_sample_per_sec: 31.780814167677676
avg_episode_per_sec: 0.2739725359282558
collect_time: 21.900005340576172
reward_mean: -97.08286647992531
reward_std: 0.9006922354269918
reward_max: -95.85224089635855
reward_min: -98.30742296918768
queue_len: 0.06437855867369052
wait_time: 0.6109913793103449
delay_time: 4.19479017021431
pressure: 0.7915561450044208
total_envstep_count: 1326576
total_train_sample_count: 1326576
total_episode_count: 11436
total_duration: 42827.19509887695
[2025-02-21 05:32:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.743608373725237
avg_train_sample_per_sec: 31.743608373725237
avg_episode_per_sec: 0.2736517963252176
collect_time: 21.925673723220825
reward_mean: -99.82504668534081
reward_std: 2.4636822206403814
reward_max: -96.02661064425772
reward_min: -103.13585434173669
queue_len: 0.06619698056057083
wait_time: 0.6218323315179298
delay_time: 4.355671340862421
pressure: 0.8072502210433244
total_envstep_count: 1327272
total_train_sample_count: 1327272
total_episode_count: 11442
total_duration: 42849.120772600174
[2025-02-21 05:32:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.632029236688737
avg_train_sample_per_sec: 31.632029236688737
avg_episode_per_sec: 0.2726899072128339
collect_time: 22.00301456451416
reward_mean: -99.15604575163398
reward_std: 1.6228218357506945
reward_max: -96.36554621848737
reward_min: -101.31162464985991
queue_len: 0.0657533459891472
wait_time: 0.6256663032144777
delay_time: 4.306149709066905
pressure: 0.8106763925729442
total_envstep_count: 1327968
total_train_sample_count: 1327968
total_episode_count: 11448
total_duration: 42871.12378716469
[2025-02-21 05:33:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09845564460274
avg_train_sample_per_sec: 32.09845564460274
avg_episode_per_sec: 0.2767108245224374
collect_time: 21.68328619003296
reward_mean: -98.14320728291318
reward_std: 2.047482880840454
reward_max: -95.71428571428572
reward_min: -101.5532212885154
queue_len: 0.06508170244225012
wait_time: 0.6107485876755654
delay_time: 4.169290593041827
pressure: 0.7994031830238727
total_envstep_count: 1328664
total_train_sample_count: 1328664
total_episode_count: 11454
total_duration: 42892.80707335472
[2025-02-21 05:33:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.702087413444076
avg_train_sample_per_sec: 31.702087413444076
avg_episode_per_sec: 0.27329385701244896
collect_time: 21.954390287399292
reward_mean: -98.49626517273578
reward_std: 2.662141246900884
reward_max: -94.23949579831933
reward_min: -102.8788515406163
queue_len: 0.06531582571136325
wait_time: 0.6163333370483474
delay_time: 4.196260104646999
pressure: 0.8036030061892131
total_envstep_count: 1329360
total_train_sample_count: 1329360
total_episode_count: 11460
total_duration: 42914.76146364212
[2025-02-21 05:33:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.172493074744324
avg_train_sample_per_sec: 31.172493074744324
avg_episode_per_sec: 0.2687283885753821
collect_time: 22.32737684249878
reward_mean: -99.4125816993464
reward_std: 3.7752665116634607
reward_max: -94.2857142857143
reward_min: -106.65126050420172
queue_len: 0.06592346266534908
wait_time: 0.6203694674156135
delay_time: 4.317931240401072
pressure: 0.81078691423519
total_envstep_count: 1330056
total_train_sample_count: 1330056
total_episode_count: 11466
total_duration: 42937.08884048462
[2025-02-21 05:34:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.71022026233609
avg_train_sample_per_sec: 31.71022026233609
avg_episode_per_sec: 0.2733639677787594
collect_time: 21.94875955581665
reward_mean: -96.02521008403363
reward_std: 2.0108079342815697
reward_max: -94.08963585434174
reward_min: -99.20798319327731
queue_len: 0.06367719501593742
wait_time: 0.5991090622809688
delay_time: 4.127158605410098
pressure: 0.7913351016799292
total_envstep_count: 1330752
total_train_sample_count: 1330752
total_episode_count: 11472
total_duration: 42959.037600040436
[2025-02-21 05:34:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98054092379167
avg_train_sample_per_sec: 31.98054092379167
avg_episode_per_sec: 0.27569431830854885
collect_time: 21.76323413848877
reward_mean: -98.75
reward_std: 2.254163392276356
reward_max: -95.1827731092437
reward_min: -101.63725490196077
queue_len: 0.0654840848806366
wait_time: 0.6200314785507484
delay_time: 4.284450484830113
pressure: 0.8026083112290009
total_envstep_count: 1331448
total_train_sample_count: 1331448
total_episode_count: 11478
total_duration: 42980.800834178925
[2025-02-21 05:35:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.894492312671034
avg_train_sample_per_sec: 31.894492312671034
avg_episode_per_sec: 0.27495251993681924
collect_time: 21.82194948196411
reward_mean: -98.99638188608776
reward_std: 2.3982318898383284
reward_max: -96.45168067226892
reward_min: -102.91596638655459
queue_len: 0.06564746809422266
wait_time: 0.6163713385442594
delay_time: 4.306382155635935
pressure: 0.8001768346595933
total_envstep_count: 1332144
total_train_sample_count: 1332144
total_episode_count: 11484
total_duration: 43002.62278366089
[2025-02-21 05:35:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08745479128163
avg_train_sample_per_sec: 32.08745479128163
avg_episode_per_sec: 0.27661598958001404
collect_time: 21.690720081329346
reward_mean: -96.46300186741364
reward_std: 1.6547687414270587
reward_max: -94.57002801120449
reward_min: -98.71638655462183
queue_len: 0.06396750786963769
wait_time: 0.6035069421225608
delay_time: 4.188990707914923
pressure: 0.7869142351900972
total_envstep_count: 1332840
total_train_sample_count: 1332840
total_episode_count: 11490
total_duration: 43024.31350374222
[2025-02-21 05:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.83805316647948
avg_train_sample_per_sec: 31.83805316647948
avg_episode_per_sec: 0.274465975573099
collect_time: 21.86063313484192
reward_mean: -98.55357142857143
reward_std: 2.103411193480315
reward_max: -96.36344537815121
reward_min: -101.51050420168067
queue_len: 0.06535382720727548
wait_time: 0.6174483055821797
delay_time: 4.283178945291338
pressure: 0.8010610079575597
total_envstep_count: 1333536
total_train_sample_count: 1333536
total_episode_count: 11496
total_duration: 43046.17413687706
[2025-02-21 05:36:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.093767540414845
avg_train_sample_per_sec: 32.093767540414845
avg_episode_per_sec: 0.2766704098311625
collect_time: 21.686453580856323
reward_mean: -98.22770774976658
reward_std: 1.9888151792413762
reward_max: -94.50840336134453
reward_min: -100.03921568627452
queue_len: 0.06513773723459322
wait_time: 0.6142249892883768
delay_time: 4.254733819018395
pressure: 0.802497789566755
total_envstep_count: 1334232
total_train_sample_count: 1334232
total_episode_count: 11502
total_duration: 43067.860590457916
[2025-02-21 05:36:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02008334114484
avg_train_sample_per_sec: 32.02008334114484
avg_episode_per_sec: 0.2760352012167659
collect_time: 21.736358165740967
reward_mean: -97.39659197012138
reward_std: 2.594810152988694
reward_max: -94.96988795518207
reward_min: -102.75770308123248
queue_len: 0.0645865994496826
wait_time: 0.6059697641213868
delay_time: 4.235868416594955
pressure: 0.7889036251105216
total_envstep_count: 1334928
total_train_sample_count: 1334928
total_episode_count: 11508
total_duration: 43089.59694862366
[2025-02-21 05:36:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76675321601266
avg_train_sample_per_sec: 31.76675321601266
avg_episode_per_sec: 0.27385132082769537
collect_time: 21.909698963165283
reward_mean: -97.63375350140056
reward_std: 1.9195916500067849
reward_max: -94.98669467787116
reward_min: -101.18347338935577
queue_len: 0.06474386836962902
wait_time: 0.6096586180891456
delay_time: 4.257917990114422
pressure: 0.8007294429708223
total_envstep_count: 1335624
total_train_sample_count: 1335624
total_episode_count: 11514
total_duration: 43111.50664758682
[2025-02-21 05:37:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.003676913664066
avg_train_sample_per_sec: 32.003676913664066
avg_episode_per_sec: 0.275893766497104
collect_time: 21.747501134872437
reward_mean: -96.672152194211
reward_std: 2.7415857101101517
reward_max: -93.77661064425766
reward_min: -100.51190476190472
queue_len: 0.06410620172029906
wait_time: 0.6029520119276711
delay_time: 4.1904860540758975
pressure: 0.7809460654288239
total_envstep_count: 1336320
total_train_sample_count: 1336320
total_episode_count: 11520
total_duration: 43133.254148721695
[2025-02-21 05:37:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.90694443032666
avg_train_sample_per_sec: 31.90694443032666
avg_episode_per_sec: 0.27505986577867814
collect_time: 21.813433170318604
reward_mean: -99.1295518207283
reward_std: 2.0725024268111194
reward_max: -96.46358543417368
reward_min: -102.17857142857139
queue_len: 0.06573577706944847
wait_time: 0.6228312058687314
delay_time: 4.269643819718274
pressure: 0.8054818744473917
total_envstep_count: 1337016
total_train_sample_count: 1337016
total_episode_count: 11526
total_duration: 43155.06758189201
[2025-02-21 05:38:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17726822092485
avg_train_sample_per_sec: 32.17726822092485
avg_episode_per_sec: 0.27739024328383494
collect_time: 21.630176782608032
reward_mean: -100.81512605042015
reward_std: 4.147357099966257
reward_max: -95.73669467787113
reward_min: -108.50350140056025
queue_len: 0.06685353186367386
wait_time: 0.6323058843342818
delay_time: 4.317612597608594
pressure: 0.8290229885057471
total_envstep_count: 1337712
total_train_sample_count: 1337712
total_episode_count: 11532
total_duration: 43176.69775867462
[2025-02-21 05:38:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76584928382931
avg_train_sample_per_sec: 31.76584928382931
avg_episode_per_sec: 0.2738435283088734
collect_time: 21.910322427749634
reward_mean: -99.55427170868347
reward_std: 2.4534963327383905
reward_max: -96.63935574229689
reward_min: -103.05322128851543
queue_len: 0.0660174215574824
wait_time: 0.6293803883180152
delay_time: 4.246828663878428
pressure: 0.811450044208665
total_envstep_count: 1338408
total_train_sample_count: 1338408
total_episode_count: 11538
total_duration: 43198.60808110237
[2025-02-21 05:38:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.906471546413023
avg_train_sample_per_sec: 31.906471546413023
avg_episode_per_sec: 0.2750557891932157
collect_time: 21.813756465911865
reward_mean: -96.56477591036413
reward_std: 2.36711651631182
reward_max: -93.94957983193278
reward_min: -100.27240896358542
queue_len: 0.06403499728803988
wait_time: 0.6031953453353049
delay_time: 4.150009197711129
pressure: 0.792661361626879
total_envstep_count: 1339104
total_train_sample_count: 1339104
total_episode_count: 11544
total_duration: 43220.42183756828
[2025-02-21 05:39:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.010284220160656
avg_train_sample_per_sec: 32.010284220160656
avg_episode_per_sec: 0.27595072603586773
collect_time: 21.743012189865112
reward_mean: -97.74054621848741
reward_std: 2.3675618178793325
reward_max: -94.66806722689076
reward_min: -101.84173669467793
queue_len: 0.06481468582127813
wait_time: 0.6091474167031976
delay_time: 4.176421337943585
pressure: 0.8038240495137048
total_envstep_count: 1339800
total_train_sample_count: 1339800
total_episode_count: 11550
total_duration: 43242.16484975815
[2025-02-21 05:39:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.713427095166857
avg_train_sample_per_sec: 31.713427095166857
avg_episode_per_sec: 0.2733916128893695
collect_time: 21.946540117263794
reward_mean: -98.35585901027076
reward_std: 3.0959857735616994
reward_max: -95.06162464985994
reward_min: -104.5833333333333
queue_len: 0.06522271817657212
wait_time: 0.6191975353359734
delay_time: 4.256271605487682
pressure: 0.8003978779840848
total_envstep_count: 1340496
total_train_sample_count: 1340496
total_episode_count: 11556
total_duration: 43264.11138987541
[2025-02-21 05:39:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968681761982047
avg_train_sample_per_sec: 31.968681761982047
avg_episode_per_sec: 0.2755920841550177
collect_time: 21.771307468414307
reward_mean: -97.14589169000932
reward_std: 1.5368751084751577
reward_max: -94.02661064425769
reward_min: -98.76330532212886
queue_len: 0.0644203525795818
wait_time: 0.6026076765808003
delay_time: 4.201393159995792
pressure: 0.792661361626879
total_envstep_count: 1341192
total_train_sample_count: 1341192
total_episode_count: 11562
total_duration: 43285.882697343826
[2025-02-21 05:40:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77134384224401
avg_train_sample_per_sec: 31.77134384224401
avg_episode_per_sec: 0.2738908951917587
collect_time: 21.906533241271973
reward_mean: -98.04528478057891
reward_std: 2.386032733726918
reward_max: -94.54271708683474
reward_min: -101.20168067226892
queue_len: 0.0650167670958746
wait_time: 0.6136915752154088
delay_time: 4.249438884589353
pressure: 0.8022767462422635
total_envstep_count: 1341888
total_train_sample_count: 1341888
total_episode_count: 11568
total_duration: 43307.7892305851
[2025-02-21 05:40:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.887090142641103
avg_train_sample_per_sec: 31.887090142641103
avg_episode_per_sec: 0.2748887081262164
collect_time: 21.827015161514282
reward_mean: -100.2794117647059
reward_std: 1.8203850319249937
reward_max: -99.06722689075633
reward_min: -104.31582633053218
queue_len: 0.06649828366359807
wait_time: 0.6285065861003996
delay_time: 4.33053197828712
pressure: 0.8148762157382846
total_envstep_count: 1342584
total_train_sample_count: 1342584
total_episode_count: 11574
total_duration: 43329.61624574661
[2025-02-21 05:40:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08503441641829
avg_train_sample_per_sec: 32.08503441641829
avg_episode_per_sec: 0.27659512427946803
collect_time: 21.69235634803772
reward_mean: -96.94619514472454
reward_std: 2.045167854088316
reward_max: -94.32492997198878
reward_min: -100.63725490196079
queue_len: 0.06428792781480408
wait_time: 0.5980049292042193
delay_time: 4.224314889709077
pressure: 0.7798408488063661
total_envstep_count: 1343280
total_train_sample_count: 1343280
total_episode_count: 11580
total_duration: 43351.30860209465
[2025-02-21 05:41:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07830386431491
avg_train_sample_per_sec: 32.07830386431491
avg_episode_per_sec: 0.2765371022785768
collect_time: 21.69690775871277
reward_mean: -98.87114845938375
reward_std: 2.662617949152488
reward_max: -94.23669467787116
reward_min: -102.24649859943978
queue_len: 0.06556442205529427
wait_time: 0.6177448875217638
delay_time: 4.231309460009672
pressure: 0.8062555260831124
total_envstep_count: 1343976
total_train_sample_count: 1343976
total_episode_count: 11586
total_duration: 43373.00550985336
[2025-02-21 05:41:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.935018237263616
avg_train_sample_per_sec: 31.935018237263616
avg_episode_per_sec: 0.2753018813557208
collect_time: 21.794257164001465
reward_mean: -97.64962651727359
reward_std: 2.738240981631607
reward_max: -93.87535014005603
reward_min: -102.36274509803923
queue_len: 0.06475439424222386
wait_time: 0.6046010910995698
delay_time: 4.238154185173616
pressure: 0.7927718832891246
total_envstep_count: 1344672
total_train_sample_count: 1344672
total_episode_count: 11592
total_duration: 43394.799767017365
[2025-02-21 05:42:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.574802913525314
avg_train_sample_per_sec: 31.574802913525314
avg_episode_per_sec: 0.27219657684073545
collect_time: 22.042892932891846
reward_mean: -99.46195144724557
reward_std: 3.264346250899123
reward_max: -96.52941176470588
reward_min: -104.81302521008404
queue_len: 0.06595620122496389
wait_time: 0.6195719777743103
delay_time: 4.242681588805959
pressure: 0.806366047745358
total_envstep_count: 1345368
total_train_sample_count: 1345368
total_episode_count: 11598
total_duration: 43416.842659950256
[2025-02-21 05:42:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.780000770975686
avg_train_sample_per_sec: 31.780000770975686
avg_episode_per_sec: 0.27396552388772144
collect_time: 21.90056586265564
reward_mean: -97.49999999999999
reward_std: 2.159950255976207
reward_max: -94.71148459383754
reward_min: -100.53221288515401
queue_len: 0.06465517241379311
wait_time: 0.6078730895541241
delay_time: 4.203952867446966
pressure: 0.7902298850574713
total_envstep_count: 1346064
total_train_sample_count: 1346064
total_episode_count: 11604
total_duration: 43438.74322581291
[2025-02-21 05:42:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1053401290128
avg_train_sample_per_sec: 32.1053401290128
avg_episode_per_sec: 0.2767701735259724
collect_time: 21.67863655090332
reward_mean: -98.65231092436973
reward_std: 2.1899596785939486
reward_max: -95.44887955182072
reward_min: -102.69677871148457
queue_len: 0.06541930432650513
wait_time: 0.611237111997761
delay_time: 4.237901815783039
pressure: 0.8049292661361628
total_envstep_count: 1346760
total_train_sample_count: 1346760
total_episode_count: 11610
total_duration: 43460.421862363815
[2025-02-21 05:43:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865276754119694
avg_train_sample_per_sec: 31.865276754119694
avg_episode_per_sec: 0.27470066167344565
collect_time: 21.841956853866577
reward_mean: -98.18965919701213
reward_std: 2.2895562474504842
reward_max: -94.92366946778712
reward_min: -101.20868347338936
queue_len: 0.0651125060988144
wait_time: 0.612408579700669
delay_time: 4.200233946942802
pressure: 0.8012820512820514
total_envstep_count: 1347456
total_train_sample_count: 1347456
total_episode_count: 11616
total_duration: 43482.26381921768
[2025-02-21 05:43:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72323488463118
avg_train_sample_per_sec: 31.72323488463118
avg_episode_per_sec: 0.27347616279854464
collect_time: 21.939754962921143
reward_mean: -99.55999066293185
reward_std: 3.8084462398397685
reward_max: -96.11904761904759
reward_min: -107.19257703081234
queue_len: 0.06602121396746144
wait_time: 0.6210791124584228
delay_time: 4.283640598602809
pressure: 0.8133289124668436
total_envstep_count: 1348152
total_train_sample_count: 1348152
total_episode_count: 11622
total_duration: 43504.2035741806
[2025-02-21 05:43:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.724332215130907
avg_train_sample_per_sec: 31.724332215130907
avg_episode_per_sec: 0.273485622544232
collect_time: 21.938996076583862
reward_mean: -98.41970121381887
reward_std: 2.898512697117799
reward_max: -94.45098039215681
reward_min: -103.34453781512605
queue_len: 0.06526505385531756
wait_time: 0.6134048999794436
delay_time: 4.173238722977178
pressure: 0.7988505747126436
total_envstep_count: 1348848
total_train_sample_count: 1348848
total_episode_count: 11628
total_duration: 43526.14257025719
[2025-02-21 05:44:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929034582522625
avg_train_sample_per_sec: 31.929034582522625
avg_episode_per_sec: 0.275250298125195
collect_time: 21.798341512680054
reward_mean: -97.9735060690943
reward_std: 4.858840497708793
reward_max: -93.17086834733892
reward_min: -108.00490196078431
queue_len: 0.06496916848083177
wait_time: 0.6082970655105543
delay_time: 4.283718591847151
pressure: 0.7965296198054818
total_envstep_count: 1349544
total_train_sample_count: 1349544
total_episode_count: 11634
total_duration: 43547.94091176987
[2025-02-21 05:44:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.159729586592775
avg_train_sample_per_sec: 32.159729586592775
avg_episode_per_sec: 0.27723904816028255
collect_time: 21.64197301864624
reward_mean: -98.44281045751632
reward_std: 2.326692858785372
reward_max: -95.49089635854342
reward_min: -102.57633053221286
queue_len: 0.06528037828747767
wait_time: 0.6081079093883354
delay_time: 4.228300375244262
pressure: 0.8021662245800177
total_envstep_count: 1350240
total_train_sample_count: 1350240
total_episode_count: 11640
total_duration: 43569.58288478851
[2025-02-21 05:45:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80924795756215
avg_train_sample_per_sec: 31.80924795756215
avg_episode_per_sec: 0.2742176548065703
collect_time: 21.8804292678833
reward_mean: -99.68043884220356
reward_std: 2.508288687257601
reward_max: -95.23319327731095
reward_min: -103.53571428571425
queue_len: 0.06610108676538698
wait_time: 0.6240267437655876
delay_time: 4.236801897437527
pressure: 0.8108974358974358
total_envstep_count: 1350936
total_train_sample_count: 1350936
total_episode_count: 11646
total_duration: 43591.4633140564
[2025-02-21 05:45:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91071370460451
avg_train_sample_per_sec: 31.91071370460451
avg_episode_per_sec: 0.2750923595224527
collect_time: 21.810856580734253
reward_mean: -97.374883286648
reward_std: 2.4617392470960766
reward_max: -94.35154061624651
reward_min: -100.90546218487394
queue_len: 0.06457220377098673
wait_time: 0.6101368487271125
delay_time: 4.151445111656982
pressure: 0.7975243147656941
total_envstep_count: 1351632
total_train_sample_count: 1351632
total_episode_count: 11652
total_duration: 43613.27417063713
[2025-02-21 05:45:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.683668345801753
avg_train_sample_per_sec: 31.683668345801753
avg_episode_per_sec: 0.27313507194656683
collect_time: 21.967153310775757
reward_mean: -97.55333800186742
reward_std: 2.229124271778407
reward_max: -94.34033613445376
reward_min: -100.10994397759103
queue_len: 0.06469054244155664
wait_time: 0.6103517003618424
delay_time: 4.2001460047362515
pressure: 0.7919982316534041
total_envstep_count: 1352328
total_train_sample_count: 1352328
total_episode_count: 11658
total_duration: 43635.24132394791
[2025-02-21 05:46:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.717522614838398
avg_train_sample_per_sec: 31.717522614838398
avg_episode_per_sec: 0.2734269190934345
collect_time: 21.943706274032593
reward_mean: -97.17857142857143
reward_std: 1.5976657609257594
reward_max: -93.95238095238095
reward_min: -98.60994397759104
queue_len: 0.06444202349374763
wait_time: 0.6050929434550124
delay_time: 4.153088481653458
pressure: 0.7898983200707339
total_envstep_count: 1353024
total_train_sample_count: 1353024
total_episode_count: 11664
total_duration: 43657.18503022194
[2025-02-21 05:46:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.771690665091075
avg_train_sample_per_sec: 31.771690665091075
avg_episode_per_sec: 0.27389388504388856
collect_time: 21.906294107437134
reward_mean: -98.8719654528478
reward_std: 1.8314877903080478
reward_max: -95.26540616246498
reward_min: -101.37535014005601
queue_len: 0.0655649638281484
wait_time: 0.6216612086921417
delay_time: 4.25370674180649
pressure: 0.8040450928381965
total_envstep_count: 1353720
total_train_sample_count: 1353720
total_episode_count: 11670
total_duration: 43679.091324329376
[2025-02-21 05:46:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55116511567935
avg_train_sample_per_sec: 31.55116511567935
avg_episode_per_sec: 0.2719928027213737
collect_time: 22.059407234191895
reward_mean: -100.17028478057891
reward_std: 3.2013241665652727
reward_max: -96.07563025210086
reward_min: -104.21358543417365
queue_len: 0.06642591828950857
wait_time: 0.6238730350672541
delay_time: 4.32586073383339
pressure: 0.8204022988505747
total_envstep_count: 1354416
total_train_sample_count: 1354416
total_episode_count: 11676
total_duration: 43701.15073156357
[2025-02-21 05:47:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.787841351161052
avg_train_sample_per_sec: 31.787841351161052
avg_episode_per_sec: 0.274033115096216
collect_time: 21.895164012908936
reward_mean: -98.17215219421102
reward_std: 3.301447655613827
reward_max: -93.8144257703081
reward_min: -103.50770308123248
queue_len: 0.06510089668051128
wait_time: 0.6134564457967094
delay_time: 4.16407804872225
pressure: 0.8054818744473917
total_envstep_count: 1355112
total_train_sample_count: 1355112
total_episode_count: 11682
total_duration: 43723.04589557648
[2025-02-21 05:47:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.441641510267356
avg_train_sample_per_sec: 31.441641510267356
avg_episode_per_sec: 0.27104863370920135
collect_time: 22.13624882698059
reward_mean: -97.22373949579833
reward_std: 2.5604382174393465
reward_max: -93.55112044817929
reward_min: -102.12955182072834
queue_len: 0.06447197579296972
wait_time: 0.6037281402392964
delay_time: 4.234833788307864
pressure: 0.7956454465075155
total_envstep_count: 1355808
total_train_sample_count: 1355808
total_episode_count: 11688
total_duration: 43745.18214440346
[2025-02-21 05:48:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.859606405510135
avg_train_sample_per_sec: 31.859606405510135
avg_episode_per_sec: 0.27465177935784596
collect_time: 21.845844268798828
reward_mean: -98.27532679738562
reward_std: 3.6034389016641617
reward_max: -92.87394957983192
reward_min: -104.31232492997202
queue_len: 0.06516931485237772
wait_time: 0.6141533978755074
delay_time: 4.213485949919783
pressure: 0.8071396993810787
total_envstep_count: 1356504
total_train_sample_count: 1356504
total_episode_count: 11694
total_duration: 43767.02798867226
[2025-02-21 05:48:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.730284564640574
avg_train_sample_per_sec: 31.730284564640574
avg_episode_per_sec: 0.2735369359020739
collect_time: 21.93488049507141
reward_mean: -98.64098972922504
reward_std: 1.5855096781243319
reward_max: -95.2955182072829
reward_min: -100.26750700280114
queue_len: 0.06541179690266911
wait_time: 0.6188092389917949
delay_time: 4.283731548572543
pressure: 0.8032714412024758
total_envstep_count: 1357200
total_train_sample_count: 1357200
total_episode_count: 11700
total_duration: 43788.96286916733
[2025-02-21 05:48:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80234088172898
avg_train_sample_per_sec: 31.80234088172898
avg_episode_per_sec: 0.27415811104938775
collect_time: 21.885181427001953
reward_mean: -95.99906629318393
reward_std: 1.6274611584610228
reward_max: -94.28501400560222
reward_min: -99.13935574229693
queue_len: 0.06365985828460473
wait_time: 0.5961697897549825
delay_time: 4.149580985162608
pressure: 0.7848143236074271
total_envstep_count: 1357896
total_train_sample_count: 1357896
total_episode_count: 11706
total_duration: 43810.84805059433
[2025-02-21 05:49:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.949230673391654
avg_train_sample_per_sec: 31.949230673391654
avg_episode_per_sec: 0.2754244023568246
collect_time: 21.78456211090088
reward_mean: -95.76622315592903
reward_std: 2.4077373222690683
reward_max: -92.41806722689076
reward_min: -99.3550420168067
queue_len: 0.0635054530211731
wait_time: 0.5935359223264902
delay_time: 4.1611410598672895
pressure: 0.7848143236074271
total_envstep_count: 1358592
total_train_sample_count: 1358592
total_episode_count: 11712
total_duration: 43832.63261270523
[2025-02-21 05:49:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.701345860584127
avg_train_sample_per_sec: 31.701345860584127
avg_episode_per_sec: 0.2732874643153804
collect_time: 21.954903841018677
reward_mean: -96.74509803921569
reward_std: 1.448124018057108
reward_max: -94.96918767507003
reward_min: -98.58963585434174
queue_len: 0.06415457429656214
wait_time: 0.606723447557626
delay_time: 4.256416056346022
pressure: 0.7877984084880637
total_envstep_count: 1359288
total_train_sample_count: 1359288
total_episode_count: 11718
total_duration: 43854.58751654625
[2025-02-21 05:49:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.757945266840675
avg_train_sample_per_sec: 31.757945266840675
avg_episode_per_sec: 0.27377539023138514
collect_time: 21.915775537490845
reward_mean: -99.2417133520075
reward_std: 3.3875301194596354
reward_max: -95.13725490196074
reward_min: -103.85504201680678
queue_len: 0.06581015474271053
wait_time: 0.6220030673631081
delay_time: 4.272729162952542
pressure: 0.812444739168877
total_envstep_count: 1359984
total_train_sample_count: 1359984
total_episode_count: 11724
total_duration: 43876.50329208374
[2025-02-21 05:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.878115088988565
avg_train_sample_per_sec: 31.878115088988565
avg_episode_per_sec: 0.27481133697403937
collect_time: 21.833160400390625
reward_mean: -98.19782913165268
reward_std: 3.1980476502261492
reward_max: -93.90056022408967
reward_min: -102.17296918767508
queue_len: 0.06511792382735589
wait_time: 0.6103247665113792
delay_time: 4.318238166362975
pressure: 0.8016136162687887
total_envstep_count: 1360680
total_train_sample_count: 1360680
total_episode_count: 11730
total_duration: 43898.33645248413
[2025-02-21 05:50:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75761152688032
avg_train_sample_per_sec: 31.75761152688032
avg_episode_per_sec: 0.2737725131627614
collect_time: 21.916005849838257
reward_mean: -97.97747432306255
reward_std: 3.5733325378517637
reward_max: -93.24159663865545
reward_min: -103.79341736694674
queue_len: 0.06497179994898047
wait_time: 0.6100586786438713
delay_time: 4.167835799248174
pressure: 0.8043766578249337
total_envstep_count: 1361376
total_train_sample_count: 1361376
total_episode_count: 11736
total_duration: 43920.25245833397
[2025-02-21 05:51:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17577511320765
avg_train_sample_per_sec: 32.17577511320765
avg_episode_per_sec: 0.2773773716655832
collect_time: 21.63118052482605
reward_mean: -98.91316526610645
reward_std: 2.852763493910234
reward_max: -95.04481792717088
reward_min: -102.87885154061631
queue_len: 0.06559228465922179
wait_time: 0.6116756384251313
delay_time: 4.269915434289335
pressure: 0.8054818744473917
total_envstep_count: 1362072
total_train_sample_count: 1362072
total_episode_count: 11742
total_duration: 43941.883638858795
[2025-02-21 05:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.895572946909496
avg_train_sample_per_sec: 31.895572946909496
avg_episode_per_sec: 0.2749618357492198
collect_time: 21.821210145950317
reward_mean: -97.50653594771241
reward_std: 1.708748270393324
reward_max: -95.3844537815126
reward_min: -100.86344537815125
queue_len: 0.06465950659662627
wait_time: 0.6140582006454217
delay_time: 4.20105363874278
pressure: 0.7943191865605659
total_envstep_count: 1362768
total_train_sample_count: 1362768
total_episode_count: 11748
total_duration: 43963.704849004745
[2025-02-21 05:51:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.982238110601102
avg_train_sample_per_sec: 31.982238110601102
avg_episode_per_sec: 0.2757089492293198
collect_time: 21.7620792388916
reward_mean: -96.80368814192344
reward_std: 2.869841019600201
reward_max: -93.18557422969187
reward_min: -101.09173669467792
queue_len: 0.06419342714981661
wait_time: 0.608459210386188
delay_time: 4.259484177800721
pressure: 0.7849248452696728
total_envstep_count: 1363464
total_train_sample_count: 1363464
total_episode_count: 11754
total_duration: 43985.46692824364
[2025-02-21 05:52:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01134287799672
avg_train_sample_per_sec: 32.01134287799672
avg_episode_per_sec: 0.2759598523965235
collect_time: 21.742293119430542
reward_mean: -95.80753968253966
reward_std: 2.7094445202848094
reward_max: -92.09313725490195
reward_min: -100.57633053221289
queue_len: 0.06353285124836848
wait_time: 0.5966029758499333
delay_time: 4.17411582927306
pressure: 0.7818302387267905
total_envstep_count: 1364160
total_train_sample_count: 1364160
total_episode_count: 11760
total_duration: 44007.20922136307
[2025-02-21 05:52:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.732552713935558
avg_train_sample_per_sec: 31.732552713935558
avg_episode_per_sec: 0.2735564889132376
collect_time: 21.93331265449524
reward_mean: -98.46195144724555
reward_std: 1.0032925219202793
reward_max: -96.5266106442577
reward_min: -99.51540616246496
queue_len: 0.06529307125148909
wait_time: 0.6145118193165859
delay_time: 4.245219974730004
pressure: 0.7952033598585322
total_envstep_count: 1364856
total_train_sample_count: 1364856
total_episode_count: 11766
total_duration: 44029.14253401756
[2025-02-21 05:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.073741458295
avg_train_sample_per_sec: 32.073741458295
avg_episode_per_sec: 0.27649777119219826
collect_time: 21.69999408721924
reward_mean: -100.7798786181139
reward_std: 2.787065951021476
reward_max: -97.44747899159663
reward_min: -106.09523809523807
queue_len: 0.06683015823482354
wait_time: 0.6310740476561977
delay_time: 4.359556350267528
pressure: 0.8133289124668436
total_envstep_count: 1365552
total_train_sample_count: 1365552
total_episode_count: 11772
total_duration: 44050.84252810478
[2025-02-21 05:53:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.837800728421506
avg_train_sample_per_sec: 31.837800728421506
avg_episode_per_sec: 0.274463799382944
collect_time: 21.860806465148926
reward_mean: -96.80263772175537
reward_std: 2.765272345748648
reward_max: -91.47969187675068
reward_min: -99.86064425770307
queue_len: 0.06419273058471842
wait_time: 0.6053384439540626
delay_time: 4.19054838239391
pressure: 0.7913351016799294
total_envstep_count: 1366248
total_train_sample_count: 1366248
total_episode_count: 11778
total_duration: 44072.70333456993
[2025-02-21 05:53:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.979425097090363
avg_train_sample_per_sec: 31.979425097090363
avg_episode_per_sec: 0.275684699112848
collect_time: 21.763993501663208
reward_mean: -98.7265406162465
reward_std: 1.1099806293965666
reward_max: -97.08403361344543
reward_min: -100.4425770308123
queue_len: 0.06546852826011042
wait_time: 0.6185379655841116
delay_time: 4.247062561804121
pressure: 0.8033819628647215
total_envstep_count: 1366944
total_train_sample_count: 1366944
total_episode_count: 11784
total_duration: 44094.467328071594
[2025-02-21 05:54:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.40161745943737
avg_train_sample_per_sec: 32.40161745943737
avg_episode_per_sec: 0.2793242884434256
collect_time: 21.480409145355225
reward_mean: -98.73926237161531
reward_std: 2.8892457780852316
reward_max: -96.52030812324927
reward_min: -104.90616246498602
queue_len: 0.06547696443741068
wait_time: 0.6241670629348114
delay_time: 4.287308444656141
pressure: 0.7957559681697614
total_envstep_count: 1367640
total_train_sample_count: 1367640
total_episode_count: 11790
total_duration: 44115.94773721695
[2025-02-21 05:54:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73452795111777
avg_train_sample_per_sec: 31.73452795111777
avg_episode_per_sec: 0.27357351681998077
collect_time: 21.931947469711304
reward_mean: -98.96802054154995
reward_std: 4.711533802390805
reward_max: -93.95868347338934
reward_min: -106.6148459383754
queue_len: 0.06562866083657158
wait_time: 0.6170545141133377
delay_time: 4.238319892554853
pressure: 0.801945181255526
total_envstep_count: 1368336
total_train_sample_count: 1368336
total_episode_count: 11796
total_duration: 44137.87968468666
[2025-02-21 05:54:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80434179536916
avg_train_sample_per_sec: 31.80434179536916
avg_episode_per_sec: 0.2741753603049066
collect_time: 21.88380455970764
reward_mean: -99.56010737628384
reward_std: 3.572624509504791
reward_max: -94.10784313725489
reward_min: -103.50700280112042
queue_len: 0.06602129136358344
wait_time: 0.6246640234343075
delay_time: 4.206895841783063
pressure: 0.8135499557913352
total_envstep_count: 1369032
total_train_sample_count: 1369032
total_episode_count: 11802
total_duration: 44159.76348924637
[2025-02-21 05:55:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.847582418088333
avg_train_sample_per_sec: 31.847582418088333
avg_episode_per_sec: 0.27454812429386494
collect_time: 21.854092121124268
reward_mean: -99.61916433239962
reward_std: 1.802294523870526
reward_max: -96.35294117647057
reward_min: -102.12675070028006
queue_len: 0.06606045380132601
wait_time: 0.6253135316903063
delay_time: 4.244259578972115
pressure: 0.8110079575596818
total_envstep_count: 1369728
total_train_sample_count: 1369728
total_episode_count: 11808
total_duration: 44181.61758136749
[2025-02-21 05:55:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.408121551477738
avg_train_sample_per_sec: 31.408121551477738
avg_episode_per_sec: 0.2707596685472219
collect_time: 22.159873485565186
reward_mean: -98.56197478991596
reward_std: 2.6687915095423724
reward_max: -96.01050420168066
reward_min: -104.1029411764706
queue_len: 0.06535939972806099
wait_time: 0.6151584639160704
delay_time: 4.230327182332846
pressure: 0.7998452696728559
total_envstep_count: 1370424
total_train_sample_count: 1370424
total_episode_count: 11814
total_duration: 44203.77745485306
[2025-02-21 05:55:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.521945504887366
avg_train_sample_per_sec: 31.521945504887366
avg_episode_per_sec: 0.27174090952489105
collect_time: 22.07985544204712
reward_mean: -98.82107843137253
reward_std: 1.5953253332654243
reward_max: -96.44887955182071
reward_min: -101.69117647058822
queue_len: 0.06553121911894728
wait_time: 0.6251759987814755
delay_time: 4.291011729982212
pressure: 0.7925508399646329
total_envstep_count: 1371120
total_train_sample_count: 1371120
total_episode_count: 11820
total_duration: 44225.857310295105
[2025-02-21 05:56:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14247973631949
avg_train_sample_per_sec: 32.14247973631949
avg_episode_per_sec: 0.27709034255447834
collect_time: 21.653587579727173
reward_mean: -96.17577030812326
reward_std: 2.4444826167237963
reward_max: -91.92577030812326
reward_min: -99.92366946778711
queue_len: 0.06377703601334433
wait_time: 0.6041831520406571
delay_time: 4.152227863837723
pressure: 0.7858090185676393
total_envstep_count: 1371816
total_train_sample_count: 1371816
total_episode_count: 11826
total_duration: 44247.51089787483
[2025-02-21 05:56:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865963731927813
avg_train_sample_per_sec: 31.865963731927813
avg_episode_per_sec: 0.27470658389592945
collect_time: 21.84148597717285
reward_mean: -98.94969654528477
reward_std: 3.3237578487007364
reward_max: -95.61764705882352
reward_min: -104.30882352941177
queue_len: 0.06561650964541428
wait_time: 0.6170571455814863
delay_time: 4.313885330809999
pressure: 0.7966401414677277
total_envstep_count: 1372512
total_train_sample_count: 1372512
total_episode_count: 11832
total_duration: 44269.352383852005
[2025-02-21 05:57:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.78496518046981
avg_train_sample_per_sec: 31.78496518046981
avg_episode_per_sec: 0.2740083205212915
collect_time: 21.89714527130127
reward_mean: -100.54528478057888
reward_std: 3.1915093735572237
reward_max: -96.71568627450979
reward_min: -105.67927170868347
queue_len: 0.0666745920295616
wait_time: 0.6307865210628903
delay_time: 4.279329987359958
pressure: 0.8110079575596817
total_envstep_count: 1373208
total_train_sample_count: 1373208
total_episode_count: 11838
total_duration: 44291.249529123306
[2025-02-21 05:57:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.050889411220965
avg_train_sample_per_sec: 32.050889411220965
avg_episode_per_sec: 0.2763007707863876
collect_time: 21.715466022491455
reward_mean: -97.3609943977591
reward_std: 3.8302425469178942
reward_max: -93.9677871148459
reward_min: -105.40406162464988
queue_len: 0.06456299363246625
wait_time: 0.6109173112215709
delay_time: 4.14525353710955
pressure: 0.7997347480106102
total_envstep_count: 1373904
total_train_sample_count: 1373904
total_episode_count: 11844
total_duration: 44312.9649951458
[2025-02-21 05:57:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.815243313349363
avg_train_sample_per_sec: 31.815243313349363
avg_episode_per_sec: 0.27426933890818417
collect_time: 21.87630605697632
reward_mean: -95.85375816993464
reward_std: 1.8368411598652754
reward_max: -93.2703081232493
reward_min: -99.18837535014009
queue_len: 0.06356350011268877
wait_time: 0.6035143721502748
delay_time: 4.090501873878452
pressure: 0.7802829354553493
total_envstep_count: 1374600
total_train_sample_count: 1374600
total_episode_count: 11850
total_duration: 44334.841301202774
[2025-02-21 05:58:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.90752125608298
avg_train_sample_per_sec: 31.90752125608298
avg_episode_per_sec: 0.27506483841450846
collect_time: 21.81303882598877
reward_mean: -95.36741363211952
reward_std: 3.1474512630729916
reward_max: -91.51960784313727
reward_min: -101.35714285714289
queue_len: 0.0632409904722278
wait_time: 0.5984299113102358
delay_time: 4.16888537151742
pressure: 0.7750884173297967
total_envstep_count: 1375296
total_train_sample_count: 1375296
total_episode_count: 11856
total_duration: 44356.65434002876
[2025-02-21 05:58:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1019751810286
avg_train_sample_per_sec: 32.1019751810286
avg_episode_per_sec: 0.2767411653536948
collect_time: 21.680908918380737
reward_mean: -96.90756302521008
reward_std: 2.9518913856513773
reward_max: -93.35714285714286
reward_min: -101.06302521008405
queue_len: 0.06426230969841516
wait_time: 0.6102346774253468
delay_time: 4.137429968650517
pressure: 0.7898983200707339
total_envstep_count: 1375992
total_train_sample_count: 1375992
total_episode_count: 11862
total_duration: 44378.33524894714
[2025-02-21 05:58:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13488703192583
avg_train_sample_per_sec: 32.13488703192583
avg_episode_per_sec: 0.27702488820625715
collect_time: 21.658703804016113
reward_mean: -97.31267507002802
reward_std: 4.0228391940677275
reward_max: -91.0910364145658
reward_min: -103.71078431372548
queue_len: 0.0645309516379496
wait_time: 0.6129251214190363
delay_time: 4.218269162792943
pressure: 0.7885720601237843
total_envstep_count: 1376688
total_train_sample_count: 1376688
total_episode_count: 11868
total_duration: 44399.99395275116
[2025-02-21 05:59:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.804361545901482
avg_train_sample_per_sec: 31.804361545901482
avg_episode_per_sec: 0.2741755305681162
collect_time: 21.883790969848633
reward_mean: -97.6126283846872
reward_std: 2.460418383737869
reward_max: -94.72899159663865
reward_min: -102.20868347338936
queue_len: 0.06472985967154324
wait_time: 0.6097336149313838
delay_time: 4.225911262668268
pressure: 0.7916666666666666
total_envstep_count: 1377384
total_train_sample_count: 1377384
total_episode_count: 11874
total_duration: 44421.87774372101
[2025-02-21 05:59:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.664288931727892
avg_train_sample_per_sec: 30.664288931727892
avg_episode_per_sec: 0.2643473183769646
collect_time: 22.69741201400757
reward_mean: -99.04166666666667
reward_std: 2.6686236786507522
reward_max: -94.25490196078437
reward_min: -102.00700280112045
queue_len: 0.06567749778956676
wait_time: 0.6196454266941083
delay_time: 4.264125514824765
pressure: 0.7992926613616268
total_envstep_count: 1378080
total_train_sample_count: 1378080
total_episode_count: 11880
total_duration: 44444.575155735016
[2025-02-21 06:00:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02030074606545
avg_train_sample_per_sec: 32.02030074606545
avg_episode_per_sec: 0.2760370753971159
collect_time: 21.736210584640503
reward_mean: -98.92308590102708
reward_std: 3.9083784154205423
reward_max: -92.62394957983193
reward_min: -104.05112044817928
queue_len: 0.06559886332959354
wait_time: 0.6191965291863871
delay_time: 4.291352346978057
pressure: 0.810344827586207
total_envstep_count: 1378776
total_train_sample_count: 1378776
total_episode_count: 11886
total_duration: 44466.31136631966
[2025-02-21 06:00:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.68985209773365
avg_train_sample_per_sec: 31.68985209773365
avg_episode_per_sec: 0.2731883801528763
collect_time: 21.96286678314209
reward_mean: -96.82528011204481
reward_std: 1.2763737863729052
reward_max: -95.06792717086833
reward_min: -98.54131652661064
queue_len: 0.06420774543239045
wait_time: 0.6032313345320445
delay_time: 4.226458621744323
pressure: 0.78868258178603
total_envstep_count: 1379472
total_train_sample_count: 1379472
total_episode_count: 11892
total_duration: 44488.2742331028
[2025-02-21 06:00:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09279444964128
avg_train_sample_per_sec: 32.09279444964128
avg_episode_per_sec: 0.2766620211175973
collect_time: 21.687111139297485
reward_mean: -98.82574696545282
reward_std: 2.8670126727238983
reward_max: -94.29061624649862
reward_min: -102.3893557422969
queue_len: 0.06553431496382815
wait_time: 0.6228507096914805
delay_time: 4.262857240718685
pressure: 0.7963085764809902
total_envstep_count: 1380168
total_train_sample_count: 1380168
total_episode_count: 11898
total_duration: 44509.961344242096
[2025-02-21 06:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16703629694842
avg_train_sample_per_sec: 32.16703629694842
avg_episode_per_sec: 0.27730203704265877
collect_time: 21.637057065963745
reward_mean: -97.5673436041083
reward_std: 2.051780193569504
reward_max: -95.80672268907561
reward_min: -102.01960784313725
queue_len: 0.06469982997619912
wait_time: 0.6068225145938128
delay_time: 4.2651548097218095
pressure: 0.7884615384615384
total_envstep_count: 1380864
total_train_sample_count: 1380864
total_episode_count: 11904
total_duration: 44531.59840130806
[2025-02-21 06:01:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.783658096582972
avg_train_sample_per_sec: 31.783658096582972
avg_episode_per_sec: 0.2739970525567497
collect_time: 21.898045778274536
reward_mean: -96.1624649859944
reward_std: 2.46940828191703
reward_max: -93.796218487395
reward_min: -100.67507002801115
queue_len: 0.06376821285543395
wait_time: 0.596969446487702
delay_time: 4.2482003075939145
pressure: 0.7787356321839081
total_envstep_count: 1381560
total_train_sample_count: 1381560
total_episode_count: 11910
total_duration: 44553.496447086334
[2025-02-21 06:01:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.251201562044308
avg_train_sample_per_sec: 31.251201562044308
avg_episode_per_sec: 0.26940691001762335
collect_time: 22.271143674850464
reward_mean: -99.07621381886084
reward_std: 3.076650352593142
reward_max: -94.36344537815127
reward_min: -103.32703081232489
queue_len: 0.06570040704168492
wait_time: 0.6189378713465935
delay_time: 4.229600716866165
pressure: 0.8058134394341291
total_envstep_count: 1382256
total_train_sample_count: 1382256
total_episode_count: 11916
total_duration: 44575.767590761185
[2025-02-21 06:02:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.5763394726636
avg_train_sample_per_sec: 31.5763394726636
avg_episode_per_sec: 0.27220982304020347
collect_time: 22.041820287704468
reward_mean: -96.08963585434174
reward_std: 2.156355020151585
reward_max: -93.26610644257704
reward_min: -99.13515406162468
queue_len: 0.06371991767529293
wait_time: 0.5970842249366589
delay_time: 4.131006029421655
pressure: 0.7862511052166224
total_envstep_count: 1382952
total_train_sample_count: 1382952
total_episode_count: 11922
total_duration: 44597.80941104889
[2025-02-21 06:02:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.896818502682684
avg_train_sample_per_sec: 31.896818502682684
avg_episode_per_sec: 0.27497257329898867
collect_time: 21.82035803794861
reward_mean: -96.54026610644257
reward_std: 2.769607009470334
reward_max: -91.82212885154061
reward_min: -100.6449579831933
queue_len: 0.0640187441024155
wait_time: 0.602287566220122
delay_time: 4.209885427802129
pressure: 0.7839301503094607
total_envstep_count: 1383648
total_train_sample_count: 1383648
total_episode_count: 11928
total_duration: 44619.62976908684
[2025-02-21 06:02:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03085282280135
avg_train_sample_per_sec: 32.03085282280135
avg_episode_per_sec: 0.27612804157587373
collect_time: 21.729049921035767
reward_mean: -97.44012605042018
reward_std: 3.7535355161970294
reward_max: -93.08333333333333
reward_min: -104.90546218487397
queue_len: 0.0646154682031964
wait_time: 0.6102523237411674
delay_time: 4.206812197566742
pressure: 0.7928824049513704
total_envstep_count: 1384344
total_train_sample_count: 1384344
total_episode_count: 11934
total_duration: 44641.35881900787
[2025-02-21 06:03:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.54961566180262
avg_train_sample_per_sec: 31.54961566180262
avg_episode_per_sec: 0.2719794453603674
collect_time: 22.060490608215332
reward_mean: -96.43137254901961
reward_std: 2.6093492573395056
reward_max: -92.55602240896357
reward_min: -101.13375350140058
queue_len: 0.06394653352057003
wait_time: 0.601786194141671
delay_time: 4.160057250733003
pressure: 0.7785145888594166
total_envstep_count: 1385040
total_train_sample_count: 1385040
total_episode_count: 11940
total_duration: 44663.41930961609
[2025-02-21 06:03:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72704673637417
avg_train_sample_per_sec: 31.72704673637417
avg_episode_per_sec: 0.2735090235894325
collect_time: 21.937119007110596
reward_mean: -96.27054154995331
reward_std: 1.4566086501722506
reward_max: -93.37324929971989
reward_min: -97.73599439775909
queue_len: 0.06383988166442527
wait_time: 0.5993463587910849
delay_time: 4.139670808731728
pressure: 0.7832670203359858
total_envstep_count: 1385736
total_train_sample_count: 1385736
total_episode_count: 11946
total_duration: 44685.3564286232
[2025-02-21 06:04:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.902339290946806
avg_train_sample_per_sec: 31.902339290946806
avg_episode_per_sec: 0.2750201663012656
collect_time: 21.816581964492798
reward_mean: -99.31384220354808
reward_std: 3.2052956072993357
reward_max: -95.43767507002804
reward_min: -104.13445378151258
queue_len: 0.06585798554611941
wait_time: 0.6244003348465824
delay_time: 4.219322188614201
pressure: 0.8084659593280284
total_envstep_count: 1386432
total_train_sample_count: 1386432
total_episode_count: 11952
total_duration: 44707.17301058769
[2025-02-21 06:04:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97889401195169
avg_train_sample_per_sec: 31.97889401195169
avg_episode_per_sec: 0.275680120792687
collect_time: 21.764354944229126
reward_mean: -97.31419234360409
reward_std: 4.328438428341559
reward_max: -91.04411764705881
reward_min: -102.83123249299719
queue_len: 0.06453195778753587
wait_time: 0.6110533736040835
delay_time: 4.165524024569535
pressure: 0.7924403183023873
total_envstep_count: 1387128
total_train_sample_count: 1387128
total_episode_count: 11958
total_duration: 44728.93736553192
[2025-02-21 06:04:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.814935759777494
avg_train_sample_per_sec: 31.814935759777494
avg_episode_per_sec: 0.27426668758428874
collect_time: 21.87651753425598
reward_mean: -98.95296451914096
reward_std: 3.3174352390233803
reward_max: -92.91106442577026
reward_min: -102.89495798319327
queue_len: 0.06561867673683087
wait_time: 0.6201871995482543
delay_time: 4.266946543718908
pressure: 0.7949823165340407
total_envstep_count: 1387824
total_train_sample_count: 1387824
total_episode_count: 11964
total_duration: 44750.81388306618
[2025-02-21 06:05:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.939868001285806
avg_train_sample_per_sec: 31.939868001285806
avg_episode_per_sec: 0.27534368966625694
collect_time: 21.790947914123535
reward_mean: -97.85329131652662
reward_std: 3.0660186096167767
reward_max: -93.46008403361347
reward_min: -102.69887955182078
queue_len: 0.06488945047515028
wait_time: 0.6202616546176385
delay_time: 4.216996947055736
pressure: 0.7981874447391689
total_envstep_count: 1388520
total_train_sample_count: 1388520
total_episode_count: 11970
total_duration: 44772.6048309803
[2025-02-21 06:05:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.15425004953547
avg_train_sample_per_sec: 32.15425004953547
avg_episode_per_sec: 0.2771918107718575
collect_time: 21.645661115646362
reward_mean: -98.11332866479927
reward_std: 1.9083488967632913
reward_max: -95.16386554621849
reward_min: -100.48879551820727
queue_len: 0.06506188903501278
wait_time: 0.6150456977662859
delay_time: 4.238740315881257
pressure: 0.7979664014146772
total_envstep_count: 1389216
total_train_sample_count: 1389216
total_episode_count: 11976
total_duration: 44794.25049209595
[2025-02-21 06:05:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04227280516921
avg_train_sample_per_sec: 32.04227280516921
avg_episode_per_sec: 0.27622648969973457
collect_time: 21.72130560874939
reward_mean: -95.05999066293185
reward_std: 1.5947154466784432
reward_max: -93.18767507002804
reward_min: -97.45798319327733
queue_len: 0.06303712908682484
wait_time: 0.5946049175638426
delay_time: 4.139112270872418
pressure: 0.7740937223695844
total_envstep_count: 1389912
total_train_sample_count: 1389912
total_episode_count: 11982
total_duration: 44815.9717977047
[2025-02-21 06:06:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.59855174492573
avg_train_sample_per_sec: 31.59855174492573
avg_episode_per_sec: 0.27240130814591146
collect_time: 22.026325941085815
reward_mean: -94.82773109243698
reward_std: 2.608056747788692
reward_max: -91.65826330532214
reward_min: -98.81162464985994
queue_len: 0.0628831108040033
wait_time: 0.5941417017735475
delay_time: 4.119815265053913
pressure: 0.7693412908930152
total_envstep_count: 1390608
total_train_sample_count: 1390608
total_episode_count: 11988
total_duration: 44837.99812364578
[2025-02-21 06:06:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06991948199582
avg_train_sample_per_sec: 32.06991948199582
avg_episode_per_sec: 0.2764648231206536
collect_time: 21.702580213546753
reward_mean: -98.68534080298787
reward_std: 3.8824556253933085
reward_max: -95.01960784313725
reward_min: -105.96918767507
queue_len: 0.06544120742903704
wait_time: 0.6186037522878295
delay_time: 4.268360083191575
pressure: 0.802608311229001
total_envstep_count: 1391304
total_train_sample_count: 1391304
total_episode_count: 11994
total_duration: 44859.70070385933
[2025-02-21 06:07:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.894509387586233
avg_train_sample_per_sec: 31.894509387586233
avg_episode_per_sec: 0.27495266713436406
collect_time: 21.821937799453735
reward_mean: -96.62605042016808
reward_std: 3.6149729823119756
reward_max: -94.10084033613445
reward_min: -104.44537815126053
queue_len: 0.06407563025210085
wait_time: 0.6071142205777095
delay_time: 4.119191559048286
pressure: 0.7873563218390806
total_envstep_count: 1392000
total_train_sample_count: 1392000
total_episode_count: 12000
total_duration: 44881.52264165878
[2025-02-21 06:07:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01605152424521
avg_train_sample_per_sec: 32.01605152424521
avg_episode_per_sec: 0.2760004441745277
collect_time: 21.739095449447632
reward_mean: -97.43382352941177
reward_std: 2.5807305308635318
reward_max: -93.75490196078428
reward_min: -101.58753501400561
queue_len: 0.06461128881260726
wait_time: 0.6142034731664548
delay_time: 4.252564110879803
pressure: 0.7910035366931919
total_envstep_count: 1392696
total_train_sample_count: 1392696
total_episode_count: 12006
total_duration: 44903.26173710823
[2025-02-21 06:07:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.910595454378406
avg_train_sample_per_sec: 31.910595454378406
avg_episode_per_sec: 0.27509134012395176
collect_time: 21.81093740463257
reward_mean: -97.30088702147526
reward_std: 2.723931983257458
reward_max: -93.61554621848741
reward_min: -100.96008403361346
queue_len: 0.06452313462962551
wait_time: 0.6095734049588004
delay_time: 4.16117202679371
pressure: 0.7963085764809903
total_envstep_count: 1393392
total_train_sample_count: 1393392
total_episode_count: 12012
total_duration: 44925.07267451286
[2025-02-21 06:08:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.733162230857594
avg_train_sample_per_sec: 31.733162230857594
avg_episode_per_sec: 0.27356174336946204
collect_time: 21.932891368865967
reward_mean: -97.32329598506068
reward_std: 4.541607817717485
reward_max: -91.76750700280112
reward_min: -106.13095238095237
queue_len: 0.0645379946850535
wait_time: 0.6115178277323308
delay_time: 4.268309965051356
pressure: 0.790893015030946
total_envstep_count: 1394088
total_train_sample_count: 1394088
total_episode_count: 12018
total_duration: 44947.00556588173
[2025-02-21 06:08:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.889755949335495
avg_train_sample_per_sec: 31.889755949335495
avg_episode_per_sec: 0.2749116892184094
collect_time: 21.825190544128418
reward_mean: -96.33426704014937
reward_std: 0.9963506804654618
reward_max: -94.7002801120448
reward_min: -97.65616246498595
queue_len: 0.06388213994704867
wait_time: 0.6017527590169578
delay_time: 4.205643577362808
pressure: 0.7842617152961981
total_envstep_count: 1394784
total_train_sample_count: 1394784
total_episode_count: 12024
total_duration: 44968.83075642586
[2025-02-21 06:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.285459081643396
avg_train_sample_per_sec: 32.285459081643396
avg_episode_per_sec: 0.2783229231176155
collect_time: 21.557692527770996
reward_mean: -96.01388888888887
reward_std: 1.4068406348413964
reward_max: -94.23529411764706
reward_min: -97.78921568627452
queue_len: 0.06366968759210138
wait_time: 0.6038761216246002
delay_time: 4.174387569616752
pressure: 0.7800618921308576
total_envstep_count: 1395480
total_train_sample_count: 1395480
total_episode_count: 12030
total_duration: 44990.38844895363
[2025-02-21 06:09:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.853112936600258
avg_train_sample_per_sec: 31.853112936600258
avg_episode_per_sec: 0.2745958011775884
collect_time: 21.850297689437866
reward_mean: -97.96918767507003
reward_std: 2.950071056702072
reward_max: -93.57072829131654
reward_min: -102.50420168067227
queue_len: 0.064966304824317
wait_time: 0.614826821533211
delay_time: 4.211063746452088
pressure: 0.7995137046861185
total_envstep_count: 1396176
total_train_sample_count: 1396176
total_episode_count: 12036
total_duration: 45012.23874664307
[2025-02-21 06:09:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77757605102464
avg_train_sample_per_sec: 31.77757605102464
avg_episode_per_sec: 0.2739446211295227
collect_time: 21.902236938476562
reward_mean: -98.11846405228759
reward_std: 0.9423567078881013
reward_max: -96.10504201680672
reward_min: -98.96568627450982
queue_len: 0.06506529446438168
wait_time: 0.6146683142753123
delay_time: 4.2699553573460545
pressure: 0.7977453580901858
total_envstep_count: 1396872
total_train_sample_count: 1396872
total_episode_count: 12042
total_duration: 45034.14098358154
[2025-02-21 06:10:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23638656773674
avg_train_sample_per_sec: 32.23638656773674
avg_episode_per_sec: 0.277899884204627
collect_time: 21.590509176254272
reward_mean: -96.78629785247432
reward_std: 2.8459898222877014
reward_max: -93.78151260504197
reward_min: -102.65336134453783
queue_len: 0.06418189512763549
wait_time: 0.6069335780289127
delay_time: 4.192066071984137
pressure: 0.7897877984084879
total_envstep_count: 1397568
total_train_sample_count: 1397568
total_episode_count: 12048
total_duration: 45055.7314927578
[2025-02-21 06:10:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0011407666894
avg_train_sample_per_sec: 32.0011407666894
avg_episode_per_sec: 0.27587190316111554
collect_time: 21.74922466278076
reward_mean: -97.11204481792716
reward_std: 2.3454062414717076
reward_max: -94.91596638655464
reward_min: -101.75770308123246
queue_len: 0.06439790770419573
wait_time: 0.6099558191977056
delay_time: 4.215423712158356
pressure: 0.7911140583554377
total_envstep_count: 1398264
total_train_sample_count: 1398264
total_episode_count: 12054
total_duration: 45077.48071742058
[2025-02-21 06:10:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73409914576177
avg_train_sample_per_sec: 31.73409914576177
avg_episode_per_sec: 0.27356982022208426
collect_time: 21.932243824005127
reward_mean: -99.17903828197946
reward_std: 2.2609669461387534
reward_max: -95.48179271708683
reward_min: -102.17156862745098
queue_len: 0.06576859302518533
wait_time: 0.6208766442032163
delay_time: 4.272588104878911
pressure: 0.8029398762157384
total_envstep_count: 1398960
total_train_sample_count: 1398960
total_episode_count: 12060
total_duration: 45099.41296124458
[2025-02-21 06:11:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25152524477473
avg_train_sample_per_sec: 32.25152524477473
avg_episode_per_sec: 0.27803039004116153
collect_time: 21.580374717712402
reward_mean: -95.89332399626518
reward_std: 1.5839690465645655
reward_max: -94.70028011204484
reward_min: -99.30812324929973
queue_len: 0.06358973739805383
wait_time: 0.6023337717049683
delay_time: 4.187776111541743
pressure: 0.77763041556145
total_envstep_count: 1399656
total_train_sample_count: 1399656
total_episode_count: 12066
total_duration: 45120.993335962296
[2025-02-21 06:11:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02028002398289
avg_train_sample_per_sec: 32.02028002398289
avg_episode_per_sec: 0.2760368967584732
collect_time: 21.73622465133667
reward_mean: -96.46428571428572
reward_std: 3.7727034978495473
reward_max: -90.93977591036415
reward_min: -100.99019607843137
queue_len: 0.06396835922697992
wait_time: 0.6019623477153904
delay_time: 4.195331966911044
pressure: 0.7869142351900972
total_envstep_count: 1400352
total_train_sample_count: 1400352
total_episode_count: 12072
total_duration: 45142.72956061363
[2025-02-21 06:11:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.948509331610026
avg_train_sample_per_sec: 31.948509331610026
avg_episode_per_sec: 0.2754181838931899
collect_time: 21.785053968429565
reward_mean: -99.14892623716155
reward_std: 3.296883854130964
reward_max: -95.1113445378151
reward_min: -105.78291316526611
queue_len: 0.06574862482570394
wait_time: 0.6193952824277368
delay_time: 4.277809716126543
pressure: 0.8017241379310346
total_envstep_count: 1401048
total_train_sample_count: 1401048
total_episode_count: 12078
total_duration: 45164.51461458206
[2025-02-21 06:12:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.694972484274253
avg_train_sample_per_sec: 31.694972484274253
avg_episode_per_sec: 0.27323252141615734
collect_time: 21.9593186378479
reward_mean: -96.54446778711485
reward_std: 2.945976218720657
reward_max: -92.41106442577029
reward_min: -99.78011204481794
queue_len: 0.06402153036280825
wait_time: 0.6033198756956363
delay_time: 4.181970790968999
pressure: 0.788129973474801
total_envstep_count: 1401744
total_train_sample_count: 1401744
total_episode_count: 12084
total_duration: 45186.47393321991
[2025-02-21 06:12:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53381917132808
avg_train_sample_per_sec: 31.53381917132808
avg_episode_per_sec: 0.2718432687183455
collect_time: 22.07154154777527
reward_mean: -99.80718954248364
reward_std: 5.002362375109084
reward_max: -93.15966386554621
reward_min: -106.1603641456582
queue_len: 0.06618513895390164
wait_time: 0.6259569256526659
delay_time: 4.27977950915641
pressure: 0.8134394341290894
total_envstep_count: 1402440
total_train_sample_count: 1402440
total_episode_count: 12090
total_duration: 45208.545474767685
[2025-02-21 06:13:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02586893355683
avg_train_sample_per_sec: 32.02586893355683
avg_episode_per_sec: 0.27608507701342094
collect_time: 21.732431411743164
reward_mean: -97.53408029878618
reward_std: 1.9620059914066772
reward_max: -95.76750700280111
reward_min: -101.38515406162466
queue_len: 0.0646777720814232
wait_time: 0.6110145207508291
delay_time: 4.2130802402402585
pressure: 0.7973032714412026
total_envstep_count: 1403136
total_train_sample_count: 1403136
total_episode_count: 12096
total_duration: 45230.27790617943
[2025-02-21 06:13:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07260431898848
avg_train_sample_per_sec: 32.07260431898848
avg_episode_per_sec: 0.2764879682671421
collect_time: 21.700763463974
reward_mean: -96.22163865546219
reward_std: 1.6022635323655807
reward_max: -93.46218487394958
reward_min: -98.26470588235293
queue_len: 0.06380745268929854
wait_time: 0.604264185780413
delay_time: 4.137966005511511
pressure: 0.780503978779841
total_envstep_count: 1403832
total_train_sample_count: 1403832
total_episode_count: 12102
total_duration: 45251.9786696434
[2025-02-21 06:13:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.011971225939924
avg_train_sample_per_sec: 32.011971225939924
avg_episode_per_sec: 0.2759652691891373
collect_time: 21.74186635017395
reward_mean: -95.38807189542484
reward_std: 2.819324699230062
reward_max: -91.89845938375346
reward_min: -100.92086834733894
queue_len: 0.06325468958582549
wait_time: 0.5956016248232271
delay_time: 4.183059233375587
pressure: 0.7768567639257294
total_envstep_count: 1404528
total_train_sample_count: 1404528
total_episode_count: 12108
total_duration: 45273.720535993576
[2025-02-21 06:14:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.29869332953702
avg_train_sample_per_sec: 32.29869332953702
avg_episode_per_sec: 0.27843701146152605
collect_time: 21.548859357833862
reward_mean: -98.70389822595705
reward_std: 1.6685853701955673
reward_max: -96.3067226890756
reward_min: -100.80042016806719
queue_len: 0.06545351341243835
wait_time: 0.619403486416671
delay_time: 4.2527439047046975
pressure: 0.8041556145004422
total_envstep_count: 1405224
total_train_sample_count: 1405224
total_episode_count: 12114
total_duration: 45295.26939535141
[2025-02-21 06:14:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.855853018239806
avg_train_sample_per_sec: 31.855853018239806
avg_episode_per_sec: 0.27461942257103283
collect_time: 21.84841823577881
reward_mean: -96.91584967320262
reward_std: 1.744396935253669
reward_max: -93.94677871148463
reward_min: -99.20868347338933
queue_len: 0.06426780482307866
wait_time: 0.6099770257351395
delay_time: 4.212894553065408
pressure: 0.7838196286472149
total_envstep_count: 1405920
total_train_sample_count: 1405920
total_episode_count: 12120
total_duration: 45317.11781358719
[2025-02-21 06:14:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.589117248918356
avg_train_sample_per_sec: 31.589117248918356
avg_episode_per_sec: 0.2723199762837789
collect_time: 22.032904386520386
reward_mean: -98.43429038281978
reward_std: 3.63297401859754
reward_max: -93.30392156862746
reward_min: -104.98949579831934
queue_len: 0.06527472837057016
wait_time: 0.6188708463049233
delay_time: 4.281583497599168
pressure: 0.797524314765694
total_envstep_count: 1406616
total_train_sample_count: 1406616
total_episode_count: 12126
total_duration: 45339.15071797371
[2025-02-21 06:15:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91153031784708
avg_train_sample_per_sec: 31.91153031784708
avg_episode_per_sec: 0.2750993992917852
collect_time: 21.810298442840576
reward_mean: -98.3483893557423
reward_std: 1.8364162779833433
reward_max: -95.12745098039217
reward_min: -100.34453781512605
queue_len: 0.06521776482476278
wait_time: 0.6126277655182322
delay_time: 4.258083097369162
pressure: 0.7973032714412024
total_envstep_count: 1407312
total_train_sample_count: 1407312
total_episode_count: 12132
total_duration: 45360.96101641655
[2025-02-21 06:15:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.955406466243883
avg_train_sample_per_sec: 30.955406466243883
avg_episode_per_sec: 0.2668569522952059
collect_time: 22.48395609855652
reward_mean: -96.52847805788981
reward_std: 2.643714283121669
reward_max: -92.94607843137253
reward_min: -100.97058823529413
queue_len: 0.06401092709409138
wait_time: 0.6049212014602481
delay_time: 4.233674731344548
pressure: 0.7816091954022989
total_envstep_count: 1408008
total_train_sample_count: 1408008
total_episode_count: 12138
total_duration: 45383.444972515106
[2025-02-21 06:16:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98769737824393
avg_train_sample_per_sec: 31.98769737824393
avg_episode_per_sec: 0.2757560118814132
collect_time: 21.758365154266357
reward_mean: -95.32679738562092
reward_std: 3.4364545263759627
reward_max: -91.06232492997201
reward_min: -101.30392156862744
queue_len: 0.06321405662176453
wait_time: 0.5961112782867347
delay_time: 4.14019852251952
pressure: 0.776525198938992
total_envstep_count: 1408704
total_train_sample_count: 1408704
total_episode_count: 12144
total_duration: 45405.20333766937
[2025-02-21 06:16:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.24441908397453
avg_train_sample_per_sec: 32.24441908397453
avg_episode_per_sec: 0.27796913003426316
collect_time: 21.58513069152832
reward_mean: -95.51610644257704
reward_std: 1.9849115409375604
reward_max: -92.35224089635857
reward_min: -97.48389355742299
queue_len: 0.06333959313168237
wait_time: 0.5964786002818457
delay_time: 4.170561893376319
pressure: 0.7816091954022989
total_envstep_count: 1409400
total_train_sample_count: 1409400
total_episode_count: 12150
total_duration: 45426.7884683609
[2025-02-21 06:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91219138309842
avg_train_sample_per_sec: 31.91219138309842
avg_episode_per_sec: 0.2751050981301588
collect_time: 21.80984663963318
reward_mean: -99.15126050420169
reward_std: 2.1500172921490552
reward_max: -96.0322128851541
reward_min: -102.42436974789914
queue_len: 0.06575017274814436
wait_time: 0.6200201013208112
delay_time: 4.291752353911414
pressure: 0.8016136162687887
total_envstep_count: 1410096
total_train_sample_count: 1410096
total_episode_count: 12156
total_duration: 45448.598315000534
[2025-02-21 06:17:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.630688432371766
avg_train_sample_per_sec: 31.630688432371766
avg_episode_per_sec: 0.272678348554929
collect_time: 22.003947257995605
reward_mean: -98.41421568627452
reward_std: 3.6584046086370012
reward_max: -95.35154061624652
reward_min: -105.5595238095238
queue_len: 0.06526141623758258
wait_time: 0.6141817248561671
delay_time: 4.225952444418032
pressure: 0.7991821396993811
total_envstep_count: 1410792
total_train_sample_count: 1410792
total_episode_count: 12162
total_duration: 45470.60226225853
[2025-02-21 06:17:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.913374740847743
avg_train_sample_per_sec: 31.913374740847743
avg_episode_per_sec: 0.27511529949006674
collect_time: 21.809037923812866
reward_mean: -98.70424836601306
reward_std: 2.272769781212882
reward_max: -96.01120448179269
reward_min: -101.55252100840336
queue_len: 0.06545374560080443
wait_time: 0.6138723725564498
delay_time: 4.2677034908574205
pressure: 0.7979664014146772
total_envstep_count: 1411488
total_train_sample_count: 1411488
total_episode_count: 12168
total_duration: 45492.41130018234
[2025-02-21 06:17:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73118440441297
avg_train_sample_per_sec: 31.73118440441297
avg_episode_per_sec: 0.27354469314149116
collect_time: 21.934258460998535
reward_mean: -96.69024276377218
reward_std: 4.0606733783039255
reward_max: -92.70728291316524
reward_min: -102.95238095238095
queue_len: 0.06411819811921231
wait_time: 0.6068964278903427
delay_time: 4.210883833885044
pressure: 0.7823828470380194
total_envstep_count: 1412184
total_train_sample_count: 1412184
total_episode_count: 12174
total_duration: 45514.34555864334
[2025-02-21 06:18:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.956772970574523
avg_train_sample_per_sec: 31.956772970574523
avg_episode_per_sec: 0.2754894221601252
collect_time: 21.779420614242554
reward_mean: -98.3530578898226
reward_std: 2.5049373437896683
reward_max: -94.71218487394961
reward_min: -102.03221288515405
queue_len: 0.06522086066964364
wait_time: 0.6142833459643805
delay_time: 4.325510444152481
pressure: 0.7873563218390803
total_envstep_count: 1412880
total_train_sample_count: 1412880
total_episode_count: 12180
total_duration: 45536.12497925758
[2025-02-21 06:18:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.043685311267865
avg_train_sample_per_sec: 32.043685311267865
avg_episode_per_sec: 0.2762386664764471
collect_time: 21.720348119735718
reward_mean: -98.6029411764706
reward_std: 2.3789684228856776
reward_max: -93.71008403361344
reward_min: -101.03711484593839
queue_len: 0.06538656576689032
wait_time: 0.6177988326188125
delay_time: 4.249321579463296
pressure: 0.7995137046861185
total_envstep_count: 1413576
total_train_sample_count: 1413576
total_episode_count: 12186
total_duration: 45557.84532737732
[2025-02-21 06:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.955499641167275
avg_train_sample_per_sec: 31.955499641167275
avg_episode_per_sec: 0.2754784451824765
collect_time: 21.780288457870483
reward_mean: -99.78968253968253
reward_std: 3.4824599677659953
reward_max: -95.23459383753504
reward_min: -105.2612044817927
queue_len: 0.06617352953559848
wait_time: 0.6309899954676831
delay_time: 4.3115895901045
pressure: 0.8048187444739169
total_envstep_count: 1414272
total_train_sample_count: 1414272
total_episode_count: 12192
total_duration: 45579.62561583519
[2025-02-21 06:19:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.938476163987197
avg_train_sample_per_sec: 31.938476163987197
avg_episode_per_sec: 0.27533169106885513
collect_time: 21.791897535324097
reward_mean: -96.48599439775911
reward_std: 1.986487734361073
reward_max: -93.63025210084034
reward_min: -99.28151260504202
queue_len: 0.0639827549056758
wait_time: 0.6032759920944505
delay_time: 4.242816214069319
pressure: 0.7764146772767463
total_envstep_count: 1414968
total_train_sample_count: 1414968
total_episode_count: 12198
total_duration: 45601.417513370514
[2025-02-21 06:19:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6664526162634
avg_train_sample_per_sec: 31.6664526162634
avg_episode_per_sec: 0.2729866604850293
collect_time: 21.979095935821533
reward_mean: -98.96440242763772
reward_std: 2.3879998618762337
reward_max: -94.84033613445376
reward_min: -101.6841736694678
queue_len: 0.06562626155678894
wait_time: 0.6193311210425815
delay_time: 4.265091529680553
pressure: 0.8021662245800177
total_envstep_count: 1415664
total_train_sample_count: 1415664
total_episode_count: 12204
total_duration: 45623.396609306335
[2025-02-21 06:20:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.919408019850323
avg_train_sample_per_sec: 31.919408019850323
avg_episode_per_sec: 0.27516731051595106
collect_time: 21.8049156665802
reward_mean: -98.51680672268908
reward_std: 1.7090003398927731
reward_max: -95.34733893557424
reward_min: -101.01750700280115
queue_len: 0.06532944742883892
wait_time: 0.6173808161637776
delay_time: 4.268607026597948
pressure: 0.8023872679045092
total_envstep_count: 1416360
total_train_sample_count: 1416360
total_episode_count: 12210
total_duration: 45645.201524972916
[2025-02-21 06:20:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06437189086366
avg_train_sample_per_sec: 32.06437189086366
avg_episode_per_sec: 0.2764169990591695
collect_time: 21.706335067749023
reward_mean: -96.73727824463118
reward_std: 1.9344478299280612
reward_max: -94.62605042016807
reward_min: -100.78011204481788
queue_len: 0.06414938875638672
wait_time: 0.607691595647985
delay_time: 4.224125147791891
pressure: 0.7753094606542882
total_envstep_count: 1417056
total_train_sample_count: 1417056
total_episode_count: 12216
total_duration: 45666.907860040665
[2025-02-21 06:20:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968219999296736
avg_train_sample_per_sec: 31.968219999296736
avg_episode_per_sec: 0.27558810344221324
collect_time: 21.77162194252014
reward_mean: -96.4313725490196
reward_std: 1.6447594740502012
reward_max: -93.99089635854344
reward_min: -98.90966386554621
queue_len: 0.06394653352057003
wait_time: 0.6050333484410564
delay_time: 4.2075864682159425
pressure: 0.7812776304155614
total_envstep_count: 1417752
total_train_sample_count: 1417752
total_episode_count: 12222
total_duration: 45688.679481983185
[2025-02-21 06:21:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.637792013358286
avg_train_sample_per_sec: 31.637792013358286
avg_episode_per_sec: 0.2727395863220542
collect_time: 21.999006748199463
reward_mean: -95.42261904761904
reward_std: 1.3757614723131222
reward_max: -92.66386554621847
reward_min: -96.67927170868347
queue_len: 0.06327759883794366
wait_time: 0.597788529647049
delay_time: 4.163626782376517
pressure: 0.7770778072502211
total_envstep_count: 1418448
total_train_sample_count: 1418448
total_episode_count: 12228
total_duration: 45710.678488731384
[2025-02-21 06:21:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.30336392964171
avg_train_sample_per_sec: 32.30336392964171
avg_episode_per_sec: 0.278477275255532
collect_time: 21.545743703842163
reward_mean: -98.34418767507002
reward_std: 3.1990242840896324
reward_max: -93.04131652661064
reward_min: -103.54481792717087
queue_len: 0.06521497856437006
wait_time: 0.618995531457499
delay_time: 4.236148560478763
pressure: 0.7979664014146773
total_envstep_count: 1419144
total_train_sample_count: 1419144
total_episode_count: 12234
total_duration: 45732.22423243523
[2025-02-21 06:21:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87694931223907
avg_train_sample_per_sec: 31.87694931223907
avg_episode_per_sec: 0.2748012871744747
collect_time: 21.833958864212036
reward_mean: -97.45669934640523
reward_std: 2.5182141122794537
reward_max: -94.89355742296918
reward_min: -101.76050420168065
queue_len: 0.06462645845252336
wait_time: 0.6076437648445762
delay_time: 4.257959574557481
pressure: 0.7839301503094607
total_envstep_count: 1419840
total_train_sample_count: 1419840
total_episode_count: 12240
total_duration: 45754.05819129944
[2025-02-21 06:22:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.20346730435344
avg_train_sample_per_sec: 32.20346730435344
avg_episode_per_sec: 0.27761609745132276
collect_time: 21.612579584121704
reward_mean: -96.47782446311858
reward_std: 0.6192432106408119
reward_max: -95.56372549019606
reward_min: -97.17927170868347
queue_len: 0.06397733717713433
wait_time: 0.6039213209598605
delay_time: 4.167971951292225
pressure: 0.7810565870910698
total_envstep_count: 1420536
total_train_sample_count: 1420536
total_episode_count: 12246
total_duration: 45775.67077088356
[2025-02-21 06:22:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.699471821264588
avg_train_sample_per_sec: 31.699471821264588
avg_episode_per_sec: 0.2732713088040051
collect_time: 21.956201791763306
reward_mean: -95.54726890756302
reward_std: 1.523261191536374
reward_max: -93.26470588235294
reward_min: -97.76680672268903
queue_len: 0.06336025789626194
wait_time: 0.5937578170083241
delay_time: 4.177367483294877
pressure: 0.7753094606542884
total_envstep_count: 1421232
total_train_sample_count: 1421232
total_episode_count: 12252
total_duration: 45797.62697267532
[2025-02-21 06:23:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.984063032641227
avg_train_sample_per_sec: 31.984063032641227
avg_episode_per_sec: 0.27572468131587263
collect_time: 21.76083755493164
reward_mean: -94.97093837535014
reward_std: 2.810474570105786
reward_max: -90.29551820728288
reward_min: -98.65546218487397
queue_len: 0.0629780758457229
wait_time: 0.5953839869281046
delay_time: 4.137242698453476
pressure: 0.7664677276746241
total_envstep_count: 1421928
total_train_sample_count: 1421928
total_episode_count: 12258
total_duration: 45819.387810230255
[2025-02-21 06:23:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10327927503339
avg_train_sample_per_sec: 32.10327927503339
avg_episode_per_sec: 0.27675240754339125
collect_time: 21.680028200149536
reward_mean: -97.28513071895425
reward_std: 2.527040564940133
reward_max: -91.906162464986
reward_min: -99.63025210084035
queue_len: 0.06451268615315268
wait_time: 0.6129561572639665
delay_time: 4.243882323746358
pressure: 0.7865826702033599
total_envstep_count: 1422624
total_train_sample_count: 1422624
total_episode_count: 12264
total_duration: 45841.067838430405
[2025-02-21 06:23:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.057154336734776
avg_train_sample_per_sec: 32.057154336734776
avg_episode_per_sec: 0.27635477876495496
collect_time: 21.711222171783447
reward_mean: -95.5263772175537
reward_std: 0.677940312864357
reward_max: -94.59313725490199
reward_min: -96.63935574229691
queue_len: 0.06334640399042023
wait_time: 0.5948674452097374
delay_time: 4.173845888155821
pressure: 0.7799513704686118
total_envstep_count: 1423320
total_train_sample_count: 1423320
total_episode_count: 12270
total_duration: 45862.77906060219
[2025-02-21 06:24:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.117403742672714
avg_train_sample_per_sec: 32.117403742672714
avg_episode_per_sec: 0.27687417019545446
collect_time: 21.670493841171265
reward_mean: -96.47420634920634
reward_std: 2.969151130811908
reward_max: -92.60854341736692
reward_min: -101.0035014005602
queue_len: 0.06397493789735169
wait_time: 0.5991146348017545
delay_time: 4.145835261252984
pressure: 0.7907824933687003
total_envstep_count: 1424016
total_train_sample_count: 1424016
total_episode_count: 12276
total_duration: 45884.44955444336
[2025-02-21 06:24:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.689551091695094
avg_train_sample_per_sec: 31.689551091695094
avg_episode_per_sec: 0.27318578527323356
collect_time: 21.963075399398804
reward_mean: -98.64880952380953
reward_std: 3.8556421110040584
reward_max: -93.82422969187675
reward_min: -104.21358543417372
queue_len: 0.06541698244284452
wait_time: 0.6192250883554129
delay_time: 4.250070120634373
pressure: 0.8042661361626879
total_envstep_count: 1424712
total_train_sample_count: 1424712
total_episode_count: 12282
total_duration: 45906.41262984276
[2025-02-21 06:24:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89122715830442
avg_train_sample_per_sec: 31.89122715830442
avg_episode_per_sec: 0.27492437205434844
collect_time: 21.824183702468872
reward_mean: -97.65161064425769
reward_std: 1.6233873937364094
reward_max: -95.81652661064425
reward_min: -100.3172268907563
queue_len: 0.06475570997629822
wait_time: 0.6122688797004214
delay_time: 4.205862072806627
pressure: 0.7959770114942528
total_envstep_count: 1425408
total_train_sample_count: 1425408
total_episode_count: 12288
total_duration: 45928.23681354523
[2025-02-21 06:25:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.745394426552355
avg_train_sample_per_sec: 31.745394426552355
avg_episode_per_sec: 0.2736671933323479
collect_time: 21.924440145492554
reward_mean: -98.30427170868346
reward_std: 4.3653109460007355
reward_max: -94.19257703081232
reward_min: -106.39915966386553
queue_len: 0.0651885090906389
wait_time: 0.6157272480168018
delay_time: 4.246995039792615
pressure: 0.8048187444739169
total_envstep_count: 1426104
total_train_sample_count: 1426104
total_episode_count: 12294
total_duration: 45950.16125369072
[2025-02-21 06:25:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99570987391003
avg_train_sample_per_sec: 31.99570987391003
avg_episode_per_sec: 0.27582508511991405
collect_time: 21.75291633605957
reward_mean: -97.86998132586369
reward_std: 2.661645369613331
reward_max: -93.54481792717085
reward_min: -101.50630252100837
queue_len: 0.06490051812059924
wait_time: 0.6109162276758625
delay_time: 4.290847949680025
pressure: 0.7844827586206896
total_envstep_count: 1426800
total_train_sample_count: 1426800
total_episode_count: 12300
total_duration: 45971.91417002678
[2025-02-21 06:26:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.089004968162065
avg_train_sample_per_sec: 32.089004968162065
avg_episode_per_sec: 0.2766293531738109
collect_time: 21.689672231674194
reward_mean: -95.8548085901027
reward_std: 2.1443258800778224
reward_max: -91.38165266106441
reward_min: -97.88235294117649
queue_len: 0.06356419667778693
wait_time: 0.5981378183457292
delay_time: 4.187175846097755
pressure: 0.7764146772767462
total_envstep_count: 1427496
total_train_sample_count: 1427496
total_episode_count: 12306
total_duration: 45993.60384225845
[2025-02-21 06:26:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87289603864321
avg_train_sample_per_sec: 31.87289603864321
avg_episode_per_sec: 0.27476634516071735
collect_time: 21.836735486984253
reward_mean: -96.36671335200748
reward_std: 1.596908643173376
reward_max: -94.44677871148463
reward_min: -98.77591036414564
queue_len: 0.06390365606897047
wait_time: 0.6050425585795768
delay_time: 4.252935060922464
pressure: 0.7816091954022989
total_envstep_count: 1428192
total_train_sample_count: 1428192
total_episode_count: 12312
total_duration: 46015.44057774544
[2025-02-21 06:26:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.815499554744285
avg_train_sample_per_sec: 31.815499554744285
avg_episode_per_sec: 0.2742715478857266
collect_time: 21.876129865646362
reward_mean: -97.65266106442574
reward_std: 5.468324197095649
reward_max: -94.0287114845938
reward_min: -109.62955182072825
queue_len: 0.06475640654139639
wait_time: 0.6164646782674166
delay_time: 4.220218559141655
pressure: 0.7979664014146772
total_envstep_count: 1428888
total_train_sample_count: 1428888
total_episode_count: 12318
total_duration: 46037.316707611084
[2025-02-21 06:27:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.511521923621544
avg_train_sample_per_sec: 31.511521923621544
avg_episode_per_sec: 0.271651051065703
collect_time: 22.087159156799316
reward_mean: -97.06909430438843
reward_std: 1.9913767288193829
reward_max: -94.33683473389355
reward_min: -100.73109243697478
queue_len: 0.06436942593129204
wait_time: 0.6109526038532124
delay_time: 4.190832646924741
pressure: 0.7889036251105216
total_envstep_count: 1429584
total_train_sample_count: 1429584
total_episode_count: 12324
total_duration: 46059.40386676788
[2025-02-21 06:27:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.821132013161964
avg_train_sample_per_sec: 31.821132013161964
avg_episode_per_sec: 0.2743201035617411
collect_time: 21.872257709503174
reward_mean: -94.5235760971055
reward_std: 1.5033968423459283
reward_max: -91.92226890756301
reward_min: -96.32563025210086
queue_len: 0.06268141651001691
wait_time: 0.5932959169521036
delay_time: 4.145929005319792
pressure: 0.7702254641909815
total_envstep_count: 1430280
total_train_sample_count: 1430280
total_episode_count: 12330
total_duration: 46081.27612447739
[2025-02-21 06:27:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94793067331019
avg_train_sample_per_sec: 31.94793067331019
avg_episode_per_sec: 0.2754131954595706
collect_time: 21.78544855117798
reward_mean: -97.87406629318393
reward_std: 1.183621752192686
reward_max: -96.92296918767504
reward_min: -100.39495798319325
queue_len: 0.06490322698486999
wait_time: 0.6178947264139961
delay_time: 4.250105578933822
pressure: 0.7990716180371353
total_envstep_count: 1430976
total_train_sample_count: 1430976
total_episode_count: 12336
total_duration: 46103.061573028564
[2025-02-21 06:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02491365736764
avg_train_sample_per_sec: 32.02491365736764
avg_episode_per_sec: 0.27607684187385895
collect_time: 21.73307967185974
reward_mean: -95.68534080298787
reward_std: 1.315841527819019
reward_max: -93.86064425770304
reward_min: -98.015406162465
queue_len: 0.06345181750861265
wait_time: 0.6000645948034387
delay_time: 4.177573383984263
pressure: 0.7775198938992043
total_envstep_count: 1431672
total_train_sample_count: 1431672
total_episode_count: 12342
total_duration: 46124.794652700424
[2025-02-21 06:28:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.89695930469847
avg_train_sample_per_sec: 31.89695930469847
avg_episode_per_sec: 0.27497378710946957
collect_time: 21.82026171684265
reward_mean: -95.97969187675069
reward_std: 2.5450693591178175
reward_max: -93.38655462184873
reward_min: -100.99929971988796
queue_len: 0.06364701052834927
wait_time: 0.600258936465833
delay_time: 4.261002673258738
pressure: 0.776635720601238
total_envstep_count: 1432368
total_train_sample_count: 1432368
total_episode_count: 12348
total_duration: 46146.61491441727
[2025-02-21 06:29:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23187410616627
avg_train_sample_per_sec: 32.23187410616627
avg_episode_per_sec: 0.27786098367384715
collect_time: 21.593531847000122
reward_mean: -96.19736227824461
reward_std: 3.213020852514647
reward_max: -92.32212885154061
reward_min: -100.50070028011197
queue_len: 0.06379135429591817
wait_time: 0.5975583535801587
delay_time: 4.251886944537344
pressure: 0.7742042440318303
total_envstep_count: 1433064
total_train_sample_count: 1433064
total_episode_count: 12354
total_duration: 46168.20844626427
[2025-02-21 06:29:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.875508236062
avg_train_sample_per_sec: 30.875508236062
avg_episode_per_sec: 0.26616817444881036
collect_time: 22.542139053344727
reward_mean: -94.4144491129785
reward_std: 2.4027017289275348
reward_max: -91.07072829131651
reward_min: -97.51680672268907
queue_len: 0.0626090511359274
wait_time: 0.589800166308787
delay_time: 4.106422737496135
pressure: 0.7672413793103449
total_envstep_count: 1433760
total_train_sample_count: 1433760
total_episode_count: 12360
total_duration: 46190.75058531761
[2025-02-21 06:29:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.599121578508857
avg_train_sample_per_sec: 31.599121578508857
avg_episode_per_sec: 0.27240622050438673
collect_time: 22.025928735733032
reward_mean: -97.48260971055089
reward_std: 2.615129373819103
reward_max: -93.94327731092434
reward_min: -100.96708683473396
queue_len: 0.06464364039161201
wait_time: 0.6075012785839358
delay_time: 4.185977937574736
pressure: 0.7963085764809903
total_envstep_count: 1434456
total_train_sample_count: 1434456
total_episode_count: 12366
total_duration: 46212.776514053345
[2025-02-21 06:30:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88643290325185
avg_train_sample_per_sec: 31.88643290325185
avg_episode_per_sec: 0.2748830422694125
collect_time: 21.827465057373047
reward_mean: -95.94922969187674
reward_std: 1.7180591429474292
reward_max: -94.58333333333327
reward_min: -99.27871148459384
queue_len: 0.06362681014050182
wait_time: 0.5981363478194107
delay_time: 4.165082776101757
pressure: 0.7766357206012379
total_envstep_count: 1435152
total_train_sample_count: 1435152
total_episode_count: 12372
total_duration: 46234.60397911072
[2025-02-21 06:30:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.117067351866424
avg_train_sample_per_sec: 32.117067351866424
avg_episode_per_sec: 0.2768712702747106
collect_time: 21.67072081565857
reward_mean: -97.0344304388422
reward_std: 3.816560798223309
reward_max: -91.56652661064426
reward_min: -103.91246498599439
queue_len: 0.06434643928305185
wait_time: 0.612713133440821
delay_time: 4.185491514617752
pressure: 0.7854774535809018
total_envstep_count: 1435848
total_train_sample_count: 1435848
total_episode_count: 12378
total_duration: 46256.274699926376
[2025-02-21 06:30:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26544098390976
avg_train_sample_per_sec: 32.26544098390976
avg_episode_per_sec: 0.27815035330956694
collect_time: 21.571067333221436
reward_mean: -97.50898692810456
reward_std: 2.915252212296584
reward_max: -92.09243697478988
reward_min: -101.91246498599445
queue_len: 0.0646611319151887
wait_time: 0.6110731096151988
delay_time: 4.161282304628499
pressure: 0.7959770114942528
total_envstep_count: 1436544
total_train_sample_count: 1436544
total_episode_count: 12384
total_duration: 46277.8457672596
[2025-02-21 06:31:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.923614868327682
avg_train_sample_per_sec: 31.923614868327682
avg_episode_per_sec: 0.2752035764511007
collect_time: 21.802042245864868
reward_mean: -97.56255835667599
reward_std: 2.4803094697971564
reward_max: -94.0133053221288
reward_min: -101.95868347338934
queue_len: 0.0646966567351963
wait_time: 0.6142200359365674
delay_time: 4.177011665063825
pressure: 0.7991821396993811
total_envstep_count: 1437240
total_train_sample_count: 1437240
total_episode_count: 12390
total_duration: 46299.64780950546
[2025-02-21 06:31:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84269360074267
avg_train_sample_per_sec: 31.84269360074267
avg_episode_per_sec: 0.27450597931674714
collect_time: 21.857447385787964
reward_mean: -97.44269374416432
reward_std: 1.6126567835317014
reward_max: -94.44187675070026
reward_min: -99.54481792717084
queue_len: 0.06461717091788084
wait_time: 0.60942286950147
delay_time: 4.2557664341235375
pressure: 0.7895667550839965
total_envstep_count: 1437936
total_train_sample_count: 1437936
total_episode_count: 12396
total_duration: 46321.50525689125
[2025-02-21 06:32:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97141900377607
avg_train_sample_per_sec: 31.97141900377607
avg_episode_per_sec: 0.2756156810670351
collect_time: 21.76944351196289
reward_mean: -100.7906162464986
reward_std: 4.666915464037922
reward_max: -94.2703081232493
reward_min: -107.71498599439781
queue_len: 0.06683727867804948
wait_time: 0.633667514308995
delay_time: 4.305828074338375
pressure: 0.8146551724137931
total_envstep_count: 1438632
total_train_sample_count: 1438632
total_episode_count: 12402
total_duration: 46343.27470040321
[2025-02-21 06:32:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.902539062320706
avg_train_sample_per_sec: 31.902539062320706
avg_episode_per_sec: 0.27502188846828196
collect_time: 21.816445350646973
reward_mean: -95.28758169934639
reward_std: 1.5697766391776875
reward_max: -92.91596638655459
reward_min: -97.50350140056025
queue_len: 0.06318805152476552
wait_time: 0.5951863946285854
delay_time: 4.1836537814143195
pressure: 0.7684571175950486
total_envstep_count: 1439328
total_train_sample_count: 1439328
total_episode_count: 12408
total_duration: 46365.09114575386
[2025-02-21 06:32:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03874067816754
avg_train_sample_per_sec: 32.03874067816754
avg_episode_per_sec: 0.2761960403290305
collect_time: 21.723700284957886
reward_mean: -95.56792717086834
reward_std: 2.2142259541760474
reward_max: -92.08543417366947
reward_min: -99.00770308123253
queue_len: 0.06337395700985964
wait_time: 0.5969623260444761
delay_time: 4.189838790038023
pressure: 0.7739832007073386
total_envstep_count: 1440024
total_train_sample_count: 1440024
total_episode_count: 12414
total_duration: 46386.81484603882
[2025-02-21 06:33:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.248139916336584
avg_train_sample_per_sec: 32.248139916336584
avg_episode_per_sec: 0.2780012061753154
collect_time: 21.582640171051025
reward_mean: -97.60842670401492
reward_std: 1.7505779330109354
reward_max: -93.94047619047618
reward_min: -99.4782913165266
queue_len: 0.06472707341115048
wait_time: 0.6103537900571369
delay_time: 4.238306672453145
pressure: 0.7922192749778957
total_envstep_count: 1440720
total_train_sample_count: 1440720
total_episode_count: 12420
total_duration: 46408.39748620987
[2025-02-21 06:33:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.32422977543482
avg_train_sample_per_sec: 32.32422977543482
avg_episode_per_sec: 0.2786571532365071
collect_time: 21.531835556030273
reward_mean: -95.35247432306255
reward_std: 2.4719687150091407
reward_max: -92.17226890756302
reward_min: -98.34103641456583
queue_len: 0.06323108376860913
wait_time: 0.5981516722515708
delay_time: 4.163063655454191
pressure: 0.7754199823165341
total_envstep_count: 1441416
total_train_sample_count: 1441416
total_episode_count: 12426
total_duration: 46429.9293217659
[2025-02-21 06:33:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11579676277551
avg_train_sample_per_sec: 32.11579676277551
avg_episode_per_sec: 0.2768603169204785
collect_time: 21.67157816886902
reward_mean: -96.37219887955182
reward_std: 2.804623007130207
reward_max: -91.5658263305322
reward_min: -100.75980392156862
queue_len: 0.06390729368670546
wait_time: 0.6081551984188901
delay_time: 4.185806777557095
pressure: 0.7863616268788683
total_envstep_count: 1442112
total_train_sample_count: 1442112
total_episode_count: 12432
total_duration: 46451.60089993477
[2025-02-21 06:34:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.930672520872786
avg_train_sample_per_sec: 31.930672520872786
avg_episode_per_sec: 0.2752644182833861
collect_time: 21.797223329544067
reward_mean: -96.17985527544351
reward_std: 2.8113640724408073
reward_max: -93.34593837535012
reward_min: -101.57352941176471
queue_len: 0.06377974487761505
wait_time: 0.6024185204585812
delay_time: 4.180953913466481
pressure: 0.7798408488063661
total_envstep_count: 1442808
total_train_sample_count: 1442808
total_episode_count: 12438
total_duration: 46473.39812326431
[2025-02-21 06:34:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.712848997457844
avg_train_sample_per_sec: 31.712848997457844
avg_episode_per_sec: 0.27338662928842966
collect_time: 21.946940183639526
reward_mean: -93.84383753501398
reward_std: 2.3888358461072996
reward_max: -90.74719887955177
reward_min: -98.1225490196078
queue_len: 0.06223066149536737
wait_time: 0.5913662768378792
delay_time: 4.111775420803607
pressure: 0.7635941644562334
total_envstep_count: 1443504
total_train_sample_count: 1443504
total_episode_count: 12444
total_duration: 46495.34506344795
[2025-02-21 06:34:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19923574735167
avg_train_sample_per_sec: 32.19923574735167
avg_episode_per_sec: 0.27757961851165236
collect_time: 21.61541986465454
reward_mean: -96.14717553688142
reward_std: 3.1048545016071913
reward_max: -90.87464985994397
reward_min: -100.09873949579834
queue_len: 0.06375807396344922
wait_time: 0.6042069126501174
delay_time: 4.198775194631847
pressure: 0.7863616268788682
total_envstep_count: 1444200
total_train_sample_count: 1444200
total_episode_count: 12450
total_duration: 46516.96048331261
[2025-02-21 06:35:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22397838114433
avg_train_sample_per_sec: 32.22397838114433
avg_episode_per_sec: 0.2777929170788304
collect_time: 21.598822832107544
reward_mean: -96.83181605975722
reward_std: 2.136285005664816
reward_max: -94.18977591036416
reward_min: -99.98039215686272
queue_len: 0.06421207961522361
wait_time: 0.6085343620206703
delay_time: 4.201455338883668
pressure: 0.7862511052166224
total_envstep_count: 1444896
total_train_sample_count: 1444896
total_episode_count: 12456
total_duration: 46538.559306144714
[2025-02-21 06:35:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.952796251524724
avg_train_sample_per_sec: 31.952796251524724
avg_episode_per_sec: 0.27545514009935107
collect_time: 21.78213119506836
reward_mean: -96.33648459383754
reward_std: 3.9896175444470385
reward_max: -93.98249299719889
reward_min: -105.1239495798319
queue_len: 0.06388361047336706
wait_time: 0.6122518525535766
delay_time: 4.260283396822524
pressure: 0.7814986737400531
total_envstep_count: 1445592
total_train_sample_count: 1445592
total_episode_count: 12462
total_duration: 46560.34143733978
[2025-02-21 06:36:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.983466616239344
avg_train_sample_per_sec: 31.983466616239344
avg_episode_per_sec: 0.2757195397951668
collect_time: 21.76124334335327
reward_mean: -95.03839869281045
reward_std: 1.473717349026112
reward_max: -92.82002801120447
reward_min: -97.14145658263303
queue_len: 0.06302281080425096
wait_time: 0.5952667318032431
delay_time: 4.231940303371641
pressure: 0.7646993810786914
total_envstep_count: 1446288
total_train_sample_count: 1446288
total_episode_count: 12468
total_duration: 46582.102680683136
[2025-02-21 06:36:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11546075894316
avg_train_sample_per_sec: 32.11546075894316
avg_episode_per_sec: 0.27685742033571686
collect_time: 21.671804904937744
reward_mean: -94.29925303454718
reward_std: 2.56631472390727
reward_max: -90.34943977591037
reward_min: -97.50910364145663
queue_len: 0.06253266116349282
wait_time: 0.5946286781733029
delay_time: 4.153304696979168
pressure: 0.7606100795755969
total_envstep_count: 1446984
total_train_sample_count: 1446984
total_episode_count: 12474
total_duration: 46603.774485588074
[2025-02-21 06:36:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.865798854552455
avg_train_sample_per_sec: 31.865798854552455
avg_episode_per_sec: 0.2747051625392453
collect_time: 21.841598987579346
reward_mean: -98.91188141923436
reward_std: 3.9913241429229593
reward_max: -94.98529411764702
reward_min: -106.5581232492997
queue_len: 0.06559143330187955
wait_time: 0.621206196890781
delay_time: 4.316002754325459
pressure: 0.7992926613616268
total_envstep_count: 1447680
total_train_sample_count: 1447680
total_episode_count: 12480
total_duration: 46625.61608457565
[2025-02-21 06:37:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22316099329266
avg_train_sample_per_sec: 32.22316099329266
avg_episode_per_sec: 0.2777858706318333
collect_time: 21.59937071800232
reward_mean: -95.4125816993464
reward_std: 2.5972498938334465
reward_max: -91.92787114845943
reward_min: -99.30952380952382
queue_len: 0.06327094277144989
wait_time: 0.5991936562423378
delay_time: 4.1508362962795475
pressure: 0.7665782493368701
total_envstep_count: 1448376
total_train_sample_count: 1448376
total_episode_count: 12486
total_duration: 46647.215455293655
[2025-02-21 06:37:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.28298339700386
avg_train_sample_per_sec: 32.28298339700386
avg_episode_per_sec: 0.278301581008654
collect_time: 21.559345722198486
reward_mean: -94.62675070028013
reward_std: 2.0405101843887725
reward_max: -92.26750700280111
reward_min: -98.18907563025209
queue_len: 0.06274983468188337
wait_time: 0.5887564796033357
delay_time: 4.133976902159222
pressure: 0.7674624226348364
total_envstep_count: 1449072
total_train_sample_count: 1449072
total_episode_count: 12492
total_duration: 46668.774801015854
[2025-02-21 06:37:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.881047486706628
avg_train_sample_per_sec: 31.881047486706628
avg_episode_per_sec: 0.2748366162647123
collect_time: 21.831152200698853
reward_mean: -95.33274976657329
reward_std: 2.7592665440975948
reward_max: -92.82773109243699
reward_min: -101.19957983193275
queue_len: 0.06321800382398761
wait_time: 0.597547827707564
delay_time: 4.165158272353239
pressure: 0.7717727674624227
total_envstep_count: 1449768
total_train_sample_count: 1449768
total_episode_count: 12498
total_duration: 46690.60595321655
[2025-02-21 06:38:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01278074294604
avg_train_sample_per_sec: 32.01278074294604
avg_episode_per_sec: 0.2759722477840176
collect_time: 21.741316556930542
reward_mean: -96.41491596638654
reward_std: 1.934658664197098
reward_max: -93.17647058823528
reward_min: -99.79761904761904
queue_len: 0.06393562066736508
wait_time: 0.6082632434052312
delay_time: 4.20630167710828
pressure: 0.7845932802829355
total_envstep_count: 1450464
total_train_sample_count: 1450464
total_episode_count: 12504
total_duration: 46712.34726977348
[2025-02-21 06:38:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.995593798353603
avg_train_sample_per_sec: 31.995593798353603
avg_episode_per_sec: 0.27582408446856554
collect_time: 21.752995252609253
reward_mean: -94.03828197945846
reward_std: 2.394147666613508
reward_max: -91.45518207282917
reward_min: -98.3032212885154
queue_len: 0.06235960343465416
wait_time: 0.5887747450881324
delay_time: 4.190275102880922
pressure: 0.761604774535809
total_envstep_count: 1451160
total_train_sample_count: 1451160
total_episode_count: 12510
total_duration: 46734.10026502609
[2025-02-21 06:39:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.847507023095915
avg_train_sample_per_sec: 31.847507023095915
avg_episode_per_sec: 0.27454747433703375
collect_time: 21.854143857955933
reward_mean: -95.7735760971055
reward_std: 1.7474123030381532
reward_max: -93.24299719887955
reward_min: -97.80322128851543
queue_len: 0.06351032897686043
wait_time: 0.6023546686579141
delay_time: 4.1864471381657715
pressure: 0.7791777188328913
total_envstep_count: 1451856
total_train_sample_count: 1451856
total_episode_count: 12516
total_duration: 46755.95440888405
[2025-02-21 06:39:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03320421925004
avg_train_sample_per_sec: 32.03320421925004
avg_episode_per_sec: 0.2761483122349141
collect_time: 21.727454900741577
reward_mean: -99.0031512605042
reward_std: 4.006946927426192
reward_max: -92.92296918767506
reward_min: -103.85714285714286
queue_len: 0.06565195706929987
wait_time: 0.6218796205484848
delay_time: 4.2403352613833185
pressure: 0.8000663129973474
total_envstep_count: 1452552
total_train_sample_count: 1452552
total_episode_count: 12522
total_duration: 46777.68186378479
[2025-02-21 06:39:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.933166072032826
avg_train_sample_per_sec: 31.933166072032826
avg_episode_per_sec: 0.27528591441407607
collect_time: 21.79552125930786
reward_mean: -96.72420634920634
reward_std: 2.263789472466591
reward_max: -94.15336134453783
reward_min: -101.29341736694678
queue_len: 0.06414072039072038
wait_time: 0.6075696967558021
delay_time: 4.227822732679651
pressure: 0.7796198054818744
total_envstep_count: 1453248
total_train_sample_count: 1453248
total_episode_count: 12528
total_duration: 46799.4773850441
[2025-02-21 06:40:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86407470117725
avg_train_sample_per_sec: 31.86407470117725
avg_episode_per_sec: 0.27469029914807974
collect_time: 21.842780828475952
reward_mean: -98.56921101774043
reward_std: 1.9785413117479516
reward_max: -95.67927170868346
reward_min: -101.42436974789918
queue_len: 0.06536419828762628
wait_time: 0.6195639285776204
delay_time: 4.180973909981512
pressure: 0.8047082228116711
total_envstep_count: 1453944
total_train_sample_count: 1453944
total_episode_count: 12534
total_duration: 46821.320165872574
[2025-02-21 06:40:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.143728370043355
avg_train_sample_per_sec: 32.143728370043355
avg_episode_per_sec: 0.2771011066383048
collect_time: 21.652746438980103
reward_mean: -97.33846872082165
reward_std: 2.872719892509024
reward_max: -94.01820728291318
reward_min: -101.39285714285714
queue_len: 0.0645480561809162
wait_time: 0.6111347943244494
delay_time: 4.280911508186146
pressure: 0.7880194518125553
total_envstep_count: 1454640
total_train_sample_count: 1454640
total_episode_count: 12540
total_duration: 46842.972912311554
[2025-02-21 06:40:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92773901898274
avg_train_sample_per_sec: 31.92773901898274
avg_episode_per_sec: 0.27523912947398915
collect_time: 21.79922604560852
reward_mean: -97.28979925303456
reward_std: 3.6544562415747577
reward_max: -93.49859943977592
reward_min: -102.80182072829129
queue_len: 0.06451578199803351
wait_time: 0.6163365876854722
delay_time: 4.196513866458342
pressure: 0.7911140583554377
total_envstep_count: 1455336
total_train_sample_count: 1455336
total_episode_count: 12546
total_duration: 46864.77213835716
[2025-02-21 06:41:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.818669453026168
avg_train_sample_per_sec: 31.818669453026168
avg_episode_per_sec: 0.2742988745950532
collect_time: 21.873950481414795
reward_mean: -95.28758169934639
reward_std: 2.18088659516239
reward_max: -92.35084033613445
reward_min: -99.4334733893557
queue_len: 0.0631880515247655
wait_time: 0.5945146736855662
delay_time: 4.19938466660052
pressure: 0.7681255526083112
total_envstep_count: 1456032
total_train_sample_count: 1456032
total_episode_count: 12552
total_duration: 46886.64608883858
[2025-02-21 06:41:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87417253808184
avg_train_sample_per_sec: 31.87417253808184
avg_episode_per_sec: 0.27477734946622273
collect_time: 21.83586096763611
reward_mean: -96.94374416433239
reward_std: 2.2227913598680975
reward_max: -93.4908963585434
reward_min: -99.81722689075632
queue_len: 0.06428630249624163
wait_time: 0.604716566113625
delay_time: 4.25176897334783
pressure: 0.7913351016799294
total_envstep_count: 1456728
total_train_sample_count: 1456728
total_episode_count: 12558
total_duration: 46908.48194980621
[2025-02-21 06:42:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12884593154792
avg_train_sample_per_sec: 32.12884593154792
avg_episode_per_sec: 0.2769728097547235
collect_time: 21.662776231765747
reward_mean: -96.45751633986929
reward_std: 3.2295339775076046
reward_max: -92.44607843137256
reward_min: -100.30322128851543
queue_len: 0.0639638702519027
wait_time: 0.6031670957507672
delay_time: 4.199931919777672
pressure: 0.7824933687002652
total_envstep_count: 1457424
total_train_sample_count: 1457424
total_episode_count: 12564
total_duration: 46930.14472603798
[2025-02-21 06:42:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75469591915252
avg_train_sample_per_sec: 31.75469591915252
avg_episode_per_sec: 0.2737473786133838
collect_time: 21.918018102645874
reward_mean: -97.30322128851539
reward_std: 2.5770684901642156
reward_max: -93.79971988795515
reward_min: -101.74229691876745
queue_len: 0.0645246825520659
wait_time: 0.6115811377601439
delay_time: 4.272560310809229
pressure: 0.7856984969053934
total_envstep_count: 1458120
total_train_sample_count: 1458120
total_episode_count: 12570
total_duration: 46952.062744140625
[2025-02-21 06:42:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.015716902039415
avg_train_sample_per_sec: 32.015716902039415
avg_episode_per_sec: 0.27599755950033983
collect_time: 21.739322662353516
reward_mean: -97.07026143790848
reward_std: 3.6426442316175827
reward_max: -91.71638655462186
reward_min: -102.20238095238093
queue_len: 0.06437019989251226
wait_time: 0.6048196577481568
delay_time: 4.230315392608659
pressure: 0.7842617152961981
total_envstep_count: 1458816
total_train_sample_count: 1458816
total_episode_count: 12576
total_duration: 46973.80206680298
[2025-02-21 06:43:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.164261390493706
avg_train_sample_per_sec: 31.164261390493706
avg_episode_per_sec: 0.26865742578011814
collect_time: 22.333274364471436
reward_mean: -95.0434173669468
reward_std: 2.9243964386899837
reward_max: -92.55952380952385
reward_min: -101.43557422969188
queue_len: 0.06302613883749787
wait_time: 0.5936549575621582
delay_time: 4.204453026905736
pressure: 0.7591732979664014
total_envstep_count: 1459512
total_train_sample_count: 1459512
total_episode_count: 12582
total_duration: 46996.13534116745
[2025-02-21 06:43:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.603594083370915
avg_train_sample_per_sec: 31.603594083370915
avg_episode_per_sec: 0.27244477658078375
collect_time: 22.02281165122986
reward_mean: -95.80882352941178
reward_std: 2.7735900551307657
reward_max: -92.05322128851539
reward_min: -99.47899159663868
queue_len: 0.06353370260571074
wait_time: 0.5982872702573515
delay_time: 4.168391802581104
pressure: 0.7760831122900088
total_envstep_count: 1460208
total_train_sample_count: 1460208
total_episode_count: 12588
total_duration: 47018.15815281868
[2025-02-21 06:43:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09399653228111
avg_train_sample_per_sec: 32.09399653228111
avg_episode_per_sec: 0.2766723838989751
collect_time: 21.686298847198486
reward_mean: -95.85212418300652
reward_std: 2.56106170983992
reward_max: -93.31652661064429
reward_min: -101.03221288515404
queue_len: 0.06356241656698046
wait_time: 0.6012488328664799
delay_time: 4.23822320671653
pressure: 0.7703359858532273
total_envstep_count: 1460904
total_train_sample_count: 1460904
total_episode_count: 12594
total_duration: 47039.84445166588
[2025-02-21 06:44:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8991934832202
avg_train_sample_per_sec: 31.8991934832202
avg_episode_per_sec: 0.27499304726913965
collect_time: 21.81873345375061
reward_mean: -95.50431839402428
reward_std: 2.683059269170168
reward_max: -91.20448179271708
reward_min: -97.92997198879549
queue_len: 0.06333177612335826
wait_time: 0.5963566239935408
delay_time: 4.15681837811139
pressure: 0.7802829354553493
total_envstep_count: 1461600
total_train_sample_count: 1461600
total_episode_count: 12600
total_duration: 47061.66318511963
[2025-02-21 06:44:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.952219186574627
avg_train_sample_per_sec: 31.952219186574627
avg_episode_per_sec: 0.2754501654015054
collect_time: 21.782524585723877
reward_mean: -96.88176937441642
reward_std: 2.4473279246815474
reward_max: -93.40406162464987
reward_min: -100.42156862745102
queue_len: 0.06424520515544856
wait_time: 0.608617949832453
delay_time: 4.177895345050963
pressure: 0.7824933687002652
total_envstep_count: 1462296
total_train_sample_count: 1462296
total_episode_count: 12606
total_duration: 47083.44570970535
[2025-02-21 06:45:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.003849887285156
avg_train_sample_per_sec: 32.003849887285156
avg_episode_per_sec: 0.27589525764900996
collect_time: 21.74738359451294
reward_mean: -96.36181139122313
reward_std: 1.5818079777266278
reward_max: -94.53221288515405
reward_min: -98.77170868347336
queue_len: 0.06390040543184558
wait_time: 0.6044480015702125
delay_time: 4.2215707953879
pressure: 0.7851458885941645
total_envstep_count: 1462992
total_train_sample_count: 1462992
total_episode_count: 12612
total_duration: 47105.193093299866
[2025-02-21 06:45:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.40677727220698
avg_train_sample_per_sec: 32.40677727220698
avg_episode_per_sec: 0.27936876958799123
collect_time: 21.476989030838013
reward_mean: -93.5500700280112
reward_std: 1.0349061901736214
reward_max: -91.87605042016808
reward_min: -95.06862745098036
queue_len: 0.06203585545624085
wait_time: 0.5853950112317253
delay_time: 4.0996082036217265
pressure: 0.75552608311229
total_envstep_count: 1463688
total_train_sample_count: 1463688
total_episode_count: 12618
total_duration: 47126.670082330704
[2025-02-21 06:45:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.228071635223394
avg_train_sample_per_sec: 32.228071635223394
avg_episode_per_sec: 0.2778282037519258
collect_time: 21.5960795879364
reward_mean: -93.21568627450979
reward_std: 1.8213722555803602
reward_max: -90.02310924369746
reward_min: -95.70028011204482
queue_len: 0.06181411556665106
wait_time: 0.5840230875727832
delay_time: 4.114168522988462
pressure: 0.757736516357206
total_envstep_count: 1464384
total_train_sample_count: 1464384
total_episode_count: 12624
total_duration: 47148.26616191864
[2025-02-21 06:46:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95538455677879
avg_train_sample_per_sec: 31.95538455677879
avg_episode_per_sec: 0.2754774530756792
collect_time: 21.780366897583008
reward_mean: -98.3216619981326
reward_std: 4.496700587828752
reward_max: -93.29271708683478
reward_min: -106.84943977591034
queue_len: 0.06520004111282003
wait_time: 0.6170944505123005
delay_time: 4.248783349466671
pressure: 0.803050397877984
total_envstep_count: 1465080
total_train_sample_count: 1465080
total_episode_count: 12630
total_duration: 47170.04652881622
[2025-02-21 06:46:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91369710940664
avg_train_sample_per_sec: 31.91369710940664
avg_episode_per_sec: 0.2751180785293676
collect_time: 21.808817625045776
reward_mean: -96.72549019607841
reward_std: 3.876929982685447
reward_max: -93.62535014005603
reward_min: -104.61764705882352
queue_len: 0.0641415717480626
wait_time: 0.6071689396359782
delay_time: 4.166187660034758
pressure: 0.7835985853227232
total_envstep_count: 1465776
total_train_sample_count: 1465776
total_episode_count: 12636
total_duration: 47191.85534644127
[2025-02-21 06:46:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.816162195405266
avg_train_sample_per_sec: 31.816162195405266
avg_episode_per_sec: 0.2742772603052178
collect_time: 21.8756742477417
reward_mean: -98.13748832866482
reward_std: 3.8942166436630097
reward_max: -93.3235294117647
reward_min: -105.81372549019606
queue_len: 0.06507791003227109
wait_time: 0.6160870625880768
delay_time: 4.228386680683621
pressure: 0.7997347480106102
total_envstep_count: 1466472
total_train_sample_count: 1466472
total_episode_count: 12642
total_duration: 47213.73102068901
[2025-02-21 06:47:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13893468326663
avg_train_sample_per_sec: 32.13893468326663
avg_episode_per_sec: 0.27705978175229856
collect_time: 21.655976057052612
reward_mean: -98.00560224089638
reward_std: 3.6178383678697896
reward_max: -93.41456582633053
reward_min: -103.36134453781511
queue_len: 0.0649904524143875
wait_time: 0.608403872158943
delay_time: 4.1950418129748295
pressure: 0.8039345711759505
total_envstep_count: 1467168
total_train_sample_count: 1467168
total_episode_count: 12648
total_duration: 47235.38699674606
[2025-02-21 06:47:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.839961686059862
avg_train_sample_per_sec: 31.839961686059862
avg_episode_per_sec: 0.27448242832810227
collect_time: 21.859322786331177
reward_mean: -97.60807656395889
reward_std: 3.094917900328536
reward_max: -94.56862745098037
reward_min: -102.5364145658263
queue_len: 0.06472684122278442
wait_time: 0.6122343610299998
delay_time: 4.204497299868232
pressure: 0.7967506631299734
total_envstep_count: 1467864
total_train_sample_count: 1467864
total_episode_count: 12654
total_duration: 47257.246319532394
[2025-02-21 06:47:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13014442968847
avg_train_sample_per_sec: 32.13014442968847
avg_episode_per_sec: 0.27698400370421095
collect_time: 21.661900758743286
reward_mean: -96.9800420168067
reward_std: 2.8785533894223394
reward_max: -93.12535014005603
reward_min: -101.49229691876751
queue_len: 0.06431037269019012
wait_time: 0.6031573438393926
delay_time: 4.200574827481232
pressure: 0.7861405835543765
total_envstep_count: 1468560
total_train_sample_count: 1468560
total_episode_count: 12660
total_duration: 47278.90822029114
[2025-02-21 06:48:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14302405508044
avg_train_sample_per_sec: 32.14302405508044
avg_episode_per_sec: 0.27709503495758997
collect_time: 21.653220891952515
reward_mean: -94.59558823529413
reward_std: 1.6852424707367002
reward_max: -91.79201680672267
reward_min: -96.64215686274511
queue_len: 0.0627291699173038
wait_time: 0.5936637807200688
delay_time: 4.088351327057775
pressure: 0.774867374005305
total_envstep_count: 1469256
total_train_sample_count: 1469256
total_episode_count: 12666
total_duration: 47300.56144118309
[2025-02-21 06:48:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.869921648787635
avg_train_sample_per_sec: 31.869921648787635
avg_episode_per_sec: 0.2747407038688589
collect_time: 21.838773488998413
reward_mean: -98.62021475256769
reward_std: 2.2001300610552827
reward_max: -95.75070028011201
reward_min: -102.06022408963585
queue_len: 0.0653980203929494
wait_time: 0.6233355963959412
delay_time: 4.223879868896782
pressure: 0.7966401414677277
total_envstep_count: 1469952
total_train_sample_count: 1469952
total_episode_count: 12672
total_duration: 47322.40021467209
[2025-02-21 06:49:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99572775873832
avg_train_sample_per_sec: 31.99572775873832
avg_episode_per_sec: 0.2758252392994683
collect_time: 21.752904176712036
reward_mean: -96.2623716153128
reward_std: 2.7451275647560505
reward_max: -93.11064425770313
reward_min: -100.28501400560219
queue_len: 0.06383446393588381
wait_time: 0.600804114749348
delay_time: 4.114072751124431
pressure: 0.7835985853227232
total_envstep_count: 1470648
total_train_sample_count: 1470648
total_episode_count: 12678
total_duration: 47344.1531188488
[2025-02-21 06:49:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95782914137524
avg_train_sample_per_sec: 31.95782914137524
avg_episode_per_sec: 0.275498527080821
collect_time: 21.778700828552246
reward_mean: -93.91783380018673
reward_std: 3.5578103230839546
reward_max: -90.74859943977592
reward_min: -101.52801120448183
queue_len: 0.0622797306367286
wait_time: 0.5893830786072165
delay_time: 4.0873269394532095
pressure: 0.7627099911582671
total_envstep_count: 1471344
total_train_sample_count: 1471344
total_episode_count: 12684
total_duration: 47365.93181967735
[2025-02-21 06:49:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.765741091952105
avg_train_sample_per_sec: 31.765741091952105
avg_episode_per_sec: 0.27384259562027674
collect_time: 21.910397052764893
reward_mean: -96.04481792717087
reward_std: 3.0434094714635846
reward_max: -91.98249299719888
reward_min: -101.92997198879553
queue_len: 0.06369019756443692
wait_time: 0.604627947553911
delay_time: 4.154905936029511
pressure: 0.7753094606542882
total_envstep_count: 1472040
total_train_sample_count: 1472040
total_episode_count: 12690
total_duration: 47387.84221673012
[2025-02-21 06:50:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.026964110654184
avg_train_sample_per_sec: 32.026964110654184
avg_episode_per_sec: 0.2760945181952947
collect_time: 21.731688261032104
reward_mean: -96.21837068160598
reward_std: 2.8128947338110755
reward_max: -93.83683473389354
reward_min: -102.04341736694678
queue_len: 0.06380528559788196
wait_time: 0.6055287610181118
delay_time: 4.181672191635198
pressure: 0.7725464190981434
total_envstep_count: 1472736
total_train_sample_count: 1472736
total_episode_count: 12696
total_duration: 47409.57390499115
[2025-02-21 06:50:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.02340936222448
avg_train_sample_per_sec: 32.02340936222448
avg_episode_per_sec: 0.27606387381228
collect_time: 21.734100580215454
reward_mean: -94.99089635854341
reward_std: 2.814348870288622
reward_max: -92.04131652661063
reward_min: -100.46568627450982
queue_len: 0.06299131058258847
wait_time: 0.5907544604933043
delay_time: 4.077408867980424
pressure: 0.7697833775419983
total_envstep_count: 1473432
total_train_sample_count: 1473432
total_episode_count: 12702
total_duration: 47431.308005571365
[2025-02-21 06:50:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.782763929027706
avg_train_sample_per_sec: 31.782763929027706
avg_episode_per_sec: 0.2739893442157561
collect_time: 21.898661851882935
reward_mean: -96.62628384687207
reward_std: 1.8644925507994219
reward_max: -94.07703081232492
reward_min: -99.44257703081227
queue_len: 0.06407578504434487
wait_time: 0.5991961329182426
delay_time: 4.194165508911962
pressure: 0.7900088417329797
total_envstep_count: 1474128
total_train_sample_count: 1474128
total_episode_count: 12708
total_duration: 47453.20666742325
[2025-02-21 06:51:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05395258343561
avg_train_sample_per_sec: 32.05395258343561
avg_episode_per_sec: 0.27632717744341045
collect_time: 21.713390827178955
reward_mean: -95.54119981325863
reward_std: 3.226384488043071
reward_max: -91.86204481792714
reward_min: -100.35084033613445
queue_len: 0.06335623329791686
wait_time: 0.6010280217303543
delay_time: 4.1336503715881365
pressure: 0.77763041556145
total_envstep_count: 1474824
total_train_sample_count: 1474824
total_episode_count: 12714
total_duration: 47474.92005825043
[2025-02-21 06:51:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.937159568902175
avg_train_sample_per_sec: 31.937159568902175
avg_episode_per_sec: 0.27532034111122566
collect_time: 21.79279589653015
reward_mean: -100.60994397759104
reward_std: 3.9788663773867743
reward_max: -94.92436974789915
reward_min: -105.14495798319332
queue_len: 0.06671746948116118
wait_time: 0.6317150423387745
delay_time: 4.304007859619766
pressure: 0.8163129973474801
total_envstep_count: 1475520
total_train_sample_count: 1475520
total_episode_count: 12720
total_duration: 47496.71285414696
[2025-02-21 06:52:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81597876150183
avg_train_sample_per_sec: 31.81597876150183
avg_episode_per_sec: 0.27427567897846405
collect_time: 21.875800371170044
reward_mean: -96.13935574229691
reward_std: 1.8934996265330102
reward_max: -92.63655462184877
reward_min: -98.13305322128855
queue_len: 0.06375288842327383
wait_time: 0.5975037119180122
delay_time: 4.1837433077524855
pressure: 0.7822723253757736
total_envstep_count: 1476216
total_train_sample_count: 1476216
total_episode_count: 12726
total_duration: 47518.58865451813
[2025-02-21 06:52:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03126684036329
avg_train_sample_per_sec: 32.03126684036329
avg_episode_per_sec: 0.27613161069278697
collect_time: 21.728769063949585
reward_mean: -96.2594537815126
reward_std: 1.8339825311457079
reward_max: -93.11344537815123
reward_min: -99.02450980392156
queue_len: 0.06383252903283328
wait_time: 0.603296192482298
delay_time: 4.1753764025640505
pressure: 0.7826038903625111
total_envstep_count: 1476912
total_train_sample_count: 1476912
total_episode_count: 12732
total_duration: 47540.31742358208
[2025-02-21 06:52:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.98782987047454
avg_train_sample_per_sec: 31.98782987047454
avg_episode_per_sec: 0.27575715405581497
collect_time: 21.758275032043457
reward_mean: -96.49719887955185
reward_std: 3.0940860890698625
reward_max: -91.35924369747897
reward_min: -100.03641456582633
queue_len: 0.0639901849333898
wait_time: 0.6083239993610178
delay_time: 4.182300937887306
pressure: 0.7780725022104332
total_envstep_count: 1477608
total_train_sample_count: 1477608
total_episode_count: 12738
total_duration: 47562.07569861412
[2025-02-21 06:53:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17873734717918
avg_train_sample_per_sec: 32.17873734717918
avg_episode_per_sec: 0.27740290816533775
collect_time: 21.629189252853394
reward_mean: -94.29936974789915
reward_std: 1.5203696639704456
reward_max: -91.41316526610642
reward_min: -95.9047619047619
queue_len: 0.06253273855961482
wait_time: 0.5908782168924157
delay_time: 4.160320897604341
pressure: 0.7632625994694959
total_envstep_count: 1478304
total_train_sample_count: 1478304
total_episode_count: 12744
total_duration: 47583.704887866974
[2025-02-21 06:53:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.912052539681195
avg_train_sample_per_sec: 31.912052539681195
avg_episode_per_sec: 0.27510390120414824
collect_time: 21.80994153022766
reward_mean: -97.19514472455649
reward_std: 2.3283374266434502
reward_max: -94.5420168067227
reward_min: -99.93907563025215
queue_len: 0.06445301374307459
wait_time: 0.6071245142619383
delay_time: 4.211706735087812
pressure: 0.7832670203359858
total_envstep_count: 1479000
total_train_sample_count: 1479000
total_episode_count: 12750
total_duration: 47605.5148293972
[2025-02-21 06:53:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.911935326078513
avg_train_sample_per_sec: 31.911935326078513
avg_episode_per_sec: 0.2751028907420562
collect_time: 21.81002163887024
reward_mean: -97.68008870214753
reward_std: 2.92783925287049
reward_max: -93.64915966386555
reward_min: -103.43347338935574
queue_len: 0.06477459463007129
wait_time: 0.6117724609737794
delay_time: 4.21759928637255
pressure: 0.791445623342175
total_envstep_count: 1479696
total_train_sample_count: 1479696
total_episode_count: 12756
total_duration: 47627.32485103607
[2025-02-21 06:54:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09111161466309
avg_train_sample_per_sec: 32.09111161466309
avg_episode_per_sec: 0.27664751391950937
collect_time: 21.6882483959198
reward_mean: -94.72280578898226
reward_std: 2.3808435060742745
reward_max: -90.97759103641455
reward_min: -97.38095238095238
queue_len: 0.06281353169030653
wait_time: 0.5907937003271688
delay_time: 4.145183024924759
pressure: 0.77210433244916
total_envstep_count: 1480392
total_train_sample_count: 1480392
total_episode_count: 12762
total_duration: 47649.01309943199
[2025-02-21 06:54:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.223092701667746
avg_train_sample_per_sec: 32.223092701667746
avg_episode_per_sec: 0.2777852819109288
collect_time: 21.599416494369507
reward_mean: -98.28828197945843
reward_std: 5.403006014613994
reward_max: -92.96708683473385
reward_min: -106.8354341736695
queue_len: 0.06517790582192205
wait_time: 0.6104931030767745
delay_time: 4.267894738640098
pressure: 0.7996242263483642
total_envstep_count: 1481088
total_train_sample_count: 1481088
total_episode_count: 12768
total_duration: 47670.61251592636
[2025-02-21 06:55:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.30865626359505
avg_train_sample_per_sec: 32.30865626359505
avg_episode_per_sec: 0.27852289882409526
collect_time: 21.542214393615723
reward_mean: -94.92892156862746
reward_std: 2.2919902670297208
reward_max: -92.09943977591031
reward_min: -98.82422969187677
queue_len: 0.06295021324179538
wait_time: 0.593230826813484
delay_time: 4.1702066375576035
pressure: 0.7729885057471263
total_envstep_count: 1481784
total_train_sample_count: 1481784
total_episode_count: 12774
total_duration: 47692.15473031998
[2025-02-21 06:55:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.274093128882676
avg_train_sample_per_sec: 32.274093128882676
avg_episode_per_sec: 0.27822494076622994
collect_time: 21.565284490585327
reward_mean: -93.73937908496731
reward_std: 1.8839313579338388
reward_max: -92.04901960784315
reward_min: -97.27450980392157
queue_len: 0.06216139196615871
wait_time: 0.5841255600383389
delay_time: 4.098562798641763
pressure: 0.758289124668435
total_envstep_count: 1482480
total_train_sample_count: 1482480
total_episode_count: 12780
total_duration: 47713.72001481056
[2025-02-21 06:55:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.849331890617208
avg_train_sample_per_sec: 31.849331890617208
avg_episode_per_sec: 0.2745632059535966
collect_time: 21.85289168357849
reward_mean: -97.30847338935575
reward_std: 3.466724529402575
reward_max: -92.52661064425772
reward_min: -103.01680672268907
queue_len: 0.06452816537755686
wait_time: 0.6092591767033958
delay_time: 4.203964742284829
pressure: 0.788240495137047
total_envstep_count: 1483176
total_train_sample_count: 1483176
total_episode_count: 12786
total_duration: 47735.57290649414
[2025-02-21 06:56:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.38006869122893
avg_train_sample_per_sec: 32.38006869122893
avg_episode_per_sec: 0.2791385232002494
collect_time: 21.494704246520996
reward_mean: -96.15056022408963
reward_std: 2.268336099950974
reward_max: -91.59943977591033
reward_min: -98.4551820728291
queue_len: 0.0637603184509878
wait_time: 0.6031179492132839
delay_time: 4.126564848161826
pressure: 0.7807250221043325
total_envstep_count: 1483872
total_train_sample_count: 1483872
total_episode_count: 12792
total_duration: 47757.06761074066
[2025-02-21 06:56:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26256901963789
avg_train_sample_per_sec: 32.26256901963789
avg_episode_per_sec: 0.27812559499687833
collect_time: 21.57298755645752
reward_mean: -98.61542950513537
reward_std: 2.46856905708427
reward_max: -96.8298319327731
reward_min: -103.92296918767506
queue_len: 0.06539484715194653
wait_time: 0.6231126955645211
delay_time: 4.234002217867058
pressure: 0.8022767462422635
total_envstep_count: 1484568
total_train_sample_count: 1484568
total_episode_count: 12798
total_duration: 47778.64059829712
[2025-02-21 06:56:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95988745816223
avg_train_sample_per_sec: 31.95988745816223
avg_episode_per_sec: 0.2755162711910537
collect_time: 21.77729821205139
reward_mean: -94.32528011204482
reward_std: 1.5342152670810738
reward_max: -91.45168067226888
reward_min: -96.53851540616247
queue_len: 0.06254992049870345
wait_time: 0.5944454815524794
delay_time: 4.1380378885412625
pressure: 0.7658045977011493
total_envstep_count: 1485264
total_train_sample_count: 1485264
total_episode_count: 12804
total_duration: 47800.41789650917
[2025-02-21 06:57:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.98896165452542
avg_train_sample_per_sec: 30.98896165452542
avg_episode_per_sec: 0.2671462211597019
collect_time: 22.45961022377014
reward_mean: -96.67320261437908
reward_std: 3.1315567382015637
reward_max: -94.2128851540616
reward_min: -102.80462184873949
queue_len: 0.06410689828539727
wait_time: 0.6064760895516473
delay_time: 4.1500614331566785
pressure: 0.7884615384615384
total_envstep_count: 1485960
total_train_sample_count: 1485960
total_episode_count: 12810
total_duration: 47822.87750673294
[2025-02-21 06:57:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.892886655404073
avg_train_sample_per_sec: 31.892886655404073
avg_episode_per_sec: 0.2749386780638282
collect_time: 21.82304811477661
reward_mean: -96.78174603174602
reward_std: 2.3387829915882907
reward_max: -92.63725490196077
reward_min: -100.22338935574228
queue_len: 0.06417887667887669
wait_time: 0.6077222445123053
delay_time: 4.150444157522061
pressure: 0.7946507515473032
total_envstep_count: 1486656
total_train_sample_count: 1486656
total_episode_count: 12816
total_duration: 47844.70055484772
[2025-02-21 06:58:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09166865936292
avg_train_sample_per_sec: 32.09166865936292
avg_episode_per_sec: 0.27665231602899065
collect_time: 21.6878719329834
reward_mean: -97.54318394024274
reward_std: 1.5464694782576311
reward_max: -95.4901960784314
reward_min: -99.28571428571428
queue_len: 0.06468380897894083
wait_time: 0.6107643764844576
delay_time: 4.145450474231088
pressure: 0.806476569407604
total_envstep_count: 1487352
total_train_sample_count: 1487352
total_episode_count: 12822
total_duration: 47866.3884267807
[2025-02-21 06:58:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.09674433668195
avg_train_sample_per_sec: 32.09674433668195
avg_episode_per_sec: 0.2766960718679478
collect_time: 21.684442281723022
reward_mean: -96.49463118580765
reward_std: 1.8098192574803522
reward_max: -93.01470588235291
reward_min: -99.08333333333334
queue_len: 0.06398848221870534
wait_time: 0.6004066082666489
delay_time: 4.173094526770998
pressure: 0.7849248452696728
total_envstep_count: 1488048
total_train_sample_count: 1488048
total_episode_count: 12828
total_duration: 47888.072869062424
[2025-02-21 06:58:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.090710512121134
avg_train_sample_per_sec: 32.090710512121134
avg_episode_per_sec: 0.27664405613897525
collect_time: 21.68851947784424
reward_mean: -96.52509337068157
reward_std: 3.7791821893963515
reward_max: -91.90896358543412
reward_min: -101.35084033613445
queue_len: 0.06400868260655278
wait_time: 0.6038344825109531
delay_time: 4.2025134926994845
pressure: 0.7844827586206896
total_envstep_count: 1488744
total_train_sample_count: 1488744
total_episode_count: 12834
total_duration: 47909.76138854027
[2025-02-21 06:59:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.06947134826172
avg_train_sample_per_sec: 32.06947134826172
avg_episode_per_sec: 0.2764609598988079
collect_time: 21.70288348197937
reward_mean: -95.87441643323996
reward_std: 2.531860450428469
reward_max: -92.62745098039214
reward_min: -99.63935574229693
queue_len: 0.06357719922628645
wait_time: 0.601790605720626
delay_time: 4.1783004696804324
pressure: 0.7812776304155614
total_envstep_count: 1489440
total_train_sample_count: 1489440
total_episode_count: 12840
total_duration: 47931.46427202225
[2025-02-21 06:59:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.156647936352556
avg_train_sample_per_sec: 32.156647936352556
avg_episode_per_sec: 0.27721248220993583
collect_time: 21.644047021865845
reward_mean: -97.57971521942112
reward_std: 3.3902530965340416
reward_max: -93.8578431372549
reward_min: -103.8067226890757
queue_len: 0.06470803396513337
wait_time: 0.6047890862799584
delay_time: 4.229951529367594
pressure: 0.7948717948717948
total_envstep_count: 1490136
total_train_sample_count: 1490136
total_episode_count: 12846
total_duration: 47953.10831904411
[2025-02-21 06:59:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.786908341091838
avg_train_sample_per_sec: 30.786908341091838
avg_episode_per_sec: 0.2654043822507917
collect_time: 22.607011795043945
reward_mean: -96.82586367880485
reward_std: 2.421668147896032
reward_max: -93.42857142857144
reward_min: -100.37044817927173
queue_len: 0.06420813241300057
wait_time: 0.602955649545406
delay_time: 4.1833801794399434
pressure: 0.7953138815207782
total_envstep_count: 1490832
total_train_sample_count: 1490832
total_episode_count: 12852
total_duration: 47975.71533083916
[2025-02-21 07:00:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97236688912739
avg_train_sample_per_sec: 31.97236688912739
avg_episode_per_sec: 0.2756238524924775
collect_time: 21.768798112869263
reward_mean: -93.98085901027076
reward_std: 1.4653192850577825
reward_max: -92.08613445378147
reward_min: -95.73599439775906
queue_len: 0.06232152454261986
wait_time: 0.5862661819811921
delay_time: 4.1526690812574545
pressure: 0.7621573828470379
total_envstep_count: 1491528
total_train_sample_count: 1491528
total_episode_count: 12858
total_duration: 47997.48412895203
[2025-02-21 07:00:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.735047155735412
avg_train_sample_per_sec: 31.735047155735412
avg_episode_per_sec: 0.273577992721857
collect_time: 21.931588649749756
reward_mean: -95.26820728291317
reward_std: 1.6782901633207623
reward_max: -92.2093837535014
reward_min: -97.3704481792717
queue_len: 0.06317520376851005
wait_time: 0.5940793978953207
delay_time: 4.121767240563126
pressure: 0.7758620689655173
total_envstep_count: 1492224
total_train_sample_count: 1492224
total_episode_count: 12864
total_duration: 48019.415717601776
[2025-02-21 07:00:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.821844492492023
avg_train_sample_per_sec: 31.821844492492023
avg_episode_per_sec: 0.27432624562493124
collect_time: 21.8717679977417
reward_mean: -97.44887955182072
reward_std: 3.013789685652735
reward_max: -94.78711484593838
reward_min: -103.34103641456578
queue_len: 0.06462127291234797
wait_time: 0.6033701057788279
delay_time: 4.210644383479395
pressure: 0.7979664014146772
total_envstep_count: 1492920
total_train_sample_count: 1492920
total_episode_count: 12870
total_duration: 48041.28748559952
[2025-02-21 07:01:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.956510950269873
avg_train_sample_per_sec: 31.956510950269873
avg_episode_per_sec: 0.27548716336439544
collect_time: 21.7795991897583
reward_mean: -95.78116246498598
reward_std: 2.650533234953185
reward_max: -92.35294117647058
reward_min: -98.94957983193271
queue_len: 0.06351535972479176
wait_time: 0.601301230041088
delay_time: 4.1975327604835755
pressure: 0.7852564102564102
total_envstep_count: 1493616
total_train_sample_count: 1493616
total_episode_count: 12876
total_duration: 48063.067084789276
[2025-02-21 07:01:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10778299142825
avg_train_sample_per_sec: 32.10778299142825
avg_episode_per_sec: 0.27679123268472633
collect_time: 21.676987171173096
reward_mean: -96.5485527544351
reward_std: 2.1013066579664113
reward_max: -94.03781512605038
reward_min: -100.22619047619051
queue_len: 0.06402423922707898
wait_time: 0.6045742346452286
delay_time: 4.1455619123974605
pressure: 0.7900088417329796
total_envstep_count: 1494312
total_train_sample_count: 1494312
total_episode_count: 12882
total_duration: 48084.74407196045
[2025-02-21 07:02:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0448735166652
avg_train_sample_per_sec: 32.0448735166652
avg_episode_per_sec: 0.2762489096264241
collect_time: 21.719542741775513
reward_mean: -97.07212885154063
reward_std: 2.949205754665091
reward_max: -92.88725490196079
reward_min: -101.4404761904762
queue_len: 0.0643714382304646
wait_time: 0.607364674428569
delay_time: 4.152350773468582
pressure: 0.7999557913351018
total_envstep_count: 1495008
total_train_sample_count: 1495008
total_episode_count: 12888
total_duration: 48106.463614702225
[2025-02-21 07:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.768246977305886
avg_train_sample_per_sec: 31.768246977305886
avg_episode_per_sec: 0.27386419808022316
collect_time: 21.908668756484985
reward_mean: -95.84803921568626
reward_std: 2.6355462612583445
reward_max: -91.56512605042018
reward_min: -99.5112044817927
queue_len: 0.06355970770270973
wait_time: 0.59736230920308
delay_time: 4.266660864019706
pressure: 0.7800618921308576
total_envstep_count: 1495704
total_train_sample_count: 1495704
total_episode_count: 12894
total_duration: 48128.37228345871
[2025-02-21 07:02:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.942826801105607
avg_train_sample_per_sec: 31.942826801105607
avg_episode_per_sec: 0.27536919656125525
collect_time: 21.78892946243286
reward_mean: -95.27252567693743
reward_std: 1.8714419851471034
reward_max: -93.10994397759104
reward_min: -98.23459383753499
queue_len: 0.06317806742502483
wait_time: 0.5939112935182916
delay_time: 4.143344244363956
pressure: 0.7801724137931035
total_envstep_count: 1496400
total_train_sample_count: 1496400
total_episode_count: 12900
total_duration: 48150.16121292114
[2025-02-21 07:03:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.540697668011322
avg_train_sample_per_sec: 31.540697668011322
avg_episode_per_sec: 0.2719025661035459
collect_time: 22.066728115081787
reward_mean: -97.72245564892621
reward_std: 2.1669005962828383
reward_max: -94.11834733893556
reward_min: -101.15476190476188
queue_len: 0.06480268942236486
wait_time: 0.6144571776544393
delay_time: 4.223588820931888
pressure: 0.7970822281167108
total_envstep_count: 1497096
total_train_sample_count: 1497096
total_episode_count: 12906
total_duration: 48172.227941036224
[2025-02-21 07:03:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.57923471677838
avg_train_sample_per_sec: 31.57923471677838
avg_episode_per_sec: 0.27223478204119295
collect_time: 22.039799451828003
reward_mean: -98.40289449112981
reward_std: 4.259529726864519
reward_max: -95.23179271708685
reward_min: -107.75980392156865
queue_len: 0.06525390881374653
wait_time: 0.6154870878501709
delay_time: 4.24830880186905
pressure: 0.8044871794871794
total_envstep_count: 1497792
total_train_sample_count: 1497792
total_episode_count: 12912
total_duration: 48194.26774048805
[2025-02-21 07:03:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.956368222726077
avg_train_sample_per_sec: 31.956368222726077
avg_episode_per_sec: 0.27548593295453516
collect_time: 21.779696464538574
reward_mean: -98.56804388422034
reward_std: 1.5983816685793535
reward_max: -96.98669467787111
reward_min: -101.2107843137255
queue_len: 0.06536342432640606
wait_time: 0.6158781704547424
delay_time: 4.25009259011181
pressure: 0.8013925729442971
total_envstep_count: 1498488
total_train_sample_count: 1498488
total_episode_count: 12918
total_duration: 48216.04743695259
[2025-02-21 07:04:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.794530893272967
avg_train_sample_per_sec: 31.794530893272967
avg_episode_per_sec: 0.274090783562698
collect_time: 21.890557289123535
reward_mean: -97.1924603174603
reward_std: 1.7252812180507662
reward_max: -94.32773109243695
reward_min: -99.17507002801122
queue_len: 0.06445123363226811
wait_time: 0.6095813767593689
delay_time: 4.191627106777943
pressure: 0.7967506631299734
total_envstep_count: 1499184
total_train_sample_count: 1499184
total_episode_count: 12924
total_duration: 48237.937994241714
[2025-02-21 07:04:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.73764860941283
avg_train_sample_per_sec: 31.73764860941283
avg_episode_per_sec: 0.2736004190466623
collect_time: 21.92979097366333
reward_mean: -97.35294117647061
reward_std: 4.047571937959053
reward_max: -92.71638655462186
reward_min: -104.78991596638659
queue_len: 0.06455765330004683
wait_time: 0.6138801895647737
delay_time: 4.190889571680466
pressure: 0.7906719717064544
total_envstep_count: 1499880
total_train_sample_count: 1499880
total_episode_count: 12930
total_duration: 48259.86778521538
[2025-02-21 07:05:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67721579678528
avg_train_sample_per_sec: 31.67721579678528
avg_episode_per_sec: 0.27307944652401106
collect_time: 21.971627950668335
reward_mean: -95.71743697478992
reward_std: 2.7175392643504104
reward_max: -92.86624649859944
reward_min: -99.97408963585438
queue_len: 0.06347310144216839
wait_time: 0.6010165671042954
delay_time: 4.123619482936045
pressure: 0.7877984084880637
total_envstep_count: 1500576
total_train_sample_count: 1500576
total_episode_count: 12936
total_duration: 48281.839413166046
[2025-02-21 07:05:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.850155095228423
avg_train_sample_per_sec: 31.850155095228423
avg_episode_per_sec: 0.27457030254507264
collect_time: 21.8523268699646
reward_mean: -96.66071428571429
reward_std: 1.011221515817493
reward_max: -95.50210084033614
reward_min: -98.5273109243698
queue_len: 0.06409861690034105
wait_time: 0.6034772220117047
delay_time: 4.178578210639219
pressure: 0.7917771883289125
total_envstep_count: 1501272
total_train_sample_count: 1501272
total_episode_count: 12942
total_duration: 48303.69174003601
[2025-02-21 07:05:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88627965577918
avg_train_sample_per_sec: 31.88627965577918
avg_episode_per_sec: 0.2748817211705102
collect_time: 21.82756996154785
reward_mean: -96.25560224089635
reward_std: 2.520175775459397
reward_max: -93.31302521008405
reward_min: -99.85644257703083
queue_len: 0.0638299749608066
wait_time: 0.6024550514281753
delay_time: 4.197665571397743
pressure: 0.7847038019451813
total_envstep_count: 1501968
total_train_sample_count: 1501968
total_episode_count: 12948
total_duration: 48325.51930999756
[2025-02-21 07:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67259013119206
avg_train_sample_per_sec: 31.67259013119206
avg_episode_per_sec: 0.2730395700964833
collect_time: 21.974836826324463
reward_mean: -96.94234360410832
reward_std: 2.1428202850230003
reward_max: -94.74439775910362
reward_min: -100.17226890756302
queue_len: 0.0642853737427774
wait_time: 0.6080179750945472
delay_time: 4.156132225222487
pressure: 0.791445623342175
total_envstep_count: 1502664
total_train_sample_count: 1502664
total_episode_count: 12954
total_duration: 48347.49414682388
[2025-02-21 07:06:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74448446033887
avg_train_sample_per_sec: 31.74448446033887
avg_episode_per_sec: 0.2736593487960247
collect_time: 21.925068616867065
reward_mean: -98.82924836601308
reward_std: 5.684196307767756
reward_max: -93.44327731092436
reward_min: -110.61484593837538
queue_len: 0.06553663684748877
wait_time: 0.6185884278556691
delay_time: 4.308449236003967
pressure: 0.8050397877984086
total_envstep_count: 1503360
total_train_sample_count: 1503360
total_episode_count: 12960
total_duration: 48369.41921544075
[2025-02-21 07:06:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04198722395117
avg_train_sample_per_sec: 32.04198722395117
avg_episode_per_sec: 0.27622402779268246
collect_time: 21.72149920463562
reward_mean: -99.26925770308122
reward_std: 3.7456948654444138
reward_max: -92.8067226890756
reward_min: -103.40546218487397
queue_len: 0.06582842022750746
wait_time: 0.6218139112408889
delay_time: 4.237997321639348
pressure: 0.8208443854995578
total_envstep_count: 1504056
total_train_sample_count: 1504056
total_episode_count: 12966
total_duration: 48391.140714645386
[2025-02-21 07:07:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.42682134193352
avg_train_sample_per_sec: 32.42682134193352
avg_episode_per_sec: 0.2795415632925303
collect_time: 21.46371340751648
reward_mean: -100.48984593837537
reward_std: 4.7132275427007855
reward_max: -95.37254901960785
reward_min: -109.45238095238099
queue_len: 0.0666378288716017
wait_time: 0.6285609955741802
delay_time: 4.331188164369465
pressure: 0.8251547303271441
total_envstep_count: 1504752
total_train_sample_count: 1504752
total_episode_count: 12972
total_duration: 48412.6044280529
[2025-02-21 07:07:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.962622844158755
avg_train_sample_per_sec: 31.962622844158755
avg_episode_per_sec: 0.27553985210481685
collect_time: 21.775434494018555
reward_mean: -98.90126050420167
reward_std: 2.5857844480604273
reward_max: -96.50210084033614
reward_min: -104.12254901960787
queue_len: 0.06558439025477565
wait_time: 0.6254697170645446
delay_time: 4.235107884979025
pressure: 0.8080238726790453
total_envstep_count: 1505448
total_train_sample_count: 1505448
total_episode_count: 12978
total_duration: 48434.37986254692
[2025-02-21 07:08:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.84199998481655
avg_train_sample_per_sec: 31.84199998481655
avg_episode_per_sec: 0.2744999998691082
collect_time: 21.85792350769043
reward_mean: -96.32399626517271
reward_std: 1.7329525088435969
reward_max: -94.38445378151259
reward_min: -98.73389355742293
queue_len: 0.06387532908831084
wait_time: 0.5975416360178024
delay_time: 4.159434237026986
pressure: 0.7892351900972591
total_envstep_count: 1506144
total_train_sample_count: 1506144
total_episode_count: 12984
total_duration: 48456.23778605461
[2025-02-21 07:08:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6753583570316
avg_train_sample_per_sec: 31.6753583570316
avg_episode_per_sec: 0.2730634341123414
collect_time: 21.9729163646698
reward_mean: -98.27322595704948
reward_std: 2.102745223255073
reward_max: -95.07773109243693
reward_min: -101.80602240896354
queue_len: 0.06516792172218135
wait_time: 0.6129416841891486
delay_time: 4.219339575608169
pressure: 0.8039345711759506
total_envstep_count: 1506840
total_train_sample_count: 1506840
total_episode_count: 12990
total_duration: 48478.21070241928
[2025-02-21 07:08:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.922831846980134
avg_train_sample_per_sec: 31.922831846980134
avg_episode_per_sec: 0.2751968262670701
collect_time: 21.802577018737793
reward_mean: -99.37628384687207
reward_std: 3.0635075730600683
reward_max: -93.60784313725489
reward_min: -103.02170868347336
queue_len: 0.06589939247140057
wait_time: 0.6251766179504517
delay_time: 4.330177358165119
pressure: 0.8072502210433244
total_envstep_count: 1507536
total_train_sample_count: 1507536
total_episode_count: 12996
total_duration: 48500.01327943802
[2025-02-21 07:09:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.1055615179635
avg_train_sample_per_sec: 32.1055615179635
avg_episode_per_sec: 0.2767720820514095
collect_time: 21.678487062454224
reward_mean: -98.02427637721756
reward_std: 2.7140212495024203
reward_max: -94.34383753501399
reward_min: -102.95168067226894
queue_len: 0.06500283579391085
wait_time: 0.6135738557138152
delay_time: 4.219384178019885
pressure: 0.8007294429708223
total_envstep_count: 1508232
total_train_sample_count: 1508232
total_episode_count: 13002
total_duration: 48521.69176650047
[2025-02-21 07:09:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7908828361687
avg_train_sample_per_sec: 31.7908828361687
avg_episode_per_sec: 0.27405933479455774
collect_time: 21.89306926727295
reward_mean: -95.29026610644256
reward_std: 2.0193992031966115
reward_max: -93.35854341736692
reward_min: -98.75210084033611
queue_len: 0.06318983163557199
wait_time: 0.599143271366902
delay_time: 4.136610134526211
pressure: 0.7771883289124668
total_envstep_count: 1508928
total_train_sample_count: 1508928
total_episode_count: 13008
total_duration: 48543.584835767746
[2025-02-21 07:09:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0461286499162
avg_train_sample_per_sec: 32.0461286499162
avg_episode_per_sec: 0.2762597297406569
collect_time: 21.71869206428528
reward_mean: -96.39145658263304
reward_std: 2.327282664915482
reward_max: -92.58963585434174
reward_min: -99.40966386554621
queue_len: 0.06392006404683888
wait_time: 0.5988951393997034
delay_time: 4.213301067766161
pressure: 0.7850353669319187
total_envstep_count: 1509624
total_train_sample_count: 1509624
total_episode_count: 13014
total_duration: 48565.30352783203
[2025-02-21 07:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.699310039134467
avg_train_sample_per_sec: 31.699310039134467
avg_episode_per_sec: 0.2732699141304695
collect_time: 21.956313848495483
reward_mean: -94.85387488328665
reward_std: 2.3575769959180186
reward_max: -91.69327731092434
reward_min: -97.91666666666666
queue_len: 0.06290044753533597
wait_time: 0.5863884678539849
delay_time: 4.163192837407226
pressure: 0.7738726790450929
total_envstep_count: 1510320
total_train_sample_count: 1510320
total_episode_count: 13020
total_duration: 48587.25984168053
[2025-02-21 07:10:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.842603293502968
avg_train_sample_per_sec: 31.842603293502968
avg_episode_per_sec: 0.27450520080606006
collect_time: 21.85750937461853
reward_mean: -96.60655929038283
reward_std: 1.873114929108596
reward_max: -94.91736694677874
reward_min: -100.52030812324932
queue_len: 0.06406270509972335
wait_time: 0.6027865390187904
delay_time: 4.211526238958732
pressure: 0.7830459770114943
total_envstep_count: 1511016
total_train_sample_count: 1511016
total_episode_count: 13026
total_duration: 48609.117351055145
[2025-02-21 07:11:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.958107209273916
avg_train_sample_per_sec: 30.958107209273916
avg_episode_per_sec: 0.26688023456270615
collect_time: 22.48199462890625
reward_mean: -96.03641456582632
reward_std: 0.6866576513889955
reward_max: -94.85924369747899
reward_min: -96.73249299719889
queue_len: 0.06368462504365141
wait_time: 0.5969241697563198
delay_time: 4.168433757454506
pressure: 0.7861405835543765
total_envstep_count: 1511712
total_train_sample_count: 1511712
total_episode_count: 13032
total_duration: 48631.59934568405
[2025-02-21 07:11:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.66296370404783
avg_train_sample_per_sec: 31.66296370404783
avg_episode_per_sec: 0.27295658365558473
collect_time: 21.981517791748047
reward_mean: -95.71323529411764
reward_std: 2.2260756231039873
reward_max: -92.75420168067225
reward_min: -97.97899159663862
queue_len: 0.06347031518177562
wait_time: 0.5986171325294043
delay_time: 4.17772094005836
pressure: 0.7793987621573827
total_envstep_count: 1512408
total_train_sample_count: 1512408
total_episode_count: 13038
total_duration: 48653.5808634758
[2025-02-21 07:11:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75512182703116
avg_train_sample_per_sec: 31.75512182703116
avg_episode_per_sec: 0.27375105023302726
collect_time: 21.917724132537842
reward_mean: -96.36041083099907
reward_std: 3.225216484981876
reward_max: -90.46148459383754
reward_min: -100.2528011204482
queue_len: 0.06389947667838135
wait_time: 0.6035017565823854
delay_time: 4.235842312548361
pressure: 0.7778514588859416
total_envstep_count: 1513104
total_train_sample_count: 1513104
total_episode_count: 13044
total_duration: 48675.49858760834
[2025-02-21 07:12:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88994546046829
avg_train_sample_per_sec: 31.88994546046829
avg_episode_per_sec: 0.2749133229350715
collect_time: 21.825060844421387
reward_mean: -96.6784547152194
reward_std: 1.5391945214352325
reward_max: -95.3564425770308
reward_min: -99.33053221288513
queue_len: 0.0641103811108882
wait_time: 0.6046809638974956
delay_time: 4.181250475063408
pressure: 0.7851458885941645
total_envstep_count: 1513800
total_train_sample_count: 1513800
total_episode_count: 13050
total_duration: 48697.32364845276
[2025-02-21 07:12:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03227381229602
avg_train_sample_per_sec: 32.03227381229602
avg_episode_per_sec: 0.2761402914853105
collect_time: 21.72808599472046
reward_mean: -97.63176937441642
reward_std: 2.708539008601334
reward_max: -94.69117647058825
reward_min: -102.49299719887956
queue_len: 0.06474255263555466
wait_time: 0.6082358451780358
delay_time: 4.187205750778925
pressure: 0.7987400530503979
total_envstep_count: 1514496
total_train_sample_count: 1514496
total_episode_count: 13056
total_duration: 48719.05173444748
[2025-02-21 07:12:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.758745787654945
avg_train_sample_per_sec: 31.758745787654945
avg_episode_per_sec: 0.27378229127288745
collect_time: 21.915223121643066
reward_mean: -95.8315826330532
reward_std: 1.7216424533299306
reward_max: -92.98109243697476
reward_min: -97.72128851540614
queue_len: 0.06354879484950478
wait_time: 0.5987665070449047
delay_time: 4.158315065564221
pressure: 0.7797303271441204
total_envstep_count: 1515192
total_train_sample_count: 1515192
total_episode_count: 13062
total_duration: 48740.96695756912
[2025-02-21 07:13:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.621519720032076
avg_train_sample_per_sec: 31.621519720032076
avg_episode_per_sec: 0.272599307931311
collect_time: 22.010327339172363
reward_mean: -97.48716153127918
reward_std: 3.996271765125843
reward_max: -92.07072829131654
reward_min: -102.70168067226889
queue_len: 0.06464665884037081
wait_time: 0.6089963394730129
delay_time: 4.24087228204628
pressure: 0.793656056587091
total_envstep_count: 1515888
total_train_sample_count: 1515888
total_episode_count: 13068
total_duration: 48762.977284908295
[2025-02-21 07:13:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01006730223215
avg_train_sample_per_sec: 32.01006730223215
avg_episode_per_sec: 0.2759488560537255
collect_time: 21.743159532546997
reward_mean: -96.05543884220354
reward_std: 2.568413883926348
reward_max: -92.68977591036415
reward_min: -99.22899159663869
queue_len: 0.06369724061154082
wait_time: 0.5955571220530652
delay_time: 4.157678494810999
pressure: 0.7843722369584438
total_envstep_count: 1516584
total_train_sample_count: 1516584
total_episode_count: 13074
total_duration: 48784.72044444084
[2025-02-21 07:14:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.131865313606404
avg_train_sample_per_sec: 32.131865313606404
avg_episode_per_sec: 0.27699883891040006
collect_time: 21.660740613937378
reward_mean: -96.84407096171803
reward_std: 2.802185216240904
reward_max: -91.74439775910363
reward_min: -100.12254901960786
queue_len: 0.06422020620803581
wait_time: 0.6080531903300664
delay_time: 4.191198447628309
pressure: 0.7843722369584438
total_envstep_count: 1517280
total_train_sample_count: 1517280
total_episode_count: 13080
total_duration: 48806.38118505478
[2025-02-21 07:14:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77205755173813
avg_train_sample_per_sec: 31.77205755173813
avg_episode_per_sec: 0.27389704785981145
collect_time: 21.906041145324707
reward_mean: -95.8329831932773
reward_std: 1.8659216765617221
reward_max: -93.46708683473389
reward_min: -99.60924369747897
queue_len: 0.06354972360296902
wait_time: 0.5963614999492282
delay_time: 4.1821446523875325
pressure: 0.7823828470380194
total_envstep_count: 1517976
total_train_sample_count: 1517976
total_episode_count: 13086
total_duration: 48828.287226200104
[2025-02-21 07:14:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.150722936956086
avg_train_sample_per_sec: 32.150722936956086
avg_episode_per_sec: 0.2771614046289318
collect_time: 21.648035764694214
reward_mean: -96.88270308123249
reward_std: 2.5430926166987806
reward_max: -91.95448179271708
reward_min: -99.57002801120449
queue_len: 0.06424582432442473
wait_time: 0.605970615478729
delay_time: 4.1308671745137255
pressure: 0.7982979664014147
total_envstep_count: 1518672
total_train_sample_count: 1518672
total_episode_count: 13092
total_duration: 48849.9352619648
[2025-02-21 07:15:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.573221086665814
avg_train_sample_per_sec: 31.573221086665814
avg_episode_per_sec: 0.2721829404022915
collect_time: 22.043997287750244
reward_mean: -96.34815592903828
reward_std: 2.2758614307986202
reward_max: -93.25490196078432
reward_min: -99.71568627450984
queue_len: 0.06389135008556916
wait_time: 0.6020290631725723
delay_time: 4.155665642383817
pressure: 0.7900088417329797
total_envstep_count: 1519368
total_train_sample_count: 1519368
total_episode_count: 13098
total_duration: 48871.97925925255
[2025-02-21 07:15:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.864973449799454
avg_train_sample_per_sec: 31.864973449799454
avg_episode_per_sec: 0.2746980469810298
collect_time: 21.842164754867554
reward_mean: -99.23085901027078
reward_std: 3.6398525130621504
reward_max: -94.73739495798318
reward_min: -106.51960784313725
queue_len: 0.06580295690336259
wait_time: 0.6208237052557539
delay_time: 4.3081101636514365
pressure: 0.8032714412024758
total_envstep_count: 1520064
total_train_sample_count: 1520064
total_episode_count: 13104
total_duration: 48893.821424007416
[2025-02-21 07:15:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.746665221597656
avg_train_sample_per_sec: 31.746665221597656
avg_episode_per_sec: 0.27367814846204874
collect_time: 21.92356252670288
reward_mean: -98.11461251167134
reward_std: 2.8690082680226645
reward_max: -93.26540616246501
reward_min: -102.29901960784314
queue_len: 0.065062740392355
wait_time: 0.6118524885639489
delay_time: 4.172834409799099
pressure: 0.8066976127320955
total_envstep_count: 1520760
total_train_sample_count: 1520760
total_episode_count: 13110
total_duration: 48915.74498653412
[2025-02-21 07:16:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03607803117391
avg_train_sample_per_sec: 32.03607803117391
avg_episode_per_sec: 0.27617308647563715
collect_time: 21.725505828857422
reward_mean: -95.93720821661998
reward_std: 3.826941320363785
reward_max: -92.06442577030815
reward_min: -103.58053221288516
queue_len: 0.06361883833993366
wait_time: 0.6006966115358611
delay_time: 4.224118596631313
pressure: 0.7843722369584439
total_envstep_count: 1521456
total_train_sample_count: 1521456
total_episode_count: 13116
total_duration: 48937.470492362976
[2025-02-21 07:16:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04323439314995
avg_train_sample_per_sec: 32.04323439314995
avg_episode_per_sec: 0.2762347792512927
collect_time: 21.720653772354126
reward_mean: -98.07644724556486
reward_std: 1.983414097916423
reward_max: -95.33683473389351
reward_min: -100.48669467787116
queue_len: 0.06503743186045417
wait_time: 0.6139393202019977
delay_time: 4.2476022955497434
pressure: 0.8013925729442971
total_envstep_count: 1522152
total_train_sample_count: 1522152
total_episode_count: 13122
total_duration: 48959.19114613533
[2025-02-21 07:17:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929689388460275
avg_train_sample_per_sec: 31.929689388460275
avg_episode_per_sec: 0.2752559430039679
collect_time: 21.79789447784424
reward_mean: -98.90114379084967
reward_std: 4.1819412493041135
reward_max: -91.93347338935573
reward_min: -106.13725490196082
queue_len: 0.06558431285865363
wait_time: 0.615553338930621
delay_time: 4.30993602923287
pressure: 0.8074712643678162
total_envstep_count: 1522848
total_train_sample_count: 1522848
total_episode_count: 13128
total_duration: 48980.989040613174
[2025-02-21 07:17:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87142164896481
avg_train_sample_per_sec: 31.87142164896481
avg_episode_per_sec: 0.27475363490486904
collect_time: 21.837745666503906
reward_mean: -98.64974323062559
reward_std: 2.6311646874456827
reward_max: -93.79761904761902
reward_min: -101.88515406162465
queue_len: 0.06541760161182067
wait_time: 0.6184536812072309
delay_time: 4.217453736686554
pressure: 0.8122236958443855
total_envstep_count: 1523544
total_train_sample_count: 1523544
total_episode_count: 13134
total_duration: 49002.82678627968
[2025-02-21 07:17:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.61384997667489
avg_train_sample_per_sec: 31.61384997667489
avg_episode_per_sec: 0.2725331894540939
collect_time: 22.0156672000885
reward_mean: -96.13422035480859
reward_std: 1.5542458320565857
reward_max: -92.92226890756301
reward_min: -97.47408963585436
queue_len: 0.0637494829939049
wait_time: 0.6034184009589688
delay_time: 4.165531019414327
pressure: 0.786472148541114
total_envstep_count: 1524240
total_train_sample_count: 1524240
total_episode_count: 13140
total_duration: 49024.84245347977
[2025-02-21 07:18:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.929639447648032
avg_train_sample_per_sec: 31.929639447648032
avg_episode_per_sec: 0.2752555124797244
collect_time: 21.79792857170105
reward_mean: -96.76739028944911
reward_std: 1.1885874659226507
reward_max: -94.9761904761905
reward_min: -98.15406162464986
queue_len: 0.0641693569558681
wait_time: 0.6045357687725842
delay_time: 4.157025671168985
pressure: 0.7923297966401414
total_envstep_count: 1524936
total_train_sample_count: 1524936
total_episode_count: 13146
total_duration: 49046.64038205147
[2025-02-21 07:18:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.91978251425187
avg_train_sample_per_sec: 31.91978251425187
avg_episode_per_sec: 0.2751705389159644
collect_time: 21.804659843444824
reward_mean: -96.90802987861808
reward_std: 3.126902768111366
reward_max: -93.22619047619047
reward_min: -102.32002801120447
queue_len: 0.06426261928290326
wait_time: 0.6070818689987048
delay_time: 4.220986222317012
pressure: 0.7933244916003536
total_envstep_count: 1525632
total_train_sample_count: 1525632
total_episode_count: 13152
total_duration: 49068.44504189491
[2025-02-21 07:18:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.770563777845755
avg_train_sample_per_sec: 31.770563777845755
avg_episode_per_sec: 0.2738841704986703
collect_time: 21.907071113586426
reward_mean: -96.12068160597572
reward_std: 3.2236513141286145
reward_max: -90.70028011204481
reward_min: -100.5609243697479
queue_len: 0.06374050504375048
wait_time: 0.6018518260531446
delay_time: 4.175360422845432
pressure: 0.7829354553492484
total_envstep_count: 1526328
total_train_sample_count: 1526328
total_episode_count: 13158
total_duration: 49090.3521130085
[2025-02-21 07:19:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.942527960504844
avg_train_sample_per_sec: 31.942527960504844
avg_episode_per_sec: 0.2753666203491797
collect_time: 21.789133310317993
reward_mean: -97.10375816993462
reward_std: 1.4979193711080439
reward_max: -94.63795518207286
reward_min: -98.58893557422971
queue_len: 0.06439241257953225
wait_time: 0.6078610157590888
delay_time: 4.21289021738587
pressure: 0.7910035366931919
total_envstep_count: 1527024
total_train_sample_count: 1527024
total_episode_count: 13164
total_duration: 49112.14124631882
[2025-02-21 07:19:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97208850544268
avg_train_sample_per_sec: 31.97208850544268
avg_episode_per_sec: 0.27562145263312654
collect_time: 21.76898765563965
reward_mean: -97.0800653594771
reward_std: 2.988400604650462
reward_max: -92.97969187675069
reward_min: -101.21918767507003
queue_len: 0.06437670116676202
wait_time: 0.6098578357072272
delay_time: 4.176381777115923
pressure: 0.7882404951370469
total_envstep_count: 1527720
total_train_sample_count: 1527720
total_episode_count: 13170
total_duration: 49133.91023397446
[2025-02-21 07:19:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13110068932324
avg_train_sample_per_sec: 32.13110068932324
avg_episode_per_sec: 0.2769922473217521
collect_time: 21.661256074905396
reward_mean: -96.35224089635852
reward_std: 2.989453120679851
reward_max: -90.1050420168067
reward_min: -99.67226890756304
queue_len: 0.06389405894983988
wait_time: 0.6025940548633245
delay_time: 4.167703909850636
pressure: 0.7791777188328912
total_envstep_count: 1528416
total_train_sample_count: 1528416
total_episode_count: 13176
total_duration: 49155.57149004936
[2025-02-21 07:20:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7959493465071
avg_train_sample_per_sec: 31.7959493465071
avg_episode_per_sec: 0.2741030116078198
collect_time: 21.889580726623535
reward_mean: -98.00887021475256
reward_std: 4.428337897280055
reward_max: -92.99299719887954
reward_min: -106.8074229691877
queue_len: 0.0649926195058041
wait_time: 0.6118682773728413
delay_time: 4.19638998774277
pressure: 0.8017241379310344
total_envstep_count: 1529112
total_train_sample_count: 1529112
total_episode_count: 13182
total_duration: 49177.461070775986
[2025-02-21 07:20:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.965622613961305
avg_train_sample_per_sec: 31.965622613961305
avg_episode_per_sec: 0.2755657121893216
collect_time: 21.773391008377075
reward_mean: -95.85772642390288
reward_std: 3.421757079130778
reward_max: -92.1624649859944
reward_min: -101.53011204481791
queue_len: 0.06356613158083746
wait_time: 0.6026485417332273
delay_time: 4.190462900391748
pressure: 0.787577365163572
total_envstep_count: 1529808
total_train_sample_count: 1529808
total_episode_count: 13188
total_duration: 49199.23446178436
[2025-02-21 07:21:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.147560525783284
avg_train_sample_per_sec: 32.147560525783284
avg_episode_per_sec: 0.27713414246364904
collect_time: 21.65016531944275
reward_mean: -96.42880485527546
reward_std: 1.3858664710651554
reward_max: -94.85994397759104
reward_min: -98.70798319327733
queue_len: 0.06394483080588557
wait_time: 0.6031522356953392
delay_time: 4.17981913726618
pressure: 0.787577365163572
total_envstep_count: 1530504
total_train_sample_count: 1530504
total_episode_count: 13194
total_duration: 49220.884627103806
[2025-02-21 07:21:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17475945356524
avg_train_sample_per_sec: 32.17475945356524
avg_episode_per_sec: 0.27736861597901064
collect_time: 21.631863355636597
reward_mean: -99.51458916900093
reward_std: 2.798082836411438
reward_max: -97.05462184873947
reward_min: -105.54971988795516
queue_len: 0.0659911068759953
wait_time: 0.6271850473168932
delay_time: 4.275400434660884
pressure: 0.8101237842617154
total_envstep_count: 1531200
total_train_sample_count: 1531200
total_episode_count: 13200
total_duration: 49242.51649045944
[2025-02-21 07:21:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.763948947147064
avg_train_sample_per_sec: 31.763948947147064
avg_episode_per_sec: 0.2738271460960954
collect_time: 21.911633253097534
reward_mean: -95.83520074696544
reward_std: 1.5658003186195009
reward_max: -94.17787114845936
reward_min: -98.63585434173672
queue_len: 0.06355119412928743
wait_time: 0.6032280838949197
delay_time: 4.167353378964414
pressure: 0.7809460654288239
total_envstep_count: 1531896
total_train_sample_count: 1531896
total_episode_count: 13206
total_duration: 49264.42812371254
[2025-02-21 07:22:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07676000807271
avg_train_sample_per_sec: 32.07676000807271
avg_episode_per_sec: 0.27652379317304066
collect_time: 21.697952032089233
reward_mean: -96.68849206349205
reward_std: 2.7962381417218474
reward_max: -92.89985994397755
reward_min: -101.09383753501395
queue_len: 0.06411703717738199
wait_time: 0.6087181778104698
delay_time: 4.182021362350629
pressure: 0.7905614500442087
total_envstep_count: 1532592
total_train_sample_count: 1532592
total_episode_count: 13212
total_duration: 49286.12607574463
[2025-02-21 07:22:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.947632436463078
avg_train_sample_per_sec: 31.947632436463078
avg_episode_per_sec: 0.2754106244522679
collect_time: 21.785651922225952
reward_mean: -95.47327264239028
reward_std: 0.8753562480334799
reward_max: -94.563025210084
reward_min: -97.18697478991598
queue_len: 0.06331118875490072
wait_time: 0.5960435566799664
delay_time: 4.218053989517027
pressure: 0.7769672855879753
total_envstep_count: 1533288
total_train_sample_count: 1533288
total_episode_count: 13218
total_duration: 49307.911727666855
[2025-02-21 07:22:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.032423193978815
avg_train_sample_per_sec: 32.032423193978815
avg_episode_per_sec: 0.276141579258438
collect_time: 21.72798466682434
reward_mean: -97.46288515406162
reward_std: 1.8263438235240113
reward_max: -94.937675070028
reward_min: -100.36624649859942
queue_len: 0.06463056044699048
wait_time: 0.6081105408564841
delay_time: 4.211836057902636
pressure: 0.7975243147656941
total_envstep_count: 1533984
total_train_sample_count: 1533984
total_episode_count: 13224
total_duration: 49329.63971233368
[2025-02-21 07:23:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.913267286108695
avg_train_sample_per_sec: 31.913267286108695
avg_episode_per_sec: 0.2751143731561094
collect_time: 21.80911135673523
reward_mean: -96.05777310924367
reward_std: 1.7026532817577642
reward_max: -92.92436974789912
reward_min: -98.15476190476187
queue_len: 0.06369878853398121
wait_time: 0.5979119764616722
delay_time: 4.177573213272193
pressure: 0.7838196286472149
total_envstep_count: 1534680
total_train_sample_count: 1534680
total_episode_count: 13230
total_duration: 49351.448823690414
[2025-02-21 07:23:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.106851778433615
avg_train_sample_per_sec: 32.106851778433615
avg_episode_per_sec: 0.27678320498649667
collect_time: 21.677615880966187
reward_mean: -96.44222689075629
reward_std: 1.0918536076465075
reward_max: -94.70518207282909
reward_min: -98.15476190476193
queue_len: 0.06395373135991796
wait_time: 0.6034194071085551
delay_time: 4.220070681964588
pressure: 0.788129973474801
total_envstep_count: 1535376
total_train_sample_count: 1535376
total_episode_count: 13236
total_duration: 49373.12643957138
[2025-02-21 07:24:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10949159168787
avg_train_sample_per_sec: 32.10949159168787
avg_episode_per_sec: 0.2768059619973092
collect_time: 21.675833702087402
reward_mean: -98.3267973856209
reward_std: 3.0279484384640596
reward_max: -93.43417366946775
reward_min: -102.45518207282913
queue_len: 0.06520344654218892
wait_time: 0.6152764930021524
delay_time: 4.2685929162114755
pressure: 0.8051503094606542
total_envstep_count: 1536072
total_train_sample_count: 1536072
total_episode_count: 13242
total_duration: 49394.80227327347
[2025-02-21 07:24:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.778178996466877
avg_train_sample_per_sec: 31.778178996466877
avg_episode_per_sec: 0.27394981893505926
collect_time: 21.90182137489319
reward_mean: -94.24544817927172
reward_std: 2.5500812458015005
reward_max: -90.50770308123252
reward_min: -97.72829131652664
queue_len: 0.06249698155124119
wait_time: 0.5904803234291064
delay_time: 4.143034475471552
pressure: 0.7742042440318303
total_envstep_count: 1536768
total_train_sample_count: 1536768
total_episode_count: 13248
total_duration: 49416.70409464836
[2025-02-21 07:24:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.810785066057733
avg_train_sample_per_sec: 30.810785066057733
avg_episode_per_sec: 0.2656102160867046
collect_time: 22.589492559432983
reward_mean: -97.13993930905694
reward_std: 3.429904729425953
reward_max: -92.36274509803917
reward_min: -102.90616246498598
queue_len: 0.06441640537735871
wait_time: 0.6092269799166351
delay_time: 4.218897502807132
pressure: 0.7989610963748893
total_envstep_count: 1537464
total_train_sample_count: 1537464
total_episode_count: 13254
total_duration: 49439.293587207794
[2025-02-21 07:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.106694286240604
avg_train_sample_per_sec: 32.106694286240604
avg_episode_per_sec: 0.27678184729517763
collect_time: 21.677722215652466
reward_mean: -95.0454014939309
reward_std: 1.189786792798315
reward_max: -92.69677871148455
reward_min: -96.40476190476195
queue_len: 0.06302745457157223
wait_time: 0.5926897505244361
delay_time: 4.186621063754758
pressure: 0.782051282051282
total_envstep_count: 1538160
total_train_sample_count: 1538160
total_episode_count: 13260
total_duration: 49460.97130942345
[2025-02-21 07:25:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04136473080988
avg_train_sample_per_sec: 32.04136473080988
avg_episode_per_sec: 0.276218661472499
collect_time: 21.72192120552063
reward_mean: -93.78956582633054
reward_std: 2.5536406906771627
reward_max: -91.22128851540619
reward_min: -99.06442577030816
queue_len: 0.062194672298627685
wait_time: 0.5867095069681277
delay_time: 4.078937301553471
pressure: 0.7708885941644562
total_envstep_count: 1538856
total_train_sample_count: 1538856
total_episode_count: 13266
total_duration: 49482.69323062897
[2025-02-21 07:25:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.840437115270618
avg_train_sample_per_sec: 31.840437115270618
avg_episode_per_sec: 0.2744865268557812
collect_time: 21.858996391296387
reward_mean: -98.50315126050418
reward_std: 1.69714180626389
reward_max: -96.60924369747897
reward_min: -101.82773109243695
queue_len: 0.06532039208256246
wait_time: 0.613243761253396
delay_time: 4.225327622481033
pressure: 0.8095711759504863
total_envstep_count: 1539552
total_train_sample_count: 1539552
total_episode_count: 13272
total_duration: 49504.552227020264
[2025-02-21 07:26:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01064540556452
avg_train_sample_per_sec: 32.01064540556452
avg_episode_per_sec: 0.2759538397031424
collect_time: 21.742766857147217
reward_mean: -95.71498599439775
reward_std: 2.126547047443406
reward_max: -92.76960784313722
reward_min: -98.47408963585433
queue_len: 0.06347147612360593
wait_time: 0.5968925921385354
delay_time: 4.1108443629891624
pressure: 0.7852564102564102
total_envstep_count: 1540248
total_train_sample_count: 1540248
total_episode_count: 13278
total_duration: 49526.29499387741
[2025-02-21 07:26:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.792329009217628
avg_train_sample_per_sec: 31.792329009217628
avg_episode_per_sec: 0.27407180180360025
collect_time: 21.892073392868042
reward_mean: -95.94946311858077
reward_std: 2.0448856124669144
reward_max: -92.93837535014005
reward_min: -97.9236694677871
queue_len: 0.06362696493274586
wait_time: 0.6013855918140908
delay_time: 4.138805173819954
pressure: 0.7869142351900974
total_envstep_count: 1540944
total_train_sample_count: 1540944
total_episode_count: 13284
total_duration: 49548.18706727028
[2025-02-21 07:27:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.019248870833984
avg_train_sample_per_sec: 32.019248870833984
avg_episode_per_sec: 0.2760280075071895
collect_time: 21.736924648284912
reward_mean: -96.24241363211951
reward_std: 3.5195338902322617
reward_max: -90.92366946778711
reward_min: -100.66806722689073
queue_len: 0.06382122919901824
wait_time: 0.6066913281669873
delay_time: 4.112460745031524
pressure: 0.7942086648983201
total_envstep_count: 1541640
total_train_sample_count: 1541640
total_episode_count: 13290
total_duration: 49569.923991918564
[2025-02-21 07:27:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.120719265155735
avg_train_sample_per_sec: 32.120719265155735
avg_episode_per_sec: 0.27690275228582534
collect_time: 21.668256998062134
reward_mean: -96.8660130718954
reward_std: 2.7121581037784703
reward_max: -92.6925770308123
reward_min: -101.4236694677871
queue_len: 0.06423475667897573
wait_time: 0.6077152014652014
delay_time: 4.126506626212101
pressure: 0.8001768346595933
total_envstep_count: 1542336
total_train_sample_count: 1542336
total_episode_count: 13296
total_duration: 49591.592248916626
[2025-02-21 07:27:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75174458438787
avg_train_sample_per_sec: 31.75174458438787
avg_episode_per_sec: 0.2737219360723092
collect_time: 21.920055389404297
reward_mean: -96.41141456582635
reward_std: 1.883426447837455
reward_max: -94.20938375350144
reward_min: -98.43417366946782
queue_len: 0.06393329878370448
wait_time: 0.6084691944859288
delay_time: 4.157477975281719
pressure: 0.792661361626879
total_envstep_count: 1543032
total_train_sample_count: 1543032
total_episode_count: 13302
total_duration: 49613.51230430603
[2025-02-21 07:28:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.27401141923567
avg_train_sample_per_sec: 32.27401141923567
avg_episode_per_sec: 0.27822423637272126
collect_time: 21.56533908843994
reward_mean: -95.48622782446311
reward_std: 1.5503011130656108
reward_max: -94.28571428571429
reward_min: -98.28151260504201
queue_len: 0.06331977972444502
wait_time: 0.5993591291512185
delay_time: 4.165607734983756
pressure: 0.7827144120247568
total_envstep_count: 1543728
total_train_sample_count: 1543728
total_episode_count: 13308
total_duration: 49635.07764339447
[2025-02-21 07:28:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75838922786671
avg_train_sample_per_sec: 31.75838922786671
avg_episode_per_sec: 0.2737792174816096
collect_time: 21.9154691696167
reward_mean: -94.80777310924368
reward_std: 2.1818327501185606
reward_max: -90.74369747899158
reward_min: -98.0651260504202
queue_len: 0.06286987606713773
wait_time: 0.5953358465402075
delay_time: 4.1535913366978265
pressure: 0.779288240495137
total_envstep_count: 1544424
total_train_sample_count: 1544424
total_episode_count: 13314
total_duration: 49656.99311256409
[2025-02-21 07:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.21779458088777
avg_train_sample_per_sec: 32.21779458088777
avg_episode_per_sec: 0.27773960845592904
collect_time: 21.602968454360962
reward_mean: -94.23517740429507
reward_std: 2.0769666471913526
reward_max: -90.57072829131651
reward_min: -96.84103641456583
queue_len: 0.062490170692503344
wait_time: 0.5918497704121436
delay_time: 4.087178689771747
pressure: 0.7781830238726791
total_envstep_count: 1545120
total_train_sample_count: 1545120
total_episode_count: 13320
total_duration: 49678.59608101845
[2025-02-21 07:29:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.88487054465646
avg_train_sample_per_sec: 31.88487054465646
avg_episode_per_sec: 0.27486957366083153
collect_time: 21.828534603118896
reward_mean: -95.53244631185807
reward_std: 2.1356953250362136
reward_max: -91.80812324929974
reward_min: -98.15406162464984
queue_len: 0.06335042858876529
wait_time: 0.5999540731411929
delay_time: 4.158120020730152
pressure: 0.7843722369584438
total_envstep_count: 1545816
total_train_sample_count: 1545816
total_episode_count: 13326
total_duration: 49700.42461562157
[2025-02-21 07:29:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0371886735081
avg_train_sample_per_sec: 32.0371886735081
avg_episode_per_sec: 0.27618266097851807
collect_time: 21.72475266456604
reward_mean: -95.61776377217554
reward_std: 2.8300961188231635
reward_max: -93.56932773109243
reward_min: -101.84173669467786
queue_len: 0.06340700515396257
wait_time: 0.59525589634616
delay_time: 4.128350944129978
pressure: 0.7821618037135277
total_envstep_count: 1546512
total_train_sample_count: 1546512
total_episode_count: 13332
total_duration: 49722.14936828613
[2025-02-21 07:30:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.23057093112854
avg_train_sample_per_sec: 32.23057093112854
avg_episode_per_sec: 0.27784974940628054
collect_time: 21.594404935836792
reward_mean: -100.32329598506067
reward_std: 4.941251626843044
reward_max: -93.39005602240897
reward_min: -106.7584033613445
queue_len: 0.06652738460547791
wait_time: 0.6294271355757157
delay_time: 4.286435485141055
pressure: 0.8268125552608311
total_envstep_count: 1547208
total_train_sample_count: 1547208
total_episode_count: 13338
total_duration: 49743.74377322197
[2025-02-21 07:30:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.835466820883735
avg_train_sample_per_sec: 31.835466820883735
avg_episode_per_sec: 0.274443679490377
collect_time: 21.862409114837646
reward_mean: -97.88585434173667
reward_std: 3.672145938061404
reward_max: -94.23809523809521
reward_min: -105.43137254901963
queue_len: 0.06491104399319408
wait_time: 0.6137433532210408
delay_time: 4.223896397774438
pressure: 0.7977453580901858
total_envstep_count: 1547904
total_train_sample_count: 1547904
total_episode_count: 13344
total_duration: 49765.60618233681
[2025-02-21 07:30:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.860368594389012
avg_train_sample_per_sec: 31.860368594389012
avg_episode_per_sec: 0.2746583499516294
collect_time: 21.845321655273438
reward_mean: -95.36437908496733
reward_std: 1.6821822828051727
reward_max: -93.53921568627456
reward_min: -98.65266106442576
queue_len: 0.06323897817305524
wait_time: 0.5941956468705961
delay_time: 4.140259274079161
pressure: 0.7772988505747126
total_envstep_count: 1548600
total_train_sample_count: 1548600
total_episode_count: 13350
total_duration: 49787.45150399208
[2025-02-21 07:31:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.809363724809295
avg_train_sample_per_sec: 31.809363724809295
avg_episode_per_sec: 0.2742186528000801
collect_time: 21.88034963607788
reward_mean: -96.9514472455649
reward_std: 2.1182693099605694
reward_max: -94.47689075630251
reward_min: -100.87324929971993
queue_len: 0.06429141064029503
wait_time: 0.6092946241272813
delay_time: 4.216651468818217
pressure: 0.7900088417329797
total_envstep_count: 1549296
total_train_sample_count: 1549296
total_episode_count: 13356
total_duration: 49809.33185362816
[2025-02-21 07:31:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22209930466811
avg_train_sample_per_sec: 32.22209930466811
avg_episode_per_sec: 0.27777671814369065
collect_time: 21.600082397460938
reward_mean: -96.37138188608775
reward_std: 2.2354448916846468
reward_max: -92.38165266106441
reward_min: -98.71848739495799
queue_len: 0.0639067519138513
wait_time: 0.6073253571985823
delay_time: 4.117684580745851
pressure: 0.7934350132625996
total_envstep_count: 1549992
total_train_sample_count: 1549992
total_episode_count: 13362
total_duration: 49830.93193602562
[2025-02-21 07:31:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.724756619354118
avg_train_sample_per_sec: 31.724756619354118
avg_episode_per_sec: 0.2734892812013286
collect_time: 21.93870258331299
reward_mean: -97.07481325863678
reward_std: 4.077209154458334
reward_max: -92.89355742296917
reward_min: -103.73809523809524
queue_len: 0.06437321834127108
wait_time: 0.6084289485024779
delay_time: 4.192111177594918
pressure: 0.8031609195402298
total_envstep_count: 1550688
total_train_sample_count: 1550688
total_episode_count: 13368
total_duration: 49852.87063860893
[2025-02-21 07:32:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.905223841838755
avg_train_sample_per_sec: 31.905223841838755
avg_episode_per_sec: 0.2750450331192996
collect_time: 21.81460952758789
reward_mean: -96.95273109243698
reward_std: 4.714739764051765
reward_max: -93.08683473389354
reward_min: -106.70028011204484
queue_len: 0.06429226199763725
wait_time: 0.606085471323808
delay_time: 4.127834816238727
pressure: 0.7990716180371353
total_envstep_count: 1551384
total_train_sample_count: 1551384
total_episode_count: 13374
total_duration: 49874.68524813652
[2025-02-21 07:32:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.99132799225379
avg_train_sample_per_sec: 31.99132799225379
avg_episode_per_sec: 0.2757873102780499
collect_time: 21.755895853042603
reward_mean: -97.75268440709614
reward_std: 2.688066217302155
reward_max: -95.15756302521005
reward_min: -102.73179271708682
queue_len: 0.06482273501796827
wait_time: 0.6150353266859353
delay_time: 4.169784407228249
pressure: 0.8055923961096375
total_envstep_count: 1552080
total_train_sample_count: 1552080
total_episode_count: 13380
total_duration: 49896.44114398956
[2025-02-21 07:33:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.818332701541344
avg_train_sample_per_sec: 31.818332701541344
avg_episode_per_sec: 0.27429597156501156
collect_time: 21.874181985855103
reward_mean: -99.20926704014938
reward_std: 3.350355334901656
reward_max: -96.91456582633052
reward_min: -106.5721288515406
queue_len: 0.06578863862078872
wait_time: 0.6247005544039013
delay_time: 4.215707179841317
pressure: 0.8126657824933687
total_envstep_count: 1552776
total_train_sample_count: 1552776
total_episode_count: 13386
total_duration: 49918.31532597542
[2025-02-21 07:33:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.823195654595168
avg_train_sample_per_sec: 31.823195654595168
avg_episode_per_sec: 0.27433789357409627
collect_time: 21.8708393573761
reward_mean: -96.62219887955182
reward_std: 1.596265781869284
reward_max: -94.23179271708685
reward_min: -98.7927170868347
queue_len: 0.06407307618007414
wait_time: 0.6047840555320271
delay_time: 4.152923059145929
pressure: 0.7907824933687002
total_envstep_count: 1553472
total_train_sample_count: 1553472
total_episode_count: 13392
total_duration: 49940.186165332794
[2025-02-21 07:33:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.734039465806266
avg_train_sample_per_sec: 31.734039465806266
avg_episode_per_sec: 0.27356930573970917
collect_time: 21.93228507041931
reward_mean: -96.10655929038285
reward_std: 1.0182740992486863
reward_max: -94.88655462184875
reward_min: -97.44887955182074
queue_len: 0.06373114011298597
wait_time: 0.6024865516498377
delay_time: 4.126983853888683
pressure: 0.7869142351900972
total_envstep_count: 1554168
total_train_sample_count: 1554168
total_episode_count: 13398
total_duration: 49962.11845040321
[2025-02-21 07:34:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.57401153803576
avg_train_sample_per_sec: 32.57401153803576
avg_episode_per_sec: 0.28081044429341173
collect_time: 21.366726636886597
reward_mean: -97.39227357609711
reward_std: 2.101093177154539
reward_max: -93.34663865546219
reward_min: -99.74649859943979
queue_len: 0.06458373579316785
wait_time: 0.6083510880037248
delay_time: 4.193807131100037
pressure: 0.7973032714412026
total_envstep_count: 1554864
total_train_sample_count: 1554864
total_episode_count: 13404
total_duration: 49983.4851770401
[2025-02-21 07:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80552756378087
avg_train_sample_per_sec: 31.80552756378087
avg_episode_per_sec: 0.2741855824463868
collect_time: 21.882988691329956
reward_mean: -97.15312791783379
reward_std: 2.785403492427212
reward_max: -93.9033613445378
reward_min: -101.6820728291316
queue_len: 0.06442515113914708
wait_time: 0.607209417807795
delay_time: 4.220244090112781
pressure: 0.7895667550839964
total_envstep_count: 1555560
total_train_sample_count: 1555560
total_episode_count: 13410
total_duration: 50005.36816573143
[2025-02-21 07:34:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53282285751814
avg_train_sample_per_sec: 31.53282285751814
avg_episode_per_sec: 0.27183467980619086
collect_time: 22.07223892211914
reward_mean: -98.84232026143792
reward_std: 3.0589387821209133
reward_max: -94.98669467787117
reward_min: -103.20238095238099
queue_len: 0.06554530521315512
wait_time: 0.6243203846525348
delay_time: 4.244186490521355
pressure: 0.8017241379310346
total_envstep_count: 1556256
total_train_sample_count: 1556256
total_episode_count: 13416
total_duration: 50027.44040465355
[2025-02-21 07:35:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53110593930373
avg_train_sample_per_sec: 31.53110593930373
avg_episode_per_sec: 0.2718198787871011
collect_time: 22.07344079017639
reward_mean: -98.08181605975723
reward_std: 4.2428024169231096
reward_max: -91.67647058823528
reward_min: -104.2724089635854
queue_len: 0.06504099208206714
wait_time: 0.6137894813097653
delay_time: 4.20622179409422
pressure: 0.8091290893015031
total_envstep_count: 1556952
total_train_sample_count: 1556952
total_episode_count: 13422
total_duration: 50049.513845443726
[2025-02-21 07:35:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.643719475732656
avg_train_sample_per_sec: 31.643719475732656
avg_episode_per_sec: 0.2727906851356264
collect_time: 21.99488592147827
reward_mean: -95.81792717086834
reward_std: 1.8316702384856862
reward_max: -93.63585434173666
reward_min: -99.37114845938376
queue_len: 0.06353973950322835
wait_time: 0.597644882444578
delay_time: 4.174277838031103
pressure: 0.7843722369584439
total_envstep_count: 1557648
total_train_sample_count: 1557648
total_episode_count: 13428
total_duration: 50071.508731365204
[2025-02-21 07:36:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.957858878893834
avg_train_sample_per_sec: 31.957858878893834
avg_episode_per_sec: 0.27549878343873996
collect_time: 21.778680562973022
reward_mean: -96.71603641456583
reward_std: 2.1823569810486383
reward_max: -93.10714285714285
reward_min: -99.6141456582633
queue_len: 0.06413530266217893
wait_time: 0.6077594720469973
delay_time: 4.2013805306695415
pressure: 0.7912245800176834
total_envstep_count: 1558344
total_train_sample_count: 1558344
total_episode_count: 13434
total_duration: 50093.28741192818
[2025-02-21 07:36:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0427061105317
avg_train_sample_per_sec: 32.0427061105317
avg_episode_per_sec: 0.2762302250907905
collect_time: 21.721011877059937
reward_mean: -96.18674136321196
reward_std: 2.5950011199922183
reward_max: -93.0448179271709
reward_min: -101.40546218487397
queue_len: 0.06378431124881428
wait_time: 0.6000662975181231
delay_time: 4.166988055952402
pressure: 0.7841511936339524
total_envstep_count: 1559040
total_train_sample_count: 1559040
total_episode_count: 13440
total_duration: 50115.00842380524
[2025-02-21 07:36:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77045209622843
avg_train_sample_per_sec: 31.77045209622843
avg_episode_per_sec: 0.27388320772610714
collect_time: 21.907148122787476
reward_mean: -96.57492997198881
reward_std: 1.863416736886846
reward_max: -94.21708683473392
reward_min: -99.68907563025205
queue_len: 0.06404173075065571
wait_time: 0.6046517855594936
delay_time: 4.179050685675591
pressure: 0.7891246684350133
total_envstep_count: 1559736
total_train_sample_count: 1559736
total_episode_count: 13446
total_duration: 50136.915571928024
[2025-02-21 07:37:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.793231679003274
avg_train_sample_per_sec: 31.793231679003274
avg_episode_per_sec: 0.2740795834396834
collect_time: 21.891451835632324
reward_mean: -97.5514705882353
reward_std: 3.023646687000107
reward_max: -93.97268907563023
reward_min: -103.03151260504204
queue_len: 0.06468930410360431
wait_time: 0.6129395170977322
delay_time: 4.211270173801255
pressure: 0.7924403183023871
total_envstep_count: 1560432
total_train_sample_count: 1560432
total_episode_count: 13452
total_duration: 50158.80702376366
[2025-02-21 07:37:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.773091173347602
avg_train_sample_per_sec: 31.773091173347602
avg_episode_per_sec: 0.27390595839092763
collect_time: 21.905328512191772
reward_mean: -97.4983660130719
reward_std: 2.0434122338993963
reward_max: -94.60644257703078
reward_min: -100.3914565826331
queue_len: 0.06465408886808482
wait_time: 0.6055269035111837
delay_time: 4.238012287682383
pressure: 0.7957559681697611
total_envstep_count: 1561128
total_train_sample_count: 1561128
total_episode_count: 13458
total_duration: 50180.71235227585
[2025-02-21 07:37:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12654199221421
avg_train_sample_per_sec: 32.12654199221421
avg_episode_per_sec: 0.27695294820874317
collect_time: 21.664329767227173
reward_mean: -96.13258636788049
reward_std: 1.9287174913118796
reward_max: -93.65476190476193
reward_min: -99.85994397759104
queue_len: 0.06374839944819662
wait_time: 0.601583261509732
delay_time: 4.137464554006505
pressure: 0.791445623342175
total_envstep_count: 1561824
total_train_sample_count: 1561824
total_episode_count: 13464
total_duration: 50202.376682043076
[2025-02-21 07:38:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.10542345846685
avg_train_sample_per_sec: 32.10542345846685
avg_episode_per_sec: 0.2767708918833349
collect_time: 21.678580284118652
reward_mean: -96.56139122315592
reward_std: 1.8708255770013522
reward_max: -93.43907563025206
reward_min: -99.47619047619048
queue_len: 0.06403275280050127
wait_time: 0.601063546550362
delay_time: 4.164543280997534
pressure: 0.7906719717064545
total_envstep_count: 1562520
total_train_sample_count: 1562520
total_episode_count: 13470
total_duration: 50224.055262327194
[2025-02-21 07:38:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.77702905702207
avg_train_sample_per_sec: 30.77702905702207
avg_episode_per_sec: 0.2653192160088109
collect_time: 22.61426854133606
reward_mean: -97.10912698412699
reward_std: 2.3315965378912624
reward_max: -94.41806722689074
reward_min: -101.8249299719888
queue_len: 0.06439597280114522
wait_time: 0.6061201447864734
delay_time: 4.221243953392536
pressure: 0.7922192749778957
total_envstep_count: 1563216
total_train_sample_count: 1563216
total_episode_count: 13476
total_duration: 50246.66953086853
[2025-02-21 07:38:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.646768093148598
avg_train_sample_per_sec: 31.646768093148598
avg_episode_per_sec: 0.27281696632024655
collect_time: 21.992767095565796
reward_mean: -95.68837535014005
reward_std: 2.2760754806153316
reward_max: -91.77871148459383
reward_min: -98.82072829131654
queue_len: 0.06345382980778519
wait_time: 0.5974058058236557
delay_time: 4.131920067831539
pressure: 0.7760831122900088
total_envstep_count: 1563912
total_train_sample_count: 1563912
total_episode_count: 13482
total_duration: 50268.662297964096
[2025-02-21 07:39:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.08946775761759
avg_train_sample_per_sec: 32.08946775761759
avg_episode_per_sec: 0.2766333427380827
collect_time: 21.689359426498413
reward_mean: -97.01785714285712
reward_std: 1.6312179461015934
reward_max: -93.91596638655464
reward_min: -98.58683473389355
queue_len: 0.0643354490337249
wait_time: 0.606859819524627
delay_time: 4.147479890237829
pressure: 0.7916666666666666
total_envstep_count: 1564608
total_train_sample_count: 1564608
total_episode_count: 13488
total_duration: 50290.351657390594
[2025-02-21 07:39:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76049311546501
avg_train_sample_per_sec: 31.76049311546501
avg_episode_per_sec: 0.2737973544436639
collect_time: 21.91401743888855
reward_mean: -97.93253968253968
reward_std: 2.0015276286350328
reward_max: -95.40406162464987
reward_min: -100.97128851540616
queue_len: 0.06494200244200243
wait_time: 0.6142638421416312
delay_time: 4.211664148512305
pressure: 0.79973474801061
total_envstep_count: 1565304
total_train_sample_count: 1565304
total_episode_count: 13494
total_duration: 50312.26567482948
[2025-02-21 07:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.954613267909927
avg_train_sample_per_sec: 31.954613267909927
avg_episode_per_sec: 0.2754708040337063
collect_time: 21.780892610549927
reward_mean: -96.58041549953316
reward_std: 1.1316790524671176
reward_max: -95.07422969187675
reward_min: -97.90686274509807
queue_len: 0.06404536836839068
wait_time: 0.6006776494859659
delay_time: 4.135299660829473
pressure: 0.7911140583554377
total_envstep_count: 1566000
total_train_sample_count: 1566000
total_episode_count: 13500
total_duration: 50334.04656744003
[2025-02-21 07:40:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.86256565489119
avg_train_sample_per_sec: 31.86256565489119
avg_episode_per_sec: 0.27467729012837233
collect_time: 21.843815326690674
reward_mean: -97.05590569561157
reward_std: 2.3794126198983303
reward_max: -94.17366946778716
reward_min: -100.77871148459387
queue_len: 0.0643606801695037
wait_time: 0.6058860215173605
delay_time: 4.217069346416562
pressure: 0.7967506631299736
total_envstep_count: 1566696
total_train_sample_count: 1566696
total_episode_count: 13506
total_duration: 50355.89038276672
[2025-02-21 07:40:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.968149633296107
avg_train_sample_per_sec: 31.968149633296107
avg_episode_per_sec: 0.27558749683875955
collect_time: 21.77166986465454
reward_mean: -96.23669467787114
reward_std: 1.2806936917041072
reward_max: -94.68347338935575
reward_min: -98.17226890756301
queue_len: 0.06381743678903921
wait_time: 0.6008780280458779
delay_time: 4.1710626711049565
pressure: 0.7916666666666666
total_envstep_count: 1567392
total_train_sample_count: 1567392
total_episode_count: 13512
total_duration: 50377.66205263138
[2025-02-21 07:41:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.75812837766647
avg_train_sample_per_sec: 31.75812837766647
avg_episode_per_sec: 0.2737769687729868
collect_time: 21.91564917564392
reward_mean: -97.04353408029878
reward_std: 1.673071603885696
reward_max: -93.67787114845936
reward_min: -98.93697478991598
queue_len: 0.06435247618056948
wait_time: 0.6082376252888423
delay_time: 4.147212620854223
pressure: 0.7898983200707338
total_envstep_count: 1568088
total_train_sample_count: 1568088
total_episode_count: 13518
total_duration: 50399.57770180702
[2025-02-21 07:41:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.016694805048594
avg_train_sample_per_sec: 32.016694805048594
avg_episode_per_sec: 0.2760059896986948
collect_time: 21.738658666610718
reward_mean: -94.68604108309991
reward_std: 1.333712332233179
reward_max: -93.32843137254902
reward_min: -97.24929971988797
queue_len: 0.06278915191186996
wait_time: 0.5961328718047785
delay_time: 4.076141660385943
pressure: 0.7763041556145005
total_envstep_count: 1568784
total_train_sample_count: 1568784
total_episode_count: 13524
total_duration: 50421.31636047363
[2025-02-21 07:41:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.030402265765645
avg_train_sample_per_sec: 32.030402265765645
avg_episode_per_sec: 0.27612415746349694
collect_time: 21.729355573654175
reward_mean: -96.52147525676935
reward_std: 1.7525227986352148
reward_max: -93.94047619047619
reward_min: -98.88165266106441
queue_len: 0.06400628332677012
wait_time: 0.6025792722040187
delay_time: 4.112296309735967
pressure: 0.7992926613616268
total_envstep_count: 1569480
total_train_sample_count: 1569480
total_episode_count: 13530
total_duration: 50443.04571604729
[2025-02-21 07:42:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.979914509765017
avg_train_sample_per_sec: 31.979914509765017
avg_episode_per_sec: 0.2756889181876295
collect_time: 21.763660430908203
reward_mean: -94.90697945845004
reward_std: 3.681640054577079
reward_max: -92.25280112044817
reward_min: -102.75980392156863
queue_len: 0.06293566277085548
wait_time: 0.5946941552925326
delay_time: 4.131370138867057
pressure: 0.7812776304155614
total_envstep_count: 1570176
total_train_sample_count: 1570176
total_episode_count: 13536
total_duration: 50464.809376478195
[2025-02-21 07:42:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22473035767833
avg_train_sample_per_sec: 32.22473035767833
avg_episode_per_sec: 0.27779939963515804
collect_time: 21.598318815231323
reward_mean: -95.12745098039215
reward_std: 1.0313917643848654
reward_max: -93.62114845938376
reward_min: -96.32983193277308
queue_len: 0.06308186404535288
wait_time: 0.5929202361758142
delay_time: 4.117078479692392
pressure: 0.7756410256410257
total_envstep_count: 1570872
total_train_sample_count: 1570872
total_episode_count: 13542
total_duration: 50486.40769529343
[2025-02-21 07:43:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.960302442462332
avg_train_sample_per_sec: 31.960302442462332
avg_episode_per_sec: 0.27551984864191664
collect_time: 21.777015447616577
reward_mean: -97.53816526610643
reward_std: 3.3017815863863937
reward_max: -93.06932773109239
reward_min: -101.56512605042016
queue_len: 0.06468048094569391
wait_time: 0.6116768767630838
delay_time: 4.211842492740375
pressure: 0.8044871794871794
total_envstep_count: 1571568
total_train_sample_count: 1571568
total_episode_count: 13548
total_duration: 50508.18471074104
[2025-02-21 07:43:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.955051201510933
avg_train_sample_per_sec: 31.955051201510933
avg_episode_per_sec: 0.2754745793233701
collect_time: 21.78059411048889
reward_mean: -96.3046218487395
reward_std: 2.0573222229971964
reward_max: -93.0644257703081
reward_min: -99.57072829131654
queue_len: 0.06386248133205537
wait_time: 0.6055950120985618
delay_time: 4.16833968584769
pressure: 0.7906719717064545
total_envstep_count: 1572264
total_train_sample_count: 1572264
total_episode_count: 13554
total_duration: 50529.96530485153
[2025-02-21 07:43:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.406703700276115
avg_train_sample_per_sec: 31.406703700276115
avg_episode_per_sec: 0.27074744569203546
collect_time: 22.160873889923096
reward_mean: -96.89519140989728
reward_std: 2.898238628542273
reward_max: -94.0658263305322
reward_min: -102.2773109243697
queue_len: 0.06425410570948097
wait_time: 0.6053680866687966
delay_time: 4.202805139862179
pressure: 0.7898983200707339
total_envstep_count: 1572960
total_train_sample_count: 1572960
total_episode_count: 13560
total_duration: 50552.126178741455
[2025-02-21 07:44:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03287240188036
avg_train_sample_per_sec: 32.03287240188036
avg_episode_per_sec: 0.27614545174034794
collect_time: 21.72767996788025
reward_mean: -96.65732959850607
reward_std: 1.58846909814617
reward_max: -94.02310924369755
reward_min: -98.19607843137254
queue_len: 0.06409637241280244
wait_time: 0.6034954874965016
delay_time: 4.175008180388733
pressure: 0.7894562334217508
total_envstep_count: 1573656
total_train_sample_count: 1573656
total_episode_count: 13566
total_duration: 50573.853858709335
[2025-02-21 07:44:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.976738673989708
avg_train_sample_per_sec: 31.976738673989708
avg_episode_per_sec: 0.27566154029301476
collect_time: 21.765821933746338
reward_mean: -97.57574696545284
reward_std: 2.5988648996076917
reward_max: -94.86134453781513
reward_min: -102.42577030812325
queue_len: 0.06470540249698466
wait_time: 0.6147593321148089
delay_time: 4.158510297750799
pressure: 0.8058134394341291
total_envstep_count: 1574352
total_train_sample_count: 1574352
total_episode_count: 13572
total_duration: 50595.61968064308
[2025-02-21 07:44:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.744142028293503
avg_train_sample_per_sec: 31.744142028293503
avg_episode_per_sec: 0.27365639679563364
collect_time: 21.925305128097534
reward_mean: -96.5364145658263
reward_std: 2.8806834510781845
reward_max: -92.72759103641454
reward_min: -101.44117647058823
queue_len: 0.06401619003038879
wait_time: 0.6001207069919038
delay_time: 4.141422360198112
pressure: 0.794871794871795
total_envstep_count: 1575048
total_train_sample_count: 1575048
total_episode_count: 13578
total_duration: 50617.54498577118
[2025-02-21 07:45:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.77980322323313
avg_train_sample_per_sec: 31.77980322323313
avg_episode_per_sec: 0.27396382088994076
collect_time: 21.900701999664307
reward_mean: -97.40779645191411
reward_std: 2.737883464324114
reward_max: -93.96008403361344
reward_min: -101.77170868347343
queue_len: 0.06459402947739663
wait_time: 0.610661904018902
delay_time: 4.231340625713165
pressure: 0.788129973474801
total_envstep_count: 1575744
total_train_sample_count: 1575744
total_episode_count: 13584
total_duration: 50639.44568777084
[2025-02-21 07:45:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.987396996484463
avg_train_sample_per_sec: 31.987396996484463
avg_episode_per_sec: 0.27575342238348677
collect_time: 21.758569478988647
reward_mean: -95.54131652661066
reward_std: 1.672812162008053
reward_max: -94.05112044817928
reward_min: -98.35714285714286
queue_len: 0.0633563106940389
wait_time: 0.6003302182942143
delay_time: 4.172679265994653
pressure: 0.7866931918656057
total_envstep_count: 1576440
total_train_sample_count: 1576440
total_episode_count: 13590
total_duration: 50661.20425724983
[2025-02-21 07:46:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13909496874502
avg_train_sample_per_sec: 32.13909496874502
avg_episode_per_sec: 0.277061163523664
collect_time: 21.65586805343628
reward_mean: -95.07271241830063
reward_std: 1.3764377124338898
reward_max: -93.54271708683471
reward_min: -97.08053221288513
queue_len: 0.0630455652641251
wait_time: 0.5998785345261005
delay_time: 4.114745031312212
pressure: 0.7858090185676393
total_envstep_count: 1577136
total_train_sample_count: 1577136
total_episode_count: 13596
total_duration: 50682.86012530327
[2025-02-21 07:46:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.733990825083705
avg_train_sample_per_sec: 31.733990825083705
avg_episode_per_sec: 0.27356888642313537
collect_time: 21.932318687438965
reward_mean: -95.07796451914096
reward_std: 2.8593948138842333
reward_max: -91.94747899159664
reward_min: -100.99159663865547
queue_len: 0.06304904808961603
wait_time: 0.5993314213395349
delay_time: 4.111722660137672
pressure: 0.7824933687002652
total_envstep_count: 1577832
total_train_sample_count: 1577832
total_episode_count: 13602
total_duration: 50704.79244399071
[2025-02-21 07:46:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.997906350508437
avg_train_sample_per_sec: 31.997906350508437
avg_episode_per_sec: 0.27584402026300375
collect_time: 21.751423120498657
reward_mean: -95.73599439775911
reward_std: 1.3095303005176666
reward_max: -93.81442577030813
reward_min: -97.59103641456583
queue_len: 0.0634854074255697
wait_time: 0.5970682813355227
delay_time: 4.165809528092401
pressure: 0.7935455349248453
total_envstep_count: 1578528
total_train_sample_count: 1578528
total_episode_count: 13608
total_duration: 50726.543867111206
[2025-02-21 07:47:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.951100789127405
avg_train_sample_per_sec: 31.951100789127405
avg_episode_per_sec: 0.2754405240442018
collect_time: 21.783287048339844
reward_mean: -95.76563958916898
reward_std: 2.150423237041887
reward_max: -93.562324929972
reward_min: -99.48389355742295
queue_len: 0.063505066040563
wait_time: 0.600588876134008
delay_time: 4.156936270454212
pressure: 0.7877984084880637
total_envstep_count: 1579224
total_train_sample_count: 1579224
total_episode_count: 13614
total_duration: 50748.327154159546
[2025-02-21 07:47:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.183115372702986
avg_train_sample_per_sec: 32.183115372702986
avg_episode_per_sec: 0.2774406497646809
collect_time: 21.6262469291687
reward_mean: -96.22327264239027
reward_std: 2.4517460927691657
reward_max: -92.43627450980391
reward_min: -99.32492997198878
queue_len: 0.06380853623500682
wait_time: 0.6039703127050997
delay_time: 4.1664656320362985
pressure: 0.7891246684350133
total_envstep_count: 1579920
total_train_sample_count: 1579920
total_episode_count: 13620
total_duration: 50769.953401088715
[2025-02-21 07:47:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.037742089728006
avg_train_sample_per_sec: 32.037742089728006
avg_episode_per_sec: 0.27618743180800004
collect_time: 21.724377393722534
reward_mean: -94.27882819794586
reward_std: 1.4032209446697534
reward_max: -92.47759103641461
reward_min: -96.77240896358542
queue_len: 0.06251911684213915
wait_time: 0.5911262714634926
delay_time: 4.090159578811114
pressure: 0.7695623342175066
total_envstep_count: 1580616
total_train_sample_count: 1580616
total_episode_count: 13626
total_duration: 50791.67777848244
[2025-02-21 07:48:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.801309513420296
avg_train_sample_per_sec: 31.801309513420296
avg_episode_per_sec: 0.2741492199432784
collect_time: 21.88589119911194
reward_mean: -96.44362745098039
reward_std: 1.3408216051783768
reward_max: -94.41246498599438
reward_min: -98.48529411764706
queue_len: 0.06395466011338223
wait_time: 0.5996180191793782
delay_time: 4.197537593609389
pressure: 0.7797303271441202
total_envstep_count: 1581312
total_train_sample_count: 1581312
total_episode_count: 13632
total_duration: 50813.56366968155
[2025-02-21 07:48:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.03185590247178
avg_train_sample_per_sec: 32.03185590247178
avg_episode_per_sec: 0.2761366888144119
collect_time: 21.72836947441101
reward_mean: -95.58391690009337
reward_std: 1.990407334676259
reward_max: -92.81022408963587
reward_min: -97.9446778711484
queue_len: 0.06338456027857652
wait_time: 0.6039658237300225
delay_time: 4.210185372634714
pressure: 0.7821618037135277
total_envstep_count: 1582008
total_train_sample_count: 1582008
total_episode_count: 13638
total_duration: 50835.29203915596
[2025-02-21 07:49:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.730258353131624
avg_train_sample_per_sec: 31.730258353131624
avg_episode_per_sec: 0.2735367099407899
collect_time: 21.934898614883423
reward_mean: -98.83788515406162
reward_std: 2.5838851001353196
reward_max: -96.20378151260509
reward_min: -103.25980392156866
queue_len: 0.06554236416051833
wait_time: 0.6156133209251871
delay_time: 4.270783366433413
pressure: 0.8011715296198054
total_envstep_count: 1582704
total_train_sample_count: 1582704
total_episode_count: 13644
total_duration: 50857.22693777084
[2025-02-21 07:49:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.4920987910804
avg_train_sample_per_sec: 31.4920987910804
avg_episode_per_sec: 0.2714836102679345
collect_time: 22.100781679153442
reward_mean: -97.9095471521942
reward_std: 2.822075140201353
reward_max: -94.94187675070026
reward_min: -101.68417366946777
queue_len: 0.06492675540596432
wait_time: 0.6189993238674781
delay_time: 4.239509921925427
pressure: 0.7929929266136163
total_envstep_count: 1583400
total_train_sample_count: 1583400
total_episode_count: 13650
total_duration: 50879.32771945
[2025-02-21 07:49:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.943066576671594
avg_train_sample_per_sec: 31.943066576671594
avg_episode_per_sec: 0.2753712635919965
collect_time: 21.788765907287598
reward_mean: -96.2421802054155
reward_std: 2.243590577238418
reward_max: -93.48249299719889
reward_min: -99.18907563025212
queue_len: 0.06382107440677419
wait_time: 0.6031465857784316
delay_time: 4.187935242947193
pressure: 0.7755305039787799
total_envstep_count: 1584096
total_train_sample_count: 1584096
total_episode_count: 13656
total_duration: 50901.116485357285
[2025-02-21 07:50:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.12845696832941
avg_train_sample_per_sec: 32.12845696832941
avg_episode_per_sec: 0.2769694566235294
collect_time: 21.66303849220276
reward_mean: -96.75700280112045
reward_std: 3.303399434259531
reward_max: -93.17156862745098
reward_min: -101.13165266106444
queue_len: 0.06416246870100825
wait_time: 0.6059151998553621
delay_time: 4.202654744117984
pressure: 0.7892351900972591
total_envstep_count: 1584792
total_train_sample_count: 1584792
total_episode_count: 13662
total_duration: 50922.77952384949
[2025-02-21 07:50:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.895132460262435
avg_train_sample_per_sec: 31.895132460262435
avg_episode_per_sec: 0.27495803845053823
collect_time: 21.8215115070343
reward_mean: -97.42763772175537
reward_std: 0.9917696879162505
reward_max: -96.61904761904762
reward_min: -99.5910364145658
queue_len: 0.06460718681814016
wait_time: 0.6134055965445419
delay_time: 4.20861529465169
pressure: 0.792661361626879
total_envstep_count: 1585488
total_train_sample_count: 1585488
total_episode_count: 13668
total_duration: 50944.60103535652
[2025-02-21 07:50:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639343625149362
avg_train_sample_per_sec: 31.639343625149362
avg_episode_per_sec: 0.27275296228577034
collect_time: 21.99792790412903
reward_mean: -96.60854341736695
reward_std: 1.9105047270233113
reward_max: -94.01540616246497
reward_min: -99.19607843137257
queue_len: 0.06406402083379771
wait_time: 0.6016923126456596
delay_time: 4.153577042121379
pressure: 0.7832670203359858
total_envstep_count: 1586184
total_train_sample_count: 1586184
total_episode_count: 13674
total_duration: 50966.59896326065
[2025-02-21 07:51:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.188332528855355
avg_train_sample_per_sec: 32.188332528855355
avg_episode_per_sec: 0.27748562524875303
collect_time: 21.62274169921875
reward_mean: -97.06267507002798
reward_std: 2.4669997619888533
reward_max: -93.63025210084038
reward_min: -100.37324929971983
queue_len: 0.0643651691445809
wait_time: 0.6077013475593597
delay_time: 4.210534445412751
pressure: 0.7842617152961981
total_envstep_count: 1586880
total_train_sample_count: 1586880
total_episode_count: 13680
total_duration: 50988.22170495987
[2025-02-21 07:51:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6781717551045
avg_train_sample_per_sec: 31.6781717551045
avg_episode_per_sec: 0.2730876875440043
collect_time: 21.970964908599854
reward_mean: -96.41059757236228
reward_std: 1.88422913142401
reward_max: -94.53361344537814
reward_min: -100.36204481792718
queue_len: 0.06393275701085033
wait_time: 0.6045909522075851
delay_time: 4.14100898582197
pressure: 0.7844827586206896
total_envstep_count: 1587576
total_train_sample_count: 1587576
total_episode_count: 13686
total_duration: 51010.19266986847
[2025-02-21 07:52:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.881214262803415
avg_train_sample_per_sec: 31.881214262803415
avg_episode_per_sec: 0.2748380539896846
collect_time: 21.831037998199463
reward_mean: -97.16619981325863
reward_std: 2.4939989183707683
reward_max: -94.99089635854341
reward_min: -102.41176470588236
queue_len: 0.0644338195048134
wait_time: 0.6058232532624014
delay_time: 4.211516511830817
pressure: 0.7883510167992928
total_envstep_count: 1588272
total_train_sample_count: 1588272
total_episode_count: 13692
total_duration: 51032.02370786667
[2025-02-21 07:52:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30075631814395
avg_train_sample_per_sec: 31.30075631814395
avg_episode_per_sec: 0.2698341061908961
collect_time: 22.235884428024292
reward_mean: -96.80567226890754
reward_std: 0.7490447341827023
reward_max: -95.34453781512603
reward_min: -97.60434173669466
queue_len: 0.06419474288389095
wait_time: 0.6096859389202188
delay_time: 4.18272808248647
pressure: 0.7869142351900974
total_envstep_count: 1588968
total_train_sample_count: 1588968
total_episode_count: 13698
total_duration: 51054.25959229469
[2025-02-21 07:52:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.504412706229196
avg_train_sample_per_sec: 31.504412706229196
avg_episode_per_sec: 0.27158976470887236
collect_time: 22.092143297195435
reward_mean: -97.78069561157797
reward_std: 1.826327194452606
reward_max: -94.2156862745098
reward_min: -100.2002801120448
queue_len: 0.06484131008725329
wait_time: 0.6106966548776894
delay_time: 4.210869799575474
pressure: 0.7917771883289125
total_envstep_count: 1589664
total_train_sample_count: 1589664
total_episode_count: 13704
total_duration: 51076.35173559189
[2025-02-21 07:53:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04404654733998
avg_train_sample_per_sec: 32.04404654733998
avg_episode_per_sec: 0.27624178058051707
collect_time: 21.72010326385498
reward_mean: -95.63048552754435
reward_std: 0.712900593381729
reward_max: -94.63725490196082
reward_min: -96.90476190476193
queue_len: 0.06341544133126283
wait_time: 0.5931150422149408
delay_time: 4.1646413407167335
pressure: 0.7779619805481874
total_envstep_count: 1590360
total_train_sample_count: 1590360
total_episode_count: 13710
total_duration: 51098.07183885574
[2025-02-21 07:53:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.7097817803346
avg_train_sample_per_sec: 31.7097817803346
avg_episode_per_sec: 0.27336018776150517
collect_time: 21.949063062667847
reward_mean: -97.76832399626517
reward_std: 1.464368902513333
reward_max: -94.59453781512607
reward_min: -98.7738095238095
queue_len: 0.06483310609831908
wait_time: 0.6169224763291701
delay_time: 4.208299989197821
pressure: 0.7973032714412024
total_envstep_count: 1591056
total_train_sample_count: 1591056
total_episode_count: 13716
total_duration: 51120.02090191841
[2025-02-21 07:53:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.940914667361234
avg_train_sample_per_sec: 31.940914667361234
avg_episode_per_sec: 0.2753527126496658
collect_time: 21.790233850479126
reward_mean: -94.6816059757236
reward_std: 2.2133378767634952
reward_max: -90.17226890756301
reward_min: -97.39215686274508
queue_len: 0.06278621085923315
wait_time: 0.592940978336516
delay_time: 4.094247710734632
pressure: 0.7694518125552609
total_envstep_count: 1591752
total_train_sample_count: 1591752
total_episode_count: 13722
total_duration: 51141.81113576889
[2025-02-21 07:54:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16087539266923
avg_train_sample_per_sec: 32.16087539266923
avg_episode_per_sec: 0.2772489257988727
collect_time: 21.641201972961426
reward_mean: -95.99988328664797
reward_std: 3.020869215740122
reward_max: -92.0595238095238
reward_min: -100.14775910364143
queue_len: 0.06366040005745888
wait_time: 0.5986386486513261
delay_time: 4.15542001640209
pressure: 0.7843722369584438
total_envstep_count: 1592448
total_train_sample_count: 1592448
total_episode_count: 13728
total_duration: 51163.45233774185
[2025-02-21 07:54:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.731347891705248
avg_train_sample_per_sec: 31.731347891705248
avg_episode_per_sec: 0.2735461025147004
collect_time: 21.93414545059204
reward_mean: -98.7095004668534
reward_std: 4.880761205370667
reward_max: -93.9628851540616
reward_min: -107.61974789915966
queue_len: 0.06545722842629535
wait_time: 0.620007872733532
delay_time: 4.2620697349152685
pressure: 0.8044871794871796
total_envstep_count: 1593144
total_train_sample_count: 1593144
total_episode_count: 13734
total_duration: 51185.386483192444
[2025-02-21 07:55:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80635162441018
avg_train_sample_per_sec: 31.80635162441018
avg_episode_per_sec: 0.27419268641732913
collect_time: 21.882421731948853
reward_mean: -96.71556956115778
reward_std: 1.9465832452917133
reward_max: -95.50140056022407
reward_min: -101.0378151260504
queue_len: 0.06413499307769083
wait_time: 0.6097516482278146
delay_time: 4.15727754936685
pressure: 0.7849248452696728
total_envstep_count: 1593840
total_train_sample_count: 1593840
total_episode_count: 13740
total_duration: 51207.26890492439
[2025-02-21 07:55:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.962005530524504
avg_train_sample_per_sec: 31.962005530524504
avg_episode_per_sec: 0.2755345304355561
collect_time: 21.77585506439209
reward_mean: -96.39939309056956
reward_std: 2.7578650960241164
reward_max: -93.08963585434171
reward_min: -101.11624649859948
queue_len: 0.06392532698313631
wait_time: 0.6007660358573137
delay_time: 4.250769604179084
pressure: 0.7813881520778073
total_envstep_count: 1594536
total_train_sample_count: 1594536
total_episode_count: 13746
total_duration: 51229.044759988785
[2025-02-21 07:55:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.095107665558935
avg_train_sample_per_sec: 32.095107665558935
avg_episode_per_sec: 0.27668196263412875
collect_time: 21.685548067092896
reward_mean: -97.4094304388422
reward_std: 3.7270230963382156
reward_max: -94.21918767507002
reward_min: -104.32142857142856
queue_len: 0.0645951130231049
wait_time: 0.6136092257415786
delay_time: 4.270213435649432
pressure: 0.782161803713528
total_envstep_count: 1595232
total_train_sample_count: 1595232
total_episode_count: 13752
total_duration: 51250.73030805588
[2025-02-21 07:56:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.959009938318616
avg_train_sample_per_sec: 31.959009938318616
avg_episode_per_sec: 0.27550870636481567
collect_time: 21.77789616584778
reward_mean: -95.03921568627452
reward_std: 2.030895672651329
reward_max: -93.3144257703081
reward_min: -99.10784313725489
queue_len: 0.06302335257710512
wait_time: 0.5935670355675428
delay_time: 4.139370776728454
pressure: 0.772656940760389
total_envstep_count: 1595928
total_train_sample_count: 1595928
total_episode_count: 13758
total_duration: 51272.508204221725
[2025-02-21 07:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.135747351111874
avg_train_sample_per_sec: 32.135747351111874
avg_episode_per_sec: 0.2770323047509644
collect_time: 21.65812397003174
reward_mean: -94.84675536881419
reward_std: 1.8339630857030256
reward_max: -92.93067226890756
reward_min: -98.0721288515406
queue_len: 0.06289572637189271
wait_time: 0.5933875539605763
delay_time: 4.115930578491686
pressure: 0.7727674624226348
total_envstep_count: 1596624
total_train_sample_count: 1596624
total_episode_count: 13764
total_duration: 51294.16632819176
[2025-02-21 07:56:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.123682328296816
avg_train_sample_per_sec: 32.123682328296816
avg_episode_per_sec: 0.27692829593359325
collect_time: 21.666258335113525
reward_mean: -94.73214285714285
reward_std: 2.3578451044304227
reward_max: -92.83473389355743
reward_min: -99.50700280112044
queue_len: 0.0628197233800682
wait_time: 0.5949056014978936
delay_time: 4.112662439282876
pressure: 0.7745358090185676
total_envstep_count: 1597320
total_train_sample_count: 1597320
total_episode_count: 13770
total_duration: 51315.83258652687
[2025-02-21 07:57:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.862568089282647
avg_train_sample_per_sec: 31.862568089282647
avg_episode_per_sec: 0.2746773111145056
collect_time: 21.84381365776062
reward_mean: -95.39437441643322
reward_std: 2.4780285381537013
reward_max: -92.31022408963582
reward_min: -99.84733893557419
queue_len: 0.0632588689764146
wait_time: 0.5966008861546387
delay_time: 4.201417955660529
pressure: 0.7711096374889478
total_envstep_count: 1598016
total_train_sample_count: 1598016
total_episode_count: 13776
total_duration: 51337.67640018463
[2025-02-21 07:57:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87946372301688
avg_train_sample_per_sec: 31.87946372301688
avg_episode_per_sec: 0.27482296312945587
collect_time: 21.832236766815186
reward_mean: -96.10177404295051
reward_std: 2.3184776916214997
reward_max: -93.45028011204482
reward_min: -100.66036414565825
queue_len: 0.06372796687198311
wait_time: 0.604075416638804
delay_time: 4.1910906164554556
pressure: 0.7862511052166224
total_envstep_count: 1598712
total_train_sample_count: 1598712
total_episode_count: 13782
total_duration: 51359.50863695145
[2025-02-21 07:57:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.757855439660403
avg_train_sample_per_sec: 31.757855439660403
avg_episode_per_sec: 0.2737746158591414
collect_time: 21.91583752632141
reward_mean: -96.42892156862744
reward_std: 2.3851411343694133
reward_max: -92.27310924369746
reward_min: -98.52521008403365
queue_len: 0.06394490820200759
wait_time: 0.6002226376846053
delay_time: 4.168539032849802
pressure: 0.7829354553492486
total_envstep_count: 1599408
total_train_sample_count: 1599408
total_episode_count: 13788
total_duration: 51381.42447447777
[2025-02-21 07:58:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.11998521125532
avg_train_sample_per_sec: 32.11998521125532
avg_episode_per_sec: 0.27689642423495964
collect_time: 21.668752193450928
reward_mean: -97.2131185807656
reward_std: 2.755707018921686
reward_max: -91.81442577030806
reward_min: -99.91526610644257
queue_len: 0.06446493274586579
wait_time: 0.6069727404666553
delay_time: 4.267115664618539
pressure: 0.7907824933687002
total_envstep_count: 1600104
total_train_sample_count: 1600104
total_episode_count: 13794
total_duration: 51403.09322667122
[2025-02-21 07:58:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.902313491684772
avg_train_sample_per_sec: 31.902313491684772
avg_episode_per_sec: 0.2750199438938343
collect_time: 21.81659960746765
reward_mean: -95.57131185807657
reward_std: 1.6503092201291525
reward_max: -93.40056022408962
reward_min: -98.37254901960787
queue_len: 0.06337620149739824
wait_time: 0.5966365657668903
delay_time: 4.147611323230548
pressure: 0.7757515473032713
total_envstep_count: 1600800
total_train_sample_count: 1600800
total_episode_count: 13800
total_duration: 51424.90982627869
[2025-02-21 07:59:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.82053159892767
avg_train_sample_per_sec: 31.82053159892767
avg_episode_per_sec: 0.27431492757696263
collect_time: 21.8726704120636
reward_mean: -95.83613445378153
reward_std: 1.5124559009366503
reward_max: -93.57913165266113
reward_min: -98.51820728291312
queue_len: 0.0635518132982636
wait_time: 0.6018381269395467
delay_time: 4.215452844731117
pressure: 0.776635720601238
total_envstep_count: 1601496
total_train_sample_count: 1601496
total_episode_count: 13806
total_duration: 51446.78249669075
[2025-02-21 07:59:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94729784442416
avg_train_sample_per_sec: 31.94729784442416
avg_episode_per_sec: 0.2754077400381393
collect_time: 21.785880088806152
reward_mean: -98.01774042950512
reward_std: 2.196047119021291
reward_max: -95.17997198879553
reward_min: -100.18067226890753
queue_len: 0.06499850161107767
wait_time: 0.61269471316378
delay_time: 4.226012686236875
pressure: 0.7891246684350133
total_envstep_count: 1602192
total_train_sample_count: 1602192
total_episode_count: 13812
total_duration: 51468.568376779556
[2025-02-21 07:59:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.29850920580626
avg_train_sample_per_sec: 31.29850920580626
avg_episode_per_sec: 0.2698147345328126
collect_time: 22.237480878829956
reward_mean: -97.16900093370684
reward_std: 1.6931613980807876
reward_max: -93.921568627451
reward_min: -99.4481792717087
queue_len: 0.06443567701174192
wait_time: 0.6079579930999809
delay_time: 4.276824935317108
pressure: 0.7884615384615384
total_envstep_count: 1602888
total_train_sample_count: 1602888
total_episode_count: 13818
total_duration: 51490.805857658386
[2025-02-21 08:00:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.314474187290045
avg_train_sample_per_sec: 31.314474187290045
avg_episode_per_sec: 0.26995236368353487
collect_time: 22.22614359855652
reward_mean: -95.9520308123249
reward_std: 2.1731523461969275
reward_max: -93.31442577030813
reward_min: -98.87605042016806
queue_len: 0.06362866764743032
wait_time: 0.5989361593443744
delay_time: 4.156650159677818
pressure: 0.7891246684350133
total_envstep_count: 1603584
total_train_sample_count: 1603584
total_episode_count: 13824
total_duration: 51513.03200125694
[2025-02-21 08:00:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.991724510686115
avg_train_sample_per_sec: 31.991724510686115
avg_episode_per_sec: 0.27579072854039755
collect_time: 21.75562620162964
reward_mean: -96.38316993464049
reward_std: 3.381558965619566
reward_max: -92.1708683473389
reward_min: -101.4411764705882
queue_len: 0.0639145689221754
wait_time: 0.6024256409018073
delay_time: 4.195698442699141
pressure: 0.7874668435013263
total_envstep_count: 1604280
total_train_sample_count: 1604280
total_episode_count: 13830
total_duration: 51534.78762745857
[2025-02-21 08:00:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92801348808694
avg_train_sample_per_sec: 31.92801348808694
avg_episode_per_sec: 0.2752414955869564
collect_time: 21.799038648605347
reward_mean: -99.03618113912229
reward_std: 3.6823917607832755
reward_max: -94.01120448179275
reward_min: -105.44817927170865
queue_len: 0.06567386017183179
wait_time: 0.6198454956695323
delay_time: 4.344430118436191
pressure: 0.8068081343943413
total_envstep_count: 1604976
total_train_sample_count: 1604976
total_episode_count: 13836
total_duration: 51556.58666610718
[2025-02-21 08:01:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.589874412950806
avg_train_sample_per_sec: 31.589874412950806
avg_episode_per_sec: 0.2723265035599208
collect_time: 22.032376289367676
reward_mean: -97.57633053221288
reward_std: 2.603121499732306
reward_max: -93.47408963585431
reward_min: -101.95938375350137
queue_len: 0.06470578947759474
wait_time: 0.6135358542179029
delay_time: 4.253420310467491
pressure: 0.7925508399646332
total_envstep_count: 1605672
total_train_sample_count: 1605672
total_episode_count: 13842
total_duration: 51578.619042396545
[2025-02-21 08:01:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05370480509615
avg_train_sample_per_sec: 32.05370480509615
avg_episode_per_sec: 0.2763250414232427
collect_time: 21.713558673858643
reward_mean: -96.30835667600373
reward_std: 3.8359759919282856
reward_max: -91.85014005602237
reward_min: -102.21288515406162
queue_len: 0.06386495800796003
wait_time: 0.6033830309312054
delay_time: 4.176632024400332
pressure: 0.7796198054818745
total_envstep_count: 1606368
total_train_sample_count: 1606368
total_episode_count: 13848
total_duration: 51600.332601070404
[2025-02-21 08:02:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72345758521533
avg_train_sample_per_sec: 31.72345758521533
avg_episode_per_sec: 0.27347808263116663
collect_time: 21.939600944519043
reward_mean: -96.14997665732959
reward_std: 2.1694358552168636
reward_max: -92.89845938375349
reward_min: -98.33123249299716
queue_len: 0.06375993147037771
wait_time: 0.6054606524307337
delay_time: 4.194358147083314
pressure: 0.7843722369584438
total_envstep_count: 1607064
total_train_sample_count: 1607064
total_episode_count: 13854
total_duration: 51622.27220201492
[2025-02-21 08:02:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.785770871113318
avg_train_sample_per_sec: 31.785770871113318
avg_episode_per_sec: 0.2740152661302872
collect_time: 21.89659023284912
reward_mean: -99.69316059757237
reward_std: 2.7968330989647754
reward_max: -96.35364145658264
reward_min: -104.03291316526611
queue_len: 0.06610952294268724
wait_time: 0.6305947334725225
delay_time: 4.252209439079112
pressure: 0.813549955791335
total_envstep_count: 1607760
total_train_sample_count: 1607760
total_episode_count: 13860
total_duration: 51644.16879224777
[2025-02-21 08:02:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.00985108922904
avg_train_sample_per_sec: 32.00985108922904
avg_episode_per_sec: 0.2759469921485262
collect_time: 21.743306398391724
reward_mean: -96.21942110177405
reward_std: 3.1741430761083986
reward_max: -90.33823529411764
reward_min: -101.13305322128855
queue_len: 0.06380598216298013
wait_time: 0.6022495647242097
delay_time: 4.201419227128025
pressure: 0.7863616268788682
total_envstep_count: 1608456
total_train_sample_count: 1608456
total_episode_count: 13866
total_duration: 51665.912098646164
[2025-02-21 08:03:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.705757474678062
avg_train_sample_per_sec: 31.705757474678062
avg_episode_per_sec: 0.2733254954713626
collect_time: 21.95184898376465
reward_mean: -95.82563025210084
reward_std: 1.6849528723463885
reward_max: -93.80532212885154
reward_min: -98.60994397759104
queue_len: 0.06354484764728173
wait_time: 0.6019223339203056
delay_time: 4.164292632246813
pressure: 0.7852564102564102
total_envstep_count: 1609152
total_train_sample_count: 1609152
total_episode_count: 13872
total_duration: 51687.86394762993
[2025-02-21 08:03:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.72798777309205
avg_train_sample_per_sec: 31.72798777309205
avg_episode_per_sec: 0.27351713597493144
collect_time: 21.936468362808228
reward_mean: -97.50350140056021
reward_std: 3.471706299107473
reward_max: -92.26540616246498
reward_min: -103.4712885154061
queue_len: 0.06465749429745372
wait_time: 0.6142282399255015
delay_time: 4.229009553698899
pressure: 0.7912245800176835
total_envstep_count: 1609848
total_train_sample_count: 1609848
total_episode_count: 13878
total_duration: 51709.80041599274
[2025-02-21 08:03:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.981154398895992
avg_train_sample_per_sec: 31.981154398895992
avg_episode_per_sec: 0.27569960688703443
collect_time: 21.762816667556763
reward_mean: -95.58963585434174
reward_std: 0.9177037499774509
reward_max: -94.56792717086836
reward_min: -97.02801120448176
queue_len: 0.06338835268855553
wait_time: 0.5947569235474915
delay_time: 4.155416228092397
pressure: 0.7800618921308576
total_envstep_count: 1610544
total_train_sample_count: 1610544
total_episode_count: 13884
total_duration: 51731.56323266029
[2025-02-21 08:04:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.814999211718675
avg_train_sample_per_sec: 31.814999211718675
avg_episode_per_sec: 0.27426723458378166
collect_time: 21.876473903656006
reward_mean: -95.52917833800187
reward_std: 1.3011625765363766
reward_max: -94.59033613445376
reward_min: -98.33683473389351
queue_len: 0.06334826149734872
wait_time: 0.6011356797360855
delay_time: 4.141288557922022
pressure: 0.7775198938992043
total_envstep_count: 1611240
total_train_sample_count: 1611240
total_episode_count: 13890
total_duration: 51753.43970656395
[2025-02-21 08:04:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.836027524654163
avg_train_sample_per_sec: 31.836027524654163
avg_episode_per_sec: 0.2744485131435704
collect_time: 21.862024068832397
reward_mean: -96.07866479925303
reward_std: 1.4398444645806652
reward_max: -94.59103641456585
reward_min: -98.9957983193277
queue_len: 0.06371264243982296
wait_time: 0.6017757456651981
delay_time: 4.169513735120234
pressure: 0.784261715296198
total_envstep_count: 1611936
total_train_sample_count: 1611936
total_episode_count: 13896
total_duration: 51775.30173063278
[2025-02-21 08:05:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.758291451726674
avg_train_sample_per_sec: 31.758291451726674
avg_episode_per_sec: 0.2737783745838506
collect_time: 21.915536642074585
reward_mean: -96.62009803921569
reward_std: 2.144043276362671
reward_max: -94.5959383753501
reward_min: -100.60924369747897
queue_len: 0.06407168304987777
wait_time: 0.6134417405335254
delay_time: 4.235958770177164
pressure: 0.7818302387267905
total_envstep_count: 1612632
total_train_sample_count: 1612632
total_episode_count: 13902
total_duration: 51797.21726727486
[2025-02-21 08:05:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.617619147566582
avg_train_sample_per_sec: 31.617619147566582
avg_episode_per_sec: 0.2725656823066085
collect_time: 22.01304268836975
reward_mean: -95.2329598506069
reward_std: 1.338861507222696
reward_max: -93.37184873949577
reward_min: -97.86484593837535
queue_len: 0.06315183013965976
wait_time: 0.5998550835011282
delay_time: 4.170455838908674
pressure: 0.7807250221043324
total_envstep_count: 1613328
total_train_sample_count: 1613328
total_episode_count: 13908
total_duration: 51819.230309963226
[2025-02-21 08:05:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.782015829040795
avg_train_sample_per_sec: 31.782015829040795
avg_episode_per_sec: 0.2739828950779379
collect_time: 21.899177312850952
reward_mean: -95.8654295051354
reward_std: 1.8599182889044763
reward_max: -93.57913165266106
reward_min: -99.67226890756305
queue_len: 0.06357123972489083
wait_time: 0.6013727440578354
delay_time: 4.115544411833873
pressure: 0.786472148541114
total_envstep_count: 1614024
total_train_sample_count: 1614024
total_episode_count: 13914
total_duration: 51841.12948727608
[2025-02-21 08:06:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.431497027497585
avg_train_sample_per_sec: 31.431497027497585
avg_episode_per_sec: 0.2709611812715309
collect_time: 22.14339327812195
reward_mean: -95.19339402427637
reward_std: 1.652360125112455
reward_max: -92.29621848739495
reward_min: -97.28641456582635
queue_len: 0.06312559285429468
wait_time: 0.5990081377378537
delay_time: 4.164111973865453
pressure: 0.7787356321839081
total_envstep_count: 1614720
total_train_sample_count: 1614720
total_episode_count: 13920
total_duration: 51863.2728805542
[2025-02-21 08:06:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.024048881708364
avg_train_sample_per_sec: 31.024048881708364
avg_episode_per_sec: 0.2674486972561066
collect_time: 22.43420910835266
reward_mean: -94.9139822595705
reward_std: 1.763210457146114
reward_max: -91.32002801120449
reward_min: -96.63025210084038
queue_len: 0.06294030653817673
wait_time: 0.5905579517394934
delay_time: 4.135291936898436
pressure: 0.7761936339522547
total_envstep_count: 1615416
total_train_sample_count: 1615416
total_episode_count: 13926
total_duration: 51885.70708966255
[2025-02-21 08:06:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.897194906891254
avg_train_sample_per_sec: 31.897194906891254
avg_episode_per_sec: 0.27497581816285566
collect_time: 21.82010054588318
reward_mean: -94.01528944911297
reward_std: 1.687186130879525
reward_max: -91.7612044817927
reward_min: -96.3487394957983
queue_len: 0.062344356398616026
wait_time: 0.5873844785482717
delay_time: 4.112079682003931
pressure: 0.7724358974358975
total_envstep_count: 1616112
total_train_sample_count: 1616112
total_episode_count: 13932
total_duration: 51907.527190208435
[2025-02-21 08:07:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.55557971126348
avg_train_sample_per_sec: 31.55557971126348
avg_episode_per_sec: 0.27203085957985756
collect_time: 22.056321144104004
reward_mean: -96.08006535947713
reward_std: 2.411059092363119
reward_max: -91.95798319327727
reward_min: -99.18767507002804
queue_len: 0.06371357119328722
wait_time: 0.6073234996916539
delay_time: 4.178604895769698
pressure: 0.7838196286472149
total_envstep_count: 1616808
total_train_sample_count: 1616808
total_episode_count: 13938
total_duration: 51929.58351135254
[2025-02-21 08:07:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.902538713677387
avg_train_sample_per_sec: 31.902538713677387
avg_episode_per_sec: 0.2750218854627361
collect_time: 21.81644558906555
reward_mean: -95.90347805788984
reward_std: 2.7457996414437287
reward_max: -93.59173669467788
reward_min: -101.7717086834734
queue_len: 0.06359647086066965
wait_time: 0.6043145706558485
delay_time: 4.132769677709947
pressure: 0.7858090185676393
total_envstep_count: 1617504
total_train_sample_count: 1617504
total_episode_count: 13944
total_duration: 51951.399956941605
[2025-02-21 08:08:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.088355251223575
avg_train_sample_per_sec: 32.088355251223575
avg_episode_per_sec: 0.2766237521657205
collect_time: 21.6901113986969
reward_mean: -97.15569561157797
reward_std: 1.7196787835183391
reward_max: -94.38445378151262
reward_min: -99.67997198879553
queue_len: 0.06442685385383154
wait_time: 0.6055550756995991
delay_time: 4.212779484384438
pressure: 0.7895667550839965
total_envstep_count: 1618200
total_train_sample_count: 1618200
total_episode_count: 13950
total_duration: 51973.0900683403
[2025-02-21 08:08:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.34301507634562
avg_train_sample_per_sec: 32.34301507634562
avg_episode_per_sec: 0.27881909548573813
collect_time: 21.51932954788208
reward_mean: -93.90417833800183
reward_std: 1.410608933665086
reward_max: -91.57072829131648
reward_min: -95.22338935574227
queue_len: 0.06227067529045214
wait_time: 0.5893425230392776
delay_time: 4.133643671272734
pressure: 0.7663572060123784
total_envstep_count: 1618896
total_train_sample_count: 1618896
total_episode_count: 13956
total_duration: 51994.60939788818
[2025-02-21 08:08:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.9003479895207
avg_train_sample_per_sec: 31.9003479895207
avg_episode_per_sec: 0.2750029999096612
collect_time: 21.817943811416626
reward_mean: -97.19852941176471
reward_std: 2.2990232962380674
reward_max: -93.1155462184874
reward_min: -99.47128851540614
queue_len: 0.0644552582306132
wait_time: 0.6111525180363923
delay_time: 4.181405923743238
pressure: 0.7948717948717948
total_envstep_count: 1619592
total_train_sample_count: 1619592
total_episode_count: 13962
total_duration: 52016.4273416996
[2025-02-21 08:09:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.93705929129431
avg_train_sample_per_sec: 31.93705929129431
avg_episode_per_sec: 0.2753194766490889
collect_time: 21.792864322662354
reward_mean: -97.5486694677871
reward_std: 1.244700096655135
reward_max: -95.6827731092437
reward_min: -98.97759103641457
queue_len: 0.0646874465966758
wait_time: 0.6127483486763405
delay_time: 4.1793641234264
pressure: 0.7986295313881522
total_envstep_count: 1620288
total_train_sample_count: 1620288
total_episode_count: 13968
total_duration: 52038.22020602226
[2025-02-21 08:09:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.891310773593997
avg_train_sample_per_sec: 31.891310773593997
avg_episode_per_sec: 0.27492509287581035
collect_time: 21.824126482009888
reward_mean: -95.58986928104576
reward_std: 1.4372244430395587
reward_max: -93.96148459383754
reward_min: -98.53571428571429
queue_len: 0.06338850748079959
wait_time: 0.5970384838285446
delay_time: 4.115671561421791
pressure: 0.7787356321839081
total_envstep_count: 1620984
total_train_sample_count: 1620984
total_episode_count: 13974
total_duration: 52060.04433250427
[2025-02-21 08:09:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.04775470021877
avg_train_sample_per_sec: 32.04775470021877
avg_episode_per_sec: 0.276273747415679
collect_time: 21.71759009361267
reward_mean: -96.4190009337068
reward_std: 2.2445222134791925
reward_max: -92.88375350140056
reward_min: -98.75210084033613
queue_len: 0.06393832953163582
wait_time: 0.6001996510363651
delay_time: 4.191801142186706
pressure: 0.7833775419982317
total_envstep_count: 1621680
total_train_sample_count: 1621680
total_episode_count: 13980
total_duration: 52081.761922597885
[2025-02-21 08:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.810209128544816
avg_train_sample_per_sec: 31.810209128544816
avg_episode_per_sec: 0.27422594076331736
collect_time: 21.879768133163452
reward_mean: -94.08309990662933
reward_std: 2.2283968279849904
reward_max: -91.44747899159667
reward_min: -97.48319327731095
queue_len: 0.06238932354551016
wait_time: 0.5864328932280252
delay_time: 4.11480872736131
pressure: 0.7700044208664898
total_envstep_count: 1622376
total_train_sample_count: 1622376
total_episode_count: 13986
total_duration: 52103.64169073105
[2025-02-21 08:10:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.597400853214673
avg_train_sample_per_sec: 31.597400853214673
avg_episode_per_sec: 0.2723913866656437
collect_time: 22.027128219604492
reward_mean: -97.9735060690943
reward_std: 2.034551976188614
reward_max: -95.17857142857143
reward_min: -100.43837535014003
queue_len: 0.06496916848083177
wait_time: 0.6113083938261423
delay_time: 4.196055079446997
pressure: 0.7966401414677278
total_envstep_count: 1623072
total_train_sample_count: 1623072
total_episode_count: 13992
total_duration: 52125.66881895065
[2025-02-21 08:11:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.655275905190567
avg_train_sample_per_sec: 31.655275905190567
avg_episode_per_sec: 0.27289030952750487
collect_time: 21.98685622215271
reward_mean: -96.12873482726422
reward_std: 3.811238775442756
reward_max: -91.07492997198878
reward_min: -103.53291316526608
queue_len: 0.06374584537616991
wait_time: 0.5987708412277378
delay_time: 4.163354718032729
pressure: 0.7830459770114943
total_envstep_count: 1623768
total_train_sample_count: 1623768
total_episode_count: 13998
total_duration: 52147.655675172806
[2025-02-21 08:11:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74500122913598
avg_train_sample_per_sec: 31.74500122913598
avg_episode_per_sec: 0.2736638036994481
collect_time: 21.92471170425415
reward_mean: -98.3454715219421
reward_std: 4.463008067968291
reward_max: -93.92927170868343
reward_min: -107.51750700280108
queue_len: 0.06521582992171227
wait_time: 0.6231835130161701
delay_time: 4.251170607259102
pressure: 0.8029398762157384
total_envstep_count: 1624464
total_train_sample_count: 1624464
total_episode_count: 14004
total_duration: 52169.58038687706
[2025-02-21 08:11:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.911557178539827
avg_train_sample_per_sec: 31.911557178539827
avg_episode_per_sec: 0.27509963084948125
collect_time: 21.810280084609985
reward_mean: -96.5219421101774
reward_std: 2.624381251864778
reward_max: -92.22759103641458
reward_min: -100.62885154061625
queue_len: 0.06400659291125822
wait_time: 0.6040398918187965
delay_time: 4.21041419442285
pressure: 0.7852564102564101
total_envstep_count: 1625160
total_train_sample_count: 1625160
total_episode_count: 14010
total_duration: 52191.39066696167
[2025-02-21 08:12:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.946595468679305
avg_train_sample_per_sec: 31.946595468679305
avg_episode_per_sec: 0.2754016850748216
collect_time: 21.786359071731567
reward_mean: -94.74206349206348
reward_std: 3.126788306237404
reward_max: -92.09313725490198
reward_min: -100.82002801120446
queue_len: 0.06282630205043997
wait_time: 0.5923361276429229
delay_time: 4.110439733437958
pressure: 0.7719938107869142
total_envstep_count: 1625856
total_train_sample_count: 1625856
total_episode_count: 14016
total_duration: 52213.1770260334
[2025-02-21 08:12:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.808195692722453
avg_train_sample_per_sec: 31.808195692722453
avg_episode_per_sec: 0.2742085835579522
collect_time: 21.881153106689453
reward_mean: -96.98190943043882
reward_std: 1.8021580185703918
reward_max: -94.48949579831931
reward_min: -100.12815126050415
queue_len: 0.06431161102814247
wait_time: 0.6053936273890634
delay_time: 4.204238269856839
pressure: 0.7950928381962864
total_envstep_count: 1626552
total_train_sample_count: 1626552
total_episode_count: 14022
total_duration: 52235.05817914009
[2025-02-21 08:12:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.778119842459432
avg_train_sample_per_sec: 31.778119842459432
avg_episode_per_sec: 0.2739493089867192
collect_time: 21.901862144470215
reward_mean: -95.85725957049486
reward_std: 2.0410445009785576
reward_max: -93.02310924369748
reward_min: -99.25210084033611
queue_len: 0.06356582199634939
wait_time: 0.5958629141311697
delay_time: 4.136909827033328
pressure: 0.7844827586206896
total_envstep_count: 1627248
total_train_sample_count: 1627248
total_episode_count: 14028
total_duration: 52256.96004128456
[2025-02-21 08:13:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.670040217488246
avg_train_sample_per_sec: 31.670040217488246
avg_episode_per_sec: 0.2730175880817952
collect_time: 21.976606130599976
reward_mean: -95.22163865546217
reward_std: 4.037923979114689
reward_max: -92.13305322128849
reward_min: -104.14845938375349
queue_len: 0.06314432271582372
wait_time: 0.5925955594439368
delay_time: 4.124418430970896
pressure: 0.7771883289124668
total_envstep_count: 1627944
total_train_sample_count: 1627944
total_episode_count: 14034
total_duration: 52278.93664741516
[2025-02-21 08:13:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.680503971724388
avg_train_sample_per_sec: 31.680503971724388
avg_episode_per_sec: 0.273107792859693
collect_time: 21.96934747695923
reward_mean: -96.29680205415498
reward_std: 1.8851222997461947
reward_max: -94.59663865546223
reward_min: -99.60364145658261
queue_len: 0.06385729579187996
wait_time: 0.6036100337570925
delay_time: 4.18454569928796
pressure: 0.7852564102564102
total_envstep_count: 1628640
total_train_sample_count: 1628640
total_episode_count: 14040
total_duration: 52300.90599489212
[2025-02-21 08:14:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.95032586045714
avg_train_sample_per_sec: 31.95032586045714
avg_episode_per_sec: 0.2754338436246305
collect_time: 21.783815383911133
reward_mean: -97.84850606909431
reward_std: 3.2137002803658263
reward_max: -93.8389355742297
reward_min: -103.83753501400561
queue_len: 0.06488627723414742
wait_time: 0.612672190892272
delay_time: 4.186450064091382
pressure: 0.8021662245800177
total_envstep_count: 1629336
total_train_sample_count: 1629336
total_episode_count: 14046
total_duration: 52322.68981027603
[2025-02-21 08:14:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.209260369449794
avg_train_sample_per_sec: 32.209260369449794
avg_episode_per_sec: 0.2776660376676706
collect_time: 21.608692407608032
reward_mean: -97.312908496732
reward_std: 0.9891567855621788
reward_max: -96.15406162464987
reward_min: -98.84243697478989
queue_len: 0.06453110643019365
wait_time: 0.6120075903924788
delay_time: 4.1292443368740095
pressure: 0.7961980548187445
total_envstep_count: 1630032
total_train_sample_count: 1630032
total_episode_count: 14052
total_duration: 52344.29850268364
[2025-02-21 08:14:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.853587368342858
avg_train_sample_per_sec: 31.853587368342858
avg_episode_per_sec: 0.2745998911064039
collect_time: 21.849972248077393
reward_mean: -95.01318860877684
reward_std: 1.9007156097683622
reward_max: -92.74789915966387
reward_min: -97.38305322128855
queue_len: 0.06300609324189445
wait_time: 0.5927892819373549
delay_time: 4.10720055995139
pressure: 0.7767462422634837
total_envstep_count: 1630728
total_train_sample_count: 1630728
total_episode_count: 14058
total_duration: 52366.14847493172
[2025-02-21 08:15:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.01536332667945
avg_train_sample_per_sec: 32.01536332667945
avg_episode_per_sec: 0.2759945114368918
collect_time: 21.73956274986267
reward_mean: -97.01365546218487
reward_std: 2.670398170556941
reward_max: -93.26120448179272
reward_min: -100.06302521008399
queue_len: 0.06433266277333213
wait_time: 0.6083061982529528
delay_time: 4.227679816528984
pressure: 0.7870247568523431
total_envstep_count: 1631424
total_train_sample_count: 1631424
total_episode_count: 14064
total_duration: 52387.88803768158
[2025-02-21 08:15:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05234244462471
avg_train_sample_per_sec: 32.05234244462471
avg_episode_per_sec: 0.2763132969364199
collect_time: 21.714481592178345
reward_mean: -95.15721288515407
reward_std: 2.441381220946739
reward_max: -91.89565826330531
reward_min: -98.50840336134452
queue_len: 0.0631016000564682
wait_time: 0.5956251532443217
delay_time: 4.194595693296905
pressure: 0.7787356321839081
total_envstep_count: 1632120
total_train_sample_count: 1632120
total_episode_count: 14070
total_duration: 52409.60251927376
[2025-02-21 08:15:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.617697224923457
avg_train_sample_per_sec: 31.617697224923457
avg_episode_per_sec: 0.2725663553872712
collect_time: 22.012988328933716
reward_mean: -93.96148459383754
reward_std: 1.5682130638460816
reward_max: -91.766106442577
reward_min: -95.91036414565829
queue_len: 0.062308676786364404
wait_time: 0.5871416869134923
delay_time: 4.115433375852179
pressure: 0.7671308576480991
total_envstep_count: 1632816
total_train_sample_count: 1632816
total_episode_count: 14076
total_duration: 52431.61550760269
[2025-02-21 08:16:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70999395864197
avg_train_sample_per_sec: 31.70999395864197
avg_episode_per_sec: 0.27336201688484457
collect_time: 21.94891619682312
reward_mean: -94.47222222222221
reward_std: 1.8949511971867712
reward_max: -90.82773109243696
reward_min: -97.09383753501396
queue_len: 0.06264736221632773
wait_time: 0.5893544420420688
delay_time: 4.141595211945433
pressure: 0.77210433244916
total_envstep_count: 1633512
total_train_sample_count: 1633512
total_episode_count: 14082
total_duration: 52453.564423799515
[2025-02-21 08:16:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.988300261809517
avg_train_sample_per_sec: 31.988300261809517
avg_episode_per_sec: 0.2757612091535303
collect_time: 21.757955074310303
reward_mean: -95.11788048552752
reward_std: 2.587938999135078
reward_max: -92.35084033613445
reward_min: -99.90266106442574
queue_len: 0.06307551756334716
wait_time: 0.5933888696946507
delay_time: 4.098621270196087
pressure: 0.7819407603890363
total_envstep_count: 1634208
total_train_sample_count: 1634208
total_episode_count: 14088
total_duration: 52475.322378873825
[2025-02-21 08:17:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.018086795882
avg_train_sample_per_sec: 32.018086795882
avg_episode_per_sec: 0.2760179896196724
collect_time: 21.73771357536316
reward_mean: -95.20529878618113
reward_std: 1.3794050868626362
reward_max: -93.9264705882353
reward_min: -97.13585434173673
queue_len: 0.06313348725874081
wait_time: 0.5961912284807821
delay_time: 4.161970069000665
pressure: 0.7755305039787798
total_envstep_count: 1634904
total_train_sample_count: 1634904
total_episode_count: 14094
total_duration: 52497.06009244919
[2025-02-21 08:17:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.87215030125431
avg_train_sample_per_sec: 31.87215030125431
avg_episode_per_sec: 0.27475991639012337
collect_time: 21.837246417999268
reward_mean: -95.94782913165267
reward_std: 2.5142924195082754
reward_max: -92.08683473389355
reward_min: -99.764705882353
queue_len: 0.06362588138703758
wait_time: 0.602947677744838
delay_time: 4.178440030706384
pressure: 0.7881299734748012
total_envstep_count: 1635600
total_train_sample_count: 1635600
total_episode_count: 14100
total_duration: 52518.89733886719
[2025-02-21 08:17:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.05842205015349
avg_train_sample_per_sec: 32.05842205015349
avg_episode_per_sec: 0.2763657073289094
collect_time: 21.710363626480103
reward_mean: -97.93265639589168
reward_std: 2.499356470797671
reward_max: -93.64635854341735
reward_min: -101.70658263305324
queue_len: 0.06494207983812446
wait_time: 0.6156785658560506
delay_time: 4.225880395639117
pressure: 0.7995137046861185
total_envstep_count: 1636296
total_train_sample_count: 1636296
total_episode_count: 14106
total_duration: 52540.60770249367
[2025-02-21 08:18:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.74614770815715
avg_train_sample_per_sec: 31.74614770815715
avg_episode_per_sec: 0.27367368713928575
collect_time: 21.923919916152954
reward_mean: -96.99883286647993
reward_std: 1.5207230235487448
reward_max: -95.16316526610643
reward_min: -99.18487394957981
queue_len: 0.06432283346583549
wait_time: 0.6099329873417094
delay_time: 4.120742005120105
pressure: 0.7928824049513704
total_envstep_count: 1636992
total_train_sample_count: 1636992
total_episode_count: 14112
total_duration: 52562.53162240982
[2025-02-21 08:18:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.97613062208436
avg_train_sample_per_sec: 31.97613062208436
avg_episode_per_sec: 0.27565629846624445
collect_time: 21.766235828399658
reward_mean: -97.89157329598505
reward_std: 3.092947908094539
reward_max: -93.4593837535014
reward_min: -102.77240896358543
queue_len: 0.06491483640317312
wait_time: 0.6135541970988218
delay_time: 4.265193591137869
pressure: 0.8011715296198054
total_envstep_count: 1637688
total_train_sample_count: 1637688
total_episode_count: 14118
total_duration: 52584.29785823822
[2025-02-21 08:18:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.712076281170408
avg_train_sample_per_sec: 31.712076281170408
avg_episode_per_sec: 0.2733799679411242
collect_time: 21.94747495651245
reward_mean: -95.67950513538749
reward_std: 2.372509804791736
reward_max: -92.49439775910362
reward_min: -99.27100840336136
queue_len: 0.0634479477025116
wait_time: 0.6004509562445669
delay_time: 4.162679755162635
pressure: 0.7869142351900974
total_envstep_count: 1638384
total_train_sample_count: 1638384
total_episode_count: 14124
total_duration: 52606.24533319473
[2025-02-21 08:19:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.893510710017786
avg_train_sample_per_sec: 31.893510710017786
avg_episode_per_sec: 0.27494405784498094
collect_time: 21.82262110710144
reward_mean: -97.17623716153128
reward_std: 1.967244620647204
reward_max: -95.45658263305323
reward_min: -101.2948179271709
queue_len: 0.06444047557130722
wait_time: 0.6095686837953573
delay_time: 4.202627437795849
pressure: 0.7939876215738284
total_envstep_count: 1639080
total_train_sample_count: 1639080
total_episode_count: 14130
total_duration: 52628.067954301834
[2025-02-21 08:19:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53589204641268
avg_train_sample_per_sec: 31.53589204641268
avg_episode_per_sec: 0.2718611383311438
collect_time: 22.070090770721436
reward_mean: -97.61309523809524
reward_std: 2.279021996634732
reward_max: -94.21918767507003
reward_min: -101.37745098039215
queue_len: 0.06473016925603133
wait_time: 0.6138240773763085
delay_time: 4.183308094327425
pressure: 0.8022767462422635
total_envstep_count: 1639776
total_train_sample_count: 1639776
total_episode_count: 14136
total_duration: 52650.138045072556
[2025-02-21 08:19:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.8631241835938
avg_train_sample_per_sec: 31.8631241835938
avg_episode_per_sec: 0.274682105030981
collect_time: 21.843432426452637
reward_mean: -96.79306722689076
reward_std: 1.490625176803334
reward_max: -94.70308123249303
reward_min: -98.67647058823529
queue_len: 0.0641863841027127
wait_time: 0.6043605439523289
delay_time: 4.199180922621281
pressure: 0.7944297082228117
total_envstep_count: 1640472
total_train_sample_count: 1640472
total_episode_count: 14142
total_duration: 52671.98147749901
[2025-02-21 08:20:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.77562478358517
avg_train_sample_per_sec: 30.77562478358517
avg_episode_per_sec: 0.26530711020332043
collect_time: 22.61530041694641
reward_mean: -96.48167600373479
reward_std: 2.7618542591455273
reward_max: -93.69887955182071
reward_min: -101.42296918767501
queue_len: 0.06397989124916101
wait_time: 0.6080795050115537
delay_time: 4.137491106909892
pressure: 0.7961980548187445
total_envstep_count: 1641168
total_train_sample_count: 1641168
total_episode_count: 14148
total_duration: 52694.596777915955
[2025-02-21 08:20:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.947648869063514
avg_train_sample_per_sec: 31.947648869063514
avg_episode_per_sec: 0.2754107661126165
collect_time: 21.785640716552734
reward_mean: -97.29353408029878
reward_std: 3.235525020374384
reward_max: -93.71498599439775
reward_min: -101.92366946778712
queue_len: 0.06451825867393819
wait_time: 0.6127793071251489
delay_time: 4.132714389976049
pressure: 0.8013925729442969
total_envstep_count: 1641864
total_train_sample_count: 1641864
total_episode_count: 14154
total_duration: 52716.38241863251
[2025-02-21 08:21:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.46151815127596
avg_train_sample_per_sec: 31.46151815127596
avg_episode_per_sec: 0.2712199840627238
collect_time: 22.12226366996765
reward_mean: -95.9876283846872
reward_std: 1.1913590856546208
reward_max: -93.94187675070027
reward_min: -97.36204481792717
queue_len: 0.06365227346464669
wait_time: 0.6047271693823418
delay_time: 4.1919948136136975
pressure: 0.7927718832891246
total_envstep_count: 1642560
total_train_sample_count: 1642560
total_episode_count: 14160
total_duration: 52738.504682302475
[2025-02-21 08:21:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.53891208458237
avg_train_sample_per_sec: 31.53891208458237
avg_episode_per_sec: 0.27188717314295147
collect_time: 22.06797742843628
reward_mean: -95.65721288515407
reward_std: 2.4702017326816144
reward_max: -91.92647058823532
reward_min: -99.75560224089632
queue_len: 0.06343316504320562
wait_time: 0.6001765095958808
delay_time: 4.180825362285234
pressure: 0.7812776304155614
total_envstep_count: 1643256
total_train_sample_count: 1643256
total_episode_count: 14166
total_duration: 52760.57265973091
[2025-02-21 08:21:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.65101902527022
avg_train_sample_per_sec: 31.65101902527022
avg_episode_per_sec: 0.27285361228681226
collect_time: 21.989813327789307
reward_mean: -96.48716153127918
reward_std: 2.478245562975226
reward_max: -92.02731092436973
reward_min: -99.72408963585436
queue_len: 0.06398352886689601
wait_time: 0.602703647772106
delay_time: 4.140466726741374
pressure: 0.7960875331564988
total_envstep_count: 1643952
total_train_sample_count: 1643952
total_episode_count: 14172
total_duration: 52782.5624730587
[2025-02-21 08:22:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81989721705516
avg_train_sample_per_sec: 31.81989721705516
avg_episode_per_sec: 0.2743094587677169
collect_time: 21.873106479644775
reward_mean: -97.35667600373483
reward_std: 1.791890587057005
reward_max: -95.6575630252101
reward_min: -100.23109243697478
queue_len: 0.06456012997595148
wait_time: 0.6178127639207761
delay_time: 4.239796157888013
pressure: 0.790893015030946
total_envstep_count: 1644648
total_train_sample_count: 1644648
total_episode_count: 14178
total_duration: 52804.435579538345
[2025-02-21 08:22:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.80558474070495
avg_train_sample_per_sec: 31.80558474070495
avg_episode_per_sec: 0.2741860753509047
collect_time: 21.882949352264404
reward_mean: -98.42238562091502
reward_std: 3.2414161153808796
reward_max: -93.64635854341732
reward_min: -102.37254901960786
queue_len: 0.06526683396612402
wait_time: 0.6143711131667521
delay_time: 4.233031017700935
pressure: 0.8048187444739169
total_envstep_count: 1645344
total_train_sample_count: 1645344
total_episode_count: 14184
total_duration: 52826.31852889061
[2025-02-21 08:22:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.930870551671696
avg_train_sample_per_sec: 31.930870551671696
avg_episode_per_sec: 0.27526612544544565
collect_time: 21.797088146209717
reward_mean: -94.6359710550887
reward_std: 1.61320359606012
reward_max: -92.97969187675069
reward_min: -96.9089635854342
queue_len: 0.06275594897552302
wait_time: 0.5907173877508564
delay_time: 4.096646232755536
pressure: 0.7754199823165341
total_envstep_count: 1646040
total_train_sample_count: 1646040
total_episode_count: 14190
total_duration: 52848.11561703682
[2025-02-21 08:23:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14745078018452
avg_train_sample_per_sec: 32.14745078018452
avg_episode_per_sec: 0.277133196380901
collect_time: 21.65023922920227
reward_mean: -93.5200746965453
reward_std: 1.2437462181281957
reward_max: -91.46918767507009
reward_min: -94.92016806722685
queue_len: 0.062015964652881506
wait_time: 0.5833474968236632
delay_time: 4.109566065747201
pressure: 0.760941644562334
total_envstep_count: 1646736
total_train_sample_count: 1646736
total_episode_count: 14196
total_duration: 52869.76585626602
[2025-02-21 08:23:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.13125983568944
avg_train_sample_per_sec: 32.13125983568944
avg_episode_per_sec: 0.27699361927318483
collect_time: 21.6611487865448
reward_mean: -94.12406629318393
reward_std: 1.937718575176221
reward_max: -91.55112044817928
reward_min: -97.42647058823528
queue_len: 0.06241648958433948
wait_time: 0.586680715610736
delay_time: 4.129045382703371
pressure: 0.7740937223695843
total_envstep_count: 1647432
total_train_sample_count: 1647432
total_episode_count: 14202
total_duration: 52891.42700505257
[2025-02-21 08:24:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19377433899406
avg_train_sample_per_sec: 32.19377433899406
avg_episode_per_sec: 0.27753253740512124
collect_time: 21.619086742401123
reward_mean: -95.38690476190476
reward_std: 3.0678720172529736
reward_max: -92.07633053221288
reward_min: -100.4859943977591
queue_len: 0.06325391562460528
wait_time: 0.5991773256605915
delay_time: 4.184294579961363
pressure: 0.7772988505747126
total_envstep_count: 1648128
total_train_sample_count: 1648128
total_episode_count: 14208
total_duration: 52913.04609179497
[2025-02-21 08:24:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.67788540842602
avg_train_sample_per_sec: 31.67788540842602
avg_episode_per_sec: 0.27308521903815536
collect_time: 21.971163511276245
reward_mean: -96.83018207282913
reward_std: 2.594181751966981
reward_max: -92.44957983193277
reward_min: -101.41106442577029
queue_len: 0.06421099606951534
wait_time: 0.6082270994162474
delay_time: 4.201899999674201
pressure: 0.7922192749778957
total_envstep_count: 1648824
total_train_sample_count: 1648824
total_episode_count: 14214
total_duration: 52935.017255306244
[2025-02-21 08:24:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.851151059421923
avg_train_sample_per_sec: 31.851151059421923
avg_episode_per_sec: 0.2745788884432924
collect_time: 21.851643562316895
reward_mean: -97.91363211951445
reward_std: 2.442612020028968
reward_max: -95.17507002801119
reward_min: -101.17296918767506
queue_len: 0.06492946427023505
wait_time: 0.6102782514420446
delay_time: 4.248645814072581
pressure: 0.7966401414677277
total_envstep_count: 1649520
total_train_sample_count: 1649520
total_episode_count: 14220
total_duration: 52956.86889886856
[2025-02-21 08:25:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.811983617333265
avg_train_sample_per_sec: 31.811983617333265
avg_episode_per_sec: 0.2742412380804592
collect_time: 21.87854766845703
reward_mean: -95.42005135387485
reward_std: 2.45018702701436
reward_max: -92.27801120448179
reward_min: -99.24159663865547
queue_len: 0.0632758961232592
wait_time: 0.5955603726901901
delay_time: 4.156714595341156
pressure: 0.78105658709107
total_envstep_count: 1650216
total_train_sample_count: 1650216
total_episode_count: 14226
total_duration: 52978.74744653702
[2025-02-21 08:25:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.652101069634327
avg_train_sample_per_sec: 31.652101069634327
avg_episode_per_sec: 0.2728629402554683
collect_time: 21.9890615940094
reward_mean: -97.42121848739497
reward_std: 1.6237045463496316
reward_max: -95.55252100840332
reward_min: -100.72689075630252
queue_len: 0.06460293003142902
wait_time: 0.6029106050023901
delay_time: 4.213238477694584
pressure: 0.7990716180371352
total_envstep_count: 1650912
total_train_sample_count: 1650912
total_episode_count: 14232
total_duration: 53000.73650813103
[2025-02-21 08:25:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.81424196572129
avg_train_sample_per_sec: 31.81424196572129
avg_episode_per_sec: 0.2742607066010456
collect_time: 21.876994609832764
reward_mean: -95.38001867413631
reward_std: 1.9164304394087994
reward_max: -92.29131652661066
reward_min: -98.10924369747902
queue_len: 0.06324934925340604
wait_time: 0.5959095839927483
delay_time: 4.158204944196455
pressure: 0.7765251989389922
total_envstep_count: 1651608
total_train_sample_count: 1651608
total_episode_count: 14238
total_duration: 53022.61350274086
[2025-02-21 08:26:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76002801793915
avg_train_sample_per_sec: 31.76002801793915
avg_episode_per_sec: 0.27379334498223407
collect_time: 21.91433835029602
reward_mean: -96.80590569561157
reward_std: 1.7062231361038733
reward_max: -94.67436974789918
reward_min: -99.20868347338937
queue_len: 0.064194897676135
wait_time: 0.6035101927596858
delay_time: 4.1941929702668626
pressure: 0.7917771883289125
total_envstep_count: 1652304
total_train_sample_count: 1652304
total_episode_count: 14244
total_duration: 53044.527841091156
[2025-02-21 08:26:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.726204712731587
avg_train_sample_per_sec: 31.726204712731587
avg_episode_per_sec: 0.2735017647649275
collect_time: 21.93770122528076
reward_mean: -97.45133053221286
reward_std: 1.2178704523077148
reward_max: -95.94887955182075
reward_min: -99.15896358543417
queue_len: 0.0646228982309104
wait_time: 0.6091044618554761
delay_time: 4.196711190413476
pressure: 0.7938770999115827
total_envstep_count: 1653000
total_train_sample_count: 1653000
total_episode_count: 14250
total_duration: 53066.46554231644
[2025-02-21 08:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.846296235366832
avg_train_sample_per_sec: 31.846296235366832
avg_episode_per_sec: 0.274537036511783
collect_time: 21.8549747467041
reward_mean: -96.66059757236228
reward_std: 1.2846195154034954
reward_max: -94.80602240896356
reward_min: -98.3760504201681
queue_len: 0.06409853950421902
wait_time: 0.6075356424621131
delay_time: 4.23955132628161
pressure: 0.7854774535809019
total_envstep_count: 1653696
total_train_sample_count: 1653696
total_episode_count: 14256
total_duration: 53088.32051706314
[2025-02-21 08:27:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.64546205898225
avg_train_sample_per_sec: 31.64546205898225
avg_episode_per_sec: 0.2728057074050194
collect_time: 21.993674755096436
reward_mean: -97.687441643324
reward_std: 3.469388670340514
reward_max: -94.20588235294115
reward_min: -104.73459383753502
queue_len: 0.0647794705857586
wait_time: 0.6121736824703357
delay_time: 4.282195812780016
pressure: 0.7891246684350133
total_envstep_count: 1654392
total_train_sample_count: 1654392
total_episode_count: 14262
total_duration: 53110.31419181824
[2025-02-21 08:27:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.0985534088865
avg_train_sample_per_sec: 32.0985534088865
avg_episode_per_sec: 0.27671166731798713
collect_time: 21.683220148086548
reward_mean: -96.8469887955182
reward_std: 1.7502211645987569
reward_max: -95.21848739495799
reward_min: -99.77801120448177
queue_len: 0.06422214111108634
wait_time: 0.6041539737026553
delay_time: 4.16670234592588
pressure: 0.793656056587091
total_envstep_count: 1655088
total_train_sample_count: 1655088
total_episode_count: 14268
total_duration: 53131.997411966324
[2025-02-21 08:28:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.628352578591578
avg_train_sample_per_sec: 31.628352578591578
avg_episode_per_sec: 0.27265821188441014
collect_time: 22.00557231903076
reward_mean: -96.54960317460318
reward_std: 2.2754605393531158
reward_max: -92.02661064425769
reward_min: -98.25770308123249
queue_len: 0.06402493579217718
wait_time: 0.605395562292114
delay_time: 4.122066946862467
pressure: 0.7871352785145889
total_envstep_count: 1655784
total_train_sample_count: 1655784
total_episode_count: 14274
total_duration: 53154.002984285355
[2025-02-21 08:28:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.906491772724145
avg_train_sample_per_sec: 31.906491772724145
avg_episode_per_sec: 0.2750559635579668
collect_time: 21.813742637634277
reward_mean: -95.10107376283848
reward_std: 1.434241009819267
reward_max: -93.27170868347342
reward_min: -96.96358543417365
queue_len: 0.06306437252177617
wait_time: 0.5961221911399397
delay_time: 4.148132511823512
pressure: 0.7781830238726791
total_envstep_count: 1656480
total_train_sample_count: 1656480
total_episode_count: 14280
total_duration: 53175.81672692299
[2025-02-21 08:28:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.539863121125936
avg_train_sample_per_sec: 31.539863121125936
avg_episode_per_sec: 0.27189537173384426
collect_time: 22.067312002182007
reward_mean: -96.35387488328662
reward_std: 1.9105861647922815
reward_max: -92.9173669467787
reward_min: -98.10574229691875
queue_len: 0.06389514249554816
wait_time: 0.6068883786936526
delay_time: 4.163020132398653
pressure: 0.7885720601237843
total_envstep_count: 1657176
total_train_sample_count: 1657176
total_episode_count: 14286
total_duration: 53197.88403892517
[2025-02-21 08:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.768989934733327
avg_train_sample_per_sec: 31.768989934733327
avg_episode_per_sec: 0.27387060288563214
collect_time: 21.908156394958496
reward_mean: -95.72724089635852
reward_std: 1.1918074715635012
reward_max: -94.4439775910364
reward_min: -97.87394957983186
queue_len: 0.06347960271641813
wait_time: 0.5951508698085777
delay_time: 4.174283121530892
pressure: 0.7838196286472149
total_envstep_count: 1657872
total_train_sample_count: 1657872
total_episode_count: 14292
total_duration: 53219.79219532013
[2025-02-21 08:29:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.826922265107267
avg_train_sample_per_sec: 31.826922265107267
avg_episode_per_sec: 0.2743700195267868
collect_time: 21.86827850341797
reward_mean: -95.31442577030812
reward_std: 2.2307999383906703
reward_max: -91.7016806722689
reward_min: -98.01120448179272
queue_len: 0.06320585263283031
wait_time: 0.594984700334599
delay_time: 4.196948848615374
pressure: 0.7840406719717063
total_envstep_count: 1658568
total_train_sample_count: 1658568
total_episode_count: 14298
total_duration: 53241.66047382355
[2025-02-21 08:30:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.639807938128584
avg_train_sample_per_sec: 31.639807938128584
avg_episode_per_sec: 0.2727569649838671
collect_time: 21.997605085372925
reward_mean: -97.796568627451
reward_std: 2.715399946033122
reward_max: -94.71848739495802
reward_min: -101.46918767507005
queue_len: 0.06485183595984816
wait_time: 0.6111125816374295
delay_time: 4.193312389156021
pressure: 0.8017241379310344
total_envstep_count: 1659264
total_train_sample_count: 1659264
total_episode_count: 14304
total_duration: 53263.65807890892
[2025-02-21 08:30:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.662319105366006
avg_train_sample_per_sec: 31.662319105366006
avg_episode_per_sec: 0.27295102677039657
collect_time: 21.98196530342102
reward_mean: -95.93440709617177
reward_std: 1.5539908727572955
reward_max: -93.74789915966383
reward_min: -98.11204481792717
queue_len: 0.06361698083300517
wait_time: 0.6034160016791862
delay_time: 4.153915465282169
pressure: 0.7828249336870027
total_envstep_count: 1659960
total_train_sample_count: 1659960
total_episode_count: 14310
total_duration: 53285.64004421234
[2025-02-21 08:30:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.76628171303658
avg_train_sample_per_sec: 31.76628171303658
avg_episode_per_sec: 0.27384725614686706
collect_time: 21.910024166107178
reward_mean: -96.14600840336134
reward_std: 1.644652818287068
reward_max: -94.13305322128852
reward_min: -98.46218487394961
queue_len: 0.063757300002229
wait_time: 0.6027128579106268
delay_time: 4.203244492674851
pressure: 0.7870247568523431
total_envstep_count: 1660656
total_train_sample_count: 1660656
total_episode_count: 14316
total_duration: 53307.55006837845
[2025-02-21 08:31:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.70358680573445
avg_train_sample_per_sec: 31.70358680573445
avg_episode_per_sec: 0.2733067828080556
collect_time: 21.953351974487305
reward_mean: -95.8795518207283
reward_std: 0.7700394234695016
reward_max: -94.98249299719889
reward_min: -97.30322128851542
queue_len: 0.06358060465565536
wait_time: 0.6017408400141665
delay_time: 4.170950311322529
pressure: 0.7855879752431477
total_envstep_count: 1661352
total_train_sample_count: 1661352
total_episode_count: 14322
total_duration: 53329.503420352936
[2025-02-21 08:31:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.564496567662342
avg_train_sample_per_sec: 31.564496567662342
avg_episode_per_sec: 0.27210772903157193
collect_time: 22.050090312957764
reward_mean: -95.16036414565826
reward_std: 1.816764026262249
reward_max: -92.91526610644254
reward_min: -98.32633053221285
queue_len: 0.06310368975176277
wait_time: 0.5965658257113633
delay_time: 4.153341492286265
pressure: 0.7756410256410257
total_envstep_count: 1662048
total_train_sample_count: 1662048
total_episode_count: 14328
total_duration: 53351.55351066589
[2025-02-21 08:31:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.17265847574344
avg_train_sample_per_sec: 32.17265847574344
avg_episode_per_sec: 0.2773505041012366
collect_time: 21.633275985717773
reward_mean: -98.78536414565825
reward_std: 4.664381785841376
reward_max: -92.71918767507002
reward_min: -105.49299719887955
queue_len: 0.06550753590560891
wait_time: 0.615227269068547
delay_time: 4.229068766394737
pressure: 0.806918656056587
total_envstep_count: 1662744
total_train_sample_count: 1662744
total_episode_count: 14334
total_duration: 53373.18678665161
[2025-02-21 08:32:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.94651331126433
avg_train_sample_per_sec: 31.94651331126433
avg_episode_per_sec: 0.27540097682124426
collect_time: 21.786415100097656
reward_mean: -98.17903828197944
reward_std: 1.417690274314055
reward_max: -96.10294117647058
reward_min: -100.14355742296918
queue_len: 0.0651054630517105
wait_time: 0.6109628201413192
delay_time: 4.2164929440865055
pressure: 0.8009504862953137
total_envstep_count: 1663440
total_train_sample_count: 1663440
total_episode_count: 14340
total_duration: 53394.97320175171
[2025-02-21 08:32:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.30358412447231
avg_train_sample_per_sec: 31.30358412447231
avg_episode_per_sec: 0.26985848383165784
collect_time: 22.23387575149536
reward_mean: -96.15604575163395
reward_std: 2.380825620584428
reward_max: -92.91526610644256
reward_min: -100.38165266106444
queue_len: 0.06376395606872279
wait_time: 0.5999007472131205
delay_time: 4.194391407226686
pressure: 0.7871352785145889
total_envstep_count: 1664136
total_train_sample_count: 1664136
total_episode_count: 14346
total_duration: 53417.207077503204
[2025-02-21 08:33:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.948504436527433
avg_train_sample_per_sec: 31.948504436527433
avg_episode_per_sec: 0.27541814169420203
collect_time: 21.785057306289673
reward_mean: -96.42880485527543
reward_std: 1.0931717723994132
reward_max: -94.08123249299713
reward_min: -97.28571428571429
queue_len: 0.06394483080588557
wait_time: 0.6032098958062447
delay_time: 4.138165458907002
pressure: 0.7937665782493369
total_envstep_count: 1664832
total_train_sample_count: 1664832
total_episode_count: 14352
total_duration: 53438.992134809494
[2025-02-21 08:33:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.6108032479856
avg_train_sample_per_sec: 31.6108032479856
avg_episode_per_sec: 0.2725069245516
collect_time: 22.017789125442505
reward_mean: -98.34325396825396
reward_std: 2.410508097434629
reward_max: -95.1435574229692
reward_min: -102.83053221288516
queue_len: 0.06521435939539387
wait_time: 0.6187675224820256
delay_time: 4.316041694513404
pressure: 0.8042661361626879
total_envstep_count: 1665528
total_train_sample_count: 1665528
total_episode_count: 14358
total_duration: 53461.00992393494
[2025-02-21 08:33:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.813302739521134
avg_train_sample_per_sec: 31.813302739521134
avg_episode_per_sec: 0.27425260982345806
collect_time: 21.87764048576355
reward_mean: -95.0890522875817
reward_std: 0.7726218770284785
reward_max: -93.81932773109241
reward_min: -95.9558823529412
queue_len: 0.06305640072120802
wait_time: 0.5957212018317496
delay_time: 4.1196713492094785
pressure: 0.7796198054818744
total_envstep_count: 1666224
total_train_sample_count: 1666224
total_episode_count: 14364
total_duration: 53482.8875644207
[2025-02-21 08:34:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.23424841825764
avg_train_sample_per_sec: 24.23424841825764
avg_episode_per_sec: 0.20891593464015207
collect_time: 28.719685792922974
reward_mean: -96.72584033613445
reward_std: 2.025375168987314
reward_max: -93.16316526610642
reward_min: -99.5028011204482
queue_len: 0.06414180393642867
wait_time: 0.604786996584664
delay_time: 4.170563818345269
pressure: 0.7912245800176834
total_envstep_count: 1666920
total_train_sample_count: 1666920
total_episode_count: 14370
total_duration: 53511.60725021362
[2025-02-21 08:34:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 25.393507662440157
avg_train_sample_per_sec: 25.393507662440157
avg_episode_per_sec: 0.2189095488141393
collect_time: 27.408580541610718
reward_mean: -95.7826797385621
reward_std: 1.709563794646438
reward_max: -93.72408963585433
reward_min: -99.08683473389355
queue_len: 0.06351636587437803
wait_time: 0.5982564666007871
delay_time: 4.1513491274047425
pressure: 0.7853669319186561
total_envstep_count: 1667616
total_train_sample_count: 1667616
total_episode_count: 14376
total_duration: 53539.015830755234
[2025-02-21 08:35:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 24.195841298467357
avg_train_sample_per_sec: 24.195841298467357
avg_episode_per_sec: 0.208584838779891
collect_time: 28.765273809432983
reward_mean: -96.31127450980391
reward_std: 1.2375039219758683
reward_max: -94.87394957983192
reward_min: -98.67857142857143
queue_len: 0.06386689291101054
wait_time: 0.6033161606817794
delay_time: 4.207130294267783
pressure: 0.7863616268788682
total_envstep_count: 1668312
total_train_sample_count: 1668312
total_episode_count: 14382
total_duration: 53567.78110456467
[2025-02-21 08:35:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.052178497705004
avg_train_sample_per_sec: 29.052178497705004
avg_episode_per_sec: 0.25044981463538796
collect_time: 23.956895351409912
reward_mean: -96.1018907563025
reward_std: 1.447467458554976
reward_max: -93.76330532212883
reward_min: -97.89845938375355
queue_len: 0.06372804426810509
wait_time: 0.6000941601220505
delay_time: 4.212668202999809
pressure: 0.7858090185676393
total_envstep_count: 1669008
total_train_sample_count: 1669008
total_episode_count: 14388
total_duration: 53591.73799991608
[2025-02-21 08:36:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.9861219264505
avg_train_sample_per_sec: 31.9861219264505
avg_episode_per_sec: 0.27574243040043533
collect_time: 21.75943684577942
reward_mean: -95.5484360410831
reward_std: 0.9581165696649039
reward_max: -94.42787114845935
reward_min: -97.01190476190472
queue_len: 0.06336103185748215
wait_time: 0.593556896675558
delay_time: 4.148377991802017
pressure: 0.7805039787798408
total_envstep_count: 1669704
total_train_sample_count: 1669704
total_episode_count: 14394
total_duration: 53613.497436761856
[2025-02-21 08:36:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.493072310318325
avg_train_sample_per_sec: 32.493072310318325
avg_episode_per_sec: 0.28011269233033037
collect_time: 21.419950485229492
reward_mean: -96.25035014005601
reward_std: 1.560570458827391
reward_max: -93.95378151260503
reward_min: -98.39915966386553
queue_len: 0.06382649213531566
wait_time: 0.599628312863607
delay_time: 4.17564177123089
pressure: 0.7830459770114943
total_envstep_count: 1670400
total_train_sample_count: 1670400
total_episode_count: 14400
total_duration: 53634.917387247086
[2025-02-21 08:36:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.317397433506066
avg_train_sample_per_sec: 32.317397433506066
avg_episode_per_sec: 0.27859825373712127
collect_time: 21.53638768196106
reward_mean: -95.69596171802054
reward_std: 1.1696561498580398
reward_max: -93.7233893557423
reward_min: -97.59173669467786
queue_len: 0.06345886055571653
wait_time: 0.5993004628907267
delay_time: 4.161609729781367
pressure: 0.7826038903625111
total_envstep_count: 1671096
total_train_sample_count: 1671096
total_episode_count: 14406
total_duration: 53656.45377492905
[2025-02-21 08:37:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.576975211156864
avg_train_sample_per_sec: 32.576975211156864
avg_episode_per_sec: 0.28083599319962815
collect_time: 21.36478281021118
reward_mean: -95.14787581699348
reward_std: 3.16524119931933
reward_max: -90.13515406162468
reward_min: -98.68977591036418
queue_len: 0.06309540836670655
wait_time: 0.5964025972900212
delay_time: 4.109481934758473
pressure: 0.7757515473032716
total_envstep_count: 1671792
total_train_sample_count: 1671792
total_episode_count: 14412
total_duration: 53677.81855773926
[2025-02-21 08:37:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.136164084778116
avg_train_sample_per_sec: 32.136164084778116
avg_episode_per_sec: 0.27703589728256994
collect_time: 21.657843112945557
reward_mean: -94.68580765639588
reward_std: 2.8453413246926926
reward_max: -91.06792717086837
reward_min: -100.0392156862745
queue_len: 0.0627889971196259
wait_time: 0.5945093333531467
delay_time: 4.136370511221152
pressure: 0.7717727674624227
total_envstep_count: 1672488
total_train_sample_count: 1672488
total_episode_count: 14418
total_duration: 53699.4764008522
[2025-02-21 08:37:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.227267203445635
avg_train_sample_per_sec: 32.227267203445635
avg_episode_per_sec: 0.27782126899522097
collect_time: 21.59661865234375
reward_mean: -95.31267507002799
reward_std: 3.011299554174133
reward_max: -92.32492997198878
reward_min: -101.7906162464986
queue_len: 0.063204691691
wait_time: 0.5962111192841416
delay_time: 4.133404626092221
pressure: 0.7747568523430591
total_envstep_count: 1673184
total_train_sample_count: 1673184
total_episode_count: 14424
total_duration: 53721.07301950455
[2025-02-21 08:38:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.550604651443884
avg_train_sample_per_sec: 32.550604651443884
avg_episode_per_sec: 0.28060866078830937
collect_time: 21.382091283798218
reward_mean: -95.3374183006536
reward_std: 3.1337354379468527
reward_max: -91.4824929971989
reward_min: -100.63095238095238
queue_len: 0.06322109966886842
wait_time: 0.6001609529753547
delay_time: 4.119492982655494
pressure: 0.7827144120247569
total_envstep_count: 1673880
total_train_sample_count: 1673880
total_episode_count: 14430
total_duration: 53742.455110788345
[2025-02-21 08:38:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.44244879535539
avg_train_sample_per_sec: 32.44244879535539
avg_episode_per_sec: 0.27967628271858097
collect_time: 21.45337438583374
reward_mean: -95.98646125116711
reward_std: 3.4082497962504315
reward_max: -89.4698879551821
reward_min: -100.421568627451
queue_len: 0.06365149950342648
wait_time: 0.6010404825059996
delay_time: 4.1394955657314645
pressure: 0.7865826702033599
total_envstep_count: 1674576
total_train_sample_count: 1674576
total_episode_count: 14436
total_duration: 53763.90848517418
[2025-02-21 08:38:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52270706123624
avg_train_sample_per_sec: 32.52270706123624
avg_episode_per_sec: 0.2803681643210021
collect_time: 21.400432586669922
reward_mean: -95.50513538748834
reward_std: 2.169943203167984
reward_max: -92.39425770308127
reward_min: -99.6015406162465
queue_len: 0.06333231789621242
wait_time: 0.5905913868642064
delay_time: 4.196380382024415
pressure: 0.7821618037135277
total_envstep_count: 1675272
total_train_sample_count: 1675272
total_episode_count: 14442
total_duration: 53785.30891776085
[2025-02-21 08:39:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.976825103223078
avg_train_sample_per_sec: 30.976825103223078
avg_episode_per_sec: 0.26704159571744035
collect_time: 22.468409776687622
reward_mean: -95.59197012138189
reward_std: 2.842814454207432
reward_max: -90.33893557422967
reward_min: -100.04341736694676
queue_len: 0.06338990061099593
wait_time: 0.5980333335810009
delay_time: 4.1251690900623155
pressure: 0.7822723253757737
total_envstep_count: 1675968
total_train_sample_count: 1675968
total_episode_count: 14448
total_duration: 53807.77732753754
[2025-02-21 08:39:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.40208680560172
avg_train_sample_per_sec: 29.40208680560172
avg_episode_per_sec: 0.25346626556553203
collect_time: 23.671789169311523
reward_mean: -95.23821195144724
reward_std: 1.2789095123022785
reward_max: -93.73809523809526
reward_min: -97.27100840336138
queue_len: 0.06315531296515069
wait_time: 0.5967720089804268
delay_time: 4.156138160663777
pressure: 0.7754199823165342
total_envstep_count: 1676664
total_train_sample_count: 1676664
total_episode_count: 14454
total_duration: 53831.44911670685
[2025-02-21 08:40:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.35655226827396
avg_train_sample_per_sec: 32.35655226827396
avg_episode_per_sec: 0.2789357954161548
collect_time: 21.510326385498047
reward_mean: -95.17401960784314
reward_std: 1.8472125175924834
reward_max: -92.953781512605
reward_min: -98.70658263305317
queue_len: 0.06311274509803921
wait_time: 0.5929374955110248
delay_time: 4.167765927062931
pressure: 0.7745358090185676
total_envstep_count: 1677360
total_train_sample_count: 1677360
total_episode_count: 14460
total_duration: 53852.959443092346
[2025-02-21 08:40:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.56086926110381
avg_train_sample_per_sec: 32.56086926110381
avg_episode_per_sec: 0.2806971488026191
collect_time: 21.37535071372986
reward_mean: -95.249883286648
reward_std: 1.518380104483864
reward_max: -92.9453781512605
reward_min: -97.79131652661066
queue_len: 0.06316305257735279
wait_time: 0.5930069198324776
delay_time: 4.162703246659891
pressure: 0.7761936339522547
total_envstep_count: 1678056
total_train_sample_count: 1678056
total_episode_count: 14466
total_duration: 53874.334793806076
[2025-02-21 08:40:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.16589146953701
avg_train_sample_per_sec: 32.16589146953701
avg_episode_per_sec: 0.2772921678408363
collect_time: 21.637827157974243
reward_mean: -95.32948179271706
reward_std: 2.5582240096295683
reward_max: -90.48319327731089
reward_min: -98.27380952380952
queue_len: 0.063215836732571
wait_time: 0.5964048417775598
delay_time: 4.1321748553540845
pressure: 0.7828249336870027
total_envstep_count: 1678752
total_train_sample_count: 1678752
total_episode_count: 14472
total_duration: 53895.97262096405
[2025-02-21 08:41:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.331766485976324
avg_train_sample_per_sec: 32.331766485976324
avg_episode_per_sec: 0.27872212487910625
collect_time: 21.526816368103027
reward_mean: -97.30847338935574
reward_std: 4.861027621816658
reward_max: -93.54341736694673
reward_min: -106.98039215686275
queue_len: 0.06452816537755686
wait_time: 0.6046713667783649
delay_time: 4.274086492717271
pressure: 0.7895667550839964
total_envstep_count: 1679448
total_train_sample_count: 1679448
total_episode_count: 14478
total_duration: 53917.49943733215
[2025-02-21 08:41:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.24563718268115
avg_train_sample_per_sec: 32.24563718268115
avg_episode_per_sec: 0.2779796308851823
collect_time: 21.584315299987793
reward_mean: -95.29108309990663
reward_std: 5.138548842313037
reward_max: -90.85714285714289
reward_min: -106.2275910364146
queue_len: 0.06319037340842615
wait_time: 0.5935781806091137
delay_time: 4.101117562093225
pressure: 0.7758620689655172
total_envstep_count: 1680144
total_train_sample_count: 1680144
total_episode_count: 14484
total_duration: 53939.08375263214
[2025-02-21 08:41:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.47177379418308
avg_train_sample_per_sec: 32.47177379418308
avg_episode_per_sec: 0.2799290844326127
collect_time: 21.43400001525879
reward_mean: -95.80917366946782
reward_std: 4.109381983965753
reward_max: -91.54131652661064
reward_min: -103.99719887955185
queue_len: 0.0635339347940768
wait_time: 0.596120488425255
delay_time: 4.149795755796098
pressure: 0.7808355437665782
total_envstep_count: 1680840
total_train_sample_count: 1680840
total_episode_count: 14490
total_duration: 53960.5177526474
[2025-02-21 08:42:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.376964421086704
avg_train_sample_per_sec: 32.376964421086704
avg_episode_per_sec: 0.27911176225074746
collect_time: 21.49676513671875
reward_mean: -97.453431372549
reward_std: 2.7247867289191463
reward_max: -93.38935574229689
reward_min: -100.74859943977593
queue_len: 0.06462429136110676
wait_time: 0.6130556886768855
delay_time: 4.2611718694009
pressure: 0.7870247568523432
total_envstep_count: 1681536
total_train_sample_count: 1681536
total_episode_count: 14496
total_duration: 53982.01451778412
[2025-02-21 08:42:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.66695128673007
avg_train_sample_per_sec: 32.66695128673007
avg_episode_per_sec: 0.281611649023535
collect_time: 21.305936813354492
reward_mean: -94.41725023342671
reward_std: 1.8883209761818887
reward_max: -91.36834733893558
reward_min: -97.46638655462186
queue_len: 0.06261090864285591
wait_time: 0.5878285774964275
delay_time: 4.094030814767059
pressure: 0.7701149425287355
total_envstep_count: 1682232
total_train_sample_count: 1682232
total_episode_count: 14502
total_duration: 54003.32045459747
[2025-02-21 08:43:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.48864968903894
avg_train_sample_per_sec: 32.48864968903894
avg_episode_per_sec: 0.2800745662848184
collect_time: 21.422866344451904
reward_mean: -97.59313725490195
reward_std: 2.412220671741973
reward_max: -94.09103641456583
reward_min: -100.0861344537815
queue_len: 0.06471693451916576
wait_time: 0.6169690687946267
delay_time: 4.173150700496746
pressure: 0.7894562334217506
total_envstep_count: 1682928
total_train_sample_count: 1682928
total_episode_count: 14508
total_duration: 54024.743320941925
[2025-02-21 08:43:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.662108087591875
avg_train_sample_per_sec: 32.662108087591875
avg_episode_per_sec: 0.2815698973068265
collect_time: 21.309096097946167
reward_mean: -94.88328664799253
reward_std: 2.3869444107864144
reward_max: -92.44817927170868
reward_min: -97.91596638655463
queue_len: 0.06291995135808523
wait_time: 0.5956293326349108
delay_time: 4.120817169280495
pressure: 0.7703359858532273
total_envstep_count: 1683624
total_train_sample_count: 1683624
total_episode_count: 14514
total_duration: 54046.05241703987
[2025-02-21 08:43:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.46652790931833
avg_train_sample_per_sec: 32.46652790931833
avg_episode_per_sec: 0.279883861287227
collect_time: 21.43746328353882
reward_mean: -96.64425770308124
reward_std: 2.425623603359519
reward_max: -93.57282913165267
reward_min: -100.0581232492997
queue_len: 0.06408770404713608
wait_time: 0.6008634775749382
delay_time: 4.186041308024345
pressure: 0.7852564102564102
total_envstep_count: 1684320
total_train_sample_count: 1684320
total_episode_count: 14520
total_duration: 54067.48988032341
[2025-02-21 08:44:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.528506098875695
avg_train_sample_per_sec: 32.528506098875695
avg_episode_per_sec: 0.2804181560247904
collect_time: 21.39661741256714
reward_mean: -94.45751633986924
reward_std: 1.6301842004645066
reward_max: -92.31862745098037
reward_min: -96.93907563025208
queue_len: 0.06263761030495309
wait_time: 0.592875191632798
delay_time: 4.104799260025376
pressure: 0.7660256410256411
total_envstep_count: 1685016
total_train_sample_count: 1685016
total_episode_count: 14526
total_duration: 54088.88649773598
[2025-02-21 08:44:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.86026753550953
avg_train_sample_per_sec: 32.86026753550953
avg_episode_per_sec: 0.2832781684095649
collect_time: 21.180594444274902
reward_mean: -95.80637254901961
reward_std: 0.6924873067740568
reward_max: -94.98459383753502
reward_min: -96.75420168067225
queue_len: 0.06353207728714828
wait_time: 0.6000035292631641
delay_time: 4.124695628757068
pressure: 0.7835985853227233
total_envstep_count: 1685712
total_train_sample_count: 1685712
total_episode_count: 14532
total_duration: 54110.06709218025
[2025-02-21 08:44:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.798543570067835
avg_train_sample_per_sec: 32.798543570067835
avg_episode_per_sec: 0.2827460652592055
collect_time: 21.220454454421997
reward_mean: -94.69922969187677
reward_std: 2.4468875641393546
reward_max: -91.03851540616246
reward_min: -96.99649859943979
queue_len: 0.06279789767365833
wait_time: 0.5938489122439427
delay_time: 4.060441613515867
pressure: 0.7756410256410257
total_envstep_count: 1686408
total_train_sample_count: 1686408
total_episode_count: 14538
total_duration: 54131.287546634674
[2025-02-21 08:45:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.454479195506046
avg_train_sample_per_sec: 32.454479195506046
avg_episode_per_sec: 0.2797799930647073
collect_time: 21.445421934127808
reward_mean: -95.11064425770307
reward_std: 2.1099764773415077
reward_max: -91.07913165266108
reward_min: -97.2703081232493
queue_len: 0.06307071900378187
wait_time: 0.5995484400656815
delay_time: 4.143840127462016
pressure: 0.7779619805481874
total_envstep_count: 1687104
total_train_sample_count: 1687104
total_episode_count: 14544
total_duration: 54152.7329685688
[2025-02-21 08:45:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.60332626713173
avg_train_sample_per_sec: 32.60332626713173
avg_episode_per_sec: 0.2810631574752735
collect_time: 21.347515106201172
reward_mean: -95.7921335200747
reward_std: 1.6693105993697726
reward_max: -93.45098039215691
reward_min: -98.45308123249298
queue_len: 0.06352263496026174
wait_time: 0.6024014933117368
delay_time: 4.13736591460482
pressure: 0.7870247568523431
total_envstep_count: 1687800
total_train_sample_count: 1687800
total_episode_count: 14550
total_duration: 54174.080483675
[2025-02-21 08:45:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.656452745009766
avg_train_sample_per_sec: 32.656452745009766
avg_episode_per_sec: 0.2815211443535324
collect_time: 21.3127863407135
reward_mean: -96.13375350140053
reward_std: 2.8241242340549135
reward_max: -93.54411764705887
reward_min: -101.81722689075625
queue_len: 0.06374917340941681
wait_time: 0.5987953757984185
delay_time: 4.185358858259023
pressure: 0.7817197170645446
total_envstep_count: 1688496
total_train_sample_count: 1688496
total_episode_count: 14556
total_duration: 54195.39327001572
[2025-02-21 08:46:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.67374683236296
avg_train_sample_per_sec: 32.67374683236296
avg_episode_per_sec: 0.28167023131347374
collect_time: 21.30150556564331
reward_mean: -95.47514005602243
reward_std: 2.9667548497264984
reward_max: -93.54061624649863
reward_min: -102.05532212885149
queue_len: 0.06331242709285306
wait_time: 0.6011406330878948
delay_time: 4.1518651053521305
pressure: 0.7787356321839081
total_envstep_count: 1689192
total_train_sample_count: 1689192
total_episode_count: 14562
total_duration: 54216.69477558136
[2025-02-21 08:46:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22949879103315
avg_train_sample_per_sec: 32.22949879103315
avg_episode_per_sec: 0.2778405068192513
collect_time: 21.595123291015625
reward_mean: -95.98272642390289
reward_std: 2.9337423461823477
reward_max: -92.75
reward_min: -100.49299719887956
queue_len: 0.06364902282752181
wait_time: 0.5997717278777116
delay_time: 4.193232002690439
pressure: 0.7865826702033599
total_envstep_count: 1689888
total_train_sample_count: 1689888
total_episode_count: 14568
total_duration: 54238.289898872375
[2025-02-21 08:47:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.564373242959746
avg_train_sample_per_sec: 32.564373242959746
avg_episode_per_sec: 0.28072735554275646
collect_time: 21.373050689697266
reward_mean: -97.37535014005603
reward_std: 0.8991029415689011
reward_max: -96.25560224089637
reward_min: -98.55882352941178
queue_len: 0.06457251335547481
wait_time: 0.6134348522786657
delay_time: 4.222358541948883
pressure: 0.7924403183023871
total_envstep_count: 1690584
total_train_sample_count: 1690584
total_episode_count: 14574
total_duration: 54259.66294956207
[2025-02-21 08:47:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.888322500815946
avg_train_sample_per_sec: 32.888322500815946
avg_episode_per_sec: 0.28352002155875816
collect_time: 21.162526607513428
reward_mean: -94.73366013071895
reward_std: 1.1884693406763593
reward_max: -93.09313725490198
reward_min: -96.3410364145658
queue_len: 0.06282072952965446
wait_time: 0.5902470515173356
delay_time: 4.145466861325526
pressure: 0.7796198054818744
total_envstep_count: 1691280
total_train_sample_count: 1691280
total_episode_count: 14580
total_duration: 54280.825476169586
[2025-02-21 08:47:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26749168098672
avg_train_sample_per_sec: 32.26749168098672
avg_episode_per_sec: 0.27816803173264415
collect_time: 21.5696964263916
reward_mean: -97.13468720821659
reward_std: 3.6553044768405023
reward_max: -91.66246498599433
reward_min: -103.59173669467786
queue_len: 0.06441292255186777
wait_time: 0.610698899365228
delay_time: 4.2369799909162635
pressure: 0.7900088417329797
total_envstep_count: 1691976
total_train_sample_count: 1691976
total_episode_count: 14586
total_duration: 54302.39517259598
[2025-02-21 08:48:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.219814688436244
avg_train_sample_per_sec: 32.219814688436244
avg_episode_per_sec: 0.27775702317617457
collect_time: 21.601613998413086
reward_mean: -96.14915966386555
reward_std: 1.1254395416923482
reward_max: -94.08823529411767
reward_min: -97.4040616246499
queue_len: 0.06375938969752357
wait_time: 0.5990092212835622
delay_time: 4.199631451200622
pressure: 0.7818302387267905
total_envstep_count: 1692672
total_train_sample_count: 1692672
total_episode_count: 14592
total_duration: 54323.99678659439
[2025-02-21 08:48:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52786564613106
avg_train_sample_per_sec: 32.52786564613106
avg_episode_per_sec: 0.2804126348804402
collect_time: 21.39703869819641
reward_mean: -98.02964519140988
reward_std: 3.442526476814026
reward_max: -94.59733893557421
reward_min: -104.593837535014
queue_len: 0.0650063960155238
wait_time: 0.616666527353647
delay_time: 4.241263475828258
pressure: 0.7959770114942529
total_envstep_count: 1693368
total_train_sample_count: 1693368
total_episode_count: 14598
total_duration: 54345.39382529259
[2025-02-21 08:48:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.482889791845544
avg_train_sample_per_sec: 32.482889791845544
avg_episode_per_sec: 0.28002491199866847
collect_time: 21.42666506767273
reward_mean: -96.21907096171803
reward_std: 3.425349174563127
reward_max: -92.37955182072828
reward_min: -102.40686274509804
queue_len: 0.06380574997461408
wait_time: 0.6070856614086837
delay_time: 4.158529627005167
pressure: 0.7903404067197171
total_envstep_count: 1694064
total_train_sample_count: 1694064
total_episode_count: 14604
total_duration: 54366.82049036026
[2025-02-21 08:49:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.8534282064671
avg_train_sample_per_sec: 32.8534282064671
avg_episode_per_sec: 0.2832192086764405
collect_time: 21.185003757476807
reward_mean: -94.4891456582633
reward_std: 1.9371781520454117
reward_max: -91.58683473389355
reward_min: -97.30112044817928
queue_len: 0.06265858465402076
wait_time: 0.590839054454673
delay_time: 4.139103736013887
pressure: 0.7716622458001767
total_envstep_count: 1694760
total_train_sample_count: 1694760
total_episode_count: 14610
total_duration: 54388.00549411774
[2025-02-21 08:49:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.656393563900636
avg_train_sample_per_sec: 32.656393563900636
avg_episode_per_sec: 0.2815206341715572
collect_time: 21.312824964523315
reward_mean: -96.25210084033614
reward_std: 5.365779701042405
reward_max: -89.62044817927172
reward_min: -106.29341736694677
queue_len: 0.06382765307714598
wait_time: 0.6042562913759669
delay_time: 4.224838033373303
pressure: 0.7810565870910698
total_envstep_count: 1695456
total_train_sample_count: 1695456
total_episode_count: 14616
total_duration: 54409.31831908226
[2025-02-21 08:50:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.47224805140244
avg_train_sample_per_sec: 32.47224805140244
avg_episode_per_sec: 0.27993317285691754
collect_time: 21.43368697166443
reward_mean: -95.27450980392159
reward_std: 2.3785166661984554
reward_max: -90.91456582633052
reward_min: -98.02100840336135
queue_len: 0.06317938315909918
wait_time: 0.6002802203993889
delay_time: 4.1390076132298095
pressure: 0.7811671087533156
total_envstep_count: 1696152
total_train_sample_count: 1696152
total_episode_count: 14622
total_duration: 54430.752006053925
[2025-02-21 08:50:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52695665972907
avg_train_sample_per_sec: 32.52695665972907
avg_episode_per_sec: 0.28040479879076785
collect_time: 21.397636651992798
reward_mean: -94.83415032679737
reward_std: 1.7431110676587411
reward_max: -91.32843137254903
reward_min: -96.42366946778706
queue_len: 0.06288736759071444
wait_time: 0.5929946912451982
delay_time: 4.14311402789889
pressure: 0.7768567639257293
total_envstep_count: 1696848
total_train_sample_count: 1696848
total_episode_count: 14628
total_duration: 54452.14964270592
[2025-02-21 08:50:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.48135517611824
avg_train_sample_per_sec: 32.48135517611824
avg_episode_per_sec: 0.2800116825527435
collect_time: 21.427677392959595
reward_mean: -94.66328197945843
reward_std: 2.5998715799724055
reward_max: -90.10434173669469
reward_min: -97.49509803921565
queue_len: 0.0627740596680759
wait_time: 0.5928148226576219
delay_time: 4.128816087515819
pressure: 0.7714412024756853
total_envstep_count: 1697544
total_train_sample_count: 1697544
total_episode_count: 14634
total_duration: 54473.57732009888
[2025-02-21 08:51:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.66842525516916
avg_train_sample_per_sec: 32.66842525516916
avg_episode_per_sec: 0.28162435564801
collect_time: 21.304975509643555
reward_mean: -95.1031746031746
reward_std: 2.571207457079552
reward_max: -90.59313725490196
reward_min: -99.39845938375349
queue_len: 0.06306576565197256
wait_time: 0.5963145205031616
delay_time: 4.099976293435299
pressure: 0.7744252873563218
total_envstep_count: 1698240
total_train_sample_count: 1698240
total_episode_count: 14640
total_duration: 54494.88229560852
[2025-02-21 08:51:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.713201861752054
avg_train_sample_per_sec: 32.713201861752054
avg_episode_per_sec: 0.2820103608771729
collect_time: 21.275814056396484
reward_mean: -96.14740896358542
reward_std: 2.8654696849380388
reward_max: -91.2422969187675
reward_min: -100.68977591036412
queue_len: 0.06375822875569326
wait_time: 0.6017803894325192
delay_time: 4.176952853552709
pressure: 0.7807250221043325
total_envstep_count: 1698936
total_train_sample_count: 1698936
total_episode_count: 14646
total_duration: 54516.15810966492
[2025-02-21 08:51:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.50205795240466
avg_train_sample_per_sec: 32.50205795240466
avg_episode_per_sec: 0.2801901547621091
collect_time: 21.414028644561768
reward_mean: -95.6218487394958
reward_std: 2.9245569136813
reward_max: -90.4110644257703
reward_min: -100.05112044817926
queue_len: 0.0634097140182333
wait_time: 0.5970030364046591
delay_time: 4.163386859043855
pressure: 0.7749778956675509
total_envstep_count: 1699632
total_train_sample_count: 1699632
total_episode_count: 14652
total_duration: 54537.57213830948
[2025-02-21 08:52:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.891445929525304
avg_train_sample_per_sec: 32.891445929525304
avg_episode_per_sec: 0.28354694766832156
collect_time: 21.16051697731018
reward_mean: -94.10842670401492
reward_std: 2.091914957902861
reward_max: -90.1764705882353
reward_min: -96.43907563025208
queue_len: 0.062406118503988674
wait_time: 0.5899363060874216
delay_time: 4.0338441321490714
pressure: 0.769893899204244
total_envstep_count: 1700328
total_train_sample_count: 1700328
total_episode_count: 14658
total_duration: 54558.73265528679
[2025-02-21 08:52:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.71036692422517
avg_train_sample_per_sec: 32.71036692422517
avg_episode_per_sec: 0.2819859217605618
collect_time: 21.277657985687256
reward_mean: -94.0454014939309
reward_std: 1.0323110983833355
reward_max: -93.14565826330531
reward_min: -95.9075630252101
queue_len: 0.06236432459809741
wait_time: 0.5865766178266179
delay_time: 4.101953470723741
pressure: 0.760499557913351
total_envstep_count: 1701024
total_train_sample_count: 1701024
total_episode_count: 14664
total_duration: 54580.010313272476
[2025-02-21 08:52:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.689490622602236
avg_train_sample_per_sec: 32.689490622602236
avg_episode_per_sec: 0.2818059536431227
collect_time: 21.29124641418457
reward_mean: -94.22700746965451
reward_std: 3.617785535608947
reward_max: -90.37675070028008
reward_min: -100.95098039215684
queue_len: 0.06248475296396189
wait_time: 0.5886489763898486
delay_time: 4.085170561448741
pressure: 0.7734305923961097
total_envstep_count: 1701720
total_train_sample_count: 1701720
total_episode_count: 14670
total_duration: 54601.30155968666
[2025-02-21 08:53:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.68622865982095
avg_train_sample_per_sec: 32.68622865982095
avg_episode_per_sec: 0.2817778332743185
collect_time: 21.293371200561523
reward_mean: -94.86297852474324
reward_std: 1.9806381008106968
reward_max: -92.33333333333331
reward_min: -98.14215686274513
queue_len: 0.0629064844328536
wait_time: 0.5958199592834482
delay_time: 4.084318014855134
pressure: 0.7736516357206012
total_envstep_count: 1702416
total_train_sample_count: 1702416
total_episode_count: 14676
total_duration: 54622.59493088722
[2025-02-21 08:53:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64940585616861
avg_train_sample_per_sec: 32.64940585616861
avg_episode_per_sec: 0.2814603953117984
collect_time: 21.317386388778687
reward_mean: -95.67868814192343
reward_std: 2.269552723828215
reward_max: -91.33543417366947
reward_min: -97.6267507002801
queue_len: 0.06344740592965743
wait_time: 0.6000943149142947
delay_time: 4.126263578995606
pressure: 0.7805039787798408
total_envstep_count: 1703112
total_train_sample_count: 1703112
total_episode_count: 14682
total_duration: 54643.912317276
[2025-02-21 08:54:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.53758352157781
avg_train_sample_per_sec: 32.53758352157781
avg_episode_per_sec: 0.2804964096687742
collect_time: 21.390648126602173
reward_mean: -93.98039215686272
reward_std: 1.6578355311987665
reward_max: -91.94397759103641
reward_min: -96.20658263305316
queue_len: 0.062321214958131775
wait_time: 0.5840755621435134
delay_time: 4.086214360312488
pressure: 0.7674624226348365
total_envstep_count: 1703808
total_train_sample_count: 1703808
total_episode_count: 14688
total_duration: 54665.3029654026
[2025-02-21 08:54:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.558278172566006
avg_train_sample_per_sec: 32.558278172566006
avg_episode_per_sec: 0.28067481183246556
collect_time: 21.377051830291748
reward_mean: -95.55053688141923
reward_std: 2.7427915473294218
reward_max: -92.35574229691876
reward_min: -100.45518207282915
queue_len: 0.06336242498767855
wait_time: 0.5919157893042274
delay_time: 4.1739934898178435
pressure: 0.777740937223696
total_envstep_count: 1704504
total_train_sample_count: 1704504
total_episode_count: 14694
total_duration: 54686.680017232895
[2025-02-21 08:54:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.86105468111005
avg_train_sample_per_sec: 32.86105468111005
avg_episode_per_sec: 0.2832849541475004
collect_time: 21.180087089538574
reward_mean: -95.44035947712418
reward_std: 3.3403101348426043
reward_max: -92.42857142857142
reward_min: -102.6393557422969
queue_len: 0.06328936304849084
wait_time: 0.5936746935732736
delay_time: 4.167344406476757
pressure: 0.774867374005305
total_envstep_count: 1705200
total_train_sample_count: 1705200
total_episode_count: 14700
total_duration: 54707.86010432243
[2025-02-21 08:55:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.7861393231535
avg_train_sample_per_sec: 32.7861393231535
avg_episode_per_sec: 0.2826391320961509
collect_time: 21.228482961654663
reward_mean: -93.59675536881417
reward_std: 1.4291291075131656
reward_max: -91.88095238095237
reward_min: -95.68767507002799
queue_len: 0.06206681390504918
wait_time: 0.5859601577147217
delay_time: 4.111843718642573
pressure: 0.7652519893899203
total_envstep_count: 1705896
total_train_sample_count: 1705896
total_episode_count: 14706
total_duration: 54729.08858728409
[2025-02-21 08:55:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.3849981763692
avg_train_sample_per_sec: 32.3849981763692
avg_episode_per_sec: 0.27918101876180346
collect_time: 21.491432428359985
reward_mean: -97.32212885154063
reward_std: 3.1518676923072197
reward_max: -93.33613445378147
reward_min: -102.30672268907563
queue_len: 0.06453722072383329
wait_time: 0.6111838634658107
delay_time: 4.222493534946616
pressure: 0.787577365163572
total_envstep_count: 1706592
total_train_sample_count: 1706592
total_episode_count: 14712
total_duration: 54750.58001971245
[2025-02-21 08:55:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.342688276146646
avg_train_sample_per_sec: 32.342688276146646
avg_episode_per_sec: 0.2788162782426435
collect_time: 21.51954698562622
reward_mean: -94.95588235294116
reward_std: 1.2258988247637213
reward_max: -93.31652661064422
reward_min: -96.95798319327731
queue_len: 0.0629680917459822
wait_time: 0.5887867414870458
delay_time: 4.119822206711829
pressure: 0.7709991158267021
total_envstep_count: 1707288
total_train_sample_count: 1707288
total_episode_count: 14718
total_duration: 54772.099566698074
[2025-02-21 08:56:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.763517302976766
avg_train_sample_per_sec: 32.763517302976766
avg_episode_per_sec: 0.2824441146808342
collect_time: 21.24314045906067
reward_mean: -96.68545751633987
reward_std: 2.3885268864153235
reward_max: -94.1358543417367
reward_min: -100.52871148459381
queue_len: 0.06411502487820947
wait_time: 0.603144031706405
delay_time: 4.195725406520022
pressure: 0.787577365163572
total_envstep_count: 1707984
total_train_sample_count: 1707984
total_episode_count: 14724
total_duration: 54793.342707157135
[2025-02-21 08:56:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.750365724974614
avg_train_sample_per_sec: 32.750365724974614
avg_episode_per_sec: 0.2823307390084019
collect_time: 21.251671075820923
reward_mean: -95.25186741363211
reward_std: 2.954868469722691
reward_max: -92.2598039215686
reward_min: -100.62955182072828
queue_len: 0.06316436831142713
wait_time: 0.5955604500863122
delay_time: 4.156439929447401
pressure: 0.7763041556145005
total_envstep_count: 1708680
total_train_sample_count: 1708680
total_episode_count: 14730
total_duration: 54814.594378232956
[2025-02-21 08:56:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.57386360479057
avg_train_sample_per_sec: 32.57386360479057
avg_episode_per_sec: 0.28080916900681524
collect_time: 21.36682367324829
reward_mean: -94.23809523809524
reward_std: 2.1631875960627456
reward_max: -91.90196078431372
reward_min: -98.58753501400558
queue_len: 0.062492105595553855
wait_time: 0.5900174946194218
delay_time: 4.168424534710474
pressure: 0.7688992042440318
total_envstep_count: 1709376
total_train_sample_count: 1709376
total_episode_count: 14736
total_duration: 54835.961201906204
[2025-02-21 08:57:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.77655690059709
avg_train_sample_per_sec: 32.77655690059709
avg_episode_per_sec: 0.2825565250051474
collect_time: 21.234689235687256
reward_mean: -95.13573762838467
reward_std: 1.787079100592373
reward_max: -93.51750700280112
reward_min: -98.2766106442577
queue_len: 0.06308735917001639
wait_time: 0.5993559559102156
delay_time: 4.173074509344233
pressure: 0.7712201591511936
total_envstep_count: 1710072
total_train_sample_count: 1710072
total_episode_count: 14742
total_duration: 54857.19589114189
[2025-02-21 08:57:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64884972923773
avg_train_sample_per_sec: 32.64884972923773
avg_episode_per_sec: 0.2814556011141183
collect_time: 21.317749500274658
reward_mean: -96.37336601307187
reward_std: 0.9169463630452468
reward_max: -95.5735294117647
reward_min: -98.26960784313727
queue_len: 0.06390806764792566
wait_time: 0.6032101279946106
delay_time: 4.1963786036133355
pressure: 0.7807250221043325
total_envstep_count: 1710768
total_train_sample_count: 1710768
total_episode_count: 14748
total_duration: 54878.513640642166
[2025-02-21 08:58:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.515438897828275
avg_train_sample_per_sec: 32.515438897828275
avg_episode_per_sec: 0.28030550773989893
collect_time: 21.405216217041016
reward_mean: -95.58625116713351
reward_std: 2.1364505840201127
reward_max: -92.7892156862745
reward_min: -99.16036414565826
queue_len: 0.06338610820101691
wait_time: 0.6005802851644636
delay_time: 4.157416948615302
pressure: 0.7778514588859418
total_envstep_count: 1711464
total_train_sample_count: 1711464
total_episode_count: 14754
total_duration: 54899.91885685921
[2025-02-21 08:58:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.94853309313733
avg_train_sample_per_sec: 32.94853309313733
avg_episode_per_sec: 0.2840390783891149
collect_time: 21.12385392189026
reward_mean: -95.2359943977591
reward_std: 1.8455160602591003
reward_max: -92.91666666666664
reward_min: -98.79761904761907
queue_len: 0.06315384243883229
wait_time: 0.5973272487598046
delay_time: 4.1408952710041085
pressure: 0.7822723253757736
total_envstep_count: 1712160
total_train_sample_count: 1712160
total_episode_count: 14760
total_duration: 54921.0427107811
[2025-02-21 08:58:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.554724675998735
avg_train_sample_per_sec: 32.554724675998735
avg_episode_per_sec: 0.2806441782413684
collect_time: 21.379385232925415
reward_mean: -95.25548552754435
reward_std: 1.604072545747245
reward_max: -93.95168067226889
reward_min: -98.74509803921568
queue_len: 0.06316676759120977
wait_time: 0.5965070046586274
delay_time: 4.0984168317695975
pressure: 0.7757515473032713
total_envstep_count: 1712856
total_train_sample_count: 1712856
total_episode_count: 14766
total_duration: 54942.42209601402
[2025-02-21 08:59:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.80347192065684
avg_train_sample_per_sec: 32.80347192065684
avg_episode_per_sec: 0.28278855104014516
collect_time: 21.21726632118225
reward_mean: -95.23856209150325
reward_std: 2.4845371140229835
reward_max: -92.32703081232495
reward_min: -99.2801120448179
queue_len: 0.06315554515351675
wait_time: 0.5951319077586826
delay_time: 4.12657814735638
pressure: 0.7708885941644562
total_envstep_count: 1713552
total_train_sample_count: 1713552
total_episode_count: 14772
total_duration: 54963.639362335205
[2025-02-21 08:59:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.81072155710287
avg_train_sample_per_sec: 32.81072155710287
avg_episode_per_sec: 0.28285104790605925
collect_time: 21.212578296661377
reward_mean: -94.57551353874881
reward_std: 1.1505205434703607
reward_max: -92.38655462184877
reward_min: -96.03361344537812
queue_len: 0.0627158577843162
wait_time: 0.5839187576002992
delay_time: 4.156829916253492
pressure: 0.7631520778072503
total_envstep_count: 1714248
total_train_sample_count: 1714248
total_episode_count: 14778
total_duration: 54984.85194063187
[2025-02-21 08:59:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.68387519493283
avg_train_sample_per_sec: 32.68387519493283
avg_episode_per_sec: 0.28175754478390375
collect_time: 21.294904470443726
reward_mean: -96.01470588235293
reward_std: 3.611218950525687
reward_max: -91.74159663865544
reward_min: -100.87044817927166
queue_len: 0.06367022936495552
wait_time: 0.602787854752865
delay_time: 4.199055641822658
pressure: 0.774867374005305
total_envstep_count: 1714944
total_train_sample_count: 1714944
total_episode_count: 14784
total_duration: 55006.14684510231
[2025-02-21 09:00:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.802948232018068
avg_train_sample_per_sec: 31.802948232018068
avg_episode_per_sec: 0.27416334682774196
collect_time: 21.884763479232788
reward_mean: -98.69257703081234
reward_std: 2.9132782458070965
reward_max: -94.9607843137255
reward_min: -104.40826330532212
queue_len: 0.06544600598860235
wait_time: 0.6167975589882283
delay_time: 4.3443046474315326
pressure: 0.7998452696728559
total_envstep_count: 1715640
total_train_sample_count: 1715640
total_episode_count: 14790
total_duration: 55028.03160858154
[2025-02-21 09:00:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73759917337897
avg_train_sample_per_sec: 32.73759917337897
avg_episode_per_sec: 0.282220682529129
collect_time: 21.259958505630493
reward_mean: -96.812441643324
reward_std: 1.1936290030490002
reward_max: -95.24019607843135
reward_min: -98.56582633053223
queue_len: 0.06419923185896816
wait_time: 0.6091094926034074
delay_time: 4.184624689297795
pressure: 0.7911140583554377
total_envstep_count: 1716336
total_train_sample_count: 1716336
total_episode_count: 14796
total_duration: 55049.29156708717
[2025-02-21 09:00:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.89856989207638
avg_train_sample_per_sec: 32.89856989207638
avg_episode_per_sec: 0.2836083611385895
collect_time: 21.155934810638428
reward_mean: -96.18335667600371
reward_std: 1.798889415574322
reward_max: -94.49929971988796
reward_min: -99.83613445378151
queue_len: 0.06378206676127567
wait_time: 0.5992123861038667
delay_time: 4.162583599407516
pressure: 0.7872458001768347
total_envstep_count: 1717032
total_train_sample_count: 1717032
total_episode_count: 14802
total_duration: 55070.44750189781
[2025-02-21 09:01:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.617472604623494
avg_train_sample_per_sec: 32.617472604623494
avg_episode_per_sec: 0.2811851086605474
collect_time: 21.33825659751892
reward_mean: -95.61986461251166
reward_std: 1.1992542042698897
reward_max: -93.68837535014006
reward_min: -97.66806722689074
queue_len: 0.06340839828415892
wait_time: 0.5979180133591898
delay_time: 4.133672715109019
pressure: 0.787577365163572
total_envstep_count: 1717728
total_train_sample_count: 1717728
total_episode_count: 14808
total_duration: 55091.78575849533
[2025-02-21 09:01:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.07644843501814
avg_train_sample_per_sec: 32.07644843501814
avg_episode_per_sec: 0.2765211071984323
collect_time: 21.69816279411316
reward_mean: -98.140522875817
reward_std: 3.8172649956591536
reward_max: -93.82282913165267
reward_min: -103.65056022408963
queue_len: 0.06507992233144363
wait_time: 0.6170684454153014
delay_time: 4.236428937315857
pressure: 0.8055923961096374
total_envstep_count: 1718424
total_train_sample_count: 1718424
total_episode_count: 14814
total_duration: 55113.483921289444
[2025-02-21 09:02:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.266697049516665
avg_train_sample_per_sec: 32.266697049516665
avg_episode_per_sec: 0.27816118146135055
collect_time: 21.57022762298584
reward_mean: -95.7265406162465
reward_std: 2.2228341260313362
reward_max: -93.26610644257701
reward_min: -98.66456582633054
queue_len: 0.063479138339686
wait_time: 0.59794788826229
delay_time: 4.1248112500323355
pressure: 0.7868037135278515
total_envstep_count: 1719120
total_train_sample_count: 1719120
total_episode_count: 14820
total_duration: 55135.05414891243
[2025-02-21 09:02:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.54763670211501
avg_train_sample_per_sec: 32.54763670211501
avg_episode_per_sec: 0.2805830750182328
collect_time: 21.38404107093811
reward_mean: -97.35842670401492
reward_std: 2.4260486796638117
reward_max: -94.07002801120446
reward_min: -100.42857142857144
queue_len: 0.0645612909177818
wait_time: 0.6094568463990371
delay_time: 4.185941938907473
pressure: 0.8052608311229
total_envstep_count: 1719816
total_train_sample_count: 1719816
total_episode_count: 14826
total_duration: 55156.43818998337
[2025-02-21 09:02:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.612064415370575
avg_train_sample_per_sec: 32.612064415370575
avg_episode_per_sec: 0.28113848633940147
collect_time: 21.341795206069946
reward_mean: -97.33345004668534
reward_std: 2.67309089508804
reward_max: -93.57422969187672
reward_min: -101.23949579831934
queue_len: 0.06454472814766932
wait_time: 0.6132273532755278
delay_time: 4.246883550107461
pressure: 0.7992926613616268
total_envstep_count: 1720512
total_train_sample_count: 1720512
total_episode_count: 14832
total_duration: 55177.77998518944
[2025-02-21 09:03:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.6565448049392
avg_train_sample_per_sec: 32.6565448049392
avg_episode_per_sec: 0.28152193797361386
collect_time: 21.312726259231567
reward_mean: -96.63690476190477
reward_std: 2.72793191848396
reward_max: -92.97478991596634
reward_min: -100.37815126050418
queue_len: 0.06408282809144877
wait_time: 0.6028193549745273
delay_time: 4.1606079791648325
pressure: 0.7907824933687003
total_envstep_count: 1721208
total_train_sample_count: 1721208
total_episode_count: 14838
total_duration: 55199.09271144867
[2025-02-21 09:03:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.409360133655674
avg_train_sample_per_sec: 32.409360133655674
avg_episode_per_sec: 0.2793910356349627
collect_time: 21.475277423858643
reward_mean: -97.06909430438843
reward_std: 4.504906182033159
reward_max: -92.29551820728295
reward_min: -103.28291316526611
queue_len: 0.06436942593129205
wait_time: 0.611147796872949
delay_time: 4.196407774334865
pressure: 0.7971927497789566
total_envstep_count: 1721904
total_train_sample_count: 1721904
total_episode_count: 14844
total_duration: 55220.56798887253
[2025-02-21 09:03:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.53292833942031
avg_train_sample_per_sec: 32.53292833942031
avg_episode_per_sec: 0.28045627878810614
collect_time: 21.39370894432068
reward_mean: -96.21918767507003
reward_std: 2.450592839841391
reward_max: -92.45798319327731
reward_min: -99.51960784313727
queue_len: 0.0638058273707361
wait_time: 0.6067698852308386
delay_time: 4.1493201012939265
pressure: 0.792661361626879
total_envstep_count: 1722600
total_train_sample_count: 1722600
total_episode_count: 14850
total_duration: 55241.96169781685
[2025-02-21 09:04:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.59013777203396
avg_train_sample_per_sec: 32.59013777203396
avg_episode_per_sec: 0.2809494635520169
collect_time: 21.356153964996338
reward_mean: -95.44677871148458
reward_std: 2.0443097612431935
reward_max: -91.78221288515405
reward_min: -98.61134453781511
queue_len: 0.06329361983520199
wait_time: 0.6014513011216867
delay_time: 4.1653803213290805
pressure: 0.7787356321839081
total_envstep_count: 1723296
total_train_sample_count: 1723296
total_episode_count: 14856
total_duration: 55263.317851781845
[2025-02-21 09:04:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.621903029915636
avg_train_sample_per_sec: 32.621903029915636
avg_episode_per_sec: 0.2812233019820313
collect_time: 21.33535861968994
reward_mean: -95.94654528478058
reward_std: 2.9251970677966552
reward_max: -93.13725490196077
reward_min: -101.97128851540617
queue_len: 0.06362503002969534
wait_time: 0.6068204248985184
delay_time: 4.208739132709561
pressure: 0.7843722369584438
total_envstep_count: 1723992
total_train_sample_count: 1723992
total_episode_count: 14862
total_duration: 55284.653210401535
[2025-02-21 09:04:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.72296111657919
avg_train_sample_per_sec: 32.72296111657919
avg_episode_per_sec: 0.2820944923843034
collect_time: 21.269468784332275
reward_mean: -95.60025676937441
reward_std: 1.1073952582148352
reward_max: -94.33823529411764
reward_min: -97.4824929971989
queue_len: 0.06339539573565943
wait_time: 0.6015395327007902
delay_time: 4.180793202014679
pressure: 0.7760831122900088
total_envstep_count: 1724688
total_train_sample_count: 1724688
total_episode_count: 14868
total_duration: 55305.92267918587
[2025-02-21 09:05:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.56987827279105
avg_train_sample_per_sec: 32.56987827279105
avg_episode_per_sec: 0.2807748126964746
collect_time: 21.36943817138672
reward_mean: -95.26984126984128
reward_std: 2.4687530125307613
reward_max: -91.37885154061627
reward_min: -98.52100840336134
queue_len: 0.06317628731421836
wait_time: 0.5966597846034966
delay_time: 4.159315391460772
pressure: 0.7798408488063661
total_envstep_count: 1725384
total_train_sample_count: 1725384
total_episode_count: 14874
total_duration: 55327.292117357254
[2025-02-21 09:05:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.62190703989538
avg_train_sample_per_sec: 32.62190703989538
avg_episode_per_sec: 0.28122333655082227
collect_time: 21.33535599708557
reward_mean: -96.82317927170868
reward_std: 1.9811853743507841
reward_max: -94.77310924369746
reward_min: -100.86834733893558
queue_len: 0.06420635230219408
wait_time: 0.6077943003019068
delay_time: 4.2189350746920695
pressure: 0.7925508399646329
total_envstep_count: 1726080
total_train_sample_count: 1726080
total_episode_count: 14880
total_duration: 55348.62747335434
[2025-02-21 09:06:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.37408980311333
avg_train_sample_per_sec: 32.37408980311333
avg_episode_per_sec: 0.2790869810613218
collect_time: 21.498673915863037
reward_mean: -96.57236227824463
reward_std: 2.566320520240099
reward_max: -93.98739495798321
reward_min: -101.56372549019605
queue_len: 0.06404002803597125
wait_time: 0.6052514507129113
delay_time: 4.163217296542867
pressure: 0.7912245800176834
total_envstep_count: 1726776
total_train_sample_count: 1726776
total_episode_count: 14886
total_duration: 55370.1261472702
[2025-02-21 09:06:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.9120107351916
avg_train_sample_per_sec: 32.9120107351916
avg_episode_per_sec: 0.28372423047578965
collect_time: 21.147294998168945
reward_mean: -93.82002801120449
reward_std: 1.9843351898228767
reward_max: -90.31372549019605
reward_min: -97.04481792717088
queue_len: 0.06221487268647511
wait_time: 0.5863322008732759
delay_time: 4.065715826080818
pressure: 0.7659151193633953
total_envstep_count: 1727472
total_train_sample_count: 1727472
total_episode_count: 14892
total_duration: 55391.27344226837
[2025-02-21 09:06:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.60492341298263
avg_train_sample_per_sec: 32.60492341298263
avg_episode_per_sec: 0.2810769259739882
collect_time: 21.346469402313232
reward_mean: -96.54154995331466
reward_std: 3.0344110075039903
reward_max: -92.70868347338937
reward_min: -102.21358543417364
queue_len: 0.06401959545975773
wait_time: 0.6013186441685426
delay_time: 4.219685546780437
pressure: 0.7943191865605659
total_envstep_count: 1728168
total_train_sample_count: 1728168
total_episode_count: 14898
total_duration: 55412.619911670685
[2025-02-21 09:07:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.40579985701748
avg_train_sample_per_sec: 32.40579985701748
avg_episode_per_sec: 0.27936034359497824
collect_time: 21.47763681411743
reward_mean: -97.3705648926237
reward_std: 2.30258026652619
reward_max: -94.58053221288512
reward_min: -101.22619047619045
queue_len: 0.06456934011447196
wait_time: 0.608866468780262
delay_time: 4.2178075458012385
pressure: 0.7926613616268788
total_envstep_count: 1728864
total_train_sample_count: 1728864
total_episode_count: 14904
total_duration: 55434.0975484848
[2025-02-21 09:07:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.51911713009947
avg_train_sample_per_sec: 32.51911713009947
avg_episode_per_sec: 0.2803372166387885
collect_time: 21.40279507637024
reward_mean: -95.7309757236228
reward_std: 1.872896003083979
reward_max: -92.81722689075632
reward_min: -98.25210084033615
queue_len: 0.0634820793923228
wait_time: 0.5998824043322015
delay_time: 4.198019602258004
pressure: 0.7840406719717063
total_envstep_count: 1729560
total_train_sample_count: 1729560
total_episode_count: 14910
total_duration: 55455.50034356117
[2025-02-21 09:07:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73812748761373
avg_train_sample_per_sec: 32.73812748761373
avg_episode_per_sec: 0.2822252369621873
collect_time: 21.259615421295166
reward_mean: -94.77100840336135
reward_std: 1.9230161529624243
reward_max: -91.58473389355743
reward_min: -97.80672268907563
queue_len: 0.06284549628870116
wait_time: 0.5918793357307556
delay_time: 4.11957307689358
pressure: 0.7763041556145005
total_envstep_count: 1730256
total_train_sample_count: 1730256
total_episode_count: 14916
total_duration: 55476.75995898247
[2025-02-21 09:08:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.696813742628564
avg_train_sample_per_sec: 32.696813742628564
avg_episode_per_sec: 0.2818690839881773
collect_time: 21.28647780418396
reward_mean: -94.47537348272641
reward_std: 2.272993836815477
reward_max: -92.05182072829132
reward_min: -97.7892156862745
queue_len: 0.06264945191162229
wait_time: 0.5918296474204183
delay_time: 4.159831457185321
pressure: 0.7645888594164457
total_envstep_count: 1730952
total_train_sample_count: 1730952
total_episode_count: 14922
total_duration: 55498.04643678665
[2025-02-21 09:08:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52436009446924
avg_train_sample_per_sec: 32.52436009446924
avg_episode_per_sec: 0.2803824146074934
collect_time: 21.39934492111206
reward_mean: -97.08473389355744
reward_std: 1.4406075933905382
reward_max: -95.7668067226891
reward_min: -100.01890756302521
queue_len: 0.06437979701164287
wait_time: 0.6065099890530924
delay_time: 4.229602429732171
pressure: 0.79210875331565
total_envstep_count: 1731648
total_train_sample_count: 1731648
total_episode_count: 14928
total_duration: 55519.445781707764
[2025-02-21 09:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73016383068128
avg_train_sample_per_sec: 32.73016383068128
avg_episode_per_sec: 0.28215658474725236
collect_time: 21.264788150787354
reward_mean: -96.39577497665732
reward_std: 1.3654384439182663
reward_max: -94.67086834733894
reward_min: -98.48319327731092
queue_len: 0.06392292770335367
wait_time: 0.607742909276885
delay_time: 4.293878552571117
pressure: 0.7787356321839081
total_envstep_count: 1732344
total_train_sample_count: 1732344
total_episode_count: 14934
total_duration: 55540.71056985855
[2025-02-21 09:09:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.40632615017771
avg_train_sample_per_sec: 32.40632615017771
avg_episode_per_sec: 0.27936488060498027
collect_time: 21.477288007736206
reward_mean: -97.10866013071895
reward_std: 4.184942957863483
reward_max: -91.140756302521
reward_min: -104.30252100840337
queue_len: 0.06439566321665713
wait_time: 0.6082575934883236
delay_time: 4.287398746128174
pressure: 0.788129973474801
total_envstep_count: 1733040
total_train_sample_count: 1733040
total_episode_count: 14940
total_duration: 55562.18785786629
[2025-02-21 09:09:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.85823178494068
avg_train_sample_per_sec: 32.85823178494068
avg_episode_per_sec: 0.2832606188356955
collect_time: 21.181906700134277
reward_mean: -94.91923436041081
reward_std: 2.2683231525178496
reward_max: -91.71428571428572
reward_min: -97.32282913165264
queue_len: 0.06294378936366765
wait_time: 0.5908657561167704
delay_time: 4.115229798490407
pressure: 0.7781830238726789
total_envstep_count: 1733736
total_train_sample_count: 1733736
total_episode_count: 14946
total_duration: 55583.36976456642
[2025-02-21 09:10:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.636023537271186
avg_train_sample_per_sec: 32.636023537271186
avg_episode_per_sec: 0.2813450304937171
collect_time: 21.326127529144287
reward_mean: -96.86998132586366
reward_std: 1.376304770392328
reward_max: -94.5735294117647
reward_min: -98.31792717086839
queue_len: 0.06423738814712444
wait_time: 0.6066422590256261
delay_time: 4.246049884233977
pressure: 0.7874668435013262
total_envstep_count: 1734432
total_train_sample_count: 1734432
total_episode_count: 14952
total_duration: 55604.695892095566
[2025-02-21 09:10:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.62935819107511
avg_train_sample_per_sec: 32.62935819107511
avg_episode_per_sec: 0.2812875706127165
collect_time: 21.33048391342163
reward_mean: -93.99929971988796
reward_std: 1.0961089947521498
reward_max: -92.42366946778712
reward_min: -95.48319327731095
queue_len: 0.06233375312989917
wait_time: 0.5886143803233052
delay_time: 4.174060020465354
pressure: 0.7589522546419097
total_envstep_count: 1735128
total_train_sample_count: 1735128
total_episode_count: 14958
total_duration: 55626.02637600899
[2025-02-21 09:10:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.83312116120939
avg_train_sample_per_sec: 32.83312116120939
avg_episode_per_sec: 0.28304414794146027
collect_time: 21.19810652732849
reward_mean: -96.2545518207283
reward_std: 1.7769536550109186
reward_max: -94.24579831932776
reward_min: -99.41946778711483
queue_len: 0.06382927839570841
wait_time: 0.5984987938588344
delay_time: 4.22900887960795
pressure: 0.7832670203359858
total_envstep_count: 1735824
total_train_sample_count: 1735824
total_episode_count: 14964
total_duration: 55647.224482536316
[2025-02-21 09:11:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.77409695030484
avg_train_sample_per_sec: 32.77409695030484
avg_episode_per_sec: 0.28253531853711067
collect_time: 21.23628306388855
reward_mean: -95.34372082166202
reward_std: 2.026505680853713
reward_max: -92.43977591036419
reward_min: -97.50140056022406
queue_len: 0.06322527905945757
wait_time: 0.5972719105325598
delay_time: 4.15059057109023
pressure: 0.7787356321839081
total_envstep_count: 1736520
total_train_sample_count: 1736520
total_episode_count: 14970
total_duration: 55668.460765600204
[2025-02-21 09:11:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.41226297114525
avg_train_sample_per_sec: 32.41226297114525
avg_episode_per_sec: 0.2794160600960798
collect_time: 21.47335410118103
reward_mean: -94.71230158730158
reward_std: 1.7644383206391683
reward_max: -91.34943977591034
reward_min: -96.57913165266109
queue_len: 0.06280656603932465
wait_time: 0.5916086814920488
delay_time: 4.165129395029635
pressure: 0.7749778956675509
total_envstep_count: 1737216
total_train_sample_count: 1737216
total_episode_count: 14976
total_duration: 55689.934119701385
[2025-02-21 09:11:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.541925158921146
avg_train_sample_per_sec: 32.541925158921146
avg_episode_per_sec: 0.2805338375769064
collect_time: 21.387794256210327
reward_mean: -94.42483660130718
reward_std: 1.8716552406178992
reward_max: -91.88795518207279
reward_min: -97.21708683473389
queue_len: 0.06261593939078725
wait_time: 0.5932031963979224
delay_time: 4.165384973933328
pressure: 0.7692307692307692
total_envstep_count: 1737912
total_train_sample_count: 1737912
total_episode_count: 14982
total_duration: 55711.321913957596
[2025-02-21 09:12:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.6496139978436
avg_train_sample_per_sec: 32.6496139978436
avg_episode_per_sec: 0.28146218963658276
collect_time: 21.3172504901886
reward_mean: -94.500350140056
reward_std: 2.558854855607519
reward_max: -90.69187675070027
reward_min: -98.06652661064422
queue_len: 0.06266601468173476
wait_time: 0.5919410204400061
delay_time: 4.148380483211806
pressure: 0.7733200707338638
total_envstep_count: 1738608
total_train_sample_count: 1738608
total_episode_count: 14988
total_duration: 55732.639164447784
[2025-02-21 09:12:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.550702648729846
avg_train_sample_per_sec: 32.550702648729846
avg_episode_per_sec: 0.2806095055924987
collect_time: 21.38202691078186
reward_mean: -96.66654995331464
reward_std: 2.9735773505634646
reward_max: -93.47478991596638
reward_min: -102.67927170868344
queue_len: 0.06410248670644207
wait_time: 0.6032578040057756
delay_time: 4.201254767919438
pressure: 0.786472148541114
total_envstep_count: 1739304
total_train_sample_count: 1739304
total_episode_count: 14994
total_duration: 55754.021191358566
[2025-02-21 09:12:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.6635958725498
avg_train_sample_per_sec: 32.6635958725498
avg_episode_per_sec: 0.2815827230392224
collect_time: 21.308125495910645
reward_mean: -94.23541083099907
reward_std: 2.2509068763831155
reward_max: -90.47128851540616
reward_min: -97.51540616246501
queue_len: 0.062490325484747394
wait_time: 0.5896831433722914
delay_time: 4.15885311624928
pressure: 0.771551724137931
total_envstep_count: 1740000
total_train_sample_count: 1740000
total_episode_count: 15000
total_duration: 55775.32931685448
[2025-02-21 09:13:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.58942976650436
avg_train_sample_per_sec: 32.58942976650436
avg_episode_per_sec: 0.28094336005607207
collect_time: 21.35661792755127
reward_mean: -95.47093837535014
reward_std: 2.2702484607742286
reward_max: -92.15056022408967
reward_min: -98.4229691876751
queue_len: 0.06330964083246031
wait_time: 0.6011197361349491
delay_time: 4.150874741940224
pressure: 0.7822723253757736
total_envstep_count: 1740696
total_train_sample_count: 1740696
total_episode_count: 15006
total_duration: 55796.68593478203
[2025-02-21 09:13:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.581480460005345
avg_train_sample_per_sec: 32.581480460005345
avg_episode_per_sec: 0.2808748315517702
collect_time: 21.361828565597534
reward_mean: -96.72759103641458
reward_std: 2.727314596045978
reward_max: -94.0644257703081
reward_min: -101.61344537815125
queue_len: 0.064142964878259
wait_time: 0.6065856050643069
delay_time: 4.185177582039156
pressure: 0.7922192749778957
total_envstep_count: 1741392
total_train_sample_count: 1741392
total_episode_count: 15012
total_duration: 55818.047763347626
[2025-02-21 09:14:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.850086129148195
avg_train_sample_per_sec: 32.850086129148195
avg_episode_per_sec: 0.28319039766507065
collect_time: 21.187159061431885
reward_mean: -94.9205182072829
reward_std: 1.1552466871732319
reward_max: -92.51190476190477
reward_min: -95.88235294117645
queue_len: 0.06294464072100989
wait_time: 0.5970161937454027
delay_time: 4.160526293156087
pressure: 0.7798408488063661
total_envstep_count: 1742088
total_train_sample_count: 1742088
total_episode_count: 15018
total_duration: 55839.23492240906
[2025-02-21 09:14:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73775814313771
avg_train_sample_per_sec: 32.73775814313771
avg_episode_per_sec: 0.2822220529580837
collect_time: 21.259855270385742
reward_mean: -96.42588702147525
reward_std: 1.2692566513190853
reward_max: -93.73529411764709
reward_min: -97.59103641456585
queue_len: 0.06394289590283504
wait_time: 0.5980181639410848
delay_time: 4.240095319280917
pressure: 0.7852564102564102
total_envstep_count: 1742784
total_train_sample_count: 1742784
total_episode_count: 15024
total_duration: 55860.49477767944
[2025-02-21 09:14:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.679154648755144
avg_train_sample_per_sec: 32.679154648755144
avg_episode_per_sec: 0.281716850420303
collect_time: 21.297980546951294
reward_mean: -95.3608776844071
reward_std: 2.3080732371809707
reward_max: -92.29621848739497
reward_min: -99.58403361344536
queue_len: 0.06323665628939464
wait_time: 0.5990894036659756
delay_time: 4.171248706653355
pressure: 0.788129973474801
total_envstep_count: 1743480
total_train_sample_count: 1743480
total_episode_count: 15030
total_duration: 55881.792758226395
[2025-02-21 09:15:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64512347382106
avg_train_sample_per_sec: 32.64512347382106
avg_episode_per_sec: 0.28142347822259534
collect_time: 21.32018280029297
reward_mean: -97.03338001867412
reward_std: 2.688583099378689
reward_max: -93.83473389355743
reward_min: -99.88445378151262
queue_len: 0.06434574271795367
wait_time: 0.606474851213695
delay_time: 4.230857382753796
pressure: 0.7877984084880635
total_envstep_count: 1744176
total_train_sample_count: 1744176
total_episode_count: 15036
total_duration: 55903.11294102669
[2025-02-21 09:15:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.56116816161564
avg_train_sample_per_sec: 32.56116816161564
avg_episode_per_sec: 0.28069972553116934
collect_time: 21.375154495239258
reward_mean: -96.40371148459384
reward_std: 1.7334133800014242
reward_max: -94.45098039215686
reward_min: -99.68487394957985
queue_len: 0.06392819063965108
wait_time: 0.606040968553646
delay_time: 4.190795166027829
pressure: 0.7870247568523431
total_envstep_count: 1744872
total_train_sample_count: 1744872
total_episode_count: 15042
total_duration: 55924.48809552193
[2025-02-21 09:15:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.15930657307415
avg_train_sample_per_sec: 32.15930657307415
avg_episode_per_sec: 0.27723540149201853
collect_time: 21.642257690429688
reward_mean: -98.09850606909431
reward_std: 4.281957113358374
reward_max: -92.70588235294119
reward_min: -103.46288515406162
queue_len: 0.06505205972751613
wait_time: 0.6150403574338666
delay_time: 4.2594503518955795
pressure: 0.7971927497789567
total_envstep_count: 1745568
total_train_sample_count: 1745568
total_episode_count: 15048
total_duration: 55946.13035321236
[2025-02-21 09:16:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.534103794049685
avg_train_sample_per_sec: 32.534103794049685
avg_episode_per_sec: 0.2804664120176697
collect_time: 21.39293599128723
reward_mean: -94.69946311858075
reward_std: 1.9856349003065485
reward_max: -90.88795518207282
reward_min: -97.00280112044817
queue_len: 0.06279805246590235
wait_time: 0.5948835436031176
delay_time: 4.158729424528517
pressure: 0.7715517241379309
total_envstep_count: 1746264
total_train_sample_count: 1746264
total_episode_count: 15054
total_duration: 55967.523289203644
[2025-02-21 09:16:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.623167316007894
avg_train_sample_per_sec: 32.623167316007894
avg_episode_per_sec: 0.281234201000068
collect_time: 21.334531784057617
reward_mean: -94.8984593837535
reward_std: 2.0157580561601507
reward_max: -92.10714285714285
reward_min: -97.85154061624647
queue_len: 0.06293001285394795
wait_time: 0.5930425994447291
delay_time: 4.153708913909801
pressure: 0.7685676392572945
total_envstep_count: 1746960
total_train_sample_count: 1746960
total_episode_count: 15060
total_duration: 55988.8578209877
[2025-02-21 09:16:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.76898908732552
avg_train_sample_per_sec: 32.76898908732552
avg_episode_per_sec: 0.2824912852355648
collect_time: 21.239593267440796
reward_mean: -96.06279178338002
reward_std: 2.5404259099600726
reward_max: -93.35504201680675
reward_min: -100.55742296918764
queue_len: 0.06370211656722813
wait_time: 0.6040788994642949
delay_time: 4.230574873887532
pressure: 0.7779619805481874
total_envstep_count: 1747656
total_train_sample_count: 1747656
total_episode_count: 15066
total_duration: 56010.09741425514
[2025-02-21 09:17:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 33.054021469996506
avg_train_sample_per_sec: 33.054021469996506
avg_episode_per_sec: 0.2849484609482457
collect_time: 21.05643939971924
reward_mean: -97.21463585434172
reward_std: 3.0365498423629744
reward_max: -91.9502801120448
reward_min: -100.54271708683477
queue_len: 0.06446593889545206
wait_time: 0.6091584843486465
delay_time: 4.248230098564599
pressure: 0.7918877099911583
total_envstep_count: 1748352
total_train_sample_count: 1748352
total_episode_count: 15072
total_duration: 56031.15385365486
[2025-02-21 09:17:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.692083966833664
avg_train_sample_per_sec: 32.692083966833664
avg_episode_per_sec: 0.2818283100589109
collect_time: 21.289557456970215
reward_mean: -93.80485527544351
reward_std: 1.356325898830389
reward_max: -91.53571428571429
reward_min: -95.73529411764703
queue_len: 0.06220481119061241
wait_time: 0.5869503636998566
delay_time: 4.119762072649266
pressure: 0.7635941644562334
total_envstep_count: 1749048
total_train_sample_count: 1749048
total_episode_count: 15078
total_duration: 56052.44341111183
[2025-02-21 09:18:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.40151676142041
avg_train_sample_per_sec: 32.40151676142041
avg_episode_per_sec: 0.2793234203570725
collect_time: 21.480475902557373
reward_mean: -96.41479925303456
reward_std: 1.2533314483128597
reward_max: -94.53571428571428
reward_min: -97.89845938375353
queue_len: 0.06393554327124307
wait_time: 0.6024571411234696
delay_time: 4.203550472624287
pressure: 0.7872458001768347
total_envstep_count: 1749744
total_train_sample_count: 1749744
total_episode_count: 15084
total_duration: 56073.92388701439
[2025-02-21 09:18:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.50766500952201
avg_train_sample_per_sec: 32.50766500952201
avg_episode_per_sec: 0.2802384914613966
collect_time: 21.410335063934326
reward_mean: -95.74334733893558
reward_std: 2.263485359397304
reward_max: -93.63935574229691
reward_min: -99.6631652661065
queue_len: 0.06349028338125702
wait_time: 0.5995475113122171
delay_time: 4.236478192055548
pressure: 0.7777409372236957
total_envstep_count: 1750440
total_train_sample_count: 1750440
total_episode_count: 15090
total_duration: 56095.33422207832
[2025-02-21 09:18:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.66192646358488
avg_train_sample_per_sec: 32.66192646358488
avg_episode_per_sec: 0.2815683315826283
collect_time: 21.30921459197998
reward_mean: -94.91398225957046
reward_std: 1.0746379905478076
reward_max: -93.11764705882352
reward_min: -96.12324929971989
queue_len: 0.06294030653817671
wait_time: 0.5953453662632162
delay_time: 4.1008221834137855
pressure: 0.7789566755083998
total_envstep_count: 1751136
total_train_sample_count: 1751136
total_episode_count: 15096
total_duration: 56116.6434366703
[2025-02-21 09:19:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.80950132335025
avg_train_sample_per_sec: 32.80950132335025
avg_episode_per_sec: 0.2828405286495711
collect_time: 21.213367223739624
reward_mean: -96.96965452847805
reward_std: 4.366626135872271
reward_max: -92.07072829131651
reward_min: -104.88935574229691
queue_len: 0.06430348443533027
wait_time: 0.6117802005859815
delay_time: 4.22362340146575
pressure: 0.7819407603890363
total_envstep_count: 1751832
total_train_sample_count: 1751832
total_episode_count: 15102
total_duration: 56137.85680389404
[2025-02-21 09:19:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.34846307723149
avg_train_sample_per_sec: 32.34846307723149
avg_episode_per_sec: 0.2788660610106163
collect_time: 21.515705347061157
reward_mean: -96.11893090569562
reward_std: 3.2825677974858913
reward_max: -92.37394957983194
reward_min: -101.0686274509804
queue_len: 0.06373934410192017
wait_time: 0.6021994894332622
delay_time: 4.146734159988933
pressure: 0.7859195402298851
total_envstep_count: 1752528
total_train_sample_count: 1752528
total_episode_count: 15108
total_duration: 56159.372509241104
[2025-02-21 09:19:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.795665452699595
avg_train_sample_per_sec: 32.795665452699595
avg_episode_per_sec: 0.2827212539025827
collect_time: 21.22231674194336
reward_mean: -94.07621381886086
reward_std: 3.6494676481695305
reward_max: -91.19467787114844
reward_min: -101.56652661064426
queue_len: 0.06238475717431091
wait_time: 0.5840677451351893
delay_time: 4.1368580179664525
pressure: 0.7606100795755969
total_envstep_count: 1753224
total_train_sample_count: 1753224
total_episode_count: 15114
total_duration: 56180.59482598305
[2025-02-21 09:20:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.835788314374454
avg_train_sample_per_sec: 32.835788314374454
avg_episode_per_sec: 0.2830671406411591
collect_time: 21.19638466835022
reward_mean: -93.85772642390289
reward_std: 2.8980600498547284
reward_max: -90.13865546218484
reward_min: -97.95378151260505
queue_len: 0.06223987163388786
wait_time: 0.5888049295757206
delay_time: 4.122432956627351
pressure: 0.7667992926613616
total_envstep_count: 1753920
total_train_sample_count: 1753920
total_episode_count: 15120
total_duration: 56201.7912106514
[2025-02-21 09:20:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.530278620802534
avg_train_sample_per_sec: 32.530278620802534
avg_episode_per_sec: 0.28043343638622875
collect_time: 21.395451545715332
reward_mean: -95.79551820728291
reward_std: 4.435660667487826
reward_max: -91.12535014005606
reward_min: -104.92577030812322
queue_len: 0.06352487944780033
wait_time: 0.599828304442909
delay_time: 4.160848264448468
pressure: 0.7798408488063661
total_envstep_count: 1754616
total_train_sample_count: 1754616
total_episode_count: 15126
total_duration: 56223.18666219711
[2025-02-21 09:20:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.22091676905097
avg_train_sample_per_sec: 32.22091676905097
avg_episode_per_sec: 0.2777665238711291
collect_time: 21.60087513923645
reward_mean: -97.07072829131648
reward_std: 2.464812808246396
reward_max: -93.9488795518207
reward_min: -100.60434173669469
queue_len: 0.06437050947700033
wait_time: 0.608811594929749
delay_time: 4.264745300964261
pressure: 0.7883510167992926
total_envstep_count: 1755312
total_train_sample_count: 1755312
total_episode_count: 15132
total_duration: 56244.78753733635
[2025-02-21 09:21:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.640332363803246
avg_train_sample_per_sec: 32.640332363803246
avg_episode_per_sec: 0.281382175550028
collect_time: 21.323312282562256
reward_mean: -95.24661531279179
reward_std: 1.220481656328992
reward_max: -93.1232492997199
reward_min: -96.68137254901963
queue_len: 0.0631608854859362
wait_time: 0.5954116173436661
delay_time: 4.194194421879105
pressure: 0.7723253757736517
total_envstep_count: 1756008
total_train_sample_count: 1756008
total_episode_count: 15138
total_duration: 56266.11084961891
[2025-02-21 09:21:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.334528296244116
avg_train_sample_per_sec: 32.334528296244116
avg_episode_per_sec: 0.27874593358831135
collect_time: 21.524977684020996
reward_mean: -94.13690476190476
reward_std: 2.814951722598673
reward_max: -91.24089635854342
reward_min: -98.03921568627452
queue_len: 0.06242500315776178
wait_time: 0.5898693584418737
delay_time: 4.085797588896492
pressure: 0.7651414677276747
total_envstep_count: 1756704
total_train_sample_count: 1756704
total_episode_count: 15144
total_duration: 56287.63582730293
[2025-02-21 09:22:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.85654944818339
avg_train_sample_per_sec: 32.85654944818339
avg_episode_per_sec: 0.2832461159326154
collect_time: 21.18299126625061
reward_mean: -95.92460317460318
reward_std: 0.6580309136771859
reward_max: -95.07212885154061
reward_min: -96.82563025210084
queue_len: 0.06361047955875541
wait_time: 0.6063625494406427
delay_time: 4.108401620306776
pressure: 0.7844827586206896
total_envstep_count: 1757400
total_train_sample_count: 1757400
total_episode_count: 15150
total_duration: 56308.81881856918
[2025-02-21 09:22:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.63754616585116
avg_train_sample_per_sec: 32.63754616585116
avg_episode_per_sec: 0.2813581566021652
collect_time: 21.325132608413696
reward_mean: -95.36963118580768
reward_std: 1.8676802483866601
reward_max: -93.16106442577033
reward_min: -98.42647058823529
queue_len: 0.06324246099854619
wait_time: 0.5975655514195068
delay_time: 4.126611886512349
pressure: 0.7758620689655172
total_envstep_count: 1758096
total_train_sample_count: 1758096
total_episode_count: 15156
total_duration: 56330.1439511776
[2025-02-21 09:22:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.742159611842794
avg_train_sample_per_sec: 32.742159611842794
avg_episode_per_sec: 0.2822599966538172
collect_time: 21.25699734687805
reward_mean: -95.41806722689074
reward_std: 1.7605321959494615
reward_max: -92.5735294117647
reward_min: -98.3844537815126
queue_len: 0.06327458038918485
wait_time: 0.5955491502524971
delay_time: 4.14210488694798
pressure: 0.7814986737400531
total_envstep_count: 1758792
total_train_sample_count: 1758792
total_episode_count: 15162
total_duration: 56351.400948524475
[2025-02-21 09:23:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.377196753877335
avg_train_sample_per_sec: 32.377196753877335
avg_episode_per_sec: 0.2791137651196322
collect_time: 21.49661087989807
reward_mean: -97.97770774976657
reward_std: 2.377904947405913
reward_max: -94.88935574229697
reward_min: -102.55812324929973
queue_len: 0.06497195474122451
wait_time: 0.6181887542815534
delay_time: 4.236687558054238
pressure: 0.8033819628647215
total_envstep_count: 1759488
total_train_sample_count: 1759488
total_episode_count: 15168
total_duration: 56372.89755940437
[2025-02-21 09:23:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.82395377312045
avg_train_sample_per_sec: 32.82395377312045
avg_episode_per_sec: 0.282965118733797
collect_time: 21.20402693748474
reward_mean: -94.80823996265171
reward_std: 3.0817615679971775
reward_max: -90.64775910364145
reward_min: -98.45168067226889
queue_len: 0.06287018565162582
wait_time: 0.5936873091411631
delay_time: 4.085690515527889
pressure: 0.7713306808134394
total_envstep_count: 1760184
total_train_sample_count: 1760184
total_episode_count: 15174
total_duration: 56394.10158634186
[2025-02-21 09:23:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.92360369699957
avg_train_sample_per_sec: 31.92360369699957
avg_episode_per_sec: 0.27520348014654805
collect_time: 21.8020498752594
reward_mean: -94.80707282913164
reward_std: 2.5451732052424263
reward_max: -92.1596638655462
reward_min: -99.08123249299719
queue_len: 0.0628694116904056
wait_time: 0.5915774908548742
delay_time: 4.149210098425376
pressure: 0.7722148541114057
total_envstep_count: 1760880
total_train_sample_count: 1760880
total_episode_count: 15180
total_duration: 56415.90363621712
[2025-02-21 09:24:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.63719171254646
avg_train_sample_per_sec: 29.63719171254646
avg_episode_per_sec: 0.25549303200471085
collect_time: 23.48400640487671
reward_mean: -97.30940709617177
reward_std: 2.3357858066854944
reward_max: -93.84453781512605
reward_min: -100.38515406162463
queue_len: 0.064528784546533
wait_time: 0.6134500219185818
delay_time: 4.244641912076523
pressure: 0.7929929266136163
total_envstep_count: 1761576
total_train_sample_count: 1761576
total_episode_count: 15186
total_duration: 56439.387642621994
[2025-02-21 09:24:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.19955255168306
avg_train_sample_per_sec: 32.19955255168306
avg_episode_per_sec: 0.27758234958347466
collect_time: 21.615207195281982
reward_mean: -96.3705648926237
reward_std: 2.5518570621631986
reward_max: -92.61764705882356
reward_min: -99.39775910364146
queue_len: 0.06390621014099716
wait_time: 0.5996894558000035
delay_time: 4.1450367779555135
pressure: 0.7839301503094607
total_envstep_count: 1762272
total_train_sample_count: 1762272
total_episode_count: 15192
total_duration: 56461.002849817276
[2025-02-21 09:25:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.633648154802724
avg_train_sample_per_sec: 30.633648154802724
avg_episode_per_sec: 0.2640831737482993
collect_time: 22.720114707946777
reward_mean: -95.7330765639589
reward_std: 1.892842307148803
reward_max: -93.80742296918767
reward_min: -98.27661064425774
queue_len: 0.06348347252251918
wait_time: 0.5995545543593211
delay_time: 4.164975894809424
pressure: 0.7833775419982317
total_envstep_count: 1762968
total_train_sample_count: 1762968
total_episode_count: 15198
total_duration: 56483.72296452522
[2025-02-21 09:25:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.683402875811158
avg_train_sample_per_sec: 31.683402875811158
avg_episode_per_sec: 0.2731327834121652
collect_time: 21.967337369918823
reward_mean: -95.19782913165265
reward_std: 2.0018125163677745
reward_max: -93.59453781512606
reward_min: -98.406862745098
queue_len: 0.06312853390693146
wait_time: 0.5925165380033535
delay_time: 4.153901898842335
pressure: 0.7811671087533156
total_envstep_count: 1763664
total_train_sample_count: 1763664
total_episode_count: 15204
total_duration: 56505.69030189514
[2025-02-21 09:25:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.675667686061978
avg_train_sample_per_sec: 31.675667686061978
avg_episode_per_sec: 0.2730661007419136
collect_time: 21.97270178794861
reward_mean: -95.328431372549
reward_std: 1.993579409301639
reward_max: -92.14565826330534
reward_min: -98.31652661064422
queue_len: 0.0632151401674728
wait_time: 0.5960108181203515
delay_time: 4.163728131649608
pressure: 0.7771883289124668
total_envstep_count: 1764360
total_train_sample_count: 1764360
total_episode_count: 15210
total_duration: 56527.66300368309
[2025-02-21 09:26:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.434208818058558
avg_train_sample_per_sec: 30.434208818058558
avg_episode_per_sec: 0.26236386912119447
collect_time: 22.8690025806427
reward_mean: -95.39939309056956
reward_std: 1.804960211764793
reward_max: -93.05042016806725
reward_min: -97.62044817927173
queue_len: 0.06326219700966153
wait_time: 0.5984649717535114
delay_time: 4.142211238068534
pressure: 0.7801724137931033
total_envstep_count: 1765056
total_train_sample_count: 1765056
total_episode_count: 15216
total_duration: 56550.53200626373
[2025-02-21 09:26:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.528858745708128
avg_train_sample_per_sec: 28.528858745708128
avg_episode_per_sec: 0.24593843746300112
collect_time: 24.39634919166565
reward_mean: -97.26902427637721
reward_std: 1.728461290509363
reward_max: -94.73949579831928
reward_min: -99.80812324929975
queue_len: 0.0645020054883138
wait_time: 0.6074047656197757
delay_time: 4.217891571058329
pressure: 0.7904509283819628
total_envstep_count: 1765752
total_train_sample_count: 1765752
total_episode_count: 15222
total_duration: 56574.9283554554
[2025-02-21 09:26:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.182116476508313
avg_train_sample_per_sec: 30.182116476508313
avg_episode_per_sec: 0.2601906592802441
collect_time: 23.06001305580139
reward_mean: -96.41269841269843
reward_std: 2.5636800499050842
reward_max: -93.9859943977591
reward_min: -100.99439775910365
queue_len: 0.0639341501410467
wait_time: 0.6088913129354306
delay_time: 4.14001374049653
pressure: 0.7942086648983201
total_envstep_count: 1766448
total_train_sample_count: 1766448
total_episode_count: 15228
total_duration: 56597.9883685112
[2025-02-21 09:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.40622703516448
avg_train_sample_per_sec: 29.40622703516448
avg_episode_per_sec: 0.2535019571996938
collect_time: 23.668456315994263
reward_mean: -95.48996265172735
reward_std: 2.4759658412091525
reward_max: -91.0028011204482
reward_min: -99.16806722689074
queue_len: 0.0633222564003497
wait_time: 0.6014772288225635
delay_time: 4.113692359281439
pressure: 0.779288240495137
total_envstep_count: 1767144
total_train_sample_count: 1767144
total_episode_count: 15234
total_duration: 56621.656824827194
[2025-02-21 09:27:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.36477756495955
avg_train_sample_per_sec: 31.36477756495955
avg_episode_per_sec: 0.2703860134910306
collect_time: 22.190496921539307
reward_mean: -95.01820728291317
reward_std: 1.9922023151190347
reward_max: -92.37955182072828
reward_min: -98.4901960784314
queue_len: 0.06300942127514136
wait_time: 0.593605656232431
delay_time: 4.109628958802826
pressure: 0.7799513704686118
total_envstep_count: 1767840
total_train_sample_count: 1767840
total_episode_count: 15240
total_duration: 56643.84732174873
[2025-02-21 09:28:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.769209389839332
avg_train_sample_per_sec: 28.769209389839332
avg_episode_per_sec: 0.248010425774477
collect_time: 24.19253134727478
reward_mean: -96.45833333333336
reward_std: 1.5732884220519352
reward_max: -94.39075630252101
reward_min: -99.11834733893558
queue_len: 0.06396441202475686
wait_time: 0.6088003724920561
delay_time: 4.176834054129277
pressure: 0.7879089301503094
total_envstep_count: 1768536
total_train_sample_count: 1768536
total_episode_count: 15246
total_duration: 56668.03985309601
[2025-02-21 09:28:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.592002034858925
avg_train_sample_per_sec: 30.592002034858925
avg_episode_per_sec: 0.2637241554729218
collect_time: 22.751044511795044
reward_mean: -96.34453781512605
reward_std: 1.6847901234412526
reward_max: -93.42787114845939
reward_min: -98.7247899159664
queue_len: 0.0638889508057865
wait_time: 0.6040660517080396
delay_time: 4.148226628755742
pressure: 0.7910035366931919
total_envstep_count: 1769232
total_train_sample_count: 1769232
total_episode_count: 15252
total_duration: 56690.7908976078
[2025-02-21 09:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.54592252066658
avg_train_sample_per_sec: 32.54592252066658
avg_episode_per_sec: 0.2805682975919533
collect_time: 21.385167360305786
reward_mean: -96.26984126984127
reward_std: 2.881378482731733
reward_max: -90.85784313725489
reward_min: -100.4908963585434
queue_len: 0.06383941728769314
wait_time: 0.6068028559788193
delay_time: 4.161146036658205
pressure: 0.7850353669319187
total_envstep_count: 1769928
total_train_sample_count: 1769928
total_episode_count: 15258
total_duration: 56712.17606496811
[2025-02-21 09:29:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.88182037990655
avg_train_sample_per_sec: 32.88182037990655
avg_episode_per_sec: 0.28346396879229785
collect_time: 21.16671133041382
reward_mean: -96.27474323062559
reward_std: 1.586983151037565
reward_max: -94.0518207282913
reward_min: -98.14635854341736
queue_len: 0.06384266792481803
wait_time: 0.6068881465052866
delay_time: 4.208432853568577
pressure: 0.7795092838196287
total_envstep_count: 1770624
total_train_sample_count: 1770624
total_episode_count: 15264
total_duration: 56733.34277629852
[2025-02-21 09:29:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.38033494530389
avg_train_sample_per_sec: 31.38033494530389
avg_episode_per_sec: 0.27052012883882665
collect_time: 22.179495573043823
reward_mean: -96.11753034547151
reward_std: 3.375574053167774
reward_max: -92.8109243697479
reward_min: -101.7752100840336
queue_len: 0.06373841534845591
wait_time: 0.6013371418417057
delay_time: 4.1927969884598815
pressure: 0.780393457117595
total_envstep_count: 1771320
total_train_sample_count: 1771320
total_episode_count: 15270
total_duration: 56755.52227187157
[2025-02-21 09:30:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.449513748429716
avg_train_sample_per_sec: 32.449513748429716
avg_episode_per_sec: 0.2797371874864631
collect_time: 21.44870352745056
reward_mean: -93.2419467787115
reward_std: 1.8506907069249883
reward_max: -90.76750700280111
reward_min: -96.51330532212884
queue_len: 0.06183152969410576
wait_time: 0.5896971520703772
delay_time: 4.105818641528109
pressure: 0.7621573828470382
total_envstep_count: 1772016
total_train_sample_count: 1772016
total_episode_count: 15276
total_duration: 56776.97097539902
[2025-02-21 09:30:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.34379376176793
avg_train_sample_per_sec: 32.34379376176793
avg_episode_per_sec: 0.2788258082911028
collect_time: 21.518811464309692
reward_mean: -93.7484827264239
reward_std: 1.769611049249027
reward_max: -91.30812324929971
reward_min: -96.96778711484585
queue_len: 0.062167428863676315
wait_time: 0.5861796531167728
delay_time: 4.077008779988529
pressure: 0.7704465075154731
total_envstep_count: 1772712
total_train_sample_count: 1772712
total_episode_count: 15282
total_duration: 56798.48978686333
[2025-02-21 09:30:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.604386643819154
avg_train_sample_per_sec: 32.604386643819154
avg_episode_per_sec: 0.2810722986536134
collect_time: 21.346820831298828
reward_mean: -94.9110644257703
reward_std: 1.1585094074548399
reward_max: -93.96778711484595
reward_min: -96.8949579831933
queue_len: 0.06293837163512621
wait_time: 0.5927271328513721
delay_time: 4.125503833390766
pressure: 0.7750884173297967
total_envstep_count: 1773408
total_train_sample_count: 1773408
total_episode_count: 15288
total_duration: 56819.836607694626
[2025-02-21 09:31:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.32159569126228
avg_train_sample_per_sec: 32.32159569126228
avg_episode_per_sec: 0.27863444561433004
collect_time: 21.53359031677246
reward_mean: -95.3106909430439
reward_std: 1.522398262139581
reward_max: -92.39075630252103
reward_min: -96.96358543417367
queue_len: 0.06320337595692566
wait_time: 0.5937671045429667
delay_time: 4.155342744096396
pressure: 0.7796198054818744
total_envstep_count: 1774104
total_train_sample_count: 1774104
total_episode_count: 15294
total_duration: 56841.3701980114
[2025-02-21 09:31:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.159611609341674
avg_train_sample_per_sec: 32.159611609341674
avg_episode_per_sec: 0.27723803111501444
collect_time: 21.64205241203308
reward_mean: -96.28571428571429
reward_std: 2.7236257432907705
reward_max: -93.68487394957987
reward_min: -100.12324929971986
queue_len: 0.06384994316028798
wait_time: 0.6007469190151745
delay_time: 4.189252329953484
pressure: 0.7866931918656057
total_envstep_count: 1774800
total_train_sample_count: 1774800
total_episode_count: 15300
total_duration: 56863.01225042343
[2025-02-21 09:31:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.67272362691285
avg_train_sample_per_sec: 32.67272362691285
avg_episode_per_sec: 0.28166141057683486
collect_time: 21.302172660827637
reward_mean: -94.10574229691876
reward_std: 1.7236722711054329
reward_max: -92.48039215686275
reward_min: -97.24019607843134
queue_len: 0.062404338393182206
wait_time: 0.5915829085834156
delay_time: 4.0639976334562915
pressure: 0.7723253757736517
total_envstep_count: 1775496
total_train_sample_count: 1775496
total_episode_count: 15306
total_duration: 56884.31442308426
[2025-02-21 09:32:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.6309101068172
avg_train_sample_per_sec: 32.6309101068172
avg_episode_per_sec: 0.2813009491967
collect_time: 21.329469442367554
reward_mean: -95.95436507936506
reward_std: 2.511412136290318
reward_max: -91.35364145658264
reward_min: -98.96708683473388
queue_len: 0.06363021556987074
wait_time: 0.6013544785730384
delay_time: 4.132337850738929
pressure: 0.7828249336870027
total_envstep_count: 1776192
total_train_sample_count: 1776192
total_episode_count: 15312
total_duration: 56905.64389252663
[2025-02-21 09:32:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73816310079199
avg_train_sample_per_sec: 32.73816310079199
avg_episode_per_sec: 0.2822255439723448
collect_time: 21.259592294692993
reward_mean: -95.35597572362279
reward_std: 2.4839518201853865
reward_max: -91.93347338935574
reward_min: -99.59873949579837
queue_len: 0.06323340565226974
wait_time: 0.5957934898097169
delay_time: 4.066638984702651
pressure: 0.7842617152961981
total_envstep_count: 1776888
total_train_sample_count: 1776888
total_episode_count: 15318
total_duration: 56926.90348482132
[2025-02-21 09:32:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.57655569123747
avg_train_sample_per_sec: 32.57655569123747
avg_episode_per_sec: 0.2808323766485989
collect_time: 21.365057945251465
reward_mean: -94.32282913165267
reward_std: 1.3197876279204743
reward_max: -92.95728291316529
reward_min: -96.69047619047622
queue_len: 0.06254829518014103
wait_time: 0.5912670550094485
delay_time: 4.079413707792576
pressure: 0.772656940760389
total_envstep_count: 1777584
total_train_sample_count: 1777584
total_episode_count: 15324
total_duration: 56948.26854276657
[2025-02-21 09:33:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.536395485899874
avg_train_sample_per_sec: 32.536395485899874
avg_episode_per_sec: 0.28048616798189546
collect_time: 21.39142918586731
reward_mean: -94.218954248366
reward_std: 1.452527352542133
reward_max: -91.3060224089636
reward_min: -95.44467787114844
queue_len: 0.06247941263154245
wait_time: 0.5899877745085655
delay_time: 4.105068029439414
pressure: 0.7673519009725905
total_envstep_count: 1778280
total_train_sample_count: 1778280
total_episode_count: 15330
total_duration: 56969.65997195244
[2025-02-21 09:33:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.843419533432915
avg_train_sample_per_sec: 32.843419533432915
avg_episode_per_sec: 0.2831329270123527
collect_time: 21.19145965576172
reward_mean: -94.36414565826328
reward_std: 2.0858777391334233
reward_max: -91.6421568627451
reward_min: -97.1344537815126
queue_len: 0.06257569340733639
wait_time: 0.5933216898607366
delay_time: 4.104040604863712
pressure: 0.777740937223696
total_envstep_count: 1778976
total_train_sample_count: 1778976
total_episode_count: 15336
total_duration: 56990.8514316082
[2025-02-21 09:34:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.60924442937969
avg_train_sample_per_sec: 32.60924442937969
avg_episode_per_sec: 0.2811141761153422
collect_time: 21.34364080429077
reward_mean: -94.9153828197946
reward_std: 2.6091582884911326
reward_max: -89.71218487394955
reward_min: -98.26540616246496
queue_len: 0.06294123529164097
wait_time: 0.5942488954025466
delay_time: 4.147355627702905
pressure: 0.7735411140583555
total_envstep_count: 1779672
total_train_sample_count: 1779672
total_episode_count: 15342
total_duration: 57012.19507241249
[2025-02-21 09:34:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64791498207216
avg_train_sample_per_sec: 32.64791498207216
avg_episode_per_sec: 0.28144754294889796
collect_time: 21.318359851837158
reward_mean: -94.32644724556486
reward_std: 2.5665789771990513
reward_max: -89.53011204481788
reward_min: -97.82002801120447
queue_len: 0.06255069445992366
wait_time: 0.5908817771140287
delay_time: 4.085344118986845
pressure: 0.7745358090185676
total_envstep_count: 1780368
total_train_sample_count: 1780368
total_episode_count: 15348
total_duration: 57033.51343226433
[2025-02-21 09:34:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52189111466688
avg_train_sample_per_sec: 32.52189111466688
avg_episode_per_sec: 0.2803611302988524
collect_time: 21.40096950531006
reward_mean: -97.5078197945845
reward_std: 1.8084250613226842
reward_max: -95.26120448179275
reward_min: -100.86414565826331
queue_len: 0.0646603579539685
wait_time: 0.6104211246832951
delay_time: 4.213461693524855
pressure: 0.7984084880636604
total_envstep_count: 1781064
total_train_sample_count: 1781064
total_episode_count: 15354
total_duration: 57054.91440176964
[2025-02-21 09:35:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.91378711459591
avg_train_sample_per_sec: 28.91378711459591
avg_episode_per_sec: 0.2492567854706544
collect_time: 24.071561336517334
reward_mean: -95.23622782446311
reward_std: 0.9801284881758654
reward_max: -94.39635854341739
reward_min: -96.86064425770304
queue_len: 0.06315399723107633
wait_time: 0.6004368701503591
delay_time: 4.163582868563713
pressure: 0.7827144120247569
total_envstep_count: 1781760
total_train_sample_count: 1781760
total_episode_count: 15360
total_duration: 57078.985963106155
[2025-02-21 09:35:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.297307476935337
avg_train_sample_per_sec: 28.297307476935337
avg_episode_per_sec: 0.24394230583564946
collect_time: 24.595979690551758
reward_mean: -94.90207749766573
reward_std: 2.6931484684608487
reward_max: -91.33683473389353
reward_min: -98.5119047619048
queue_len: 0.06293241213373059
wait_time: 0.5934736184482634
delay_time: 4.175545863877217
pressure: 0.7789566755083998
total_envstep_count: 1782456
total_train_sample_count: 1782456
total_episode_count: 15366
total_duration: 57103.58194279671
[2025-02-21 09:36:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.275448913530184
avg_train_sample_per_sec: 28.275448913530184
avg_episode_per_sec: 0.24375386994422574
collect_time: 24.614993810653687
reward_mean: -94.24486461251166
reward_std: 2.0133145238561627
reward_max: -91.96148459383753
reward_min: -97.41526610644259
queue_len: 0.06249659457063108
wait_time: 0.5914946770043118
delay_time: 4.156952947476121
pressure: 0.7726569407603892
total_envstep_count: 1783152
total_train_sample_count: 1783152
total_episode_count: 15372
total_duration: 57128.19693660736
[2025-02-21 09:36:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.4145155743453
avg_train_sample_per_sec: 32.4145155743453
avg_episode_per_sec: 0.27943547908918365
collect_time: 21.471861839294434
reward_mean: -94.3530578898226
reward_std: 1.846604416425045
reward_max: -91.72689075630254
reward_min: -96.92016806722691
queue_len: 0.06256834077574443
wait_time: 0.5878891786599699
delay_time: 4.117821713851273
pressure: 0.775972590627763
total_envstep_count: 1783848
total_train_sample_count: 1783848
total_episode_count: 15378
total_duration: 57149.668798446655
[2025-02-21 09:36:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.5510445549926
avg_train_sample_per_sec: 32.5510445549926
avg_episode_per_sec: 0.28061245306028104
collect_time: 21.381802320480347
reward_mean: -95.4234360410831
reward_std: 1.71479262090966
reward_max: -93.04901960784308
reward_min: -97.6771708683473
queue_len: 0.0632781406107978
wait_time: 0.5970752469865047
delay_time: 4.155245567904248
pressure: 0.7904509283819628
total_envstep_count: 1784544
total_train_sample_count: 1784544
total_episode_count: 15384
total_duration: 57171.050600767136
[2025-02-21 09:37:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.42178081390761
avg_train_sample_per_sec: 32.42178081390761
avg_episode_per_sec: 0.2794981104647208
collect_time: 21.467050313949585
reward_mean: -96.54271708683473
reward_std: 2.8802082868879473
reward_max: -90.67717086834736
reward_min: -99.6393557422969
queue_len: 0.06402036942097793
wait_time: 0.6059718538166813
delay_time: 4.206554818348676
pressure: 0.7929929266136163
total_envstep_count: 1785240
total_train_sample_count: 1785240
total_episode_count: 15390
total_duration: 57192.517651081085
[2025-02-21 09:37:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.488496745018836
avg_train_sample_per_sec: 32.488496745018836
avg_episode_per_sec: 0.2800732478018865
collect_time: 21.422967195510864
reward_mean: -93.97105508870216
reward_std: 1.2778918421848555
reward_max: -92.14635854341736
reward_min: -95.52591036414567
queue_len: 0.06231502326837013
wait_time: 0.5912525819346307
delay_time: 4.144741789951691
pressure: 0.769893899204244
total_envstep_count: 1785936
total_train_sample_count: 1785936
total_episode_count: 15396
total_duration: 57213.940618276596
[2025-02-21 09:37:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.25145825811546
avg_train_sample_per_sec: 32.25145825811546
avg_episode_per_sec: 0.2780298125699609
collect_time: 21.580419540405273
reward_mean: -96.92717086834735
reward_std: 2.970442601414901
reward_max: -92.50000000000004
reward_min: -101.59453781512603
queue_len: 0.06427531224691468
wait_time: 0.60578796063076
delay_time: 4.211793292487068
pressure: 0.7890141467727675
total_envstep_count: 1786632
total_train_sample_count: 1786632
total_episode_count: 15402
total_duration: 57235.521037817
[2025-02-21 09:38:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.48353389656949
avg_train_sample_per_sec: 32.48353389656949
avg_episode_per_sec: 0.28003046462559905
collect_time: 21.42624020576477
reward_mean: -96.56559290382819
reward_std: 2.6447107218518466
reward_max: -93.33543417366947
reward_min: -101.24299719887951
queue_len: 0.06403553906089403
wait_time: 0.6068106729871435
delay_time: 4.201502826843135
pressure: 0.7960875331564986
total_envstep_count: 1787328
total_train_sample_count: 1787328
total_episode_count: 15408
total_duration: 57256.947278022766
[2025-02-21 09:38:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.580798647962446
avg_train_sample_per_sec: 32.580798647962446
avg_episode_per_sec: 0.2808689538617452
collect_time: 21.36227560043335
reward_mean: -96.14589169000935
reward_std: 1.5672354260705295
reward_max: -94.02240896358545
reward_min: -98.39425770308117
queue_len: 0.06375722260610699
wait_time: 0.6014629105399896
delay_time: 4.146567164862311
pressure: 0.7929929266136163
total_envstep_count: 1788024
total_train_sample_count: 1788024
total_episode_count: 15414
total_duration: 57278.3095536232
[2025-02-21 09:38:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.6278877457867
avg_train_sample_per_sec: 32.6278877457867
avg_episode_per_sec: 0.2812748943602302
collect_time: 21.33144521713257
reward_mean: -95.32738095238092
reward_std: 1.4268449013550557
reward_max: -93.08403361344531
reward_min: -97.2219887955182
queue_len: 0.06321444360237463
wait_time: 0.599149772641152
delay_time: 4.121267921499402
pressure: 0.784814323607427
total_envstep_count: 1788720
total_train_sample_count: 1788720
total_episode_count: 15420
total_duration: 57299.64099884033
[2025-02-21 09:39:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.84642771660283
avg_train_sample_per_sec: 27.84642771660283
avg_episode_per_sec: 0.24005541135002437
collect_time: 24.994229316711426
reward_mean: -96.27824463118581
reward_std: 1.9443723274260742
reward_max: -93.12885154061624
reward_min: -98.45588235294117
queue_len: 0.06384498980847865
wait_time: 0.6067806432917995
delay_time: 4.1949023896214745
pressure: 0.784261715296198
total_envstep_count: 1789416
total_train_sample_count: 1789416
total_episode_count: 15426
total_duration: 57324.63522815704
[2025-02-21 09:39:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.484232688209236
avg_train_sample_per_sec: 28.484232688209236
avg_episode_per_sec: 0.24555373007076928
collect_time: 24.434570789337158
reward_mean: -95.70051353874884
reward_std: 1.4088032791496405
reward_max: -93.5378151260504
reward_min: -97.28221288515401
queue_len: 0.06346187900447535
wait_time: 0.6046400213489462
delay_time: 4.1769357741597855
pressure: 0.7868037135278515
total_envstep_count: 1790112
total_train_sample_count: 1790112
total_episode_count: 15432
total_duration: 57349.06979894638
[2025-02-21 09:40:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.509171974527618
avg_train_sample_per_sec: 30.509171974527618
avg_episode_per_sec: 0.26301010322868634
collect_time: 22.812811851501465
reward_mean: -95.72537348272641
reward_std: 1.516929434684245
reward_max: -93.10994397759099
reward_min: -97.62815126050421
queue_len: 0.06347836437846578
wait_time: 0.6006194476022062
delay_time: 4.203425414692888
pressure: 0.779288240495137
total_envstep_count: 1790808
total_train_sample_count: 1790808
total_episode_count: 15438
total_duration: 57371.88261079788
[2025-02-21 09:40:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.53536708551206
avg_train_sample_per_sec: 32.53536708551206
avg_episode_per_sec: 0.28047730246131086
collect_time: 21.39210534095764
reward_mean: -96.34617180205414
reward_std: 3.291647123340024
reward_max: -91.17086834733894
reward_min: -99.82282913165267
queue_len: 0.06389003435149479
wait_time: 0.6014240576867351
delay_time: 4.216066279378158
pressure: 0.7842617152961981
total_envstep_count: 1791504
total_train_sample_count: 1791504
total_episode_count: 15444
total_duration: 57393.27471613884
[2025-02-21 09:40:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.65443742018682
avg_train_sample_per_sec: 32.65443742018682
avg_episode_per_sec: 0.28150377086367945
collect_time: 21.314101696014404
reward_mean: -93.54901960784314
reward_std: 1.468861308733237
reward_max: -90.57703081232495
reward_min: -94.9810924369748
queue_len: 0.06203515889114266
wait_time: 0.5857661256368153
delay_time: 4.109795962362888
pressure: 0.7684571175950486
total_envstep_count: 1792200
total_train_sample_count: 1792200
total_episode_count: 15450
total_duration: 57414.588817834854
[2025-02-21 09:41:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.149064824045816
avg_train_sample_per_sec: 32.149064824045816
avg_episode_per_sec: 0.2771471105521191
collect_time: 21.649152278900146
reward_mean: -96.73832866479925
reward_std: 1.116842329402849
reward_max: -94.53011204481793
reward_min: -98.09943977591034
queue_len: 0.06415008532148492
wait_time: 0.6066595183608369
delay_time: 4.217899024589286
pressure: 0.7928824049513704
total_envstep_count: 1792896
total_train_sample_count: 1792896
total_episode_count: 15456
total_duration: 57436.237970113754
[2025-02-21 09:41:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.57165276260918
avg_train_sample_per_sec: 32.57165276260918
avg_episode_per_sec: 0.28079011002249293
collect_time: 21.368273973464966
reward_mean: -96.812441643324
reward_std: 2.775806468965096
reward_max: -93.72689075630254
reward_min: -102.09733893557423
queue_len: 0.06419923185896816
wait_time: 0.6074520546503306
delay_time: 4.2316150740821685
pressure: 0.7866931918656057
total_envstep_count: 1793592
total_train_sample_count: 1793592
total_episode_count: 15462
total_duration: 57457.60624408722
[2025-02-21 09:42:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.65785598463802
avg_train_sample_per_sec: 32.65785598463802
avg_episode_per_sec: 0.28153324124687945
collect_time: 21.311870574951172
reward_mean: -95.39098972922501
reward_std: 2.238112097438558
reward_max: -92.85854341736692
reward_min: -98.53991596638652
queue_len: 0.063256624488876
wait_time: 0.5964963239937885
delay_time: 4.138881737368988
pressure: 0.7830459770114943
total_envstep_count: 1794288
total_train_sample_count: 1794288
total_episode_count: 15468
total_duration: 57478.91811466217
[2025-02-21 09:42:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.28730877368828
avg_train_sample_per_sec: 32.28730877368828
avg_episode_per_sec: 0.27833886873869207
collect_time: 21.55645751953125
reward_mean: -94.40044351073765
reward_std: 1.838463700925527
reward_max: -91.50350140056024
reward_min: -97.39705882352942
queue_len: 0.0625997636012849
wait_time: 0.5890484177755984
delay_time: 4.157730085211399
pressure: 0.7694518125552609
total_envstep_count: 1794984
total_train_sample_count: 1794984
total_episode_count: 15474
total_duration: 57500.4745721817
[2025-02-21 09:42:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.42528445587111
avg_train_sample_per_sec: 32.42528445587111
avg_episode_per_sec: 0.2795283142747509
collect_time: 21.464730739593506
reward_mean: -95.5330298786181
reward_std: 2.5158348141051907
reward_max: -91.20238095238096
reward_min: -98.7521008403361
queue_len: 0.0633508155693754
wait_time: 0.6012467431711853
delay_time: 4.182444749081724
pressure: 0.7858090185676393
total_envstep_count: 1795680
total_train_sample_count: 1795680
total_episode_count: 15480
total_duration: 57521.939302921295
[2025-02-21 09:43:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.593617123900685
avg_train_sample_per_sec: 32.593617123900685
avg_episode_per_sec: 0.28097945796466106
collect_time: 21.35387420654297
reward_mean: -96.22280578898226
reward_std: 4.058697338018315
reward_max: -91.5497198879552
reward_min: -102.24509803921569
queue_len: 0.06380822665051876
wait_time: 0.5997479672682513
delay_time: 4.163815436688902
pressure: 0.7868037135278514
total_envstep_count: 1796376
total_train_sample_count: 1796376
total_episode_count: 15486
total_duration: 57543.29317712784
[2025-02-21 09:43:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 31.60835841622486
avg_train_sample_per_sec: 31.60835841622486
avg_episode_per_sec: 0.27248584841573154
collect_time: 22.019492149353027
reward_mean: -95.1390056022409
reward_std: 1.0999202585891965
reward_max: -93.84383753501403
reward_min: -96.97689075630252
queue_len: 0.06308952626143295
wait_time: 0.5930706168409009
delay_time: 4.0906968384375775
pressure: 0.7809460654288242
total_envstep_count: 1797072
total_train_sample_count: 1797072
total_episode_count: 15492
total_duration: 57565.31266927719
[2025-02-21 09:43:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.71373928700292
avg_train_sample_per_sec: 32.71373928700292
avg_episode_per_sec: 0.2820149938534735
collect_time: 21.27546453475952
reward_mean: -95.42250233426704
reward_std: 3.2778587995477624
reward_max: -91.81302521008402
reward_min: -101.67577030812325
queue_len: 0.06327752144182165
wait_time: 0.5944584841009791
delay_time: 4.138841484867248
pressure: 0.7844827586206896
total_envstep_count: 1797768
total_train_sample_count: 1797768
total_episode_count: 15498
total_duration: 57586.58813381195
[2025-02-21 09:44:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.54660033374575
avg_train_sample_per_sec: 32.54660033374575
avg_episode_per_sec: 0.28057414080815307
collect_time: 21.384721994400024
reward_mean: -96.56839402427636
reward_std: 2.424234983271845
reward_max: -94.34943977591035
reward_min: -101.73809523809521
queue_len: 0.06403739656782252
wait_time: 0.6033326460557698
delay_time: 4.237756216713677
pressure: 0.7873563218390806
total_envstep_count: 1798464
total_train_sample_count: 1798464
total_episode_count: 15504
total_duration: 57607.97285580635
[2025-02-21 09:44:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.47714024688
avg_train_sample_per_sec: 32.47714024688
avg_episode_per_sec: 0.279975346955862
collect_time: 21.430458307266235
reward_mean: -93.68405695611578
reward_std: 1.8872143838757633
reward_max: -90.46498599439778
reward_min: -96.69747899159661
queue_len: 0.062124706204320805
wait_time: 0.5819195383723782
delay_time: 4.109820179164017
pressure: 0.7681255526083112
total_envstep_count: 1799160
total_train_sample_count: 1799160
total_episode_count: 15510
total_duration: 57629.40331411362
[2025-02-21 09:44:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.7102056547314
avg_train_sample_per_sec: 32.7102056547314
avg_episode_per_sec: 0.2819845315063052
collect_time: 21.27776288986206
reward_mean: -93.92752100840339
reward_std: 1.6936285126685995
reward_max: -92.312324929972
reward_min: -97.3627450980392
queue_len: 0.06228615451485634
wait_time: 0.585787719154859
delay_time: 4.099210238652378
pressure: 0.7725464190981431
total_envstep_count: 1799856
total_train_sample_count: 1799856
total_episode_count: 15516
total_duration: 57650.68107700348
[2025-02-21 09:45:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.67313941067584
avg_train_sample_per_sec: 32.67313941067584
avg_episode_per_sec: 0.2816649949196193
collect_time: 21.3019015789032
reward_mean: -95.2735760971055
reward_std: 2.4505022431650163
reward_max: -91.90266106442576
reward_min: -98.5658263305322
queue_len: 0.06317876399012301
wait_time: 0.5956133116376524
delay_time: 4.185799865360994
pressure: 0.7833775419982317
total_envstep_count: 1800552
total_train_sample_count: 1800552
total_episode_count: 15522
total_duration: 57671.98297858238
[2025-02-21 09:45:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.89822287075238
avg_train_sample_per_sec: 32.89822287075238
avg_episode_per_sec: 0.2836053695754515
collect_time: 21.156157970428467
reward_mean: -93.35912698412699
reward_std: 0.8896839878039356
reward_max: -92.44187675070026
reward_min: -95.18697478991595
queue_len: 0.061909235400614715
wait_time: 0.5810386157115365
delay_time: 4.162477027838729
pressure: 0.7663572060123786
total_envstep_count: 1801248
total_train_sample_count: 1801248
total_episode_count: 15528
total_duration: 57693.13913655281
[2025-02-21 09:46:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.76984654083193
avg_train_sample_per_sec: 32.76984654083193
avg_episode_per_sec: 0.28249867707613735
collect_time: 21.23903751373291
reward_mean: -95.14332399626517
reward_std: 1.1484604275309656
reward_max: -93.83543417366948
reward_min: -97.31162464985994
queue_len: 0.06309238991794773
wait_time: 0.593423620553438
delay_time: 4.210125835821599
pressure: 0.7785145888594164
total_envstep_count: 1801944
total_train_sample_count: 1801944
total_episode_count: 15534
total_duration: 57714.37817406654
[2025-02-21 09:46:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.861915109900444
avg_train_sample_per_sec: 32.861915109900444
avg_episode_per_sec: 0.2832923716370728
collect_time: 21.179532527923584
reward_mean: -94.36414565826328
reward_std: 2.0356366760789077
reward_max: -92.54691876750701
reward_min: -98.09453781512606
queue_len: 0.0625756934073364
wait_time: 0.5902570356170762
delay_time: 4.167658073776759
pressure: 0.7756410256410257
total_envstep_count: 1802640
total_train_sample_count: 1802640
total_episode_count: 15540
total_duration: 57735.55770659447
[2025-02-21 09:46:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.55495521038316
avg_train_sample_per_sec: 32.55495521038316
avg_episode_per_sec: 0.28064616560675143
collect_time: 21.379233837127686
reward_mean: -96.71918767507005
reward_std: 1.6750521208083975
reward_max: -94.4390756302521
reward_min: -99.14215686274513
queue_len: 0.0641373923574735
wait_time: 0.6116729295608605
delay_time: 4.231044805984176
pressure: 0.7889036251105218
total_envstep_count: 1803336
total_train_sample_count: 1803336
total_episode_count: 15546
total_duration: 57756.936940431595
[2025-02-21 09:47:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.440359217702586
avg_train_sample_per_sec: 32.440359217702586
avg_episode_per_sec: 0.27965826911812575
collect_time: 21.454756259918213
reward_mean: -94.76225490196079
reward_std: 2.47526361818458
reward_max: -91.2941176470588
reward_min: -99.01610644257707
queue_len: 0.06283969157954959
wait_time: 0.5974767006714269
delay_time: 4.166759851134187
pressure: 0.7789566755083998
total_envstep_count: 1804032
total_train_sample_count: 1804032
total_episode_count: 15552
total_duration: 57778.39169669151
[2025-02-21 09:47:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.67796868959954
avg_train_sample_per_sec: 32.67796868959954
avg_episode_per_sec: 0.2817066266344788
collect_time: 21.29875349998474
reward_mean: -94.42553688141923
reward_std: 1.3815889296480057
reward_max: -92.31652661064425
reward_min: -97.00420168067228
queue_len: 0.06261640376751938
wait_time: 0.5881168780509551
delay_time: 4.1777805356792195
pressure: 0.7809460654288242
total_envstep_count: 1804728
total_train_sample_count: 1804728
total_episode_count: 15558
total_duration: 57799.6904501915
[2025-02-21 09:47:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.745878668104766
avg_train_sample_per_sec: 32.745878668104766
avg_episode_per_sec: 0.28229205748366176
collect_time: 21.25458312034607
reward_mean: -95.33613445378153
reward_std: 1.3015132442725144
reward_max: -93.14145658263307
reward_min: -97.07352941176471
queue_len: 0.0632202483115262
wait_time: 0.6007435909819276
delay_time: 4.250451711252183
pressure: 0.7747568523430592
total_envstep_count: 1805424
total_train_sample_count: 1805424
total_episode_count: 15564
total_duration: 57820.945033311844
[2025-02-21 09:48:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 33.01731280691592
avg_train_sample_per_sec: 33.01731280691592
avg_episode_per_sec: 0.2846320069561717
collect_time: 21.0798499584198
reward_mean: -95.2264239028945
reward_std: 2.1486040785833134
reward_max: -91.71708683473388
reward_min: -97.31092436974791
queue_len: 0.06314749595682659
wait_time: 0.5973033333581
delay_time: 4.173256831861052
pressure: 0.7793987621573829
total_envstep_count: 1806120
total_train_sample_count: 1806120
total_episode_count: 15570
total_duration: 57842.024883270264
[2025-02-21 09:48:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.70982814372554
avg_train_sample_per_sec: 32.70982814372554
avg_episode_per_sec: 0.28198127710108223
collect_time: 21.278008460998535
reward_mean: -94.0484360410831
reward_std: 1.1319050845182999
reward_max: -91.91246498599439
reward_min: -95.05392156862743
queue_len: 0.06236633689726995
wait_time: 0.5854294525060245
delay_time: 4.153196653907976
pressure: 0.7703359858532273
total_envstep_count: 1806816
total_train_sample_count: 1806816
total_episode_count: 15576
total_duration: 57863.30289173126
[2025-02-21 09:48:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.320830241060385
avg_train_sample_per_sec: 32.320830241060385
avg_episode_per_sec: 0.278627846905693
collect_time: 21.53410029411316
reward_mean: -95.96918767507005
reward_std: 1.6691493407864846
reward_max: -94.21568627450979
reward_min: -99.12254901960785
queue_len: 0.0636400448773674
wait_time: 0.5957061095879554
delay_time: 4.190194778661429
pressure: 0.7800618921308576
total_envstep_count: 1807512
total_train_sample_count: 1807512
total_episode_count: 15582
total_duration: 57884.836992025375
[2025-02-21 09:49:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.61007205071399
avg_train_sample_per_sec: 32.61007205071399
avg_episode_per_sec: 0.28112131078201713
collect_time: 21.343099117279053
reward_mean: -95.01318860877683
reward_std: 1.6638320161715265
reward_max: -92.57492997198878
reward_min: -97.85294117647057
queue_len: 0.06300609324189445
wait_time: 0.5968069146314582
delay_time: 4.175602375210457
pressure: 0.7781830238726791
total_envstep_count: 1808208
total_train_sample_count: 1808208
total_episode_count: 15588
total_duration: 57906.180091142654
[2025-02-21 09:49:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.70428156922892
avg_train_sample_per_sec: 32.70428156922892
avg_episode_per_sec: 0.28193346180369755
collect_time: 21.281617164611816
reward_mean: -96.77567693744163
reward_std: 2.471854874615801
reward_max: -94.31652661064425
reward_min: -101.74299719887958
queue_len: 0.0641748520805316
wait_time: 0.6081587586405031
delay_time: 4.24098522259989
pressure: 0.7902298850574713
total_envstep_count: 1808904
total_train_sample_count: 1808904
total_episode_count: 15594
total_duration: 57927.461708307266
[2025-02-21 09:50:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.75449788770173
avg_train_sample_per_sec: 32.75449788770173
avg_episode_per_sec: 0.28236636110087704
collect_time: 21.248990058898926
reward_mean: -94.95541549953315
reward_std: 2.941274665635114
reward_max: -92.10574229691878
reward_min: -100.53991596638652
queue_len: 0.06296778216149412
wait_time: 0.5928748046521879
delay_time: 4.157513279221834
pressure: 0.7690097259062777
total_envstep_count: 1809600
total_train_sample_count: 1809600
total_episode_count: 15600
total_duration: 57948.710698366165
[2025-02-21 09:50:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.43215997418968
avg_train_sample_per_sec: 32.43215997418968
avg_episode_per_sec: 0.2795875859843938
collect_time: 21.460180282592773
reward_mean: -94.85014005602243
reward_std: 1.7797318364114199
reward_max: -92.47899159663868
reward_min: -97.91386554621849
queue_len: 0.0628979708594313
wait_time: 0.5970406509199612
delay_time: 4.136713818633138
pressure: 0.7763041556145005
total_envstep_count: 1810296
total_train_sample_count: 1810296
total_episode_count: 15606
total_duration: 57970.17087864876
[2025-02-21 09:50:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.617977732601965
avg_train_sample_per_sec: 32.617977732601965
avg_episode_per_sec: 0.28118946321208593
collect_time: 21.337926149368286
reward_mean: -95.65021008403362
reward_std: 2.3836403083624917
reward_max: -90.59593837535016
reward_min: -97.59033613445379
queue_len: 0.06342852127588434
wait_time: 0.6002818457179512
delay_time: 4.172816720736096
pressure: 0.7788461538461539
total_envstep_count: 1810992
total_train_sample_count: 1810992
total_episode_count: 15612
total_duration: 57991.508804798126
[2025-02-21 09:51:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73835328381856
avg_train_sample_per_sec: 32.73835328381856
avg_episode_per_sec: 0.28222718348119447
collect_time: 21.25946879386902
reward_mean: -94.49871615312789
reward_std: 2.1315783687561334
reward_max: -92.29271708683468
reward_min: -97.87955182072827
queue_len: 0.06266493113602646
wait_time: 0.5906100393296133
delay_time: 4.15366209787548
pressure: 0.774314765694076
total_envstep_count: 1811688
total_train_sample_count: 1811688
total_episode_count: 15618
total_duration: 58012.768273591995
[2025-02-21 09:51:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.72586574173203
avg_train_sample_per_sec: 32.72586574173203
avg_episode_per_sec: 0.28211953225631065
collect_time: 21.26758098602295
reward_mean: -93.84010270774975
reward_std: 1.1790037827547653
reward_max: -91.45238095238093
reward_min: -95.02731092436974
queue_len: 0.062228184819462705
wait_time: 0.5872607995452823
delay_time: 4.110984123538894
pressure: 0.7696728558797524
total_envstep_count: 1812384
total_train_sample_count: 1812384
total_episode_count: 15624
total_duration: 58034.03585457802
[2025-02-21 09:51:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.84369925578403
avg_train_sample_per_sec: 32.84369925578403
avg_episode_per_sec: 0.28313533841193134
collect_time: 21.19127917289734
reward_mean: -93.7174369747899
reward_std: 2.711037530073845
reward_max: -91.02450980392156
reward_min: -99.00210084033608
queue_len: 0.06214684149521877
wait_time: 0.5840798963263466
delay_time: 4.137689129676706
pressure: 0.767683465959328
total_envstep_count: 1813080
total_train_sample_count: 1813080
total_episode_count: 15630
total_duration: 58055.227133750916
[2025-02-21 09:52:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64264306110817
avg_train_sample_per_sec: 32.64264306110817
avg_episode_per_sec: 0.28140209535438077
collect_time: 21.321802854537964
reward_mean: -94.51832399626517
reward_std: 1.5684006468201404
reward_max: -92.58753501400558
reward_min: -96.55322128851542
queue_len: 0.06267793368452597
wait_time: 0.5862331338370893
delay_time: 4.157607415827411
pressure: 0.767130857648099
total_envstep_count: 1813776
total_train_sample_count: 1813776
total_episode_count: 15636
total_duration: 58076.54893660545
[2025-02-21 09:52:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.628463216774065
avg_train_sample_per_sec: 32.628463216774065
avg_episode_per_sec: 0.28127985531701777
collect_time: 21.331068992614746
reward_mean: -94.12068160597573
reward_std: 1.7199426834958058
reward_max: -91.91526610644254
reward_min: -96.26120448179273
queue_len: 0.06241424509680087
wait_time: 0.5922421687507894
delay_time: 4.125379510839392
pressure: 0.7697833775419981
total_envstep_count: 1814472
total_train_sample_count: 1814472
total_episode_count: 15642
total_duration: 58097.88000559807
[2025-02-21 09:52:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52132012134788
avg_train_sample_per_sec: 32.52132012134788
avg_episode_per_sec: 0.2803562079426541
collect_time: 21.401345252990723
reward_mean: -96.31057422969188
reward_std: 1.6216284381606132
reward_max: -93.7233893557423
reward_min: -98.86484593837534
queue_len: 0.06386642853427842
wait_time: 0.5985843165736674
delay_time: 4.203529049709094
pressure: 0.7849248452696728
total_envstep_count: 1815168
total_train_sample_count: 1815168
total_episode_count: 15648
total_duration: 58119.28135085106
[2025-02-21 09:53:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.555026005062004
avg_train_sample_per_sec: 32.555026005062004
avg_episode_per_sec: 0.2806467759057069
collect_time: 21.37918734550476
reward_mean: -93.9705882352941
reward_std: 1.7664661718408083
reward_max: -91.1344537815126
reward_min: -97.1841736694678
queue_len: 0.06231471368388205
wait_time: 0.5891261234821072
delay_time: 4.082153466565448
pressure: 0.7681255526083112
total_envstep_count: 1815864
total_train_sample_count: 1815864
total_episode_count: 15654
total_duration: 58140.660538196564
[2025-02-21 09:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.54939352629088
avg_train_sample_per_sec: 32.54939352629088
avg_episode_per_sec: 0.2805982200542317
collect_time: 21.38288688659668
reward_mean: -96.66549953314659
reward_std: 1.1643645023754121
reward_max: -94.46918767507
reward_min: -98.09733893557424
queue_len: 0.06410179014134389
wait_time: 0.6015247500414844
delay_time: 4.194926477418568
pressure: 0.7911140583554377
total_envstep_count: 1816560
total_train_sample_count: 1816560
total_episode_count: 15660
total_duration: 58162.04342508316
[2025-02-21 09:54:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.669738851528756
avg_train_sample_per_sec: 32.669738851528756
avg_episode_per_sec: 0.2816356797545583
collect_time: 21.304118871688843
reward_mean: -95.56897759103641
reward_std: 2.41363365744379
reward_max: -91.90126050420167
reward_min: -98.65826330532211
queue_len: 0.06337465357495782
wait_time: 0.6002844771861001
delay_time: 4.127592748975196
pressure: 0.784261715296198
total_envstep_count: 1817256
total_train_sample_count: 1817256
total_episode_count: 15666
total_duration: 58183.34754395485
[2025-02-21 09:54:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.56288213331841
avg_train_sample_per_sec: 32.56288213331841
avg_episode_per_sec: 0.28071450114929664
collect_time: 21.374029397964478
reward_mean: -95.95880018674137
reward_std: 3.670379227844716
reward_max: -91.86554621848735
reward_min: -102.97128851540623
queue_len: 0.06363315662250754
wait_time: 0.6013906999581441
delay_time: 4.1781775687633695
pressure: 0.7886825817860301
total_envstep_count: 1817952
total_train_sample_count: 1817952
total_episode_count: 15672
total_duration: 58204.721573352814
[2025-02-21 09:54:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.591099413598464
avg_train_sample_per_sec: 32.591099413598464
avg_episode_per_sec: 0.28095775356550395
collect_time: 21.355523824691772
reward_mean: -94.82749766573295
reward_std: 2.5852924720213593
reward_max: -90.79831932773108
reward_min: -98.96918767507003
queue_len: 0.06288295601175925
wait_time: 0.5928899742921041
delay_time: 4.115746125878081
pressure: 0.7763041556145005
total_envstep_count: 1818648
total_train_sample_count: 1818648
total_episode_count: 15678
total_duration: 58226.077097177505
[2025-02-21 09:55:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.84819172469932
avg_train_sample_per_sec: 32.84819172469932
avg_episode_per_sec: 0.28317406659223554
collect_time: 21.18838095664978
reward_mean: -95.53618113912232
reward_std: 2.3636854554092515
reward_max: -93.70658263305322
reward_min: -100.3445378151261
queue_len: 0.06335290526466997
wait_time: 0.5967145810578872
delay_time: 4.090168264757653
pressure: 0.7852564102564102
total_envstep_count: 1819344
total_train_sample_count: 1819344
total_episode_count: 15684
total_duration: 58247.265478134155
[2025-02-21 09:55:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.47215233195977
avg_train_sample_per_sec: 32.47215233195977
avg_episode_per_sec: 0.27993234768930836
collect_time: 21.43375015258789
reward_mean: -94.8094070961718
reward_std: 1.3383579515218063
reward_max: -92.86974789915969
reward_min: -96.49369747899158
queue_len: 0.06287095961284601
wait_time: 0.5923721168396624
delay_time: 4.124991341853593
pressure: 0.7724358974358975
total_envstep_count: 1820040
total_train_sample_count: 1820040
total_episode_count: 15690
total_duration: 58268.69922828674
[2025-02-21 09:55:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.73240431861988
avg_train_sample_per_sec: 32.73240431861988
avg_episode_per_sec: 0.2821758992984472
collect_time: 21.26333260536194
reward_mean: -94.36496265172734
reward_std: 0.8163365456202972
reward_max: -93.3207282913165
reward_min: -95.75420168067227
queue_len: 0.06257623518019055
wait_time: 0.5898503963919784
delay_time: 4.080275613560446
pressure: 0.7776304155614501
total_envstep_count: 1820736
total_train_sample_count: 1820736
total_episode_count: 15696
total_duration: 58289.962560892105
[2025-02-21 09:56:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.87262467017843
avg_train_sample_per_sec: 32.87262467017843
avg_episode_per_sec: 0.2833846954325727
collect_time: 21.172632455825806
reward_mean: -95.16339869281046
reward_std: 1.1313624053056461
reward_max: -93.03711484593839
reward_min: -96.5112044817927
queue_len: 0.06310570205093531
wait_time: 0.5930553698048627
delay_time: 4.181342525458533
pressure: 0.7790671971706455
total_envstep_count: 1821432
total_train_sample_count: 1821432
total_episode_count: 15702
total_duration: 58311.13519334793
[2025-02-21 09:56:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.458019022779226
avg_train_sample_per_sec: 30.458019022779226
avg_episode_per_sec: 0.26256912950671746
collect_time: 22.85112500190735
reward_mean: -95.02030812324931
reward_std: 2.0725272321596635
reward_max: -92.87815126050418
reward_min: -99.1344537815126
queue_len: 0.06301081440533773
wait_time: 0.5964931507527856
delay_time: 4.09621073644739
pressure: 0.7774093722369585
total_envstep_count: 1822128
total_train_sample_count: 1822128
total_episode_count: 15708
total_duration: 58333.98631834984
[2025-02-21 09:57:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 27.82411924468464
avg_train_sample_per_sec: 27.82411924468464
avg_episode_per_sec: 0.23986309693693655
collect_time: 25.01426887512207
reward_mean: -98.02556022408965
reward_std: 3.622681112211643
reward_max: -93.27591036414562
reward_min: -102.05322128851535
queue_len: 0.06500368715125306
wait_time: 0.6131152062947196
delay_time: 4.239306189605554
pressure: 0.8069186560565872
total_envstep_count: 1822824
total_train_sample_count: 1822824
total_episode_count: 15714
total_duration: 58359.00058722496
[2025-02-21 09:57:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.59049342424009
avg_train_sample_per_sec: 30.59049342424009
avg_episode_per_sec: 0.2637111502089663
collect_time: 22.752166509628296
reward_mean: -95.07679738562092
reward_std: 1.7989980580709068
reward_max: -92.4719887955182
reward_min: -98.15336134453781
queue_len: 0.06304827412839582
wait_time: 0.5951291988944118
delay_time: 4.141293644434721
pressure: 0.7790671971706454
total_envstep_count: 1823520
total_train_sample_count: 1823520
total_episode_count: 15720
total_duration: 58381.75275373459
[2025-02-21 09:57:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.282754913378284
avg_train_sample_per_sec: 32.282754913378284
avg_episode_per_sec: 0.2782996113222266
collect_time: 21.55949831008911
reward_mean: -97.36472922502332
reward_std: 4.284390708617766
reward_max: -91.81792717086834
reward_min: -105.53221288515407
queue_len: 0.06456547030837091
wait_time: 0.6065417988592432
delay_time: 4.187528319709366
pressure: 0.7998452696728559
total_envstep_count: 1824216
total_train_sample_count: 1824216
total_episode_count: 15726
total_duration: 58403.31225204468
[2025-02-21 09:58:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.30924091131889
avg_train_sample_per_sec: 32.30924091131889
avg_episode_per_sec: 0.27852793889068006
collect_time: 21.54182457923889
reward_mean: -96.34593837535014
reward_std: 3.249888842525744
reward_max: -90.68627450980392
reward_min: -101.33473389355746
queue_len: 0.06388987955925074
wait_time: 0.6043433620132402
delay_time: 4.1317447544712556
pressure: 0.7942086648983201
total_envstep_count: 1824912
total_train_sample_count: 1824912
total_episode_count: 15732
total_duration: 58424.85407662392
[2025-02-21 09:58:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.29003727776978
avg_train_sample_per_sec: 32.29003727776978
avg_episode_per_sec: 0.27836239032560156
collect_time: 21.554636001586914
reward_mean: -95.9625350140056
reward_std: 2.1466092340077205
reward_max: -92.58053221288512
reward_min: -99.45028011204481
queue_len: 0.0636356332984122
wait_time: 0.6007618564667246
delay_time: 4.196345831521621
pressure: 0.787577365163572
total_envstep_count: 1825608
total_train_sample_count: 1825608
total_episode_count: 15738
total_duration: 58446.4087126255
[2025-02-21 09:58:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.64224155807418
avg_train_sample_per_sec: 32.64224155807418
avg_episode_per_sec: 0.2813986341213292
collect_time: 21.322065114974976
reward_mean: -95.2580532212885
reward_std: 1.9303046418815708
reward_max: -92.1435574229692
reward_min: -98.2906162464986
queue_len: 0.06316847030589424
wait_time: 0.5995013058273707
delay_time: 4.125086957000684
pressure: 0.7822723253757736
total_envstep_count: 1826304
total_train_sample_count: 1826304
total_episode_count: 15744
total_duration: 58467.73077774048
[2025-02-21 09:59:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.653025343324614
avg_train_sample_per_sec: 32.653025343324614
avg_episode_per_sec: 0.28149159778728117
collect_time: 21.31502342224121
reward_mean: -93.28524743230626
reward_std: 0.6804436868914732
reward_max: -92.20798319327734
reward_min: -94.35084033613445
queue_len: 0.061860243655375506
wait_time: 0.5806446694504502
delay_time: 4.116545793631637
pressure: 0.7650309460654289
total_envstep_count: 1827000
total_train_sample_count: 1827000
total_episode_count: 15750
total_duration: 58489.04580116272
[2025-02-21 09:59:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52042091998294
avg_train_sample_per_sec: 32.52042091998294
avg_episode_per_sec: 0.2803484562067495
collect_time: 21.401937007904053
reward_mean: -96.07352941176468
reward_std: 2.2500702158074253
reward_max: -92.22899159663864
reward_min: -98.99509803921569
queue_len: 0.06370923701045404
wait_time: 0.6025089965252236
delay_time: 4.159273322330311
pressure: 0.7918877099911583
total_envstep_count: 1827696
total_train_sample_count: 1827696
total_episode_count: 15756
total_duration: 58510.447738170624
[2025-02-21 09:59:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.765398275554496
avg_train_sample_per_sec: 32.765398275554496
avg_episode_per_sec: 0.2824603299616767
collect_time: 21.241920948028564
reward_mean: -94.66176470588236
reward_std: 1.7674208529302935
reward_max: -92.25980392156862
reward_min: -97.69327731092434
queue_len: 0.06277305351848962
wait_time: 0.5907709458672947
delay_time: 4.1534311430243385
pressure: 0.7734305923961097
total_envstep_count: 1828392
total_train_sample_count: 1828392
total_episode_count: 15762
total_duration: 58531.68965911865
[2025-02-21 10:00:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.79946450222894
avg_train_sample_per_sec: 29.79946450222894
avg_episode_per_sec: 0.2568919353640426
collect_time: 23.35612440109253
reward_mean: -95.09500466853409
reward_std: 1.1734751383599005
reward_max: -93.27661064425772
reward_min: -97.01330532212883
queue_len: 0.06306034792343108
wait_time: 0.5948559131875563
delay_time: 4.127976503733179
pressure: 0.7784040671971706
total_envstep_count: 1829088
total_train_sample_count: 1829088
total_episode_count: 15768
total_duration: 58555.045783519745
[2025-02-21 10:00:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.2006354871055
avg_train_sample_per_sec: 32.2006354871055
avg_episode_per_sec: 0.2775916852336681
collect_time: 21.6144802570343
reward_mean: -96.06944444444446
reward_std: 2.005510767845046
reward_max: -93.66876750700284
reward_min: -99.17927170868349
queue_len: 0.06370652814618333
wait_time: 0.5975171788432437
delay_time: 4.210291454977962
pressure: 0.7854774535809019
total_envstep_count: 1829784
total_train_sample_count: 1829784
total_episode_count: 15774
total_duration: 58576.66026377678
[2025-02-21 10:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.52265633512277
avg_train_sample_per_sec: 32.52265633512277
avg_episode_per_sec: 0.2803677270269204
collect_time: 21.400465965270996
reward_mean: -96.31092436974787
reward_std: 1.1934263440202566
reward_max: -94.63165266106442
reward_min: -98.24999999999997
queue_len: 0.06386666072264448
wait_time: 0.6006750180178172
delay_time: 4.204191693951551
pressure: 0.787135278514589
total_envstep_count: 1830480
total_train_sample_count: 1830480
total_episode_count: 15780
total_duration: 58598.06072974205
[2025-02-21 10:01:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.14360555511193
avg_train_sample_per_sec: 32.14360555511193
avg_episode_per_sec: 0.277100047888896
collect_time: 21.65282917022705
reward_mean: -96.22000466853406
reward_std: 2.6368985834719414
reward_max: -93.92436974789916
reward_min: -101.25980392156859
queue_len: 0.06380636914359024
wait_time: 0.6045113889941476
delay_time: 4.164993683418904
pressure: 0.7898983200707339
total_envstep_count: 1831176
total_train_sample_count: 1831176
total_episode_count: 15786
total_duration: 58619.71355891228
[2025-02-21 10:01:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.7686245636282
avg_train_sample_per_sec: 32.7686245636282
avg_episode_per_sec: 0.28248814278989826
collect_time: 21.239829540252686
reward_mean: -94.30847338935575
reward_std: 1.2254344891967088
reward_max: -92.06932773109247
reward_min: -95.74439775910363
queue_len: 0.06253877545713246
wait_time: 0.5872847149469868
delay_time: 4.101858023064614
pressure: 0.7717727674624227
total_envstep_count: 1831872
total_train_sample_count: 1831872
total_episode_count: 15792
total_duration: 58640.95338845253
[2025-02-21 10:02:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.470512185720345
avg_train_sample_per_sec: 32.470512185720345
avg_episode_per_sec: 0.2799182084975892
collect_time: 21.43483281135559
reward_mean: -95.9576330532213
reward_std: 2.7304226521341795
reward_max: -91.30532212885154
reward_min: -99.24229691876747
queue_len: 0.06363238266128733
wait_time: 0.5982900565177443
delay_time: 4.14885517043496
pressure: 0.7830459770114944
total_envstep_count: 1832568
total_train_sample_count: 1832568
total_episode_count: 15798
total_duration: 58662.388221263885
[2025-02-21 10:02:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.600089122053966
avg_train_sample_per_sec: 32.600089122053966
avg_episode_per_sec: 0.28103525105218935
collect_time: 21.349634885787964
reward_mean: -93.95786647992527
reward_std: 1.6201823706366092
reward_max: -91.57633053221286
reward_min: -96.296918767507
queue_len: 0.06230627750658175
wait_time: 0.5894797463636207
delay_time: 4.125660969013922
pressure: 0.7726569407603888
total_envstep_count: 1833264
total_train_sample_count: 1833264
total_episode_count: 15804
total_duration: 58683.73785614967
[2025-02-21 10:02:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.67385398374567
avg_train_sample_per_sec: 32.67385398374567
avg_episode_per_sec: 0.2816711550322903
collect_time: 21.301435708999634
reward_mean: -94.90382819794586
reward_std: 1.676559104086836
reward_max: -92.26190476190473
reward_min: -97.96778711484595
queue_len: 0.06293357307556091
wait_time: 0.591650630190184
delay_time: 4.131433945747347
pressure: 0.7736516357206012
total_envstep_count: 1833960
total_train_sample_count: 1833960
total_episode_count: 15810
total_duration: 58705.03929185867
[2025-02-21 10:03:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.561505929430155
avg_train_sample_per_sec: 32.561505929430155
avg_episode_per_sec: 0.28070263732267375
collect_time: 21.374932765960693
reward_mean: -94.7329598506069
reward_std: 1.8500823905405346
reward_max: -91.39075630252098
reward_min: -97.68277310924364
queue_len: 0.06282026515292234
wait_time: 0.5896134868624726
delay_time: 4.083216443449214
pressure: 0.7823828470380194
total_envstep_count: 1834656
total_train_sample_count: 1834656
total_episode_count: 15816
total_duration: 58726.414224624634
[2025-02-21 10:03:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.26646416000752
avg_train_sample_per_sec: 32.26646416000752
avg_episode_per_sec: 0.2781591737931683
collect_time: 21.570383310317993
reward_mean: -95.42635387488326
reward_std: 2.474661819141894
reward_max: -91.12394957983189
reward_min: -98.50280112044813
queue_len: 0.06328007551384832
wait_time: 0.5980951730824956
delay_time: 4.1772255525898565
pressure: 0.777740937223696
total_envstep_count: 1835352
total_train_sample_count: 1835352
total_episode_count: 15822
total_duration: 58747.98460793495
[2025-02-21 10:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.741741702368344
avg_train_sample_per_sec: 32.741741702368344
avg_episode_per_sec: 0.282256393985934
collect_time: 21.25726866722107
reward_mean: -95.44129318394023
reward_std: 2.4559156466940064
reward_max: -92.5987394957983
reward_min: -99.78851540616247
queue_len: 0.063289982217467
wait_time: 0.5942370537958773
delay_time: 4.18810388181729
pressure: 0.7739832007073386
total_envstep_count: 1836048
total_train_sample_count: 1836048
total_episode_count: 15828
total_duration: 58769.24187660217
[2025-02-21 10:04:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.34706013385018
avg_train_sample_per_sec: 32.34706013385018
avg_episode_per_sec: 0.2788539666711222
collect_time: 21.51663851737976
reward_mean: -93.93347338935575
reward_std: 1.7287962124585108
reward_max: -91.84383753501399
reward_min: -97.05672268907564
queue_len: 0.0622901017170794
wait_time: 0.5891305350610624
delay_time: 4.127079392625231
pressure: 0.7726569407603892
total_envstep_count: 1836744
total_train_sample_count: 1836744
total_episode_count: 15834
total_duration: 58790.75851511955
[2025-02-21 10:04:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.66219140873776
avg_train_sample_per_sec: 32.66219140873776
avg_episode_per_sec: 0.2815706155925669
collect_time: 21.309041738510132
reward_mean: -93.36321195144724
reward_std: 2.5406201605320944
reward_max: -90.3879551820728
reward_min: -98.33613445378147
queue_len: 0.061911944264885437
wait_time: 0.5888063227059169
delay_time: 4.088987089944949
pressure: 0.763262599469496
total_envstep_count: 1837440
total_train_sample_count: 1837440
total_episode_count: 15840
total_duration: 58812.06755685806
[2025-02-21 10:05:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 32.59825656616773
avg_train_sample_per_sec: 32.59825656616773
avg_episode_per_sec: 0.28101945315661836
collect_time: 21.35083508491516
reward_mean: -95.46790382819795
reward_std: 3.0613206092062186
reward_max: -92.76050420168063
reward_min: -101.8326330532213
queue_len: 0.06330762853328777
wait_time: 0.5969606233297917
delay_time: 4.1391938819438066
pressure: 0.7777409372236957
total_envstep_count: 1838136
total_train_sample_count: 1838136
total_episode_count: 15846
total_duration: 58833.41839194298
[2025-02-21 10:05:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 30.092736225486437
avg_train_sample_per_sec: 30.092736225486437
avg_episode_per_sec: 0.2594201398748831
collect_time: 23.128504991531372
reward_mean: -94.56594304388422
reward_std: 1.871760292729577
reward_max: -91.98949579831928
reward_min: -97.359943977591
queue_len: 0.06270951130231048
wait_time: 0.5922558678643871
delay_time: 4.129538599694826
pressure: 0.7766357206012379
total_envstep_count: 1838832
total_train_sample_count: 1838832
total_episode_count: 15852
total_duration: 58856.54689693451
[2025-02-21 10:05:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 29.95761164559428
avg_train_sample_per_sec: 29.95761164559428
avg_episode_per_sec: 0.25825527280684724
collect_time: 23.232826709747314
reward_mean: -95.8608776844071
reward_std: 2.302155173380481
reward_max: -93.70308123249299
reward_min: -100.63935574229694
queue_len: 0.06356822127613201
wait_time: 0.59928335834776
delay_time: 4.199078542715331
pressure: 0.780393457117595
total_envstep_count: 1839528
total_train_sample_count: 1839528
total_episode_count: 15858
total_duration: 58879.77972364426
[2025-02-21 10:06:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.955795963276778
avg_train_sample_per_sec: 28.955795963276778
avg_episode_per_sec: 0.24961893071790325
collect_time: 24.036638498306274
reward_mean: -97.39063958916903
reward_std: 2.3380568237711854
reward_max: -93.53361344537812
reward_min: -100.57983193277312
queue_len: 0.06458265224745956
wait_time: 0.6077268882796267
delay_time: 4.20434986097486
pressure: 0.7955349248452697
total_envstep_count: 1840224
total_train_sample_count: 1840224
total_episode_count: 15864
total_duration: 58903.81636214256
[2025-02-21 10:06:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 28.324907529648055
avg_train_sample_per_sec: 28.324907529648055
avg_episode_per_sec: 0.2441802373245522
collect_time: 24.57201313972473
reward_mean: -95.88830532212883
reward_std: 3.498049581130614
reward_max: -91.3480392156863
reward_min: -102.4628851540616
queue_len: 0.06358640936480693
wait_time: 0.5981858039413821
delay_time: 4.18661197170444
pressure: 0.788240495137047
total_envstep_count: 1840920
total_train_sample_count: 1840920
total_episode_count: 15870
total_duration: 58928.38837528229
