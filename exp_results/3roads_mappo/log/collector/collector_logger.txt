[2024-12-26 01:27:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 12
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.949228282265526
avg_train_sample_per_sec: 14.949228282265526
avg_episode_per_sec: 0.1288726576057373
collect_time: 93.11517449040153
reward_mean: -325.1897175536881
reward_std: 31.384216357028787
reward_max: -284.4544817927171
reward_min: -394.6624649859944
queue_len: 0.2156430487756553
wait_time: 2.041008644837246
delay_time: 16.053070211347567
pressure: 2.6644009725906277
total_envstep_count: 1392
total_train_sample_count: 1392
total_episode_count: 12
total_duration: 93.11517449040153
[2024-12-26 01:27:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.864304129856913
avg_train_sample_per_sec: 14.864304129856913
avg_episode_per_sec: 0.12814055284359407
collect_time: 46.82358446918428
reward_mean: -344.10352474323054
reward_std: 29.597389681376903
reward_max: -321.38935574229686
reward_min: -407.07563025210095
queue_len: 0.22818536123556407
wait_time: 2.011882704009986
delay_time: 18.816192335226756
pressure: 2.8257073386383733
total_envstep_count: 2088
total_train_sample_count: 2088
total_episode_count: 18
total_duration: 139.9387589595858
[2024-12-26 01:28:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.909531719696934
avg_train_sample_per_sec: 14.909531719696934
avg_episode_per_sec: 0.12853044585945633
collect_time: 46.68154661628417
reward_mean: -375.44654528478054
reward_std: 35.68588460278026
reward_max: -335.2359943977592
reward_min: -418.66946778711474
queue_len: 0.2489698576159022
wait_time: 2.077872727340273
delay_time: 20.981062872191405
pressure: 3.175066312997347
total_envstep_count: 2784
total_train_sample_count: 2784
total_episode_count: 24
total_duration: 186.62030557587
[2024-12-26 01:29:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.031685394870802
avg_train_sample_per_sec: 15.031685394870802
avg_episode_per_sec: 0.129583494783369
collect_time: 46.30219311518408
reward_mean: -357.6805555555556
reward_std: 39.71948757907373
reward_max: -303.1141456582633
reward_min: -408.3837535014005
queue_len: 0.2371886973180077
wait_time: 1.958576666740967
delay_time: 20.96707774466776
pressure: 2.88052608311229
total_envstep_count: 3480
total_train_sample_count: 3480
total_episode_count: 30
total_duration: 232.92249869105407
[2024-12-26 01:30:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.815036075711038
avg_train_sample_per_sec: 14.815036075711038
avg_episode_per_sec: 0.12771582823888827
collect_time: 46.979298358988025
reward_mean: -366.64787581699346
reward_std: 23.53323423824827
reward_max: -332.68627450980387
reward_min: -396.1379551820728
queue_len: 0.24313519616511503
wait_time: 2.0035240002278543
delay_time: 21.91001773428776
pressure: 2.993037135278515
total_envstep_count: 4176
total_train_sample_count: 4176
total_episode_count: 36
total_duration: 279.9017970500421
[2024-12-26 01:30:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.269169827452435
avg_train_sample_per_sec: 15.269169827452435
avg_episode_per_sec: 0.13163077437458995
collect_time: 45.582045904595404
reward_mean: -319.87885154061615
reward_std: 13.806651012826169
reward_max: -299.92577030812316
reward_min: -336.68837535014
queue_len: 0.2121212543372786
wait_time: 1.9433971201212585
delay_time: 16.999409601881542
pressure: 2.511162687886826
total_envstep_count: 4872
total_train_sample_count: 4872
total_episode_count: 42
total_duration: 325.4838429546375
[2024-12-26 01:31:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.920233496131543
avg_train_sample_per_sec: 14.920233496131543
avg_episode_per_sec: 0.12862270255285813
collect_time: 46.64806352933123
reward_mean: -356.9856442577031
reward_std: 97.13624226645045
reward_max: -274.0098039215687
reward_min: -526.1309523809524
queue_len: 0.2367278808074954
wait_time: 1.9300988410395108
delay_time: 21.736780534947272
pressure: 2.7722148541114056
total_envstep_count: 5568
total_train_sample_count: 5568
total_episode_count: 48
total_duration: 372.13190648396875
[2024-12-26 01:32:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.44909742593425
avg_train_sample_per_sec: 15.44909742593425
avg_episode_per_sec: 0.13318187436150214
collect_time: 45.05117553544789
reward_mean: -301.44409430438844
reward_std: 24.643225281072485
reward_max: -268.0609243697479
reward_min: -345.25630252100837
queue_len: 0.19989661426020452
wait_time: 1.8799674379035434
delay_time: 15.283409672512574
pressure: 2.414235190097259
total_envstep_count: 6264
total_train_sample_count: 6264
total_episode_count: 54
total_duration: 417.18308201941664
[2024-12-26 01:33:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.126722332152296
avg_train_sample_per_sec: 15.126722332152296
avg_episode_per_sec: 0.13040277872545084
collect_time: 46.01128947284445
reward_mean: -327.7501167133521
reward_std: 33.79132908807612
reward_max: -281.2408963585434
reward_min: -376.33053221288526
queue_len: 0.2173409262024881
wait_time: 1.9426493961864146
delay_time: 17.69584191496462
pressure: 2.632847038019452
total_envstep_count: 6960
total_train_sample_count: 6960
total_episode_count: 60
total_duration: 463.1943714922611
[2024-12-26 01:34:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.396568813087415
avg_train_sample_per_sec: 15.396568813087415
avg_episode_per_sec: 0.13272904149213288
collect_time: 45.204877037823195
reward_mean: -316.18989262371616
reward_std: 42.286223773646725
reward_max: -268.281512605042
reward_min: -402.2612044817927
queue_len: 0.2096749951085651
wait_time: 1.8664501277964767
delay_time: 17.644666709935667
pressure: 2.532493368700265
total_envstep_count: 7656
total_train_sample_count: 7656
total_episode_count: 66
total_duration: 508.39924853008426
[2024-12-26 01:34:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.21851599207154
avg_train_sample_per_sec: 15.21851599207154
avg_episode_per_sec: 0.13119410337992707
collect_time: 45.73376276389882
reward_mean: -321.7951680672268
reward_std: 17.713878360578956
reward_max: -297.19677871148457
reward_min: -345.0490196078431
queue_len: 0.2133920212647393
wait_time: 1.9224348448486381
delay_time: 17.699577456973397
pressure: 2.5109416445623345
total_envstep_count: 8352
total_train_sample_count: 8352
total_episode_count: 72
total_duration: 554.133011293983
[2024-12-26 01:35:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.588539678160563
avg_train_sample_per_sec: 15.588539678160563
avg_episode_per_sec: 0.13438396274276349
collect_time: 44.6481847799439
reward_mean: -309.20950046685346
reward_std: 19.84639926590509
reward_max: -287.30392156862746
reward_min: -347.05532212885174
queue_len: 0.20504608784274103
wait_time: 1.853871168272791
delay_time: 16.10235567241377
pressure: 2.4795534924845266
total_envstep_count: 9048
total_train_sample_count: 9048
total_episode_count: 78
total_duration: 598.7811960739269
[2024-12-26 01:36:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.133984726216509
avg_train_sample_per_sec: 15.133984726216509
avg_episode_per_sec: 0.13046538557083198
collect_time: 45.98920988695882
reward_mean: -331.1084267040149
reward_std: 30.44998687760734
reward_max: -292.3095238095238
reward_min: -368.141456582633
queue_len: 0.21956792221751653
wait_time: 1.8923317005847429
delay_time: 19.20775304646592
pressure: 2.6236737400530505
total_envstep_count: 9744
total_train_sample_count: 9744
total_episode_count: 84
total_duration: 644.7704059608858
[2024-12-26 01:37:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.662389296329176
avg_train_sample_per_sec: 15.662389296329176
avg_episode_per_sec: 0.13502059738214806
collect_time: 44.43766444773039
reward_mean: -298.4133986928105
reward_std: 29.486831078276396
reward_max: -263.1764705882353
reward_min: -347.9726890756302
queue_len: 0.19788686915968867
wait_time: 1.8393350930115633
delay_time: 14.718584908373723
pressure: 2.417219274977896
total_envstep_count: 10440
total_train_sample_count: 10440
total_episode_count: 90
total_duration: 689.2080704086162
[2024-12-26 01:37:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.586191104681742
avg_train_sample_per_sec: 15.586191104681742
avg_episode_per_sec: 0.13436371641967018
collect_time: 44.65491250078008
reward_mean: -295.282329598506
reward_std: 23.871965970977783
reward_max: -261.4341736694678
reward_min: -325.50630252100837
queue_len: 0.19581056339423475
wait_time: 1.8133034491426985
delay_time: 15.182373605925507
pressure: 2.4034040671971706
total_envstep_count: 11136
total_train_sample_count: 11136
total_episode_count: 96
total_duration: 733.8629829093962
[2024-12-26 01:38:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.524685961899992
avg_train_sample_per_sec: 15.524685961899992
avg_episode_per_sec: 0.13383349967155167
collect_time: 44.8318247279264
reward_mean: -288.52135854341736
reward_std: 31.460511274973086
reward_max: -248.44957983193277
reward_min: -348.6505602240896
queue_len: 0.1913271608378099
wait_time: 1.7688088055735116
delay_time: 15.478862909298556
pressure: 2.326149425287356
total_envstep_count: 11832
total_train_sample_count: 11832
total_episode_count: 102
total_duration: 778.6948076373226
[2024-12-26 01:39:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.771338339859199
avg_train_sample_per_sec: 15.771338339859199
avg_episode_per_sec: 0.13595981327464826
collect_time: 44.130687263298775
reward_mean: -283.1120448179272
reward_std: 15.41446955819333
reward_max: -258.6099439775911
reward_min: -308.4796918767508
queue_len: 0.18774008277050877
wait_time: 1.7837019091456208
delay_time: 13.64989223172505
pressure: 2.2595048629531385
total_envstep_count: 12528
total_train_sample_count: 12528
total_episode_count: 108
total_duration: 822.8254949006214
[2024-12-26 01:40:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.753940192897591
avg_train_sample_per_sec: 15.753940192897591
avg_episode_per_sec: 0.13580982924911716
collect_time: 44.179423780838036
reward_mean: -281.79878618113906
reward_std: 25.51827070861931
reward_max: -256.50490196078425
reward_min: -331.3746498599439
queue_len: 0.1868692216055299
wait_time: 1.8216274794621647
delay_time: 12.937742403711217
pressure: 2.2829354553492482
total_envstep_count: 13224
total_train_sample_count: 13224
total_episode_count: 114
total_duration: 867.0049186814595
[2024-12-26 01:40:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.900727150771122
avg_train_sample_per_sec: 15.900727150771122
avg_episode_per_sec: 0.13707523405837174
collect_time: 43.7715831106659
reward_mean: -275.62710084033614
reward_std: 15.25607343062885
reward_max: -247.17086834733894
reward_min: -295.8627450980393
queue_len: 0.18277659206918842
wait_time: 1.8166942506445551
delay_time: 13.028271960015141
pressure: 2.1988284703801946
total_envstep_count: 13920
total_train_sample_count: 13920
total_episode_count: 120
total_duration: 910.7765017921254
[2024-12-26 01:41:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.549313943273974
avg_train_sample_per_sec: 15.549313943273974
avg_episode_per_sec: 0.13404580985581013
collect_time: 44.760817264292385
reward_mean: -281.124533146592
reward_std: 24.19237309127273
reward_max: -241.7163865546219
reward_min: -311.51540616246496
queue_len: 0.18642210420861538
wait_time: 1.7559379852736852
delay_time: 14.388892689289762
pressure: 2.3072502210433243
total_envstep_count: 14616
total_train_sample_count: 14616
total_episode_count: 126
total_duration: 955.5373190564178
[2024-12-26 01:42:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.838408000011786
avg_train_sample_per_sec: 15.838408000011786
avg_episode_per_sec: 0.1365380000001016
collect_time: 43.94381051425636
reward_mean: -270.1743697478991
reward_std: 25.45754864952057
reward_max: -243.91946778711488
reward_min: -300.28361344537814
queue_len: 0.17916072264449548
wait_time: 1.7287793764720742
delay_time: 13.242501871218339
pressure: 2.2076702033598585
total_envstep_count: 15312
total_train_sample_count: 15312
total_episode_count: 132
total_duration: 999.4811295706742
[2024-12-26 01:43:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.712317779895546
avg_train_sample_per_sec: 15.712317779895546
avg_episode_per_sec: 0.13545101534392712
collect_time: 44.29645643308946
reward_mean: -267.10352474323065
reward_std: 20.00058523132059
reward_max: -238.41386554621846
reward_min: -300.3655462184874
queue_len: 0.17712435327800438
wait_time: 1.750388528532545
delay_time: 12.494654381518998
pressure: 2.190981432360743
total_envstep_count: 16008
total_train_sample_count: 16008
total_episode_count: 138
total_duration: 1043.7775860037636
[2024-12-26 01:43:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.161415750885773
avg_train_sample_per_sec: 16.161415750885773
avg_episode_per_sec: 0.13932254957660148
collect_time: 43.065534030448646
reward_mean: -252.16736694677877
reward_std: 15.012505412320529
reward_max: -227.7584033613446
reward_min: -273.2457983193278
queue_len: 0.16721973935462783
wait_time: 1.6541534164505765
delay_time: 11.20965269674884
pressure: 2.0708443854995577
total_envstep_count: 16704
total_train_sample_count: 16704
total_episode_count: 144
total_duration: 1086.8431200342122
[2024-12-26 01:44:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.988764696930891
avg_train_sample_per_sec: 15.988764696930891
avg_episode_per_sec: 0.13783417842181803
collect_time: 43.53056744487584
reward_mean: -253.24614845938376
reward_std: 13.274107093341293
reward_max: -230.95378151260505
reward_min: -272.1267507002802
queue_len: 0.1679351117104667
wait_time: 1.64394393920256
delay_time: 11.676577372450616
pressure: 2.0886383731211318
total_envstep_count: 17400
total_train_sample_count: 17400
total_episode_count: 150
total_duration: 1130.3736874790882
[2024-12-26 01:45:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.985957881465207
avg_train_sample_per_sec: 15.985957881465207
avg_episode_per_sec: 0.13780998173676903
collect_time: 43.53821054457873
reward_mean: -259.2223389355742
reward_std: 19.117371552405796
reward_max: -228.7619047619048
reward_min: -291.0770308123249
queue_len: 0.17189810274242323
wait_time: 1.6655971296564605
delay_time: 12.129715534900098
pressure: 2.1082007073386384
total_envstep_count: 18096
total_train_sample_count: 18096
total_episode_count: 156
total_duration: 1173.911898023667
[2024-12-26 01:46:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.880453444284795
avg_train_sample_per_sec: 15.880453444284795
avg_episode_per_sec: 0.13690046072659307
collect_time: 43.82746389716491
reward_mean: -261.30170401493933
reward_std: 16.70776272063173
reward_max: -239.4859943977591
reward_min: -290.8424369747899
queue_len: 0.173276992052347
wait_time: 1.6969035514294137
delay_time: 12.163705238959492
pressure: 2.1589301503094607
total_envstep_count: 18792
total_train_sample_count: 18792
total_episode_count: 162
total_duration: 1217.739361920832
[2024-12-26 01:46:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.961287406559814
avg_train_sample_per_sec: 15.961287406559814
avg_episode_per_sec: 0.1375973052289639
collect_time: 43.60550513700768
reward_mean: -264.9477124183007
reward_std: 31.851572639441383
reward_max: -219.9159663865547
reward_min: -324.9012605042017
queue_len: 0.175694769508157
wait_time: 1.6838116878050953
delay_time: 13.042290460633886
pressure: 2.1497568523430592
total_envstep_count: 19488
total_train_sample_count: 19488
total_episode_count: 168
total_duration: 1261.3448670578396
[2024-12-26 01:47:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.938639440693343
avg_train_sample_per_sec: 15.938639440693343
avg_episode_per_sec: 0.13740206414390813
collect_time: 43.6674662595745
reward_mean: -265.11531279178337
reward_std: 27.581243936351907
reward_max: -220.0980392156862
reward_min: -313.5798319327731
queue_len: 0.1758059103393789
wait_time: 1.661602406214475
delay_time: 13.014180878067037
pressure: 2.1928603006189213
total_envstep_count: 20184
total_train_sample_count: 20184
total_episode_count: 174
total_duration: 1305.012333317414
[2024-12-26 01:48:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.014780274874
avg_train_sample_per_sec: 16.014780274874
avg_episode_per_sec: 0.1380584506454655
collect_time: 43.459853213969616
reward_mean: -260.99171335200754
reward_std: 19.72827858302068
reward_max: -234.3746498599441
reward_min: -288.8382352941177
queue_len: 0.1730714279522596
wait_time: 1.6529413157836077
delay_time: 12.720643025522369
pressure: 2.1341732979664014
total_envstep_count: 20880
total_train_sample_count: 20880
total_episode_count: 180
total_duration: 1348.4721865313836
[2024-12-26 01:49:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.713059997308191
avg_train_sample_per_sec: 15.713059997308191
avg_episode_per_sec: 0.1354574137698982
collect_time: 44.29436405889317
reward_mean: -267.7401960784313
reward_std: 13.197135913298782
reward_max: -247.1757703081233
reward_min: -280.58193277310926
queue_len: 0.1775465491236282
wait_time: 1.697926341181919
delay_time: 12.781020329129653
pressure: 2.2390583554376655
total_envstep_count: 21576
total_train_sample_count: 21576
total_episode_count: 186
total_duration: 1392.766550590277
[2024-12-26 01:49:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.810651732990749
avg_train_sample_per_sec: 15.810651732990749
avg_episode_per_sec: 0.13629872183612715
collect_time: 44.02095572997258
reward_mean: -267.8374183006536
reward_std: 16.37167062282236
reward_max: -250.83963585434182
reward_min: -299.0581232492997
queue_len: 0.17761102009327165
wait_time: 1.6965589064980549
delay_time: 12.435103347502638
pressure: 2.2641467727674622
total_envstep_count: 22272
total_train_sample_count: 22272
total_episode_count: 192
total_duration: 1436.7875063202496
[2024-12-26 01:50:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.04031866309599
avg_train_sample_per_sec: 16.04031866309599
avg_episode_per_sec: 0.13827860916462062
collect_time: 43.39065916447715
reward_mean: -253.8953081232493
reward_std: 10.650805870670528
reward_max: -237.54761904761898
reward_min: -269.1757703081233
queue_len: 0.16836558894114675
wait_time: 1.6530567134015408
delay_time: 11.470102767898771
pressure: 2.126657824933687
total_envstep_count: 22968
total_train_sample_count: 22968
total_episode_count: 198
total_duration: 1480.1781654847268
[2024-12-26 01:51:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.890750348073917
avg_train_sample_per_sec: 15.890750348073917
avg_episode_per_sec: 0.13698922713856826
collect_time: 43.79906453469396
reward_mean: -260.5085200746966
reward_std: 18.2990389897113
reward_max: -236.60994397759103
reward_min: -281.5077030812325
queue_len: 0.1727510080070932
wait_time: 1.641277720195063
delay_time: 12.033314052332598
pressure: 2.217506631299735
total_envstep_count: 23664
total_train_sample_count: 23664
total_episode_count: 204
total_duration: 1523.9772300194209
[2024-12-26 01:51:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.032868400017104
avg_train_sample_per_sec: 16.032868400017104
avg_episode_per_sec: 0.13821438275876816
collect_time: 43.410822233110665
reward_mean: -263.2173202614379
reward_std: 20.18012181431856
reward_max: -245.8536414565827
reward_min: -301.35504201680664
queue_len: 0.17454729460307558
wait_time: 1.6246251705810526
delay_time: 12.672588047484142
pressure: 2.2319849690539346
total_envstep_count: 24360
total_train_sample_count: 24360
total_episode_count: 210
total_duration: 1567.3880522525315
[2024-12-26 01:52:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.686454372667624
avg_train_sample_per_sec: 15.686454372667624
avg_episode_per_sec: 0.13522805493678985
collect_time: 44.3694912479855
reward_mean: -293.3447712418301
reward_std: 43.05887173413009
reward_max: -250.93907563025226
reward_min: -364.50490196078425
queue_len: 0.19452571037256636
wait_time: 1.7735921181027674
delay_time: 14.836244378811807
pressure: 2.5228779840848805
total_envstep_count: 25056
total_train_sample_count: 25056
total_episode_count: 216
total_duration: 1611.757543500517
[2024-12-26 01:53:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.586111069384879
avg_train_sample_per_sec: 15.586111069384879
avg_episode_per_sec: 0.13436302646021447
collect_time: 44.655141805522135
reward_mean: -279.60294117647055
reward_std: 20.30277568522718
reward_max: -245.66946778711488
reward_min: -306.7885154061623
queue_len: 0.18541309096582928
wait_time: 1.7404373995398335
delay_time: 13.366556180901393
pressure: 2.3702475685234305
total_envstep_count: 25752
total_train_sample_count: 25752
total_episode_count: 222
total_duration: 1656.412685306039
[2024-12-26 01:54:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.27551933871846
avg_train_sample_per_sec: 16.27551933871846
avg_episode_per_sec: 0.1403062011958488
collect_time: 42.76361236254125
reward_mean: -245.14892623716153
reward_std: 24.251198342963956
reward_max: -209.66596638655466
reward_min: -278.5812324929971
queue_len: 0.16256560095302489
wait_time: 1.5894384942305837
delay_time: 11.105543053048224
pressure: 2.0060786914235194
total_envstep_count: 26448
total_train_sample_count: 26448
total_episode_count: 228
total_duration: 1699.1762976685802
[2024-12-26 01:54:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.98496562882966
avg_train_sample_per_sec: 15.98496562882966
avg_episode_per_sec: 0.13780142783473845
collect_time: 43.54091314057819
reward_mean: -259.2302754435107
reward_std: 9.419331978481733
reward_max: -250.5385154061625
reward_min: -276.1449579831933
queue_len: 0.17190336567872067
wait_time: 1.6404344120495236
delay_time: 12.183650325173977
pressure: 2.1921971706454464
total_envstep_count: 27144
total_train_sample_count: 27144
total_episode_count: 234
total_duration: 1742.7172108091584
[2024-12-26 01:55:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.91056649782497
avg_train_sample_per_sec: 15.91056649782497
avg_episode_per_sec: 0.1371600560157325
collect_time: 43.744514068380006
reward_mean: -254.9647525676938
reward_std: 23.911949095131618
reward_max: -221.62394957983201
reward_min: -287.9474789915966
queue_len: 0.169074769607224
wait_time: 1.613168222638304
delay_time: 11.746882892960796
pressure: 2.1610300618921308
total_envstep_count: 27840
total_train_sample_count: 27840
total_episode_count: 240
total_duration: 1786.4617248775385
[2024-12-26 01:56:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.80022131748038
avg_train_sample_per_sec: 15.80022131748038
avg_episode_per_sec: 0.13620880446103775
collect_time: 44.05001588363759
reward_mean: -277.88130252100837
reward_std: 28.724434349764007
reward_max: -236.4173669467787
reward_min: -326.7296918767506
queue_len: 0.18427142076989944
wait_time: 1.6859995213823815
delay_time: 13.492392668180399
pressure: 2.353337754199823
total_envstep_count: 28536
total_train_sample_count: 28536
total_episode_count: 246
total_duration: 1830.511740761176
[2024-12-26 01:57:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.152786612128523
avg_train_sample_per_sec: 16.152786612128523
avg_episode_per_sec: 0.13924816044938382
collect_time: 43.08854049228878
reward_mean: -242.6582633053221
reward_std: 13.86147224736577
reward_max: -228.40966386554626
reward_min: -266.2394957983193
queue_len: 0.16091396770909958
wait_time: 1.6093546835179697
delay_time: 10.488147801647198
pressure: 2.0175729442970822
total_envstep_count: 29232
total_train_sample_count: 29232
total_episode_count: 252
total_duration: 1873.6002812534648
[2024-12-26 01:57:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.912025701988771
avg_train_sample_per_sec: 15.912025701988771
avg_episode_per_sec: 0.13717263536197216
collect_time: 43.74050250013172
reward_mean: -280.45249766573295
reward_std: 45.84110658126612
reward_max: -227.00350140056014
reward_min: -370.75770308123236
queue_len: 0.18597645733801918
wait_time: 1.7330637162026619
delay_time: 12.962319993041381
pressure: 2.3906940760389035
total_envstep_count: 29928
total_train_sample_count: 29928
total_episode_count: 258
total_duration: 1917.3407837535965
[2024-12-26 01:58:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.25962807271629
avg_train_sample_per_sec: 16.25962807271629
avg_episode_per_sec: 0.1401692075234163
collect_time: 42.805407164748765
reward_mean: -261.9383753501401
reward_std: 15.896667182967736
reward_max: -235.92577030812325
reward_min: -281.95378151260513
queue_len: 0.1736991878979709
wait_time: 1.6279191495342609
delay_time: 12.507687871590555
pressure: 2.208554376657825
total_envstep_count: 30624
total_train_sample_count: 30624
total_episode_count: 264
total_duration: 1960.1461909183452
[2024-12-26 01:59:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.006320173859926
avg_train_sample_per_sec: 16.006320173859926
avg_episode_per_sec: 0.1379855187401718
collect_time: 43.482823812099184
reward_mean: -255.82831465919705
reward_std: 30.410420847816486
reward_max: -223.19957983193277
reward_min: -307.4474789915967
queue_len: 0.16964742351405637
wait_time: 1.6723870140452288
delay_time: 11.570320896157105
pressure: 2.126105216622458
total_envstep_count: 31320
total_train_sample_count: 31320
total_episode_count: 270
total_duration: 2003.6290147304444
[2024-12-26 02:00:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.950943357112378
avg_train_sample_per_sec: 15.950943357112378
avg_episode_per_sec: 0.1375081323888998
collect_time: 43.63378293169476
reward_mean: -246.47152194211023
reward_std: 13.286350359896723
reward_max: -219.76120448179267
reward_min: -260.53011204481794
queue_len: 0.16344265380776538
wait_time: 1.6214407071405041
delay_time: 10.984240218773351
pressure: 2.06631299734748
total_envstep_count: 32016
total_train_sample_count: 32016
total_episode_count: 276
total_duration: 2047.262797662139
[2024-12-26 02:00:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.996918523930223
avg_train_sample_per_sec: 15.996918523930223
avg_episode_per_sec: 0.13790447003388123
collect_time: 43.50837937686779
reward_mean: -244.4541316526611
reward_std: 16.979448247252485
reward_max: -226.23669467787116
reward_min: -273.25840336134456
queue_len: 0.16210486183863465
wait_time: 1.5936506233793253
delay_time: 10.964522894897266
pressure: 2.044098143236074
total_envstep_count: 32712
total_train_sample_count: 32712
total_episode_count: 282
total_duration: 2090.771177039007
[2024-12-26 02:01:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.43809632357639
avg_train_sample_per_sec: 16.43809632357639
avg_episode_per_sec: 0.14170772692738268
collect_time: 42.34066927821562
reward_mean: -227.26528944911297
reward_std: 12.258838552850795
reward_max: -208.75070028011208
reward_min: -238.8543417366947
queue_len: 0.15070642536413328
wait_time: 1.5159888778676816
delay_time: 9.67088397379292
pressure: 1.8566534040671971
total_envstep_count: 33408
total_train_sample_count: 33408
total_episode_count: 288
total_duration: 2133.1118463172224
[2024-12-26 02:02:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.03229738332206
avg_train_sample_per_sec: 16.03229738332206
avg_episode_per_sec: 0.13820946020105224
collect_time: 43.412368381092335
reward_mean: -250.3661297852474
reward_std: 23.732097103228543
reward_max: -228.37324929971984
reward_min: -301.1218487394959
queue_len: 0.1660252850034797
wait_time: 1.620741820158656
delay_time: 11.334575651505595
pressure: 2.050508399646331
total_envstep_count: 34104
total_train_sample_count: 34104
total_episode_count: 294
total_duration: 2176.5242146983146
[2024-12-26 02:02:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.313348521038407
avg_train_sample_per_sec: 16.313348521038407
avg_episode_per_sec: 0.14063231483653799
collect_time: 42.66444740651547
reward_mean: -232.186858076564
reward_std: 10.479372502479944
reward_max: -216.42296918767505
reward_min: -250.87044817927173
queue_len: 0.15397006503750926
wait_time: 1.5721109730364289
delay_time: 10.112586764602243
pressure: 1.9290450928381964
total_envstep_count: 34800
total_train_sample_count: 34800
total_episode_count: 300
total_duration: 2219.18866210483
[2024-12-26 02:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.101060352821644
avg_train_sample_per_sec: 16.101060352821644
avg_episode_per_sec: 0.13880224442087627
collect_time: 43.22696671825274
reward_mean: -240.81337535014003
reward_std: 17.736187693546494
reward_max: -211.44047619047615
reward_min: -262.5805322128851
queue_len: 0.15969056720831568
wait_time: 1.58920398398086
delay_time: 10.394343756046025
pressure: 1.9935897435897438
total_envstep_count: 35496
total_train_sample_count: 35496
total_episode_count: 306
total_duration: 2262.415628823083
[2024-12-26 02:04:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.433614457613558
avg_train_sample_per_sec: 16.433614457613558
avg_episode_per_sec: 0.141669090151841
collect_time: 42.352216659041126
reward_mean: -226.3953081232493
reward_std: 12.463492123145393
reward_max: -208.21288515406164
reward_min: -243.93627450980392
queue_len: 0.1501295146705897
wait_time: 1.5160309039619386
delay_time: 9.6348537464298
pressure: 1.875663129973475
total_envstep_count: 36192
total_train_sample_count: 36192
total_episode_count: 312
total_duration: 2304.767845482124
[2024-12-26 02:05:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.29889415289503
avg_train_sample_per_sec: 16.29889415289503
avg_episode_per_sec: 0.14050770821461234
collect_time: 42.702283570347355
reward_mean: -228.71265172735764
reward_std: 14.362043524210424
reward_max: -206.1617647058823
reward_min: -246.8396358543417
queue_len: 0.1516662146733141
wait_time: 1.5470785131028537
delay_time: 9.459137503461402
pressure: 1.9074933687002653
total_envstep_count: 36888
total_train_sample_count: 36888
total_episode_count: 318
total_duration: 2347.4701290524713
[2024-12-26 02:05:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.96144517409842
avg_train_sample_per_sec: 15.96144517409842
avg_episode_per_sec: 0.1375986652939519
collect_time: 43.605074127588416
reward_mean: -253.08648459383753
reward_std: 24.015923858400992
reward_max: -223.4453781512605
reward_min: -293.9180672268907
queue_len: 0.16782923381554207
wait_time: 1.6152414325588769
delay_time: 11.643973052991077
pressure: 2.0691865605658712
total_envstep_count: 37584
total_train_sample_count: 37584
total_episode_count: 324
total_duration: 2391.07520318006
[2024-12-26 02:06:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.073945420069084
avg_train_sample_per_sec: 16.073945420069084
avg_episode_per_sec: 0.13856849500059554
collect_time: 43.29988573502377
reward_mean: -253.95891690009339
reward_std: 36.13484249972473
reward_max: -219.92647058823525
reward_min: -304.3487394957983
queue_len: 0.16840776982764816
wait_time: 1.6097644959840702
delay_time: 12.185484839824142
pressure: 2.085654288240495
total_envstep_count: 38280
total_train_sample_count: 38280
total_episode_count: 330
total_duration: 2434.375088915084
[2024-12-26 02:07:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.0117510331321
avg_train_sample_per_sec: 16.0117510331321
avg_episode_per_sec: 0.13803233649251812
collect_time: 43.4680753254164
reward_mean: -242.64098972922497
reward_std: 12.793119307553305
reward_max: -224.71078431372538
reward_min: -262.9278711484594
queue_len: 0.16090251308304046
wait_time: 1.6316751059398114
delay_time: 10.72745819406714
pressure: 1.9981211317418213
total_envstep_count: 38976
total_train_sample_count: 38976
total_episode_count: 336
total_duration: 2477.8431642405003
[2024-12-26 02:08:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.31743652635348
avg_train_sample_per_sec: 16.31743652635348
avg_episode_per_sec: 0.1406675562616679
collect_time: 42.65375868788735
reward_mean: -236.5274276377218
reward_std: 14.414120055496667
reward_max: -220.10364145658266
reward_min: -260.6491596638656
queue_len: 0.1568484268154654
wait_time: 1.5615884284748383
delay_time: 10.312435913597023
pressure: 1.9470601237842615
total_envstep_count: 39672
total_train_sample_count: 39672
total_episode_count: 342
total_duration: 2520.4969229283874
[2024-12-26 02:08:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.117700091787675
avg_train_sample_per_sec: 16.117700091787675
avg_episode_per_sec: 0.13894569044644547
collect_time: 43.1823396661058
reward_mean: -236.7301587301587
reward_std: 16.29787388958761
reward_max: -209.42296918767505
reward_min: -260.6960784313726
queue_len: 0.1569828638794156
wait_time: 1.5931997135724314
delay_time: 10.513406782896636
pressure: 1.9530282935455352
total_envstep_count: 40368
total_train_sample_count: 40368
total_episode_count: 348
total_duration: 2563.679262594493
[2024-12-26 02:09:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.10525456161545
avg_train_sample_per_sec: 16.10525456161545
avg_episode_per_sec: 0.13883840139323664
collect_time: 43.21570934114978
reward_mean: -240.843954248366
reward_std: 20.58855733079828
reward_max: -209.0014005602241
reward_min: -277.9467787114845
queue_len: 0.15971084499228513
wait_time: 1.6146275265190069
delay_time: 10.762568711860036
pressure: 2.013373121131742
total_envstep_count: 41064
total_train_sample_count: 41064
total_episode_count: 354
total_duration: 2606.894971935643
[2024-12-26 02:10:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.747378882528453
avg_train_sample_per_sec: 15.747378882528453
avg_episode_per_sec: 0.13575326622869358
collect_time: 44.197831600546834
reward_mean: -249.14239028944914
reward_std: 24.618117386053793
reward_max: -213.29061624649853
reward_min: -284.84033613445376
queue_len: 0.16521378666409092
wait_time: 1.6761852287334031
delay_time: 11.312094021191365
pressure: 2.0423297966401415
total_envstep_count: 41760
total_train_sample_count: 41760
total_episode_count: 360
total_duration: 2651.09280353619
[2024-12-26 02:11:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.396721354782073
avg_train_sample_per_sec: 16.396721354782073
avg_episode_per_sec: 0.14135104616191443
collect_time: 42.44751038578898
reward_mean: -215.8048552754435
reward_std: 10.508872651681443
reward_max: -199.73319327731085
reward_min: -232.3326330532212
queue_len: 0.14310666795453814
wait_time: 1.4494717869464318
delay_time: 9.317089785951842
pressure: 1.772767462422635
total_envstep_count: 42456
total_train_sample_count: 42456
total_episode_count: 366
total_duration: 2693.540313921979
[2024-12-26 02:11:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.16967125675735
avg_train_sample_per_sec: 16.16967125675735
avg_episode_per_sec: 0.1393937177306668
collect_time: 43.04354670841806
reward_mean: -246.40499533146593
reward_std: 23.436139799835615
reward_max: -208.54691876750704
reward_min: -275.5847338935574
queue_len: 0.1633985380182135
wait_time: 1.5627941052636791
delay_time: 11.481046208928655
pressure: 2.0942749778956675
total_envstep_count: 43152
total_train_sample_count: 43152
total_episode_count: 372
total_duration: 2736.583860630397
[2024-12-26 02:12:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.04471715197083
avg_train_sample_per_sec: 16.04471715197083
avg_episode_per_sec: 0.1383165271721623
collect_time: 43.378764075906936
reward_mean: -235.77439309056956
reward_std: 9.259819707088228
reward_max: -224.8501400560224
reward_min: -251.266106442577
queue_len: 0.1563490670361867
wait_time: 1.5355706385118149
delay_time: 10.988789172345351
pressure: 1.9910477453580901
total_envstep_count: 43848
total_train_sample_count: 43848
total_episode_count: 378
total_duration: 2779.962624706304
[2024-12-26 02:13:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.286843178353646
avg_train_sample_per_sec: 16.286843178353646
avg_episode_per_sec: 0.14040382050304867
collect_time: 42.73387987949885
reward_mean: -235.12021475256768
reward_std: 18.215064117226927
reward_max: -213.17997198879547
reward_min: -270.1428571428571
queue_len: 0.15591526177225976
wait_time: 1.5589618362818163
delay_time: 10.488493605599283
pressure: 1.956896551724138
total_envstep_count: 44544
total_train_sample_count: 44544
total_episode_count: 384
total_duration: 2822.696504585803
[2024-12-26 02:13:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.747883011526998
avg_train_sample_per_sec: 16.747883011526998
avg_episode_per_sec: 0.1443783018235086
collect_time: 41.55749114804342
reward_mean: -207.51073762838465
reward_std: 9.801923246277616
reward_max: -191.92226890756305
reward_min: -221.7773109243697
queue_len: 0.13760658993924713
wait_time: 1.4263352224178796
delay_time: 8.538936852321262
pressure: 1.7060123784261716
total_envstep_count: 45240
total_train_sample_count: 45240
total_episode_count: 390
total_duration: 2864.2539957338463
[2024-12-26 02:14:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.560404130525374
avg_train_sample_per_sec: 16.560404130525374
avg_episode_per_sec: 0.1427621045734946
collect_time: 42.02795985618979
reward_mean: -214.8609943977591
reward_std: 14.326756735274117
reward_max: -192.82843137254898
reward_min: -227.00280112044823
queue_len: 0.14248076551575536
wait_time: 1.4892983608120522
delay_time: 8.831599132007504
pressure: 1.7905614500442084
total_envstep_count: 45936
total_train_sample_count: 45936
total_episode_count: 396
total_duration: 2906.281955590036
[2024-12-26 02:15:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.383177322470768
avg_train_sample_per_sec: 16.383177322470768
avg_episode_per_sec: 0.14123428726267903
collect_time: 42.482601897092536
reward_mean: -216.0511204481793
reward_std: 9.948787187893915
reward_max: -197.00770308123256
reward_min: -226.71008403361344
queue_len: 0.1432699737720022
wait_time: 1.4700027336310297
delay_time: 9.315014179973998
pressure: 1.77553050397878
total_envstep_count: 46632
total_train_sample_count: 46632
total_episode_count: 402
total_duration: 2948.7645574871285
[2024-12-26 02:16:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.528034941415434
avg_train_sample_per_sec: 16.528034941415434
avg_episode_per_sec: 0.1424830598397882
collect_time: 42.11026915583201
reward_mean: -210.88445378151255
reward_std: 14.239358466897743
reward_max: -188.594537815126
reward_min: -230.7633053221288
queue_len: 0.13984380224238235
wait_time: 1.4187506346482006
delay_time: 9.002127451784219
pressure: 1.754310344827586
total_envstep_count: 47328
total_train_sample_count: 47328
total_episode_count: 408
total_duration: 2990.8748266429607
[2024-12-26 02:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.523595304988397
avg_train_sample_per_sec: 16.523595304988397
avg_episode_per_sec: 0.14244478711196892
collect_time: 42.121583538776264
reward_mean: -226.51552287581694
reward_std: 23.734652269610958
reward_max: -199.7913165266106
reward_min: -266.41036414565815
queue_len: 0.1502092326762712
wait_time: 1.5191084833579762
delay_time: 9.66454694485844
pressure: 1.884394341290893
total_envstep_count: 48024
total_train_sample_count: 48024
total_episode_count: 414
total_duration: 3032.996410181737
[2024-12-26 02:17:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.550671097436457
avg_train_sample_per_sec: 16.550671097436457
avg_episode_per_sec: 0.14267819911583152
collect_time: 42.05267544152961
reward_mean: -210.6527777777778
reward_std: 15.41811535201165
reward_max: -190.8774509803921
reward_min: -236.63025210084035
queue_len: 0.13969017094017097
wait_time: 1.4467510036729105
delay_time: 8.546783684056706
pressure: 1.7407161803713531
total_envstep_count: 48720
total_train_sample_count: 48720
total_episode_count: 420
total_duration: 3075.0490856232664
[2024-12-26 02:18:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.48441613961482
avg_train_sample_per_sec: 16.48441613961482
avg_episode_per_sec: 0.14210703568633465
collect_time: 42.22169557630829
reward_mean: -209.60189075630248
reward_std: 12.726854977708062
reward_max: -186.3487394957982
reward_min: -227.03711484593836
queue_len: 0.138993296257495
wait_time: 1.427431770674671
delay_time: 8.852963556282363
pressure: 1.753205128205128
total_envstep_count: 49416
total_train_sample_count: 49416
total_episode_count: 426
total_duration: 3117.2707811995747
[2024-12-26 02:18:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.420590749530394
avg_train_sample_per_sec: 16.420590749530394
avg_episode_per_sec: 0.1415568168062965
collect_time: 42.38580758855491
reward_mean: -220.28022875816995
reward_std: 12.566256995789661
reward_max: -204.01190476190476
reward_min: -238.95448179271705
queue_len: 0.14607442225342834
wait_time: 1.4731636686504845
delay_time: 9.094238731880099
pressure: 1.8467064544650753
total_envstep_count: 50112
total_train_sample_count: 50112
total_episode_count: 432
total_duration: 3159.6565887881297
[2024-12-26 02:19:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.607500941446695
avg_train_sample_per_sec: 16.607500941446695
avg_episode_per_sec: 0.14316811156419565
collect_time: 41.90877377962507
reward_mean: -214.22385620915034
reward_std: 7.0677242079873475
reward_max: -203.68907563025212
reward_min: -225.99509803921572
queue_len: 0.14205826008564346
wait_time: 1.4408419645488608
delay_time: 9.442061377001176
pressure: 1.730658709106985
total_envstep_count: 50808
total_train_sample_count: 50808
total_episode_count: 438
total_duration: 3201.5653625677546
[2024-12-26 02:20:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.40572296405675
avg_train_sample_per_sec: 16.40572296405675
avg_episode_per_sec: 0.14142864624186852
collect_time: 42.42421998255514
reward_mean: -206.72035480859014
reward_std: 13.592306188261116
reward_max: -188.83333333333337
reward_min: -222.04831932773112
queue_len: 0.13708246340092184
wait_time: 1.412284730426211
delay_time: 8.627278092820172
pressure: 1.7348585322723256
total_envstep_count: 51504
total_train_sample_count: 51504
total_episode_count: 444
total_duration: 3243.98958255031
[2024-12-26 02:21:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.503212563096262
avg_train_sample_per_sec: 16.503212563096262
avg_episode_per_sec: 0.14226907381979537
collect_time: 42.17360694707185
reward_mean: -209.87966853408025
reward_std: 11.758626452770145
reward_max: -199.29551820728292
reward_min: -232.71568627450978
queue_len: 0.13917749902790472
wait_time: 1.4474593329816454
delay_time: 8.848130473031878
pressure: 1.7602785145888593
total_envstep_count: 52200
total_train_sample_count: 52200
total_episode_count: 450
total_duration: 3286.1631894973816
[2024-12-26 02:21:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.66257049552981
avg_train_sample_per_sec: 16.66257049552981
avg_episode_per_sec: 0.14364284909939493
collect_time: 41.77026588945091
reward_mean: -201.37091503267973
reward_std: 10.100850698781633
reward_max: -187.3333333333333
reward_min: -217.77310924369746
queue_len: 0.13353508954421733
wait_time: 1.3679287033115635
delay_time: 8.705921176599476
pressure: 1.6725243147656939
total_envstep_count: 52896
total_train_sample_count: 52896
total_episode_count: 456
total_duration: 3327.9334553868325
[2024-12-26 02:22:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.65238978837699
avg_train_sample_per_sec: 16.65238978837699
avg_episode_per_sec: 0.14355508438256023
collect_time: 41.79580281538888
reward_mean: -199.67775443510732
reward_std: 11.933343000745714
reward_max: -184.91666666666663
reward_min: -223.0343137254902
queue_len: 0.13241230400206058
wait_time: 1.3675200517872934
delay_time: 8.495541304650793
pressure: 1.6237842617152962
total_envstep_count: 53592
total_train_sample_count: 53592
total_episode_count: 462
total_duration: 3369.7292582022214
[2024-12-26 02:23:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54033903899572
avg_train_sample_per_sec: 16.54033903899572
avg_episode_per_sec: 0.14258912964651485
collect_time: 42.07894399015046
reward_mean: -200.64705882352942
reward_std: 6.793140514491475
reward_max: -189.06372549019608
reward_min: -208.17787114845947
queue_len: 0.1330550787954439
wait_time: 1.3778455458222194
delay_time: 8.165308584416207
pressure: 1.6711980548187446
total_envstep_count: 54288
total_train_sample_count: 54288
total_episode_count: 468
total_duration: 3411.808202192372
[2024-12-26 02:23:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.367311765283517
avg_train_sample_per_sec: 16.367311765283517
avg_episode_per_sec: 0.14109751521796135
collect_time: 42.523782156839964
reward_mean: -213.6528944911298
reward_std: 9.072316083471128
reward_max: -200.1757703081233
reward_min: -222.55042016806718
queue_len: 0.14167963825671737
wait_time: 1.4422547533602297
delay_time: 9.037938278043425
pressure: 1.7944297082228118
total_envstep_count: 54984
total_train_sample_count: 54984
total_episode_count: 474
total_duration: 3454.331984349212
[2024-12-26 02:24:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.328738966449745
avg_train_sample_per_sec: 16.328738966449745
avg_episode_per_sec: 0.14076499109008403
collect_time: 42.62423457378147
reward_mean: -217.2256069094304
reward_std: 14.81508514561449
reward_max: -195.70238095238096
reward_min: -237.49299719887955
queue_len: 0.14404881094789815
wait_time: 1.4798874567510472
delay_time: 9.354916004774422
pressure: 1.7950928381962863
total_envstep_count: 55680
total_train_sample_count: 55680
total_episode_count: 480
total_duration: 3496.9562189229932
[2024-12-26 02:25:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.40690404028763
avg_train_sample_per_sec: 16.40690404028763
avg_episode_per_sec: 0.14143882793351403
collect_time: 42.42116600980611
reward_mean: -209.46697012138188
reward_std: 12.872584603839758
reward_max: -196.6449579831933
reward_min: -227.49789915966386
queue_len: 0.13890382634043894
wait_time: 1.4350456915745964
delay_time: 8.878230928485957
pressure: 1.752210433244916
total_envstep_count: 56376
total_train_sample_count: 56376
total_episode_count: 486
total_duration: 3539.3773849327995
[2024-12-26 02:26:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.45779557741268
avg_train_sample_per_sec: 16.45779557741268
avg_episode_per_sec: 0.14187754808114378
collect_time: 42.28998936863802
reward_mean: -214.33146591970123
reward_std: 11.402057538473978
reward_max: -198.57983193277312
reward_min: -230.81162464986
queue_len: 0.1421296193101467
wait_time: 1.4628897204328233
delay_time: 8.904610004357957
pressure: 1.797082228116711
total_envstep_count: 57072
total_train_sample_count: 57072
total_episode_count: 492
total_duration: 3581.6673743014376
[2024-12-26 02:26:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.561602688814826
avg_train_sample_per_sec: 16.561602688814826
avg_episode_per_sec: 0.1427724369725416
collect_time: 42.02491830516234
reward_mean: -217.04003267973852
reward_std: 12.089221512250353
reward_max: -203.83543417366934
reward_min: -241.64565826330536
queue_len: 0.14392575111388498
wait_time: 1.474836972808575
delay_time: 8.959949511163522
pressure: 1.8160919540229887
total_envstep_count: 57768
total_train_sample_count: 57768
total_episode_count: 498
total_duration: 3623.6922926066
[2024-12-26 02:27:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52131471020808
avg_train_sample_per_sec: 16.52131471020808
avg_episode_per_sec: 0.14242512681213862
collect_time: 42.127397983040666
reward_mean: -208.18709150326796
reward_std: 9.307848570371272
reward_max: -198.68767507002804
reward_min: -226.38305322128855
queue_len: 0.13805510046635808
wait_time: 1.417547511931386
delay_time: 8.731183318585403
pressure: 1.740605658709107
total_envstep_count: 58464
total_train_sample_count: 58464
total_episode_count: 504
total_duration: 3665.8196905896407
[2024-12-26 02:28:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.236063952375872
avg_train_sample_per_sec: 16.236063952375872
avg_episode_per_sec: 0.1399660685549644
collect_time: 42.86753255231864
reward_mean: -226.936974789916
reward_std: 17.12229259294965
reward_max: -209.02170868347355
reward_min: -254.10924369747903
queue_len: 0.1504887100728886
wait_time: 1.5562558356676004
delay_time: 9.585130743395379
pressure: 1.849027409372237
total_envstep_count: 59160
total_train_sample_count: 59160
total_episode_count: 510
total_duration: 3708.6872231419593
[2024-12-26 02:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.363954191617037
avg_train_sample_per_sec: 16.363954191617037
avg_episode_per_sec: 0.14106857061738823
collect_time: 42.532507232056936
reward_mean: -217.0219421101774
reward_std: 20.678080398482688
reward_max: -189.5966386554621
reward_min: -254.53571428571428
queue_len: 0.14391375471497175
wait_time: 1.4908095974906324
delay_time: 9.115497918335194
pressure: 1.810344827586207
total_envstep_count: 59856
total_train_sample_count: 59856
total_episode_count: 516
total_duration: 3751.2197303740163
[2024-12-26 02:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.439717049119896
avg_train_sample_per_sec: 16.439717049119896
avg_episode_per_sec: 0.14172169869930945
collect_time: 42.33649508202822
reward_mean: -207.47105508870217
reward_std: 12.298716770523981
reward_max: -192.6106442577031
reward_min: -226.16596638655463
queue_len: 0.13758027525776
wait_time: 1.4140363594597873
delay_time: 8.79341459085503
pressure: 1.7402740937223697
total_envstep_count: 60552
total_train_sample_count: 60552
total_episode_count: 522
total_duration: 3793.5562254560446
[2024-12-26 02:30:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71769113261786
avg_train_sample_per_sec: 16.71769113261786
avg_episode_per_sec: 0.14411802700532636
collect_time: 41.63254330270737
reward_mean: -194.05847338935578
reward_std: 7.805078957412538
reward_max: -183.24229691876752
reward_min: -208.48179271708685
queue_len: 0.12868599031124392
wait_time: 1.3340937502321886
delay_time: 8.029855692262322
pressure: 1.5927276746242265
total_envstep_count: 61248
total_train_sample_count: 61248
total_episode_count: 528
total_duration: 3835.188768758752
[2024-12-26 02:31:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.672550928961115
avg_train_sample_per_sec: 16.672550928961115
avg_episode_per_sec: 0.14372888731863032
collect_time: 41.74526159587317
reward_mean: -202.63083566760034
reward_std: 12.326404639310445
reward_max: -181.65266106442576
reward_min: -222.99159663865544
queue_len: 0.1343705806814326
wait_time: 1.3903383634620958
delay_time: 8.281838045846706
pressure: 1.6777188328912465
total_envstep_count: 61944
total_train_sample_count: 61944
total_episode_count: 534
total_duration: 3876.934030354625
[2024-12-26 02:31:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.357583945635852
avg_train_sample_per_sec: 16.357583945635852
avg_episode_per_sec: 0.14101365470375735
collect_time: 42.54907095773704
reward_mean: -214.19572829131656
reward_std: 7.169332271007573
reward_max: -205.33473389355754
reward_min: -223.46008403361347
queue_len: 0.14203960762023646
wait_time: 1.454977205294142
delay_time: 9.12147025879827
pressure: 1.7673519009725907
total_envstep_count: 62640
total_train_sample_count: 62640
total_episode_count: 540
total_duration: 3919.483101312362
[2024-12-26 02:32:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.43181452688
avg_train_sample_per_sec: 16.43181452688
avg_episode_per_sec: 0.1416535735075862
collect_time: 42.35685589448735
reward_mean: -204.80812324929977
reward_std: 11.866792349123001
reward_max: -186.49089635854347
reward_min: -217.5560224089636
queue_len: 0.13581440533773192
wait_time: 1.398258540816857
delay_time: 8.707740394204269
pressure: 1.6903183023872677
total_envstep_count: 63336
total_train_sample_count: 63336
total_episode_count: 546
total_duration: 3961.8399572068492
[2024-12-26 02:33:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.422017124101156
avg_train_sample_per_sec: 16.422017124101156
avg_episode_per_sec: 0.14156911313880308
collect_time: 42.38212606528961
reward_mean: -207.9299719887955
reward_std: 11.188225609494213
reward_max: -190.03221288515394
reward_min: -224.75910364145653
queue_len: 0.1378845968095461
wait_time: 1.417016342345957
delay_time: 8.723095658505677
pressure: 1.735079575596817
total_envstep_count: 64032
total_train_sample_count: 64032
total_episode_count: 552
total_duration: 4004.2220832721387
[2024-12-26 02:33:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.733928007865305
avg_train_sample_per_sec: 16.733928007865305
avg_episode_per_sec: 0.14425800006780437
collect_time: 41.59214738302119
reward_mean: -199.6898926237161
reward_std: 11.77223919596044
reward_max: -175.46218487394947
reward_min: -213.0973389355742
queue_len: 0.13242035319875076
wait_time: 1.3654293503431436
delay_time: 8.225584156528079
pressure: 1.6619142351900973
total_envstep_count: 64728
total_train_sample_count: 64728
total_episode_count: 558
total_duration: 4045.81423065516
[2024-12-26 02:34:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.734967513733142
avg_train_sample_per_sec: 16.734967513733142
avg_episode_per_sec: 0.14426696132528571
collect_time: 41.58956385358051
reward_mean: -206.78676470588232
reward_std: 8.404522520828634
reward_max: -192.23459383753502
reward_min: -218.71918767506995
queue_len: 0.13712650179435168
wait_time: 1.424999984520775
delay_time: 8.369973204253489
pressure: 1.720822281167109
total_envstep_count: 65424
total_train_sample_count: 65424
total_episode_count: 564
total_duration: 4087.4037945087402
[2024-12-26 02:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.526823083264688
avg_train_sample_per_sec: 16.526823083264688
avg_episode_per_sec: 0.14247261278676457
collect_time: 42.11335696482285
reward_mean: -200.26855742296922
reward_std: 13.816686150013336
reward_max: -182.04201680672264
reward_min: -220.5084033613445
queue_len: 0.13280408317173023
wait_time: 1.3814323917011542
delay_time: 8.054366238709823
pressure: 1.6794871794871795
total_envstep_count: 66120
total_train_sample_count: 66120
total_episode_count: 570
total_duration: 4129.517151473563
[2024-12-26 02:36:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53705979330527
avg_train_sample_per_sec: 16.53705979330527
avg_episode_per_sec: 0.14256086028711443
collect_time: 42.08728810920566
reward_mean: -208.17682072829132
reward_std: 13.476787668210923
reward_max: -196.1162464985994
reward_min: -233.046218487395
queue_len: 0.13804828960762025
wait_time: 1.4369258755668495
delay_time: 8.533532498603725
pressure: 1.7316534040671971
total_envstep_count: 66816
total_train_sample_count: 66816
total_episode_count: 576
total_duration: 4171.6044395827685
[2024-12-26 02:36:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.903273853652035
avg_train_sample_per_sec: 16.903273853652035
avg_episode_per_sec: 0.14571787804872444
collect_time: 41.17545547838508
reward_mean: -195.6310690943044
reward_std: 7.701088066732532
reward_max: -180.42156862745102
reward_min: -204.6022408963586
queue_len: 0.12972882565935304
wait_time: 1.3492459760208242
delay_time: 7.9790324737926825
pressure: 1.6298629531388151
total_envstep_count: 67512
total_train_sample_count: 67512
total_episode_count: 582
total_duration: 4212.779895061153
[2024-12-26 02:37:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.62919594281579
avg_train_sample_per_sec: 16.62919594281579
avg_episode_per_sec: 0.14335513743806716
collect_time: 41.8540982013438
reward_mean: -206.12535014005604
reward_std: 14.44801137932307
reward_max: -185.6491596638655
reward_min: -231.3165266106443
queue_len: 0.13668789797085942
wait_time: 1.3679648473005475
delay_time: 8.677803106852496
pressure: 1.7376215738284706
total_envstep_count: 68208
total_train_sample_count: 68208
total_episode_count: 588
total_duration: 4254.633993262497
[2024-12-26 02:38:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.563006596681884
avg_train_sample_per_sec: 16.563006596681884
avg_episode_per_sec: 0.14278453962656795
collect_time: 42.021356203494584
reward_mean: -203.4282212885154
reward_std: 6.345018598593555
reward_max: -194.66876750700283
reward_min: -214.2128851540616
queue_len: 0.1348993509870792
wait_time: 1.4095377098673245
delay_time: 8.17648880924524
pressure: 1.7176171529619808
total_envstep_count: 68904
total_train_sample_count: 68904
total_episode_count: 594
total_duration: 4296.655349465991
[2024-12-26 02:38:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.656727756619638
avg_train_sample_per_sec: 16.656727756619638
avg_episode_per_sec: 0.1435924806605141
collect_time: 41.78491779235564
reward_mean: -198.65009337068162
reward_std: 9.244991161865865
reward_max: -186.12324929971987
reward_min: -213.45938375350147
queue_len: 0.13173083114766684
wait_time: 1.3543000201849085
delay_time: 8.218627372993787
pressure: 1.6352785145888598
total_envstep_count: 69600
total_train_sample_count: 69600
total_episode_count: 600
total_duration: 4338.4402672583465
[2024-12-26 02:39:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.490161454258768
avg_train_sample_per_sec: 16.490161454258768
avg_episode_per_sec: 0.14215656426085144
collect_time: 42.206985172983266
reward_mean: -195.1741363211952
reward_std: 12.182933466890903
reward_max: -177.21428571428575
reward_min: -212.18137254901967
queue_len: 0.12942581984164137
wait_time: 1.3434625508028146
delay_time: 8.11989778585743
pressure: 1.60289566755084
total_envstep_count: 70296
total_train_sample_count: 70296
total_episode_count: 606
total_duration: 4380.647252431329
[2024-12-26 02:40:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.856946075747604
avg_train_sample_per_sec: 16.856946075747604
avg_episode_per_sec: 0.1453185006529966
collect_time: 41.28861757476628
reward_mean: -195.0639589169001
reward_std: 12.268605348109094
reward_max: -173.70098039215685
reward_min: -207.7514005602241
queue_len: 0.12935275790245365
wait_time: 1.3293262265118249
delay_time: 8.075516895085201
pressure: 1.6202475685234308
total_envstep_count: 70992
total_train_sample_count: 70992
total_episode_count: 612
total_duration: 4421.935870006096
[2024-12-26 02:40:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.668348876472923
avg_train_sample_per_sec: 16.668348876472923
avg_episode_per_sec: 0.14369266272821485
collect_time: 41.75578548049181
reward_mean: -194.45599906629317
reward_std: 14.300073872636483
reward_max: -165.71428571428572
reward_min: -210.23669467787116
queue_len: 0.12894960150284696
wait_time: 1.3374073878003896
delay_time: 8.063360946511105
pressure: 1.6073165340406719
total_envstep_count: 71688
total_train_sample_count: 71688
total_episode_count: 618
total_duration: 4463.6916554865875
[2024-12-26 02:41:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.399353686175317
avg_train_sample_per_sec: 16.399353686175317
avg_episode_per_sec: 0.14137373867392514
collect_time: 42.440696951778605
reward_mean: -197.22082166199814
reward_std: 7.672567339660652
reward_max: -189.09173669467796
reward_min: -209.2794117647059
queue_len: 0.1307830382373993
wait_time: 1.3482423031104573
delay_time: 7.982686965258833
pressure: 1.6499778956675508
total_envstep_count: 72384
total_train_sample_count: 72384
total_episode_count: 624
total_duration: 4506.132352438366
[2024-12-26 02:42:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.64552889339476
avg_train_sample_per_sec: 16.64552889339476
avg_episode_per_sec: 0.14349593873616173
collect_time: 41.81303006095439
reward_mean: -191.13457049486465
reward_std: 10.183754818716809
reward_max: -176.21288515406155
reward_min: -205.233893557423
queue_len: 0.12674706266237706
wait_time: 1.3046499435317893
delay_time: 7.720134156887192
pressure: 1.584106984969054
total_envstep_count: 73080
total_train_sample_count: 73080
total_episode_count: 630
total_duration: 4547.945382499321
[2024-12-26 02:43:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.84215338078163
avg_train_sample_per_sec: 16.84215338078163
avg_episode_per_sec: 0.1451909774205313
collect_time: 41.32488193547725
reward_mean: -199.88153594771242
reward_std: 8.11923763003357
reward_max: -191.47759103641454
reward_min: -212.0357142857142
queue_len: 0.13254743763110902
wait_time: 1.3775551555723968
delay_time: 8.096204512206848
pressure: 1.651635720601238
total_envstep_count: 73776
total_train_sample_count: 73776
total_episode_count: 636
total_duration: 4589.270264434798
[2024-12-26 02:43:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.617570283599424
avg_train_sample_per_sec: 16.617570283599424
avg_episode_per_sec: 0.14325491623792605
collect_time: 41.88337934619188
reward_mean: -197.52859477124184
reward_std: 11.364361486852836
reward_max: -177.54061624649867
reward_min: -210.61974789915962
queue_len: 0.13098713181116833
wait_time: 1.3488589180145976
delay_time: 7.936092035974563
pressure: 1.6652298850574716
total_envstep_count: 74472
total_train_sample_count: 74472
total_episode_count: 642
total_duration: 4631.15364378099
[2024-12-26 02:44:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.726298944049475
avg_train_sample_per_sec: 16.726298944049475
avg_episode_per_sec: 0.14419223227628858
collect_time: 41.611118055952716
reward_mean: -195.18137254901964
reward_std: 13.81475285609302
reward_max: -172.0987394957983
reward_min: -215.67647058823533
queue_len: 0.12943061840120662
wait_time: 1.320077002949721
delay_time: 7.993746566467163
pressure: 1.6167108753315649
total_envstep_count: 75168
total_train_sample_count: 75168
total_episode_count: 648
total_duration: 4672.764761836943
[2024-12-26 02:45:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.78896357467118
avg_train_sample_per_sec: 16.78896357467118
avg_episode_per_sec: 0.1447324446092343
collect_time: 41.45580499382503
reward_mean: -195.90044351073766
reward_std: 11.720935207208306
reward_max: -179.57843137254906
reward_min: -215.8725490196078
queue_len: 0.1299074559089772
wait_time: 1.3356246455257612
delay_time: 7.934698989774674
pressure: 1.6233421750663128
total_envstep_count: 75864
total_train_sample_count: 75864
total_episode_count: 654
total_duration: 4714.220566830768
[2024-12-26 02:45:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.548559394769526
avg_train_sample_per_sec: 16.548559394769526
avg_episode_per_sec: 0.1426599947824959
collect_time: 42.05804163352028
reward_mean: -196.56290849673204
reward_std: 15.203325648053235
reward_max: -180.23599439775913
reward_min: -225.8816526610645
queue_len: 0.13034675629756767
wait_time: 1.3579524979753177
delay_time: 7.927134972723266
pressure: 1.651193633952255
total_envstep_count: 76560
total_train_sample_count: 76560
total_episode_count: 660
total_duration: 4756.2786084642885
[2024-12-26 02:46:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.70619963545347
avg_train_sample_per_sec: 16.70619963545347
avg_episode_per_sec: 0.14401896237459888
collect_time: 41.661180590884754
reward_mean: -193.41795051353878
reward_std: 9.929800566980779
reward_max: -175.5273109243698
reward_min: -205.81722689075633
queue_len: 0.12826124039359335
wait_time: 1.3081064543412415
delay_time: 8.190235120427651
pressure: 1.5970380194518128
total_envstep_count: 77256
total_train_sample_count: 77256
total_episode_count: 666
total_duration: 4797.939789055174
[2024-12-26 02:47:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75188942978724
avg_train_sample_per_sec: 16.75188942978724
avg_episode_per_sec: 0.14441283991195897
collect_time: 41.54755216819979
reward_mean: -210.6510270774977
reward_std: 18.20057704683191
reward_max: -185.00700280112048
reward_min: -232.97759103641454
queue_len: 0.13968900999834064
wait_time: 1.4322795541735704
delay_time: 8.320087798966986
pressure: 1.7943191865605659
total_envstep_count: 77952
total_train_sample_count: 77952
total_episode_count: 672
total_duration: 4839.487341223374
[2024-12-26 02:48:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.066472831822534
avg_train_sample_per_sec: 17.066472831822534
avg_episode_per_sec: 0.14712476579157358
collect_time: 40.78171317873149
reward_mean: -184.24136321195147
reward_std: 6.102087343729809
reward_max: -173.99159663865544
reward_min: -190.66386554621852
queue_len: 0.12217597029970252
wait_time: 1.2493610950127176
delay_time: 7.422423180143981
pressure: 1.5282935455349247
total_envstep_count: 78648
total_train_sample_count: 78648
total_episode_count: 678
total_duration: 4880.269054402105
[2024-12-26 02:48:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.038872341693498
avg_train_sample_per_sec: 17.038872341693498
avg_episode_per_sec: 0.14688683053184048
collect_time: 40.84777361098677
reward_mean: -186.2546685340803
reward_std: 9.856689381564617
reward_max: -173.11554621848737
reward_min: -203.6295518207283
queue_len: 0.12351105340456253
wait_time: 1.299537387899457
delay_time: 7.406705382098419
pressure: 1.5667550839964635
total_envstep_count: 79344
total_train_sample_count: 79344
total_episode_count: 684
total_duration: 4921.116828013092
[2024-12-26 02:49:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.800118764224095
avg_train_sample_per_sec: 16.800118764224095
avg_episode_per_sec: 0.14482861003641462
collect_time: 41.428278559681026
reward_mean: -183.21825396825398
reward_std: 6.742551999127378
reward_max: -175.87885154061618
reward_min: -195.4173669467787
queue_len: 0.12149751589406761
wait_time: 1.279667094512429
delay_time: 7.237837165610738
pressure: 1.505636604774536
total_envstep_count: 80040
total_train_sample_count: 80040
total_episode_count: 690
total_duration: 4962.545106572773
[2024-12-26 02:50:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.862608123244787
avg_train_sample_per_sec: 16.862608123244787
avg_episode_per_sec: 0.14536731140728265
collect_time: 41.27475387633406
reward_mean: -187.94035947712416
reward_std: 8.061073268051683
reward_max: -175.0077030812325
reward_min: -197.97549019607845
queue_len: 0.12462888559490994
wait_time: 1.2828366205014279
delay_time: 7.47969898730793
pressure: 1.5699602122015914
total_envstep_count: 80736
total_train_sample_count: 80736
total_episode_count: 696
total_duration: 5003.819860449107
[2024-12-26 02:50:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.821735334553974
avg_train_sample_per_sec: 16.821735334553974
avg_episode_per_sec: 0.1450149597806377
collect_time: 41.37504164450429
reward_mean: -180.14764239028946
reward_std: 10.833026701189366
reward_max: -169.38935574229689
reward_min: -199.8718487394959
queue_len: 0.11946130131982059
wait_time: 1.2218485537451056
delay_time: 7.476707182008224
pressure: 1.4820954907161805
total_envstep_count: 81432
total_train_sample_count: 81432
total_episode_count: 702
total_duration: 5045.194902093612
[2024-12-26 02:51:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.608854634646917
avg_train_sample_per_sec: 16.608854634646917
avg_episode_per_sec: 0.1431797813331631
collect_time: 41.905358034027735
reward_mean: -192.0068860877685
reward_std: 8.722562554821728
reward_max: -179.91946778711485
reward_min: -207.83053221288515
queue_len: 0.12732552127836103
wait_time: 1.3108136158972874
delay_time: 7.7817759127549735
pressure: 1.595159151193634
total_envstep_count: 82128
total_train_sample_count: 82128
total_episode_count: 708
total_duration: 5087.10026012764
[2024-12-26 02:52:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.739353221731385
avg_train_sample_per_sec: 16.739353221731385
avg_episode_per_sec: 0.14430476915285675
collect_time: 41.578667394176136
reward_mean: -194.69922969187678
reward_std: 7.584072956950876
reward_max: -181.42366946778714
reward_min: -205.9404761904762
queue_len: 0.12911089502113843
wait_time: 1.3172203120859305
delay_time: 8.129489602400955
pressure: 1.6161582670203358
total_envstep_count: 82824
total_train_sample_count: 82824
total_episode_count: 714
total_duration: 5128.678927521816
[2024-12-26 02:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.795227888650665
avg_train_sample_per_sec: 16.795227888650665
avg_episode_per_sec: 0.144786447315954
collect_time: 41.44034273392148
reward_mean: -186.046802054155
reward_std: 10.768783877253973
reward_max: -167.62745098039218
reward_min: -204.68347338935575
queue_len: 0.12337321091124337
wait_time: 1.2834323384526225
delay_time: 7.503588962968649
pressure: 1.528846153846154
total_envstep_count: 83520
total_train_sample_count: 83520
total_episode_count: 720
total_duration: 5170.119270255737
[2024-12-26 02:53:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.088589952771482
avg_train_sample_per_sec: 17.088589952771482
avg_episode_per_sec: 0.14731543062734034
collect_time: 40.72893093716726
reward_mean: -186.58426704014937
reward_std: 11.395094697853587
reward_max: -168.21708683473383
reward_min: -200.7920168067226
queue_len: 0.12372962005314946
wait_time: 1.2851756861011423
delay_time: 7.522817503562458
pressure: 1.5550397877984083
total_envstep_count: 84216
total_train_sample_count: 84216
total_episode_count: 726
total_duration: 5210.8482011929045
[2024-12-26 02:54:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.91070473662632
avg_train_sample_per_sec: 16.91070473662632
avg_episode_per_sec: 0.14578193738470965
collect_time: 41.15736220576055
reward_mean: -182.656045751634
reward_std: 6.032247739403483
reward_max: -176.23529411764704
reward_min: -195.19257703081232
queue_len: 0.12112469877429309
wait_time: 1.2422240890166854
delay_time: 7.4529601143642585
pressure: 1.4958001768346596
total_envstep_count: 84912
total_train_sample_count: 84912
total_episode_count: 732
total_duration: 5252.005563398665
[2024-12-26 02:55:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73966877838509
avg_train_sample_per_sec: 16.73966877838509
avg_episode_per_sec: 0.14430748946883698
collect_time: 41.577883601777245
reward_mean: -184.79435107376284
reward_std: 10.422862077034713
reward_max: -174.23879551820735
reward_min: -204.88655462184875
queue_len: 0.12254267312583743
wait_time: 1.2724780009262766
delay_time: 7.502411705334943
pressure: 1.5111626878868256
total_envstep_count: 85608
total_train_sample_count: 85608
total_episode_count: 738
total_duration: 5293.583447000442
[2024-12-26 02:55:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.934061201984992
avg_train_sample_per_sec: 16.934061201984992
avg_episode_per_sec: 0.14598328622400855
collect_time: 41.100595521552485
reward_mean: -180.62394957983193
reward_std: 7.761777949347851
reward_max: -172.2079831932773
reward_min: -190.24649859943972
queue_len: 0.11977715489378776
wait_time: 1.2291091613480052
delay_time: 7.209413863354976
pressure: 1.4755747126436782
total_envstep_count: 86304
total_train_sample_count: 86304
total_episode_count: 744
total_duration: 5334.684042521994
[2024-12-26 02:56:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.84907964523687
avg_train_sample_per_sec: 16.84907964523687
avg_episode_per_sec: 0.14525068659686957
collect_time: 41.30789423841052
reward_mean: -194.9433940242764
reward_std: 16.776417629929426
reward_max: -172.75560224089637
reward_min: -227.22619047619045
queue_len: 0.12927280770840607
wait_time: 1.3100096249817348
delay_time: 8.027391966332175
pressure: 1.5941644562334218
total_envstep_count: 87000
total_train_sample_count: 87000
total_episode_count: 750
total_duration: 5375.991936760405
[2024-12-26 02:57:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.10352389300899
avg_train_sample_per_sec: 17.10352389300899
avg_episode_per_sec: 0.14744417149145683
collect_time: 40.69336847504786
reward_mean: -181.94164332399623
reward_std: 10.486378270150034
reward_max: -166.1281512605042
reward_min: -198.32142857142858
queue_len: 0.12065095711140333
wait_time: 1.235453553658422
delay_time: 7.3433223631907
pressure: 1.5079575596816976
total_envstep_count: 87696
total_train_sample_count: 87696
total_episode_count: 756
total_duration: 5416.685305235453
[2024-12-26 02:57:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85158380212823
avg_train_sample_per_sec: 16.85158380212823
avg_episode_per_sec: 0.14527227415627783
collect_time: 41.30175585704297
reward_mean: -180.21125116713355
reward_std: 7.9007788611805
reward_max: -169.623949579832
reward_min: -189.92296918767505
queue_len: 0.11950348220632197
wait_time: 1.2290219359184875
delay_time: 7.266186434911709
pressure: 1.4786693191865605
total_envstep_count: 88392
total_train_sample_count: 88392
total_episode_count: 762
total_duration: 5457.987061092495
[2024-12-26 02:58:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.022005071691733
avg_train_sample_per_sec: 17.022005071691733
avg_episode_per_sec: 0.1467414230318253
collect_time: 40.88825006623194
reward_mean: -172.53758169934636
reward_std: 4.636502913485199
reward_max: -166.57773109243692
reward_min: -181.13515406162458
queue_len: 0.11441484197569389
wait_time: 1.1723121719952347
delay_time: 7.075955937334318
pressure: 1.4121352785145886
total_envstep_count: 89088
total_train_sample_count: 89088
total_episode_count: 768
total_duration: 5498.8753111587275
[2024-12-26 02:59:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.786425592753574
avg_train_sample_per_sec: 16.786425592753574
avg_episode_per_sec: 0.14471056545477218
collect_time: 41.4620728012789
reward_mean: -177.233893557423
reward_std: 3.738931466351137
reward_max: -170.74019607843138
reward_min: -181.98949579831933
queue_len: 0.11752910713356962
wait_time: 1.1968232916508779
delay_time: 7.197074180049609
pressure: 1.4450707338638376
total_envstep_count: 89784
total_train_sample_count: 89784
total_episode_count: 774
total_duration: 5540.337383960006
[2024-12-26 02:59:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.883676578758294
avg_train_sample_per_sec: 16.883676578758294
avg_episode_per_sec: 0.14554893602377839
collect_time: 41.223248784311124
reward_mean: -179.77917833800188
reward_std: 4.2080684338846845
reward_max: -175.1596638655463
reward_min: -186.79481792717093
queue_len: 0.11921696176260073
wait_time: 1.2153959616561039
delay_time: 7.378289032251913
pressure: 1.4786693191865605
total_envstep_count: 90480
total_train_sample_count: 90480
total_episode_count: 780
total_duration: 5581.560632744317
[2024-12-26 03:00:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.04269722363998
avg_train_sample_per_sec: 17.04269722363998
avg_episode_per_sec: 0.14691980365206878
collect_time: 40.83860617054067
reward_mean: -170.45261437908493
reward_std: 7.569776427308821
reward_max: -161.38235294117646
reward_min: -184.88655462184863
queue_len: 0.1130322376519131
wait_time: 1.1430824429683457
delay_time: 7.052601911647634
pressure: 1.379973474801061
total_envstep_count: 91176
total_train_sample_count: 91176
total_episode_count: 786
total_duration: 5622.399238914858
[2024-12-26 03:01:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17523268356079
avg_train_sample_per_sec: 17.17523268356079
avg_episode_per_sec: 0.14806235072035162
collect_time: 40.523468463176854
reward_mean: -175.14927637721757
reward_std: 8.404718488845214
reward_max: -160.48949579831933
reward_min: -185.61484593837537
queue_len: 0.11614673499815488
wait_time: 1.1808017526197039
delay_time: 7.28412542640863
pressure: 1.4101458885941645
total_envstep_count: 91872
total_train_sample_count: 91872
total_episode_count: 792
total_duration: 5662.922707378035
[2024-12-26 03:01:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.128468800068198
avg_train_sample_per_sec: 17.128468800068198
avg_episode_per_sec: 0.14765921379369137
collect_time: 40.6341050168611
reward_mean: -174.99953314659197
reward_std: 3.996218446217575
reward_max: -170.4775910364146
reward_min: -181.94747899159665
queue_len: 0.1160474357736021
wait_time: 1.1795245618141152
delay_time: 7.163660613139014
pressure: 1.4207559681697612
total_envstep_count: 92568
total_train_sample_count: 92568
total_episode_count: 798
total_duration: 5703.556812394896
[2024-12-26 03:02:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95904823062611
avg_train_sample_per_sec: 16.95904823062611
avg_episode_per_sec: 0.14619869164332852
collect_time: 41.040038953548304
reward_mean: -180.27707749766572
reward_std: 6.142440644440891
reward_max: -171.52450980392155
reward_min: -187.36484593837534
queue_len: 0.11954713361914171
wait_time: 1.208673102309005
delay_time: 7.537753653462546
pressure: 1.4614279398762158
total_envstep_count: 93264
total_train_sample_count: 93264
total_episode_count: 804
total_duration: 5744.596851348444
[2024-12-26 03:03:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.967347234413886
avg_train_sample_per_sec: 16.967347234413886
avg_episode_per_sec: 0.14627023477943005
collect_time: 41.01996560713649
reward_mean: -173.80065359477123
reward_std: 7.462969106451568
reward_max: -166.01260504201682
reward_min: -189.63375350140052
queue_len: 0.11525242280820375
wait_time: 1.1728789437967937
delay_time: 7.201028458838386
pressure: 1.4085985853227232
total_envstep_count: 93960
total_train_sample_count: 93960
total_episode_count: 810
total_duration: 5785.61681695558
[2024-12-26 03:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.073984731524188
avg_train_sample_per_sec: 17.073984731524188
avg_episode_per_sec: 0.14718952354762233
collect_time: 40.76377078602836
reward_mean: -182.08776844070962
reward_std: 11.410713232193784
reward_max: -169.2436974789916
reward_min: -201.93697478991595
queue_len: 0.12074785705617348
wait_time: 1.222646275574775
delay_time: 7.607271143963941
pressure: 1.4586648983200707
total_envstep_count: 94656
total_train_sample_count: 94656
total_episode_count: 816
total_duration: 5826.380587741609
[2024-12-26 03:04:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93220349637325
avg_train_sample_per_sec: 16.93220349637325
avg_episode_per_sec: 0.14596727152045907
collect_time: 41.10510484645887
reward_mean: -177.3849206349207
reward_std: 4.837422585144335
reward_max: -169.01400560224087
reward_min: -185.37675070028018
queue_len: 0.11762925771546466
wait_time: 1.1981279580797837
delay_time: 7.420180405320302
pressure: 1.4227453580901859
total_envstep_count: 95352
total_train_sample_count: 95352
total_episode_count: 822
total_duration: 5867.485692588068
[2024-12-26 03:05:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.82516722818042
avg_train_sample_per_sec: 16.82516722818042
avg_episode_per_sec: 0.14504454507052084
collect_time: 41.366602219220255
reward_mean: -182.69841269841268
reward_std: 5.289763493145738
reward_max: -179.1148459383753
reward_min: -194.38795518207283
queue_len: 0.12115279356658666
wait_time: 1.2276600737554084
delay_time: 7.659147690192557
pressure: 1.4748010610079574
total_envstep_count: 96048
total_train_sample_count: 96048
total_episode_count: 828
total_duration: 5908.852294807288
[2024-12-26 03:06:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85615734623482
avg_train_sample_per_sec: 16.85615734623482
avg_episode_per_sec: 0.145311701260645
collect_time: 41.29054954244755
reward_mean: -174.67203548085902
reward_std: 6.793049623511423
reward_max: -165.3648459383754
reward_min: -188.07913165266115
queue_len: 0.11583026225521158
wait_time: 1.1617958965195274
delay_time: 7.348372973679621
pressure: 1.3803050397877985
total_envstep_count: 96744
total_train_sample_count: 96744
total_episode_count: 834
total_duration: 5950.142844349735
[2024-12-26 03:06:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8742502045501
avg_train_sample_per_sec: 16.8742502045501
avg_episode_per_sec: 0.14546767417715606
collect_time: 41.24627711234987
reward_mean: -187.18475723622782
reward_std: 9.628544527969176
reward_max: -176.52170868347338
reward_min: -200.45168067226894
queue_len: 0.12412782310094685
wait_time: 1.2456734019867894
delay_time: 8.088341223309923
pressure: 1.4881741821396994
total_envstep_count: 97440
total_train_sample_count: 97440
total_episode_count: 840
total_duration: 5991.389121462085
[2024-12-26 03:07:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.788585389477365
avg_train_sample_per_sec: 16.788585389477365
avg_episode_per_sec: 0.14472918439204624
collect_time: 41.456738840917126
reward_mean: -182.40406162464987
reward_std: 5.799975786410071
reward_max: -176.56092436974788
reward_min: -192.27310924369743
queue_len: 0.12095760054685005
wait_time: 1.222948894411876
delay_time: 7.604753000974642
pressure: 1.458885941644562
total_envstep_count: 98136
total_train_sample_count: 98136
total_episode_count: 846
total_duration: 6032.845860303002
[2024-12-26 03:08:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.014566771774337
avg_train_sample_per_sec: 17.014566771774337
avg_episode_per_sec: 0.14667729975667532
collect_time: 40.906125282872466
reward_mean: -181.16258169934642
reward_std: 11.962168335219369
reward_max: -166.36204481792709
reward_min: -199.2044817927171
queue_len: 0.12013433799691405
wait_time: 1.2269309248898501
delay_time: 7.512962696871649
pressure: 1.4581122900088417
total_envstep_count: 98832
total_train_sample_count: 98832
total_episode_count: 852
total_duration: 6073.7519855858745
[2024-12-26 03:08:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95347371863573
avg_train_sample_per_sec: 16.95347371863573
avg_episode_per_sec: 0.14615063550548044
collect_time: 41.05353342630528
reward_mean: -176.06827731092437
reward_std: 6.860958064340752
reward_max: -169.50350140056025
reward_min: -186.86134453781506
queue_len: 0.1167561520629472
wait_time: 1.1829864903521092
delay_time: 7.299963596923896
pressure: 1.392683465959328
total_envstep_count: 99528
total_train_sample_count: 99528
total_episode_count: 858
total_duration: 6114.8055190121795
[2024-12-26 03:09:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.955664808450138
avg_train_sample_per_sec: 16.955664808450138
avg_episode_per_sec: 0.14616952421077703
collect_time: 41.048228297904124
reward_mean: -181.41713352007469
reward_std: 11.279690633249656
reward_max: -171.07352941176478
reward_min: -205.89915966386553
queue_len: 0.12030313893904158
wait_time: 1.220140189143739
delay_time: 7.699272265253019
pressure: 1.4763483642793986
total_envstep_count: 100224
total_train_sample_count: 100224
total_episode_count: 864
total_duration: 6155.853747310083
[2024-12-26 03:10:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.031884044908303
avg_train_sample_per_sec: 17.031884044908303
avg_episode_per_sec: 0.1468265865940371
collect_time: 40.864533727733416
reward_mean: -175.63958916900097
reward_std: 6.945343055575959
reward_max: -167.71708683473383
reward_min: -187.37394957983201
queue_len: 0.11647187610676456
wait_time: 1.190099271361949
delay_time: 7.2691185970715
pressure: 1.4257294429708223
total_envstep_count: 100920
total_train_sample_count: 100920
total_episode_count: 870
total_duration: 6196.718281037816
[2024-12-26 03:11:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.751504770956824
avg_train_sample_per_sec: 16.751504770956824
avg_episode_per_sec: 0.14440952388755884
collect_time: 41.54850620982424
reward_mean: -180.7721755368814
reward_std: 6.450639829857177
reward_max: -171.14495798319334
reward_min: -187.88865546218494
queue_len: 0.11987544796875427
wait_time: 1.224616703445304
delay_time: 7.472506339047629
pressure: 1.460322723253758
total_envstep_count: 101616
total_train_sample_count: 101616
total_episode_count: 876
total_duration: 6238.26678724764
[2024-12-26 03:11:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.88365613795347
avg_train_sample_per_sec: 16.88365613795347
avg_episode_per_sec: 0.14554875980994372
collect_time: 41.223298692718146
reward_mean: -179.49906629318397
reward_std: 6.986264294121971
reward_max: -171.19957983193277
reward_min: -192.42507002801125
queue_len: 0.11903121106975063
wait_time: 1.2073545045781355
delay_time: 7.413968607532748
pressure: 1.467396109637489
total_envstep_count: 102312
total_train_sample_count: 102312
total_episode_count: 882
total_duration: 6279.490085940359
[2024-12-26 03:12:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.938459478033224
avg_train_sample_per_sec: 16.938459478033224
avg_episode_per_sec: 0.14602120239683813
collect_time: 41.08992325439118
reward_mean: -181.73844537815125
reward_std: 8.482197973609697
reward_max: -170.6428571428571
reward_min: -195.32633053221286
queue_len: 0.12051621046296503
wait_time: 1.224208748486132
delay_time: 7.477887774047162
pressure: 1.473474801061008
total_envstep_count: 103008
total_train_sample_count: 103008
total_episode_count: 888
total_duration: 6320.58000919475
[2024-12-26 03:13:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93527753370749
avg_train_sample_per_sec: 16.93527753370749
avg_episode_per_sec: 0.14599377184230597
collect_time: 41.09764357948676
reward_mean: -177.32364612511674
reward_std: 6.593602336764121
reward_max: -164.66806722689077
reward_min: -183.87885154061627
queue_len: 0.11758862475140365
wait_time: 1.1949147032818432
delay_time: 7.382722425343985
pressure: 1.4167771883289129
total_envstep_count: 103704
total_train_sample_count: 103704
total_episode_count: 894
total_duration: 6361.677652774237
[2024-12-26 03:13:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.92345571917788
avg_train_sample_per_sec: 16.92345571917788
avg_episode_per_sec: 0.14589185964808518
collect_time: 41.126352179436005
reward_mean: -175.7983193277311
reward_std: 9.348995247535964
reward_max: -166.45588235294125
reward_min: -191.9908963585434
queue_len: 0.11657713483271294
wait_time: 1.177386571339411
delay_time: 7.352646333129193
pressure: 1.4202033598585324
total_envstep_count: 104400
total_train_sample_count: 104400
total_episode_count: 900
total_duration: 6402.804004953673
[2024-12-26 03:14:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16069895936642
avg_train_sample_per_sec: 17.16069895936642
avg_episode_per_sec: 0.14793705999453813
collect_time: 40.557788563741376
reward_mean: -171.53396358543412
reward_std: 7.278305197040733
reward_max: -163.5413165266106
reward_min: -181.88165266106446
queue_len: 0.11374931272243644
wait_time: 1.165789149435194
delay_time: 7.016185174203208
pressure: 1.3853890362511052
total_envstep_count: 105096
total_train_sample_count: 105096
total_episode_count: 906
total_duration: 6443.361793517414
[2024-12-26 03:15:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.058896988713823
avg_train_sample_per_sec: 17.058896988713823
avg_episode_per_sec: 0.1470594567992571
collect_time: 40.79982430637069
reward_mean: -174.87021475256768
reward_std: 4.192428317910412
reward_max: -167.22198879551812
reward_min: -180.65476190476195
queue_len: 0.11596168087040298
wait_time: 1.205818268952143
delay_time: 7.20420573034481
pressure: 1.4360079575596814
total_envstep_count: 105792
total_train_sample_count: 105792
total_episode_count: 912
total_duration: 6484.161617823785
[2024-12-26 03:15:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.123382223327233
avg_train_sample_per_sec: 17.123382223327233
avg_episode_per_sec: 0.14761536399420028
collect_time: 40.646175558228045
reward_mean: -176.21895424836597
reward_std: 4.472641247325843
reward_max: -170.24719887955186
reward_min: -181.91386554621846
queue_len: 0.11685607045647611
wait_time: 1.2055940523866486
delay_time: 7.172709253836623
pressure: 1.4252873563218393
total_envstep_count: 106488
total_train_sample_count: 106488
total_episode_count: 918
total_duration: 6524.807793382012
[2024-12-26 03:16:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08712142700882
avg_train_sample_per_sec: 17.08712142700882
avg_episode_per_sec: 0.14730277092248983
collect_time: 40.7324313210454
reward_mean: -177.7872315592904
reward_std: 7.731980363332802
reward_max: -170.91876750700285
reward_min: -194.1435574229693
queue_len: 0.11789604214807055
wait_time: 1.2103693931153363
delay_time: 7.285453133461684
pressure: 1.445181255526083
total_envstep_count: 107184
total_train_sample_count: 107184
total_episode_count: 924
total_duration: 6565.540224703058
[2024-12-26 03:17:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.922179226693963
avg_train_sample_per_sec: 16.922179226693963
avg_episode_per_sec: 0.14588085540253418
collect_time: 41.12945446778461
reward_mean: -175.94934640522877
reward_std: 8.809675875750965
reward_max: -165.7514005602241
reward_min: -191.6778711484594
queue_len: 0.11667728541460792
wait_time: 1.1774624195389918
delay_time: 7.317194611535547
pressure: 1.4206454465075156
total_envstep_count: 107880
total_train_sample_count: 107880
total_episode_count: 930
total_duration: 6606.669679170843
[2024-12-26 03:17:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.080997813110546
avg_train_sample_per_sec: 17.080997813110546
avg_episode_per_sec: 0.1472499811475047
collect_time: 40.74703407934308
reward_mean: -179.2219887955182
reward_std: 6.234695801932282
reward_max: -170.14355742296908
reward_min: -188.08893557422974
queue_len: 0.11884747267607308
wait_time: 1.213245897386364
delay_time: 7.487907534126211
pressure: 1.4491600353669318
total_envstep_count: 108576
total_train_sample_count: 108576
total_episode_count: 936
total_duration: 6647.416713250186
[2024-12-26 03:18:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.162476869906154
avg_train_sample_per_sec: 17.162476869906154
avg_episode_per_sec: 0.14795238680953582
collect_time: 40.55358706530369
reward_mean: -181.29610177404297
reward_std: 4.648640716979204
reward_max: -175.3697478991597
reward_min: -188.95028011204482
queue_len: 0.12022287916050593
wait_time: 1.2136325684119804
delay_time: 7.762788545577648
pressure: 1.457449160035367
total_envstep_count: 109272
total_train_sample_count: 109272
total_episode_count: 942
total_duration: 6687.97030031549
[2024-12-26 03:19:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.99257367458929
avg_train_sample_per_sec: 16.99257367458929
avg_episode_per_sec: 0.146487704091287
collect_time: 40.95906913976186
reward_mean: -176.93779178338002
reward_std: 2.9894380676216077
reward_max: -173.77801120448174
reward_min: -182.71358543417364
queue_len: 0.11733275317200266
wait_time: 1.1856636996089327
delay_time: 7.3708684592405005
pressure: 1.43578691423519
total_envstep_count: 109968
total_train_sample_count: 109968
total_episode_count: 948
total_duration: 6728.929369455252
[2024-12-26 03:20:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.893701875109027
avg_train_sample_per_sec: 16.893701875109027
avg_episode_per_sec: 0.14563536099231922
collect_time: 41.198785508668045
reward_mean: -177.62044817927176
reward_std: 5.9639708800340925
reward_max: -166.07983193277312
reward_min: -185.09103641456585
queue_len: 0.11778544308970275
wait_time: 1.2022904763143099
delay_time: 7.376597067731101
pressure: 1.4416445623342173
total_envstep_count: 110664
total_train_sample_count: 110664
total_episode_count: 954
total_duration: 6770.12815496392
[2024-12-26 03:20:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.007358711637618
avg_train_sample_per_sec: 17.007358711637618
avg_episode_per_sec: 0.14661516130722085
collect_time: 40.923462120179096
reward_mean: -185.06897759103643
reward_std: 19.33065062452641
reward_max: -168.05532212885157
reward_min: -226.84173669467776
queue_len: 0.12272478620095255
wait_time: 1.2499180375067802
delay_time: 7.694281748415995
pressure: 1.4686118479221928
total_envstep_count: 111360
total_train_sample_count: 111360
total_episode_count: 960
total_duration: 6811.051617084099
[2024-12-26 03:21:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.00156288066099
avg_train_sample_per_sec: 17.00156288066099
avg_episode_per_sec: 0.1465651972470775
collect_time: 40.93741292406059
reward_mean: -172.6189309056956
reward_std: 9.656733279725833
reward_max: -160.64215686274508
reward_min: -186.50910364145656
queue_len: 0.11446878707274244
wait_time: 1.1585968826080388
delay_time: 7.152080935543651
pressure: 1.3800839964633067
total_envstep_count: 112056
total_train_sample_count: 112056
total_episode_count: 966
total_duration: 6851.98903000816
[2024-12-26 03:22:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.839122209505753
avg_train_sample_per_sec: 16.839122209505753
avg_episode_per_sec: 0.1451648466336703
collect_time: 41.33232073148713
reward_mean: -179.13830532212887
reward_std: 9.907863331917529
reward_max: -165.53991596638653
reward_min: -193.2275910364146
queue_len: 0.11879197965658413
wait_time: 1.2036600006934692
delay_time: 7.473900921909375
pressure: 1.4376657824933687
total_envstep_count: 112752
total_train_sample_count: 112752
total_episode_count: 972
total_duration: 6893.321350739647
[2024-12-26 03:22:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.14936715176686
avg_train_sample_per_sec: 17.14936715176686
avg_episode_per_sec: 0.1478393719979902
collect_time: 40.58458798162081
reward_mean: -171.77310924369746
reward_std: 7.9026418483272405
reward_max: -163.046218487395
reward_min: -185.90756302521007
queue_len: 0.11390789737645722
wait_time: 1.1705679729893728
delay_time: 7.03828395803776
pressure: 1.389809902740937
total_envstep_count: 113448
total_train_sample_count: 113448
total_episode_count: 978
total_duration: 6933.905938721267
[2024-12-26 03:23:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.03915420287845
avg_train_sample_per_sec: 17.03915420287845
avg_episode_per_sec: 0.1468892603696418
collect_time: 40.847097908323626
reward_mean: -178.37733426704017
reward_std: 8.992047004719504
reward_max: -165.25560224089637
reward_min: -192.4705882352942
queue_len: 0.11828735694100806
wait_time: 1.2116966592118723
delay_time: 7.291597966987898
pressure: 1.450154730327144
total_envstep_count: 114144
total_train_sample_count: 114144
total_episode_count: 984
total_duration: 6974.753036629591
[2024-12-26 03:24:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08887639132699
avg_train_sample_per_sec: 17.08887639132699
avg_episode_per_sec: 0.1473178999252327
collect_time: 40.72824825119786
reward_mean: -172.0652427637721
reward_std: 10.972978403959612
reward_max: -156.6750700280112
reward_min: -186.91456582633043
queue_len: 0.1141016198698754
wait_time: 1.1552570851505946
delay_time: 7.169992244227675
pressure: 1.3878205128205128
total_envstep_count: 114840
total_train_sample_count: 114840
total_episode_count: 990
total_duration: 7015.48128488079
[2024-12-26 03:24:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.840012776602187
avg_train_sample_per_sec: 16.840012776602187
avg_episode_per_sec: 0.14517252393622576
collect_time: 41.330134913379325
reward_mean: -174.87336601307186
reward_std: 7.038415139687282
reward_max: -166.10364145658258
reward_min: -184.58613445378148
queue_len: 0.11596377056569752
wait_time: 1.164875720403104
delay_time: 7.418222629241985
pressure: 1.4063881520778072
total_envstep_count: 115536
total_train_sample_count: 115536
total_episode_count: 996
total_duration: 7056.811419794169
[2024-12-26 03:25:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.110493346163935
avg_train_sample_per_sec: 17.110493346163935
avg_episode_per_sec: 0.14750425298417183
collect_time: 40.676793235540394
reward_mean: -172.05333800186736
reward_std: 6.684153327646648
reward_max: -162.09173669467785
reward_min: -179.9390756302521
queue_len: 0.11409372546542929
wait_time: 1.1525165658659573
delay_time: 7.128415482785715
pressure: 1.3740053050397878
total_envstep_count: 116232
total_train_sample_count: 116232
total_episode_count: 1002
total_duration: 7097.488213029709
[2024-12-26 03:26:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.14932192609176
avg_train_sample_per_sec: 17.14932192609176
avg_episode_per_sec: 0.1478389821214807
collect_time: 40.58469501007348
reward_mean: -177.20039682539684
reward_std: 9.028620737009634
reward_max: -158.61904761904762
reward_min: -184.57843137254903
queue_len: 0.1175068944465496
wait_time: 1.1971598099894245
delay_time: 7.406631539799953
pressure: 1.4362290008841734
total_envstep_count: 116928
total_train_sample_count: 116928
total_episode_count: 1008
total_duration: 7138.072908039782
[2024-12-26 03:26:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.94763019387997
avg_train_sample_per_sec: 16.94763019387997
avg_episode_per_sec: 0.1461002602920687
collect_time: 41.06768864070066
reward_mean: -175.94619514472456
reward_std: 7.3746385378941275
reward_max: -165.20658263305322
reward_min: -185.86344537815123
queue_len: 0.11667519571931338
wait_time: 1.1871165022153864
delay_time: 7.415848389536376
pressure: 1.4350132625994696
total_envstep_count: 117624
total_train_sample_count: 117624
total_episode_count: 1014
total_duration: 7179.140596680483
[2024-12-26 03:27:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.925875738379126
avg_train_sample_per_sec: 16.925875738379126
avg_episode_per_sec: 0.1459127218825787
collect_time: 41.120472036896274
reward_mean: -175.08426704014937
reward_std: 2.753593940543134
reward_max: -170.43767507002795
reward_min: -179.19817927170868
queue_len: 0.11610362535818926
wait_time: 1.186214063432623
delay_time: 7.290805409807354
pressure: 1.4110300618921308
total_envstep_count: 118320
total_train_sample_count: 118320
total_episode_count: 1020
total_duration: 7220.261068717379
[2024-12-26 03:28:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.11600968432522
avg_train_sample_per_sec: 17.11600968432522
avg_episode_per_sec: 0.14755180762349326
collect_time: 40.66368346574344
reward_mean: -172.00688608776844
reward_std: 6.2255130059042525
reward_max: -163.73179271708682
reward_min: -180.5091036414566
queue_len: 0.11406292180886503
wait_time: 1.1656596657230531
delay_time: 7.057782337188457
pressure: 1.3917992926613616
total_envstep_count: 119016
total_train_sample_count: 119016
total_episode_count: 1026
total_duration: 7260.924752183123
[2024-12-26 03:29:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.021866307703803
avg_train_sample_per_sec: 17.021866307703803
avg_episode_per_sec: 0.14674022679055002
collect_time: 40.888583391411224
reward_mean: -167.22724089635858
reward_std: 4.206984431685607
reward_max: -159.11414565826334
reward_min: -172.2289915966387
queue_len: 0.11089339581986642
wait_time: 1.1246595344592303
delay_time: 7.026129116886964
pressure: 1.3426171529619806
total_envstep_count: 119712
total_train_sample_count: 119712
total_episode_count: 1032
total_duration: 7301.813335574534
[2024-12-26 03:29:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16880188957378
avg_train_sample_per_sec: 17.16880188957378
avg_episode_per_sec: 0.14800691284115328
collect_time: 40.53864704575949
reward_mean: -169.41573295985066
reward_std: 8.771883021883413
reward_max: -159.0364145658263
reward_min: -184.77591036414574
queue_len: 0.11234465050387972
wait_time: 1.1402927771462252
delay_time: 7.020782066716991
pressure: 1.357869142351901
total_envstep_count: 120408
total_train_sample_count: 120408
total_episode_count: 1038
total_duration: 7342.351982620294
[2024-12-26 03:30:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.296173234035624
avg_train_sample_per_sec: 17.296173234035624
avg_episode_per_sec: 0.1491049416727209
collect_time: 40.240115000143646
reward_mean: -171.6858076563959
reward_std: 1.986669363076134
reward_max: -167.44817927170868
reward_min: -173.406162464986
queue_len: 0.11385000507718562
wait_time: 1.1461470198158838
delay_time: 7.113887495993462
pressure: 1.3787577365163572
total_envstep_count: 121104
total_train_sample_count: 121104
total_episode_count: 1044
total_duration: 7382.592097620437
[2024-12-26 03:31:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.298868524216644
avg_train_sample_per_sec: 17.298868524216644
avg_episode_per_sec: 0.1491281769329021
collect_time: 40.23384529604762
reward_mean: -173.98494397759103
reward_std: 5.780903796793713
reward_max: -166.77661064425772
reward_min: -181.35084033613455
queue_len: 0.1153746312848747
wait_time: 1.1725477657906664
delay_time: 7.299390722400577
pressure: 1.3913572060123782
total_envstep_count: 121800
total_train_sample_count: 121800
total_episode_count: 1050
total_duration: 7422.825942916485
[2024-12-26 03:31:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.024229972379324
avg_train_sample_per_sec: 17.024229972379324
avg_episode_per_sec: 0.1467606032101666
collect_time: 40.882906371049586
reward_mean: -169.29750233426702
reward_std: 7.755055438447654
reward_max: -159.81582633053222
reward_min: -179.96778711484592
queue_len: 0.11226624823227259
wait_time: 1.1221270559505852
delay_time: 7.135442866036917
pressure: 1.3500221043324492
total_envstep_count: 122496
total_train_sample_count: 122496
total_episode_count: 1056
total_duration: 7463.708849287535
[2024-12-26 03:32:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.105179730263448
avg_train_sample_per_sec: 17.105179730263448
avg_episode_per_sec: 0.14745844595054697
collect_time: 40.68942922409623
reward_mean: -173.53699813258638
reward_std: 9.443835635314146
reward_max: -160.37535014005604
reward_min: -188.6057422969188
queue_len: 0.11507758496855859
wait_time: 1.1668633302127216
delay_time: 7.210829888748144
pressure: 1.390030946065429
total_envstep_count: 123192
total_train_sample_count: 123192
total_episode_count: 1062
total_duration: 7504.39827851163
[2024-12-26 03:33:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.078172133019912
avg_train_sample_per_sec: 17.078172133019912
avg_episode_per_sec: 0.14722562183637855
collect_time: 40.7537759063989
reward_mean: -172.41141456582633
reward_std: 10.30456464396821
reward_max: -154.08963585434174
reward_min: -183.5938375350141
queue_len: 0.11433117676778932
wait_time: 1.1677563266685984
delay_time: 7.2153928533498854
pressure: 1.3908045977011494
total_envstep_count: 123888
total_train_sample_count: 123888
total_episode_count: 1068
total_duration: 7545.152054418029
[2024-12-26 03:33:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.066150663535385
avg_train_sample_per_sec: 17.066150663535385
avg_episode_per_sec: 0.14712198847875332
collect_time: 40.78248304036818
reward_mean: -171.99334733893556
reward_std: 4.944261922871102
reward_max: -166.01190476190473
reward_min: -179.45658263305313
queue_len: 0.11405394385871058
wait_time: 1.1687353876121624
delay_time: 7.280884120731474
pressure: 1.3775419982316535
total_envstep_count: 124584
total_train_sample_count: 124584
total_episode_count: 1074
total_duration: 7585.934537458397
[2024-12-26 03:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40094521134336
avg_train_sample_per_sec: 17.40094521134336
avg_episode_per_sec: 0.15000814837364965
collect_time: 39.997827218391
reward_mean: -168.99603174603178
reward_std: 8.361398658487982
reward_max: -154.48249299719896
reward_min: -177.99999999999997
queue_len: 0.11206633404909268
wait_time: 1.1324968205673074
delay_time: 7.015203929837383
pressure: 1.3660477453580901
total_envstep_count: 125280
total_train_sample_count: 125280
total_episode_count: 1080
total_duration: 7625.932364676788
[2024-12-26 03:35:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.063047784205747
avg_train_sample_per_sec: 17.063047784205747
avg_episode_per_sec: 0.14709523951901507
collect_time: 40.78989924908058
reward_mean: -167.53314659197008
reward_std: 8.234973989990147
reward_max: -159.0511204481792
reward_min: -181.80532212885151
queue_len: 0.11109625105568309
wait_time: 1.129743221338049
delay_time: 7.144450570298399
pressure: 1.3608532272325375
total_envstep_count: 125976
total_train_sample_count: 125976
total_episode_count: 1086
total_duration: 7666.722263925869
[2024-12-26 03:35:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17371699412829
avg_train_sample_per_sec: 17.17371699412829
avg_episode_per_sec: 0.14804928443214044
collect_time: 40.527044916249814
reward_mean: -167.35025676937443
reward_std: 6.901356460937782
reward_max: -160.43207282913167
reward_min: -181.08543417366948
queue_len: 0.11097497133247641
wait_time: 1.1336939063866038
delay_time: 7.035258848870449
pressure: 1.354664014146773
total_envstep_count: 126672
total_train_sample_count: 126672
total_episode_count: 1092
total_duration: 7707.249308842119
[2024-12-26 03:36:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.02860131553275
avg_train_sample_per_sec: 17.02860131553275
avg_episode_per_sec: 0.14679828720286853
collect_time: 40.87241148602963
reward_mean: -169.42705415499532
reward_std: 3.909101778472229
reward_max: -161.9747899159664
reward_min: -174.20798319327722
queue_len: 0.11235215792771573
wait_time: 1.1554819208850646
delay_time: 6.998230885276796
pressure: 1.3653846153846152
total_envstep_count: 127368
total_train_sample_count: 127368
total_episode_count: 1098
total_duration: 7748.1217203281485
[2024-12-26 03:37:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.142155815451904
avg_train_sample_per_sec: 17.142155815451904
avg_episode_per_sec: 0.14777720530561986
collect_time: 40.601661045026034
reward_mean: -171.83870214752565
reward_std: 5.555508394334114
reward_max: -164.84803921568624
reward_min: -182.66596638655466
queue_len: 0.11395139399703295
wait_time: 1.1615623150232683
delay_time: 7.241711590596563
pressure: 1.3884836427939877
total_envstep_count: 128064
total_train_sample_count: 128064
total_episode_count: 1104
total_duration: 7788.723381373175
[2024-12-26 03:37:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.980569502886638
avg_train_sample_per_sec: 16.980569502886638
avg_episode_per_sec: 0.14638421985247102
collect_time: 40.98802457018196
reward_mean: -175.50641923436044
reward_std: 5.978028919912461
reward_max: -166.53851540616256
reward_min: -184.8564425770308
queue_len: 0.11638356713153875
wait_time: 1.183531204258892
delay_time: 7.595645977569332
pressure: 1.4124668435013261
total_envstep_count: 128760
total_train_sample_count: 128760
total_episode_count: 1110
total_duration: 7829.711405943356
[2024-12-26 03:38:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.990390322818843
avg_train_sample_per_sec: 16.990390322818843
avg_episode_per_sec: 0.14646888209326592
collect_time: 40.96433258894831
reward_mean: -172.4190009337068
reward_std: 4.957741496233762
reward_max: -165.38515406162466
reward_min: -178.4187675070028
queue_len: 0.1143362075157207
wait_time: 1.1737789059036523
delay_time: 7.52507009142749
pressure: 1.388815207780725
total_envstep_count: 129456
total_train_sample_count: 129456
total_episode_count: 1116
total_duration: 7870.675738532304
[2024-12-26 03:39:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.04695434054294
avg_train_sample_per_sec: 17.04695434054294
avg_episode_per_sec: 0.146956502935715
collect_time: 40.828407590949915
reward_mean: -168.86251167133523
reward_std: 4.376630001448086
reward_max: -163.35644257703083
reward_min: -175.873949579832
queue_len: 0.1119777928855008
wait_time: 1.1448075251320686
delay_time: 6.981323948123691
pressure: 1.3759946949602122
total_envstep_count: 130152
total_train_sample_count: 130152
total_episode_count: 1122
total_duration: 7911.504146123254
[2024-12-26 03:40:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.931618825407966
avg_train_sample_per_sec: 16.931618825407966
avg_episode_per_sec: 0.14596223125351696
collect_time: 41.10652425954492
reward_mean: -169.29516806722688
reward_std: 6.671220876425526
reward_max: -158.82773109243695
reward_min: -180.7836134453782
queue_len: 0.11226470030983215
wait_time: 1.1549492033771953
delay_time: 7.115286542397214
pressure: 1.381631299734748
total_envstep_count: 130848
total_train_sample_count: 130848
total_episode_count: 1128
total_duration: 7952.610670382799
[2024-12-26 03:40:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.98513248360865
avg_train_sample_per_sec: 16.98513248360865
avg_episode_per_sec: 0.14642355589317801
collect_time: 40.97701331865787
reward_mean: -160.40499533146593
reward_std: 5.664693975343089
reward_max: -152.58403361344537
reward_min: -169.9208683473389
queue_len: 0.10636936029938056
wait_time: 1.071984430376925
delay_time: 6.739134531255125
pressure: 1.3003978779840848
total_envstep_count: 131544
total_train_sample_count: 131544
total_episode_count: 1134
total_duration: 7993.587683701457
[2024-12-26 03:41:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.153800871256742
avg_train_sample_per_sec: 17.153800871256742
avg_episode_per_sec: 0.14787759371773052
collect_time: 40.57409813857824
reward_mean: -170.34325396825395
reward_std: 4.9576900068777086
reward_max: -161.0420168067227
reward_min: -175.5112044817926
queue_len: 0.11295971748557955
wait_time: 1.1443354087877415
delay_time: 7.047061743789851
pressure: 1.3759946949602124
total_envstep_count: 132240
total_train_sample_count: 132240
total_episode_count: 1140
total_duration: 8034.161781840035
[2024-12-26 03:42:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.067711266131372
avg_train_sample_per_sec: 17.067711266131372
avg_episode_per_sec: 0.14713544194940836
collect_time: 40.778754054805255
reward_mean: -163.86799719887955
reward_std: 7.585598852245045
reward_max: -152.8011204481793
reward_min: -172.19467787114846
queue_len: 0.10866578063586178
wait_time: 1.0983425310884742
delay_time: 6.77768899962588
pressure: 1.3213969938107868
total_envstep_count: 132936
total_train_sample_count: 132936
total_episode_count: 1146
total_duration: 8074.94053589484
[2024-12-26 03:42:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97011759143575
avg_train_sample_per_sec: 16.97011759143575
avg_episode_per_sec: 0.14629411716754956
collect_time: 41.01326913322321
reward_mean: -165.0862511671335
reward_std: 10.17656000556737
reward_max: -149.84453781512602
reward_min: -178.84173669467782
queue_len: 0.10947364135751558
wait_time: 1.1015162364680617
delay_time: 6.921476789426001
pressure: 1.340627763041556
total_envstep_count: 133632
total_train_sample_count: 133632
total_episode_count: 1152
total_duration: 8115.953805028063
[2024-12-26 03:43:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.033657716236505
avg_train_sample_per_sec: 17.033657716236505
avg_episode_per_sec: 0.1468418768641078
collect_time: 40.86027860807441
reward_mean: -169.93288982259568
reward_std: 9.602481124506154
reward_max: -160.59313725490193
reward_min: -184.00280112044823
queue_len: 0.11268759272055417
wait_time: 1.1571001190042771
delay_time: 7.15530154378741
pressure: 1.3964412024756854
total_envstep_count: 134328
total_train_sample_count: 134328
total_episode_count: 1158
total_duration: 8156.814083636137
[2024-12-26 03:44:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.075560796514612
avg_train_sample_per_sec: 17.075560796514612
avg_episode_per_sec: 0.14720311031478114
collect_time: 40.76000831211731
reward_mean: -168.2889822595705
reward_std: 8.978036053456789
reward_max: -154.28431372549014
reward_min: -178.83543417366954
queue_len: 0.11159746834189027
wait_time: 1.1344208107646245
delay_time: 7.001067860247616
pressure: 1.3687002652519895
total_envstep_count: 135024
total_train_sample_count: 135024
total_episode_count: 1164
total_duration: 8197.574091948254
[2024-12-26 03:44:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.214488794059005
avg_train_sample_per_sec: 17.214488794059005
avg_episode_per_sec: 0.14840076546602593
collect_time: 40.43105829783343
reward_mean: -169.3208450046685
reward_std: 9.460068701780067
reward_max: -160.3424369747899
reward_min: -186.02170868347335
queue_len: 0.11228172745667674
wait_time: 1.1464175966584689
delay_time: 7.046562073481795
pressure: 1.3663793103448274
total_envstep_count: 135720
total_train_sample_count: 135720
total_episode_count: 1170
total_duration: 8238.005150246088
[2024-12-26 03:45:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.199730905095684
avg_train_sample_per_sec: 17.199730905095684
avg_episode_per_sec: 0.14827354228530765
collect_time: 40.46574936784617
reward_mean: -160.2876984126984
reward_std: 4.589496993210199
reward_max: -154.96078431372547
reward_min: -166.85084033613438
queue_len: 0.10629157719674957
wait_time: 1.07873050856063
delay_time: 6.616449296037717
pressure: 1.2864721485411141
total_envstep_count: 136416
total_train_sample_count: 136416
total_episode_count: 1176
total_duration: 8278.470899613934
[2024-12-26 03:46:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.943712811763326
avg_train_sample_per_sec: 16.943712811763326
avg_episode_per_sec: 0.1460664897565804
collect_time: 41.07718347992747
reward_mean: -163.46697012138193
reward_std: 3.9678182688391908
reward_max: -158.37955182072832
reward_min: -168.68907563025212
queue_len: 0.1083998475605981
wait_time: 1.1027763227306837
delay_time: 6.824323107276819
pressure: 1.3283598585322722
total_envstep_count: 137112
total_train_sample_count: 137112
total_episode_count: 1182
total_duration: 8319.548083093861
[2024-12-26 03:46:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.048236603101167
avg_train_sample_per_sec: 17.048236603101167
avg_episode_per_sec: 0.14696755692328592
collect_time: 40.82533673150652
reward_mean: -164.0108543417367
reward_std: 6.066785033668278
reward_max: -155.82913165266112
reward_min: -175.6512605042017
queue_len: 0.10876051348921534
wait_time: 1.112706090393717
delay_time: 6.6829980820403305
pressure: 1.3107869142351902
total_envstep_count: 137808
total_train_sample_count: 137808
total_episode_count: 1188
total_duration: 8360.373419825368
[2024-12-26 03:47:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.102433275148773
avg_train_sample_per_sec: 17.102433275148773
avg_episode_per_sec: 0.14743476961335147
collect_time: 40.69596348090097
reward_mean: -167.1706349206349
reward_std: 5.924466713919706
reward_max: -157.60154061624647
reward_min: -175.27941176470597
queue_len: 0.11085585870068627
wait_time: 1.1217463444263645
delay_time: 6.973977293509584
pressure: 1.3372015915119364
total_envstep_count: 138504
total_train_sample_count: 138504
total_episode_count: 1194
total_duration: 8401.069383306269
[2024-12-26 03:48:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.976430990464625
avg_train_sample_per_sec: 16.976430990464625
avg_episode_per_sec: 0.14634854302124678
collect_time: 40.99801662616432
reward_mean: -167.4947478991597
reward_std: 2.8047646914622963
reward_max: -164.88095238095238
reward_min: -173.2521008403362
queue_len: 0.11107078773153824
wait_time: 1.1258605674807503
delay_time: 7.130308745157556
pressure: 1.3381962864721484
total_envstep_count: 139200
total_train_sample_count: 139200
total_episode_count: 1200
total_duration: 8442.067399932434
[2024-12-26 03:49:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.07962538724402
avg_train_sample_per_sec: 17.07962538724402
avg_episode_per_sec: 0.14723814989003464
collect_time: 40.7503082895372
reward_mean: -167.65301120448177
reward_std: 9.434623209185833
reward_max: -154.31022408963582
reward_min: -182.76890756302527
queue_len: 0.11117573687299853
wait_time: 1.1193194342281565
delay_time: 7.0871581165421125
pressure: 1.3356542882404954
total_envstep_count: 139896
total_train_sample_count: 139896
total_episode_count: 1206
total_duration: 8482.81770822197
[2024-12-26 03:49:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.000303098082046
avg_train_sample_per_sec: 17.000303098082046
avg_episode_per_sec: 0.14655433705243145
collect_time: 40.94044653112813
reward_mean: -161.69654528478057
reward_std: 7.8258040373097035
reward_max: -151.54131652661064
reward_min: -174.6330532212885
queue_len: 0.10722582578566352
wait_time: 1.0710386497658304
delay_time: 6.838059426380911
pressure: 1.3040450928381964
total_envstep_count: 140592
total_train_sample_count: 140592
total_episode_count: 1212
total_duration: 8523.758154753097
[2024-12-26 03:50:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.130337478726556
avg_train_sample_per_sec: 17.130337478726556
avg_episode_per_sec: 0.1476753230924703
collect_time: 40.629672408049935
reward_mean: -164.84733893557424
reward_std: 4.42194372463087
reward_max: -160.33403361344537
reward_min: -171.85434173669464
queue_len: 0.10931521149573888
wait_time: 1.107387506284565
delay_time: 7.021013184250577
pressure: 1.320733863837312
total_envstep_count: 141288
total_train_sample_count: 141288
total_episode_count: 1218
total_duration: 8564.387827161147
[2024-12-26 03:51:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.187112977944192
avg_train_sample_per_sec: 17.187112977944192
avg_episode_per_sec: 0.14816476705124304
collect_time: 40.4954573169537
reward_mean: -166.76085434173666
reward_std: 5.8006156557627175
reward_max: -158.46848739495786
reward_min: -174.97268907563023
queue_len: 0.110584120916271
wait_time: 1.106713076477275
delay_time: 6.913933909669697
pressure: 1.3609637488947834
total_envstep_count: 141984
total_train_sample_count: 141984
total_episode_count: 1224
total_duration: 8604.8832844781
[2024-12-26 03:51:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.993882717391408
avg_train_sample_per_sec: 16.993882717391408
avg_episode_per_sec: 0.14649898894302937
collect_time: 40.955914052985605
reward_mean: -172.82376283846872
reward_std: 8.838959196738907
reward_max: -161.72058823529423
reward_min: -185.12745098039213
queue_len: 0.11460461726688909
wait_time: 1.1632874745831134
delay_time: 7.321768904068711
pressure: 1.4028514588859415
total_envstep_count: 142680
total_train_sample_count: 142680
total_episode_count: 1230
total_duration: 8645.839198531086
[2024-12-26 03:52:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.20178338585586
avg_train_sample_per_sec: 17.20178338585586
avg_episode_per_sec: 0.14829123608496433
collect_time: 40.4609210793972
reward_mean: -166.13935574229694
reward_std: 8.112990922756982
reward_max: -152.5427170868348
reward_min: -178.63025210084035
queue_len: 0.11017198656650991
wait_time: 1.1107350433542118
delay_time: 7.062794257526574
pressure: 1.3464854111405835
total_envstep_count: 143376
total_train_sample_count: 143376
total_episode_count: 1236
total_duration: 8686.300119610483
[2024-12-26 03:53:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18462787084761
avg_train_sample_per_sec: 17.18462787084761
avg_episode_per_sec: 0.14814334371420354
collect_time: 40.50131345472485
reward_mean: -170.04960317460316
reward_std: 5.460734105150807
reward_max: -161.65756302521007
reward_min: -177.34593837535016
queue_len: 0.11276498884257503
wait_time: 1.1354577640074597
delay_time: 7.198606247251298
pressure: 1.3692528735632186
total_envstep_count: 144072
total_train_sample_count: 144072
total_episode_count: 1242
total_duration: 8726.801433065208
[2024-12-26 03:53:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.99172569439312
avg_train_sample_per_sec: 16.99172569439312
avg_episode_per_sec: 0.1464803939171821
collect_time: 40.96111322169378
reward_mean: -163.14204014939307
reward_std: 6.472043078196574
reward_max: -153.43697478991606
reward_min: -172.13165266106444
queue_len: 0.10818437675689196
wait_time: 1.0941270739064857
delay_time: 6.751498744548716
pressure: 1.3142130857648098
total_envstep_count: 144768
total_train_sample_count: 144768
total_episode_count: 1248
total_duration: 8767.762546286902
[2024-12-26 03:54:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.1843051749357
avg_train_sample_per_sec: 17.1843051749357
avg_episode_per_sec: 0.14814056185289398
collect_time: 40.50207400966995
reward_mean: -163.0601073762838
reward_std: 7.122464211340274
reward_max: -152.32773109243695
reward_min: -171.43417366946773
queue_len: 0.1081300446792333
wait_time: 1.096170950696813
delay_time: 6.930811954194767
pressure: 1.3339964633068082
total_envstep_count: 145464
total_train_sample_count: 145464
total_episode_count: 1254
total_duration: 8808.264620296572
[2024-12-26 03:55:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47006530397269
avg_train_sample_per_sec: 17.47006530397269
avg_episode_per_sec: 0.15060401124114386
collect_time: 39.83957632040046
reward_mean: -159.77742763772173
reward_std: 5.996169487060478
reward_max: -151.8375350140056
reward_min: -167.84173669467785
queue_len: 0.10595320135127438
wait_time: 1.061307170967415
delay_time: 6.7369013616256295
pressure: 1.3009504862953138
total_envstep_count: 146160
total_train_sample_count: 146160
total_episode_count: 1260
total_duration: 8848.104196616972
[2024-12-26 03:55:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.02752625960599
avg_train_sample_per_sec: 17.02752625960599
avg_episode_per_sec: 0.14678901947936202
collect_time: 40.87499202107265
reward_mean: -165.68043884220353
reward_std: 3.944111806344401
reward_max: -159.81862745098044
reward_min: -172.24999999999997
queue_len: 0.10986766501472384
wait_time: 1.1129247344384259
delay_time: 6.958583304328173
pressure: 1.3317860300618922
total_envstep_count: 146856
total_train_sample_count: 146856
total_episode_count: 1266
total_duration: 8888.979188638044
[2024-12-26 03:56:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.090326536140452
avg_train_sample_per_sec: 17.090326536140452
avg_episode_per_sec: 0.1473304011736246
collect_time: 40.724792386394
reward_mean: -158.79808590102706
reward_std: 3.554376311481184
reward_max: -154.24019607843135
reward_min: -165.08543417366948
queue_len: 0.10530377049139727
wait_time: 1.0586185070845315
delay_time: 6.62739410490165
pressure: 1.2766357206012378
total_envstep_count: 147552
total_train_sample_count: 147552
total_episode_count: 1272
total_duration: 8929.703981024439
[2024-12-26 03:57:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.129318344484293
avg_train_sample_per_sec: 17.129318344484293
avg_episode_per_sec: 0.14766653745245079
collect_time: 40.632089730769394
reward_mean: -160.57924836601305
reward_std: 8.019678627217141
reward_max: -151.81652661064425
reward_min: -175.36974789915968
queue_len: 0.10648491270955777
wait_time: 1.0722114332028125
delay_time: 6.736565858954581
pressure: 1.300839964633068
total_envstep_count: 148248
total_train_sample_count: 148248
total_episode_count: 1278
total_duration: 8970.336070755207
[2024-12-26 03:57:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.131925888045288
avg_train_sample_per_sec: 17.131925888045288
avg_episode_per_sec: 0.14768901627625247
collect_time: 40.62590537387691
reward_mean: -156.86788048552754
reward_std: 3.2415731059578525
reward_max: -152.55742296918766
reward_min: -160.55602240896368
queue_len: 0.10402379342541616
wait_time: 1.0511564373760114
delay_time: 6.66103296568263
pressure: 1.2551945181255526
total_envstep_count: 148944
total_train_sample_count: 148944
total_episode_count: 1284
total_duration: 9010.961976129085
[2024-12-26 03:58:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.065123675614874
avg_train_sample_per_sec: 17.065123675614874
avg_episode_per_sec: 0.147113135134611
collect_time: 40.784937351174655
reward_mean: -154.40476190476193
reward_std: 2.951052457755783
reward_max: -150.93347338935578
reward_min: -159.983893557423
queue_len: 0.10239042566628774
wait_time: 1.0359652039418774
delay_time: 6.380594420902381
pressure: 1.2442528735632183
total_envstep_count: 149640
total_train_sample_count: 149640
total_episode_count: 1290
total_duration: 9051.74691348026
[2024-12-26 03:59:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.179219593661223
avg_train_sample_per_sec: 17.179219593661223
avg_episode_per_sec: 0.14809672063501053
collect_time: 40.51406387847849
reward_mean: -157.69642857142858
reward_std: 10.148834255654783
reward_max: -148.47759103641457
reward_min: -172.11624649859942
queue_len: 0.10457322849564228
wait_time: 1.0529445973791816
delay_time: 6.553785941925114
pressure: 1.2634836427939875
total_envstep_count: 150336
total_train_sample_count: 150336
total_episode_count: 1296
total_duration: 9092.260977358737
[2024-12-26 04:00:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.026510396383863
avg_train_sample_per_sec: 17.026510396383863
avg_episode_per_sec: 0.14678026203779193
collect_time: 40.877430771006274
reward_mean: -156.12791783380018
reward_std: 4.5002245879851195
reward_max: -150.03221288515405
reward_min: -162.11414565826325
queue_len: 0.10353310201180382
wait_time: 1.0396217837267534
delay_time: 6.47385035672831
pressure: 1.2416003536693192
total_envstep_count: 151032
total_train_sample_count: 151032
total_episode_count: 1302
total_duration: 9133.138408129744
[2024-12-26 04:00:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.254320011215906
avg_train_sample_per_sec: 17.254320011215906
avg_episode_per_sec: 0.14874413802772332
collect_time: 40.337724091565235
reward_mean: -154.15301120448177
reward_std: 6.2451019098103595
reward_max: -144.02450980392155
reward_min: -161.54061624649867
queue_len: 0.10222348223108874
wait_time: 1.0400101574670542
delay_time: 6.36731440437013
pressure: 1.2223695844385498
total_envstep_count: 151728
total_train_sample_count: 151728
total_episode_count: 1308
total_duration: 9173.476132221309
[2024-12-26 04:01:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.0523626605325
avg_train_sample_per_sec: 17.0523626605325
avg_episode_per_sec: 0.14700312638390084
collect_time: 40.81545847080089
reward_mean: -157.68825863678808
reward_std: 6.977216281103903
reward_max: -144.49719887955183
reward_min: -167.28361344537814
queue_len: 0.10456781076710085
wait_time: 1.0466183931574398
delay_time: 6.591101919852808
pressure: 1.2515473032714413
total_envstep_count: 152424
total_train_sample_count: 152424
total_episode_count: 1314
total_duration: 9214.29159069211
[2024-12-26 04:02:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.233824388053414
avg_train_sample_per_sec: 17.233824388053414
avg_episode_per_sec: 0.14856745162115012
collect_time: 40.38569642629474
reward_mean: -157.6279178338002
reward_std: 6.479610527130396
reward_max: -145.1071428571429
reward_min: -166.30812324929974
queue_len: 0.10452779697201604
wait_time: 1.0558938540049085
delay_time: 6.582966128918623
pressure: 1.258731211317418
total_envstep_count: 153120
total_train_sample_count: 153120
total_episode_count: 1320
total_duration: 9254.677287118404
[2024-12-26 04:02:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.266575575563735
avg_train_sample_per_sec: 17.266575575563735
avg_episode_per_sec: 0.14884978944451496
collect_time: 40.309092961374674
reward_mean: -159.6387721755369
reward_std: 4.922127242458736
reward_max: -152.68697478991598
reward_min: -166.30462184873952
queue_len: 0.1058612547583136
wait_time: 1.0723658384662442
delay_time: 6.791023650079253
pressure: 1.2745358090185677
total_envstep_count: 153816
total_train_sample_count: 153816
total_episode_count: 1326
total_duration: 9294.98638007978
[2024-12-26 04:03:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.018120489636782
avg_train_sample_per_sec: 17.018120489636782
avg_episode_per_sec: 0.1467079352554895
collect_time: 40.897583280352876
reward_mean: -157.54201680672267
reward_std: 3.8947541386823037
reward_max: -152.67296918767502
reward_min: -165.38515406162458
queue_len: 0.10447083342620866
wait_time: 1.052467450286923
delay_time: 6.419575900920151
pressure: 1.2695623342175066
total_envstep_count: 154512
total_train_sample_count: 154512
total_episode_count: 1332
total_duration: 9335.883963360133
[2024-12-26 04:04:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.36764562724878
avg_train_sample_per_sec: 17.36764562724878
avg_episode_per_sec: 0.14972108299352396
collect_time: 40.07451642771996
reward_mean: -152.29866946778716
reward_std: 8.101853390188795
reward_max: -143.07142857142858
reward_min: -168.12394957983196
queue_len: 0.10099381264442119
wait_time: 1.0175799873441862
delay_time: 6.232636977104916
pressure: 1.223916887709991
total_envstep_count: 155208
total_train_sample_count: 155208
total_episode_count: 1338
total_duration: 9375.958479787852
[2024-12-26 04:04:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.21300010932311
avg_train_sample_per_sec: 17.21300010932311
avg_episode_per_sec: 0.14838793197692338
collect_time: 40.43455502117984
reward_mean: -151.453197945845
reward_std: 3.569220734616554
reward_max: -145.85154061624655
reward_min: -155.22689075630254
queue_len: 0.10043315513650199
wait_time: 1.0043861156310443
delay_time: 6.408858409916861
pressure: 1.2225906277630416
total_envstep_count: 155904
total_train_sample_count: 155904
total_episode_count: 1344
total_duration: 9416.393034809033
[2024-12-26 04:05:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.341777628645865
avg_train_sample_per_sec: 17.341777628645865
avg_episode_per_sec: 0.1494980830055678
collect_time: 40.13429389443436
reward_mean: -158.05532212885154
reward_std: 5.7680950601694825
reward_max: -147.7240896358543
reward_min: -164.8935574229692
queue_len: 0.10481122157085644
wait_time: 1.0512915710050599
delay_time: 6.612465044535359
pressure: 1.2766357206012378
total_envstep_count: 156600
total_train_sample_count: 156600
total_episode_count: 1350
total_duration: 9456.527328703467
[2024-12-26 04:06:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37863977932345
avg_train_sample_per_sec: 17.37863977932345
avg_episode_per_sec: 0.14981586016658147
collect_time: 40.04916430963018
reward_mean: -153.99042950513538
reward_std: 8.075076013340258
reward_max: -146.87324929971984
reward_min: -171.32913165266112
queue_len: 0.10211566943311366
wait_time: 1.0145099927681063
delay_time: 6.523039176256851
pressure: 1.2340848806366047
total_envstep_count: 157296
total_train_sample_count: 157296
total_episode_count: 1356
total_duration: 9496.576493013097
[2024-12-26 04:06:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.29333026576342
avg_train_sample_per_sec: 17.29333026576342
avg_episode_per_sec: 0.1490804333255467
collect_time: 40.2467303465493
reward_mean: -154.50420168067222
reward_std: 4.268681827001009
reward_max: -148.88935574229689
reward_min: -160.3116246498598
queue_len: 0.10245636716224948
wait_time: 1.021236412336818
delay_time: 6.588299551131372
pressure: 1.2270114942528736
total_envstep_count: 157992
total_train_sample_count: 157992
total_episode_count: 1362
total_duration: 9536.823223359646
[2024-12-26 04:07:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.113780587191503
avg_train_sample_per_sec: 17.113780587191503
avg_episode_per_sec: 0.14753259126889226
collect_time: 40.66897997517326
reward_mean: -158.125116713352
reward_std: 5.874626718497902
reward_max: -150.8473389355742
reward_min: -166.42296918767505
queue_len: 0.10485750445182494
wait_time: 1.0514384688446556
delay_time: 6.785013718114793
pressure: 1.2706675508399647
total_envstep_count: 158688
total_train_sample_count: 158688
total_episode_count: 1368
total_duration: 9577.49220333482
[2024-12-26 04:08:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25959217121808
avg_train_sample_per_sec: 17.25959217121808
avg_episode_per_sec: 0.1487895876829145
collect_time: 40.32540242524632
reward_mean: -156.40849673202612
reward_std: 2.5091861722593283
reward_max: -151.67997198879553
reward_min: -159.1778711484594
queue_len: 0.103719162289142
wait_time: 1.0367866863810071
delay_time: 6.627271646140851
pressure: 1.262820512820513
total_envstep_count: 159384
total_train_sample_count: 159384
total_episode_count: 1374
total_duration: 9617.817605760065
[2024-12-26 04:08:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.07571008393585
avg_train_sample_per_sec: 17.07571008393585
avg_episode_per_sec: 0.14720439727530904
collect_time: 40.759651960521936
reward_mean: -149.62651727357607
reward_std: 6.773158304477654
reward_max: -144.06022408963582
reward_min: -164.2114845938374
queue_len: 0.09922182843075335
wait_time: 0.9987954841529892
delay_time: 6.199176605358205
pressure: 1.2066755083996463
total_envstep_count: 160080
total_train_sample_count: 160080
total_episode_count: 1380
total_duration: 9658.577257720586
[2024-12-26 04:09:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.217985130330337
avg_train_sample_per_sec: 17.217985130330337
avg_episode_per_sec: 0.14843090629595118
collect_time: 40.422848244534805
reward_mean: -155.77369281045753
reward_std: 4.195607878317212
reward_max: -150.0119047619047
reward_min: -161.77240896358552
queue_len: 0.1032982047814705
wait_time: 1.0315662405545771
delay_time: 6.626338040927994
pressure: 1.2312113174182138
total_envstep_count: 160776
total_train_sample_count: 160776
total_episode_count: 1386
total_duration: 9699.00010596512
[2024-12-26 04:10:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.356554960041876
avg_train_sample_per_sec: 17.356554960041876
avg_episode_per_sec: 0.14962547379346447
collect_time: 40.100123647943136
reward_mean: -153.98961251167134
reward_std: 4.440043816798821
reward_max: -147.28781512605045
reward_min: -161.0497198879552
queue_len: 0.1021151276602595
wait_time: 1.0201565816423825
delay_time: 6.475215793034242
pressure: 1.2353006189213085
total_envstep_count: 161472
total_train_sample_count: 161472
total_episode_count: 1392
total_duration: 9739.100229613063
[2024-12-26 04:10:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35929985314215
avg_train_sample_per_sec: 17.35929985314215
avg_episode_per_sec: 0.14964913666501853
collect_time: 40.09378292258828
reward_mean: -154.078664799253
reward_std: 2.993383023510531
reward_max: -147.82983193277315
reward_min: -157.29621848739492
queue_len: 0.10217418090136139
wait_time: 1.0164450506108718
delay_time: 6.55728128361071
pressure: 1.2230327144120245
total_envstep_count: 162168
total_train_sample_count: 162168
total_episode_count: 1398
total_duration: 9779.19401253565
[2024-12-26 04:11:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.324009418825735
avg_train_sample_per_sec: 17.324009418825735
avg_episode_per_sec: 0.14934490878298048
collect_time: 40.17545726127737
reward_mean: -155.73599439775913
reward_std: 8.813778486763793
reward_max: -140.4439775910364
reward_min: -169.875350140056
queue_len: 0.10327320583405776
wait_time: 1.045821290496747
delay_time: 6.763962919256005
pressure: 1.2238063660477454
total_envstep_count: 162864
total_train_sample_count: 162864
total_episode_count: 1404
total_duration: 9819.369469796928
[2024-12-26 04:12:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27063473038523
avg_train_sample_per_sec: 17.27063473038523
avg_episode_per_sec: 0.14888478215849335
collect_time: 40.29961902763694
reward_mean: -154.08543417366948
reward_std: 4.7983039805480585
reward_max: -145.13865546218486
reward_min: -160.98599439775919
queue_len: 0.10217866987643864
wait_time: 1.0266857184960634
delay_time: 6.549403269529826
pressure: 1.221816976127321
total_envstep_count: 163560
total_train_sample_count: 163560
total_episode_count: 1410
total_duration: 9859.669088824565
[2024-12-26 04:13:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.15089444676352
avg_train_sample_per_sec: 17.15089444676352
avg_episode_per_sec: 0.14785253833416828
collect_time: 40.580973905494446
reward_mean: -154.55602240896354
reward_std: 4.626979952339565
reward_max: -148.406162464986
reward_min: -162.766806722689
queue_len: 0.10249073104042676
wait_time: 1.0418829114315928
delay_time: 6.488386216413873
pressure: 1.245026525198939
total_envstep_count: 164256
total_train_sample_count: 164256
total_episode_count: 1416
total_duration: 9900.25006273006
[2024-12-26 04:13:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.184042175432545
avg_train_sample_per_sec: 17.184042175432545
avg_episode_per_sec: 0.1481382946157978
collect_time: 40.502693888580424
reward_mean: -148.64764239028946
reward_std: 3.4320513109577724
reward_max: -143.65966386554624
reward_min: -154.27661064425774
queue_len: 0.09857270715536437
wait_time: 0.9783655394076286
delay_time: 6.164430846351919
pressure: 1.1888815207780727
total_envstep_count: 164952
total_train_sample_count: 164952
total_episode_count: 1422
total_duration: 9940.75275661864
[2024-12-26 04:14:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.36956875262339
avg_train_sample_per_sec: 17.36956875262339
avg_episode_per_sec: 0.14973766166054644
collect_time: 40.07007945403829
reward_mean: -152.0409663865546
reward_std: 4.924679774578628
reward_max: -144.92857142857144
reward_min: -158.28291316526608
queue_len: 0.10082292200699909
wait_time: 1.0030258013904059
delay_time: 6.530631104873152
pressure: 1.208554376657825
total_envstep_count: 165648
total_train_sample_count: 165648
total_episode_count: 1428
total_duration: 9980.822836072679
[2024-12-26 04:15:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25422369932422
avg_train_sample_per_sec: 17.25422369932422
avg_episode_per_sec: 0.148743307752795
collect_time: 40.337949253970756
reward_mean: -152.61823062558352
reward_std: 6.660539187820702
reward_max: -143.48949579831924
reward_min: -165.0987394957983
queue_len: 0.10120572322651428
wait_time: 1.0201267067392827
delay_time: 6.467744129034191
pressure: 1.2233642793987622
total_envstep_count: 166344
total_train_sample_count: 166344
total_episode_count: 1434
total_duration: 10021.16078532665
[2024-12-26 04:15:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.165805351422215
avg_train_sample_per_sec: 17.165805351422215
avg_episode_per_sec: 0.14798108061570875
collect_time: 40.54572364950738
reward_mean: -152.10235760971057
reward_std: 4.8031048530995974
reward_max: -144.69537815126043
reward_min: -158.83963585434174
queue_len: 0.10086363236718206
wait_time: 1.0105745547555893
delay_time: 6.556947412905902
pressure: 1.2112068965517242
total_envstep_count: 167040
total_train_sample_count: 167040
total_episode_count: 1440
total_duration: 10061.706508976158
[2024-12-26 04:16:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.431672060718096
avg_train_sample_per_sec: 17.431672060718096
avg_episode_per_sec: 0.1502730350061905
collect_time: 39.9273229542002
reward_mean: -155.8828197945845
reward_std: 5.8250085427340474
reward_max: -149.02521008403363
reward_min: -162.7780112044818
queue_len: 0.10337057015556
wait_time: 1.0284986452582803
delay_time: 6.633563494829776
pressure: 1.254310344827586
total_envstep_count: 167736
total_train_sample_count: 167736
total_episode_count: 1446
total_duration: 10101.633831930358
[2024-12-26 04:17:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.419128248519428
avg_train_sample_per_sec: 17.419128248519428
avg_episode_per_sec: 0.150164898694133
collect_time: 39.9560753023997
reward_mean: -154.86204481792717
reward_std: 5.776345744575455
reward_max: -143.38305322128852
reward_min: -161.94677871148465
queue_len: 0.1026936636723655
wait_time: 1.0194463174305972
delay_time: 6.604397244162374
pressure: 1.2295534924845268
total_envstep_count: 168432
total_train_sample_count: 168432
total_episode_count: 1452
total_duration: 10141.589907232757
[2024-12-26 04:17:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.24655152617488
avg_train_sample_per_sec: 17.24655152617488
avg_episode_per_sec: 0.1486771683290938
collect_time: 40.35589369525202
reward_mean: -152.56652661064425
reward_std: 7.4336405465050746
reward_max: -143.92997198879553
reward_min: -166.66946778711483
queue_len: 0.10117143674445905
wait_time: 1.0093507672741953
delay_time: 6.470742599677515
pressure: 1.2243589743589745
total_envstep_count: 169128
total_train_sample_count: 169128
total_episode_count: 1458
total_duration: 10181.94580092801
[2024-12-26 04:18:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39083041402445
avg_train_sample_per_sec: 17.39083041402445
avg_episode_per_sec: 0.14992095184503837
collect_time: 40.0210906224884
reward_mean: -149.50957049486462
reward_std: 4.10068452935337
reward_max: -142.3669467787115
reward_min: -155.42577030812328
queue_len: 0.09914427751648847
wait_time: 0.997859532849391
delay_time: 6.269112262447245
pressure: 1.1927497789566754
total_envstep_count: 169824
total_train_sample_count: 169824
total_episode_count: 1464
total_duration: 10221.966891550499
[2024-12-26 04:19:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.204069636570857
avg_train_sample_per_sec: 17.204069636570857
avg_episode_per_sec: 0.14831094514285223
collect_time: 40.455544223124164
reward_mean: -150.48902894491127
reward_std: 4.262535471062092
reward_max: -144.7640056022409
reward_min: -156.84733893557421
queue_len: 0.0997937857724876
wait_time: 0.9967804761161759
delay_time: 6.387488506615174
pressure: 1.2018125552608312
total_envstep_count: 170520
total_train_sample_count: 170520
total_episode_count: 1470
total_duration: 10262.422435773624
[2024-12-26 04:19:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.257128546965493
avg_train_sample_per_sec: 17.257128546965493
avg_episode_per_sec: 0.14876834954280596
collect_time: 40.33115927170776
reward_mean: -152.07574696545285
reward_std: 3.6952139574868053
reward_max: -149.07072829131653
reward_min: -159.92507002801125
queue_len: 0.1008459860513613
wait_time: 1.0092140083265844
delay_time: 6.5632354442061915
pressure: 1.2128647214854111
total_envstep_count: 171216
total_train_sample_count: 171216
total_episode_count: 1476
total_duration: 10302.753595045331
[2024-12-26 04:20:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.251754415062397
avg_train_sample_per_sec: 17.251754415062397
avg_episode_per_sec: 0.14872202081950342
collect_time: 40.34372291970067
reward_mean: -149.3057889822596
reward_std: 7.50296594511006
reward_max: -141.74999999999997
reward_min: -165.39425770308122
queue_len: 0.09900914388744005
wait_time: 0.9887517120022191
delay_time: 6.22993834506413
pressure: 1.2003757736516356
total_envstep_count: 171912
total_train_sample_count: 171912
total_episode_count: 1482
total_duration: 10343.097317965032
[2024-12-26 04:21:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35049953690878
avg_train_sample_per_sec: 17.35049953690878
avg_episode_per_sec: 0.1495732718699033
collect_time: 40.11411881942861
reward_mean: -151.79598506069092
reward_std: 6.435668471752735
reward_max: -144.69677871148463
reward_min: -162.74299719887955
queue_len: 0.1006604675468773
wait_time: 1.0098769835078152
delay_time: 6.236437772574409
pressure: 1.202475685234306
total_envstep_count: 172608
total_train_sample_count: 172608
total_episode_count: 1488
total_duration: 10383.21143678446
[2024-12-26 04:21:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.199892893248883
avg_train_sample_per_sec: 17.199892893248883
avg_episode_per_sec: 0.1482749387349042
collect_time: 40.46536826244926
reward_mean: -151.23622782446313
reward_std: 4.299231197472973
reward_max: -144.60434173669466
reward_min: -155.46498599439778
queue_len: 0.1002892757456652
wait_time: 0.9969361197175597
delay_time: 6.502699849588555
pressure: 1.2131962864721486
total_envstep_count: 173304
total_train_sample_count: 173304
total_episode_count: 1494
total_duration: 10423.676805046909
[2024-12-26 04:22:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.311241424998418
avg_train_sample_per_sec: 17.311241424998418
avg_episode_per_sec: 0.149234839870676
collect_time: 40.20508887334541
reward_mean: -156.1737861811391
reward_std: 5.589390072678601
reward_max: -150.9082633053221
reward_min: -165.70028011204477
queue_len: 0.10356351868775802
wait_time: 1.039791436026223
delay_time: 6.573959021719406
pressure: 1.2469053934571177
total_envstep_count: 174000
total_train_sample_count: 174000
total_episode_count: 1500
total_duration: 10463.881893920254
[2024-12-26 04:23:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.293510468819964
avg_train_sample_per_sec: 17.293510468819964
avg_episode_per_sec: 0.1490819868001721
collect_time: 40.24631096473336
reward_mean: -157.35679271708682
reward_std: 4.698618300592062
reward_max: -150.5
reward_min: -165.29621848739492
queue_len: 0.10434800578056157
wait_time: 1.046243950719103
delay_time: 6.5871612762847285
pressure: 1.2679045092838195
total_envstep_count: 174696
total_train_sample_count: 174696
total_episode_count: 1506
total_duration: 10504.128204884988
[2024-12-26 04:23:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.467324088141098
avg_train_sample_per_sec: 17.467324088141098
avg_episode_per_sec: 0.15058038007018187
collect_time: 39.84582850171812
reward_mean: -151.3232959850607
reward_std: 8.382263632722808
reward_max: -140.35994397759112
reward_min: -164.44117647058832
queue_len: 0.10034701325269278
wait_time: 1.0053601458266774
delay_time: 6.1853858395209365
pressure: 1.2158488063660478
total_envstep_count: 175392
total_train_sample_count: 175392
total_episode_count: 1512
total_duration: 10543.974033386707
[2024-12-26 04:24:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.3447052955889
avg_train_sample_per_sec: 17.3447052955889
avg_episode_per_sec: 0.1495233215136974
collect_time: 40.127519501700995
reward_mean: -150.31605975723622
reward_std: 6.098881076157449
reward_max: -140.49369747899155
reward_min: -158.55672268907566
queue_len: 0.09967908471965269
wait_time: 0.9907212885154063
delay_time: 6.4227003348215925
pressure: 1.2093280282935455
total_envstep_count: 176088
total_train_sample_count: 176088
total_episode_count: 1518
total_duration: 10584.101552888407
[2024-12-26 04:25:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.343308190462174
avg_train_sample_per_sec: 17.343308190462174
avg_episode_per_sec: 0.14951127750398427
collect_time: 40.13075200859085
reward_mean: -152.20039682539684
reward_std: 7.790085981772029
reward_max: -142.70868347338939
reward_min: -163.4383753501401
queue_len: 0.1009286451096796
wait_time: 0.9973885000507717
delay_time: 6.4273629602706075
pressure: 1.221816976127321
total_envstep_count: 176784
total_train_sample_count: 176784
total_episode_count: 1524
total_duration: 10624.232304896997
[2024-12-26 04:25:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.183869614676617
avg_train_sample_per_sec: 17.183869614676617
avg_episode_per_sec: 0.14813680702307427
collect_time: 40.50310061742738
reward_mean: -157.10294117647058
reward_std: 4.659601912690821
reward_max: -150.54691876750707
reward_min: -162.25210084033614
queue_len: 0.10417966921516618
wait_time: 1.032885767038911
delay_time: 6.637942423481104
pressure: 1.2418213969938108
total_envstep_count: 177480
total_train_sample_count: 177480
total_episode_count: 1530
total_duration: 10664.735405514424
[2024-12-26 04:26:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.4395159885726
avg_train_sample_per_sec: 17.4395159885726
avg_episode_per_sec: 0.15034065507390174
collect_time: 39.90936448328384
reward_mean: -152.32166199813256
reward_std: 5.812106934403574
reward_max: -144.2885154061624
reward_min: -159.26050420168065
queue_len: 0.10100905968045927
wait_time: 1.0052572089843894
delay_time: 6.439491997086951
pressure: 1.2095490716180373
total_envstep_count: 178176
total_train_sample_count: 178176
total_episode_count: 1536
total_duration: 10704.644769997709
[2024-12-26 04:27:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47560221061705
avg_train_sample_per_sec: 17.47560221061705
avg_episode_per_sec: 0.15065174319497457
collect_time: 39.82695369302668
reward_mean: -152.7391456582633
reward_std: 6.220726846457828
reward_max: -144.5994397759103
reward_min: -163.39985994397756
queue_len: 0.10128590560892792
wait_time: 1.0093689553628697
delay_time: 6.514744079035491
pressure: 1.2224801061007957
total_envstep_count: 178872
total_train_sample_count: 178872
total_episode_count: 1542
total_duration: 10744.471723690736
[2024-12-26 04:27:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.421941028985966
avg_train_sample_per_sec: 17.421941028985966
avg_episode_per_sec: 0.15018914680160317
collect_time: 39.94962437549418
reward_mean: -147.78244631185808
reward_std: 4.794660994264849
reward_max: -140.8165266106443
reward_min: -154.05532212885151
queue_len: 0.09799896970282367
wait_time: 0.9776267934229393
delay_time: 6.34524027827536
pressure: 1.1795977011494252
total_envstep_count: 179568
total_train_sample_count: 179568
total_episode_count: 1548
total_duration: 10784.421348066231
[2024-12-26 04:28:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.574296462878387
avg_train_sample_per_sec: 17.574296462878387
avg_episode_per_sec: 0.15150255571446886
collect_time: 39.60329231216385
reward_mean: -149.8872549019608
reward_std: 4.5250288694703995
reward_max: -144.21498599439772
reward_min: -155.63585434173672
queue_len: 0.09939473136734801
wait_time: 0.9966888391077031
delay_time: 6.217745404595199
pressure: 1.1983863837312112
total_envstep_count: 180264
total_train_sample_count: 180264
total_episode_count: 1554
total_duration: 10824.024640378395
[2024-12-26 04:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.490311404019614
avg_train_sample_per_sec: 17.490311404019614
avg_episode_per_sec: 0.150778546586376
collect_time: 39.79345958586224
reward_mean: -148.72724089635852
reward_std: 4.926946953935452
reward_max: -141.69467787114846
reward_min: -155.86274509803923
queue_len: 0.09862549131058257
wait_time: 0.9952310831494401
delay_time: 6.168766460792461
pressure: 1.184239610963749
total_envstep_count: 180960
total_train_sample_count: 180960
total_episode_count: 1560
total_duration: 10863.818099964257
[2024-12-26 04:29:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.44733470084195
avg_train_sample_per_sec: 17.44733470084195
avg_episode_per_sec: 0.15040805776587887
collect_time: 39.89147981246748
reward_mean: -151.01237161531276
reward_std: 6.979484497763898
reward_max: -138.00140056022408
reward_min: -158.54831932773112
queue_len: 0.10014082998362916
wait_time: 0.9967040861437413
delay_time: 6.436621999735507
pressure: 1.2060123784261714
total_envstep_count: 181656
total_train_sample_count: 181656
total_episode_count: 1566
total_duration: 10903.709579776725
[2024-12-26 04:30:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.443083618436184
avg_train_sample_per_sec: 17.443083618436184
avg_episode_per_sec: 0.1503714105037602
collect_time: 39.90120183018409
reward_mean: -150.3260971055089
reward_std: 4.206575146190366
reward_max: -145.0273109243698
reward_min: -157.59873949579827
queue_len: 0.09968574078614646
wait_time: 0.9913989689598207
delay_time: 6.319742720738
pressure: 1.2066755083996463
total_envstep_count: 182352
total_train_sample_count: 182352
total_episode_count: 1572
total_duration: 10943.610781606909
[2024-12-26 04:31:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.381949712373466
avg_train_sample_per_sec: 17.381949712373466
avg_episode_per_sec: 0.14984439407218506
collect_time: 40.04153800448216
reward_mean: -149.46043417366946
reward_std: 6.460558748521442
reward_max: -143.3606442577031
reward_min: -159.7121848739496
queue_len: 0.09911169374911767
wait_time: 0.9827600138198515
delay_time: 6.465213998552765
pressure: 1.1849027409372237
total_envstep_count: 183048
total_train_sample_count: 183048
total_episode_count: 1578
total_duration: 10983.65231961139
[2024-12-26 04:32:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.282048521430266
avg_train_sample_per_sec: 17.282048521430266
avg_episode_per_sec: 0.1489831769088816
collect_time: 40.273003465818235
reward_mean: -149.51178804855275
reward_std: 7.0946455580546885
reward_max: -136.87394957983193
reward_min: -159.69957983193277
queue_len: 0.09914574804280686
wait_time: 0.9945381556689874
delay_time: 6.281051240230838
pressure: 1.187997347480106
total_envstep_count: 183744
total_train_sample_count: 183744
total_episode_count: 1584
total_duration: 11023.925323077208
[2024-12-26 04:32:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.242074251265596
avg_train_sample_per_sec: 17.242074251265596
avg_episode_per_sec: 0.14863857113159995
collect_time: 40.366372969824816
reward_mean: -147.45308123249296
reward_std: 3.709636230901198
reward_max: -141.33613445378148
reward_min: -152.14775910364136
queue_len: 0.09778055784648072
wait_time: 0.9725708917519262
delay_time: 6.2870944129936746
pressure: 1.1811450044208665
total_envstep_count: 184440
total_train_sample_count: 184440
total_episode_count: 1590
total_duration: 11064.291696047034
[2024-12-26 04:33:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.275027321486427
avg_train_sample_per_sec: 17.275027321486427
avg_episode_per_sec: 0.14892264932315885
collect_time: 40.28937188043259
reward_mean: -149.15919701213818
reward_std: 6.716524607011215
reward_max: -136.49159663865544
reward_min: -157.76540616246498
queue_len: 0.09891193435818181
wait_time: 0.9869021768742865
delay_time: 6.378722613339728
pressure: 1.1882183908045978
total_envstep_count: 185136
total_train_sample_count: 185136
total_episode_count: 1596
total_duration: 11104.581067927467
[2024-12-26 04:34:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.485405047680345
avg_train_sample_per_sec: 17.485405047680345
avg_episode_per_sec: 0.15073625041103744
collect_time: 39.804625520661475
reward_mean: -147.52205882352942
reward_std: 6.416983907572683
reward_max: -139.54901960784315
reward_min: -157.95378151260502
queue_len: 0.0978262989545951
wait_time: 0.9623580090745404
delay_time: 6.1836140611576065
pressure: 1.1868921308576479
total_envstep_count: 185832
total_train_sample_count: 185832
total_episode_count: 1602
total_duration: 11144.385693448128
[2024-12-26 04:34:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.48089806206538
avg_train_sample_per_sec: 17.48089806206538
avg_episode_per_sec: 0.1506973970867705
collect_time: 39.81488808692059
reward_mean: -146.2329598506069
reward_std: 4.017975103827409
reward_max: -141.27661064425774
reward_min: -151.4481792717087
queue_len: 0.09697145878687462
wait_time: 0.955651635101432
delay_time: 6.262933171161415
pressure: 1.160366931918656
total_envstep_count: 186528
total_train_sample_count: 186528
total_episode_count: 1608
total_duration: 11184.20058153505
[2024-12-26 04:35:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.170106283716116
avg_train_sample_per_sec: 17.170106283716116
avg_episode_per_sec: 0.14801815761824236
collect_time: 40.53556736920589
reward_mean: -148.43790849673204
reward_std: 1.4464309964800413
reward_max: -146.29901960784315
reward_min: -150.95098039215685
queue_len: 0.09843362632409286
wait_time: 0.9773055995165526
delay_time: 6.16713558104059
pressure: 1.1892130857648098
total_envstep_count: 187224
total_train_sample_count: 187224
total_episode_count: 1614
total_duration: 11224.736148904256
[2024-12-26 04:36:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.389078460846356
avg_train_sample_per_sec: 17.389078460846356
avg_episode_per_sec: 0.14990584880039962
collect_time: 40.025122755477206
reward_mean: -144.80648926237163
reward_std: 3.2721161972037307
reward_max: -139.96428571428567
reward_min: -148.87535014005604
queue_len: 0.09602552338353558
wait_time: 0.9513679145398214
delay_time: 5.9843984831497385
pressure: 1.1643457117595049
total_envstep_count: 187920
total_train_sample_count: 187920
total_episode_count: 1620
total_duration: 11264.761271659732
[2024-12-26 04:36:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.534858639214637
avg_train_sample_per_sec: 17.534858639214637
avg_episode_per_sec: 0.15116257447598824
collect_time: 39.69236446785367
reward_mean: -143.42308590102706
reward_std: 3.8658149969621447
reward_max: -138.59173669467788
reward_min: -150.17997198879553
queue_len: 0.09510814714922218
wait_time: 0.9480128700463384
delay_time: 5.773643061762583
pressure: 1.1568302387267906
total_envstep_count: 188616
total_train_sample_count: 188616
total_episode_count: 1626
total_duration: 11304.453636127586
[2024-12-26 04:37:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.22593917699512
avg_train_sample_per_sec: 17.22593917699512
avg_episode_per_sec: 0.14849947566375102
collect_time: 40.40418306651712
reward_mean: -148.18662464985994
reward_std: 5.641322203485672
reward_max: -141.43627450980387
reward_min: -158.4040616246499
queue_len: 0.09826699247338193
wait_time: 0.969509023768659
delay_time: 6.206627110406878
pressure: 1.1929708222811672
total_envstep_count: 189312
total_train_sample_count: 189312
total_episode_count: 1632
total_duration: 11344.857819194103
[2024-12-26 04:38:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.384341474752034
avg_train_sample_per_sec: 17.384341474752034
avg_episode_per_sec: 0.14986501271337963
collect_time: 40.03602903284132
reward_mean: -144.24007936507937
reward_std: 2.55748638787585
reward_max: -139.15196078431373
reward_min: -146.8634453781512
queue_len: 0.09564992000336826
wait_time: 0.9382805398905805
delay_time: 5.9652159131779525
pressure: 1.1436781609195403
total_envstep_count: 190008
total_train_sample_count: 190008
total_episode_count: 1638
total_duration: 11384.893848226944
[2024-12-26 04:38:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.375743200036585
avg_train_sample_per_sec: 17.375743200036585
avg_episode_per_sec: 0.14979088965548779
collect_time: 40.05584060418979
reward_mean: -146.27415966386556
reward_std: 4.689001999689368
reward_max: -140.75490196078425
reward_min: -155.48739495798318
queue_len: 0.09699877961794796
wait_time: 0.939495272025698
delay_time: 6.2800715234306805
pressure: 1.1546198054818746
total_envstep_count: 190704
total_train_sample_count: 190704
total_episode_count: 1644
total_duration: 11424.949688831133
[2024-12-26 04:39:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.70433751208444
avg_train_sample_per_sec: 17.70433751208444
avg_episode_per_sec: 0.15262359924210725
collect_time: 39.312400112397974
reward_mean: -145.499649859944
reward_std: 5.807267195657759
reward_max: -139.953081232493
reward_min: -157.11484593837542
queue_len: 0.09648517895221749
wait_time: 0.9504253845658512
delay_time: 5.972582796104039
pressure: 1.1624668435013263
total_envstep_count: 191400
total_train_sample_count: 191400
total_episode_count: 1650
total_duration: 11464.262088943531
[2024-12-26 04:40:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.255635853784916
avg_train_sample_per_sec: 17.255635853784916
avg_episode_per_sec: 0.14875548149814583
collect_time: 40.334648105554265
reward_mean: -150.8403361344538
reward_std: 5.261156292457419
reward_max: -144.02450980392157
reward_min: -156.8487394957983
queue_len: 0.10002674809977041
wait_time: 0.9918080848608232
delay_time: 6.417653249123508
pressure: 1.208112290008842
total_envstep_count: 192096
total_train_sample_count: 192096
total_episode_count: 1656
total_duration: 11504.596737049085
[2024-12-26 04:40:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.34147307846336
avg_train_sample_per_sec: 17.34147307846336
avg_episode_per_sec: 0.14949545757295998
collect_time: 40.134998731127006
reward_mean: -145.51937441643324
reward_std: 5.037220940984603
reward_max: -138.9019607843137
reward_min: -155.44607843137257
queue_len: 0.09649825889683904
wait_time: 0.9506725103834638
delay_time: 6.196335009896834
pressure: 1.1630194518125554
total_envstep_count: 192792
total_train_sample_count: 192792
total_episode_count: 1662
total_duration: 11544.731735780213
[2024-12-26 04:41:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.473193265829448
avg_train_sample_per_sec: 17.473193265829448
avg_episode_per_sec: 0.15063097642956422
collect_time: 39.83244444283098
reward_mean: -143.41608309990661
reward_std: 4.800549537101417
reward_max: -137.66666666666669
reward_min: -149.77521008403363
queue_len: 0.09510350338190095
wait_time: 0.9363213344577442
delay_time: 6.067129628417867
pressure: 1.1408045977011494
total_envstep_count: 193488
total_train_sample_count: 193488
total_episode_count: 1668
total_duration: 11584.564180223044
[2024-12-26 04:42:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.31296045513299
avg_train_sample_per_sec: 17.31296045513299
avg_episode_per_sec: 0.14924965909597407
collect_time: 40.201096849016835
reward_mean: -147.25746965452848
reward_std: 5.775108819299776
reward_max: -137.93977591036418
reward_min: -154.49929971988792
queue_len: 0.0976508419459738
wait_time: 0.9630822045882899
delay_time: 6.236296690738061
pressure: 1.1841290893015033
total_envstep_count: 194184
total_train_sample_count: 194184
total_episode_count: 1674
total_duration: 11624.765277072062
[2024-12-26 04:42:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.538925430127136
avg_train_sample_per_sec: 17.538925430127136
avg_episode_per_sec: 0.15119763301833736
collect_time: 39.6831609081626
reward_mean: -142.250116713352
reward_std: 3.1221499966452697
reward_max: -139.13235294117646
reward_min: -147.37254901960782
queue_len: 0.09433031612291247
wait_time: 0.9279917316174923
delay_time: 5.917614806547867
pressure: 1.132294429708223
total_envstep_count: 194880
total_train_sample_count: 194880
total_episode_count: 1680
total_duration: 11664.448437980223
[2024-12-26 04:43:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.537039558008072
avg_train_sample_per_sec: 17.537039558008072
avg_episode_per_sec: 0.15118137550006958
collect_time: 39.68742829699442
reward_mean: -142.34010270774976
reward_std: 4.353730678711282
reward_max: -134.91946778711483
reward_min: -148.5035014005602
queue_len: 0.09438998853299056
wait_time: 0.9294391938915266
delay_time: 5.812750872819646
pressure: 1.1426834659593281
total_envstep_count: 195576
total_train_sample_count: 195576
total_episode_count: 1686
total_duration: 11704.135866277218
[2024-12-26 04:44:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.450261901150085
avg_train_sample_per_sec: 17.450261901150085
avg_episode_per_sec: 0.15043329225129382
collect_time: 39.88478820218332
reward_mean: -143.80450513538747
reward_std: 3.645679570641239
reward_max: -137.22128851540617
reward_min: -148.49369747899163
queue_len: 0.0953610776759864
wait_time: 0.9310828553348837
delay_time: 6.026602432538749
pressure: 1.1462201591511936
total_envstep_count: 196272
total_train_sample_count: 196272
total_episode_count: 1692
total_duration: 11744.020654479402
[2024-12-26 04:44:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.276978556213994
avg_train_sample_per_sec: 17.276978556213994
avg_episode_per_sec: 0.1489394703121896
collect_time: 40.28482166227325
reward_mean: -142.41211484593836
reward_std: 3.3206436410609146
reward_max: -136.16106442577026
reward_min: -145.9082633053221
queue_len: 0.09443774194027743
wait_time: 0.9321041745610712
delay_time: 5.8917050748901
pressure: 1.1362732095490717
total_envstep_count: 196968
total_train_sample_count: 196968
total_episode_count: 1698
total_duration: 11784.305476141675
[2024-12-26 04:45:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33637878544023
avg_train_sample_per_sec: 17.33637878544023
avg_episode_per_sec: 0.14945154125379506
collect_time: 40.14679239614493
reward_mean: -141.23856209150327
reward_std: 4.434019197921449
reward_max: -133.25350140056025
reward_min: -147.60364145658264
queue_len: 0.09365952393335762
wait_time: 0.9155692670525326
delay_time: 5.861327251224139
pressure: 1.1261052166224579
total_envstep_count: 197664
total_train_sample_count: 197664
total_episode_count: 1704
total_duration: 11824.45226853782
[2024-12-26 04:46:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.340859490121584
avg_train_sample_per_sec: 17.340859490121584
avg_episode_per_sec: 0.14949016801828952
collect_time: 40.136418866463
reward_mean: -141.26949112978522
reward_std: 2.294874356925709
reward_max: -136.79551820728284
reward_min: -144.5301120448179
queue_len: 0.09368003390569313
wait_time: 0.9145274378540101
delay_time: 5.855120677014683
pressure: 1.1358311229000886
total_envstep_count: 198360
total_train_sample_count: 198360
total_episode_count: 1710
total_duration: 11864.588687404283
[2024-12-26 04:46:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.5033163041632
avg_train_sample_per_sec: 17.5033163041632
avg_episode_per_sec: 0.15089065779451033
collect_time: 39.76389319059812
reward_mean: -140.7750933706816
reward_std: 4.665512725935277
reward_max: -134.78711484593842
reward_min: -147.34873949579833
queue_len: 0.09335218393281274
wait_time: 0.9086128262091752
delay_time: 5.930779945177651
pressure: 1.1158267020335986
total_envstep_count: 199056
total_train_sample_count: 199056
total_episode_count: 1716
total_duration: 11904.352580594881
[2024-12-26 04:47:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.376352688833776
avg_train_sample_per_sec: 17.376352688833776
avg_episode_per_sec: 0.1497961438692567
collect_time: 40.05443561509066
reward_mean: -140.99824929971984
reward_std: 4.196297219377675
reward_max: -136.43907563025215
reward_min: -147.25210084033608
queue_len: 0.09350016531811663
wait_time: 0.9191808022943926
delay_time: 5.802704150415486
pressure: 1.1300839964633067
total_envstep_count: 199752
total_train_sample_count: 199752
total_episode_count: 1722
total_duration: 11944.407016209972
[2024-12-26 04:48:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.390740423962622
avg_train_sample_per_sec: 17.390740423962622
avg_episode_per_sec: 0.1499201760686433
collect_time: 40.021297715477644
reward_mean: -143.33076563958915
reward_std: 5.646115234575353
reward_max: -135.53291316526608
reward_min: -149.15476190476193
queue_len: 0.09504692681670368
wait_time: 0.9246533272902441
delay_time: 5.985993678038671
pressure: 1.1385941644562336
total_envstep_count: 200448
total_train_sample_count: 200448
total_episode_count: 1728
total_duration: 11984.42831392545
[2024-12-26 04:48:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.50037651378123
avg_train_sample_per_sec: 17.50037651378123
avg_episode_per_sec: 0.1508653147739761
collect_time: 39.7705729046408
reward_mean: -141.09967320261438
reward_std: 4.942793547142025
reward_max: -130.88445378151258
reward_min: -147.0119047619048
queue_len: 0.09356742254815277
wait_time: 0.9008843590486592
delay_time: 5.932704112173531
pressure: 1.1204686118479221
total_envstep_count: 201144
total_train_sample_count: 201144
total_episode_count: 1734
total_duration: 12024.19888683009
[2024-12-26 04:49:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.553167174567147
avg_train_sample_per_sec: 17.553167174567147
avg_episode_per_sec: 0.15132040667730298
collect_time: 39.650964015681296
reward_mean: -141.26995798319328
reward_std: 6.750548899138923
reward_max: -131.04271708683478
reward_min: -153.4005602240896
queue_len: 0.09368034349018121
wait_time: 0.9233933958198665
delay_time: 5.901487996313153
pressure: 1.125
total_envstep_count: 201840
total_train_sample_count: 201840
total_episode_count: 1740
total_duration: 12063.849850845772
[2024-12-26 04:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.62444808084736
avg_train_sample_per_sec: 17.62444808084736
avg_episode_per_sec: 0.15193489724868411
collect_time: 39.49059833291173
reward_mean: -139.6276844070962
reward_std: 4.111374370416315
reward_max: -134.09103641456582
reward_min: -144.81862745098044
queue_len: 0.0925913026572256
wait_time: 0.9053216335163596
delay_time: 5.840690552448682
pressure: 1.1217948717948716
total_envstep_count: 202536
total_train_sample_count: 202536
total_episode_count: 1746
total_duration: 12103.340449178684
[2024-12-26 04:50:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.61315985796729
avg_train_sample_per_sec: 17.61315985796729
avg_episode_per_sec: 0.15183758498247663
collect_time: 39.515907742423934
reward_mean: -141.28489729225024
reward_std: 4.815762150772471
reward_max: -131.7471988795518
reward_min: -146.1484593837535
queue_len: 0.09369025019379988
wait_time: 0.9195896086109068
delay_time: 5.872833574314576
pressure: 1.124889478337754
total_envstep_count: 203232
total_train_sample_count: 203232
total_episode_count: 1752
total_duration: 12142.856356921107
[2024-12-26 04:51:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.402400164591704
avg_train_sample_per_sec: 17.402400164591704
avg_episode_per_sec: 0.1500206910740664
collect_time: 39.99448314124718
reward_mean: -140.88060224089637
reward_std: 3.065083405885881
reward_max: -136.23809523809524
reward_min: -146.01260504201684
queue_len: 0.09342215002711961
wait_time: 0.9134327471041467
delay_time: 5.847214955808336
pressure: 1.119916003536693
total_envstep_count: 203928
total_train_sample_count: 203928
total_episode_count: 1758
total_duration: 12182.850840062354
[2024-12-26 04:52:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.428183347260063
avg_train_sample_per_sec: 17.428183347260063
avg_episode_per_sec: 0.15024295989017297
collect_time: 39.93531546759979
reward_mean: -141.63258636788052
reward_std: 6.112885043710827
reward_max: -132.89915966386553
reward_min: -150.86904761904756
queue_len: 0.09392081324130007
wait_time: 0.9128808353580159
delay_time: 5.967000500375586
pressure: 1.1160477453580901
total_envstep_count: 204624
total_train_sample_count: 204624
total_episode_count: 1764
total_duration: 12222.786155529953
[2024-12-26 04:53:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.227688503486007
avg_train_sample_per_sec: 17.227688503486007
avg_episode_per_sec: 0.14851455606453454
collect_time: 40.40008036244474
reward_mean: -145.17612044817926
reward_std: 2.687290744527818
reward_max: -141.48319327731085
reward_min: -148.18347338935573
queue_len: 0.09627063690197563
wait_time: 0.9440429133634002
delay_time: 6.203725007644248
pressure: 1.150419982316534
total_envstep_count: 205320
total_train_sample_count: 205320
total_episode_count: 1770
total_duration: 12263.186235892397
[2024-12-26 04:53:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.593446125051816
avg_train_sample_per_sec: 17.593446125051816
avg_episode_per_sec: 0.15166763900906738
collect_time: 39.56018593815713
reward_mean: -142.9558823529412
reward_std: 4.2562461226231
reward_max: -138.43417366946778
reward_min: -150.1134453781513
queue_len: 0.09479833047277265
wait_time: 0.9233663071771591
delay_time: 6.170131031639131
pressure: 1.110632183908046
total_envstep_count: 206016
total_train_sample_count: 206016
total_episode_count: 1776
total_duration: 12302.746421830554
[2024-12-26 04:54:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.505007369349702
avg_train_sample_per_sec: 17.505007369349702
avg_episode_per_sec: 0.15090523594266983
collect_time: 39.76005181344039
reward_mean: -143.80707282913164
reward_std: 4.147800163956061
reward_max: -138.05112044817926
reward_min: -150.80532212885151
queue_len: 0.09536278039067086
wait_time: 0.9460225513724502
delay_time: 5.857518459262416
pressure: 1.1602564102564104
total_envstep_count: 206712
total_train_sample_count: 206712
total_episode_count: 1782
total_duration: 12342.506473643994
[2024-12-26 04:55:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.372820697404354
avg_train_sample_per_sec: 17.372820697404354
avg_episode_per_sec: 0.14976569566727893
collect_time: 40.06257890545018
reward_mean: -145.1189309056956
reward_std: 3.574654088397813
reward_max: -140.4075630252101
reward_min: -149.5896358543417
queue_len: 0.09623271280218541
wait_time: 0.9442329208429614
delay_time: 6.025994142066001
pressure: 1.1635720601237842
total_envstep_count: 207408
total_train_sample_count: 207408
total_episode_count: 1788
total_duration: 12382.569052549445
[2024-12-26 04:55:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39330718811264
avg_train_sample_per_sec: 17.39330718811264
avg_episode_per_sec: 0.14994230334579864
collect_time: 40.01539169478231
reward_mean: -141.5455182072829
reward_std: 2.41178775022041
reward_max: -137.4740896358543
reward_min: -144.57142857142864
queue_len: 0.09386307573427248
wait_time: 0.9172211324848242
delay_time: 5.9373522373000585
pressure: 1.124557913351017
total_envstep_count: 208104
total_train_sample_count: 208104
total_episode_count: 1794
total_duration: 12422.584444244227
[2024-12-26 04:56:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.417656157040184
avg_train_sample_per_sec: 17.417656157040184
avg_episode_per_sec: 0.15015220825034642
collect_time: 39.959452277893206
reward_mean: -138.50385154061624
reward_std: 2.5935269766648865
reward_max: -135.375350140056
reward_min: -142.16596638655457
queue_len: 0.09184605539828665
wait_time: 0.891477402189877
delay_time: 5.8492801296791574
pressure: 1.1003536693191864
total_envstep_count: 208800
total_train_sample_count: 208800
total_episode_count: 1800
total_duration: 12462.54389652212
[2024-12-26 04:57:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45329359363478
avg_train_sample_per_sec: 17.45329359363478
avg_episode_per_sec: 0.1504594275313343
collect_time: 39.87786008789948
reward_mean: -142.81512605042016
reward_std: 2.632300033075776
reward_max: -139.6792717086835
reward_min: -147.42997198879553
queue_len: 0.09470499074961548
wait_time: 0.9303969709015347
delay_time: 5.90710917490656
pressure: 1.1492042440318302
total_envstep_count: 209496
total_train_sample_count: 209496
total_episode_count: 1806
total_duration: 12502.42175661002
[2024-12-26 04:57:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.406328484060968
avg_train_sample_per_sec: 17.406328484060968
avg_episode_per_sec: 0.1500545558970773
collect_time: 39.98545705013722
reward_mean: -140.69514472455649
reward_std: 2.3940348370004085
reward_max: -136.85364145658266
reward_min: -144.9278711484593
queue_len: 0.09329916758922845
wait_time: 0.9215404552625648
delay_time: 5.748870006618212
pressure: 1.1311892130857648
total_envstep_count: 210192
total_train_sample_count: 210192
total_episode_count: 1812
total_duration: 12542.407213660157
[2024-12-26 04:58:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.530994741682896
avg_train_sample_per_sec: 17.530994741682896
avg_episode_per_sec: 0.1511292650145077
collect_time: 39.70111281507276
reward_mean: -143.83893557422968
reward_std: 4.29965493477342
reward_max: -138.4530812324929
reward_min: -151.79131652661064
queue_len: 0.09538390953198254
wait_time: 0.932852749853257
delay_time: 5.960373585464944
pressure: 1.1503094606542883
total_envstep_count: 210888
total_train_sample_count: 210888
total_episode_count: 1818
total_duration: 12582.10832647523
[2024-12-26 04:59:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.36928218998045
avg_train_sample_per_sec: 17.36928218998045
avg_episode_per_sec: 0.14973519129293492
collect_time: 40.070740539956844
reward_mean: -140.51972455648925
reward_std: 1.8671627873365158
reward_max: -137.406862745098
reward_min: -143.63235294117646
queue_len: 0.09318284121783105
wait_time: 0.9095849988978791
delay_time: 5.934907729158567
pressure: 1.1191423519009727
total_envstep_count: 211584
total_train_sample_count: 211584
total_episode_count: 1824
total_duration: 12622.179067015188
[2024-12-26 04:59:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.359892599813126
avg_train_sample_per_sec: 17.359892599813126
avg_episode_per_sec: 0.14965424655011317
collect_time: 40.09241393621826
reward_mean: -135.96697012138188
reward_std: 3.158106357331662
reward_max: -131.52731092436971
reward_min: -139.57563025210084
queue_len: 0.09016377329004104
wait_time: 0.8843308764708357
delay_time: 5.575375195068045
pressure: 1.0904067197170646
total_envstep_count: 212280
total_train_sample_count: 212280
total_episode_count: 1830
total_duration: 12662.271480951405
[2024-12-26 05:00:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.3958310003902
avg_train_sample_per_sec: 17.3958310003902
avg_episode_per_sec: 0.14996406034819137
collect_time: 40.009586203981186
reward_mean: -140.76960784313727
reward_std: 3.0859116389691716
reward_max: -136.68207282913167
reward_min: -145.46918767507
queue_len: 0.09334854631507776
wait_time: 0.9150970733120835
delay_time: 5.937541501250898
pressure: 1.1262157382847038
total_envstep_count: 212976
total_train_sample_count: 212976
total_episode_count: 1836
total_duration: 12702.281067155387
[2024-12-26 05:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.569279535871832
avg_train_sample_per_sec: 17.569279535871832
avg_episode_per_sec: 0.15145930634372268
collect_time: 39.614601075641815
reward_mean: -140.26318860877686
reward_std: 1.570653121366673
reward_max: -138.08473389355737
reward_min: -142.53291316526614
queue_len: 0.09301272454162923
wait_time: 0.9037836177795612
delay_time: 5.944682260289724
pressure: 1.1129531388152076
total_envstep_count: 213672
total_train_sample_count: 213672
total_episode_count: 1842
total_duration: 12741.895668231029
[2024-12-26 05:01:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.412979965170376
avg_train_sample_per_sec: 17.412979965170376
avg_episode_per_sec: 0.15011189625146876
collect_time: 39.97018324216455
reward_mean: -142.70611577964522
reward_std: 4.982492565230976
reward_max: -135.88795518207286
reward_min: -149.640056022409
queue_len: 0.094632702771648
wait_time: 0.9254737261836653
delay_time: 6.047792836241345
pressure: 1.1549513704686118
total_envstep_count: 214368
total_train_sample_count: 214368
total_episode_count: 1848
total_duration: 12781.865851473194
[2024-12-26 05:02:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74914425396076
avg_train_sample_per_sec: 17.74914425396076
avg_episode_per_sec: 0.15300986425828242
collect_time: 39.21315811294317
reward_mean: -138.89157329598507
reward_std: 4.7906785253461495
reward_max: -130.05672268907563
reward_min: -144.7051820728292
queue_len: 0.09210316531563996
wait_time: 0.8914051916080314
delay_time: 5.844293184894006
pressure: 1.099580017683466
total_envstep_count: 215064
total_train_sample_count: 215064
total_episode_count: 1854
total_duration: 12821.079009586138
[2024-12-26 05:03:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.42552010047504
avg_train_sample_per_sec: 17.42552010047504
avg_episode_per_sec: 0.15022000086616416
collect_time: 39.94141902146302
reward_mean: -138.70681605975724
reward_std: 5.880424793849847
reward_max: -131.359943977591
reward_min: -147.47128851540617
queue_len: 0.09198064725448092
wait_time: 0.9051310068678221
delay_time: 5.728325996357142
pressure: 1.1093059239610963
total_envstep_count: 215760
total_train_sample_count: 215760
total_episode_count: 1860
total_duration: 12861.0204286076
[2024-12-26 05:03:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.529780551221865
avg_train_sample_per_sec: 17.529780551221865
avg_episode_per_sec: 0.15111879785536092
collect_time: 39.703862690482296
reward_mean: -141.73062558356676
reward_std: 2.226844645487235
reward_max: -139.13025210084035
reward_min: -145.89915966386562
queue_len: 0.09398582598379761
wait_time: 0.9216063967585266
delay_time: 5.904545862056025
pressure: 1.1314102564102564
total_envstep_count: 216456
total_train_sample_count: 216456
total_episode_count: 1866
total_duration: 12900.724291298082
[2024-12-26 05:04:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.577224534764955
avg_train_sample_per_sec: 17.577224534764955
avg_episode_per_sec: 0.151527797713491
collect_time: 39.59669506544805
reward_mean: -138.42810457516336
reward_std: 5.514420718942357
reward_max: -133.15756302521004
reward_min: -146.24089635854332
queue_len: 0.0917958253150951
wait_time: 0.8979731813149662
delay_time: 5.687145991757774
pressure: 1.1104111405835544
total_envstep_count: 217152
total_train_sample_count: 217152
total_episode_count: 1872
total_duration: 12940.32098636353
[2024-12-26 05:05:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.53700248340092
avg_train_sample_per_sec: 17.53700248340092
avg_episode_per_sec: 0.15118105589138722
collect_time: 39.687512199349705
reward_mean: -139.70226423902895
reward_std: 3.8201684158921343
reward_max: -134.41106442577026
reward_min: -145.1519607843138
queue_len: 0.09264075877919692
wait_time: 0.9072571557358575
delay_time: 5.836227824482809
pressure: 1.1286472148541116
total_envstep_count: 217848
total_train_sample_count: 217848
total_episode_count: 1878
total_duration: 12980.008498562878
[2024-12-26 05:05:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60670241055331
avg_train_sample_per_sec: 17.60670241055331
avg_episode_per_sec: 0.15178191733235613
collect_time: 39.53040062645822
reward_mean: -137.03151260504202
reward_std: 4.991451956539264
reward_max: -130.13025210084032
reward_min: -142.61064425770311
queue_len: 0.0908697033189934
wait_time: 0.8928189865689866
delay_time: 5.684498375640783
pressure: 1.0994694960212201
total_envstep_count: 218544
total_train_sample_count: 218544
total_episode_count: 1884
total_duration: 13019.538899189336
[2024-12-26 05:06:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73594597203273
avg_train_sample_per_sec: 17.73594597203273
avg_episode_per_sec: 0.1528960859657994
collect_time: 39.24233875641598
reward_mean: -137.71031746031747
reward_std: 3.64328950105493
reward_max: -132.30322128851543
reward_min: -141.81092436974797
queue_len: 0.09131983916466675
wait_time: 0.8989933395993236
delay_time: 5.609708037179332
pressure: 1.1164898320070733
total_envstep_count: 219240
total_train_sample_count: 219240
total_episode_count: 1890
total_duration: 13058.781237945752
[2024-12-26 05:07:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.529007700312736
avg_train_sample_per_sec: 17.529007700312736
avg_episode_per_sec: 0.1511121353475236
collect_time: 39.70561322690175
reward_mean: -140.38970588235296
reward_std: 1.5163243682097627
reward_max: -138.71918767507003
reward_min: -143.4964985994398
queue_len: 0.09309662193789985
wait_time: 0.9149703758603356
delay_time: 5.785830607403276
pressure: 1.1312997347480105
total_envstep_count: 219936
total_train_sample_count: 219936
total_episode_count: 1896
total_duration: 13098.486851172654
[2024-12-26 05:07:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.487853101767076
avg_train_sample_per_sec: 17.487853101767076
avg_episode_per_sec: 0.15075735432557824
collect_time: 39.7990534315314
reward_mean: -141.09990662931844
reward_std: 5.331747945662339
reward_max: -134.3403361344538
reward_min: -149.01400560224093
queue_len: 0.09356757734039682
wait_time: 0.918269695145963
delay_time: 5.8183863751572
pressure: 1.1357206012378425
total_envstep_count: 220632
total_train_sample_count: 220632
total_episode_count: 1902
total_duration: 13138.285904604187
[2024-12-26 05:08:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.72310037673121
avg_train_sample_per_sec: 17.72310037673121
avg_episode_per_sec: 0.15278534807526906
collect_time: 39.27078136474268
reward_mean: -141.20016339869275
reward_std: 4.636572063008462
reward_max: -133.10084033613444
reward_min: -147.4103641456583
queue_len: 0.09363406060921271
wait_time: 0.9177788489401065
delay_time: 5.982001681514828
pressure: 1.1297524314765692
total_envstep_count: 221328
total_train_sample_count: 221328
total_episode_count: 1908
total_duration: 13177.55668596893
[2024-12-26 05:09:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.46125079180591
avg_train_sample_per_sec: 17.46125079180591
avg_episode_per_sec: 0.15052802406729232
collect_time: 39.859687504552305
reward_mean: -142.30415499533146
reward_std: 3.859970269061467
reward_max: -137.41526610644263
reward_min: -148.70098039215674
queue_len: 0.09436615052740811
wait_time: 0.9213495964256614
delay_time: 5.969135880923375
pressure: 1.133399646330681
total_envstep_count: 222024
total_train_sample_count: 222024
total_episode_count: 1914
total_duration: 13217.416373473481
[2024-12-26 05:09:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.582422375660798
avg_train_sample_per_sec: 17.582422375660798
avg_episode_per_sec: 0.15157260668673103
collect_time: 39.584989208510144
reward_mean: -140.37920168067225
reward_std: 2.147535435800716
reward_max: -136.21848739495798
reward_min: -142.77100840336135
queue_len: 0.09308965628691795
wait_time: 0.9089680744092509
delay_time: 5.928405738952896
pressure: 1.1274314765694076
total_envstep_count: 222720
total_train_sample_count: 222720
total_episode_count: 1920
total_duration: 13257.001362681991
[2024-12-26 05:10:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.487237406863507
avg_train_sample_per_sec: 17.487237406863507
avg_episode_per_sec: 0.1507520466108923
collect_time: 39.80045468627476
reward_mean: -139.89297385620912
reward_std: 5.170868021993634
reward_max: -132.7913165266106
reward_min: -147.99369747899166
queue_len: 0.09276722404257902
wait_time: 0.9088038398383226
delay_time: 5.799864284887913
pressure: 1.1065428824049512
total_envstep_count: 223416
total_train_sample_count: 223416
total_episode_count: 1926
total_duration: 13296.801817368265
[2024-12-26 05:11:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.573740055399774
avg_train_sample_per_sec: 17.573740055399774
avg_episode_per_sec: 0.15149775909827393
collect_time: 39.60454620393366
reward_mean: -142.27532679738562
reward_std: 4.621658181862824
reward_max: -136.86694677871145
reward_min: -149.72338935574226
queue_len: 0.09434703368526898
wait_time: 0.9257311456855067
delay_time: 5.88777319055913
pressure: 1.1452254641909814
total_envstep_count: 224112
total_train_sample_count: 224112
total_episode_count: 1932
total_duration: 13336.406363572198
[2024-12-26 05:11:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52018058525656
avg_train_sample_per_sec: 17.52018058525656
avg_episode_per_sec: 0.15103603952807382
collect_time: 39.72561793031358
reward_mean: -138.9160830999066
reward_std: 5.089552532670029
reward_max: -132.30672268907563
reward_min: -146.6673669467787
queue_len: 0.09211941850126433
wait_time: 0.9052366525743806
delay_time: 5.8017314164408065
pressure: 1.1091954022988506
total_envstep_count: 224808
total_train_sample_count: 224808
total_episode_count: 1938
total_duration: 13376.13198150251
[2024-12-26 05:12:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.49842763696345
avg_train_sample_per_sec: 17.49842763696345
avg_episode_per_sec: 0.15084851411175387
collect_time: 39.77500232819655
reward_mean: -139.2952847805789
reward_std: 3.959937322246717
reward_max: -133.3578431372549
reward_min: -144.21078431372547
queue_len: 0.09237087850171015
wait_time: 0.9063387733519579
delay_time: 5.761474148677462
pressure: 1.1246684350132627
total_envstep_count: 225504
total_train_sample_count: 225504
total_episode_count: 1944
total_duration: 13415.906983830708
[2024-12-26 05:13:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.525364840667276
avg_train_sample_per_sec: 17.525364840667276
avg_episode_per_sec: 0.15108073138506273
collect_time: 39.71386652019621
reward_mean: -137.32317927170868
reward_std: 2.732279804556588
reward_max: -133.5119047619048
reward_min: -142.64495798319325
queue_len: 0.09106311622792353
wait_time: 0.8917149308883591
delay_time: 5.645879443821703
pressure: 1.0991379310344827
total_envstep_count: 226200
total_train_sample_count: 226200
total_episode_count: 1950
total_duration: 13455.620850350904
[2024-12-26 05:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.671758013081206
avg_train_sample_per_sec: 17.671758013081206
avg_episode_per_sec: 0.15234274149207935
collect_time: 39.384876110503455
reward_mean: -139.53267973856205
reward_std: 4.616111682558205
reward_max: -130.0175070028011
reward_min: -144.07913165266106
queue_len: 0.09252830221390057
wait_time: 0.9037984778349891
delay_time: 5.809227081114655
pressure: 1.1068744473916887
total_envstep_count: 226896
total_train_sample_count: 226896
total_episode_count: 1956
total_duration: 13495.005726461408
[2024-12-26 05:14:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.473809635959793
avg_train_sample_per_sec: 17.473809635959793
avg_episode_per_sec: 0.15063628996517064
collect_time: 39.83103939553536
reward_mean: -139.9356909430439
reward_std: 5.271048259985614
reward_max: -133.58193277310932
reward_min: -147.15966386554624
queue_len: 0.09279555102323866
wait_time: 0.9148775779100324
delay_time: 5.7286567243811035
pressure: 1.129973474801061
total_envstep_count: 227592
total_train_sample_count: 227592
total_episode_count: 1962
total_duration: 13534.836765856944
[2024-12-26 05:15:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.494384722783852
avg_train_sample_per_sec: 17.494384722783852
avg_episode_per_sec: 0.15081366140330907
collect_time: 39.784194244543094
reward_mean: -138.36799719887952
reward_std: 1.2669163826857581
reward_max: -136.39005602240894
reward_min: -140.0203081232493
queue_len: 0.09175596631225434
wait_time: 0.8984504058033472
delay_time: 5.719186367615059
pressure: 1.1108532272325375
total_envstep_count: 228288
total_train_sample_count: 228288
total_episode_count: 1968
total_duration: 13574.620960101487
[2024-12-26 05:15:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60286555776075
avg_train_sample_per_sec: 17.60286555776075
avg_episode_per_sec: 0.15174884101517888
collect_time: 39.53901696949265
reward_mean: -138.15616246498604
reward_std: 4.525319788197508
reward_max: -130.82002801120453
reward_min: -144.71148459383755
queue_len: 0.09161549235078648
wait_time: 0.8972018515629062
delay_time: 5.699255785174738
pressure: 1.0988063660477454
total_envstep_count: 228984
total_train_sample_count: 228984
total_episode_count: 1974
total_duration: 13614.15997707098
[2024-12-26 05:16:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51346687829996
avg_train_sample_per_sec: 17.51346687829996
avg_episode_per_sec: 0.15097816274396517
collect_time: 39.740846563188356
reward_mean: -136.43639122315588
reward_std: 2.9799198750812246
reward_max: -133.43977591036415
reward_min: -142.12955182072827
queue_len: 0.09047506049280896
wait_time: 0.8849714067766806
delay_time: 5.622459488830583
pressure: 1.0938328912466841
total_envstep_count: 229680
total_train_sample_count: 229680
total_episode_count: 1980
total_duration: 13653.900823634169
[2024-12-26 05:17:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.658979401052303
avg_train_sample_per_sec: 17.658979401052303
avg_episode_per_sec: 0.15223258104355433
collect_time: 39.41337628824264
reward_mean: -136.18347338935573
reward_std: 3.97755330987752
reward_max: -129.89005602240894
reward_min: -142.69467787114849
queue_len: 0.09030734309638973
wait_time: 0.8845597368036516
delay_time: 5.592507096109183
pressure: 1.0916224580017684
total_envstep_count: 230376
total_train_sample_count: 230376
total_episode_count: 1986
total_duration: 13693.314199922412
[2024-12-26 05:17:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.425297627306225
avg_train_sample_per_sec: 17.425297627306225
avg_episode_per_sec: 0.15021808299401918
collect_time: 39.9419289636314
reward_mean: -135.63970588235296
reward_std: 4.606490904231328
reward_max: -131.6596638655462
reward_min: -144.18207282913167
queue_len: 0.08994675456389452
wait_time: 0.8762255675922005
delay_time: 5.6133135320137315
pressure: 1.0875331564986737
total_envstep_count: 231072
total_train_sample_count: 231072
total_episode_count: 1992
total_duration: 13733.256128886043
[2024-12-26 05:18:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.653793847150407
avg_train_sample_per_sec: 17.653793847150407
avg_episode_per_sec: 0.1521878779926759
collect_time: 39.42495341375843
reward_mean: -134.49859943977592
reward_std: 2.782607972778825
reward_max: -131.2766106442577
reward_min: -139.92296918767505
queue_len: 0.0891900526788965
wait_time: 0.8744763378384066
delay_time: 5.468212537880678
pressure: 1.0849911582670204
total_envstep_count: 231768
total_train_sample_count: 231768
total_episode_count: 1998
total_duration: 13772.681082299801
[2024-12-26 05:19:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65192311081305
avg_train_sample_per_sec: 17.65192311081305
avg_episode_per_sec: 0.15217175095528493
collect_time: 39.4291316379942
reward_mean: -136.984360410831
reward_std: 4.8102448812983685
reward_max: -127.57422969187672
reward_min: -142.07072829131653
queue_len: 0.09083843528569695
wait_time: 0.8849661438403832
delay_time: 5.699926871606457
pressure: 1.0863174182139699
total_envstep_count: 232464
total_train_sample_count: 232464
total_episode_count: 2004
total_duration: 13812.110213937796
[2024-12-26 05:19:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.455553750356042
avg_train_sample_per_sec: 17.455553750356042
avg_episode_per_sec: 0.15047891164100038
collect_time: 39.872696676025164
reward_mean: -137.76692343604108
reward_std: 6.998436296299746
reward_max: -131.24649859943978
reward_min: -147.515406162465
queue_len: 0.09135737628384688
wait_time: 0.8935412471796854
delay_time: 5.610676636315595
pressure: 1.096264367816092
total_envstep_count: 233160
total_train_sample_count: 233160
total_episode_count: 2010
total_duration: 13851.982910613822
[2024-12-26 05:20:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.535262286437327
avg_train_sample_per_sec: 17.535262286437327
avg_episode_per_sec: 0.15116605419342524
collect_time: 39.69145078247972
reward_mean: -140.76832399626517
reward_std: 5.2624535130828
reward_max: -131.62885154061627
reward_min: -148.87815126050424
queue_len: 0.09334769495773554
wait_time: 0.9202567631827266
delay_time: 5.820479840531043
pressure: 1.122236958443855
total_envstep_count: 233856
total_train_sample_count: 233856
total_episode_count: 2016
total_duration: 13891.674361396303
[2024-12-26 05:21:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.756728086685175
avg_train_sample_per_sec: 17.756728086685175
avg_episode_per_sec: 0.15307524212659632
collect_time: 39.19641031851433
reward_mean: -137.3041549953315
reward_std: 4.604215270345837
reward_max: -129.59383753501402
reward_min: -141.9131652661065
queue_len: 0.09105050066003413
wait_time: 0.8945751045776399
delay_time: 5.718059285920208
pressure: 1.0943854995579134
total_envstep_count: 234552
total_train_sample_count: 234552
total_episode_count: 2022
total_duration: 13930.870771714817
[2024-12-26 05:21:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.777203537180974
avg_train_sample_per_sec: 17.777203537180974
avg_episode_per_sec: 0.15325175463087048
collect_time: 39.15126462631301
reward_mean: -138.5396825396825
reward_std: 3.7379593397112703
reward_max: -133.81722689075627
reward_min: -144.41106442577026
queue_len: 0.09186981600774703
wait_time: 0.8998380408750593
delay_time: 5.830261517494615
pressure: 1.1138373121131744
total_envstep_count: 235248
total_train_sample_count: 235248
total_episode_count: 2028
total_duration: 13970.02203634113
[2024-12-26 05:22:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.422572042852586
avg_train_sample_per_sec: 17.422572042852586
avg_episode_per_sec: 0.1501945865763154
collect_time: 39.948177472770226
reward_mean: -137.7317927170868
reward_std: 2.8117424653779923
reward_max: -133.7156862745098
reward_min: -141.78361344537814
queue_len: 0.09133408005111858
wait_time: 0.8873233201326508
delay_time: 5.718804897037111
pressure: 1.0959328028293547
total_envstep_count: 235944
total_train_sample_count: 235944
total_episode_count: 2034
total_duration: 14009.9702138139
[2024-12-26 05:23:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.664160950669242
avg_train_sample_per_sec: 17.664160950669242
avg_episode_per_sec: 0.15227724957473485
collect_time: 39.40181489195674
reward_mean: -142.62103174603178
reward_std: 4.1743540141160524
reward_max: -139.1232492997199
reward_min: -151.12955182072838
queue_len: 0.09457628099869482
wait_time: 0.9220217817454124
delay_time: 6.005362406659589
pressure: 1.1284261715296198
total_envstep_count: 236640
total_train_sample_count: 236640
total_episode_count: 2040
total_duration: 14049.372028705857
[2024-12-26 05:23:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.672729055182273
avg_train_sample_per_sec: 17.672729055182273
avg_episode_per_sec: 0.15235111254467476
collect_time: 39.38271207727864
reward_mean: -136.99416433239963
reward_std: 4.952416313935838
reward_max: -128.11064425770306
reward_min: -142.72408963585437
queue_len: 0.0908449365599467
wait_time: 0.8800018791778424
delay_time: 5.661895218061875
pressure: 1.1001326259946949
total_envstep_count: 237336
total_train_sample_count: 237336
total_episode_count: 2046
total_duration: 14088.754740783135
[2024-12-26 05:24:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.46044199727893
avg_train_sample_per_sec: 17.46044199727893
avg_episode_per_sec: 0.15052105170068045
collect_time: 39.86153386658058
reward_mean: -139.968370681606
reward_std: 3.5060362500652866
reward_max: -133.71498599439778
reward_min: -143.82703081232492
queue_len: 0.09281722193740449
wait_time: 0.9049598066459121
delay_time: 5.838802232199391
pressure: 1.1109637488947834
total_envstep_count: 238032
total_train_sample_count: 238032
total_episode_count: 2052
total_duration: 14128.616274649716
[2024-12-26 05:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39917341123389
avg_train_sample_per_sec: 17.39917341123389
avg_episode_per_sec: 0.1499928742347749
collect_time: 40.0019002943337
reward_mean: -138.32317927170868
reward_std: 3.807753490617758
reward_max: -133.41386554621843
reward_min: -143.50770308123245
queue_len: 0.09172624620139831
wait_time: 0.8942798383721303
delay_time: 5.7583034138129365
pressure: 1.1104111405835544
total_envstep_count: 238728
total_train_sample_count: 238728
total_episode_count: 2058
total_duration: 14168.61817494405
[2024-12-26 05:25:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.368126670187436
avg_train_sample_per_sec: 17.368126670187436
avg_episode_per_sec: 0.14972522991540893
collect_time: 40.07340648860484
reward_mean: -141.96463585434174
reward_std: 4.6538405339986575
reward_max: -136.5175070028011
reward_min: -147.86764705882354
queue_len: 0.09414100520844942
wait_time: 0.9253854172084394
delay_time: 6.059375323704249
pressure: 1.133841732979664
total_envstep_count: 239424
total_train_sample_count: 239424
total_episode_count: 2064
total_duration: 14208.691581432655
[2024-12-26 05:26:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.512901043548197
avg_train_sample_per_sec: 17.512901043548197
avg_episode_per_sec: 0.1509732848581741
collect_time: 39.74213057387248
reward_mean: -133.32049486461253
reward_std: 3.1719649659373284
reward_max: -128.31582633053225
reward_min: -138.2857142857143
queue_len: 0.08840881622321783
wait_time: 0.8566117649535502
delay_time: 5.748023470662914
pressure: 1.063107869142352
total_envstep_count: 240120
total_train_sample_count: 240120
total_episode_count: 2070
total_duration: 14248.433712006527
[2024-12-26 05:27:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.69506277781768
avg_train_sample_per_sec: 17.69506277781768
avg_episode_per_sec: 0.1525436446363593
collect_time: 39.33300541168452
reward_mean: -138.63328664799255
reward_std: 5.82951653415481
reward_max: -126.12955182072831
reward_min: -143.7948179271709
queue_len: 0.09193188769760778
wait_time: 0.8968651010359937
delay_time: 5.8019377211160466
pressure: 1.1015694076038904
total_envstep_count: 240816
total_train_sample_count: 240816
total_episode_count: 2076
total_duration: 14287.766717418212
[2024-12-26 05:27:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.578189236520828
avg_train_sample_per_sec: 17.578189236520828
avg_episode_per_sec: 0.15153611410793816
collect_time: 39.59452197465114
reward_mean: -135.3148926237162
reward_std: 4.511474002712821
reward_max: -129.1323529411765
reward_min: -140.9446778711485
queue_len: 0.08973136115631047
wait_time: 0.8709988526798872
delay_time: 5.61407951638327
pressure: 1.076370468611848
total_envstep_count: 241512
total_train_sample_count: 241512
total_episode_count: 2082
total_duration: 14327.361239392863
[2024-12-26 05:28:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.38688483505367
avg_train_sample_per_sec: 17.38688483505367
avg_episode_per_sec: 0.1498869382332213
collect_time: 40.030172546884046
reward_mean: -141.12243230625586
reward_std: 4.393567420359907
reward_max: -135.65616246498595
reward_min: -146.10784313725492
queue_len: 0.09358251479194683
wait_time: 0.913156288156288
delay_time: 5.915641233367686
pressure: 1.1235632183908046
total_envstep_count: 242208
total_train_sample_count: 242208
total_episode_count: 2088
total_duration: 14367.391411939747
[2024-12-26 05:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45863471324418
avg_train_sample_per_sec: 17.45863471324418
avg_episode_per_sec: 0.15050547166589812
collect_time: 39.86566025532409
reward_mean: -139.35200746965455
reward_std: 1.8661081746477217
reward_max: -136.71148459383753
reward_min: -142.53221288515417
queue_len: 0.0924084930170123
wait_time: 0.9045188809387592
delay_time: 5.890248763277104
pressure: 1.1246684350132627
total_envstep_count: 242904
total_train_sample_count: 242904
total_episode_count: 2094
total_duration: 14407.25707219507
[2024-12-26 05:29:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.457224586928444
avg_train_sample_per_sec: 17.457224586928444
avg_episode_per_sec: 0.15049331540455554
collect_time: 39.868880447419365
reward_mean: -141.40044351073766
reward_std: 3.3428767890743236
reward_max: -136.20168067226888
reward_min: -145.73529411764707
queue_len: 0.09376687235460057
wait_time: 0.9104129826112587
delay_time: 5.98353389119992
pressure: 1.1358311229000881
total_envstep_count: 243600
total_train_sample_count: 243600
total_episode_count: 2100
total_duration: 14447.12595264249
[2024-12-26 05:30:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.307945356724485
avg_train_sample_per_sec: 17.307945356724485
avg_episode_per_sec: 0.1492064254890042
collect_time: 40.21274539843575
reward_mean: -140.06127450980392
reward_std: 4.770519061863819
reward_max: -135.70308123249302
reward_min: -150.1792717086835
queue_len: 0.0928788292505331
wait_time: 0.9066604316350766
delay_time: 5.88298990626522
pressure: 1.1205791335101678
total_envstep_count: 244296
total_train_sample_count: 244296
total_episode_count: 2106
total_duration: 14487.338698040925
[2024-12-26 05:31:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.72259947154946
avg_train_sample_per_sec: 17.72259947154946
avg_episode_per_sec: 0.15278102992715054
collect_time: 39.27189129999278
reward_mean: -138.45063025210084
reward_std: 2.9215972391471077
reward_max: -134.80952380952382
reward_min: -142.16176470588235
queue_len: 0.09181076276664513
wait_time: 0.8930783409738786
delay_time: 5.93530864141533
pressure: 1.1121794871794872
total_envstep_count: 244992
total_train_sample_count: 244992
total_episode_count: 2112
total_duration: 14526.610589340919
[2024-12-26 05:32:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.611491498805528
avg_train_sample_per_sec: 17.611491498805528
avg_episode_per_sec: 0.15182320257590973
collect_time: 39.51965113501063
reward_mean: -136.56827731092437
reward_std: 7.430718089013772
reward_max: -128.76540616246496
reward_min: -151.78711484593833
queue_len: 0.09056251811069255
wait_time: 0.8806610619490943
delay_time: 5.856425576086759
pressure: 1.095048629531388
total_envstep_count: 245688
total_train_sample_count: 245688
total_episode_count: 2118
total_duration: 14566.13024047593
[2024-12-26 05:32:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.612883300309576
avg_train_sample_per_sec: 17.612883300309576
avg_episode_per_sec: 0.15183520086473773
collect_time: 39.51652822157554
reward_mean: -136.4828431372549
reward_std: 4.963992675108102
reward_max: -132.20868347338939
reward_min: -147.23319327731087
queue_len: 0.09050586414937327
wait_time: 0.8801350779038407
delay_time: 5.787044427278491
pressure: 1.0894120247568524
total_envstep_count: 246384
total_train_sample_count: 246384
total_episode_count: 2124
total_duration: 14605.646768697505
[2024-12-26 05:33:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51709381491633
avg_train_sample_per_sec: 17.51709381491633
avg_episode_per_sec: 0.15100942943893386
collect_time: 39.732618170220405
reward_mean: -138.60550887021475
reward_std: 4.5706872647291465
reward_max: -131.30812324929974
reward_min: -144.10994397759097
queue_len: 0.09191346742056682
wait_time: 0.8937920880111548
delay_time: 5.7215008554624065
pressure: 1.1204686118479221
total_envstep_count: 247080
total_train_sample_count: 247080
total_episode_count: 2130
total_duration: 14645.379386867726
[2024-12-26 05:34:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.409515198195567
avg_train_sample_per_sec: 17.409515198195567
avg_episode_per_sec: 0.15008202757065145
collect_time: 39.97813793643937
reward_mean: -136.65196078431373
reward_std: 2.6567005288899663
reward_max: -132.42296918767505
reward_min: -140.37464985994393
queue_len: 0.09061801113018149
wait_time: 0.8885456370877266
delay_time: 5.76606550229353
pressure: 1.0888594164456233
total_envstep_count: 247776
total_train_sample_count: 247776
total_episode_count: 2136
total_duration: 14685.357524804165
[2024-12-26 05:34:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39074688652996
avg_train_sample_per_sec: 17.39074688652996
avg_episode_per_sec: 0.1499202317804307
collect_time: 40.021282843181865
reward_mean: -137.7421802054155
reward_std: 5.11750952457849
reward_max: -127.18487394957985
reward_min: -141.63725490196074
queue_len: 0.09134096830597845
wait_time: 0.8835280464971134
delay_time: 5.794682645037675
pressure: 1.09394341290893
total_envstep_count: 248472
total_train_sample_count: 248472
total_episode_count: 2142
total_duration: 14725.378807647347
[2024-12-26 05:35:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40092880804179
avg_train_sample_per_sec: 17.40092880804179
avg_episode_per_sec: 0.15000800696587752
collect_time: 39.99786492306925
reward_mean: -138.5997899159664
reward_std: 2.723130129622699
reward_max: -134.66526610644257
reward_min: -142.2212885154062
queue_len: 0.09190967501058782
wait_time: 0.8956890669618863
delay_time: 5.772216043938227
pressure: 1.11184792219275
total_envstep_count: 249168
total_train_sample_count: 249168
total_episode_count: 2148
total_duration: 14765.376672570415
[2024-12-26 05:36:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.480677631781976
avg_train_sample_per_sec: 17.480677631781976
avg_episode_per_sec: 0.1506954968257067
collect_time: 39.815390150241555
reward_mean: -135.94444444444443
reward_std: 5.490853008265737
reward_max: -126.92226890756302
reward_min: -144.97969187675068
queue_len: 0.090148835838491
wait_time: 0.8805540231123393
delay_time: 5.593477374501
pressure: 1.08631741821397
total_envstep_count: 249864
total_train_sample_count: 249864
total_episode_count: 2154
total_duration: 14805.192062720656
[2024-12-26 05:36:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.570852115355667
avg_train_sample_per_sec: 17.570852115355667
avg_episode_per_sec: 0.15147286306341093
collect_time: 39.6110555954054
reward_mean: -136.43137254901958
reward_std: 3.1317995410602952
reward_max: -131.5959383753501
reward_min: -141.16876750700283
queue_len: 0.09047173245956208
wait_time: 0.880240568818155
delay_time: 5.679902789816715
pressure: 1.098474801061008
total_envstep_count: 250560
total_train_sample_count: 250560
total_episode_count: 2160
total_duration: 14844.803118316062
[2024-12-26 05:37:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37942556361708
avg_train_sample_per_sec: 17.37942556361708
avg_episode_per_sec: 0.14982263416911276
collect_time: 40.04735354757867
reward_mean: -134.60060690943044
reward_std: 4.157695908947201
reward_max: -129.46288515406164
reward_min: -141.8144257703081
queue_len: 0.08925769688954271
wait_time: 0.8593431514957884
delay_time: 5.816702119704559
pressure: 1.0748231653404068
total_envstep_count: 251256
total_train_sample_count: 251256
total_episode_count: 2166
total_duration: 14884.850471863641
[2024-12-26 05:38:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.411252315519956
avg_train_sample_per_sec: 17.411252315519956
avg_episode_per_sec: 0.1500970027199996
collect_time: 39.97414932523854
reward_mean: -133.1471755368814
reward_std: 6.056454999713077
reward_max: -123.55742296918764
reward_min: -141.32492997198875
queue_len: 0.08829388298201685
wait_time: 0.850699552588498
delay_time: 5.583423555014046
pressure: 1.0595711759504862
total_envstep_count: 251952
total_train_sample_count: 251952
total_episode_count: 2172
total_duration: 14924.82462118888
[2024-12-26 05:38:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35323180836587
avg_train_sample_per_sec: 17.35323180836587
avg_episode_per_sec: 0.14959682593418852
collect_time: 40.10780283961074
reward_mean: -136.8033380018674
reward_std: 5.860809534207018
reward_max: -128.67436974789914
reward_min: -144.05392156862746
queue_len: 0.09071839390044256
wait_time: 0.8844284729807043
delay_time: 5.7225324576124335
pressure: 1.0959328028293547
total_envstep_count: 252648
total_train_sample_count: 252648
total_episode_count: 2178
total_duration: 14964.932424028491
[2024-12-26 05:39:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.534971266761843
avg_train_sample_per_sec: 17.534971266761843
avg_episode_per_sec: 0.15116354540311933
collect_time: 39.69210952283068
reward_mean: -136.00210084033617
reward_std: 3.305050586062215
reward_max: -132.11624649859945
reward_min: -141.73949579831935
queue_len: 0.09018706952276932
wait_time: 0.8779323842711265
delay_time: 5.667648336032626
pressure: 1.087975243147657
total_envstep_count: 253344
total_train_sample_count: 253344
total_episode_count: 2184
total_duration: 15004.624533551321
[2024-12-26 05:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.410716854419828
avg_train_sample_per_sec: 17.410716854419828
avg_episode_per_sec: 0.150092386676033
collect_time: 39.97537871758082
reward_mean: -138.95319794584498
reward_std: 6.096891843059951
reward_max: -130.98039215686273
reward_min: -150.27240896358535
queue_len: 0.09214403046806696
wait_time: 0.8946509527772206
delay_time: 5.895898118788441
pressure: 1.10289566755084
total_envstep_count: 254040
total_train_sample_count: 254040
total_episode_count: 2190
total_duration: 15044.599912268903
[2024-12-26 05:40:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.540924197009577
avg_train_sample_per_sec: 17.540924197009577
avg_episode_per_sec: 0.15121486376732393
collect_time: 39.67863906045817
reward_mean: -137.16608309990661
reward_std: 2.724356395811763
reward_max: -131.87464985994396
reward_min: -140.375350140056
queue_len: 0.09095894104768343
wait_time: 0.8852238729267127
delay_time: 5.741508053111523
pressure: 1.0933908045977012
total_envstep_count: 254736
total_train_sample_count: 254736
total_episode_count: 2196
total_duration: 15084.27855132936
[2024-12-26 05:41:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600810094875023
avg_train_sample_per_sec: 17.600810094875023
avg_episode_per_sec: 0.15173112150754328
collect_time: 39.543634426387015
reward_mean: -137.6551120448179
reward_std: 4.587369548332092
reward_max: -130.64215686274514
reward_min: -143.1995798319327
queue_len: 0.09128323079895088
wait_time: 0.8808207301488234
delay_time: 5.87917059703821
pressure: 1.0899646330680812
total_envstep_count: 255432
total_train_sample_count: 255432
total_episode_count: 2202
total_duration: 15123.822185755747
[2024-12-26 05:42:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.715093457456124
avg_train_sample_per_sec: 17.715093457456124
avg_episode_per_sec: 0.1527163229091045
collect_time: 39.28853108630143
reward_mean: -134.2592203548086
reward_std: 3.819304564185041
reward_max: -129.45588235294122
reward_min: -140.33613445378148
queue_len: 0.08903131323263169
wait_time: 0.867719037217009
delay_time: 5.59887009380279
pressure: 1.0816755083996463
total_envstep_count: 256128
total_train_sample_count: 256128
total_episode_count: 2208
total_duration: 15163.11071684205
[2024-12-26 05:42:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.684314560828394
avg_train_sample_per_sec: 17.684314560828394
avg_episode_per_sec: 0.15245098759334824
collect_time: 39.35691132421233
reward_mean: -134.9952147525677
reward_std: 4.257944130032674
reward_max: -130.13655462184877
reward_min: -143.17366946778714
queue_len: 0.08951937317809529
wait_time: 0.8710734625415152
delay_time: 5.664854166132545
pressure: 1.0887488947833777
total_envstep_count: 256824
total_train_sample_count: 256824
total_episode_count: 2214
total_duration: 15202.467628166261
[2024-12-26 05:43:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.552293981675295
avg_train_sample_per_sec: 17.552293981675295
avg_episode_per_sec: 0.15131287915237324
collect_time: 39.65293657493592
reward_mean: -133.64320728291318
reward_std: 3.9956959995169554
reward_max: -127.67997198879554
reward_min: -139.37955182072827
queue_len: 0.08862281650060555
wait_time: 0.8567823460064838
delay_time: 5.590823705596004
pressure: 1.0674182139699382
total_envstep_count: 257520
total_train_sample_count: 257520
total_episode_count: 2220
total_duration: 15242.120564741197
[2024-12-26 05:44:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600584875867796
avg_train_sample_per_sec: 17.600584875867796
avg_episode_per_sec: 0.15172917996437757
collect_time: 39.544140431053926
reward_mean: -136.76307189542482
reward_std: 4.003861908885601
reward_max: -131.7408963585434
reward_min: -144.19747899159665
queue_len: 0.09069169223834538
wait_time: 0.8778542141878857
delay_time: 5.7997214136303805
pressure: 1.0885278514588859
total_envstep_count: 258216
total_train_sample_count: 258216
total_episode_count: 2226
total_duration: 15281.66470517225
[2024-12-26 05:44:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.670809609088934
avg_train_sample_per_sec: 17.670809609088934
avg_episode_per_sec: 0.15233456559559427
collect_time: 39.38698992274888
reward_mean: -130.70063025210084
reward_std: 2.9193558518532288
reward_max: -125.13865546218487
reward_min: -133.1589635854342
queue_len: 0.08667150547221542
wait_time: 0.8391815391054741
delay_time: 5.478717791265876
pressure: 1.0466401414677275
total_envstep_count: 258912
total_train_sample_count: 258912
total_episode_count: 2232
total_duration: 15321.051695094999
[2024-12-26 05:45:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.63458084537183
avg_train_sample_per_sec: 17.63458084537183
avg_episode_per_sec: 0.15202224866699854
collect_time: 39.4679071820788
reward_mean: -134.47619047619045
reward_std: 2.415022413995674
reward_max: -129.93767507002795
reward_min: -137.01050420168067
queue_len: 0.08917519262346847
wait_time: 0.8695386974418415
delay_time: 5.539503891486089
pressure: 1.079686118479222
total_envstep_count: 259608
total_train_sample_count: 259608
total_episode_count: 2238
total_duration: 15360.519602277078
[2024-12-26 05:46:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.636811670492943
avg_train_sample_per_sec: 17.636811670492943
avg_episode_per_sec: 0.15204147991804262
collect_time: 39.46291500999778
reward_mean: -134.04213352007469
reward_std: 1.6939825324895128
reward_max: -132.53711484593833
reward_min: -137.42997198879553
queue_len: 0.08888735644567286
wait_time: 0.8662449506769994
delay_time: 5.499757072626513
pressure: 1.0647656940760388
total_envstep_count: 260304
total_train_sample_count: 260304
total_episode_count: 2244
total_duration: 15399.982517287075
[2024-12-26 05:46:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.59287338651496
avg_train_sample_per_sec: 17.59287338651496
avg_episode_per_sec: 0.15166270160788756
collect_time: 39.561473825730374
reward_mean: -134.59197012138188
reward_std: 3.504589249882791
reward_max: -130.14635854341734
reward_min: -139.83403361344537
queue_len: 0.08925196957651317
wait_time: 0.8713058830959439
delay_time: 5.571337271147698
pressure: 1.0754862953138815
total_envstep_count: 261000
total_train_sample_count: 261000
total_episode_count: 2250
total_duration: 15439.543991112805
[2024-12-26 05:47:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52028467648791
avg_train_sample_per_sec: 17.52028467648791
avg_episode_per_sec: 0.15103693686627512
collect_time: 39.72538191311621
reward_mean: -136.27812791783379
reward_std: 3.9450848326325128
reward_max: -131.51540616246498
reward_min: -144.0896358543417
queue_len: 0.09037011135134866
wait_time: 0.8826904656646035
delay_time: 5.673511863991
pressure: 1.0897435897435896
total_envstep_count: 261696
total_train_sample_count: 261696
total_episode_count: 2256
total_duration: 15479.269373025922
[2024-12-26 05:48:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37603268748663
avg_train_sample_per_sec: 17.37603268748663
avg_episode_per_sec: 0.14979338523695374
collect_time: 40.055173267556356
reward_mean: -136.62056489262372
reward_std: 6.491411045615
reward_max: -124.73599439775917
reward_min: -144.10224089635858
queue_len: 0.0905971915733579
wait_time: 0.8694078979956262
delay_time: 5.811830151682499
pressure: 1.0854332449160033
total_envstep_count: 262392
total_train_sample_count: 262392
total_episode_count: 2262
total_duration: 15519.324546293477
[2024-12-26 05:48:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.527729712096622
avg_train_sample_per_sec: 17.527729712096622
avg_episode_per_sec: 0.15110111820772948
collect_time: 39.708508257042624
reward_mean: -133.953314659197
reward_std: 3.705808704290438
reward_max: -128.77030812324927
reward_min: -138.5259103641456
queue_len: 0.08882845799681499
wait_time: 0.8619874674007534
delay_time: 5.640652157853573
pressure: 1.0604553492484527
total_envstep_count: 263088
total_train_sample_count: 263088
total_episode_count: 2268
total_duration: 15559.03305455052
[2024-12-26 05:49:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60703936448034
avg_train_sample_per_sec: 17.60703936448034
avg_episode_per_sec: 0.15178482210758912
collect_time: 39.529644115187224
reward_mean: -133.22724089635855
reward_std: 3.270182154126741
reward_max: -130.05602240896357
reward_min: -139.84873949579833
queue_len: 0.08834697672172316
wait_time: 0.8613512712777419
delay_time: 5.5441657335053245
pressure: 1.0583554376657824
total_envstep_count: 263784
total_train_sample_count: 263784
total_episode_count: 2274
total_duration: 15598.562698665708
[2024-12-26 05:50:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33836024854609
avg_train_sample_per_sec: 17.33836024854609
avg_episode_per_sec: 0.14946862283229387
collect_time: 40.142204338980854
reward_mean: -133.82598039215688
reward_std: 3.7773262383681576
reward_max: -129.10364145658264
reward_min: -139.6442577030812
queue_len: 0.08874401882769023
wait_time: 0.8601266324390057
delay_time: 5.6841139042658
pressure: 1.0629973474801062
total_envstep_count: 264480
total_train_sample_count: 264480
total_episode_count: 2280
total_duration: 15638.70490300469
[2024-12-26 05:50:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.523795998513133
avg_train_sample_per_sec: 17.523795998513133
avg_episode_per_sec: 0.1510672068837339
collect_time: 39.71742195920647
reward_mean: -136.26797385620918
reward_std: 3.7324589392260754
reward_max: -129.4467787114846
reward_min: -141.2871148459384
queue_len: 0.09036337788873285
wait_time: 0.8801754012834135
delay_time: 5.639095055296828
pressure: 1.0836648983200707
total_envstep_count: 265176
total_train_sample_count: 265176
total_episode_count: 2286
total_duration: 15678.422324963896
[2024-12-26 05:51:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85374172340153
avg_train_sample_per_sec: 17.85374172340153
avg_episode_per_sec: 0.15391156658104768
collect_time: 38.98342491914332
reward_mean: -133.66771708683473
reward_std: 3.4112643912614575
reward_max: -128.62394957983193
reward_min: -137.59663865546221
queue_len: 0.08863906968622992
wait_time: 0.8583465990286475
delay_time: 5.708148120974685
pressure: 1.0648762157382847
total_envstep_count: 265872
total_train_sample_count: 265872
total_episode_count: 2292
total_duration: 15717.405749883039
[2024-12-26 05:52:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.510860215219747
avg_train_sample_per_sec: 17.510860215219747
avg_episode_per_sec: 0.15095569151051508
collect_time: 39.74676237750241
reward_mean: -134.3312324929972
reward_std: 2.7827999151798224
reward_max: -129.19677871148463
reward_min: -138.703781512605
queue_len: 0.08907906663991856
wait_time: 0.8644650720588855
delay_time: 5.703722532731464
pressure: 1.0611184792219275
total_envstep_count: 266568
total_train_sample_count: 266568
total_episode_count: 2298
total_duration: 15757.152512260542
[2024-12-26 05:52:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.715831682360168
avg_train_sample_per_sec: 17.715831682360168
avg_episode_per_sec: 0.152722686916898
collect_time: 39.28689391946607
reward_mean: -135.4861111111111
reward_std: 4.745130910664122
reward_max: -128.42296918767508
reward_min: -142.71148459383747
queue_len: 0.08984490126731504
wait_time: 0.8726165864223673
delay_time: 5.757171265525492
pressure: 1.0786914235190097
total_envstep_count: 267264
total_train_sample_count: 267264
total_episode_count: 2304
total_duration: 15796.439406180009
[2024-12-26 05:53:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83596008560773
avg_train_sample_per_sec: 17.83596008560773
avg_episode_per_sec: 0.15375827660006666
collect_time: 39.02228961375728
reward_mean: -133.31757703081234
reward_std: 4.01522257492314
reward_max: -124.94957983193275
reward_min: -136.76610644257704
queue_len: 0.08840688132016733
wait_time: 0.850307154249852
delay_time: 5.659168628371813
pressure: 1.0739389920424405
total_envstep_count: 267960
total_train_sample_count: 267960
total_episode_count: 2310
total_duration: 15835.461695793765
[2024-12-26 05:54:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.886971949030467
avg_train_sample_per_sec: 17.886971949030467
avg_episode_per_sec: 0.1541980340433661
collect_time: 38.911001928290354
reward_mean: -133.33800186741362
reward_std: 4.419222751942085
reward_max: -127.72338935574228
reward_min: -141.83613445378154
queue_len: 0.08842042564152099
wait_time: 0.8491957459376325
delay_time: 5.633833933869661
pressure: 1.058576480990274
total_envstep_count: 268656
total_train_sample_count: 268656
total_episode_count: 2316
total_duration: 15874.372697722056
[2024-12-26 05:54:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.551482489243245
avg_train_sample_per_sec: 17.551482489243245
avg_episode_per_sec: 0.151305883527959
collect_time: 39.654769927643244
reward_mean: -136.24439775910363
reward_std: 5.6912683239874315
reward_max: -129.90056022408967
reward_min: -144.92016806722688
queue_len: 0.09034774387208465
wait_time: 0.8681223484088597
delay_time: 5.807023023704836
pressure: 1.0815649867374006
total_envstep_count: 269352
total_train_sample_count: 269352
total_episode_count: 2322
total_duration: 15914.0274676497
[2024-12-26 05:55:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73406745862036
avg_train_sample_per_sec: 17.73406745862036
avg_episode_per_sec: 0.15287989188465825
collect_time: 39.24649557266013
reward_mean: -135.9564659197012
reward_std: 4.179238392377525
reward_max: -129.60574229691878
reward_min: -143.5931372549019
queue_len: 0.09015680763905914
wait_time: 0.8731094449273962
delay_time: 5.682308731257688
pressure: 1.0776967285587975
total_envstep_count: 270048
total_train_sample_count: 270048
total_episode_count: 2328
total_duration: 15953.27396322236
[2024-12-26 05:56:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.430917859362197
avg_train_sample_per_sec: 17.430917859362197
avg_episode_per_sec: 0.15026653327036377
collect_time: 39.92905053053052
reward_mean: -137.02007469654527
reward_std: 3.8370633324475913
reward_max: -131.00700280112042
reward_min: -142.3242296918767
queue_len: 0.09086211849903532
wait_time: 0.8784913390643614
delay_time: 5.807144134088884
pressure: 1.1002431476569408
total_envstep_count: 270744
total_train_sample_count: 270744
total_episode_count: 2334
total_duration: 15993.203013752891
[2024-12-26 05:56:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.421409624930483
avg_train_sample_per_sec: 17.421409624930483
avg_episode_per_sec: 0.15018456573215933
collect_time: 39.95084295612946
reward_mean: -135.61262838468718
reward_std: 4.869925775798168
reward_max: -131.94327731092437
reward_min: -146.22268907563026
queue_len: 0.08992879866358566
wait_time: 0.8688371015957222
delay_time: 5.806775606458655
pressure: 1.0663129973474803
total_envstep_count: 271440
total_train_sample_count: 271440
total_episode_count: 2340
total_duration: 16033.153856709021
[2024-12-26 05:57:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.512563135137782
avg_train_sample_per_sec: 17.512563135137782
avg_episode_per_sec: 0.15097037185463605
collect_time: 39.74289740623534
reward_mean: -132.35901027077497
reward_std: 1.78127258633855
reward_max: -130.78571428571428
reward_min: -135.34873949579833
queue_len: 0.08777122697000994
wait_time: 0.8456014700309833
delay_time: 5.55781980299497
pressure: 1.051503094606543
total_envstep_count: 272136
total_train_sample_count: 272136
total_episode_count: 2346
total_duration: 16072.896754115256
[2024-12-26 05:58:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.461015065817495
avg_train_sample_per_sec: 17.461015065817495
avg_episode_per_sec: 0.15052599194670255
collect_time: 39.86022561554983
reward_mean: -133.9936974789916
reward_std: 4.645133586575714
reward_max: -126.86694677871148
reward_min: -139.64635854341736
queue_len: 0.08885523705503422
wait_time: 0.8623807944928634
delay_time: 5.714977651888954
pressure: 1.0733863837312112
total_envstep_count: 272832
total_train_sample_count: 272832
total_episode_count: 2352
total_duration: 16112.756979730806
[2024-12-26 05:58:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52686292923068
avg_train_sample_per_sec: 17.52686292923068
avg_episode_per_sec: 0.1510936459416438
collect_time: 39.71047202287615
reward_mean: -133.00093370681606
reward_std: 2.40315660001141
reward_max: -130.52100840336135
reward_min: -137.41386554621846
queue_len: 0.0881969056411247
wait_time: 0.859382081745165
delay_time: 5.609155997414277
pressure: 1.0621131741821397
total_envstep_count: 273528
total_train_sample_count: 273528
total_episode_count: 2358
total_duration: 16152.467451753682
[2024-12-26 05:59:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.426351933662357
avg_train_sample_per_sec: 17.426351933662357
avg_episode_per_sec: 0.15022717184191686
collect_time: 39.93951244927757
reward_mean: -134.8720821661998
reward_std: 5.382394103000966
reward_max: -129.43277310924373
reward_min: -146.37464985994396
queue_len: 0.08943772026936325
wait_time: 0.8664122036966865
delay_time: 5.644782156353098
pressure: 1.0810123784261716
total_envstep_count: 274224
total_train_sample_count: 274224
total_episode_count: 2364
total_duration: 16192.40696420296
[2024-12-26 06:00:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.389183090112915
avg_train_sample_per_sec: 17.389183090112915
avg_episode_per_sec: 0.1499067507768355
collect_time: 40.024881927646696
reward_mean: -136.54166666666669
reward_std: 5.051758532828971
reward_max: -126.61204481792716
reward_min: -142.41736694677869
queue_len: 0.0905448717948718
wait_time: 0.8738911457598069
delay_time: 5.845558606515996
pressure: 1.0845490716180373
total_envstep_count: 274920
total_train_sample_count: 274920
total_episode_count: 2370
total_duration: 16232.431846130608
[2024-12-26 06:00:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.61354950877324
avg_train_sample_per_sec: 17.61354950877324
avg_episode_per_sec: 0.15184094404114862
collect_time: 39.51503356284462
reward_mean: -133.9389589169001
reward_std: 7.414927183763709
reward_max: -124.10434173669469
reward_min: -146.73879551820727
queue_len: 0.08881893827380644
wait_time: 0.8572425433480201
delay_time: 5.748014370673398
pressure: 1.0603448275862066
total_envstep_count: 275616
total_train_sample_count: 275616
total_episode_count: 2376
total_duration: 16271.946879693453
[2024-12-26 06:01:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.420496159659635
avg_train_sample_per_sec: 17.420496159659635
avg_episode_per_sec: 0.1501766910315486
collect_time: 39.95293782801181
reward_mean: -131.64612511671336
reward_std: 3.76128142069576
reward_max: -127.10784313725497
reward_min: -137.44957983193274
queue_len: 0.08729849145670648
wait_time: 0.8441560974522434
delay_time: 5.639379629685742
pressure: 1.0450928381962865
total_envstep_count: 276312
total_train_sample_count: 276312
total_episode_count: 2382
total_duration: 16311.899817521464
[2024-12-26 06:02:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.468953031596026
avg_train_sample_per_sec: 17.468953031596026
avg_episode_per_sec: 0.15059442268617265
collect_time: 39.84211296127178
reward_mean: -137.61694677871148
reward_std: 4.439850374330981
reward_max: -131.75980392156865
reward_min: -145.2556022408963
queue_len: 0.09125792226705004
wait_time: 0.8849328635079141
delay_time: 5.811315202946076
pressure: 1.0893015030946065
total_envstep_count: 277008
total_train_sample_count: 277008
total_episode_count: 2388
total_duration: 16351.741930482736
[2024-12-26 06:02:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.530372257581334
avg_train_sample_per_sec: 17.530372257581334
avg_episode_per_sec: 0.15112389877225288
collect_time: 39.702522557614365
reward_mean: -137.07551353874885
reward_std: 3.8212891077992803
reward_max: -130.31862745098033
reward_min: -141.04271708683478
queue_len: 0.09089888165699526
wait_time: 0.8764334535759485
delay_time: 5.777046817285698
pressure: 1.089633068081344
total_envstep_count: 277704
total_train_sample_count: 277704
total_episode_count: 2394
total_duration: 16391.44445304035
[2024-12-26 06:03:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.544960007734716
avg_train_sample_per_sec: 17.544960007734716
avg_episode_per_sec: 0.15124965523909237
collect_time: 39.669511910723514
reward_mean: -137.05508870214751
reward_std: 2.536421676458594
reward_max: -134.06092436974794
reward_min: -141.5721288515405
queue_len: 0.0908853373356416
wait_time: 0.8760272013314608
delay_time: 5.842206262779413
pressure: 1.0841069849690539
total_envstep_count: 278400
total_train_sample_count: 278400
total_episode_count: 2400
total_duration: 16431.113964951073
[2024-12-26 06:04:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.601749707233626
avg_train_sample_per_sec: 17.601749707233626
avg_episode_per_sec: 0.151739221614083
collect_time: 39.54152351762912
reward_mean: -137.09768907563026
reward_std: 3.950105229529933
reward_max: -132.58823529411765
reward_min: -144.17016806722685
queue_len: 0.09091358692017924
wait_time: 0.8817316825050091
delay_time: 5.788096414407935
pressure: 1.0837754199823164
total_envstep_count: 279096
total_train_sample_count: 279096
total_episode_count: 2406
total_duration: 16470.655488468703
[2024-12-26 06:04:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.616409926120088
avg_train_sample_per_sec: 17.616409926120088
avg_episode_per_sec: 0.1518656028113801
collect_time: 39.50861741517671
reward_mean: -138.53979925303452
reward_std: 4.70623688099806
reward_max: -130.40336134453779
reward_min: -144.4495798319327
queue_len: 0.09186989340386904
wait_time: 0.8839678112624361
delay_time: 5.9090571106523955
pressure: 1.1005747126436782
total_envstep_count: 279792
total_train_sample_count: 279792
total_episode_count: 2412
total_duration: 16510.16410588388
[2024-12-26 06:05:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.708409197057527
avg_train_sample_per_sec: 17.708409197057527
avg_episode_per_sec: 0.15265869997463385
collect_time: 39.30336103344896
reward_mean: -135.06279178338
reward_std: 3.105537092189141
reward_max: -129.4803921568627
reward_min: -138.56372549019605
queue_len: 0.08956418553274535
wait_time: 0.8795725628889928
delay_time: 5.689215231976057
pressure: 1.0844385499557914
total_envstep_count: 280488
total_train_sample_count: 280488
total_episode_count: 2418
total_duration: 16549.46746691733
[2024-12-26 06:06:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.547307265538738
avg_train_sample_per_sec: 17.547307265538738
avg_episode_per_sec: 0.15126989022016155
collect_time: 39.66420542295276
reward_mean: -135.83951914098975
reward_std: 3.0998247904703815
reward_max: -130.71148459383755
reward_min: -138.58193277310923
queue_len: 0.09007925672479428
wait_time: 0.8732906292490473
delay_time: 5.7746271100021564
pressure: 1.0667550839964635
total_envstep_count: 281184
total_train_sample_count: 281184
total_episode_count: 2424
total_duration: 16589.13167234028
[2024-12-26 06:06:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.677686823813357
avg_train_sample_per_sec: 17.677686823813357
avg_episode_per_sec: 0.15239385192942548
collect_time: 39.37166705897451
reward_mean: -133.04668534080304
reward_std: 3.8933066841076998
reward_max: -129.6645658263306
reward_min: -140.58263305322137
queue_len: 0.08822724492095689
wait_time: 0.8536457133693443
delay_time: 5.612266342963586
pressure: 1.059239610963749
total_envstep_count: 281880
total_train_sample_count: 281880
total_episode_count: 2430
total_duration: 16628.503339399256
[2024-12-26 06:07:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60333874595269
avg_train_sample_per_sec: 17.60333874595269
avg_episode_per_sec: 0.15175292022373008
collect_time: 39.53795413725265
reward_mean: -132.64495798319328
reward_std: 4.100122035680472
reward_max: -127.69747899159661
reward_min: -139.0511204481793
queue_len: 0.08796084746896105
wait_time: 0.8440901559562818
delay_time: 5.592978979936633
pressure: 1.0561450044208665
total_envstep_count: 282576
total_train_sample_count: 282576
total_episode_count: 2436
total_duration: 16668.04129353651
[2024-12-26 06:08:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.400725511484033
avg_train_sample_per_sec: 17.400725511484033
avg_episode_per_sec: 0.15000625440934512
collect_time: 39.998332227047534
reward_mean: -137.57913165266106
reward_std: 4.66898545320305
reward_max: -132.27380952380952
reward_min: -146.3956582633053
queue_len: 0.09123284592351528
wait_time: 0.8902409217444713
delay_time: 5.768388783386723
pressure: 1.096816976127321
total_envstep_count: 283272
total_train_sample_count: 283272
total_episode_count: 2442
total_duration: 16708.03962576356
[2024-12-26 06:08:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39011056515008
avg_train_sample_per_sec: 17.39011056515008
avg_episode_per_sec: 0.1499147462512938
collect_time: 40.0227472615838
reward_mean: -135.4855275443511
reward_std: 3.3729433564941833
reward_max: -128.93347338935578
reward_min: -139.83823529411768
queue_len: 0.08984451428670497
wait_time: 0.8682284584921501
delay_time: 5.714132077795309
pressure: 1.0842175066312998
total_envstep_count: 283968
total_train_sample_count: 283968
total_episode_count: 2448
total_duration: 16748.062373025143
[2024-12-26 06:09:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.635527556649343
avg_train_sample_per_sec: 17.635527556649343
avg_episode_per_sec: 0.15203040997111503
collect_time: 39.46578846389988
reward_mean: -136.35749299719888
reward_std: 1.649767539191298
reward_max: -134.63025210084032
reward_min: -139.14705882352936
queue_len: 0.09042274071432284
wait_time: 0.8766064339086651
delay_time: 5.684732054453488
pressure: 1.0877541998231655
total_envstep_count: 284664
total_train_sample_count: 284664
total_episode_count: 2454
total_duration: 16787.52816148904
[2024-12-26 06:10:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.514701558285328
avg_train_sample_per_sec: 17.514701558285328
avg_episode_per_sec: 0.1509888065369425
collect_time: 39.738045075096196
reward_mean: -134.45424836601308
reward_std: 2.599094947671735
reward_max: -130.4418767507003
reward_min: -138.593137254902
queue_len: 0.08916064215252856
wait_time: 0.8679054070788351
delay_time: 5.547767496389806
pressure: 1.0750442086648984
total_envstep_count: 285360
total_train_sample_count: 285360
total_episode_count: 2460
total_duration: 16827.266206564138
[2024-12-26 06:10:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.556604018543627
avg_train_sample_per_sec: 17.556604018543627
avg_episode_per_sec: 0.15135003464261748
collect_time: 39.643202026136215
reward_mean: -133.97093837535013
reward_std: 4.640630002232016
reward_max: -128.92296918767505
reward_min: -140.47058823529412
queue_len: 0.08884014481124014
wait_time: 0.8627773722220984
delay_time: 5.637310869531263
pressure: 1.0674182139699382
total_envstep_count: 286056
total_train_sample_count: 286056
total_episode_count: 2466
total_duration: 16866.909408590273
[2024-12-26 06:11:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47355386336018
avg_train_sample_per_sec: 17.47355386336018
avg_episode_per_sec: 0.15063408502896708
collect_time: 39.831622430250064
reward_mean: -137.1395891690009
reward_std: 3.8355783667502226
reward_max: -132.68487394957987
reward_min: -143.09873949579827
queue_len: 0.0909413721279847
wait_time: 0.8796321579029489
delay_time: 5.72709516066782
pressure: 1.0908488063660478
total_envstep_count: 286752
total_train_sample_count: 286752
total_episode_count: 2472
total_duration: 16906.741031020523
[2024-12-26 06:12:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74528407050245
avg_train_sample_per_sec: 17.74528407050245
avg_episode_per_sec: 0.1529765868146763
collect_time: 39.22168826572597
reward_mean: -136.906162464986
reward_std: 3.6822965932152134
reward_max: -132.63725490196077
reward_min: -141.9516806722689
queue_len: 0.09078657988394297
wait_time: 0.8758735700292495
delay_time: 5.879233615176601
pressure: 1.0743810786914236
total_envstep_count: 287448
total_train_sample_count: 287448
total_episode_count: 2478
total_duration: 16945.96271928625
[2024-12-26 06:12:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.725638578699765
avg_train_sample_per_sec: 17.725638578699765
avg_episode_per_sec: 0.1528072291267221
collect_time: 39.26515803139285
reward_mean: -135.81500933706818
reward_std: 5.019940507773138
reward_max: -129.55322128851543
reward_min: -143.6736694677871
queue_len: 0.09006300353916986
wait_time: 0.871613842265465
delay_time: 5.624223219617562
pressure: 1.083554376657825
total_envstep_count: 288144
total_train_sample_count: 288144
total_episode_count: 2484
total_duration: 16985.227877317644
[2024-12-26 06:13:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.566542101815923
avg_train_sample_per_sec: 17.566542101815923
avg_episode_per_sec: 0.15143570777427517
collect_time: 39.62077430868149
reward_mean: -136.218370681606
reward_std: 4.745977362820379
reward_max: -129.73039215686276
reward_min: -145.4712885154062
queue_len: 0.09033048453687399
wait_time: 0.8773449477049883
delay_time: 5.570388802902326
pressure: 1.0957117595048629
total_envstep_count: 288840
total_train_sample_count: 288840
total_episode_count: 2490
total_duration: 17024.848651626326
[2024-12-26 06:14:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7503194463875
avg_train_sample_per_sec: 17.7503194463875
avg_episode_per_sec: 0.15301999522747847
collect_time: 39.21056193395145
reward_mean: -135.23751167133523
reward_std: 3.416920953486478
reward_max: -129.75840336134456
reward_min: -139.70168067226894
queue_len: 0.08968004752741061
wait_time: 0.872407384704545
delay_time: 5.583968377629387
pressure: 1.0805702917771884
total_envstep_count: 289536
total_train_sample_count: 289536
total_episode_count: 2496
total_duration: 17064.05921356028
[2024-12-26 06:14:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.742499021979537
avg_train_sample_per_sec: 17.742499021979537
avg_episode_per_sec: 0.15295257777568566
collect_time: 39.22784491281584
reward_mean: -132.5247432306256
reward_std: 3.075034049157547
reward_max: -128.6603641456583
reward_min: -135.8151260504202
queue_len: 0.08788112946327958
wait_time: 0.8524011063311265
delay_time: 5.465413613350432
pressure: 1.057581786030062
total_envstep_count: 290232
total_train_sample_count: 290232
total_episode_count: 2502
total_duration: 17103.287058473095
[2024-12-26 06:15:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.643172070644546
avg_train_sample_per_sec: 17.643172070644546
avg_episode_per_sec: 0.15209631095383228
collect_time: 39.448688547227526
reward_mean: -134.22572362278245
reward_std: 3.1807079268380543
reward_max: -130.44047619047615
reward_min: -140.00560224089634
queue_len: 0.08900910054561169
wait_time: 0.8652321450242343
delay_time: 5.534093131545595
pressure: 1.0822281167108752
total_envstep_count: 290928
total_train_sample_count: 290928
total_episode_count: 2508
total_duration: 17142.735747020324
[2024-12-26 06:16:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80252105954264
avg_train_sample_per_sec: 17.80252105954264
avg_episode_per_sec: 0.1534700091339883
collect_time: 39.09558638757654
reward_mean: -136.86192810457518
reward_std: 5.749402151171807
reward_max: -129.29271708683473
reward_min: -146.68207282913167
queue_len: 0.09075724675369705
wait_time: 0.8913657969819228
delay_time: 5.553769602875232
pressure: 1.1106321839080462
total_envstep_count: 291624
total_train_sample_count: 291624
total_episode_count: 2514
total_duration: 17181.8313334079
[2024-12-26 06:16:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65714629670681
avg_train_sample_per_sec: 17.65714629670681
avg_episode_per_sec: 0.15221677841988626
collect_time: 39.41746804973855
reward_mean: -129.8760504201681
reward_std: 4.216599913094353
reward_max: -124.5686274509804
reward_min: -136.80952380952382
queue_len: 0.08612470187013799
wait_time: 0.8362924966626794
delay_time: 5.433414076301742
pressure: 1.0233200707338639
total_envstep_count: 292320
total_train_sample_count: 292320
total_episode_count: 2520
total_duration: 17221.248801457637
[2024-12-26 06:17:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80049885377108
avg_train_sample_per_sec: 17.80049885377108
avg_episode_per_sec: 0.15345257632561277
collect_time: 39.100027797959754
reward_mean: -134.66783380018674
reward_std: 4.594907804620999
reward_max: -130.35644257703083
reward_min: -142.78291316526614
queue_len: 0.08930227705582676
wait_time: 0.8614824577045672
delay_time: 5.650676352975149
pressure: 1.0695181255526083
total_envstep_count: 293016
total_train_sample_count: 293016
total_episode_count: 2526
total_duration: 17260.348829255596
[2024-12-26 06:18:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.72822061599747
avg_train_sample_per_sec: 17.72822061599747
avg_episode_per_sec: 0.1528294880689437
collect_time: 39.25943923396059
reward_mean: -134.14775910364145
reward_std: 4.638136848142878
reward_max: -128.91666666666666
reward_min: -141.1204481792717
queue_len: 0.08895739993610176
wait_time: 0.8639609137200414
delay_time: 5.503521217769975
pressure: 1.0701812555260832
total_envstep_count: 293712
total_train_sample_count: 293712
total_episode_count: 2532
total_duration: 17299.608268489555
[2024-12-26 06:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35797439576818
avg_train_sample_per_sec: 17.35797439576818
avg_episode_per_sec: 0.1496377103083464
collect_time: 40.096844489509245
reward_mean: -136.68650793650798
reward_std: 3.3091900178589015
reward_max: -131.16946778711483
reward_min: -141.9306722689076
queue_len: 0.0906409203822997
wait_time: 0.882076095248002
delay_time: 5.7128500869876175
pressure: 1.0803492484526966
total_envstep_count: 294408
total_train_sample_count: 294408
total_episode_count: 2538
total_duration: 17339.705112979063
[2024-12-26 06:19:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.5679012815526
avg_train_sample_per_sec: 17.5679012815526
avg_episode_per_sec: 0.1514474248409707
collect_time: 39.61770895939879
reward_mean: -135.2924836601307
reward_std: 3.68622049105138
reward_max: -129.66596638655463
reward_min: -140.5203081232493
queue_len: 0.08971650110088243
wait_time: 0.8690131777733198
delay_time: 5.617526776696285
pressure: 1.073054818744474
total_envstep_count: 295104
total_train_sample_count: 295104
total_episode_count: 2544
total_duration: 17379.322821938462
[2024-12-26 06:20:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.567957556540563
avg_train_sample_per_sec: 17.567957556540563
avg_episode_per_sec: 0.15144790997017726
collect_time: 39.61758205300757
reward_mean: -133.5348972922502
reward_std: 3.9216953722821195
reward_max: -127.85154061624644
reward_min: -139.79621848739498
queue_len: 0.08855099289937017
wait_time: 0.856441493485104
delay_time: 5.576429321665144
pressure: 1.0738284703801946
total_envstep_count: 295800
total_train_sample_count: 295800
total_episode_count: 2550
total_duration: 17418.94040399147
[2024-12-26 06:20:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.710458962029698
avg_train_sample_per_sec: 17.710458962029698
avg_episode_per_sec: 0.15267637036232498
collect_time: 39.29881215908564
reward_mean: -134.92880485527544
reward_std: 5.923962570778773
reward_max: -124.3641456582633
reward_min: -141.32282913165267
queue_len: 0.0894753347846654
wait_time: 0.879306552417607
delay_time: 5.566986473731572
pressure: 1.0712864721485411
total_envstep_count: 296496
total_train_sample_count: 296496
total_episode_count: 2556
total_duration: 17458.239216150556
[2024-12-26 06:21:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.555560189961806
avg_train_sample_per_sec: 17.555560189961806
avg_episode_per_sec: 0.15134103612036037
collect_time: 39.64555915441365
reward_mean: -133.7316760037348
reward_std: 3.0426039551554402
reward_max: -128.9432773109244
reward_min: -137.5763305322128
queue_len: 0.08868148276109734
wait_time: 0.8652819881268159
delay_time: 5.558607143777965
pressure: 1.0579133510167993
total_envstep_count: 297192
total_train_sample_count: 297192
total_episode_count: 2562
total_duration: 17497.88477530497
[2024-12-26 06:22:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.880038923799578
avg_train_sample_per_sec: 17.880038923799578
avg_episode_per_sec: 0.1541382665844791
collect_time: 38.92608975663781
reward_mean: -132.90709617180207
reward_std: 3.9772707330387713
reward_max: -126.32142857142856
reward_min: -138.22969187675068
queue_len: 0.08813467915901992
wait_time: 0.855806535700045
delay_time: 5.576615868873894
pressure: 1.0551503094606545
total_envstep_count: 297888
total_train_sample_count: 297888
total_episode_count: 2568
total_duration: 17536.81086506161
[2024-12-26 06:22:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.50246052410843
avg_train_sample_per_sec: 17.50246052410843
avg_episode_per_sec: 0.15088328038024507
collect_time: 39.76583743990213
reward_mean: -133.5592903828198
reward_std: 4.944008086300744
reward_max: -127.50350140056021
reward_min: -142.2401960784314
queue_len: 0.08856716868887256
wait_time: 0.864329783637593
delay_time: 5.470638906769044
pressure: 1.066865605658709
total_envstep_count: 298584
total_train_sample_count: 298584
total_episode_count: 2574
total_duration: 17576.576702501512
[2024-12-26 06:23:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.839992181275427
avg_train_sample_per_sec: 17.839992181275427
avg_episode_per_sec: 0.1537930360454778
collect_time: 39.01347001320497
reward_mean: -132.72432306255834
reward_std: 1.7984377491010561
reward_max: -130.46498599439772
reward_min: -135.59523809523807
queue_len: 0.08801347683193524
wait_time: 0.8580744742636224
delay_time: 5.546516219406428
pressure: 1.0599027409372235
total_envstep_count: 299280
total_train_sample_count: 299280
total_episode_count: 2580
total_duration: 17615.590172514716
[2024-12-26 06:24:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.902190010795636
avg_train_sample_per_sec: 17.902190010795636
avg_episode_per_sec: 0.15432922423099688
collect_time: 38.87792496785522
reward_mean: -131.33415032679736
reward_std: 2.5806329111583013
reward_max: -126.93767507002798
reward_min: -134.22619047619045
queue_len: 0.08709161162254468
wait_time: 0.8484999548006646
delay_time: 5.361233287493719
pressure: 1.043103448275862
total_envstep_count: 299976
total_train_sample_count: 299976
total_episode_count: 2586
total_duration: 17654.46809748257
[2024-12-26 06:24:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.61180964189381
avg_train_sample_per_sec: 17.61180964189381
avg_episode_per_sec: 0.15182594518873976
collect_time: 39.51893724449537
reward_mean: -135.6826563958917
reward_std: 3.6015365635396837
reward_max: -131.13655462184872
reward_min: -141.5021008403361
queue_len: 0.08997523633679821
wait_time: 0.8716085019330455
delay_time: 5.679890944705815
pressure: 1.0781388152077807
total_envstep_count: 300672
total_train_sample_count: 300672
total_episode_count: 2592
total_duration: 17693.987034727066
[2024-12-26 06:25:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.71995767402802
avg_train_sample_per_sec: 17.71995767402802
avg_episode_per_sec: 0.15275825581058639
collect_time: 39.27774618898333
reward_mean: -133.74801587301587
reward_std: 3.333068349573013
reward_max: -129.50420168067228
reward_min: -139.40406162464984
queue_len: 0.08869231821818029
wait_time: 0.8618541138825115
delay_time: 5.526223246438437
pressure: 1.0707338638373123
total_envstep_count: 301368
total_train_sample_count: 301368
total_episode_count: 2598
total_duration: 17733.264780916048
[2024-12-26 06:26:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.560943679944724
avg_train_sample_per_sec: 17.560943679944724
avg_episode_per_sec: 0.15138744551676486
collect_time: 39.633405395796515
reward_mean: -131.94677871148457
reward_std: 4.401111401993791
reward_max: -124.86134453781511
reward_min: -138.5455182072829
queue_len: 0.08749786386703222
wait_time: 0.8430466240430744
delay_time: 5.544380801768913
pressure: 1.0434350132625996
total_envstep_count: 302064
total_train_sample_count: 302064
total_episode_count: 2604
total_duration: 17772.898186311846
[2024-12-26 06:26:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.585500825759663
avg_train_sample_per_sec: 17.585500825759663
avg_episode_per_sec: 0.15159914504965227
collect_time: 39.57805961263739
reward_mean: -135.21790382819793
reward_std: 8.439223764322456
reward_max: -125.87394957983194
reward_min: -151.65546218487398
queue_len: 0.08966704497891109
wait_time: 0.8746018743483247
delay_time: 5.7285257725554315
pressure: 1.072281167108753
total_envstep_count: 302760
total_train_sample_count: 302760
total_episode_count: 2610
total_duration: 17812.476245924485
[2024-12-26 06:27:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7411403470222
avg_train_sample_per_sec: 17.7411403470222
avg_episode_per_sec: 0.1529408650605362
collect_time: 39.23084911037422
reward_mean: -130.2543183940243
reward_std: 3.172199198695575
reward_max: -125.27030812324935
reward_min: -134.39355742296922
queue_len: 0.08637554270160762
wait_time: 0.8342536506202833
delay_time: 5.4252496212290575
pressure: 1.0340406719717063
total_envstep_count: 303456
total_train_sample_count: 303456
total_episode_count: 2616
total_duration: 17851.70709503486
[2024-12-26 06:28:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.529757323163373
avg_train_sample_per_sec: 17.529757323163373
avg_episode_per_sec: 0.15111859761347737
collect_time: 39.70391530065983
reward_mean: -133.83356676003734
reward_std: 4.698652045145403
reward_max: -126.79831932773108
reward_min: -140.89775910364148
queue_len: 0.08874904957562159
wait_time: 0.8585303374223252
delay_time: 5.554811341865679
pressure: 1.0772546419098141
total_envstep_count: 304152
total_train_sample_count: 304152
total_episode_count: 2622
total_duration: 17891.41101033552
[2024-12-26 06:28:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.529592779924865
avg_train_sample_per_sec: 17.529592779924865
avg_episode_per_sec: 0.15111717913728331
collect_time: 39.70428798534721
reward_mean: -134.96195144724555
reward_std: 3.811288318446368
reward_max: -129.35434173669466
reward_min: -140.28851540616245
queue_len: 0.08949731528331933
wait_time: 0.8718326411024181
delay_time: 5.656309368103147
pressure: 1.0717285587975243
total_envstep_count: 304848
total_train_sample_count: 304848
total_episode_count: 2628
total_duration: 17931.115298320867
[2024-12-26 06:29:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83426807000152
avg_train_sample_per_sec: 17.83426807000152
avg_episode_per_sec: 0.1537436902586338
collect_time: 39.025991830341525
reward_mean: -131.37745098039215
reward_std: 2.891769958950688
reward_max: -128.00000000000006
reward_min: -137.15546218487395
queue_len: 0.08712032558381443
wait_time: 0.8376874069698612
delay_time: 5.4541584734463475
pressure: 1.0477453580901857
total_envstep_count: 305544
total_train_sample_count: 305544
total_episode_count: 2634
total_duration: 17970.14129015121
[2024-12-26 06:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.677053687972542
avg_train_sample_per_sec: 17.677053687972542
avg_episode_per_sec: 0.15238839386183226
collect_time: 39.37307722686604
reward_mean: -133.8423202614379
reward_std: 7.365616330683506
reward_max: -125.27240896358543
reward_min: -145.83403361344537
queue_len: 0.08875485428477314
wait_time: 0.8606481275091822
delay_time: 5.583103892099577
pressure: 1.0645446507515473
total_envstep_count: 306240
total_train_sample_count: 306240
total_episode_count: 2640
total_duration: 18009.514367378073
[2024-12-26 06:30:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.871232709103264
avg_train_sample_per_sec: 17.871232709103264
avg_episode_per_sec: 0.15406235094054538
collect_time: 38.945270946277304
reward_mean: -132.82586367880484
reward_std: 3.5522144682918615
reward_max: -127.59663865546216
reward_min: -137.80182072829126
queue_len: 0.08808081145809339
wait_time: 0.8575550688887402
delay_time: 5.589640365498194
pressure: 1.057471264367816
total_envstep_count: 306936
total_train_sample_count: 306936
total_episode_count: 2646
total_duration: 18048.45963832435
[2024-12-26 06:31:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.543136966152318
avg_train_sample_per_sec: 17.543136966152318
avg_episode_per_sec: 0.15123393936338206
collect_time: 39.6736342732124
reward_mean: -130.81582633053222
reward_std: 4.35111376703257
reward_max: -123.81232492997195
reward_min: -135.71778711484592
queue_len: 0.08674789544465
wait_time: 0.8456249984520777
delay_time: 5.43997065887564
pressure: 1.0411140583554377
total_envstep_count: 307632
total_train_sample_count: 307632
total_episode_count: 2652
total_duration: 18088.133272597563
[2024-12-26 06:32:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.730518249338576
avg_train_sample_per_sec: 17.730518249338576
avg_episode_per_sec: 0.15284929525291877
collect_time: 39.25435174608975
reward_mean: -134.14355742296917
reward_std: 3.4638863603202084
reward_max: -129.78851540616247
reward_min: -139.81302521008405
queue_len: 0.08895461367570902
wait_time: 0.8617202185914153
delay_time: 5.566019442421613
pressure: 1.066423519009726
total_envstep_count: 308328
total_train_sample_count: 308328
total_episode_count: 2658
total_duration: 18127.387624343653
[2024-12-26 06:32:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.716887059680893
avg_train_sample_per_sec: 17.716887059680893
avg_episode_per_sec: 0.15273178499724907
collect_time: 39.28455363831483
reward_mean: -132.0857843137255
reward_std: 2.9479239536610007
reward_max: -126.00140056022408
reward_min: -134.80462184873946
queue_len: 0.08759004264835908
wait_time: 0.8472075943551601
delay_time: 5.581830103395117
pressure: 1.0484084880636606
total_envstep_count: 309024
total_train_sample_count: 309024
total_episode_count: 2664
total_duration: 18166.672177981967
[2024-12-26 06:33:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.884443711670627
avg_train_sample_per_sec: 17.884443711670627
avg_episode_per_sec: 0.1541762388937123
collect_time: 38.916502588549626
reward_mean: -132.11332866479924
reward_std: 3.0203204742370184
reward_max: -127.64075630252103
reward_min: -137.43837535013998
queue_len: 0.087608308133156
wait_time: 0.8452311295871134
delay_time: 5.528470751935031
pressure: 1.0523872679045094
total_envstep_count: 309720
total_train_sample_count: 309720
total_episode_count: 2670
total_duration: 18205.588680570516
[2024-12-26 06:34:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.480325131977143
avg_train_sample_per_sec: 17.480325131977143
avg_episode_per_sec: 0.15069245803428571
collect_time: 39.816193048194044
reward_mean: -134.3081232492997
reward_std: 5.471673179412263
reward_max: -127.30742296918764
reward_min: -144.266106442577
queue_len: 0.08906374220775842
wait_time: 0.8678597433668429
delay_time: 5.64178616079899
pressure: 1.0590185676392574
total_envstep_count: 310416
total_train_sample_count: 310416
total_episode_count: 2676
total_duration: 18245.40487361871
[2024-12-26 06:34:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.430997623846665
avg_train_sample_per_sec: 17.430997623846665
avg_episode_per_sec: 0.15026722089522987
collect_time: 39.928867814647035
reward_mean: -133.15627917833802
reward_std: 4.384381199349454
reward_max: -125.90196078431372
reward_min: -139.01260504201687
queue_len: 0.0882999198795345
wait_time: 0.856288713540235
delay_time: 5.695076392397517
pressure: 1.0366931918656055
total_envstep_count: 311112
total_train_sample_count: 311112
total_episode_count: 2682
total_duration: 18285.33374143336
[2024-12-26 06:35:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.848948992196043
avg_train_sample_per_sec: 17.848948992196043
avg_episode_per_sec: 0.1538702499327245
collect_time: 38.99389259862341
reward_mean: -132.25070028011206
reward_std: 2.2362434552258796
reward_max: -128.66806722689077
reward_min: -134.90896358543415
queue_len: 0.08769940336877458
wait_time: 0.8530917119279189
delay_time: 5.600310394541999
pressure: 1.0415561450044206
total_envstep_count: 311808
total_train_sample_count: 311808
total_episode_count: 2688
total_duration: 18324.327634031983
[2024-12-26 06:36:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.811002776531257
avg_train_sample_per_sec: 17.811002776531257
avg_episode_per_sec: 0.15354312738389014
collect_time: 39.07696881149709
reward_mean: -130.25735294117644
reward_std: 4.151222441259344
reward_max: -124.06162464985991
reward_min: -135.93067226890759
queue_len: 0.08637755500078015
wait_time: 0.8417229955642735
delay_time: 5.432050614839718
pressure: 1.029840848806366
total_envstep_count: 312504
total_train_sample_count: 312504
total_episode_count: 2694
total_duration: 18363.40460284348
[2024-12-26 06:36:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.715386610242817
avg_train_sample_per_sec: 17.715386610242817
avg_episode_per_sec: 0.15271885008830013
collect_time: 39.287880942862486
reward_mean: -135.21311858076564
reward_std: 6.995160253344372
reward_max: -125.21918767507005
reward_min: -143.39425770308125
queue_len: 0.08966387173790825
wait_time: 0.8687288244210153
delay_time: 5.821984373337489
pressure: 1.0523872679045094
total_envstep_count: 313200
total_train_sample_count: 313200
total_episode_count: 2700
total_duration: 18402.69248378634
[2024-12-26 06:37:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.712444383415704
avg_train_sample_per_sec: 17.712444383415704
avg_episode_per_sec: 0.1526934860639285
collect_time: 39.29440708091482
reward_mean: -130.27264239028943
reward_std: 4.451208481711371
reward_max: -126.43277310924373
reward_min: -139.40616246498598
queue_len: 0.08638769389276486
wait_time: 0.8449977802792206
delay_time: 5.457770616486978
pressure: 1.0264146772767462
total_envstep_count: 313896
total_train_sample_count: 313896
total_episode_count: 2706
total_duration: 18441.986890867254
[2024-12-26 06:38:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.624990275643267
avg_train_sample_per_sec: 17.624990275643267
avg_episode_per_sec: 0.15193957134175232
collect_time: 39.489383489863954
reward_mean: -132.72093837535013
reward_std: 1.447396761965903
reward_max: -130.63865546218486
reward_min: -134.4852941176471
queue_len: 0.08801123234439663
wait_time: 0.8526933540878776
delay_time: 5.490936898238929
pressure: 1.0479664014146772
total_envstep_count: 314592
total_train_sample_count: 314592
total_episode_count: 2712
total_duration: 18481.47627435712
[2024-12-26 06:38:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68657491978591
avg_train_sample_per_sec: 17.68657491978591
avg_episode_per_sec: 0.15247047344643025
collect_time: 39.35188147827238
reward_mean: -136.8021708683473
reward_std: 1.229310089716213
reward_max: -135.3067226890756
reward_min: -138.35784313725486
queue_len: 0.09071761993922234
wait_time: 0.8845448767482237
delay_time: 5.7956043444107275
pressure: 1.0740495137046862
total_envstep_count: 315288
total_train_sample_count: 315288
total_episode_count: 2718
total_duration: 18520.828155835392
[2024-12-26 06:39:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.876358383697912
avg_train_sample_per_sec: 17.876358383697912
avg_episode_per_sec: 0.15410653779049924
collect_time: 38.93410419846512
reward_mean: -129.18288982259568
reward_std: 3.9995117728147473
reward_max: -123.51330532212884
reward_min: -134.9593837535014
queue_len: 0.08566504630145605
wait_time: 0.8307544945475981
delay_time: 5.280392016778495
pressure: 1.0166887709991157
total_envstep_count: 315984
total_train_sample_count: 315984
total_episode_count: 2724
total_duration: 18559.76226003386
[2024-12-26 06:40:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.764690768801465
avg_train_sample_per_sec: 17.764690768801465
avg_episode_per_sec: 0.15314388593794365
collect_time: 39.17884127892181
reward_mean: -133.26937441643324
reward_std: 2.615614610263412
reward_max: -129.03221288515408
reward_min: -137.31302521008405
queue_len: 0.08837491672177271
wait_time: 0.8561647249527574
delay_time: 5.610105126100801
pressure: 1.0552608311229001
total_envstep_count: 316680
total_train_sample_count: 316680
total_episode_count: 2730
total_duration: 18598.94110131278
[2024-12-26 06:40:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.636649190878476
avg_train_sample_per_sec: 17.636649190878476
avg_episode_per_sec: 0.152040079231711
collect_time: 39.463278566541156
reward_mean: -135.8328664799253
reward_std: 5.94119923359194
reward_max: -128.26190476190467
reward_min: -146.3060224089636
queue_len: 0.09007484514583906
wait_time: 0.8699785396032862
delay_time: 5.691195728886413
pressure: 1.0785809018567638
total_envstep_count: 317376
total_train_sample_count: 317376
total_episode_count: 2736
total_duration: 18638.40437987932
[2024-12-26 06:41:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8471441129306
avg_train_sample_per_sec: 17.8471441129306
avg_episode_per_sec: 0.15385469062871207
collect_time: 38.99783604569734
reward_mean: -137.4277544351074
reward_std: 4.903239769400386
reward_max: -129.2163865546219
reward_min: -143.94467787114846
queue_len: 0.09113246315325423
wait_time: 0.8854227035641843
delay_time: 5.8417361587038465
pressure: 1.0972590627763041
total_envstep_count: 318072
total_train_sample_count: 318072
total_episode_count: 2742
total_duration: 18677.40221592502
[2024-12-26 06:42:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.715587378349305
avg_train_sample_per_sec: 17.715587378349305
avg_episode_per_sec: 0.15272058084783882
collect_time: 39.28743569917418
reward_mean: -130.9654528478058
reward_std: 3.840681867653439
reward_max: -127.38095238095237
reward_min: -139.28711484593842
queue_len: 0.08684711727308077
wait_time: 0.8407053913519431
delay_time: 5.564341264856125
pressure: 1.0355879752431476
total_envstep_count: 318768
total_train_sample_count: 318768
total_episode_count: 2748
total_duration: 18716.689651624194
[2024-12-26 06:42:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.733483083488302
avg_train_sample_per_sec: 17.733483083488302
avg_episode_per_sec: 0.15287485416800262
collect_time: 39.247788870537654
reward_mean: -134.23937908496734
reward_std: 5.1749537779431884
reward_max: -126.31092436974792
reward_min: -142.4922969187675
queue_len: 0.08901815589188815
wait_time: 0.8689966150032075
delay_time: 5.556936803235782
pressure: 1.0692970822281167
total_envstep_count: 319464
total_train_sample_count: 319464
total_episode_count: 2754
total_duration: 18755.93744049473
[2024-12-26 06:43:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.988553357410467
avg_train_sample_per_sec: 17.988553357410467
avg_episode_per_sec: 0.1550737358397454
collect_time: 38.69127139750121
reward_mean: -133.49941643323996
reward_std: 4.777649015293026
reward_max: -126.35364145658272
reward_min: -139.9768907563025
queue_len: 0.08852746447827585
wait_time: 0.8528114605700813
delay_time: 5.686511253858658
pressure: 1.0565870910698496
total_envstep_count: 320160
total_train_sample_count: 320160
total_episode_count: 2760
total_duration: 18794.62871189223
[2024-12-26 06:44:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.974355498966247
avg_train_sample_per_sec: 17.974355498966247
avg_episode_per_sec: 0.1549513405083297
collect_time: 38.721833449885246
reward_mean: -133.531279178338
reward_std: 3.295169354946994
reward_max: -128.44327731092437
reward_min: -137.62464985994396
queue_len: 0.08854859361958752
wait_time: 0.862434739589912
delay_time: 5.567695751722725
pressure: 1.0570291777188328
total_envstep_count: 320856
total_train_sample_count: 320856
total_episode_count: 2766
total_duration: 18833.350545342117
[2024-12-26 06:44:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.580484202981836
avg_train_sample_per_sec: 17.580484202981836
avg_episode_per_sec: 0.15155589830156757
collect_time: 39.589353283110995
reward_mean: -131.90044351073763
reward_std: 4.314270132332992
reward_max: -125.4411764705882
reward_min: -137.9124649859944
queue_len: 0.08746713760658993
wait_time: 0.8534649934244256
delay_time: 5.555866757767973
pressure: 1.0401193633952255
total_envstep_count: 321552
total_train_sample_count: 321552
total_episode_count: 2772
total_duration: 18872.939898625227
[2024-12-26 06:45:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.66048517449658
avg_train_sample_per_sec: 17.66048517449658
avg_episode_per_sec: 0.15224556184910842
collect_time: 39.410015813443806
reward_mean: -132.31781045751634
reward_std: 3.2782308709651815
reward_max: -127.70028011204485
reward_min: -137.40266106442573
queue_len: 0.08774390613893657
wait_time: 0.8551144595769343
delay_time: 5.51718495495323
pressure: 1.0482979664014145
total_envstep_count: 322248
total_train_sample_count: 322248
total_episode_count: 2778
total_duration: 18912.34991443867
[2024-12-26 06:46:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.647636296202815
avg_train_sample_per_sec: 17.647636296202815
avg_episode_per_sec: 0.1521347956569208
collect_time: 39.43870942930505
reward_mean: -129.2985527544351
reward_std: 4.8400516485551615
reward_max: -124.1813725490196
reward_min: -136.34173669467788
queue_len: 0.08574174585837872
wait_time: 0.8300361037430002
delay_time: 5.499500519073998
pressure: 1.0173519009725907
total_envstep_count: 322944
total_train_sample_count: 322944
total_episode_count: 2784
total_duration: 18951.788623867975
[2024-12-26 06:46:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.509589355483854
avg_train_sample_per_sec: 17.509589355483854
avg_episode_per_sec: 0.15094473582313667
collect_time: 39.749647228706635
reward_mean: -136.05532212885154
reward_std: 5.310616233866221
reward_max: -127.35784313725487
reward_min: -142.6890756302521
queue_len: 0.09022236215441082
wait_time: 0.881813180621497
delay_time: 5.71067205943245
pressure: 1.071507515473033
total_envstep_count: 323640
total_train_sample_count: 323640
total_episode_count: 2790
total_duration: 18991.53827109668
[2024-12-26 06:47:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74409251561486
avg_train_sample_per_sec: 17.74409251561486
avg_episode_per_sec: 0.1529663147897833
collect_time: 39.22432208846509
reward_mean: -132.75116713352008
reward_std: 4.873841847969228
reward_max: -127.65826330532208
reward_min: -141.02030812324932
queue_len: 0.08803127794000006
wait_time: 0.849902372531683
delay_time: 5.6075438128099115
pressure: 1.0435455349248453
total_envstep_count: 324336
total_train_sample_count: 324336
total_episode_count: 2796
total_duration: 19030.762593185147
[2024-12-26 06:48:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.589614549904134
avg_train_sample_per_sec: 17.589614549904134
avg_episode_per_sec: 0.15163460818882873
collect_time: 39.56880339960567
reward_mean: -131.82854808590105
reward_std: 2.149843726336368
reward_max: -129.11274509803928
reward_min: -135.07142857142858
queue_len: 0.08741946159542509
wait_time: 0.8414613192757208
delay_time: 5.5298996915697884
pressure: 1.0428824049513705
total_envstep_count: 325032
total_train_sample_count: 325032
total_episode_count: 2802
total_duration: 19070.331396584752
[2024-12-26 06:48:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.767430052234893
avg_train_sample_per_sec: 17.767430052234893
avg_episode_per_sec: 0.1531675004503008
collect_time: 39.17280090332777
reward_mean: -133.19257703081232
reward_std: 3.557048662641842
reward_max: -130.06652661064427
reward_min: -139.37675070028013
queue_len: 0.08832399007348297
wait_time: 0.8521448477711157
delay_time: 5.618588194906784
pressure: 1.056366047745358
total_envstep_count: 325728
total_train_sample_count: 325728
total_episode_count: 2808
total_duration: 19109.50419748808
[2024-12-26 06:49:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.624930803526258
avg_train_sample_per_sec: 17.624930803526258
avg_episode_per_sec: 0.15193905865108845
collect_time: 39.48951673959195
reward_mean: -131.98867880485528
reward_std: 2.8258354812929056
reward_max: -128.81442577030808
reward_min: -137.45658263305316
queue_len: 0.08752564907483772
wait_time: 0.8439086620501426
delay_time: 5.5679909770393445
pressure: 1.0485190097259063
total_envstep_count: 326424
total_train_sample_count: 326424
total_episode_count: 2814
total_duration: 19148.993714227672
[2024-12-26 06:50:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.03813903101545
avg_train_sample_per_sec: 18.03813903101545
avg_episode_per_sec: 0.15550119854323666
collect_time: 38.58491160331293
reward_mean: -132.95121381886085
reward_std: 4.112308739583075
reward_max: -129.16106442577026
reward_min: -141.25070028011203
queue_len: 0.0881639348931438
wait_time: 0.8588783103869311
delay_time: 5.56646212646482
pressure: 1.0572502210433246
total_envstep_count: 327120
total_train_sample_count: 327120
total_episode_count: 2820
total_duration: 19187.578625830985
[2024-12-26 06:50:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.932987571542913
avg_train_sample_per_sec: 17.932987571542913
avg_episode_per_sec: 0.15459472044433545
collect_time: 38.81115721646138
reward_mean: -128.50536881419234
reward_std: 2.070158605482824
reward_max: -124.56792717086839
reward_min: -131.24859943977592
queue_len: 0.08521576181312489
wait_time: 0.8213839912622877
delay_time: 5.342650723827524
pressure: 1.021662245800177
total_envstep_count: 327816
total_train_sample_count: 327816
total_episode_count: 2826
total_duration: 19226.389783047445
[2024-12-26 06:51:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.588692917033953
avg_train_sample_per_sec: 17.588692917033953
avg_episode_per_sec: 0.15162666307787892
collect_time: 39.570876771971584
reward_mean: -129.98272642390285
reward_std: 4.990431115614492
reward_max: -122.87535014005603
reward_min: -135.99509803921563
queue_len: 0.08619544192566504
wait_time: 0.8271931119928077
delay_time: 5.483885932983076
pressure: 1.030282935455349
total_envstep_count: 328512
total_train_sample_count: 328512
total_episode_count: 2832
total_duration: 19265.960659819415
[2024-12-26 06:52:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.819739789648583
avg_train_sample_per_sec: 17.819739789648583
avg_episode_per_sec: 0.1536184464624878
collect_time: 39.05780938531458
reward_mean: -133.8469887955182
reward_std: 4.847287858460058
reward_max: -124.92156862745098
reward_min: -141.4124649859944
queue_len: 0.08875795012965398
wait_time: 0.862275226182427
delay_time: 5.448343557352049
pressure: 1.0771441202475684
total_envstep_count: 329208
total_train_sample_count: 329208
total_episode_count: 2838
total_duration: 19305.01846920473
[2024-12-26 06:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.034885527930488
avg_train_sample_per_sec: 18.034885527930488
avg_episode_per_sec: 0.15547315110284904
collect_time: 38.59187234219536
reward_mean: -132.29470121381885
reward_std: 5.662628339269537
reward_max: -122.38585434173669
reward_min: -141.21708683473395
queue_len: 0.08772858170677644
wait_time: 0.8538042980233649
delay_time: 5.494319640960449
pressure: 1.0540450928381961
total_envstep_count: 329904
total_train_sample_count: 329904
total_episode_count: 2844
total_duration: 19343.610341546926
[2024-12-26 06:53:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.67984233323347
avg_train_sample_per_sec: 17.67984233323347
avg_episode_per_sec: 0.15241243390718506
collect_time: 39.366866903088976
reward_mean: -132.95448179271708
reward_std: 4.251493510790382
reward_max: -127.05112044817929
reward_min: -139.7310924369747
queue_len: 0.08816610198456037
wait_time: 0.8570245958684092
delay_time: 5.476072737825855
pressure: 1.0676392572944298
total_envstep_count: 330600
total_train_sample_count: 330600
total_episode_count: 2850
total_duration: 19382.977208450015
[2024-12-26 06:54:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.592813055958217
avg_train_sample_per_sec: 17.592813055958217
avg_episode_per_sec: 0.15166218151688118
collect_time: 39.561609492819755
reward_mean: -132.9515639589169
reward_std: 4.325149983470879
reward_max: -124.0980392156863
reward_min: -137.47268907563023
queue_len: 0.08816416708150988
wait_time: 0.8567895438458318
delay_time: 5.570916569701949
pressure: 1.0468611847922193
total_envstep_count: 331296
total_train_sample_count: 331296
total_episode_count: 2856
total_duration: 19422.538817942834
[2024-12-26 06:54:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.661052942921653
avg_train_sample_per_sec: 17.661052942921653
avg_episode_per_sec: 0.15225045640449703
collect_time: 39.40874885825812
reward_mean: -132.88818860877686
reward_std: 3.248305936507415
reward_max: -128.6771708683473
reward_min: -136.8760504201681
queue_len: 0.08812214098725253
wait_time: 0.8550682540920876
delay_time: 5.487551963280111
pressure: 1.0517241379310345
total_envstep_count: 331992
total_train_sample_count: 331992
total_episode_count: 2862
total_duration: 19461.947566801093
[2024-12-26 06:55:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68346262916598
avg_train_sample_per_sec: 17.68346262916598
avg_episode_per_sec: 0.15244364335487914
collect_time: 39.358807412076736
reward_mean: -131.49871615312793
reward_std: 4.333479796244207
reward_max: -124.79131652661071
reward_min: -139.66526610644257
queue_len: 0.08720074015459411
wait_time: 0.8468628720276793
delay_time: 5.498808458227
pressure: 1.04420866489832
total_envstep_count: 332688
total_train_sample_count: 332688
total_episode_count: 2868
total_duration: 19501.30637421317
[2024-12-26 06:56:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.58205487000323
avg_train_sample_per_sec: 17.58205487000323
avg_episode_per_sec: 0.1515694385345106
collect_time: 39.5858166264426
reward_mean: -129.64390756302518
reward_std: 3.3283018078931215
reward_max: -124.1813725490196
reward_min: -134.10154061624647
queue_len: 0.08597076098343846
wait_time: 0.8387500557252081
delay_time: 5.290830130042379
pressure: 1.0349248452696729
total_envstep_count: 333384
total_train_sample_count: 333384
total_episode_count: 2874
total_duration: 19540.892190839615
[2024-12-26 06:56:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73466407595142
avg_train_sample_per_sec: 17.73466407595142
avg_episode_per_sec: 0.15288503513751225
collect_time: 39.245175269138066
reward_mean: -130.1706349206349
reward_std: 4.683275587924572
reward_max: -122.9411764705882
reward_min: -136.01120448179267
queue_len: 0.08632004968211864
wait_time: 0.8382814222063716
delay_time: 5.407147131863262
pressure: 1.0295092838196285
total_envstep_count: 334080
total_train_sample_count: 334080
total_episode_count: 2880
total_duration: 19580.137366108753
[2024-12-26 06:57:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.64504140350032
avg_train_sample_per_sec: 17.64504140350032
avg_episode_per_sec: 0.1521124258922441
collect_time: 39.444509314777335
reward_mean: -130.42693744164333
reward_std: 3.0352071841988635
reward_max: -127.6428571428571
reward_min: -136.01820728291315
queue_len: 0.08649001156607646
wait_time: 0.8459760672615643
delay_time: 5.410203421029249
pressure: 1.0339301503094604
total_envstep_count: 334776
total_train_sample_count: 334776
total_episode_count: 2886
total_duration: 19619.58187542353
[2024-12-26 06:58:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65467152394604
avg_train_sample_per_sec: 17.65467152394604
avg_episode_per_sec: 0.1521954441719486
collect_time: 39.42299345847219
reward_mean: -129.70051353874882
reward_std: 4.803650613604907
reward_max: -120.57282913165265
reward_min: -134.74649859943975
queue_len: 0.08600829810261858
wait_time: 0.8345032531138008
delay_time: 5.325259711883311
pressure: 1.0264146772767464
total_envstep_count: 335472
total_train_sample_count: 335472
total_episode_count: 2892
total_duration: 19659.004868882002
[2024-12-26 06:58:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.654174838055077
avg_train_sample_per_sec: 17.654174838055077
avg_episode_per_sec: 0.1521911623970265
collect_time: 39.42410259241983
reward_mean: -130.75910364145662
reward_std: 3.858218957552368
reward_max: -125.71778711484593
reward_min: -137.5896358543418
queue_len: 0.08671028092934789
wait_time: 0.8395005659204443
delay_time: 5.338290925467632
pressure: 1.046971706454465
total_envstep_count: 336168
total_train_sample_count: 336168
total_episode_count: 2898
total_duration: 19698.428971474423
[2024-12-26 06:59:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.609669148721768
avg_train_sample_per_sec: 17.609669148721768
avg_episode_per_sec: 0.15180749266139454
collect_time: 39.523740856342016
reward_mean: -134.0592903828198
reward_std: 3.4564380545963322
reward_max: -127.60854341736689
reward_min: -138.76190476190476
queue_len: 0.08889873367560995
wait_time: 0.8708398036491344
delay_time: 5.578429356983778
pressure: 1.0656498673740054
total_envstep_count: 336864
total_train_sample_count: 336864
total_episode_count: 2904
total_duration: 19737.952712330763
[2024-12-26 07:00:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.030311949173505
avg_train_sample_per_sec: 18.030311949173505
avg_episode_per_sec: 0.1554337236997716
collect_time: 38.601661577569324
reward_mean: -129.22117180205416
reward_std: 3.398495612478335
reward_max: -122.4348739495798
reward_min: -133.421568627451
queue_len: 0.08569043222947888
wait_time: 0.83128883737403
delay_time: 5.294917223521165
pressure: 1.0412245800176834
total_envstep_count: 337560
total_train_sample_count: 337560
total_episode_count: 2910
total_duration: 19776.554373908333
[2024-12-26 07:00:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.78466890076489
avg_train_sample_per_sec: 17.78466890076489
avg_episode_per_sec: 0.15331611121349042
collect_time: 39.13483033524825
reward_mean: -132.96230158730157
reward_std: 3.0361463075198567
reward_max: -128.20728291316533
reward_min: -136.47198879551817
queue_len: 0.0881712875247358
wait_time: 0.8590673117169061
delay_time: 5.462917365240408
pressure: 1.0540450928381964
total_envstep_count: 338256
total_train_sample_count: 338256
total_episode_count: 2916
total_duration: 19815.689204243583
[2024-12-26 07:01:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.6763085330314
avg_train_sample_per_sec: 17.6763085330314
avg_episode_per_sec: 0.15238197011233967
collect_time: 39.37473702155613
reward_mean: -131.03676470588235
reward_std: 3.4856467432100375
reward_max: -124.82913165266108
reward_min: -135.54481792717087
queue_len: 0.0868944063036355
wait_time: 0.848764339953488
delay_time: 5.410295087889256
pressure: 1.0400088417329796
total_envstep_count: 338952
total_train_sample_count: 338952
total_episode_count: 2922
total_duration: 19855.06394126514
[2024-12-26 07:02:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.548458092049323
avg_train_sample_per_sec: 17.548458092049323
avg_episode_per_sec: 0.15127981113835623
collect_time: 39.66160424746016
reward_mean: -131.02380952380955
reward_std: 4.045798535890001
reward_max: -125.71428571428577
reward_min: -136.8949579831932
queue_len: 0.08688581533409119
wait_time: 0.8431950698051104
delay_time: 5.418033628577537
pressure: 1.0541556145004423
total_envstep_count: 339648
total_train_sample_count: 339648
total_episode_count: 2928
total_duration: 19894.7255455126
[2024-12-26 07:02:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.497016878344144
avg_train_sample_per_sec: 17.497016878344144
avg_episode_per_sec: 0.15083635239951848
collect_time: 39.778209327867266
reward_mean: -129.18709150326796
reward_std: 3.761531234924842
reward_max: -124.56442577030813
reward_min: -136.20518207282916
queue_len: 0.08566783256184879
wait_time: 0.8228148907662091
delay_time: 5.349930042446918
pressure: 1.0208885941644563
total_envstep_count: 340344
total_train_sample_count: 340344
total_episode_count: 2934
total_duration: 19934.503754840465
[2024-12-26 07:03:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79924263925699
avg_train_sample_per_sec: 17.79924263925699
avg_episode_per_sec: 0.15344174689014645
collect_time: 39.10278735483623
reward_mean: -125.82598039215685
reward_std: 1.570209200570978
reward_max: -124.0763305322129
reward_min: -127.88165266106446
queue_len: 0.0834389790398918
wait_time: 0.8064837672469518
delay_time: 5.231443204762882
pressure: 1.0074049513704686
total_envstep_count: 341040
total_train_sample_count: 341040
total_episode_count: 2940
total_duration: 19973.606542195303
[2024-12-26 07:04:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84166994177895
avg_train_sample_per_sec: 17.84166994177895
avg_episode_per_sec: 0.15380749949809439
collect_time: 39.009801339851684
reward_mean: -132.29598506069095
reward_std: 4.931940100362775
reward_max: -125.45098039215688
reward_min: -139.6267507002801
queue_len: 0.08772943306411866
wait_time: 0.8556280602426648
delay_time: 5.441372557074479
pressure: 1.070291777188329
total_envstep_count: 341736
total_train_sample_count: 341736
total_episode_count: 2946
total_duration: 20012.616343535155
[2024-12-26 07:04:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75029993288702
avg_train_sample_per_sec: 17.75029993288702
avg_episode_per_sec: 0.15301982700764674
collect_time: 39.210605039438235
reward_mean: -129.45331465919705
reward_std: 2.7161752247267352
reward_max: -124.7787114845939
reward_min: -133.67226890756302
queue_len: 0.08584437311617839
wait_time: 0.8368218861373019
delay_time: 5.347009240167814
pressure: 1.0250884173297967
total_envstep_count: 342432
total_train_sample_count: 342432
total_episode_count: 2952
total_duration: 20051.826948574595
[2024-12-26 07:05:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85491983110387
avg_train_sample_per_sec: 17.85491983110387
avg_episode_per_sec: 0.15392172268192994
collect_time: 38.98085270523279
reward_mean: -130.7329598506069
reward_std: 3.7126137155211913
reward_max: -124.20868347338936
reward_min: -134.8669467787115
queue_len: 0.08669294419801521
wait_time: 0.8378632509590928
delay_time: 5.3856550539963495
pressure: 1.0422192749778956
total_envstep_count: 343128
total_train_sample_count: 343128
total_episode_count: 2958
total_duration: 20090.80780127983
[2024-12-26 07:06:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.606708299759475
avg_train_sample_per_sec: 17.606708299759475
avg_episode_per_sec: 0.1517819681013748
collect_time: 39.530387404073025
reward_mean: -131.37943510737628
reward_std: 4.918291997023717
reward_max: -124.96288515406168
reward_min: -137.6085434173669
queue_len: 0.08712164131788878
wait_time: 0.8499584847201479
delay_time: 5.457271514727986
pressure: 1.0408930150309461
total_envstep_count: 343824
total_train_sample_count: 343824
total_episode_count: 2964
total_duration: 20130.3381886839
[2024-12-26 07:06:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.629341032668634
avg_train_sample_per_sec: 17.629341032668634
avg_episode_per_sec: 0.15197707786783307
collect_time: 39.47963787814043
reward_mean: -130.1908263305322
reward_std: 2.2046228137505675
reward_max: -127.56792717086834
reward_min: -134.53081232492994
queue_len: 0.08633343921122826
wait_time: 0.8362864597651617
delay_time: 5.433150096661959
pressure: 1.0341511936339522
total_envstep_count: 344520
total_train_sample_count: 344520
total_episode_count: 2970
total_duration: 20169.81782656204
[2024-12-26 07:07:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65908563693397
avg_train_sample_per_sec: 17.65908563693397
avg_episode_per_sec: 0.15223349687012044
collect_time: 39.41313917999901
reward_mean: -128.91153127917832
reward_std: 2.933057985974524
reward_max: -124.40266106442574
reward_min: -132.53711484593842
queue_len: 0.08548510031775751
wait_time: 0.8345400936678827
delay_time: 5.31904520049425
pressure: 1.0323828470380194
total_envstep_count: 345216
total_train_sample_count: 345216
total_episode_count: 2976
total_duration: 20209.23096574204
[2024-12-26 07:08:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94442536862505
avg_train_sample_per_sec: 17.94442536862505
avg_episode_per_sec: 0.1546933221433194
collect_time: 38.78641894083284
reward_mean: -127.49171335200747
reward_std: 4.251716534198513
reward_max: -121.67927170868347
reward_min: -134.47689075630254
queue_len: 0.08454357649337364
wait_time: 0.8131313975634463
delay_time: 5.345970869606166
pressure: 1.0047524314765692
total_envstep_count: 345912
total_train_sample_count: 345912
total_episode_count: 2982
total_duration: 20248.017384682873
[2024-12-26 07:08:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.637675275066936
avg_train_sample_per_sec: 17.637675275066936
avg_episode_per_sec: 0.1520489247850598
collect_time: 39.460982762500635
reward_mean: -128.39239028944914
reward_std: 4.033890765140907
reward_max: -121.41596638655464
reward_min: -133.53011204481797
queue_len: 0.0851408423670087
wait_time: 0.8264528180856784
delay_time: 5.371523480790192
pressure: 1.0313881520778072
total_envstep_count: 346608
total_train_sample_count: 346608
total_episode_count: 2988
total_duration: 20287.478367445372
[2024-12-26 07:09:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.710042439419695
avg_train_sample_per_sec: 17.710042439419695
avg_episode_per_sec: 0.1526727796501698
collect_time: 39.299736428119246
reward_mean: -130.92927170868347
reward_std: 3.717790962053697
reward_max: -124.92577030812325
reward_min: -135.62324929971984
queue_len: 0.0868231244752543
wait_time: 0.8387250567777952
delay_time: 5.406357821661675
pressure: 1.046419098143236
total_envstep_count: 347304
total_train_sample_count: 347304
total_episode_count: 2994
total_duration: 20326.77810387349
[2024-12-26 07:10:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.929035921559734
avg_train_sample_per_sec: 17.929035921559734
avg_episode_per_sec: 0.1545606544962046
collect_time: 38.81971139134466
reward_mean: -128.77380952380952
reward_std: 5.627244549668124
reward_max: -120.90546218487394
reward_min: -136.46498599439772
queue_len: 0.08539377289377288
wait_time: 0.8263790595813921
delay_time: 5.306744411877786
pressure: 1.0362511052166223
total_envstep_count: 348000
total_train_sample_count: 348000
total_episode_count: 3000
total_duration: 20365.597815264835
[2024-12-26 07:10:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74755373445669
avg_train_sample_per_sec: 17.74755373445669
avg_episode_per_sec: 0.15299615288324733
collect_time: 39.21667236024327
reward_mean: -128.86379551820727
reward_std: 3.201944332242625
reward_max: -124.00700280112038
reward_min: -133.10854341736697
queue_len: 0.08545344530385098
wait_time: 0.8275210393618102
delay_time: 5.3911985897835715
pressure: 1.0235411140583555
total_envstep_count: 348696
total_train_sample_count: 348696
total_episode_count: 3006
total_duration: 20404.814487625077
[2024-12-26 07:11:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.77858776299313
avg_train_sample_per_sec: 17.77858776299313
avg_episode_per_sec: 0.15326368761200973
collect_time: 39.148216341950004
reward_mean: -131.22934173669464
reward_std: 3.392883851922087
reward_max: -128.83893557422974
reward_min: -137.6330532212885
queue_len: 0.08702210990496993
wait_time: 0.8472276399507637
delay_time: 5.427007644833641
pressure: 1.0377984084880636
total_envstep_count: 349392
total_train_sample_count: 349392
total_episode_count: 3012
total_duration: 20443.962703967027
[2024-12-26 07:12:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.59990509424404
avg_train_sample_per_sec: 17.59990509424404
avg_episode_per_sec: 0.15172331977796585
collect_time: 39.545667790425945
reward_mean: -128.0248599439776
reward_std: 3.9895208484866087
reward_max: -123.24019607843141
reward_min: -134.48739495798318
queue_len: 0.08489712197876499
wait_time: 0.8249621687755561
delay_time: 5.377401665301761
pressure: 1.0340406719717066
total_envstep_count: 350088
total_train_sample_count: 350088
total_episode_count: 3018
total_duration: 20483.508371757453
[2024-12-26 07:12:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.748632865316065
avg_train_sample_per_sec: 17.748632865316065
avg_episode_per_sec: 0.15300545573548333
collect_time: 39.21428795567155
reward_mean: -130.43639122315594
reward_std: 3.6517585594974284
reward_max: -125.71988795518202
reward_min: -134.96848739495798
queue_len: 0.08649628065196015
wait_time: 0.8387084166115605
delay_time: 5.412997328772348
pressure: 1.0382404951370467
total_envstep_count: 350784
total_train_sample_count: 350784
total_episode_count: 3024
total_duration: 20522.722659713123
[2024-12-26 07:13:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600491498222556
avg_train_sample_per_sec: 17.600491498222556
avg_episode_per_sec: 0.15172837498467723
collect_time: 39.54435022853128
reward_mean: -131.4173669467787
reward_std: 3.267082044514638
reward_max: -124.52591036414563
reward_min: -133.91736694677874
queue_len: 0.08714679505754556
wait_time: 0.8507468416190526
delay_time: 5.361464886894429
pressure: 1.0429929266136162
total_envstep_count: 351480
total_train_sample_count: 351480
total_episode_count: 3030
total_duration: 20562.267009941654
[2024-12-26 07:14:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.07143963544247
avg_train_sample_per_sec: 18.07143963544247
avg_episode_per_sec: 0.15578827271933166
collect_time: 38.51381041247956
reward_mean: -128.23716153127916
reward_std: 3.179655391387875
reward_max: -123.63865546218486
reward_min: -133.6295518207283
queue_len: 0.08503790552472092
wait_time: 0.8301792091726171
delay_time: 5.220177082488132
pressure: 1.0329354553492485
total_envstep_count: 352176
total_train_sample_count: 352176
total_episode_count: 3036
total_duration: 20600.78082035413
[2024-12-26 07:14:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600210276777183
avg_train_sample_per_sec: 17.600210276777183
avg_episode_per_sec: 0.15172595066187225
collect_time: 39.54498208003491
reward_mean: -129.07831465919702
reward_std: 2.1434699306536458
reward_max: -126.19047619047619
reward_min: -132.42577030812325
queue_len: 0.08559569937612534
wait_time: 0.827064170053521
delay_time: 5.303699093595649
pressure: 1.0372458001768348
total_envstep_count: 352872
total_train_sample_count: 352872
total_episode_count: 3042
total_duration: 20640.325802434167
[2024-12-26 07:15:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.732021293748492
avg_train_sample_per_sec: 17.732021293748492
avg_episode_per_sec: 0.15286225253231459
collect_time: 39.25102437393181
reward_mean: -129.44059290382816
reward_std: 2.952557468205486
reward_max: -125.77731092436973
reward_min: -134.20938375350138
queue_len: 0.08583593693887809
wait_time: 0.8394013440920135
delay_time: 5.282080687106839
pressure: 1.0349248452696729
total_envstep_count: 353568
total_train_sample_count: 353568
total_episode_count: 3048
total_duration: 20679.576826808097
[2024-12-26 07:16:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.98470837136838
avg_train_sample_per_sec: 17.98470837136838
avg_episode_per_sec: 0.1550405894083481
collect_time: 38.69954328022525
reward_mean: -128.6651493930906
reward_std: 3.944764901026154
reward_max: -123.15546218487394
reward_min: -134.92577030812328
queue_len: 0.08532171710417147
wait_time: 0.8265021194154053
delay_time: 5.326074264519041
pressure: 1.0276304155614502
total_envstep_count: 354264
total_train_sample_count: 354264
total_episode_count: 3054
total_duration: 20718.276370088322
[2024-12-26 07:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.724395227543756
avg_train_sample_per_sec: 17.724395227543756
avg_episode_per_sec: 0.15279651058227375
collect_time: 39.26791244862415
reward_mean: -129.19631185807657
reward_std: 3.5653333055451655
reward_max: -122.25280112044817
reward_min: -133.0098039215686
queue_len: 0.08567394685548842
wait_time: 0.8357434485730632
delay_time: 5.3129290029478
pressure: 1.0291777188328914
total_envstep_count: 354960
total_train_sample_count: 354960
total_episode_count: 3060
total_duration: 20757.544282536946
[2024-12-26 07:17:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76209711846455
avg_train_sample_per_sec: 17.76209711846455
avg_episode_per_sec: 0.1531215268833151
collect_time: 39.18456223710626
reward_mean: -129.45448179271708
reward_std: 5.067828503017211
reward_max: -123.1701680672269
reward_min: -135.5448179271709
queue_len: 0.0858451470773986
wait_time: 0.8308200490629497
delay_time: 5.356543851691147
pressure: 1.0310565870910697
total_envstep_count: 355656
total_train_sample_count: 355656
total_episode_count: 3066
total_duration: 20796.728844774054
[2024-12-26 07:18:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.735413446588186
avg_train_sample_per_sec: 17.735413446588186
avg_episode_per_sec: 0.1528914952292085
collect_time: 39.24351705112866
reward_mean: -127.68790849673202
reward_std: 2.283272967279567
reward_max: -124.61134453781516
reward_min: -131.2955182072829
queue_len: 0.08467367937449073
wait_time: 0.8188789883769597
delay_time: 5.262200941022163
pressure: 1.026083112290009
total_envstep_count: 356352
total_train_sample_count: 356352
total_episode_count: 3072
total_duration: 20835.97236182518
[2024-12-26 07:18:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.552642639759817
avg_train_sample_per_sec: 17.552642639759817
avg_episode_per_sec: 0.15131588482551567
collect_time: 39.6521489261929
reward_mean: -130.01669000933705
reward_std: 2.6880578861780022
reward_max: -125.94467787114839
reward_min: -134.296218487395
queue_len: 0.0862179641971731
wait_time: 0.8370367377720318
delay_time: 5.276894861650264
pressure: 1.0416666666666667
total_envstep_count: 357048
total_train_sample_count: 357048
total_episode_count: 3078
total_duration: 20875.624510751375
[2024-12-26 07:19:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.69927052227264
avg_train_sample_per_sec: 17.69927052227264
avg_episode_per_sec: 0.1525799182954538
collect_time: 39.323654561026025
reward_mean: -128.250233426704
reward_std: 2.9003233969624356
reward_max: -124.74649859943978
reward_min: -133.8249299719888
queue_len: 0.08504657389038728
wait_time: 0.8284682131031015
delay_time: 5.1888177784779
pressure: 1.0413351016799293
total_envstep_count: 357744
total_train_sample_count: 357744
total_episode_count: 3084
total_duration: 20914.948165312402
[2024-12-26 07:20:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.794690760812873
avg_train_sample_per_sec: 17.794690760812873
avg_episode_per_sec: 0.15340250655873167
collect_time: 39.112789840254926
reward_mean: -127.0454014939309
reward_std: 2.798772253862721
reward_max: -123.19817927170872
reward_min: -130.8508403361344
queue_len: 0.08424761372276585
wait_time: 0.8202718089888476
delay_time: 5.275044663656016
pressure: 1.002763041556145
total_envstep_count: 358440
total_train_sample_count: 358440
total_episode_count: 3090
total_duration: 20954.060955152658
[2024-12-26 07:20:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.014933718453058
avg_train_sample_per_sec: 18.014933718453058
avg_episode_per_sec: 0.15530115274528497
collect_time: 38.63461342003569
reward_mean: -125.72432306255835
reward_std: 3.875077447803342
reward_max: -121.75210084033615
reward_min: -133.71428571428572
queue_len: 0.08337156701761166
wait_time: 0.8011154948274624
delay_time: 5.271549462374302
pressure: 0.991710875331565
total_envstep_count: 359136
total_train_sample_count: 359136
total_episode_count: 3096
total_duration: 20992.695568572693
[2024-12-26 07:21:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65111106696352
avg_train_sample_per_sec: 17.65111106696352
avg_episode_per_sec: 0.15216475057727172
collect_time: 39.43094558521359
reward_mean: -125.57294584500467
reward_std: 3.163300823723192
reward_max: -119.05952380952381
reward_min: -129.27521008403363
queue_len: 0.08327118424735058
wait_time: 0.8041152911208692
delay_time: 5.16460476592493
pressure: 1.0072944297082227
total_envstep_count: 359832
total_train_sample_count: 359832
total_episode_count: 3102
total_duration: 21032.126514157906
[2024-12-26 07:22:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.952449619718372
avg_train_sample_per_sec: 17.952449619718372
avg_episode_per_sec: 0.1547624967217101
collect_time: 38.76908247861266
reward_mean: -127.73494397759104
reward_std: 4.0500057731031625
reward_max: -120.70028011204481
reward_min: -133.1001400560224
queue_len: 0.08470487001166514
wait_time: 0.8216020161380202
delay_time: 5.260764618511865
pressure: 1.0213306808134395
total_envstep_count: 360528
total_train_sample_count: 360528
total_episode_count: 3108
total_duration: 21070.895596636517
[2024-12-26 07:22:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.95511051162947
avg_train_sample_per_sec: 17.95511051162947
avg_episode_per_sec: 0.15478543544508164
collect_time: 38.76333702035434
reward_mean: -126.64752567693745
reward_std: 5.162457982977429
reward_max: -118.47899159663866
reward_min: -134.89915966386556
queue_len: 0.08398377034279671
wait_time: 0.8119264173397034
delay_time: 5.222733167846555
pressure: 1.009283819628647
total_envstep_count: 361224
total_train_sample_count: 361224
total_episode_count: 3114
total_duration: 21109.658933656872
[2024-12-26 07:23:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.526600132804916
avg_train_sample_per_sec: 17.526600132804916
avg_episode_per_sec: 0.15109138045521478
collect_time: 39.711067447546874
reward_mean: -129.69631185807654
reward_std: 3.2864322398228825
reward_max: -125.6512605042017
reward_min: -134.51470588235296
queue_len: 0.08600551184222582
wait_time: 0.8391337083020654
delay_time: 5.385937018487797
pressure: 1.0396772767462423
total_envstep_count: 361920
total_train_sample_count: 361920
total_episode_count: 3120
total_duration: 21149.37000110442
[2024-12-26 07:24:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.596775845577596
avg_train_sample_per_sec: 17.596775845577596
avg_episode_per_sec: 0.15169634349635858
collect_time: 39.55270022803172
reward_mean: -125.32609710550885
reward_std: 5.227472534147214
reward_max: -118.93067226890751
reward_min: -134.10574229691878
queue_len: 0.08310749144927643
wait_time: 0.8076591047559609
delay_time: 5.116979753479856
pressure: 0.9949160035366931
total_envstep_count: 362616
total_train_sample_count: 362616
total_episode_count: 3126
total_duration: 21188.922701332453
[2024-12-26 07:24:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.932410791640656
avg_train_sample_per_sec: 17.932410791640656
avg_episode_per_sec: 0.15458974820379875
collect_time: 38.812405542507776
reward_mean: -122.6108776844071
reward_std: 5.051934474262454
reward_max: -114.78361344537811
reward_min: -128.37955182072832
queue_len: 0.08130694806658295
wait_time: 0.7873559348584704
delay_time: 4.966616287401016
pressure: 0.9871794871794872
total_envstep_count: 363312
total_train_sample_count: 363312
total_episode_count: 3132
total_duration: 21227.73510687496
[2024-12-26 07:25:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.822232587112087
avg_train_sample_per_sec: 17.822232587112087
avg_episode_per_sec: 0.15363993609579385
collect_time: 39.05234636558964
reward_mean: -126.87406629318396
reward_std: 4.671789966720558
reward_max: -121.45028011204481
reward_min: -135.99439775910372
queue_len: 0.08413399621563923
wait_time: 0.8176341491503761
delay_time: 5.160260754192305
pressure: 1.0048629531388151
total_envstep_count: 364008
total_train_sample_count: 364008
total_episode_count: 3138
total_duration: 21266.787453240548
[2024-12-26 07:26:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.740878895638303
avg_train_sample_per_sec: 17.740878895638303
avg_episode_per_sec: 0.15293861116929572
collect_time: 39.23142726435699
reward_mean: -126.92985527544347
reward_std: 1.8958755703640087
reward_max: -125.38025210084032
reward_min: -130.69887955182068
queue_len: 0.08417099156196518
wait_time: 0.8167676995643527
delay_time: 5.242474278924176
pressure: 1.0205570291777188
total_envstep_count: 364704
total_train_sample_count: 364704
total_episode_count: 3144
total_duration: 21306.018880504904
[2024-12-26 07:26:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65115991301785
avg_train_sample_per_sec: 17.65115991301785
avg_episode_per_sec: 0.152165171663947
collect_time: 39.43083646795898
reward_mean: -122.42740429505136
reward_std: 3.4740564088949064
reward_max: -118.75560224089641
reward_min: -127.59173669467786
queue_len: 0.08118528136276616
wait_time: 0.7891060933657282
delay_time: 5.019492841206461
pressure: 0.9822060123784261
total_envstep_count: 365400
total_train_sample_count: 365400
total_episode_count: 3150
total_duration: 21345.449716972864
[2024-12-26 07:27:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.898229066473473
avg_train_sample_per_sec: 17.898229066473473
avg_episode_per_sec: 0.15429507815925406
collect_time: 38.88652879651263
reward_mean: -124.9440943043884
reward_std: 3.5390980337653652
reward_max: -120.60854341736695
reward_min: -131.62885154061624
queue_len: 0.08285417394190213
wait_time: 0.8023894349959259
delay_time: 5.196844436058858
pressure: 0.9964633068081344
total_envstep_count: 366096
total_train_sample_count: 366096
total_episode_count: 3156
total_duration: 21384.336245769377
[2024-12-26 07:28:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.637649443707048
avg_train_sample_per_sec: 17.637649443707048
avg_episode_per_sec: 0.15204870210092283
collect_time: 39.46104055539705
reward_mean: -128.1657329598506
reward_std: 4.280803192270685
reward_max: -122.16876750700281
reward_min: -134.08963585434174
queue_len: 0.08499053909804417
wait_time: 0.8264369518806639
delay_time: 5.2928372015496015
pressure: 1.0290671971706453
total_envstep_count: 366792
total_train_sample_count: 366792
total_episode_count: 3162
total_duration: 21423.797286324774
[2024-12-26 07:28:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.807050586000578
avg_train_sample_per_sec: 17.807050586000578
avg_episode_per_sec: 0.15350905677586707
collect_time: 39.08564175962842
reward_mean: -124.53291316526611
reward_std: 5.1730373792964235
reward_max: -119.14775910364146
reward_min: -134.33263305322123
queue_len: 0.08258150740402262
wait_time: 0.7960125363142604
delay_time: 5.286790641564546
pressure: 0.9986737400530504
total_envstep_count: 367488
total_train_sample_count: 367488
total_episode_count: 3168
total_duration: 21462.882928084404
[2024-12-26 07:29:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.749051448931063
avg_train_sample_per_sec: 17.749051448931063
avg_episode_per_sec: 0.15300906421492294
collect_time: 39.2133631480299
reward_mean: -125.93265639589168
reward_std: 3.124025096373679
reward_max: -122.60434173669468
reward_min: -132.124649859944
queue_len: 0.08350971909541889
wait_time: 0.8047567501801781
delay_time: 5.144883495905346
pressure: 1.0068523430592395
total_envstep_count: 368184
total_train_sample_count: 368184
total_episode_count: 3174
total_duration: 21502.096291232432
[2024-12-26 07:30:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.605320871634618
avg_train_sample_per_sec: 17.605320871634618
avg_episode_per_sec: 0.15177000751409153
collect_time: 39.5335026878938
reward_mean: -127.8876050420168
reward_std: 2.4607320927480276
reward_max: -123.36204481792718
reward_min: -130.6281512605042
queue_len: 0.08480610413926844
wait_time: 0.8203139124792269
delay_time: 5.331435279856273
pressure: 1.0096153846153844
total_envstep_count: 368880
total_train_sample_count: 368880
total_episode_count: 3180
total_duration: 21541.629793920325
[2024-12-26 07:30:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94885494242887
avg_train_sample_per_sec: 17.94885494242887
avg_episode_per_sec: 0.1547315081243868
collect_time: 38.776846892597156
reward_mean: -124.09593837535012
reward_std: 6.026872043406269
reward_max: -116.74369747899158
reward_min: -135.3711484593837
queue_len: 0.08229173632317648
wait_time: 0.7965246664536725
delay_time: 5.155867106399355
pressure: 0.995579133510168
total_envstep_count: 369576
total_train_sample_count: 369576
total_episode_count: 3186
total_duration: 21580.406640812922
[2024-12-26 07:31:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.815710420100704
avg_train_sample_per_sec: 17.815710420100704
avg_episode_per_sec: 0.1535837105181095
collect_time: 39.066643068846304
reward_mean: -123.17028478057887
reward_std: 1.7113313131481764
reward_max: -120.82843137254898
reward_min: -125.63585434173666
queue_len: 0.08167790767942897
wait_time: 0.7877749574630912
delay_time: 5.108613962519322
pressure: 0.9797745358090184
total_envstep_count: 370272
total_train_sample_count: 370272
total_episode_count: 3192
total_duration: 21619.47328388177
[2024-12-26 07:32:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.683474826347307
avg_train_sample_per_sec: 17.683474826347307
avg_episode_per_sec: 0.15244374850299403
collect_time: 39.35878026432916
reward_mean: -122.32563025210084
reward_std: 2.9900645748520365
reward_max: -118.38935574229689
reward_min: -127.55532212885157
queue_len: 0.08111779194436396
wait_time: 0.7821690789489978
delay_time: 5.1123425717303705
pressure: 0.9588859416445623
total_envstep_count: 370968
total_train_sample_count: 370968
total_episode_count: 3198
total_duration: 21658.8320641461
[2024-12-26 07:32:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.722882910016423
avg_train_sample_per_sec: 17.722882910016423
avg_episode_per_sec: 0.15278347336221054
collect_time: 39.271263232611126
reward_mean: -125.61076097105511
reward_std: 3.754185405136749
reward_max: -121.1386554621849
reward_min: -131.62464985994396
queue_len: 0.08329626059088535
wait_time: 0.8095991159505359
delay_time: 5.174496949686129
pressure: 1.0057471264367817
total_envstep_count: 371664
total_train_sample_count: 371664
total_episode_count: 3204
total_duration: 21698.10332737871
[2024-12-26 07:33:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.846213804391244
avg_train_sample_per_sec: 17.846213804391244
avg_episode_per_sec: 0.1538466707275107
collect_time: 38.999868971016255
reward_mean: -126.89880952380953
reward_std: 2.608052634634855
reward_max: -122.69677871148463
reward_min: -130.5581232492997
queue_len: 0.08415040419350765
wait_time: 0.8181667892621242
delay_time: 5.179757072927807
pressure: 1.01657824933687
total_envstep_count: 372360
total_train_sample_count: 372360
total_episode_count: 3210
total_duration: 21737.103196349726
[2024-12-26 07:34:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.727517230088853
avg_train_sample_per_sec: 17.727517230088853
avg_episode_per_sec: 0.1528234243973177
collect_time: 39.26099695555121
reward_mean: -123.30182072829133
reward_std: 3.960953787956913
reward_max: -115.91106442577028
reward_min: -126.97969187675069
queue_len: 0.0817651331089465
wait_time: 0.7949382781406108
delay_time: 5.128206749156273
pressure: 0.9772325375773652
total_envstep_count: 373056
total_train_sample_count: 373056
total_episode_count: 3216
total_duration: 21776.36419330528
[2024-12-26 07:34:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.825217792419355
avg_train_sample_per_sec: 17.825217792419355
avg_episode_per_sec: 0.1536656706243048
collect_time: 39.04580623390713
reward_mean: -126.51062091503269
reward_std: 5.316439819241023
reward_max: -117.60644257703085
reward_min: -134.92436974789914
queue_len: 0.08389298469166623
wait_time: 0.8118351673118407
delay_time: 5.255351777969427
pressure: 1.0049734748010608
total_envstep_count: 373752
total_train_sample_count: 373752
total_episode_count: 3222
total_duration: 21815.409999539184
[2024-12-26 07:35:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.752822943014237
avg_train_sample_per_sec: 17.752822943014237
avg_episode_per_sec: 0.15304157709495034
collect_time: 39.205032474786044
reward_mean: -124.27532679738563
reward_std: 5.414483731128387
reward_max: -116.22268907563024
reward_min: -134.04831932773112
queue_len: 0.08241069416272258
wait_time: 0.7916740966943806
delay_time: 5.109127165403296
pressure: 0.9916003536693192
total_envstep_count: 374448
total_train_sample_count: 374448
total_episode_count: 3228
total_duration: 21854.61503201397
[2024-12-26 07:36:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76866729351175
avg_train_sample_per_sec: 17.76866729351175
avg_episode_per_sec: 0.15317816632337716
collect_time: 39.17007328141853
reward_mean: -123.02882819794586
reward_std: 1.835086201156444
reward_max: -120.68837535014009
reward_min: -126.64425770308124
queue_len: 0.0815841035795397
wait_time: 0.7811106869803623
delay_time: 5.229486189479004
pressure: 0.9707117595048631
total_envstep_count: 375144
total_train_sample_count: 375144
total_episode_count: 3234
total_duration: 21893.78510529539
[2024-12-26 07:36:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.719786783056346
avg_train_sample_per_sec: 17.719786783056346
avg_episode_per_sec: 0.1527567826125547
collect_time: 39.278124986555426
reward_mean: -125.49813258636787
reward_std: 4.97783860552762
reward_max: -116.9810924369748
reward_min: -132.11484593837528
queue_len: 0.0832215733331352
wait_time: 0.8079918306845285
delay_time: 5.189290621331582
pressure: 1.0085101679929267
total_envstep_count: 375840
total_train_sample_count: 375840
total_episode_count: 3240
total_duration: 21933.063230281943
[2024-12-26 07:37:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.813690651612113
avg_train_sample_per_sec: 17.813690651612113
avg_episode_per_sec: 0.15356629872079405
collect_time: 39.071072559408854
reward_mean: -123.18814192343604
reward_std: 3.0980820507380598
reward_max: -119.39565826330532
reward_min: -128.83893557422965
queue_len: 0.08168974928609815
wait_time: 0.7942635387488329
delay_time: 5.131606932128887
pressure: 0.9801061007957559
total_envstep_count: 376536
total_train_sample_count: 376536
total_episode_count: 3246
total_duration: 21972.13430284135
[2024-12-26 07:38:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.773860418626548
avg_train_sample_per_sec: 17.773860418626548
avg_episode_per_sec: 0.1532229346433323
collect_time: 39.158628660693765
reward_mean: -122.43709150326795
reward_std: 3.048023425493855
reward_max: -118.33683473389353
reward_min: -126.24159663865547
queue_len: 0.08119170524089388
wait_time: 0.7900654182981769
delay_time: 5.072199486874041
pressure: 0.9784482758620688
total_envstep_count: 377232
total_train_sample_count: 377232
total_episode_count: 3252
total_duration: 22011.292931502045
[2024-12-26 07:38:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51532849000145
avg_train_sample_per_sec: 17.51532849000145
avg_episode_per_sec: 0.15099421112070216
collect_time: 39.736622718626634
reward_mean: -124.83228291316527
reward_std: 3.418058803959208
reward_max: -118.59453781512603
reward_min: -129.97549019607843
queue_len: 0.08278002845700615
wait_time: 0.7991987024694934
delay_time: 5.140243550655477
pressure: 0.9969053934571175
total_envstep_count: 377928
total_train_sample_count: 377928
total_episode_count: 3258
total_duration: 22051.02955422067
[2024-12-26 07:39:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.64221604775319
avg_train_sample_per_sec: 17.64221604775319
avg_episode_per_sec: 0.15208806937718267
collect_time: 39.45082625199109
reward_mean: -124.02357609710549
reward_std: 4.613342228236764
reward_max: -118.15686274509802
reward_min: -132.61694677871148
queue_len: 0.08224375072752355
wait_time: 0.7965619713844867
delay_time: 5.15567431265254
pressure: 0.9769009725906277
total_envstep_count: 378624
total_train_sample_count: 378624
total_episode_count: 3264
total_duration: 22090.48038047266
[2024-12-26 07:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.656937426514972
avg_train_sample_per_sec: 17.656937426514972
avg_episode_per_sec: 0.15221497781478424
collect_time: 39.41793433298543
reward_mean: -128.12616713352008
reward_std: 4.353566295626494
reward_max: -119.27731092436971
reward_min: -132.7170868347339
queue_len: 0.08496430181267911
wait_time: 0.8253324318233041
delay_time: 5.371335859181134
pressure: 1.013815207780725
total_envstep_count: 379320
total_train_sample_count: 379320
total_episode_count: 3270
total_duration: 22129.898314805647
[2024-12-26 07:40:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75140311135736
avg_train_sample_per_sec: 17.75140311135736
avg_episode_per_sec: 0.1530293371668738
collect_time: 39.208168257679795
reward_mean: -126.31535947712418
reward_std: 5.791023785565921
reward_max: -119.2920168067227
reward_min: -133.829131652661
queue_len: 0.08376350097952533
wait_time: 0.8112659188343772
delay_time: 5.160853024523415
pressure: 0.9967948717948717
total_envstep_count: 380016
total_train_sample_count: 380016
total_episode_count: 3276
total_duration: 22169.106483063326
[2024-12-26 07:41:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.596518671893193
avg_train_sample_per_sec: 17.596518671893193
avg_episode_per_sec: 0.15169412648183786
collect_time: 39.55327829201332
reward_mean: -127.1576797385621
reward_std: 5.109262756411771
reward_max: -119.59523809523806
reward_min: -135.88795518207286
queue_len: 0.08432206879214993
wait_time: 0.8110328791109723
delay_time: 5.281151864316386
pressure: 1.00342617152962
total_envstep_count: 380712
total_train_sample_count: 380712
total_episode_count: 3282
total_duration: 22208.65976135534
[2024-12-26 07:42:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.69156059856967
avg_train_sample_per_sec: 17.69156059856967
avg_episode_per_sec: 0.1525134534359454
collect_time: 39.3407916798629
reward_mean: -125.97385620915031
reward_std: 3.897575215313737
reward_max: -119.42226890756307
reward_min: -130.77731092436974
queue_len: 0.08353703992649227
wait_time: 0.8153164448803394
delay_time: 5.156139835830995
pressure: 0.9992263483642794
total_envstep_count: 381408
total_train_sample_count: 381408
total_episode_count: 3288
total_duration: 22248.000553035203
[2024-12-26 07:42:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.596365937875422
avg_train_sample_per_sec: 17.596365937875422
avg_episode_per_sec: 0.15169280980927088
collect_time: 39.55362160898745
reward_mean: -122.76669000933704
reward_std: 7.086419356161565
reward_max: -117.05742296918764
reward_min: -138.14075630252103
queue_len: 0.08141027188948081
wait_time: 0.793741734094168
delay_time: 4.994957792565533
pressure: 0.9833112290008841
total_envstep_count: 382104
total_train_sample_count: 382104
total_episode_count: 3294
total_duration: 22287.55417464419
[2024-12-26 07:43:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73744750572008
avg_train_sample_per_sec: 17.73744750572008
avg_episode_per_sec: 0.15290903022172483
collect_time: 39.239016762448465
reward_mean: -123.5703781512605
reward_std: 5.108446585964716
reward_max: -115.64985994397756
reward_min: -131.83333333333334
queue_len: 0.0819432215857165
wait_time: 0.7863092297042601
delay_time: 5.1833955213283245
pressure: 0.9760167992926615
total_envstep_count: 382800
total_train_sample_count: 382800
total_episode_count: 3300
total_duration: 22326.793191406636
[2024-12-26 07:44:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.923085723287954
avg_train_sample_per_sec: 17.923085723287954
avg_episode_per_sec: 0.15450935968351687
collect_time: 38.832598958987745
reward_mean: -122.33158263305323
reward_std: 2.599357293917323
reward_max: -118.02661064425772
reward_min: -126.91526610644262
queue_len: 0.081121739146587
wait_time: 0.7838343339103987
delay_time: 5.044981475557383
pressure: 0.9682802829354555
total_envstep_count: 383496
total_train_sample_count: 383496
total_episode_count: 3306
total_duration: 22365.625790365622
[2024-12-26 07:44:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.744266216860915
avg_train_sample_per_sec: 17.744266216860915
avg_episode_per_sec: 0.15296781221431824
collect_time: 39.22393811577559
reward_mean: -123.11753034547151
reward_std: 1.313071422570925
reward_max: -120.80042016806722
reward_min: -124.26470588235291
queue_len: 0.08164292463227554
wait_time: 0.7858977145234749
delay_time: 5.141888473701735
pressure: 0.9748010610079576
total_envstep_count: 384192
total_train_sample_count: 384192
total_episode_count: 3312
total_duration: 22404.849728481397
[2024-12-26 07:45:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.66326160177091
avg_train_sample_per_sec: 17.66326160177091
avg_episode_per_sec: 0.1522694965669906
collect_time: 39.403821088751776
reward_mean: -124.99673202614379
reward_std: 1.203894192182967
reward_max: -123.30532212885151
reward_min: -126.41316526610647
queue_len: 0.08288907959293355
wait_time: 0.804370233946806
delay_time: 5.223882631270001
pressure: 0.9853006189213085
total_envstep_count: 384888
total_train_sample_count: 384888
total_episode_count: 3318
total_duration: 22444.25354957015
[2024-12-26 07:46:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.723718631875474
avg_train_sample_per_sec: 17.723718631875474
avg_episode_per_sec: 0.15279067786099548
collect_time: 39.26941148502938
reward_mean: -126.43242296918767
reward_std: 3.772345758670197
reward_max: -119.76330532212883
reward_min: -130.78011204481797
queue_len: 0.08384112928991223
wait_time: 0.8165859734698476
delay_time: 5.225755096760291
pressure: 0.9941423519009726
total_envstep_count: 385584
total_train_sample_count: 385584
total_episode_count: 3324
total_duration: 22483.52296105518
[2024-12-26 07:46:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.627590014771368
avg_train_sample_per_sec: 17.627590014771368
avg_episode_per_sec: 0.15196198288596008
collect_time: 39.48355954596027
reward_mean: -125.20868347338937
reward_std: 4.895768798333207
reward_max: -117.78361344537821
reward_min: -132.41386554621852
queue_len: 0.08302963095052346
wait_time: 0.8071218208768919
delay_time: 5.167903478548573
pressure: 0.9898320070733863
total_envstep_count: 386280
total_train_sample_count: 386280
total_episode_count: 3330
total_duration: 22523.00652060114
[2024-12-26 07:47:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.625128118818935
avg_train_sample_per_sec: 17.625128118818935
avg_episode_per_sec: 0.15194075964499082
collect_time: 39.48907465000823
reward_mean: -124.30870681605977
reward_std: 5.096857106113332
reward_max: -117.8886554621849
reward_min: -134.05952380952382
queue_len: 0.08243282945362053
wait_time: 0.7986863401417152
delay_time: 5.168213828782139
pressure: 0.9835322723253758
total_envstep_count: 386976
total_train_sample_count: 386976
total_episode_count: 3336
total_duration: 22562.49559525115
[2024-12-26 07:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97266259715404
avg_train_sample_per_sec: 17.97266259715404
avg_episode_per_sec: 0.15493674652719003
collect_time: 38.72548078158498
reward_mean: -121.37126517273578
reward_std: 4.056178885194028
reward_max: -115.63795518207283
reward_min: -126.72128851540617
queue_len: 0.08048492385459932
wait_time: 0.776469086750527
delay_time: 5.055382966384215
pressure: 0.9599911582670204
total_envstep_count: 387672
total_train_sample_count: 387672
total_episode_count: 3342
total_duration: 22601.221076032733
[2024-12-26 07:48:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.714492551565044
avg_train_sample_per_sec: 17.714492551565044
avg_episode_per_sec: 0.15271114268590555
collect_time: 39.28986382048576
reward_mean: -122.97922502334269
reward_std: 3.9284301980225127
reward_max: -117.70028011204485
reward_min: -128.9733893557423
queue_len: 0.08155121022768083
wait_time: 0.7914211661676164
delay_time: 5.103880557439393
pressure: 0.9696065428824049
total_envstep_count: 388368
total_train_sample_count: 388368
total_episode_count: 3348
total_duration: 22640.51093985322
[2024-12-26 07:49:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.86244162049806
avg_train_sample_per_sec: 17.86244162049806
avg_episode_per_sec: 0.1539865656939488
collect_time: 38.96443805315532
reward_mean: -126.2483660130719
reward_std: 4.0175747001793285
reward_max: -120.03151260504202
reward_min: -131.29341736694676
queue_len: 0.08371907560548535
wait_time: 0.8095354189421126
delay_time: 5.247065011307728
pressure: 1.0026525198938994
total_envstep_count: 389064
total_train_sample_count: 389064
total_episode_count: 3354
total_duration: 22679.475377906372
[2024-12-26 07:50:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.95354158937883
avg_train_sample_per_sec: 17.95354158937883
avg_episode_per_sec: 0.15477191025326578
collect_time: 38.76672446687332
reward_mean: -121.49439775910365
reward_std: 5.219780604099481
reward_max: -111.17717086834732
reward_min: -128.70938375350138
queue_len: 0.08056657676333133
wait_time: 0.7761105105172041
delay_time: 5.008635887471809
pressure: 0.9630857648099028
total_envstep_count: 389760
total_train_sample_count: 389760
total_episode_count: 3360
total_duration: 22718.242102373246
[2024-12-26 07:50:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65822295171321
avg_train_sample_per_sec: 17.65822295171321
avg_episode_per_sec: 0.15222605992856214
collect_time: 39.41506469270588
reward_mean: -124.7705415499533
reward_std: 3.0144053587332893
reward_max: -121.17016806722688
reward_min: -129.33053221288515
queue_len: 0.08273908590845709
wait_time: 0.7923905525959279
delay_time: 5.263298057729242
pressure: 0.9888373121131742
total_envstep_count: 390456
total_train_sample_count: 390456
total_episode_count: 3366
total_duration: 22757.65716706595
[2024-12-26 07:51:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.584430092203622
avg_train_sample_per_sec: 17.584430092203622
avg_episode_per_sec: 0.15158991458796228
collect_time: 39.580469560317695
reward_mean: -125.60119047619047
reward_std: 3.1616628482537776
reward_max: -121.76540616246493
reward_min: -131.31722689075625
queue_len: 0.0832899141088796
wait_time: 0.8041032947219561
delay_time: 5.196080272778644
pressure: 0.989058355437666
total_envstep_count: 391152
total_train_sample_count: 391152
total_episode_count: 3372
total_duration: 22797.23763662627
[2024-12-26 07:52:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.700263727698715
avg_train_sample_per_sec: 17.700263727698715
avg_episode_per_sec: 0.15258848041119583
collect_time: 39.3214480138421
reward_mean: -124.00396825396825
reward_std: 3.9159291655603057
reward_max: -118.81232492997198
reward_min: -128.8641456582633
queue_len: 0.08223074817902404
wait_time: 0.8017692598701727
delay_time: 5.025475043184355
pressure: 1.002763041556145
total_envstep_count: 391848
total_train_sample_count: 391848
total_episode_count: 3378
total_duration: 22836.55908464011
[2024-12-26 07:52:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.694386579563812
avg_train_sample_per_sec: 17.694386579563812
avg_episode_per_sec: 0.15253781534106733
collect_time: 39.33450853864849
reward_mean: -125.3389355742297
reward_std: 3.8208635275249327
reward_max: -120.40966386554622
reward_min: -132.1666666666666
queue_len: 0.08311600502269872
wait_time: 0.807363451569841
delay_time: 5.1763992726477
pressure: 0.9945844385499559
total_envstep_count: 392544
total_train_sample_count: 392544
total_episode_count: 3384
total_duration: 22875.89359317876
[2024-12-26 07:53:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.96482016487263
avg_train_sample_per_sec: 17.96482016487263
avg_episode_per_sec: 0.15486913935235028
collect_time: 38.74238615318388
reward_mean: -122.41013071895428
reward_std: 4.250792970397255
reward_max: -116.91036414565828
reward_min: -129.00350140056022
queue_len: 0.08117382673670707
wait_time: 0.7956427376432447
delay_time: 5.105638790895578
pressure: 0.972259062776304
total_envstep_count: 393240
total_train_sample_count: 393240
total_episode_count: 3390
total_duration: 22914.635979331943
[2024-12-26 07:54:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79930336119023
avg_train_sample_per_sec: 17.79930336119023
avg_episode_per_sec: 0.1534422703550882
collect_time: 39.10265395653433
reward_mean: -124.23109243697478
reward_std: 2.940785788378203
reward_max: -119.73319327731087
reward_min: -128.25630252100837
queue_len: 0.08238136103247665
wait_time: 0.7943692618515131
delay_time: 5.040077834551707
pressure: 0.9920424403183025
total_envstep_count: 393936
total_train_sample_count: 393936
total_episode_count: 3396
total_duration: 22953.738633288478
[2024-12-26 07:54:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76545383809203
avg_train_sample_per_sec: 17.76545383809203
avg_episode_per_sec: 0.153150464121483
collect_time: 39.177158452752984
reward_mean: -128.8108076563959
reward_std: 2.3039689777654577
reward_max: -126.36624649859942
reward_min: -132.48529411764707
queue_len: 0.0854183074644535
wait_time: 0.8304184405857836
delay_time: 5.343442958550156
pressure: 1.0129310344827587
total_envstep_count: 394632
total_train_sample_count: 394632
total_episode_count: 3402
total_duration: 22992.91579174123
[2024-12-26 07:55:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.670599642307
avg_train_sample_per_sec: 17.670599642307
avg_episode_per_sec: 0.15233275553712933
collect_time: 39.387457929477094
reward_mean: -123.78186274509805
reward_std: 4.321436964152552
reward_max: -119.59453781512607
reward_min: -132.0231092436975
queue_len: 0.08208346335881833
wait_time: 0.7890544701523403
delay_time: 5.102737762308099
pressure: 0.9777851458885941
total_envstep_count: 395328
total_train_sample_count: 395328
total_episode_count: 3408
total_duration: 23032.30324967071
[2024-12-26 07:56:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.923419489301317
avg_train_sample_per_sec: 17.923419489301317
avg_episode_per_sec: 0.1545122369767355
collect_time: 38.83187582678907
reward_mean: -124.99019607843134
reward_std: 3.8638347415211993
reward_max: -120.48319327731093
reward_min: -130.7135854341737
queue_len: 0.08288474541010037
wait_time: 0.7972929003608518
delay_time: 5.166119559937246
pressure: 0.9825375773651636
total_envstep_count: 396024
total_train_sample_count: 396024
total_episode_count: 3414
total_duration: 23071.135125497498
[2024-12-26 07:56:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.881994957956177
avg_train_sample_per_sec: 17.881994957956177
avg_episode_per_sec: 0.1541551289478981
collect_time: 38.92183179988712
reward_mean: -123.17518674136319
reward_std: 1.9503491086009992
reward_max: -119.80532212885154
reward_min: -126.08403361344543
queue_len: 0.08168115831655386
wait_time: 0.7947608088328169
delay_time: 5.109481366349473
pressure: 0.9649646330680813
total_envstep_count: 396720
total_train_sample_count: 396720
total_episode_count: 3420
total_duration: 23110.056957297384
[2024-12-26 07:57:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.689478656277267
avg_train_sample_per_sec: 17.689478656277267
avg_episode_per_sec: 0.15249550565756265
collect_time: 39.34542184786312
reward_mean: -125.32504668534081
reward_std: 5.163939768296713
reward_max: -121.33893557422968
reward_min: -136.5917366946779
queue_len: 0.08310679488417826
wait_time: 0.8053340478543318
delay_time: 5.371442090442362
pressure: 0.982316534040672
total_envstep_count: 397416
total_train_sample_count: 397416
total_episode_count: 3426
total_duration: 23149.402379145246
[2024-12-26 07:58:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.654876746878074
avg_train_sample_per_sec: 17.654876746878074
avg_episode_per_sec: 0.1521972133351558
collect_time: 39.42253519969061
reward_mean: -126.92717086834735
reward_std: 4.652423029149496
reward_max: -121.23459383753503
reward_min: -134.20938375350138
queue_len: 0.0841692114511587
wait_time: 0.8164340448823206
delay_time: 5.297960090466467
pressure: 1.009946949602122
total_envstep_count: 398112
total_train_sample_count: 398112
total_episode_count: 3432
total_duration: 23188.824914344936
[2024-12-26 07:58:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52802917328705
avg_train_sample_per_sec: 17.52802917328705
avg_episode_per_sec: 0.15110369976971594
collect_time: 39.70782984893209
reward_mean: -124.35224089635854
reward_std: 3.6179482281873736
reward_max: -117.29481792717087
reward_min: -128.27170868347335
queue_len: 0.0824616982071343
wait_time: 0.7972894175353606
delay_time: 5.1676767477500025
pressure: 0.9715959328028294
total_envstep_count: 398808
total_train_sample_count: 398808
total_episode_count: 3438
total_duration: 23228.532744193868
[2024-12-26 07:59:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.003831675735945
avg_train_sample_per_sec: 18.003831675735945
avg_episode_per_sec: 0.1552054454804823
collect_time: 38.658437411298976
reward_mean: -123.24276377217551
reward_std: 3.6969775470131236
reward_max: -117.72619047619045
reward_min: -130.08543417366946
queue_len: 0.08172597067120393
wait_time: 0.784769433856655
delay_time: 5.192561611003582
pressure: 0.9692749778956674
total_envstep_count: 399504
total_train_sample_count: 399504
total_episode_count: 3444
total_duration: 23267.191181605165
[2024-12-26 08:00:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.843404600143312
avg_train_sample_per_sec: 17.843404600143312
avg_episode_per_sec: 0.15382245344951131
collect_time: 39.006008976247166
reward_mean: -124.50525210084032
reward_std: 5.947637956960458
reward_max: -118.39145658263303
reward_min: -135.70868347338933
queue_len: 0.08256316452310367
wait_time: 0.7994859194783128
delay_time: 5.143260282549341
pressure: 0.975132625994695
total_envstep_count: 400200
total_train_sample_count: 400200
total_episode_count: 3450
total_duration: 23306.197190581413
[2024-12-26 08:00:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.63160911980637
avg_train_sample_per_sec: 17.63160911980637
avg_episode_per_sec: 0.15199663034315838
collect_time: 39.474559313939885
reward_mean: -126.62441643323994
reward_std: 2.077990531030581
reward_max: -123.53361344537814
reward_min: -130.50210084033614
queue_len: 0.08396844591063657
wait_time: 0.8093426252021585
delay_time: 5.355323133317195
pressure: 0.9969053934571176
total_envstep_count: 400896
total_train_sample_count: 400896
total_episode_count: 3456
total_duration: 23345.671749895355
[2024-12-26 08:01:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.695115798125116
avg_train_sample_per_sec: 17.695115798125116
avg_episode_per_sec: 0.15254410170797514
collect_time: 39.332887557240205
reward_mean: -126.95191409897292
reward_std: 3.6554658889931404
reward_max: -119.39425770308121
reward_min: -131.03571428571425
queue_len: 0.08418561942902714
wait_time: 0.8026408949963716
delay_time: 5.431431952338685
pressure: 0.9878426171529621
total_envstep_count: 401592
total_train_sample_count: 401592
total_episode_count: 3462
total_duration: 23385.004637452595
[2024-12-26 08:02:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.571505922116152
avg_train_sample_per_sec: 17.571505922116152
avg_episode_per_sec: 0.1514784993285875
collect_time: 39.60958173334412
reward_mean: -125.62138188608778
reward_std: 3.128218791700602
reward_max: -119.97619047619047
reward_min: -129.5217086834734
queue_len: 0.08330330363798923
wait_time: 0.8050053465241094
delay_time: 5.190865253870769
pressure: 0.989500442086649
total_envstep_count: 402288
total_train_sample_count: 402288
total_episode_count: 3468
total_duration: 23424.61421918594
[2024-12-26 08:02:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.728389444501747
avg_train_sample_per_sec: 17.728389444501747
avg_episode_per_sec: 0.152830943487084
collect_time: 39.25906536399201
reward_mean: -120.96031746031746
reward_std: 1.8683685846110905
reward_max: -118.15266106442577
reward_min: -123.72338935574226
queue_len: 0.08021241210896382
wait_time: 0.7684012375949495
delay_time: 5.089854322574898
pressure: 0.953470380194518
total_envstep_count: 402984
total_train_sample_count: 402984
total_episode_count: 3474
total_duration: 23463.873284549933
[2024-12-26 08:03:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47099926579278
avg_train_sample_per_sec: 17.47099926579278
avg_episode_per_sec: 0.15061206263614466
collect_time: 39.8374465828482
reward_mean: -126.61437908496733
reward_std: 5.033767723949656
reward_max: -121.24089635854337
reward_min: -135.41246498599446
queue_len: 0.08396178984414278
wait_time: 0.8121682802210186
delay_time: 5.289093663248601
pressure: 0.9962422634836429
total_envstep_count: 403680
total_train_sample_count: 403680
total_episode_count: 3480
total_duration: 23503.71073113278
[2024-12-26 08:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.741009577418733
avg_train_sample_per_sec: 17.741009577418733
avg_episode_per_sec: 0.1529397377363684
collect_time: 39.23113828233816
reward_mean: -126.81372549019609
reward_std: 3.144142209329148
reward_max: -122.83543417366946
reward_min: -130.9663865546218
queue_len: 0.08409398242055444
wait_time: 0.8166074895917693
delay_time: 5.30897065489892
pressure: 0.996131741821397
total_envstep_count: 404376
total_train_sample_count: 404376
total_episode_count: 3486
total_duration: 23542.94186941512
[2024-12-26 08:04:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.780616353788652
avg_train_sample_per_sec: 17.780616353788652
avg_episode_per_sec: 0.15328117546369527
collect_time: 39.14374992134049
reward_mean: -125.11122782446311
reward_std: 4.789927030537914
reward_max: -117.88935574229696
reward_min: -129.80462184873952
queue_len: 0.08296500518863602
wait_time: 0.8002322502829603
delay_time: 5.320697374280221
pressure: 0.9829796640141466
total_envstep_count: 405072
total_train_sample_count: 405072
total_episode_count: 3492
total_duration: 23582.08561933646
[2024-12-26 08:05:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.483279022626746
avg_train_sample_per_sec: 17.483279022626746
avg_episode_per_sec: 0.15071792260885125
collect_time: 39.80946589591354
reward_mean: -124.76972455648928
reward_std: 2.9865629494219954
reward_max: -120.5686274509804
reward_min: -129.16456582633052
queue_len: 0.08273854413560296
wait_time: 0.7979979016363399
delay_time: 5.16356632654753
pressure: 0.9871794871794872
total_envstep_count: 405768
total_train_sample_count: 405768
total_episode_count: 3498
total_duration: 23621.895085232372
[2024-12-26 08:06:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.650776661846553
avg_train_sample_per_sec: 17.650776661846553
avg_episode_per_sec: 0.15216186777453924
collect_time: 39.43169262939319
reward_mean: -124.7093837535014
reward_std: 3.931249160238925
reward_max: -119.53711484593838
reward_min: -131.45168067226885
queue_len: 0.08269853034051816
wait_time: 0.7957281829619558
delay_time: 5.278662323828033
pressure: 0.9765694076038903
total_envstep_count: 406464
total_train_sample_count: 406464
total_episode_count: 3504
total_duration: 23661.326777861766
[2024-12-26 08:06:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80233269244609
avg_train_sample_per_sec: 17.80233269244609
avg_episode_per_sec: 0.15346838527970766
collect_time: 39.09600005932524
reward_mean: -125.53489729225025
reward_std: 3.861665188121444
reward_max: -120.81302521008405
reward_min: -132.687675070028
queue_len: 0.08324595311157178
wait_time: 0.8053787828128599
delay_time: 5.2802716751059515
pressure: 0.9960212201591513
total_envstep_count: 407160
total_train_sample_count: 407160
total_episode_count: 3510
total_duration: 23700.422777921092
[2024-12-26 08:07:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.627265676619626
avg_train_sample_per_sec: 17.627265676619626
avg_episode_per_sec: 0.15195918686741056
collect_time: 39.484286035534
reward_mean: -121.51622315592903
reward_std: 2.7500418291488606
reward_max: -118.14845938375353
reward_min: -125.515406162465
queue_len: 0.08058104983814922
wait_time: 0.7764351098529597
delay_time: 5.082828424064742
pressure: 0.9573386383731212
total_envstep_count: 407856
total_train_sample_count: 407856
total_episode_count: 3516
total_duration: 23739.907063956627
[2024-12-26 08:08:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.607972384701778
avg_train_sample_per_sec: 17.607972384701778
avg_episode_per_sec: 0.15179286538536016
collect_time: 39.52754949824326
reward_mean: -129.09990662931838
reward_std: 4.266659275274381
reward_max: -122.48179271708685
reward_min: -136.46498599439775
queue_len: 0.08561001765869919
wait_time: 0.8320392701731443
delay_time: 5.34124787505175
pressure: 1.0223253757736515
total_envstep_count: 408552
total_train_sample_count: 408552
total_episode_count: 3522
total_duration: 23779.43461345487
[2024-12-26 08:08:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.01770023749921
avg_train_sample_per_sec: 18.01770023749921
avg_episode_per_sec: 0.15532500204740698
collect_time: 38.6286812870521
reward_mean: -121.39332399626517
reward_std: 5.227187889459823
reward_max: -115.12955182072827
reward_min: -130.54761904761907
queue_len: 0.08049955172166125
wait_time: 0.7856272924731341
delay_time: 5.082805232482527
pressure: 0.9652961980548188
total_envstep_count: 409248
total_train_sample_count: 409248
total_episode_count: 3528
total_duration: 23818.06329474192
[2024-12-26 08:09:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79536034359148
avg_train_sample_per_sec: 17.79536034359148
avg_episode_per_sec: 0.15340827882406446
collect_time: 39.11131815044396
reward_mean: -123.87103174603175
reward_std: 5.531250572509034
reward_max: -111.99579831932776
reward_min: -129.15616246498598
queue_len: 0.08214259399604226
wait_time: 0.7998935648529968
delay_time: 5.168828165227722
pressure: 0.9849690539345713
total_envstep_count: 409944
total_train_sample_count: 409944
total_episode_count: 3534
total_duration: 23857.174612892366
[2024-12-26 08:10:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.741030235830614
avg_train_sample_per_sec: 17.741030235830614
avg_episode_per_sec: 0.15293991582612598
collect_time: 39.23109259992838
reward_mean: -126.68650793650795
reward_std: 4.586042612457678
reward_max: -117.97128851540613
reward_min: -131.9705882352941
queue_len: 0.08400962064755169
wait_time: 0.8113427731835438
delay_time: 5.356341808014221
pressure: 1.0039787798408488
total_envstep_count: 410640
total_train_sample_count: 410640
total_episode_count: 3540
total_duration: 23896.405705492296
[2024-12-26 08:10:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.648001276814583
avg_train_sample_per_sec: 17.648001276814583
avg_episode_per_sec: 0.15213794204150502
collect_time: 39.43789379222133
reward_mean: -124.2796451914099
reward_std: 6.521734608582479
reward_max: -115.94677871148463
reward_min: -133.9698879551821
queue_len: 0.08241355781923733
wait_time: 0.7993478447966279
delay_time: 5.227430142206071
pressure: 0.9885057471264368
total_envstep_count: 411336
total_train_sample_count: 411336
total_episode_count: 3546
total_duration: 23935.84359928452
[2024-12-26 08:11:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.69855869278792
avg_train_sample_per_sec: 17.69855869278792
avg_episode_per_sec: 0.1525737818343786
collect_time: 39.325236143868416
reward_mean: -124.55088702147525
reward_std: 5.8798183907986
reward_max: -115.41036414565825
reward_min: -133.78781512605036
queue_len: 0.08259342640681382
wait_time: 0.8001752093410309
delay_time: 5.239202398502199
pressure: 0.9911582670203359
total_envstep_count: 412032
total_train_sample_count: 412032
total_episode_count: 3552
total_duration: 23975.168835428387
[2024-12-26 08:12:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47786289237634
avg_train_sample_per_sec: 17.47786289237634
avg_episode_per_sec: 0.1506712318308305
collect_time: 39.82180225842073
reward_mean: -128.88398692810458
reward_std: 6.73513245068499
reward_max: -119.48389355742299
reward_min: -136.6456582633053
queue_len: 0.08546683483296058
wait_time: 0.8361113123410283
delay_time: 5.328379741639691
pressure: 1.0278514588859418
total_envstep_count: 412728
total_train_sample_count: 412728
total_episode_count: 3558
total_duration: 24014.99063768681
[2024-12-26 08:12:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65018745030286
avg_train_sample_per_sec: 17.65018745030286
avg_episode_per_sec: 0.1521567883646798
collect_time: 39.43300896716864
reward_mean: -121.8794351073763
reward_std: 4.438634981262026
reward_max: -116.64915966386555
reward_min: -128.20868347338939
queue_len: 0.08082190656987819
wait_time: 0.7785029020449915
delay_time: 5.0910539159474135
pressure: 0.966290893015031
total_envstep_count: 413424
total_train_sample_count: 413424
total_episode_count: 3564
total_duration: 24054.423646653977
[2024-12-26 08:13:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.941272908547376
avg_train_sample_per_sec: 17.941272908547376
avg_episode_per_sec: 0.15466614576333945
collect_time: 38.79323410037532
reward_mean: -124.92577030812326
reward_std: 4.230722113758086
reward_max: -118.35364145658258
reward_min: -131.79481792717087
queue_len: 0.08284202275074486
wait_time: 0.8046516462464739
delay_time: 5.233442596454956
pressure: 0.9876215738284705
total_envstep_count: 414120
total_train_sample_count: 414120
total_episode_count: 3570
total_duration: 24093.216880754353
[2024-12-26 08:14:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.12259813971697
avg_train_sample_per_sec: 18.12259813971697
avg_episode_per_sec: 0.15622929430790491
collect_time: 38.40508930530586
reward_mean: -123.25350140056021
reward_std: 2.9394843349415534
reward_max: -118.87605042016804
reward_min: -127.27450980392159
queue_len: 0.08173309111442986
wait_time: 0.7962976636277853
delay_time: 5.070023192060188
pressure: 0.9807692307692308
total_envstep_count: 414816
total_train_sample_count: 414816
total_episode_count: 3576
total_duration: 24131.62197005966
[2024-12-26 08:14:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.802969385981996
avg_train_sample_per_sec: 17.802969385981996
avg_episode_per_sec: 0.15347387401708618
collect_time: 39.0946018560268
reward_mean: -126.01715686274504
reward_std: 7.849410462155551
reward_max: -117.20308123249296
reward_min: -139.87955182072827
queue_len: 0.08356575388776198
wait_time: 0.8106859122959529
delay_time: 5.226855895952817
pressure: 0.9954686118479222
total_envstep_count: 415512
total_train_sample_count: 415512
total_episode_count: 3582
total_duration: 24170.716571915687
[2024-12-26 08:15:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.635751606686313
avg_train_sample_per_sec: 17.635751606686313
avg_episode_per_sec: 0.15203234143695096
collect_time: 39.46528707833029
reward_mean: -125.5456349206349
reward_std: 6.007694747312007
reward_max: -119.09873949579836
reward_min: -135.8004201680672
queue_len: 0.08325307355479769
wait_time: 0.8112504396099732
delay_time: 5.178530561650745
pressure: 0.9991158267020337
total_envstep_count: 416208
total_train_sample_count: 416208
total_episode_count: 3588
total_duration: 24210.18185899402
[2024-12-26 08:16:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.558457535237658
avg_train_sample_per_sec: 17.558457535237658
avg_episode_per_sec: 0.1513660132348074
collect_time: 39.639017186060556
reward_mean: -125.1519607843137
reward_std: 3.7159315712191643
reward_max: -118.09243697478989
reward_min: -130.59033613445376
queue_len: 0.08299201643522129
wait_time: 0.8058741953899154
delay_time: 5.145308666012261
pressure: 0.9994473916887712
total_envstep_count: 416904
total_train_sample_count: 416904
total_episode_count: 3594
total_duration: 24249.82087618008
[2024-12-26 08:16:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.656982988673803
avg_train_sample_per_sec: 17.656982988673803
avg_episode_per_sec: 0.15221537059201554
collect_time: 39.41783261876925
reward_mean: -125.16328197945846
reward_std: 4.273734641807274
reward_max: -120.30252100840337
reward_min: -133.57422969187667
queue_len: 0.08299952385905733
wait_time: 0.8064516478563132
delay_time: 5.183897076728701
pressure: 0.9973474801061007
total_envstep_count: 417600
total_train_sample_count: 417600
total_episode_count: 3600
total_duration: 24289.23870879885
[2024-12-26 08:17:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7107395357396
avg_train_sample_per_sec: 17.7107395357396
avg_episode_per_sec: 0.15267878910120342
collect_time: 39.29818958691694
reward_mean: -124.86998132586369
reward_std: 4.670056964501366
reward_max: -117.5322128851541
reward_min: -131.62324929971987
queue_len: 0.0828050274044189
wait_time: 0.7986936153771854
delay_time: 5.210351900362045
pressure: 0.9937002652519894
total_envstep_count: 418296
total_train_sample_count: 418296
total_episode_count: 3606
total_duration: 24328.536898385766
[2024-12-26 08:18:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.6760517543004
avg_train_sample_per_sec: 17.6760517543004
avg_episode_per_sec: 0.15237975650258964
collect_time: 39.37530901552551
reward_mean: -122.44316059757234
reward_std: 4.495892878267026
reward_max: -117.60154061624651
reward_min: -130.94677871148463
queue_len: 0.08119572983923896
wait_time: 0.7875229556897914
delay_time: 5.04619353587303
pressure: 0.9731432360742706
total_envstep_count: 418992
total_train_sample_count: 418992
total_episode_count: 3612
total_duration: 24367.912207401292
[2024-12-26 08:18:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85345872980897
avg_train_sample_per_sec: 17.85345872980897
avg_episode_per_sec: 0.15390912698111184
collect_time: 38.98404284195789
reward_mean: -125.64402427637725
reward_std: 4.077205972142724
reward_max: -117.6015406162465
reward_min: -129.3046218487395
queue_len: 0.08331831848566129
wait_time: 0.7947817057857627
delay_time: 5.258485067074066
pressure: 0.9996684350132625
total_envstep_count: 419688
total_train_sample_count: 419688
total_episode_count: 3618
total_duration: 24406.89625024325
[2024-12-26 08:19:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.64408825209306
avg_train_sample_per_sec: 17.64408825209306
avg_episode_per_sec: 0.15210420906976774
collect_time: 39.44664014687389
reward_mean: -128.90406162464984
reward_std: 6.455804657513115
reward_max: -121.76680672268908
reward_min: -137.78431372549022
queue_len: 0.08548014696594818
wait_time: 0.8257407737630861
delay_time: 5.470388820671197
pressure: 1.0224358974358976
total_envstep_count: 420384
total_train_sample_count: 420384
total_episode_count: 3624
total_duration: 24446.342890390126
[2024-12-26 08:20:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68419276672165
avg_train_sample_per_sec: 17.68419276672165
avg_episode_per_sec: 0.15244993764415218
collect_time: 39.35718238209561
reward_mean: -123.26307189542483
reward_std: 4.317146613689277
reward_max: -117.54691876750694
reward_min: -129.73319327731093
queue_len: 0.08173943759643557
wait_time: 0.7933089349798275
delay_time: 5.198437988805657
pressure: 0.9832007073386383
total_envstep_count: 421080
total_train_sample_count: 421080
total_episode_count: 3630
total_duration: 24485.700072772222
[2024-12-26 08:20:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.741975446316967
avg_train_sample_per_sec: 17.741975446316967
avg_episode_per_sec: 0.15294806419238766
collect_time: 39.22900254855677
reward_mean: -124.82668067226892
reward_std: 4.997011551601357
reward_max: -119.53431372549022
reward_min: -134.6610644257703
queue_len: 0.08277631344314916
wait_time: 0.8055103562202955
delay_time: 5.178103205651468
pressure: 1.0024314765694076
total_envstep_count: 421776
total_train_sample_count: 421776
total_episode_count: 3636
total_duration: 24524.92907532078
[2024-12-26 08:21:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.635861480499813
avg_train_sample_per_sec: 17.635861480499813
avg_episode_per_sec: 0.1520332886249984
collect_time: 39.46504120422899
reward_mean: -123.31395891690009
reward_std: 4.521076045739263
reward_max: -116.40546218487397
reward_min: -131.15476190476193
queue_len: 0.08177318230563665
wait_time: 0.7889760678807333
delay_time: 5.153759294097973
pressure: 0.9849690539345713
total_envstep_count: 422472
total_train_sample_count: 422472
total_episode_count: 3642
total_duration: 24564.394116525007
[2024-12-26 08:22:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.66744816889139
avg_train_sample_per_sec: 17.66744816889139
avg_episode_per_sec: 0.15230558766285682
collect_time: 39.39448376169614
reward_mean: -122.73984593837535
reward_std: 5.040250231131492
reward_max: -116.4607843137255
reward_min: -132.6967787114846
queue_len: 0.08139247078141602
wait_time: 0.7801686987792463
delay_time: 5.033669125323098
pressure: 0.9813218390804598
total_envstep_count: 423168
total_train_sample_count: 423168
total_episode_count: 3648
total_duration: 24603.7886002867
[2024-12-26 08:22:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.834385169298095
avg_train_sample_per_sec: 17.834385169298095
avg_episode_per_sec: 0.1537446997353284
collect_time: 39.025735588472344
reward_mean: -124.87079831932772
reward_std: 3.3382308564610286
reward_max: -120.23739495798318
reward_min: -130.05182072829132
queue_len: 0.08280556917727304
wait_time: 0.8018579558260086
delay_time: 5.192043008863446
pressure: 1.0003315649867373
total_envstep_count: 423864
total_train_sample_count: 423864
total_episode_count: 3654
total_duration: 24642.814335875173
[2024-12-26 08:23:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.92381184821995
avg_train_sample_per_sec: 17.92381184821995
avg_episode_per_sec: 0.15451561938120648
collect_time: 38.83102578256093
reward_mean: -124.25490196078427
reward_std: 5.671397467381962
reward_max: -118.84103641456582
reward_min: -136.29901960784312
queue_len: 0.0823971498413689
wait_time: 0.7912200136464841
delay_time: 5.15615990264378
pressure: 0.9964633068081344
total_envstep_count: 424560
total_train_sample_count: 424560
total_episode_count: 3660
total_duration: 24681.645361657735
[2024-12-26 08:23:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.612496679139753
avg_train_sample_per_sec: 17.612496679139753
avg_episode_per_sec: 0.15183186792361855
collect_time: 39.517395669652146
reward_mean: -127.74229691876748
reward_std: 4.656494039165738
reward_max: -123.18697478991596
reward_min: -137.03501400560216
queue_len: 0.08470974596735246
wait_time: 0.8200568025618734
delay_time: 5.247721439167068
pressure: 1.0173519009725907
total_envstep_count: 425256
total_train_sample_count: 425256
total_episode_count: 3666
total_duration: 24721.162757327387
[2024-12-26 08:24:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.556065166058506
avg_train_sample_per_sec: 17.556065166058506
avg_episode_per_sec: 0.15134538936257333
collect_time: 39.64441880436801
reward_mean: -125.28676470588233
reward_std: 7.044350858149831
reward_max: -118.35364145658261
reward_min: -136.95658263305322
queue_len: 0.0830814089561554
wait_time: 0.8053260760537637
delay_time: 5.234578814319647
pressure: 1.002210433244916
total_envstep_count: 425952
total_train_sample_count: 425952
total_episode_count: 3672
total_duration: 24760.807176131755
[2024-12-26 08:25:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.802493155586088
avg_train_sample_per_sec: 17.802493155586088
avg_episode_per_sec: 0.1534697685826387
collect_time: 39.09564766672067
reward_mean: -118.05252100840336
reward_std: 2.114812585919381
reward_max: -115.48879551820728
reward_min: -121.37184873949579
queue_len: 0.07828416512493591
wait_time: 0.7547819193990591
delay_time: 4.7807657713767195
pressure: 0.9593280282935455
total_envstep_count: 426648
total_train_sample_count: 426648
total_episode_count: 3678
total_duration: 24799.902823798475
[2024-12-26 08:25:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.713488891508508
avg_train_sample_per_sec: 17.713488891508508
avg_episode_per_sec: 0.15270249044403886
collect_time: 39.29209001472592
reward_mean: -126.5887021475257
reward_std: 4.359900311406845
reward_max: -122.64985994397763
reward_min: -135.422268907563
queue_len: 0.08394476269729821
wait_time: 0.8163296375137147
delay_time: 5.1917296094871555
pressure: 1.0045313881520779
total_envstep_count: 427344
total_train_sample_count: 427344
total_episode_count: 3684
total_duration: 24839.1949138132
[2024-12-26 08:26:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.812350197908223
avg_train_sample_per_sec: 17.812350197908223
avg_episode_per_sec: 0.15355474308541572
collect_time: 39.07401282070763
reward_mean: -126.63013538748832
reward_std: 5.563358597376986
reward_max: -115.7170868347339
reward_min: -134.62955182072827
queue_len: 0.08397223832061558
wait_time: 0.8158880926375857
delay_time: 5.1931373665111185
pressure: 1.022656940760389
total_envstep_count: 428040
total_train_sample_count: 428040
total_episode_count: 3690
total_duration: 24878.268926633908
[2024-12-26 08:27:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.575084431539345
avg_train_sample_per_sec: 17.575084431539345
avg_episode_per_sec: 0.15150934854775297
collect_time: 39.60151672164909
reward_mean: -122.65277777777777
reward_std: 5.3353160867083975
reward_max: -114.72198879551817
reward_min: -129.33333333333334
queue_len: 0.08133473327438845
wait_time: 0.7859094787340223
delay_time: 5.043419856377572
pressure: 0.9824270557029178
total_envstep_count: 428736
total_train_sample_count: 428736
total_episode_count: 3696
total_duration: 24917.870443355558
[2024-12-26 08:27:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82184994712416
avg_train_sample_per_sec: 17.82184994712416
avg_episode_per_sec: 0.1536366374752083
collect_time: 39.053184830136594
reward_mean: -125.6373716153128
reward_std: 5.9250175876971465
reward_max: -118.82773109243699
reward_min: -133.94747899159665
queue_len: 0.08331390690670609
wait_time: 0.8090701134565234
delay_time: 5.143225612133284
pressure: 1.0051945181255524
total_envstep_count: 429432
total_train_sample_count: 429432
total_episode_count: 3702
total_duration: 24956.923628185694
[2024-12-26 08:28:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.833565975632798
avg_train_sample_per_sec: 17.833565975632798
avg_episode_per_sec: 0.1537376377209724
collect_time: 39.02752825492062
reward_mean: -124.0760971055089
reward_std: 3.7541573695404478
reward_max: -118.68137254901966
reward_min: -129.8669467787115
queue_len: 0.08227857898243295
wait_time: 0.7876642810086013
delay_time: 5.104175375985484
pressure: 0.9931476569407603
total_envstep_count: 430128
total_train_sample_count: 430128
total_episode_count: 3708
total_duration: 24995.951156440613
[2024-12-26 08:29:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.926777762511097
avg_train_sample_per_sec: 17.926777762511097
avg_episode_per_sec: 0.1545411876078543
collect_time: 38.82460134333186
reward_mean: -123.05170401493929
reward_std: 4.235773823590167
reward_max: -117.69747899159661
reward_min: -129.3039215686274
queue_len: 0.08159927321945576
wait_time: 0.7876307684877664
delay_time: 5.028312031985951
pressure: 0.9869584438549955
total_envstep_count: 430824
total_train_sample_count: 430824
total_episode_count: 3714
total_duration: 25034.775757783944
[2024-12-26 08:29:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.921209610576444
avg_train_sample_per_sec: 17.921209610576444
avg_episode_per_sec: 0.1544931862980728
collect_time: 38.83666421652957
reward_mean: -124.81629318394023
reward_std: 4.125835443046887
reward_max: -117.94467787114843
reward_min: -130.1687675070028
queue_len: 0.08276942518828928
wait_time: 0.8044271974926133
delay_time: 5.057370389727452
pressure: 1.0001105216622457
total_envstep_count: 431520
total_train_sample_count: 431520
total_episode_count: 3720
total_duration: 25073.612422000475
[2024-12-26 08:30:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.958332684279178
avg_train_sample_per_sec: 17.958332684279178
avg_episode_per_sec: 0.15481321279551016
collect_time: 38.75638191118278
reward_mean: -123.0189075630252
reward_std: 2.1509008359224056
reward_max: -120.04761904761895
reward_min: -126.29971988795523
queue_len: 0.08157752490916789
wait_time: 0.7962058718270685
delay_time: 5.074455959772576
pressure: 0.9907161803713528
total_envstep_count: 432216
total_train_sample_count: 432216
total_episode_count: 3726
total_duration: 25112.368803911657
[2024-12-26 08:31:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84960505638754
avg_train_sample_per_sec: 17.84960505638754
avg_episode_per_sec: 0.15387590565851328
collect_time: 38.9924593738243
reward_mean: -124.50408496732025
reward_std: 1.0979626508940294
reward_max: -122.78501400560228
reward_min: -126.15686274509807
queue_len: 0.08256239056188347
wait_time: 0.7977745364281873
delay_time: 5.154690869798177
pressure: 1.0081786030061892
total_envstep_count: 432912
total_train_sample_count: 432912
total_episode_count: 3732
total_duration: 25151.361263285482
[2024-12-26 08:31:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.687937456776005
avg_train_sample_per_sec: 17.687937456776005
avg_episode_per_sec: 0.15248221945496557
collect_time: 39.34885012460127
reward_mean: -122.7000466853408
reward_std: 5.047010373242592
reward_max: -114.41386554621845
reward_min: -129.42086834733897
queue_len: 0.0813660787038069
wait_time: 0.7882517175747398
delay_time: 5.0333039578397685
pressure: 0.9814323607427057
total_envstep_count: 433608
total_train_sample_count: 433608
total_episode_count: 3738
total_duration: 25190.710113410085
[2024-12-26 08:32:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.871951091354955
avg_train_sample_per_sec: 17.871951091354955
avg_episode_per_sec: 0.154068543890991
collect_time: 38.943705499321226
reward_mean: -122.2389122315593
reward_std: 5.7334166694234305
reward_max: -114.39215686274511
reward_min: -130.1071428571429
queue_len: 0.08106028662570244
wait_time: 0.7862983168510551
delay_time: 4.964250638133745
pressure: 0.982869142351901
total_envstep_count: 434304
total_train_sample_count: 434304
total_episode_count: 3744
total_duration: 25229.653818909406
[2024-12-26 08:33:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.886896327078635
avg_train_sample_per_sec: 17.886896327078635
avg_episode_per_sec: 0.15419738212998824
collect_time: 38.911166435640304
reward_mean: -121.99789915966385
reward_std: 3.732495800070077
reward_max: -118.6295518207283
reward_min: -130.0343137254902
queue_len: 0.08090046363372934
wait_time: 0.7896258857212204
delay_time: 4.956904463058177
pressure: 0.9841954022988507
total_envstep_count: 435000
total_train_sample_count: 435000
total_episode_count: 3750
total_duration: 25268.564985345045
[2024-12-26 08:33:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.622179347487133
avg_train_sample_per_sec: 17.622179347487133
avg_episode_per_sec: 0.15191533920247527
collect_time: 39.495682473532845
reward_mean: -121.70506535947713
reward_std: 3.2921086769644976
reward_max: -118.95868347338939
reward_min: -128.54341736694678
queue_len: 0.080706276763579
wait_time: 0.7859895063241917
delay_time: 4.983545230996377
pressure: 0.978448275862069
total_envstep_count: 435696
total_train_sample_count: 435696
total_episode_count: 3756
total_duration: 25308.06066781858
[2024-12-26 08:34:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.645435838367494
avg_train_sample_per_sec: 17.645435838367494
avg_episode_per_sec: 0.15211582619282324
collect_time: 39.44362759726494
reward_mean: -123.3670634920635
reward_std: 4.225127591878206
reward_max: -116.8088235294118
reward_min: -129.57142857142858
queue_len: 0.08180839754115617
wait_time: 0.7965257499993807
delay_time: 5.106840483064006
pressure: 0.9866268788682583
total_envstep_count: 436392
total_train_sample_count: 436392
total_episode_count: 3762
total_duration: 25347.504295415845
[2024-12-26 08:35:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74436444155738
avg_train_sample_per_sec: 17.74436444155738
avg_episode_per_sec: 0.15296865897894293
collect_time: 39.22372098997048
reward_mean: -126.40511204481793
reward_std: 5.407375025328433
reward_max: -118.63165266106441
reward_min: -134.99369747899163
queue_len: 0.08382301859735936
wait_time: 0.8183927859384251
delay_time: 5.236208433343644
pressure: 1.0113837312113174
total_envstep_count: 437088
total_train_sample_count: 437088
total_episode_count: 3768
total_duration: 25386.728016405817
[2024-12-26 08:35:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.698130785121688
avg_train_sample_per_sec: 17.698130785121688
avg_episode_per_sec: 0.15257009297518698
collect_time: 39.32618695444986
reward_mean: -124.75326797385621
reward_std: 5.493725949338669
reward_max: -117.48319327731087
reward_min: -134.27380952380958
queue_len: 0.08272763128239802
wait_time: 0.7963506799713697
delay_time: 5.234125382334462
pressure: 0.9885057471264368
total_envstep_count: 437784
total_train_sample_count: 437784
total_episode_count: 3774
total_duration: 25426.05420336027
[2024-12-26 08:36:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.62818079290635
avg_train_sample_per_sec: 17.62818079290635
avg_episode_per_sec: 0.15196707580091678
collect_time: 39.48223632242717
reward_mean: -125.34512138188607
reward_std: 2.996918274883308
reward_max: -119.86204481792716
reward_min: -129.64285714285714
queue_len: 0.08312010701716584
wait_time: 0.8079471731221227
delay_time: 5.09020348450789
pressure: 1.0029840848806366
total_envstep_count: 438480
total_train_sample_count: 438480
total_episode_count: 3780
total_duration: 25465.536439682695
[2024-12-26 08:37:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.824658529254947
avg_train_sample_per_sec: 17.824658529254947
avg_episode_per_sec: 0.15366084939012886
collect_time: 39.047031327847385
reward_mean: -120.93580765639587
reward_std: 3.576926062766498
reward_max: -116.59803921568626
reward_min: -126.7303921568627
queue_len: 0.08019615892333942
wait_time: 0.7787732466992102
delay_time: 5.022786786156192
pressure: 0.9522546419098142
total_envstep_count: 439176
total_train_sample_count: 439176
total_episode_count: 3786
total_duration: 25504.58347101054
[2024-12-26 08:37:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56572832558681
avg_train_sample_per_sec: 17.56572832558681
avg_episode_per_sec: 0.15142869246195526
collect_time: 39.62260983999074
reward_mean: -123.86181139122316
reward_std: 1.1818670186555773
reward_max: -122.35994397759104
reward_min: -125.90616246498601
queue_len: 0.08213647970240263
wait_time: 0.7962112895556102
delay_time: 5.189710487838444
pressure: 0.9924845269672856
total_envstep_count: 439872
total_train_sample_count: 439872
total_episode_count: 3792
total_duration: 25544.20608085053
[2024-12-26 08:38:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.729055310296566
avg_train_sample_per_sec: 17.729055310296566
avg_episode_per_sec: 0.15283668370945314
collect_time: 39.25759087658673
reward_mean: -122.94526143790847
reward_std: 4.026813688232447
reward_max: -116.47128851540613
reward_min: -129.6547619047619
queue_len: 0.08152868795617273
wait_time: 0.7901310502096507
delay_time: 5.052149638795666
pressure: 0.9802166224580017
total_envstep_count: 440568
total_train_sample_count: 440568
total_episode_count: 3798
total_duration: 25583.463671727117
[2024-12-26 08:39:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.28485827923467
avg_train_sample_per_sec: 18.28485827923467
avg_episode_per_sec: 0.15762808861409197
collect_time: 38.064281897684566
reward_mean: -124.07481325863678
reward_std: 2.298983005016878
reward_max: -119.44397759103641
reward_min: -126.28361344537815
queue_len: 0.08227772762509071
wait_time: 0.795150498307192
delay_time: 5.246164027635886
pressure: 0.981211317418214
total_envstep_count: 441264
total_train_sample_count: 441264
total_episode_count: 3804
total_duration: 25621.5279536248
[2024-12-26 08:39:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97193427063943
avg_train_sample_per_sec: 17.97193427063943
avg_episode_per_sec: 0.15493046785033993
collect_time: 38.72705016159826
reward_mean: -122.53524743230628
reward_std: 3.565208367038631
reward_max: -116.72899159663865
reward_min: -128.40616246498604
queue_len: 0.08125679537951344
wait_time: 0.7845370906983483
delay_time: 5.050925139782103
pressure: 0.9872900088417329
total_envstep_count: 441960
total_train_sample_count: 441960
total_episode_count: 3810
total_duration: 25660.2550037864
[2024-12-26 08:40:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.711113585335085
avg_train_sample_per_sec: 17.711113585335085
avg_episode_per_sec: 0.15268201366668177
collect_time: 39.29735962939634
reward_mean: -120.05438842203547
reward_std: 2.787088208969886
reward_max: -116.54411764705877
reward_min: -124.44817927170872
queue_len: 0.07961166340983784
wait_time: 0.7720970572136902
delay_time: 4.884413999074752
pressure: 0.9693854995579133
total_envstep_count: 442656
total_train_sample_count: 442656
total_episode_count: 3816
total_duration: 25699.552363415794
[2024-12-26 08:41:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.899013857402394
avg_train_sample_per_sec: 17.899013857402394
avg_episode_per_sec: 0.15430184359829652
collect_time: 38.88482379782946
reward_mean: -121.5903361344538
reward_std: 4.790005769985009
reward_max: -113.80462184873952
reward_min: -127.43557422969188
queue_len: 0.08063019637563248
wait_time: 0.7728909092372581
delay_time: 5.094441545853796
pressure: 0.9680592396109639
total_envstep_count: 443352
total_train_sample_count: 443352
total_episode_count: 3822
total_duration: 25738.437187213625
[2024-12-26 08:41:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.619815543004826
avg_train_sample_per_sec: 17.619815543004826
avg_episode_per_sec: 0.15189496157762783
collect_time: 39.50098105745018
reward_mean: -124.59558823529413
reward_std: 5.887094660136016
reward_max: -116.65756302521011
reward_min: -132.5651260504202
queue_len: 0.08262306912154783
wait_time: 0.7942136956462514
delay_time: 5.200040150916787
pressure: 0.9891688770999115
total_envstep_count: 444048
total_train_sample_count: 444048
total_episode_count: 3828
total_duration: 25777.938168271074
[2024-12-26 08:42:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.780110438858745
avg_train_sample_per_sec: 17.780110438858745
avg_episode_per_sec: 0.15327681412809263
collect_time: 39.14486371686869
reward_mean: -122.86671335200748
reward_std: 5.7638605795982025
reward_max: -117.3809523809524
reward_min: -131.57773109243695
queue_len: 0.0814766003660527
wait_time: 0.789854436469548
delay_time: 5.155444176797342
pressure: 0.9735853227232538
total_envstep_count: 444744
total_train_sample_count: 444744
total_episode_count: 3834
total_duration: 25817.083031987942
[2024-12-26 08:43:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.704993711878114
avg_train_sample_per_sec: 17.704993711878114
avg_episode_per_sec: 0.1526292561368803
collect_time: 39.31094307777472
reward_mean: -124.3671802054155
reward_std: 4.920916209490713
reward_max: -117.63725490196074
reward_min: -131.72408963585437
queue_len: 0.08247160491075298
wait_time: 0.7954015713270278
delay_time: 5.2679273956376225
pressure: 0.992263483642794
total_envstep_count: 445440
total_train_sample_count: 445440
total_episode_count: 3840
total_duration: 25856.393975065715
[2024-12-26 08:43:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.846265113568798
avg_train_sample_per_sec: 17.846265113568798
avg_episode_per_sec: 0.15384711304800686
collect_time: 38.99975684384629
reward_mean: -123.0859010270775
reward_std: 2.747967737321216
reward_max: -119.06792717086833
reward_min: -126.3109243697479
queue_len: 0.08162195028320789
wait_time: 0.7881828350261414
delay_time: 5.079330319049457
pressure: 0.9960212201591511
total_envstep_count: 446136
total_train_sample_count: 446136
total_episode_count: 3846
total_duration: 25895.39373190956
[2024-12-26 08:44:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88326710890234
avg_train_sample_per_sec: 17.88326710890234
avg_episode_per_sec: 0.1541660957663995
collect_time: 38.91906304153614
reward_mean: -119.15044351073762
reward_std: 2.4278029917751938
reward_max: -114.54481792717091
reward_min: -121.85574229691878
queue_len: 0.07901223044478622
wait_time: 0.7543218768497674
delay_time: 5.01248695011624
pressure: 0.9530282935455349
total_envstep_count: 446832
total_train_sample_count: 446832
total_episode_count: 3852
total_duration: 25934.312794951096
[2024-12-26 08:45:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.722996424345027
avg_train_sample_per_sec: 17.722996424345027
avg_episode_per_sec: 0.15278445193400886
collect_time: 39.27101170341298
reward_mean: -123.57177871148458
reward_std: 5.991612499837157
reward_max: -113.67787114845936
reward_min: -129.91666666666669
queue_len: 0.08194415033918077
wait_time: 0.7956435890005871
delay_time: 5.156387160908289
pressure: 0.9891688770999116
total_envstep_count: 447528
total_train_sample_count: 447528
total_episode_count: 3858
total_duration: 25973.583806654507
[2024-12-26 08:45:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.856108768848333
avg_train_sample_per_sec: 17.856108768848333
avg_episode_per_sec: 0.15393197214524426
collect_time: 38.97825718973205
reward_mean: -125.32096171802054
reward_std: 4.5750423367622135
reward_max: -116.51050420168072
reward_min: -130.6862745098039
queue_len: 0.08310408601990751
wait_time: 0.7987242642415056
delay_time: 5.204730897326654
pressure: 0.9970159151193635
total_envstep_count: 448224
total_train_sample_count: 448224
total_episode_count: 3864
total_duration: 26012.562063844238
[2024-12-26 08:46:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.77891997877739
avg_train_sample_per_sec: 17.77891997877739
avg_episode_per_sec: 0.15326655154118443
collect_time: 39.14748482083342
reward_mean: -124.4028944911298
reward_std: 4.682731301462863
reward_max: -118.55952380952381
reward_min: -130.48459383753502
queue_len: 0.08249528812409138
wait_time: 0.7924248390779831
delay_time: 5.237731511983935
pressure: 0.9942528735632185
total_envstep_count: 448920
total_train_sample_count: 448920
total_episode_count: 3870
total_duration: 26051.709548665072
[2024-12-26 08:47:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.034121365000956
avg_train_sample_per_sec: 18.034121365000956
avg_episode_per_sec: 0.15546656349138754
collect_time: 38.593507602246476
reward_mean: -121.64554154995331
reward_std: 1.2847030344886885
reward_max: -119.2892156862745
reward_min: -123.36624649859942
queue_len: 0.08066680474134837
wait_time: 0.7708340298984315
delay_time: 5.116587341278946
pressure: 0.9708222811671088
total_envstep_count: 449616
total_train_sample_count: 449616
total_episode_count: 3876
total_duration: 26090.30305626732
[2024-12-26 08:47:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.697300238721194
avg_train_sample_per_sec: 17.697300238721194
avg_episode_per_sec: 0.1525629330924241
collect_time: 39.32803255929238
reward_mean: -123.42647058823529
reward_std: 3.4547009456641247
reward_max: -118.81092436974788
reward_min: -128.6995798319328
queue_len: 0.08184779216726477
wait_time: 0.7896039052225664
delay_time: 5.158832823971975
pressure: 0.9822060123784263
total_envstep_count: 450312
total_train_sample_count: 450312
total_episode_count: 3882
total_duration: 26129.631088826613
[2024-12-26 08:48:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.770226846757023
avg_train_sample_per_sec: 17.770226846757023
avg_episode_per_sec: 0.15319161074790535
collect_time: 39.166635631723324
reward_mean: -118.46521942110178
reward_std: 4.1674509196629606
reward_max: -112.82352941176467
reward_min: -124.2857142857143
queue_len: 0.0785578378124017
wait_time: 0.7576804815648629
delay_time: 4.915491988121509
pressure: 0.9536914235190098
total_envstep_count: 451008
total_train_sample_count: 451008
total_episode_count: 3888
total_duration: 26168.797724458334
[2024-12-26 08:49:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79130492524582
avg_train_sample_per_sec: 17.79130492524582
avg_episode_per_sec: 0.15337331832108467
collect_time: 39.12023333445191
reward_mean: -122.24416433239965
reward_std: 6.118266782102514
reward_max: -115.37955182072831
reward_min: -133.14915966386556
queue_len: 0.08106376945119338
wait_time: 0.7756311189374068
delay_time: 5.1546239531713285
pressure: 0.9711538461538461
total_envstep_count: 451704
total_train_sample_count: 451704
total_episode_count: 3894
total_duration: 26207.917957792786
[2024-12-26 08:49:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.128206199960257
avg_train_sample_per_sec: 18.128206199960257
avg_episode_per_sec: 0.1562776396548298
collect_time: 38.39320847980678
reward_mean: -119.7781279178338
reward_std: 5.189911070204118
reward_max: -113.32282913165263
reward_min: -126.08823529411764
queue_len: 0.07942846678901445
wait_time: 0.7629297961448062
delay_time: 4.95971212698561
pressure: 0.9554597701149427
total_envstep_count: 452400
total_train_sample_count: 452400
total_episode_count: 3900
total_duration: 26246.311166272593
[2024-12-26 08:50:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.927615769218914
avg_train_sample_per_sec: 17.927615769218914
avg_episode_per_sec: 0.1545484118036113
collect_time: 38.82278652998619
reward_mean: -120.13176937441642
reward_std: 4.255747422698035
reward_max: -112.6498599439776
reward_min: -125.39495798319324
queue_len: 0.07966297703873768
wait_time: 0.7529389629414984
delay_time: 5.069886077321249
pressure: 0.9505968169761273
total_envstep_count: 453096
total_train_sample_count: 453096
total_episode_count: 3906
total_duration: 26285.13395280258
[2024-12-26 08:51:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.047647679752917
avg_train_sample_per_sec: 18.047647679752917
avg_episode_per_sec: 0.1555831696530424
collect_time: 38.56458261764608
reward_mean: -120.48727824463117
reward_std: 3.6307561895486824
reward_max: -114.17927170868349
reward_min: -125.35714285714286
queue_len: 0.07989872562641323
wait_time: 0.766263556704733
delay_time: 5.006643868151349
pressure: 0.9509283819628647
total_envstep_count: 453792
total_train_sample_count: 453792
total_episode_count: 3912
total_duration: 26323.698535420226
[2024-12-26 08:51:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.870327337854885
avg_train_sample_per_sec: 17.870327337854885
avg_episode_per_sec: 0.1540545460159904
collect_time: 38.94724404547736
reward_mean: -122.37324929971989
reward_std: 2.664202839952005
reward_max: -117.85014005602238
reward_min: -126.19047619047618
queue_len: 0.08114936956214847
wait_time: 0.7837628198936515
delay_time: 5.098680307533596
pressure: 0.9765694076038903
total_envstep_count: 454488
total_train_sample_count: 454488
total_episode_count: 3918
total_duration: 26362.645779465704
[2024-12-26 08:52:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.673907818692832
avg_train_sample_per_sec: 17.673907818692832
avg_episode_per_sec: 0.15236127429907614
collect_time: 39.38008544233068
reward_mean: -124.33811858076562
reward_std: 4.337303944369208
reward_max: -117.40406162464986
reward_min: -131.04341736694678
queue_len: 0.08245233327636978
wait_time: 0.7899392626192828
delay_time: 5.128547658384163
pressure: 0.9869584438549955
total_envstep_count: 455184
total_train_sample_count: 455184
total_episode_count: 3924
total_duration: 26402.025864908035
[2024-12-26 08:53:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.678762575896826
avg_train_sample_per_sec: 17.678762575896826
avg_episode_per_sec: 0.15240312565428296
collect_time: 39.36927129441313
reward_mean: -121.34593837535012
reward_std: 2.641660173370433
reward_max: -117.28361344537817
reward_min: -125.4460784313725
queue_len: 0.08046812889612077
wait_time: 0.770981159926393
delay_time: 5.059172984823912
pressure: 0.9576702033598585
total_envstep_count: 455880
total_train_sample_count: 455880
total_episode_count: 3930
total_duration: 26441.39513620245
[2024-12-26 08:53:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.726060107577414
avg_train_sample_per_sec: 17.726060107577414
avg_episode_per_sec: 0.15281086299635702
collect_time: 39.26422429891675
reward_mean: -127.08543417366946
reward_std: 5.554042563045251
reward_max: -117.51680672268907
reward_min: -132.61764705882356
queue_len: 0.084274160592619
wait_time: 0.8110465008284479
delay_time: 5.351313398809118
pressure: 1.0160256410256412
total_envstep_count: 456576
total_train_sample_count: 456576
total_episode_count: 3936
total_duration: 26480.659360501366
[2024-12-26 08:54:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.126922470892186
avg_train_sample_per_sec: 18.126922470892186
avg_episode_per_sec: 0.15626657302493263
collect_time: 38.39592744535767
reward_mean: -119.69724556489261
reward_std: 4.676252268466498
reward_max: -112.99369747899158
reward_min: -126.71428571428577
queue_len: 0.07937483127645399
wait_time: 0.7508003532978177
delay_time: 5.052021376668019
pressure: 0.9417550839964633
total_envstep_count: 457272
total_train_sample_count: 457272
total_episode_count: 3942
total_duration: 26519.055287946725
[2024-12-26 08:55:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.783299397409152
avg_train_sample_per_sec: 17.783299397409152
avg_episode_per_sec: 0.1533043051500789
collect_time: 39.13784413377195
reward_mean: -123.54820261437908
reward_std: 4.108243763591186
reward_max: -115.54201680672264
reward_min: -129.3641456582633
queue_len: 0.08192851632253255
wait_time: 0.781364623656713
delay_time: 5.236270709250774
pressure: 0.9689434129089302
total_envstep_count: 457968
total_train_sample_count: 457968
total_episode_count: 3948
total_duration: 26558.193132080498
[2024-12-26 08:55:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.817226382672732
avg_train_sample_per_sec: 17.817226382672732
avg_episode_per_sec: 0.15359677916097184
collect_time: 39.063319118898356
reward_mean: -121.9159663865546
reward_std: 3.5242484704173864
reward_max: -116.87324929971984
reward_min: -126.35714285714283
queue_len: 0.08084613155607069
wait_time: 0.7722501467430475
delay_time: 5.164103769111066
pressure: 0.9570070733863837
total_envstep_count: 458664
total_train_sample_count: 458664
total_episode_count: 3954
total_duration: 26597.256451199395
[2024-12-26 08:56:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.750745931714565
avg_train_sample_per_sec: 17.750745931714565
avg_episode_per_sec: 0.15302367182512555
collect_time: 39.20961984794588
reward_mean: -124.03116246498598
reward_std: 4.93314256756248
reward_max: -115.43347338935574
reward_min: -131.56722689075633
queue_len: 0.0822487814754549
wait_time: 0.7885563487110141
delay_time: 5.219636437954439
pressure: 0.9916003536693192
total_envstep_count: 459360
total_train_sample_count: 459360
total_episode_count: 3960
total_duration: 26636.46607104734
[2024-12-26 08:57:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.41902850043033
avg_train_sample_per_sec: 17.41902850043033
avg_episode_per_sec: 0.15016403879681317
collect_time: 39.956304106328645
reward_mean: -120.08741830065357
reward_std: 3.097170482110618
reward_max: -115.78361344537815
reward_min: -125.8081232492997
queue_len: 0.07963356651236975
wait_time: 0.7594739045043305
delay_time: 5.065207168539161
pressure: 0.9441865605658709
total_envstep_count: 460056
total_train_sample_count: 460056
total_episode_count: 3966
total_duration: 26676.42237515367
[2024-12-26 08:57:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.425524386070016
avg_train_sample_per_sec: 17.425524386070016
avg_episode_per_sec: 0.15022003781094842
collect_time: 39.941409198358656
reward_mean: -119.82621381886086
reward_std: 2.247272907719173
reward_max: -116.77521008403359
reward_min: -123.42927170868347
queue_len: 0.07946035399128705
wait_time: 0.7564517407316594
delay_time: 5.018521318176835
pressure: 0.9461759504862952
total_envstep_count: 460752
total_train_sample_count: 460752
total_episode_count: 3972
total_duration: 26716.36378435203
[2024-12-26 08:58:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.653186027988127
avg_train_sample_per_sec: 17.653186027988127
avg_episode_per_sec: 0.15218263817231142
collect_time: 39.426310859497626
reward_mean: -123.64414098972924
reward_std: 4.91282295628927
reward_max: -116.12745098039211
reward_min: -129.17296918767508
queue_len: 0.08199213593483372
wait_time: 0.7854923136363299
delay_time: 5.2350675949100625
pressure: 0.9864058355437665
total_envstep_count: 461448
total_train_sample_count: 461448
total_episode_count: 3978
total_duration: 26755.790095211527
[2024-12-26 08:59:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.71257045383236
avg_train_sample_per_sec: 17.71257045383236
avg_episode_per_sec: 0.15269457287786517
collect_time: 39.29412740031816
reward_mean: -118.82831465919702
reward_std: 6.9350081211012595
reward_max: -112.22899159663864
reward_min: -133.1365546218488
queue_len: 0.07879861714800862
wait_time: 0.7481893951214437
delay_time: 5.0167710776068715
pressure: 0.9500442086648982
total_envstep_count: 462144
total_train_sample_count: 462144
total_episode_count: 3984
total_duration: 26795.084222611844
[2024-12-26 08:59:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.09038901903388
avg_train_sample_per_sec: 18.09038901903388
avg_episode_per_sec: 0.15595162947442998
collect_time: 38.47346783243305
reward_mean: -116.3313492063492
reward_std: 3.0066041286504315
reward_max: -112.05742296918764
reward_min: -121.17086834733894
queue_len: 0.07714280451349417
wait_time: 0.7357264523846675
delay_time: 4.940982895785678
pressure: 0.92816091954023
total_envstep_count: 462840
total_train_sample_count: 462840
total_episode_count: 3990
total_duration: 26833.55769044428
[2024-12-26 09:00:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.920773626044788
avg_train_sample_per_sec: 17.920773626044788
avg_episode_per_sec: 0.1544894278107309
collect_time: 38.837609052127235
reward_mean: -118.03944911297852
reward_std: 3.510844678660234
reward_max: -112.36064425770309
reward_min: -122.77941176470588
queue_len: 0.07827549675926958
wait_time: 0.7454285206567155
delay_time: 5.006413110907672
pressure: 0.9403183023872678
total_envstep_count: 463536
total_train_sample_count: 463536
total_episode_count: 3996
total_duration: 26872.395299496406
[2024-12-26 09:01:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.69498493333201
avg_train_sample_per_sec: 17.69498493333201
avg_episode_per_sec: 0.15254297356320698
collect_time: 39.33317844701558
reward_mean: -124.52777777777777
reward_std: 7.052653350283027
reward_max: -118.65896358543415
reward_min: -139.4411764705882
queue_len: 0.08257810197465369
wait_time: 0.7944298630150558
delay_time: 5.193513979984106
pressure: 0.9854111405835543
total_envstep_count: 464232
total_train_sample_count: 464232
total_episode_count: 4002
total_duration: 26911.72847794342
[2024-12-26 09:01:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.943298743289645
avg_train_sample_per_sec: 17.943298743289645
avg_episode_per_sec: 0.15468360985594523
collect_time: 38.78885426573455
reward_mean: -122.3501400560224
reward_std: 6.773632587290693
reward_max: -115.45238095238093
reward_min: -134.15966386554624
queue_len: 0.08113404512998833
wait_time: 0.7716772606478489
delay_time: 5.225216825246772
pressure: 0.9732537577365162
total_envstep_count: 464928
total_train_sample_count: 464928
total_episode_count: 4008
total_duration: 26950.517332209154
[2024-12-26 09:02:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85386208849844
avg_train_sample_per_sec: 17.85386208849844
avg_episode_per_sec: 0.15391260421119343
collect_time: 38.98316210521013
reward_mean: -119.7109010270775
reward_std: 5.476818355292934
reward_max: -112.63375350140052
reward_min: -130.24579831932775
queue_len: 0.07938388662273044
wait_time: 0.752422189034765
delay_time: 5.0074783729996595
pressure: 0.9550176834659595
total_envstep_count: 465624
total_train_sample_count: 465624
total_episode_count: 4014
total_duration: 26989.500494314365
[2024-12-26 09:03:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.046854428484924
avg_train_sample_per_sec: 18.046854428484924
avg_episode_per_sec: 0.15557633128004247
collect_time: 38.56627772768214
reward_mean: -119.67483660130718
reward_std: 3.01431238401645
reward_max: -116.21918767507012
reward_min: -125.65966386554625
queue_len: 0.07935997122102599
wait_time: 0.7648887693892764
delay_time: 5.098712108237641
pressure: 0.953580901856764
total_envstep_count: 466320
total_train_sample_count: 466320
total_episode_count: 4020
total_duration: 27028.066772042046
[2024-12-26 09:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.808259975412305
avg_train_sample_per_sec: 17.808259975412305
avg_episode_per_sec: 0.1535194825466578
collect_time: 39.08298738680593
reward_mean: -120.47665732959852
reward_std: 4.341108518053775
reward_max: -113.41176470588232
reward_min: -125.23879551820725
queue_len: 0.07989168257930936
wait_time: 0.7651064846805212
delay_time: 5.109555453790432
pressure: 0.9513704686118478
total_envstep_count: 467016
total_train_sample_count: 467016
total_episode_count: 4026
total_duration: 27067.149759428852
[2024-12-26 09:04:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.858919388449806
avg_train_sample_per_sec: 17.858919388449806
avg_episode_per_sec: 0.1539562016245673
collect_time: 38.97212282900698
reward_mean: -122.4517973856209
reward_std: 4.106594345702976
reward_max: -117.08823529411765
reward_min: -128.68627450980392
queue_len: 0.0812014571522685
wait_time: 0.785329781780086
delay_time: 5.130714108487787
pressure: 0.9746905393457118
total_envstep_count: 467712
total_train_sample_count: 467712
total_episode_count: 4032
total_duration: 27106.12188225786
[2024-12-26 09:05:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.032109649053417
avg_train_sample_per_sec: 18.032109649053417
avg_episode_per_sec: 0.15544922111252946
collect_time: 38.597813209090376
reward_mean: -120.89647525676936
reward_std: 6.56847917378601
reward_max: -112.84663865546217
reward_min: -133.3543417366947
queue_len: 0.08017007643021841
wait_time: 0.7675217080643044
delay_time: 5.17698340078301
pressure: 0.949049513704686
total_envstep_count: 468408
total_train_sample_count: 468408
total_episode_count: 4038
total_duration: 27144.71969546695
[2024-12-26 09:05:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.98581884324528
avg_train_sample_per_sec: 17.98581884324528
avg_episode_per_sec: 0.15505016244176967
collect_time: 38.697153911421076
reward_mean: -119.50093370681606
reward_std: 3.7660849503024396
reward_max: -113.89775910364142
reward_min: -124.68067226890751
queue_len: 0.07924465099921489
wait_time: 0.7599037625660344
delay_time: 5.021160546511324
pressure: 0.9460654288240495
total_envstep_count: 469104
total_train_sample_count: 469104
total_episode_count: 4044
total_duration: 27183.41684937837
[2024-12-26 09:06:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94322764803861
avg_train_sample_per_sec: 17.94322764803861
avg_episode_per_sec: 0.1546829969658501
collect_time: 38.78900795621797
reward_mean: -120.42086834733892
reward_std: 2.9811484215711883
reward_max: -117.42086834733897
reward_min: -124.6491596638655
queue_len: 0.07985468723298339
wait_time: 0.7665889300017089
delay_time: 5.0764093378724
pressure: 0.949049513704686
total_envstep_count: 469800
total_train_sample_count: 469800
total_episode_count: 4050
total_duration: 27222.205857334586
[2024-12-26 09:07:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.753511757525843
avg_train_sample_per_sec: 17.753511757525843
avg_episode_per_sec: 0.15304751515108486
collect_time: 39.203511367544536
reward_mean: -119.95203081232494
reward_std: 4.611148606762563
reward_max: -114.67226890756298
reward_min: -126.36974789915968
queue_len: 0.07954378701082554
wait_time: 0.7656253482825491
delay_time: 5.037971184717523
pressure: 0.9595490716180372
total_envstep_count: 470496
total_train_sample_count: 470496
total_episode_count: 4056
total_duration: 27261.40936870213
[2024-12-26 09:07:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84849439821885
avg_train_sample_per_sec: 17.84849439821885
avg_episode_per_sec: 0.153866331019128
collect_time: 38.994885757392275
reward_mean: -123.27019140989728
reward_std: 4.700160691774625
reward_max: -116.34943977591035
reward_min: -130.13725490196074
queue_len: 0.08174415875987882
wait_time: 0.7858087863792734
delay_time: 5.242585732961783
pressure: 0.9808797524314765
total_envstep_count: 471192
total_train_sample_count: 471192
total_episode_count: 4062
total_duration: 27300.40425445952
[2024-12-26 09:08:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.763738780613146
avg_train_sample_per_sec: 17.763738780613146
avg_episode_per_sec: 0.1531356791432168
collect_time: 39.18094093792885
reward_mean: -121.99754901960783
reward_std: 5.761868586751599
reward_max: -114.62044817927168
reward_min: -131.1484593837535
queue_len: 0.08090023144536328
wait_time: 0.7780957210470395
delay_time: 5.171498651321161
pressure: 0.9638594164456235
total_envstep_count: 471888
total_train_sample_count: 471888
total_episode_count: 4068
total_duration: 27339.58519539745
[2024-12-26 09:09:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.741018242542566
avg_train_sample_per_sec: 17.741018242542566
avg_episode_per_sec: 0.15293981243571178
collect_time: 39.231119120942424
reward_mean: -121.74894957983192
reward_std: 6.4844083885845025
reward_max: -113.65616246498595
reward_min: -131.20308123249296
queue_len: 0.08073537770545883
wait_time: 0.7767354068064009
delay_time: 5.106543909740843
pressure: 0.9711538461538461
total_envstep_count: 472584
total_train_sample_count: 472584
total_episode_count: 4074
total_duration: 27378.81631451839
[2024-12-26 09:09:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.830283351897716
avg_train_sample_per_sec: 17.830283351897716
avg_episode_per_sec: 0.15370933924049757
collect_time: 39.03471337296068
reward_mean: -119.71988795518206
reward_std: 4.725663222011703
reward_max: -111.5406162464986
reward_min: -125.86064425770306
queue_len: 0.07938984612412603
wait_time: 0.7635638251764013
delay_time: 4.969099474831725
pressure: 0.9529177718832891
total_envstep_count: 473280
total_train_sample_count: 473280
total_episode_count: 4080
total_duration: 27417.85102789135
[2024-12-26 09:10:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7413118156045
avg_train_sample_per_sec: 17.7413118156045
avg_episode_per_sec: 0.15294234323796982
collect_time: 39.230469946863124
reward_mean: -117.69514472455647
reward_std: 5.921175254318368
reward_max: -110.73879551820724
reward_min: -127.84873949579831
queue_len: 0.078047178199308
wait_time: 0.7444058856964536
delay_time: 4.886919265624308
pressure: 0.9414235190097259
total_envstep_count: 473976
total_train_sample_count: 473976
total_episode_count: 4086
total_duration: 27457.08149783821
[2024-12-26 09:10:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84566361781125
avg_train_sample_per_sec: 17.84566361781125
avg_episode_per_sec: 0.15384192773975217
collect_time: 39.00107134740241
reward_mean: -121.13165266106444
reward_std: 2.973733401082129
reward_max: -117.61484593837531
reward_min: -126.95238095238095
queue_len: 0.08032602961609046
wait_time: 0.7731343200410136
delay_time: 5.213617484879252
pressure: 0.9587754199823166
total_envstep_count: 474672
total_train_sample_count: 474672
total_episode_count: 4092
total_duration: 27496.082569185615
[2024-12-26 09:11:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.151092790209844
avg_train_sample_per_sec: 18.151092790209844
avg_episode_per_sec: 0.1564749378466366
collect_time: 38.344798742663116
reward_mean: -118.34197012138189
reward_std: 4.453895392306079
reward_max: -110.7156862745098
reward_min: -124.46428571428572
queue_len: 0.07847610750754767
wait_time: 0.751669743936478
delay_time: 4.977307981930063
pressure: 0.9409814323607427
total_envstep_count: 475368
total_train_sample_count: 475368
total_episode_count: 4098
total_duration: 27534.427367928278
[2024-12-26 09:12:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.876610020121873
avg_train_sample_per_sec: 17.876610020121873
avg_episode_per_sec: 0.15410870707001614
collect_time: 38.93355615055561
reward_mean: -118.26085434173667
reward_std: 2.6712255247617507
reward_max: -113.34453781512603
reward_min: -121.98459383753502
queue_len: 0.07842231720274316
wait_time: 0.7568990129208181
delay_time: 4.964207682232689
pressure: 0.9365605658709107
total_envstep_count: 476064
total_train_sample_count: 476064
total_episode_count: 4104
total_duration: 27573.360924078832
[2024-12-26 09:12:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.049608984915213
avg_train_sample_per_sec: 18.049608984915213
avg_episode_per_sec: 0.15560007745616564
collect_time: 38.560392116066076
reward_mean: -116.81232492997198
reward_std: 2.04702417815215
reward_max: -112.77731092436973
reward_min: -118.96708683473385
queue_len: 0.07746175393234217
wait_time: 0.7504864346269011
delay_time: 4.983662040198407
pressure: 0.9410919540229886
total_envstep_count: 476760
total_train_sample_count: 476760
total_episode_count: 4110
total_duration: 27611.921316194897
[2024-12-26 09:13:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.881941158350237
avg_train_sample_per_sec: 17.881941158350237
avg_episode_per_sec: 0.1541546651581917
collect_time: 38.92194890010543
reward_mean: -119.03478057889822
reward_std: 3.1439236529358703
reward_max: -113.46708683473389
reward_min: -123.93207282913163
queue_len: 0.07893553088786355
wait_time: 0.764022938972229
delay_time: 4.966356338342906
pressure: 0.9603227232537578
total_envstep_count: 477456
total_train_sample_count: 477456
total_episode_count: 4116
total_duration: 27650.843265095
[2024-12-26 09:14:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.853820156251313
avg_train_sample_per_sec: 17.853820156251313
avg_episode_per_sec: 0.15391224272630444
collect_time: 38.98325366273522
reward_mean: -117.31500933706813
reward_std: 8.01570850834669
reward_max: -109.6939775910364
reward_min: -132.04201680672267
queue_len: 0.07779509902988603
wait_time: 0.7537851347435528
delay_time: 4.8614975664929
pressure: 0.9355658709106985
total_envstep_count: 478152
total_train_sample_count: 478152
total_episode_count: 4122
total_duration: 27689.826518757738
[2024-12-26 09:14:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.869691913302994
avg_train_sample_per_sec: 17.869691913302994
avg_episode_per_sec: 0.15404906821812928
collect_time: 38.94862896219641
reward_mean: -123.19479458450047
reward_std: 6.766060194561984
reward_max: -115.6302521008403
reward_min: -135.58193277310923
queue_len: 0.08169416086505336
wait_time: 0.7877087837787635
delay_time: 5.1699023315255594
pressure: 0.9813218390804597
total_envstep_count: 478848
total_train_sample_count: 478848
total_episode_count: 4128
total_duration: 27728.775147719934
[2024-12-26 09:15:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.780248375551217
avg_train_sample_per_sec: 17.780248375551217
avg_episode_per_sec: 0.15327800323751048
collect_time: 39.14456003646366
reward_mean: -121.67915499533147
reward_std: 4.624475430222959
reward_max: -114.66176470588233
reward_min: -127.32843137254899
queue_len: 0.08068909482449037
wait_time: 0.7800446327956468
delay_time: 5.116371634072419
pressure: 0.9602122015915118
total_envstep_count: 479544
total_train_sample_count: 479544
total_episode_count: 4134
total_duration: 27767.9197077564
[2024-12-26 09:16:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.847771074158057
avg_train_sample_per_sec: 17.847771074158057
avg_episode_per_sec: 0.15386009546687981
collect_time: 38.99646611938812
reward_mean: -119.96673669467788
reward_std: 2.938260685935344
reward_max: -115.62745098039217
reward_min: -123.50420168067225
queue_len: 0.07955353892220018
wait_time: 0.7693912113917185
delay_time: 5.041444993357514
pressure: 0.9646330680813441
total_envstep_count: 480240
total_train_sample_count: 480240
total_episode_count: 4140
total_duration: 27806.916173875787
[2024-12-26 09:16:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.77738505844126
avg_train_sample_per_sec: 17.77738505844126
avg_episode_per_sec: 0.15325331946932122
collect_time: 39.15086486071906
reward_mean: -120.67612044817928
reward_std: 7.334594588931923
reward_max: -109.6939775910364
reward_min: -131.37394957983196
queue_len: 0.08002395255184301
wait_time: 0.7770861660313994
delay_time: 5.044154234783865
pressure: 0.9696065428824049
total_envstep_count: 480936
total_train_sample_count: 480936
total_episode_count: 4146
total_duration: 27846.067038736506
[2024-12-26 09:17:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79246890293287
avg_train_sample_per_sec: 17.79246890293287
avg_episode_per_sec: 0.15338335261149028
collect_time: 39.117674101162706
reward_mean: -121.97257236227824
reward_std: 4.822508611201442
reward_max: -115.67997198879549
reward_min: -127.88445378151259
queue_len: 0.0808836686752508
wait_time: 0.7788260308544285
delay_time: 5.079956443468155
pressure: 0.9801061007957559
total_envstep_count: 481632
total_train_sample_count: 481632
total_episode_count: 4152
total_duration: 27885.18471283767
[2024-12-26 09:18:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.99249317752216
avg_train_sample_per_sec: 17.99249317752216
avg_episode_per_sec: 0.15510769980622552
collect_time: 38.68279916145839
reward_mean: -116.52240896358542
reward_std: 4.568280535815044
reward_max: -110.8921568627451
reward_min: -123.5112044817927
queue_len: 0.07726950196524231
wait_time: 0.7364288221920067
delay_time: 4.976070073346378
pressure: 0.9320291777188329
total_envstep_count: 482328
total_train_sample_count: 482328
total_episode_count: 4158
total_duration: 27923.867511999128
[2024-12-26 09:18:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.654479757944742
avg_train_sample_per_sec: 17.654479757944742
avg_episode_per_sec: 0.15219379101676503
collect_time: 39.423421677820386
reward_mean: -117.93043884220356
reward_std: 3.0227177856878207
reward_max: -113.23739495798318
reward_min: -122.02731092436976
queue_len: 0.07820320878130209
wait_time: 0.7538828086495428
delay_time: 4.936198536848397
pressure: 0.9362290008841732
total_envstep_count: 483024
total_train_sample_count: 483024
total_episode_count: 4164
total_duration: 27963.290933676948
[2024-12-26 09:19:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.934462173238128
avg_train_sample_per_sec: 17.934462173238128
avg_episode_per_sec: 0.1546074325279149
collect_time: 38.807966097727416
reward_mean: -117.13363678804855
reward_std: 4.187332633430023
reward_max: -111.40336134453776
reward_min: -122.91876750700281
queue_len: 0.07767482545626563
wait_time: 0.7509805314698824
delay_time: 4.983722670272055
pressure: 0.941976127320955
total_envstep_count: 483720
total_train_sample_count: 483720
total_episode_count: 4170
total_duration: 28002.098899774675
[2024-12-26 09:20:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.66664490639753
avg_train_sample_per_sec: 17.66664490639753
avg_episode_per_sec: 0.1522986629861856
collect_time: 39.39627494001202
reward_mean: -117.38398692810456
reward_std: 3.6388627070901647
reward_max: -112.12464985994394
reward_min: -122.12114845938376
queue_len: 0.07784084013800037
wait_time: 0.7475567592200454
delay_time: 5.043591135530476
pressure: 0.9315870910698497
total_envstep_count: 484416
total_train_sample_count: 484416
total_episode_count: 4176
total_duration: 28041.495174714688
[2024-12-26 09:20:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.928309707504383
avg_train_sample_per_sec: 17.928309707504383
avg_episode_per_sec: 0.1545543940302102
collect_time: 38.82128384410217
reward_mean: -116.20716619981324
reward_std: 3.311367653737855
reward_max: -112.62535014005597
reward_min: -120.71498599439781
queue_len: 0.07706045503966395
wait_time: 0.7409160945545326
delay_time: 4.93828921233619
pressure: 0.9316976127320955
total_envstep_count: 485112
total_train_sample_count: 485112
total_episode_count: 4182
total_duration: 28080.31645855879
[2024-12-26 09:21:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75536469348555
avg_train_sample_per_sec: 17.75536469348555
avg_episode_per_sec: 0.15306348873694442
collect_time: 39.199420119788506
reward_mean: -117.80147058823529
reward_std: 4.251596623945385
reward_max: -109.53921568627447
reward_min: -121.91666666666667
queue_len: 0.07811768606646903
wait_time: 0.746906941379558
delay_time: 4.897922231517447
pressure: 0.9452917771883289
total_envstep_count: 485808
total_train_sample_count: 485808
total_episode_count: 4188
total_duration: 28119.51587867858
[2024-12-26 09:22:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.653917993324754
avg_train_sample_per_sec: 17.653917993324754
avg_episode_per_sec: 0.15218894821831683
collect_time: 39.424676168948416
reward_mean: -115.48202614379083
reward_std: 3.9570381125387417
reward_max: -109.30112044817923
reward_min: -120.73039215686276
queue_len: 0.0765795929335483
wait_time: 0.7314051947038763
delay_time: 4.839534285486258
pressure: 0.9196507515473032
total_envstep_count: 486504
total_train_sample_count: 486504
total_episode_count: 4194
total_duration: 28158.94055484753
[2024-12-26 09:22:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.857360027415787
avg_train_sample_per_sec: 17.857360027415787
avg_episode_per_sec: 0.15394275885703262
collect_time: 38.97552599776537
reward_mean: -115.25816993464052
reward_std: 4.485450710642278
reward_max: -111.1029411764706
reward_min: -124.3879551820728
queue_len: 0.0764311471715123
wait_time: 0.7340608878387783
delay_time: 4.808769710850968
pressure: 0.9234084880636605
total_envstep_count: 487200
total_train_sample_count: 487200
total_episode_count: 4200
total_duration: 28197.916080845294
[2024-12-26 09:23:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.86620872223964
avg_train_sample_per_sec: 17.86620872223964
avg_episode_per_sec: 0.1540190407089624
collect_time: 38.95622237602249
reward_mean: -117.6690009337068
reward_std: 4.072763904634754
reward_max: -112.88515406162466
reward_min: -125.13515406162468
queue_len: 0.07802984146797534
wait_time: 0.7465362913512
delay_time: 5.014444889888935
pressure: 0.9355658709106983
total_envstep_count: 487896
total_train_sample_count: 487896
total_episode_count: 4206
total_duration: 28236.872303221317
[2024-12-26 09:24:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.019628368626684
avg_train_sample_per_sec: 18.019628368626684
avg_episode_per_sec: 0.1553416238674714
collect_time: 38.624547951931135
reward_mean: -116.67658730158729
reward_std: 3.4036024815503754
reward_max: -110.52240896358545
reward_min: -121.33963585434172
queue_len: 0.07737174224243189
wait_time: 0.7477206068103636
delay_time: 4.884962392257277
pressure: 0.9440760389036251
total_envstep_count: 488592
total_train_sample_count: 488592
total_episode_count: 4212
total_duration: 28275.496851173248
[2024-12-26 09:24:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.805912309588546
avg_train_sample_per_sec: 17.805912309588546
avg_episode_per_sec: 0.15349924404817714
collect_time: 39.08814038274251
reward_mean: -117.67565359477123
reward_std: 3.4958699648958524
reward_max: -113.02731092436973
reward_min: -123.3739495798319
queue_len: 0.07803425304693053
wait_time: 0.7455525866403149
delay_time: 4.910681297944309
pressure: 0.9444076038903625
total_envstep_count: 489288
total_train_sample_count: 489288
total_episode_count: 4218
total_duration: 28314.584991555992
[2024-12-26 09:25:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79611720071501
avg_train_sample_per_sec: 17.79611720071501
avg_episode_per_sec: 0.15341480345443975
collect_time: 39.10965477188677
reward_mean: -114.79785247432305
reward_std: 3.798396612242775
reward_max: -108.85224089635852
reward_min: -119.67647058823529
queue_len: 0.07612589686626196
wait_time: 0.7345008073963449
delay_time: 4.826291379583962
pressure: 0.9246242263483643
total_envstep_count: 489984
total_train_sample_count: 489984
total_episode_count: 4224
total_duration: 28353.69464632788
[2024-12-26 09:26:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.800206127267685
avg_train_sample_per_sec: 17.800206127267685
avg_episode_per_sec: 0.15345005282127316
collect_time: 39.100670802559705
reward_mean: -115.31781045751633
reward_std: 4.859345783445691
reward_max: -109.016106442577
reward_min: -122.83263305322129
queue_len: 0.07647069658986494
wait_time: 0.7366140311120026
delay_time: 4.896565645652811
pressure: 0.9262820512820512
total_envstep_count: 490680
total_train_sample_count: 490680
total_episode_count: 4230
total_duration: 28392.79531713044
[2024-12-26 09:26:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.679400337972364
avg_train_sample_per_sec: 17.679400337972364
avg_episode_per_sec: 0.15240862360321003
collect_time: 39.36785109759123
reward_mean: -119.86192810457516
reward_std: 5.787222214682509
reward_max: -111.49859943977589
reward_min: -126.60994397759104
queue_len: 0.07948403720462544
wait_time: 0.7675331626903635
delay_time: 5.068917390731288
pressure: 0.9612068965517241
total_envstep_count: 491376
total_train_sample_count: 491376
total_episode_count: 4236
total_duration: 28432.16316822803
[2024-12-26 09:27:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.962878792503734
avg_train_sample_per_sec: 17.962878792503734
avg_episode_per_sec: 0.15485240338365286
collect_time: 38.74657331042364
reward_mean: -115.15884687208217
reward_std: 6.683311884406733
reward_max: -108.13655462184872
reward_min: -125.26540616246497
queue_len: 0.07636528307167252
wait_time: 0.7398746523366199
delay_time: 4.860300664377152
pressure: 0.9193191865605659
total_envstep_count: 492072
total_train_sample_count: 492072
total_episode_count: 4242
total_duration: 28470.909741538457
[2024-12-26 09:28:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94187377912635
avg_train_sample_per_sec: 17.94187377912635
avg_episode_per_sec: 0.15467132568212372
collect_time: 38.791934920962895
reward_mean: -116.67565359477125
reward_std: 6.476668675551555
reward_max: -108.42296918767508
reward_min: -127.09453781512606
queue_len: 0.07737112307345574
wait_time: 0.7419402000411127
delay_time: 4.916373331339387
pressure: 0.9319186560565872
total_envstep_count: 492768
total_train_sample_count: 492768
total_episode_count: 4248
total_duration: 28509.70167645942
[2024-12-26 09:28:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.922338163803968
avg_train_sample_per_sec: 17.922338163803968
avg_episode_per_sec: 0.15450291520520662
collect_time: 38.83421870733611
reward_mean: -119.92822128851539
reward_std: 5.10489254067699
reward_max: -112.60014005602241
reward_min: -125.51470588235291
queue_len: 0.07952799820193328
wait_time: 0.7667087391985973
delay_time: 5.085330749294212
pressure: 0.9593280282935455
total_envstep_count: 493464
total_train_sample_count: 493464
total_episode_count: 4254
total_duration: 28548.535895166755
[2024-12-26 09:29:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80824978669912
avg_train_sample_per_sec: 17.80824978669912
avg_episode_per_sec: 0.15351939471292342
collect_time: 39.0830097475294
reward_mean: -119.2934173669468
reward_std: 7.839163158834507
reward_max: -108.16876750700281
reward_min: -129.44677871148465
queue_len: 0.07910704069426179
wait_time: 0.760562171376066
delay_time: 4.992270418162637
pressure: 0.9457338638373122
total_envstep_count: 494160
total_train_sample_count: 494160
total_episode_count: 4260
total_duration: 28587.618904914285
[2024-12-26 09:30:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.859858614496464
avg_train_sample_per_sec: 17.859858614496464
avg_episode_per_sec: 0.1539642984008316
collect_time: 38.97007333725877
reward_mean: -120.14005602240894
reward_std: 3.9495213713548294
reward_max: -115.25560224089632
reward_min: -125.66806722689074
queue_len: 0.07966847216340116
wait_time: 0.7608125478308033
delay_time: 5.075272638896361
pressure: 0.9593280282935455
total_envstep_count: 494856
total_train_sample_count: 494856
total_episode_count: 4266
total_duration: 28626.588978251544
[2024-12-26 09:30:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.113863894697996
avg_train_sample_per_sec: 18.113863894697996
avg_episode_per_sec: 0.1561539990922241
collect_time: 38.42360768779554
reward_mean: -118.43534080298782
reward_std: 3.263090989970577
reward_max: -112.84593837535013
reward_min: -123.24089635854335
queue_len: 0.07853802440516434
wait_time: 0.7576400033930458
delay_time: 4.974561999117228
pressure: 0.9534703801945182
total_envstep_count: 495552
total_train_sample_count: 495552
total_episode_count: 4272
total_duration: 28665.01258593934
[2024-12-26 09:31:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82740679809975
avg_train_sample_per_sec: 17.82740679809975
avg_episode_per_sec: 0.1536845413629289
collect_time: 39.04101184666901
reward_mean: -119.66036414565826
reward_std: 5.058891530961734
reward_max: -112.68977591036413
reward_min: -126.67787114845945
queue_len: 0.0793503741018954
wait_time: 0.7697684400904481
delay_time: 5.021475179924643
pressure: 0.9544650751547303
total_envstep_count: 496248
total_train_sample_count: 496248
total_episode_count: 4278
total_duration: 28704.05359778601
[2024-12-26 09:32:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88191479449001
avg_train_sample_per_sec: 17.88191479449001
avg_episode_per_sec: 0.15415443788353458
collect_time: 38.922006283938885
reward_mean: -121.08928571428571
reward_std: 7.442880160336493
reward_max: -111.91946778711484
reward_min: -131.7668067226891
queue_len: 0.0802979348237969
wait_time: 0.7799714934603372
delay_time: 5.09268049287901
pressure: 0.9644120247568524
total_envstep_count: 496944
total_train_sample_count: 496944
total_episode_count: 4284
total_duration: 28742.975604069947
[2024-12-26 09:32:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.920488564009563
avg_train_sample_per_sec: 17.920488564009563
avg_episode_per_sec: 0.1544869703793928
collect_time: 38.83822684375942
reward_mean: -115.94094304388422
reward_std: 4.855126822493695
reward_max: -111.15196078431374
reward_min: -125.6890756302521
queue_len: 0.07688391448533437
wait_time: 0.7426130819259621
delay_time: 4.8544372057503855
pressure: 0.936339522546419
total_envstep_count: 497640
total_train_sample_count: 497640
total_episode_count: 4290
total_duration: 28781.813830913707
[2024-12-26 09:33:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.815036834244076
avg_train_sample_per_sec: 17.815036834244076
avg_episode_per_sec: 0.1535779037434834
collect_time: 39.06812017711624
reward_mean: -120.93405695611578
reward_std: 5.830124464705023
reward_max: -112.12955182072828
reward_min: -131.86624649859948
queue_len: 0.08019499798150913
wait_time: 0.7802320862031814
delay_time: 4.97967562745596
pressure: 0.972259062776304
total_envstep_count: 498336
total_train_sample_count: 498336
total_episode_count: 4296
total_duration: 28820.88195109082
[2024-12-26 09:34:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.779768581735276
avg_train_sample_per_sec: 17.779768581735276
avg_episode_per_sec: 0.1532738670839248
collect_time: 39.145616367300974
reward_mean: -115.5830999066293
reward_std: 3.2309409556483644
reward_max: -111.72689075630252
reward_min: -121.48389355742296
queue_len: 0.07664661797521836
wait_time: 0.7334108378099252
delay_time: 4.8490563830517
pressure: 0.9325817860300618
total_envstep_count: 499032
total_train_sample_count: 499032
total_episode_count: 4302
total_duration: 28860.02756745812
[2024-12-26 09:34:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.818567981249636
avg_train_sample_per_sec: 17.818567981249636
avg_episode_per_sec: 0.15360834466594514
collect_time: 39.06037795699387
reward_mean: -119.71171802054154
reward_std: 6.297494308150514
reward_max: -111.01400560224091
reward_min: -126.37745098039215
queue_len: 0.07938442839558459
wait_time: 0.7687244438005086
delay_time: 4.920511294617326
pressure: 0.961870026525199
total_envstep_count: 499728
total_train_sample_count: 499728
total_episode_count: 4308
total_duration: 28899.087945415115
[2024-12-26 09:35:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.01365180049131
avg_train_sample_per_sec: 18.01365180049131
avg_episode_per_sec: 0.15529010172837338
collect_time: 38.63736280175112
reward_mean: -119.07784780578898
reward_std: 6.107552048351569
reward_max: -111.23599439775909
reward_min: -129.10994397759103
queue_len: 0.07896409005688924
wait_time: 0.7592340539221878
delay_time: 4.945462560172825
pressure: 0.9543545534924845
total_envstep_count: 500424
total_train_sample_count: 500424
total_episode_count: 4314
total_duration: 28937.725308216865
[2024-12-26 09:36:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.71947130870889
avg_train_sample_per_sec: 17.71947130870889
avg_episode_per_sec: 0.1527540630061111
collect_time: 39.278824287377304
reward_mean: -117.40546218487394
reward_std: 3.576359030542641
reward_max: -112.80182072829132
reward_min: -122.624649859944
queue_len: 0.07785508102445221
wait_time: 0.7489257418263504
delay_time: 4.938923167387616
pressure: 0.9382183908045977
total_envstep_count: 501120
total_train_sample_count: 501120
total_episode_count: 4320
total_duration: 28977.00413250424
[2024-12-26 09:36:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.964494317028485
avg_train_sample_per_sec: 17.964494317028485
avg_episode_per_sec: 0.1548663303192111
collect_time: 38.74308887950516
reward_mean: -115.65873015873017
reward_std: 5.713182933689628
reward_max: -108.140056022409
reward_min: -124.79411764705884
queue_len: 0.0766967706622879
wait_time: 0.7318088154802149
delay_time: 4.864515936674777
pressure: 0.919319186560566
total_envstep_count: 501816
total_train_sample_count: 501816
total_episode_count: 4326
total_duration: 29015.747221383746
[2024-12-26 09:37:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80964859901862
avg_train_sample_per_sec: 17.80964859901862
avg_episode_per_sec: 0.15353145343981567
collect_time: 39.07994007463754
reward_mean: -117.56524276377216
reward_std: 7.9707887580071395
reward_max: -110.0693277310924
reward_min: -133.94607843137254
queue_len: 0.07796103631549878
wait_time: 0.7437648910138769
delay_time: 4.918360647251668
pressure: 0.937555260831123
total_envstep_count: 502512
total_train_sample_count: 502512
total_episode_count: 4332
total_duration: 29054.827161458383
[2024-12-26 09:38:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.645726526587787
avg_train_sample_per_sec: 17.645726526587787
avg_episode_per_sec: 0.1521183321257568
collect_time: 39.44297781966067
reward_mean: -123.14052287581698
reward_std: 6.613823594065905
reward_max: -114.10434173669466
reward_min: -133.70938375350136
queue_len: 0.08165817166831364
wait_time: 0.7885890872706289
delay_time: 5.130984784842674
pressure: 0.9893899204244033
total_envstep_count: 503208
total_train_sample_count: 503208
total_episode_count: 4338
total_duration: 29094.270139278044
[2024-12-26 09:38:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.803528566781175
avg_train_sample_per_sec: 17.803528566781175
avg_episode_per_sec: 0.15347869454121704
collect_time: 39.09337395614013
reward_mean: -117.92308590102705
reward_std: 4.2870028289529305
reward_max: -112.1428571428571
reward_min: -124.84803921568627
queue_len: 0.07819833282561477
wait_time: 0.7499365351799429
delay_time: 4.942958548535806
pressure: 0.9467285587975244
total_envstep_count: 503904
total_train_sample_count: 503904
total_episode_count: 4344
total_duration: 29133.363513234184
[2024-12-26 09:39:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.979311844735978
avg_train_sample_per_sec: 17.979311844735978
avg_episode_per_sec: 0.1549940676270343
collect_time: 38.71115902602114
reward_mean: -115.72093837535012
reward_std: 6.056148402874483
reward_max: -108.53221288515408
reward_min: -125.24789915966382
queue_len: 0.07673802279532502
wait_time: 0.7339456450130891
delay_time: 4.859630715316215
pressure: 0.9315870910698497
total_envstep_count: 504600
total_train_sample_count: 504600
total_episode_count: 4350
total_duration: 29172.074672260205
[2024-12-26 09:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.78141538270894
avg_train_sample_per_sec: 17.78141538270894
avg_episode_per_sec: 0.1532880636440426
collect_time: 39.14199095066451
reward_mean: -115.61858076563958
reward_std: 7.588424048007558
reward_max: -109.80812324929968
reward_min: -131.52801120448177
queue_len: 0.07667014639631271
wait_time: 0.73071443431484
delay_time: 4.865210498775458
pressure: 0.9318081343943412
total_envstep_count: 505296
total_train_sample_count: 505296
total_episode_count: 4356
total_duration: 29211.21666321087
[2024-12-26 09:40:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.78434584951668
avg_train_sample_per_sec: 17.78434584951668
avg_episode_per_sec: 0.15331332628893687
collect_time: 39.13554121637345
reward_mean: -123.7095004668534
reward_std: 6.062832024929984
reward_max: -116.94047619047616
reward_min: -134.57422969187678
queue_len: 0.08203547776316539
wait_time: 0.7952885729888773
delay_time: 5.15556900465585
pressure: 1.00552608311229
total_envstep_count: 505992
total_train_sample_count: 505992
total_episode_count: 4362
total_duration: 29250.352204427243
[2024-12-26 09:41:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.95347248351148
avg_train_sample_per_sec: 17.95347248351148
avg_episode_per_sec: 0.15477131451302997
collect_time: 38.7668736863695
reward_mean: -113.83064892623715
reward_std: 3.3402223410753495
reward_max: -110.38795518207282
reward_min: -120.29201680672269
queue_len: 0.07548451520307503
wait_time: 0.7198672904174934
delay_time: 4.779144565856711
pressure: 0.9161140583554377
total_envstep_count: 506688
total_train_sample_count: 506688
total_episode_count: 4368
total_duration: 29289.119078113614
[2024-12-26 09:42:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.080374770581333
avg_train_sample_per_sec: 18.080374770581333
avg_episode_per_sec: 0.1558652997463908
collect_time: 38.49477728373557
reward_mean: -115.80987394957981
reward_std: 4.5430189581297755
reward_max: -109.82703081232489
reward_min: -123.25210084033613
queue_len: 0.07679699864030491
wait_time: 0.7349190560397458
delay_time: 4.789164439306244
pressure: 0.9333554376657826
total_envstep_count: 507384
total_train_sample_count: 507384
total_episode_count: 4374
total_duration: 29327.61385539735
[2024-12-26 09:42:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88207936163788
avg_train_sample_per_sec: 17.88207936163788
avg_episode_per_sec: 0.1541558565658438
collect_time: 38.92164808825963
reward_mean: -120.19806255835668
reward_std: 5.115714126648517
reward_max: -112.15336134453779
reward_min: -125.76330532212887
queue_len: 0.07970693803604553
wait_time: 0.7645715226851131
delay_time: 4.93159620467556
pressure: 0.9626436781609197
total_envstep_count: 508080
total_train_sample_count: 508080
total_episode_count: 4380
total_duration: 29366.53550348561
[2024-12-26 09:43:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.865168316058284
avg_train_sample_per_sec: 17.865168316058284
avg_episode_per_sec: 0.1540100716901576
collect_time: 38.95849105291628
reward_mean: -113.47397292250231
reward_std: 1.249520331605144
reward_max: -111.05532212885154
reward_min: -114.79551820728284
queue_len: 0.07524799265417927
wait_time: 0.716403117391961
delay_time: 4.7574668939579645
pressure: 0.9121352785145889
total_envstep_count: 508776
total_train_sample_count: 508776
total_episode_count: 4386
total_duration: 29405.493994538527
[2024-12-26 09:43:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.98930721887738
avg_train_sample_per_sec: 17.98930721887738
avg_episode_per_sec: 0.15508023464549464
collect_time: 38.68964999772981
reward_mean: -113.14589169000932
reward_std: 1.2188728010921785
reward_max: -110.95098039215682
reward_min: -114.67366946778708
queue_len: 0.07503043215517859
wait_time: 0.7142145872495771
delay_time: 4.821018976348914
pressure: 0.9013041556145004
total_envstep_count: 509472
total_train_sample_count: 509472
total_episode_count: 4392
total_duration: 29444.183644536257
[2024-12-26 09:44:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.790609596999218
avg_train_sample_per_sec: 17.790609596999218
avg_episode_per_sec: 0.15336732411206222
collect_time: 39.121762309785936
reward_mean: -118.86239495798317
reward_std: 4.92275051130512
reward_max: -111.9467787114846
reward_min: -125.6337535014005
queue_len: 0.07882121681563871
wait_time: 0.7631488271701254
delay_time: 4.94264176183404
pressure: 0.963527851458886
total_envstep_count: 510168
total_train_sample_count: 510168
total_episode_count: 4398
total_duration: 29483.305406846044
[2024-12-26 09:45:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.011722500653864
avg_train_sample_per_sec: 18.011722500653864
avg_episode_per_sec: 0.155273469833223
collect_time: 38.64150138748438
reward_mean: -115.92740429505132
reward_std: 6.065366892981121
reward_max: -109.6750700280112
reward_min: -126.18977591036415
queue_len: 0.07687493653517995
wait_time: 0.7334315799706266
delay_time: 4.788702112257696
pressure: 0.93578691423519
total_envstep_count: 510864
total_train_sample_count: 510864
total_episode_count: 4404
total_duration: 29521.946908233527
[2024-12-26 09:45:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.816923486064937
avg_train_sample_per_sec: 17.816923486064937
avg_episode_per_sec: 0.15359416798331843
collect_time: 39.06398321485519
reward_mean: -118.55578898225957
reward_std: 6.066183516051039
reward_max: -109.07492997198878
reward_min: -125.84523809523809
queue_len: 0.0786178972030899
wait_time: 0.7597930861115444
delay_time: 4.915809444952934
pressure: 0.9659593280282935
total_envstep_count: 511560
total_train_sample_count: 511560
total_episode_count: 4410
total_duration: 29561.010891448383
[2024-12-26 09:46:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.179870463000086
avg_train_sample_per_sec: 18.179870463000086
avg_episode_per_sec: 0.15672302123275936
collect_time: 38.28410116653518
reward_mean: -115.51085434173667
reward_std: 3.9764639918618365
reward_max: -110.12745098039214
reward_min: -121.7983193277311
queue_len: 0.07659870977568745
wait_time: 0.7341676170910452
delay_time: 4.838743814701521
pressure: 0.9255083996463308
total_envstep_count: 512256
total_train_sample_count: 512256
total_episode_count: 4416
total_duration: 29599.29499261492
[2024-12-26 09:47:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.899574813698017
avg_train_sample_per_sec: 17.899574813698017
avg_episode_per_sec: 0.15430667942843118
collect_time: 38.88360518303327
reward_mean: -115.7615546218487
reward_std: 10.207092545555216
reward_max: -107.7114845938375
reward_min: -130.8578431372549
queue_len: 0.07676495664578828
wait_time: 0.7354767724950282
delay_time: 4.85790121838848
pressure: 0.9315870910698497
total_envstep_count: 512952
total_train_sample_count: 512952
total_episode_count: 4422
total_duration: 29638.178597797953
[2024-12-26 09:47:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.826702375402856
avg_train_sample_per_sec: 17.826702375402856
avg_episode_per_sec: 0.1536784687534729
collect_time: 39.04255455346219
reward_mean: -118.50256769374415
reward_std: 6.332293844478257
reward_max: -109.81162464985994
reward_min: -127.84803921568626
queue_len: 0.07858260457144839
wait_time: 0.7539844297577565
delay_time: 4.932107389506564
pressure: 0.9524756852343059
total_envstep_count: 513648
total_train_sample_count: 513648
total_episode_count: 4428
total_duration: 29677.221152351416
[2024-12-26 09:48:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.018154122137254
avg_train_sample_per_sec: 18.018154122137254
avg_episode_per_sec: 0.15532891484601083
collect_time: 38.627708214843636
reward_mean: -112.42950513538746
reward_std: 4.016659437885224
reward_max: -108.82773109243695
reward_min: -119.01260504201679
queue_len: 0.07455537475821451
wait_time: 0.7137964160022983
delay_time: 4.73917593838519
pressure: 0.8988726790450929
total_envstep_count: 514344
total_train_sample_count: 514344
total_episode_count: 4434
total_duration: 29715.84886056626
[2024-12-26 09:49:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.852851258596683
avg_train_sample_per_sec: 17.852851258596683
avg_episode_per_sec: 0.15390389016031625
collect_time: 38.985369335044176
reward_mean: -116.97397292250234
reward_std: 4.890514855284036
reward_max: -110.0581232492997
reward_min: -126.22058823529416
queue_len: 0.07756894756134107
wait_time: 0.7449650726780547
delay_time: 4.970447712810061
pressure: 0.9292661361626878
total_envstep_count: 515040
total_train_sample_count: 515040
total_episode_count: 4440
total_duration: 29754.834229901306
[2024-12-26 09:49:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.973520105539283
avg_train_sample_per_sec: 17.973520105539283
avg_episode_per_sec: 0.1549441388408559
collect_time: 38.723633206691595
reward_mean: -116.88071895424837
reward_std: 7.97325354094561
reward_max: -108.82773109243695
reward_min: -126.7633053221289
queue_len: 0.07750710805984641
wait_time: 0.7479988458690284
delay_time: 4.915551102140261
pressure: 0.9415340406719718
total_envstep_count: 515736
total_train_sample_count: 515736
total_episode_count: 4446
total_duration: 29793.557863108
[2024-12-26 09:50:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.852251548890226
avg_train_sample_per_sec: 17.852251548890226
avg_episode_per_sec: 0.15389872024905368
collect_time: 38.98667896841653
reward_mean: -118.32026143790851
reward_std: 9.034523444009602
reward_max: -109.2878151260504
reward_min: -132.66876750700283
queue_len: 0.0784617118288518
wait_time: 0.7590397122597934
delay_time: 4.984711536773389
pressure: 0.9481653404067197
total_envstep_count: 516432
total_train_sample_count: 516432
total_episode_count: 4452
total_duration: 29832.544542076415
[2024-12-26 09:51:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.001137843931385
avg_train_sample_per_sec: 18.001137843931385
avg_episode_per_sec: 0.15518222279251195
collect_time: 38.664222563833
reward_mean: -116.48949579831931
reward_std: 7.260182546156095
reward_max: -107.77661064425769
reward_min: -124.94607843137257
queue_len: 0.07724767625883244
wait_time: 0.7412092710647477
delay_time: 4.902035868367683
pressure: 0.9324712643678161
total_envstep_count: 517128
total_train_sample_count: 517128
total_episode_count: 4458
total_duration: 29871.208764640247
[2024-12-26 09:51:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.728448586591462
avg_train_sample_per_sec: 17.728448586591462
avg_episode_per_sec: 0.15283145333268502
collect_time: 39.25893439578266
reward_mean: -120.94806255835668
reward_std: 3.6160518599847657
reward_max: -116.09663865546219
reward_min: -126.96918767507007
queue_len: 0.08020428551615165
wait_time: 0.7688978111138356
delay_time: 5.047015327067142
pressure: 0.9743589743589745
total_envstep_count: 517824
total_train_sample_count: 517824
total_episode_count: 4464
total_duration: 29910.46769903603
[2024-12-26 09:52:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.878303300273355
avg_train_sample_per_sec: 17.878303300273355
avg_episode_per_sec: 0.15412330431270135
collect_time: 38.92986869673244
reward_mean: -116.63527077497668
reward_std: 2.6640272468826995
reward_max: -112.26820728291314
reward_min: -120.11904761904763
queue_len: 0.07734434401523652
wait_time: 0.744588850128911
delay_time: 4.876322385514002
pressure: 0.9386604774535808
total_envstep_count: 518520
total_train_sample_count: 518520
total_episode_count: 4470
total_duration: 29949.397567732765
[2024-12-26 09:53:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94279418366097
avg_train_sample_per_sec: 17.94279418366097
avg_episode_per_sec: 0.15467926020397385
collect_time: 38.78994502616489
reward_mean: -114.47724089635857
reward_std: 3.324519329737326
reward_max: -111.4516806722689
reward_min: -119.9404761904762
queue_len: 0.07591328971907067
wait_time: 0.7298040237315085
delay_time: 4.79092869934039
pressure: 0.919871794871795
total_envstep_count: 519216
total_train_sample_count: 519216
total_episode_count: 4476
total_duration: 29988.18751275893
[2024-12-26 09:53:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.817232320925868
avg_train_sample_per_sec: 17.817232320925868
avg_episode_per_sec: 0.1535968303528092
collect_time: 39.06330609959923
reward_mean: -114.77205882352939
reward_std: 6.897658868657044
reward_max: -107.47829131652657
reward_min: -125.72689075630248
queue_len: 0.07610879232329536
wait_time: 0.7302065609621392
delay_time: 4.811444986656702
pressure: 0.9228558797524316
total_envstep_count: 519912
total_train_sample_count: 519912
total_episode_count: 4482
total_duration: 30027.25081885853
[2024-12-26 09:54:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.9293924218965
avg_train_sample_per_sec: 17.9293924218965
avg_episode_per_sec: 0.15456372777496982
collect_time: 38.81893951687962
reward_mean: -116.52812791783379
reward_std: 4.530924155806371
reward_max: -111.3081232492997
reward_min: -125.00840336134452
queue_len: 0.07727329437522135
wait_time: 0.7362193108896964
delay_time: 4.934524808607691
pressure: 0.9358974358974358
total_envstep_count: 520608
total_train_sample_count: 520608
total_episode_count: 4488
total_duration: 30066.06975837541
[2024-12-26 09:55:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.217508350886
avg_train_sample_per_sec: 18.217508350886
avg_episode_per_sec: 0.1570474857835
collect_time: 38.20500512992219
reward_mean: -112.95249766573293
reward_std: 4.3723214827774
reward_max: -108.44327731092433
reward_min: -118.97198879551819
queue_len: 0.07490218678099
wait_time: 0.713672814395431
delay_time: 4.735151540357237
pressure: 0.9057250221043325
total_envstep_count: 521304
total_train_sample_count: 521304
total_episode_count: 4494
total_duration: 30104.274763505335
[2024-12-26 09:55:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.967436473359708
avg_train_sample_per_sec: 17.967436473359708
avg_episode_per_sec: 0.15489169373585954
collect_time: 38.736744723264124
reward_mean: -111.33835200746965
reward_std: 3.918531161942459
reward_max: -107.14635854341735
reward_min: -118.52731092436976
queue_len: 0.07383179841344141
wait_time: 0.7020885498319576
delay_time: 4.695961133384176
pressure: 0.8931255526083114
total_envstep_count: 522000
total_train_sample_count: 522000
total_episode_count: 4500
total_duration: 30143.0115082286
[2024-12-26 09:56:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.880830013885646
avg_train_sample_per_sec: 17.880830013885646
avg_episode_per_sec: 0.1541450863266004
collect_time: 38.924367574632164
reward_mean: -115.57831465919702
reward_std: 4.636416848629987
reward_max: -108.62955182072825
reward_min: -122.74929971988799
queue_len: 0.07664344473421551
wait_time: 0.7348342298900108
delay_time: 4.828106511305579
pressure: 0.9263925729442972
total_envstep_count: 522696
total_train_sample_count: 522696
total_episode_count: 4506
total_duration: 30181.935875803232
[2024-12-26 09:57:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76952575256892
avg_train_sample_per_sec: 17.76952575256892
avg_episode_per_sec: 0.15318556683249068
collect_time: 39.16818094593099
reward_mean: -124.72910830999065
reward_std: 7.757953312569056
reward_max: -113.26890756302518
reward_min: -135.39845938375348
queue_len: 0.0827116102851397
wait_time: 0.8017139216429277
delay_time: 5.227430749246563
pressure: 0.9862953138815208
total_envstep_count: 523392
total_train_sample_count: 523392
total_episode_count: 4512
total_duration: 30221.104056749162
[2024-12-26 09:57:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.823647717816613
avg_train_sample_per_sec: 17.823647717816613
avg_episode_per_sec: 0.15365213549841908
collect_time: 39.049245755922044
reward_mean: -117.28151260504201
reward_std: 1.7568311417708005
reward_max: -115.74369747899158
reward_min: -120.15336134453786
queue_len: 0.07777288634286605
wait_time: 0.7485810194988693
delay_time: 4.928281005530978
pressure: 0.9460654288240495
total_envstep_count: 524088
total_train_sample_count: 524088
total_episode_count: 4518
total_duration: 30260.153302505085
[2024-12-26 09:58:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.796076831310202
avg_train_sample_per_sec: 17.796076831310202
avg_episode_per_sec: 0.15341445544232934
collect_time: 39.10974348995089
reward_mean: -116.02707749766573
reward_std: 3.920113581158128
reward_max: -110.00770308123245
reward_min: -120.39705882352939
queue_len: 0.07694103282338577
wait_time: 0.7355410112763052
delay_time: 4.830498783853494
pressure: 0.9383289124668436
total_envstep_count: 524784
total_train_sample_count: 524784
total_episode_count: 4524
total_duration: 30299.263045995034
[2024-12-26 09:59:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.87782329487356
avg_train_sample_per_sec: 17.87782329487356
avg_episode_per_sec: 0.1541191663351169
collect_time: 38.93091393288225
reward_mean: -117.21090102707747
reward_std: 6.713852229930145
reward_max: -108.44327731092433
reward_min: -124.79621848739497
queue_len: 0.07772606168904342
wait_time: 0.7394903031946641
delay_time: 4.945096181645376
pressure: 0.9370026525198938
total_envstep_count: 525480
total_train_sample_count: 525480
total_episode_count: 4530
total_duration: 30338.193959927918
[2024-12-26 09:59:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.090028237171275
avg_train_sample_per_sec: 18.090028237171275
avg_episode_per_sec: 0.15594851928595926
collect_time: 38.47423513523675
reward_mean: -115.09313725490195
reward_std: 7.41482751183135
reward_max: -108.44327731092433
reward_min: -127.49369747899159
queue_len: 0.07632170905497476
wait_time: 0.7295103054484392
delay_time: 4.85197047289848
pressure: 0.9241821396993811
total_envstep_count: 526176
total_train_sample_count: 526176
total_episode_count: 4536
total_duration: 30376.668195063154
[2024-12-26 10:00:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94650521108698
avg_train_sample_per_sec: 17.94650521108698
avg_episode_per_sec: 0.15471125181971535
collect_time: 38.781923935253175
reward_mean: -115.11636321195145
reward_std: 6.069665693717774
reward_max: -108.44327731092433
reward_min: -125.37745098039213
queue_len: 0.07633711088325691
wait_time: 0.7316694250644554
delay_time: 4.87813305847506
pressure: 0.9160035366931919
total_envstep_count: 526872
total_train_sample_count: 526872
total_episode_count: 4542
total_duration: 30415.450118998408
[2024-12-26 10:01:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.110410874021948
avg_train_sample_per_sec: 18.110410874021948
avg_episode_per_sec: 0.156124231672603
collect_time: 38.43093372322992
reward_mean: -110.64635854341736
reward_std: 3.147552855693254
reward_max: -108.44327731092433
reward_min: -115.82703081232498
queue_len: 0.07337291680597967
wait_time: 0.695604147936805
delay_time: 4.658403151909181
pressure: 0.8896993810786914
total_envstep_count: 527568
total_train_sample_count: 527568
total_episode_count: 4548
total_duration: 30453.881052721637
[2024-12-26 10:01:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82978320748458
avg_train_sample_per_sec: 17.82978320748458
avg_episode_per_sec: 0.15370502765072913
collect_time: 39.03580833825469
reward_mean: -117.61683006535947
reward_std: 5.6708475991414
reward_max: -112.76960784313727
reward_min: -127.14075630252103
queue_len: 0.07799524540143202
wait_time: 0.7448721973316293
delay_time: 4.984175850119119
pressure: 0.937555260831123
total_envstep_count: 528264
total_train_sample_count: 528264
total_episode_count: 4554
total_duration: 30492.916861059894
[2024-12-26 10:02:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.01857659377143
avg_train_sample_per_sec: 18.01857659377143
avg_episode_per_sec: 0.15533255684285718
collect_time: 38.62680253225938
reward_mean: -114.05392156862744
reward_std: 6.605395797773892
reward_max: -107.28501400560224
reward_min: -124.1421568627451
queue_len: 0.07563257398450095
wait_time: 0.7251978709255585
delay_time: 4.814105643765161
pressure: 0.9164456233421752
total_envstep_count: 528960
total_train_sample_count: 528960
total_episode_count: 4560
total_duration: 30531.543663592154
[2024-12-26 10:03:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8597341672174
avg_train_sample_per_sec: 17.8597341672174
avg_episode_per_sec: 0.15396322557946032
collect_time: 38.97034488215112
reward_mean: -113.16339869281045
reward_std: 5.315058677121034
reward_max: -108.44327731092433
reward_min: -124.71148459383755
queue_len: 0.07504204157348172
wait_time: 0.7156967229862766
delay_time: 4.743931057631635
pressure: 0.9108090185676391
total_envstep_count: 529656
total_train_sample_count: 529656
total_episode_count: 4566
total_duration: 30570.514008474307
[2024-12-26 10:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.790939979644318
avg_train_sample_per_sec: 17.790939979644318
avg_episode_per_sec: 0.15337017223831306
collect_time: 39.12103580790759
reward_mean: -113.34080298786178
reward_std: 7.387668566871995
reward_max: -107.28501400560224
reward_min: -124.11554621848737
queue_len: 0.07515968367895343
wait_time: 0.7195191626606432
delay_time: 4.796906890604973
pressure: 0.9144562334217506
total_envstep_count: 530352
total_train_sample_count: 530352
total_episode_count: 4572
total_duration: 30609.635044282215
[2024-12-26 10:04:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.90349018299999
avg_train_sample_per_sec: 17.90349018299999
avg_episode_per_sec: 0.1543404326120689
collect_time: 38.87510160789079
reward_mean: -120.8064892623716
reward_std: 6.6980823088323325
reward_max: -107.83403361344534
reward_min: -127.58403361344534
queue_len: 0.08011040402014032
wait_time: 0.7683231449078304
delay_time: 4.948494254029845
pressure: 0.976790450928382
total_envstep_count: 531048
total_train_sample_count: 531048
total_episode_count: 4578
total_duration: 30648.510145890104
[2024-12-26 10:05:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.689256324514712
avg_train_sample_per_sec: 17.689256324514712
avg_episode_per_sec: 0.15249358900443719
collect_time: 39.34591637046076
reward_mean: -118.21148459383754
reward_std: 6.484473783002743
reward_max: -107.48109243697475
reward_min: -128.59453781512602
queue_len: 0.07838957864312833
wait_time: 0.7522163153501896
delay_time: 4.833900735738857
pressure: 0.950154730327144
total_envstep_count: 531744
total_train_sample_count: 531744
total_episode_count: 4584
total_duration: 30687.856062260566
[2024-12-26 10:05:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.940377315710993
avg_train_sample_per_sec: 17.940377315710993
avg_episode_per_sec: 0.1546584251354396
collect_time: 38.795170678516854
reward_mean: -115.00186741363211
reward_std: 8.593558174199531
reward_max: -107.14775910364142
reward_min: -133.00980392156862
queue_len: 0.07626118528755445
wait_time: 0.729613706667459
delay_time: 4.790257701560914
pressure: 0.9231874447391689
total_envstep_count: 532440
total_train_sample_count: 532440
total_episode_count: 4590
total_duration: 30726.651232939083
[2024-12-26 10:06:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.0720287289814
avg_train_sample_per_sec: 18.0720287289814
avg_episode_per_sec: 0.15579335111190862
collect_time: 38.51255497861467
reward_mean: -113.85912698412697
reward_std: 5.549193002182314
reward_max: -107.14775910364142
reward_min: -121.95378151260505
queue_len: 0.07550339985684813
wait_time: 0.7233281354097785
delay_time: 4.753573598703858
pressure: 0.9173297966401415
total_envstep_count: 533136
total_train_sample_count: 533136
total_episode_count: 4596
total_duration: 30765.163787917696
[2024-12-26 10:07:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.849950424417756
avg_train_sample_per_sec: 17.849950424417756
avg_episode_per_sec: 0.15387888296911859
collect_time: 38.99170493201539
reward_mean: -119.26377217553689
reward_std: 5.343949531346945
reward_max: -113.12955182072825
reward_min: -125.74089635854345
queue_len: 0.0790873820792685
wait_time: 0.7590585195174446
delay_time: 5.037247438717631
pressure: 0.9393236074270558
total_envstep_count: 533832
total_train_sample_count: 533832
total_episode_count: 4602
total_duration: 30804.15549284971
[2024-12-26 10:07:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.020943095282448
avg_train_sample_per_sec: 18.020943095282448
avg_episode_per_sec: 0.15535295771795213
collect_time: 38.62173007927649
reward_mean: -115.64098972922504
reward_std: 5.630041296708757
reward_max: -107.6421568627451
reward_min: -124.49159663865551
queue_len: 0.07668500645174074
wait_time: 0.7282787783548433
delay_time: 4.825911661800187
pressure: 0.9295977011494253
total_envstep_count: 534528
total_train_sample_count: 534528
total_episode_count: 4608
total_duration: 30842.777222928988
[2024-12-26 10:08:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73881132448335
avg_train_sample_per_sec: 17.73881132448335
avg_episode_per_sec: 0.1529207872800289
collect_time: 39.23599993644282
reward_mean: -116.45471521942109
reward_std: 6.599277010132311
reward_max: -107.6421568627451
reward_min: -126.68557422969187
queue_len: 0.07722461221447023
wait_time: 0.7355348195865439
delay_time: 4.946833277797789
pressure: 0.9235190097259064
total_envstep_count: 535224
total_train_sample_count: 535224
total_episode_count: 4614
total_duration: 30882.01322286543
[2024-12-26 10:09:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.032261390547507
avg_train_sample_per_sec: 18.032261390547507
avg_episode_per_sec: 0.15545052922885783
collect_time: 38.59748840846121
reward_mean: -116.18487394957982
reward_std: 7.467633801134632
reward_max: -107.28501400560224
reward_min: -128.81582633053225
queue_len: 0.07704567238035798
wait_time: 0.732973317532141
delay_time: 4.893526028623455
pressure: 0.925950486295314
total_envstep_count: 535920
total_train_sample_count: 535920
total_episode_count: 4620
total_duration: 30920.61071127389
[2024-12-26 10:09:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.775357176195183
avg_train_sample_per_sec: 17.775357176195183
avg_episode_per_sec: 0.15323583772582053
collect_time: 39.155331344457345
reward_mean: -113.406512605042
reward_std: 5.151676199413292
reward_max: -107.14775910364142
reward_min: -119.97478991596634
queue_len: 0.07520325769565119
wait_time: 0.7144714649785643
delay_time: 4.844654175877799
pressure: 0.9104774535809018
total_envstep_count: 536616
total_train_sample_count: 536616
total_episode_count: 4626
total_duration: 30959.766042618347
[2024-12-26 10:10:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.092108685325123
avg_train_sample_per_sec: 18.092108685325123
avg_episode_per_sec: 0.15596645418383726
collect_time: 38.46981090515666
reward_mean: -113.34313725490195
reward_std: 5.285341989791362
reward_max: -107.6771708683473
reward_min: -121.98879551820731
queue_len: 0.07516123160139386
wait_time: 0.7150808046472347
delay_time: 4.7969270057519635
pressure: 0.9142351900972591
total_envstep_count: 537312
total_train_sample_count: 537312
total_episode_count: 4632
total_duration: 30998.235853523503
[2024-12-26 10:10:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.263049003480983
avg_train_sample_per_sec: 18.263049003480983
avg_episode_per_sec: 0.15744007761621537
collect_time: 38.109737309873104
reward_mean: -113.86449579831931
reward_std: 7.487717045303509
reward_max: -107.14775910364142
reward_min: -128.51330532212882
queue_len: 0.07550696007846108
wait_time: 0.7187358365096702
delay_time: 4.779011884343622
pressure: 0.9150088417329797
total_envstep_count: 538008
total_train_sample_count: 538008
total_episode_count: 4638
total_duration: 31036.345590833378
[2024-12-26 10:11:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.701615224778504
avg_train_sample_per_sec: 17.701615224778504
avg_episode_per_sec: 0.15260013124809055
collect_time: 39.3184458684735
reward_mean: -113.97058823529413
reward_std: 7.114363284723726
reward_max: -107.14775910364142
reward_min: -126.37324929971992
queue_len: 0.07557731315337807
wait_time: 0.7228490534144693
delay_time: 4.745136380893077
pressure: 0.9186560565870909
total_envstep_count: 538704
total_train_sample_count: 538704
total_episode_count: 4644
total_duration: 31075.66403670185
[2024-12-26 10:12:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.266426676905308
avg_train_sample_per_sec: 18.266426676905308
avg_episode_per_sec: 0.15746919549056299
collect_time: 38.10269037895463
reward_mean: -111.01423902894489
reward_std: 4.354509758384243
reward_max: -107.55952380952377
reward_min: -119.48669467787116
queue_len: 0.07361686938258945
wait_time: 0.6997805200771733
delay_time: 4.703177089484567
pressure: 0.8884836427939877
total_envstep_count: 539400
total_train_sample_count: 539400
total_episode_count: 4650
total_duration: 31113.766727080805
[2024-12-26 10:12:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.23115281383312
avg_train_sample_per_sec: 18.23115281383312
avg_episode_per_sec: 0.15716511046407863
collect_time: 38.17641194208526
reward_mean: -109.3534080298786
reward_std: 3.127403460152421
reward_max: -107.14775910364142
reward_min: -115.75420168067228
queue_len: 0.07251552256623249
wait_time: 0.6880560137405979
delay_time: 4.612857491873634
pressure: 0.8775419982316534
total_envstep_count: 540096
total_train_sample_count: 540096
total_episode_count: 4656
total_duration: 31151.94313902289
[2024-12-26 10:13:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.06207941209699
avg_train_sample_per_sec: 18.06207941209699
avg_episode_per_sec: 0.15570758113876715
collect_time: 38.5337692366615
reward_mean: -110.24276377217551
reward_std: 4.37375489752854
reward_max: -107.14775910364142
reward_min: -118.82703081232495
queue_len: 0.0731052810160315
wait_time: 0.6904008840494641
delay_time: 4.653188991790309
pressure: 0.8877099911582671
total_envstep_count: 540792
total_train_sample_count: 540792
total_episode_count: 4662
total_duration: 31190.476908259552
[2024-12-26 10:14:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.041629346822265
avg_train_sample_per_sec: 18.041629346822265
avg_episode_per_sec: 0.15553128747260572
collect_time: 38.57744700439647
reward_mean: -112.45599906629316
reward_std: 8.209954620708023
reward_max: -106.97198879551816
reward_min: -130.24579831932775
queue_len: 0.07457294367791324
wait_time: 0.7114668701255922
delay_time: 4.743530159085164
pressure: 0.8999778956675509
total_envstep_count: 541488
total_train_sample_count: 541488
total_episode_count: 4668
total_duration: 31229.05435526395
[2024-12-26 10:14:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.148883674145278
avg_train_sample_per_sec: 18.148883674145278
avg_episode_per_sec: 0.15645589374263172
collect_time: 38.34946614328212
reward_mean: -109.57714752567692
reward_std: 4.552077928822443
reward_max: -107.14775910364142
reward_min: -119.72128851540621
queue_len: 0.0726638909321465
wait_time: 0.6910177311419705
delay_time: 4.644172049189393
pressure: 0.88395225464191
total_envstep_count: 542184
total_train_sample_count: 542184
total_episode_count: 4674
total_duration: 31267.40382140723
[2024-12-26 10:15:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82397450165433
avg_train_sample_per_sec: 17.82397450165433
avg_episode_per_sec: 0.15365495260046835
collect_time: 39.048529829045755
reward_mean: -115.69105975723623
reward_std: 6.733694688051086
reward_max: -107.14775910364142
reward_min: -123.9341736694678
queue_len: 0.07671820938808767
wait_time: 0.7320142247880584
delay_time: 4.89521681727328
pressure: 0.9183244916003536
total_envstep_count: 542880
total_train_sample_count: 542880
total_episode_count: 4680
total_duration: 31306.452351236276
[2024-12-26 10:16:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.03276445884479
avg_train_sample_per_sec: 18.03276445884479
avg_episode_per_sec: 0.15545486602452407
collect_time: 38.59641163663194
reward_mean: -119.29190009337066
reward_std: 6.886108587895212
reward_max: -112.70238095238093
reward_min: -132.40756302521004
queue_len: 0.07910603454467552
wait_time: 0.7643993937097385
delay_time: 4.989692074812649
pressure: 0.9572281167108754
total_envstep_count: 543576
total_train_sample_count: 543576
total_episode_count: 4686
total_duration: 31345.048762872906
[2024-12-26 10:16:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.946809193293927
avg_train_sample_per_sec: 17.946809193293927
avg_episode_per_sec: 0.1547138723559821
collect_time: 38.78126704885624
reward_mean: -115.51879084967321
reward_std: 3.8672237657323576
reward_max: -111.63445378151263
reward_min: -123.41456582633054
queue_len: 0.07660397271198488
wait_time: 0.7311100058944887
delay_time: 4.9605753918057385
pressure: 0.9253978779840848
total_envstep_count: 544272
total_train_sample_count: 544272
total_episode_count: 4692
total_duration: 31383.830029921763
[2024-12-26 10:17:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.13916346463703
avg_train_sample_per_sec: 18.13916346463703
avg_episode_per_sec: 0.15637209883307784
collect_time: 38.370016420926895
reward_mean: -114.0909197012138
reward_std: 2.7058940851649917
reward_max: -111.44817927170874
reward_min: -119.0392156862745
queue_len: 0.07565710855518155
wait_time: 0.7205607596708002
delay_time: 4.786875885124126
pressure: 0.9195402298850573
total_envstep_count: 544968
total_train_sample_count: 544968
total_episode_count: 4698
total_duration: 31422.20004634269
[2024-12-26 10:18:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.758697739407427
avg_train_sample_per_sec: 17.758697739407427
avg_episode_per_sec: 0.15309222189144334
collect_time: 39.19206296616793
reward_mean: -113.23669467787113
reward_std: 3.1623561533145343
reward_max: -109.17296918767504
reward_min: -118.97899159663866
queue_len: 0.07509064633811084
wait_time: 0.7141464786621988
delay_time: 4.73329411086836
pressure: 0.9198717948717948
total_envstep_count: 545664
total_train_sample_count: 545664
total_episode_count: 4704
total_duration: 31461.392109308857
[2024-12-26 10:18:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.11626569703126
avg_train_sample_per_sec: 18.11626569703126
avg_episode_per_sec: 0.15617470428475225
collect_time: 38.418513596544045
reward_mean: -114.69199346405229
reward_std: 2.8535707522378724
reward_max: -111.68837535014005
reward_min: -120.51890756302521
queue_len: 0.07605569858358906
wait_time: 0.7270422205133159
delay_time: 4.825078860691265
pressure: 0.9315870910698497
total_envstep_count: 546360
total_train_sample_count: 546360
total_episode_count: 4710
total_duration: 31499.810622905403
[2024-12-26 10:19:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.029892288626577
avg_train_sample_per_sec: 18.029892288626577
avg_episode_per_sec: 0.155430105936436
collect_time: 38.60256006293744
reward_mean: -116.91736694677871
reward_std: 4.014536844961815
reward_max: -112.093837535014
reward_min: -123.24509803921565
queue_len: 0.07753141044216094
wait_time: 0.7433665331738353
delay_time: 4.872064963469959
pressure: 0.9437444739168876
total_envstep_count: 547056
total_train_sample_count: 547056
total_episode_count: 4716
total_duration: 31538.41318296834
[2024-12-26 10:20:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.860863247668313
avg_train_sample_per_sec: 17.860863247668313
avg_episode_per_sec: 0.15397295903162336
collect_time: 38.96788135875017
reward_mean: -116.83403361344536
reward_std: 5.237707167427872
reward_max: -110.15056022408959
reward_min: -124.15406162464986
queue_len: 0.07747614961103803
wait_time: 0.7387966017529912
delay_time: 4.854365469406267
pressure: 0.9398762157382846
total_envstep_count: 547752
total_train_sample_count: 547752
total_episode_count: 4722
total_duration: 31577.381064327088
[2024-12-26 10:20:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.897193648414458
avg_train_sample_per_sec: 17.897193648414458
avg_episode_per_sec: 0.15428615214150393
collect_time: 38.88877852431685
reward_mean: -112.38585434173666
reward_std: 2.611503875317875
reward_max: -107.14775910364142
reward_min: -115.22268907563021
queue_len: 0.07452642860857868
wait_time: 0.7161981724608499
delay_time: 4.761529262170305
pressure: 0.8968832891246684
total_envstep_count: 548448
total_train_sample_count: 548448
total_episode_count: 4728
total_duration: 31616.269842851405
[2024-12-26 10:21:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.39598261342204
avg_train_sample_per_sec: 18.39598261342204
avg_episode_per_sec: 0.15858605701225897
collect_time: 37.83434756522252
reward_mean: -110.11134453781511
reward_std: 2.5418075178844903
reward_max: -106.81442577030809
reward_min: -113.54271708683473
queue_len: 0.073018132982636
wait_time: 0.6948227566888825
delay_time: 4.716747637035156
pressure: 0.8791998231653405
total_envstep_count: 549144
total_train_sample_count: 549144
total_episode_count: 4734
total_duration: 31654.104190416627
[2024-12-26 10:22:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.953914470771657
avg_train_sample_per_sec: 17.953914470771657
avg_episode_per_sec: 0.15477512474803154
collect_time: 38.76591932823695
reward_mean: -112.90767973856208
reward_std: 6.584312051411921
reward_max: -106.81442577030809
reward_min: -124.33123249299717
queue_len: 0.07487246667013399
wait_time: 0.7150590563369468
delay_time: 4.713370381934859
pressure: 0.9104774535809018
total_envstep_count: 549840
total_train_sample_count: 549840
total_episode_count: 4740
total_duration: 31692.870109744865
[2024-12-26 10:22:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.150644357800736
avg_train_sample_per_sec: 18.150644357800736
avg_episode_per_sec: 0.15647107205000635
collect_time: 38.345746094731616
reward_mean: -111.6176470588235
reward_std: 5.952272668867327
reward_max: -107.14775910364142
reward_min: -123.11974789915963
queue_len: 0.07401700733343734
wait_time: 0.7061764582048559
delay_time: 4.708853692540924
pressure: 0.8936781609195403
total_envstep_count: 550536
total_train_sample_count: 550536
total_episode_count: 4746
total_duration: 31731.215855839597
[2024-12-26 10:23:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.800492361667093
avg_train_sample_per_sec: 17.800492361667093
avg_episode_per_sec: 0.15345252035919907
collect_time: 39.10004205832072
reward_mean: -118.66631652661063
reward_std: 8.01532287146457
reward_max: -107.14775910364142
reward_min: -131.60434173669466
queue_len: 0.07869119133064366
wait_time: 0.7544855696478415
delay_time: 4.950811048409851
pressure: 0.9566755083996462
total_envstep_count: 551232
total_train_sample_count: 551232
total_episode_count: 4752
total_duration: 31770.31589789792
[2024-12-26 10:24:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.885682731964486
avg_train_sample_per_sec: 17.885682731964486
avg_episode_per_sec: 0.15418692010314214
collect_time: 38.91380667041243
reward_mean: -112.78781512605042
reward_std: 4.334785462074228
reward_max: -107.922268907563
reward_min: -120.32563025210082
queue_len: 0.07479298085281856
wait_time: 0.7140320097977298
delay_time: 4.736003169287764
pressure: 0.9108090185676393
total_envstep_count: 551928
total_train_sample_count: 551928
total_episode_count: 4758
total_duration: 31809.22970456833
[2024-12-26 10:24:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.746670621200614
avg_train_sample_per_sec: 17.746670621200614
avg_episode_per_sec: 0.15298853983793634
collect_time: 39.21862386787869
reward_mean: -119.95016339869282
reward_std: 6.843402690417743
reward_max: -108.35504201680666
reward_min: -131.50210084033617
queue_len: 0.0795425486728732
wait_time: 0.7675151293939325
delay_time: 4.991515702080632
pressure: 0.9639699381078691
total_envstep_count: 552624
total_train_sample_count: 552624
total_episode_count: 4764
total_duration: 31848.448328436207
[2024-12-26 10:25:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7871176426869
avg_train_sample_per_sec: 17.7871176426869
avg_episode_per_sec: 0.1533372210576457
collect_time: 39.12944266639837
reward_mean: -118.63468720821658
reward_std: 8.205467208910038
reward_max: -106.81442577030809
reward_min: -129.4551820728291
queue_len: 0.07867021698157599
wait_time: 0.7491303771729735
delay_time: 4.952643740686336
pressure: 0.9507073386383732
total_envstep_count: 553320
total_train_sample_count: 553320
total_episode_count: 4770
total_duration: 31887.577771102606
[2024-12-26 10:26:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.645101346844157
avg_train_sample_per_sec: 17.645101346844157
avg_episode_per_sec: 0.15211294264520825
collect_time: 39.44437531521916
reward_mean: -111.84827264239026
reward_std: 7.276865134295525
reward_max: -106.81442577030809
reward_min: -126.32492997198874
queue_len: 0.07416994207055057
wait_time: 0.70628883737403
delay_time: 4.679077375559132
pressure: 0.8966622458001768
total_envstep_count: 554016
total_train_sample_count: 554016
total_episode_count: 4776
total_duration: 31927.022146417825
[2024-12-26 10:26:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.748646240722227
avg_train_sample_per_sec: 17.748646240722227
avg_episode_per_sec: 0.15300557104070883
collect_time: 39.21425840372592
reward_mean: -114.72420634920633
reward_std: 6.407962777230219
reward_max: -107.48109243697475
reward_min: -121.6078431372549
queue_len: 0.07607705991326678
wait_time: 0.726947178075474
delay_time: 4.849966552026905
pressure: 0.923076923076923
total_envstep_count: 554712
total_train_sample_count: 554712
total_episode_count: 4782
total_duration: 31966.23640482155
[2024-12-26 10:27:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.910013096800103
avg_train_sample_per_sec: 17.910013096800103
avg_episode_per_sec: 0.15439666462758708
collect_time: 38.860943106979136
reward_mean: -109.69631185807653
reward_std: 3.1421312587087997
reward_max: -106.81442577030809
reward_min: -114.18557422969185
queue_len: 0.0727429123727298
wait_time: 0.6909103053246054
delay_time: 4.680990122045166
pressure: 0.8793103448275863
total_envstep_count: 555408
total_train_sample_count: 555408
total_episode_count: 4788
total_duration: 32005.097347928528
[2024-12-26 10:28:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.991400570041563
avg_train_sample_per_sec: 17.991400570041563
avg_episode_per_sec: 0.15509828077622037
collect_time: 38.685148345757284
reward_mean: -113.0489028944911
reward_std: 7.326028104480789
reward_max: -106.81442577030809
reward_min: -125.59803921568624
queue_len: 0.07496611597777923
wait_time: 0.7202230029943012
delay_time: 4.722062587786369
pressure: 0.9101458885941646
total_envstep_count: 556104
total_train_sample_count: 556104
total_episode_count: 4794
total_duration: 32043.782496274285
[2024-12-26 10:28:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.763718239543934
avg_train_sample_per_sec: 17.763718239543934
avg_episode_per_sec: 0.15313550206503393
collect_time: 39.18098624479585
reward_mean: -109.07037815126047
reward_std: 5.03914078140459
reward_max: -106.81442577030809
reward_min: -120.33823529411762
queue_len: 0.07232783697033188
wait_time: 0.6845238095238094
delay_time: 4.59515702497479
pressure: 0.8791998231653405
total_envstep_count: 556800
total_train_sample_count: 556800
total_episode_count: 4800
total_duration: 32082.96348251908
[2024-12-26 10:29:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.70244740628352
avg_train_sample_per_sec: 17.70244740628352
avg_episode_per_sec: 0.15260730522658209
collect_time: 39.31659753176012
reward_mean: -112.86029411764706
reward_std: 6.206398635275383
reward_max: -106.81442577030809
reward_min: -121.5420168067227
queue_len: 0.07484104384459354
wait_time: 0.7106657428665543
delay_time: 4.788437931793657
pressure: 0.9078249336870027
total_envstep_count: 557496
total_train_sample_count: 557496
total_episode_count: 4806
total_duration: 32122.28008005084
[2024-12-26 10:30:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.041413094929368
avg_train_sample_per_sec: 18.041413094929368
avg_episode_per_sec: 0.15552942323214974
collect_time: 38.57790940974653
reward_mean: -108.02450980392153
reward_std: 2.7058301576468056
reward_max: -106.81442577030809
reward_min: -114.07492997198877
queue_len: 0.07163429032090288
wait_time: 0.6803414004859238
delay_time: 4.591594408587938
pressure: 0.8677055702917773
total_envstep_count: 558192
total_train_sample_count: 558192
total_episode_count: 4812
total_duration: 32160.857989460586
[2024-12-26 10:30:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.812214347228878
avg_train_sample_per_sec: 17.812214347228878
avg_episode_per_sec: 0.15355357195886965
collect_time: 39.07431083144807
reward_mean: -110.234943977591
reward_std: 7.26618994737351
reward_max: -106.81442577030809
reward_min: -126.46708683473388
queue_len: 0.07310009547585611
wait_time: 0.695454850817427
delay_time: 4.704377270346318
pressure: 0.8852785145888594
total_envstep_count: 558888
total_train_sample_count: 558888
total_episode_count: 4818
total_duration: 32199.932300292036
[2024-12-26 10:31:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7483847198233
avg_train_sample_per_sec: 17.7483847198233
avg_episode_per_sec: 0.15300331655020086
collect_time: 39.21483622239902
reward_mean: -108.32341269841267
reward_std: 3.374197348400426
reward_max: -106.81442577030809
reward_min: -115.86834733893556
queue_len: 0.07183250178939833
wait_time: 0.6799411851389539
delay_time: 4.586957595423226
pressure: 0.8688107869142353
total_envstep_count: 559584
total_train_sample_count: 559584
total_episode_count: 4824
total_duration: 32239.147136514435
[2024-12-26 10:31:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97162780049837
avg_train_sample_per_sec: 17.97162780049837
avg_episode_per_sec: 0.15492782586636525
collect_time: 38.72771057392471
reward_mean: -114.48739495798317
reward_std: 8.139771644114285
reward_max: -106.81442577030809
reward_min: -127.49439775910362
queue_len: 0.07592002318168646
wait_time: 0.7206833551280812
delay_time: 4.768113045309261
pressure: 0.9193191865605659
total_envstep_count: 560280
total_train_sample_count: 560280
total_episode_count: 4830
total_duration: 32277.87484708836
[2024-12-26 10:32:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.08830813125946
avg_train_sample_per_sec: 18.08830813125946
avg_episode_per_sec: 0.15593369078671948
collect_time: 38.477893838904805
reward_mean: -107.03664799253032
reward_std: 0.2484519974999731
reward_max: -106.81442577030809
reward_min: -107.48109243697475
queue_len: 0.07097920954411824
wait_time: 0.6713053258438654
delay_time: 4.547963118644788
pressure: 0.8591954022988507
total_envstep_count: 560976
total_train_sample_count: 560976
total_episode_count: 4836
total_duration: 32316.352740927265
[2024-12-26 10:33:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83056987163618
avg_train_sample_per_sec: 17.83056987163618
avg_episode_per_sec: 0.1537118092382429
collect_time: 39.034086123470225
reward_mean: -111.36683006535945
reward_std: 5.9435359176717055
reward_max: -106.81442577030809
reward_min: -123.66176470588233
queue_len: 0.0738506830672145
wait_time: 0.702590850663873
delay_time: 4.711612340756307
pressure: 0.8938992042440317
total_envstep_count: 561672
total_train_sample_count: 561672
total_episode_count: 4842
total_duration: 32355.386827050734
[2024-12-26 10:33:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.6745088936761
avg_train_sample_per_sec: 17.6745088936761
avg_episode_per_sec: 0.1523664559799664
collect_time: 39.378746203750374
reward_mean: -111.1349206349206
reward_std: 8.674923519547061
reward_max: -106.81442577030809
reward_min: -130.4418767507003
queue_len: 0.07369689697275902
wait_time: 0.7000071359224503
delay_time: 4.713725925941124
pressure: 0.8933465959328029
total_envstep_count: 562368
total_train_sample_count: 562368
total_episode_count: 4848
total_duration: 32394.765573254484
[2024-12-26 10:34:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.777979645435426
avg_train_sample_per_sec: 17.777979645435426
avg_episode_per_sec: 0.15325844521927093
collect_time: 39.14955545461551
reward_mean: -119.26797385620914
reward_std: 4.423190757631828
reward_max: -115.63655462184879
reward_min: -128.68837535014006
queue_len: 0.07909016833966123
wait_time: 0.7556750706471803
delay_time: 5.014333316325586
pressure: 0.9574491600353668
total_envstep_count: 563064
total_train_sample_count: 563064
total_episode_count: 4854
total_duration: 32433.9151287091
[2024-12-26 10:35:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56760259827866
avg_train_sample_per_sec: 17.56760259827866
avg_episode_per_sec: 0.15144484998516086
collect_time: 39.61838253719359
reward_mean: -116.82784780578898
reward_std: 2.4012211711281712
reward_max: -114.5889355742297
reward_min: -120.5490196078431
queue_len: 0.07747204761657094
wait_time: 0.7436633473017854
delay_time: 4.817743875169677
pressure: 0.9442970822281168
total_envstep_count: 563760
total_train_sample_count: 563760
total_episode_count: 4860
total_duration: 32473.533511246293
[2024-12-26 10:35:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.645979474157567
avg_train_sample_per_sec: 17.645979474157567
avg_episode_per_sec: 0.15212051270825488
collect_time: 39.4424124214407
reward_mean: -115.69677871148457
reward_std: 6.085642736452611
reward_max: -106.81442577030809
reward_min: -124.76470588235293
queue_len: 0.0767220017980667
wait_time: 0.7295971438973469
delay_time: 4.867980131482348
pressure: 0.9219717064544652
total_envstep_count: 564456
total_train_sample_count: 564456
total_episode_count: 4866
total_duration: 32512.975923667735
[2024-12-26 10:36:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.91300171446006
avg_train_sample_per_sec: 17.91300171446006
avg_episode_per_sec: 0.15442242857293154
collect_time: 38.85445952021331
reward_mean: -109.62628384687206
reward_std: 4.632399655687974
reward_max: -106.81442577030809
reward_min: -119.45168067226889
queue_len: 0.07269647469951727
wait_time: 0.6901063144090527
delay_time: 4.621978831421544
pressure: 0.8815207780725022
total_envstep_count: 565152
total_train_sample_count: 565152
total_episode_count: 4872
total_duration: 32551.83038318795
[2024-12-26 10:37:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.639443124024428
avg_train_sample_per_sec: 17.639443124024428
avg_episode_per_sec: 0.15206416486227955
collect_time: 39.457027929190545
reward_mean: -119.2783613445378
reward_std: 2.0526357573971024
reward_max: -115.68977591036413
reward_min: -121.94957983193272
queue_len: 0.07909705659452108
wait_time: 0.7569532676023548
delay_time: 5.0100898123005
pressure: 0.9494916003536694
total_envstep_count: 565848
total_train_sample_count: 565848
total_episode_count: 4878
total_duration: 32591.28741111714
[2024-12-26 10:37:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60780797147381
avg_train_sample_per_sec: 17.60780797147381
avg_episode_per_sec: 0.15179144802994665
collect_time: 39.527918587457386
reward_mean: -112.23366013071893
reward_std: 6.899612116636226
reward_max: -106.81442577030809
reward_min: -121.93067226890754
queue_len: 0.07442550406546349
wait_time: 0.7090264156060302
delay_time: 4.720485978558209
pressure: 0.9046198054818744
total_envstep_count: 566544
total_train_sample_count: 566544
total_episode_count: 4884
total_duration: 32630.815329704597
[2024-12-26 10:38:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.859682140936332
avg_train_sample_per_sec: 17.859682140936332
avg_episode_per_sec: 0.15396277707703734
collect_time: 38.97045840500668
reward_mean: -113.51563958916897
reward_std: 7.156991101987346
reward_max: -106.81442577030809
reward_min: -125.11484593837535
queue_len: 0.0752756230697407
wait_time: 0.7210509093115584
delay_time: 4.815661042737102
pressure: 0.9030725022104331
total_envstep_count: 567240
total_train_sample_count: 567240
total_episode_count: 4890
total_duration: 32669.785788109602
[2024-12-26 10:39:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.724472396130807
avg_train_sample_per_sec: 17.724472396130807
avg_episode_per_sec: 0.15279717582871385
collect_time: 39.26774148447626
reward_mean: -111.7549019607843
reward_std: 3.8347281601908954
reward_max: -106.81442577030809
reward_min: -117.99299719887955
queue_len: 0.07410802517293388
wait_time: 0.7102635926165338
delay_time: 4.688299313250419
pressure: 0.8953359858532273
total_envstep_count: 567936
total_train_sample_count: 567936
total_episode_count: 4896
total_duration: 32709.05352959408
[2024-12-26 10:39:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.688605006012974
avg_train_sample_per_sec: 17.688605006012974
avg_episode_per_sec: 0.15248797418976703
collect_time: 39.347365140631794
reward_mean: -115.91981792717085
reward_std: 11.368294710323232
reward_max: -107.14775910364142
reward_min: -138.36904761904756
queue_len: 0.07686990578724856
wait_time: 0.7350003993639896
delay_time: 4.884147251464719
pressure: 0.9294871794871794
total_envstep_count: 568632
total_train_sample_count: 568632
total_episode_count: 4902
total_duration: 32748.40089473471
[2024-12-26 10:40:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.761732688350634
avg_train_sample_per_sec: 17.761732688350634
avg_episode_per_sec: 0.15311838524440202
collect_time: 39.18536621466467
reward_mean: -115.37908496732025
reward_std: 6.811234226289048
reward_max: -106.81442577030809
reward_min: -123.21988795518205
queue_len: 0.0765113295539259
wait_time: 0.7308094767526816
delay_time: 4.855920726997938
pressure: 0.9178824049513704
total_envstep_count: 569328
total_train_sample_count: 569328
total_episode_count: 4908
total_duration: 32787.58626094938
[2024-12-26 10:41:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.653134531365858
avg_train_sample_per_sec: 17.653134531365858
avg_episode_per_sec: 0.15218219423591256
collect_time: 39.42642587147095
reward_mean: -114.65254435107374
reward_std: 8.164436172440235
reward_max: -106.81442577030809
reward_min: -127.05882352941177
queue_len: 0.07602953869434596
wait_time: 0.722610286378035
delay_time: 4.8139765899487275
pressure: 0.9224137931034481
total_envstep_count: 570024
total_train_sample_count: 570024
total_episode_count: 4914
total_duration: 32827.012686820846
[2024-12-26 10:41:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.751659045782823
avg_train_sample_per_sec: 17.751659045782823
avg_episode_per_sec: 0.15303154349812778
collect_time: 39.2076029741764
reward_mean: -112.2600373482726
reward_std: 6.442434063827303
reward_max: -106.81442577030809
reward_min: -124.5385154061624
queue_len: 0.0744429955890402
wait_time: 0.7088898888467855
delay_time: 4.729574908462609
pressure: 0.8927939876215737
total_envstep_count: 570720
total_train_sample_count: 570720
total_episode_count: 4920
total_duration: 32866.22028979502
[2024-12-26 10:42:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.513110793736086
avg_train_sample_per_sec: 17.513110793736086
avg_episode_per_sec: 0.150975093049449
collect_time: 39.74165459222346
reward_mean: -123.24147992530345
reward_std: 8.062359117865583
reward_max: -109.54061624649859
reward_min: -135.85574229691875
queue_len: 0.08172511931386171
wait_time: 0.7916952258356923
delay_time: 5.135431788826275
pressure: 0.9859637488947834
total_envstep_count: 571416
total_train_sample_count: 571416
total_episode_count: 4926
total_duration: 32905.96194438724
[2024-12-26 10:43:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88517365878991
avg_train_sample_per_sec: 17.88517365878991
avg_episode_per_sec: 0.15418253154129233
collect_time: 38.914914290359235
reward_mean: -112.38842203548081
reward_std: 6.125222612901415
reward_max: -107.28501400560219
reward_min: -121.26120448179272
queue_len: 0.07452813132326315
wait_time: 0.7075317416975632
delay_time: 4.725629779912044
pressure: 0.9040671971706455
total_envstep_count: 572112
total_train_sample_count: 572112
total_episode_count: 4932
total_duration: 32944.876858677606
[2024-12-26 10:43:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.639530894423167
avg_train_sample_per_sec: 17.639530894423167
avg_episode_per_sec: 0.15206492150364798
collect_time: 39.456831599758935
reward_mean: -119.05392156862744
reward_std: 6.422772978488175
reward_max: -109.3158263305322
reward_min: -127.20098039215684
queue_len: 0.07894822385187496
wait_time: 0.7542639845504957
delay_time: 4.948005151860339
pressure: 0.946286472148541
total_envstep_count: 572808
total_train_sample_count: 572808
total_episode_count: 4938
total_duration: 32984.333690277366
[2024-12-26 10:44:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.976038885343282
avg_train_sample_per_sec: 17.976038885343282
avg_episode_per_sec: 0.15496585245985586
collect_time: 38.718207300245766
reward_mean: -115.76062091503267
reward_std: 2.466585788284904
reward_max: -112.04481792717087
reward_min: -119.18487394957981
queue_len: 0.07676433747681212
wait_time: 0.7332863074495936
delay_time: 4.835386652545509
pressure: 0.9308134394341291
total_envstep_count: 573504
total_train_sample_count: 573504
total_episode_count: 4944
total_duration: 33023.051897577614
[2024-12-26 10:45:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.747126754407937
avg_train_sample_per_sec: 17.747126754407937
avg_episode_per_sec: 0.15299247202075805
collect_time: 39.21761587841994
reward_mean: -119.62710084033613
reward_std: 8.747129947763423
reward_max: -107.75070028011203
reward_min: -133.56862745098033
queue_len: 0.07932831620711944
wait_time: 0.7649735181428894
delay_time: 4.934586278529846
pressure: 0.9612068965517242
total_envstep_count: 574200
total_train_sample_count: 574200
total_episode_count: 4950
total_duration: 33062.269513456034
[2024-12-26 10:45:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8255384230018
avg_train_sample_per_sec: 17.8255384230018
avg_episode_per_sec: 0.15366843468105
collect_time: 39.04510391124525
reward_mean: -119.11437908496731
reward_std: 6.380898413180669
reward_max: -107.49789915966383
reward_min: -125.17717086834735
queue_len: 0.07898831504308178
wait_time: 0.7635791496085614
delay_time: 4.8655515384350165
pressure: 0.9603227232537578
total_envstep_count: 574896
total_train_sample_count: 574896
total_episode_count: 4956
total_duration: 33101.31461736728
[2024-12-26 10:46:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.841633105230837
avg_train_sample_per_sec: 17.841633105230837
avg_episode_per_sec: 0.15380718194164514
collect_time: 39.00988188104517
reward_mean: -112.14519140989728
reward_std: 5.486982836339951
reward_max: -107.33893557422967
reward_min: -120.16246498599439
queue_len: 0.07436683780497168
wait_time: 0.7064508274574196
delay_time: 4.813292094003656
pressure: 0.8956675508399647
total_envstep_count: 575592
total_train_sample_count: 575592
total_episode_count: 4962
total_duration: 33140.32449924832
[2024-12-26 10:47:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85878890468114
avg_train_sample_per_sec: 17.85878890468114
avg_episode_per_sec: 0.1539550767644926
collect_time: 38.972407575609154
reward_mean: -112.65347805788981
reward_std: 7.610273075026673
reward_max: -107.14775910364142
reward_min: -127.85294117647058
queue_len: 0.07470389791637254
wait_time: 0.7106315337806212
delay_time: 4.731279790065666
pressure: 0.9046198054818744
total_envstep_count: 576288
total_train_sample_count: 576288
total_episode_count: 4968
total_duration: 33179.29690682393
[2024-12-26 10:47:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.941750628960584
avg_train_sample_per_sec: 17.941750628960584
avg_episode_per_sec: 0.15467026404276366
collect_time: 38.79220118445717
reward_mean: -110.74183006535947
reward_std: 4.234788979358795
reward_max: -107.43207282913163
reward_min: -119.609243697479
queue_len: 0.07343622683379274
wait_time: 0.6956594861640503
delay_time: 4.689721273650958
pressure: 0.8870468611847921
total_envstep_count: 576984
total_train_sample_count: 576984
total_episode_count: 4974
total_duration: 33218.08910800839
[2024-12-26 10:48:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.890289177577987
avg_train_sample_per_sec: 17.890289177577987
avg_episode_per_sec: 0.15422663084118957
collect_time: 38.90378702610918
reward_mean: -111.33730158730157
reward_std: 2.9107184953291156
reward_max: -107.56372549019605
reward_min: -115.95098039215684
queue_len: 0.07383110184834323
wait_time: 0.7037230011367943
delay_time: 4.678171505697095
pressure: 0.8958885941644561
total_envstep_count: 577680
total_train_sample_count: 577680
total_episode_count: 4980
total_duration: 33256.9928950345
[2024-12-26 10:49:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76124956217669
avg_train_sample_per_sec: 17.76124956217669
avg_episode_per_sec: 0.15311422036359215
collect_time: 39.1864321011603
reward_mean: -114.61321195144723
reward_std: 4.758482108568513
reward_max: -106.81442577030809
reward_min: -122.07983193277309
queue_len: 0.07600345620122494
wait_time: 0.72669424754871
delay_time: 4.846103050486159
pressure: 0.918103448275862
total_envstep_count: 578376
total_train_sample_count: 578376
total_episode_count: 4986
total_duration: 33296.17932713566
[2024-12-26 10:49:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.92417534476116
avg_train_sample_per_sec: 17.92417534476116
avg_episode_per_sec: 0.15451875297207895
collect_time: 38.830238301781925
reward_mean: -111.31465919701212
reward_std: 4.388431130421479
reward_max: -106.81442577030809
reward_min: -118.58683473389353
queue_len: 0.07381608700067117
wait_time: 0.7024445719932535
delay_time: 4.723199671301994
pressure: 0.8924624226348365
total_envstep_count: 579072
total_train_sample_count: 579072
total_episode_count: 4992
total_duration: 33335.00956543744
[2024-12-26 10:50:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.916143900640122
avg_train_sample_per_sec: 17.916143900640122
avg_episode_per_sec: 0.15444951638482865
collect_time: 38.84764511046
reward_mean: -113.80718954248363
reward_std: 8.600315743571937
reward_max: -106.81442577030809
reward_min: -130.46708683473386
queue_len: 0.07546895858254882
wait_time: 0.712304450958102
delay_time: 4.915407942962064
pressure: 0.9073828470380194
total_envstep_count: 579768
total_train_sample_count: 579768
total_episode_count: 4998
total_duration: 33373.857210547896
[2024-12-26 10:51:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.799308746163707
avg_train_sample_per_sec: 17.799308746163707
avg_episode_per_sec: 0.15344231677727332
collect_time: 39.102642126481975
reward_mean: -115.60037348272643
reward_std: 6.417253310304358
reward_max: -106.81442577030809
reward_min: -125.11904761904765
queue_len: 0.07665807260127748
wait_time: 0.7351587518296444
delay_time: 4.862280767462309
pressure: 0.9300397877984086
total_envstep_count: 580464
total_train_sample_count: 580464
total_episode_count: 5004
total_duration: 33412.95985267438
[2024-12-26 10:51:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.803055999320332
avg_train_sample_per_sec: 17.803055999320332
avg_episode_per_sec: 0.15347462068379594
collect_time: 39.09441165755875
reward_mean: -108.40592903828195
reward_std: 1.6052718455380355
reward_max: -106.81442577030809
reward_min: -111.1015406162465
queue_len: 0.07188722084766708
wait_time: 0.6803214322864425
delay_time: 4.60342336535349
pressure: 0.8673740053050398
total_envstep_count: 581160
total_train_sample_count: 581160
total_episode_count: 5010
total_duration: 33452.054264331935
[2024-12-26 10:52:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.714151875744914
avg_train_sample_per_sec: 17.714151875744914
avg_episode_per_sec: 0.1527082058253872
collect_time: 39.29061943705007
reward_mean: -109.54855275443508
reward_std: 3.8359571354410167
reward_max: -106.81442577030809
reward_min: -116.29761904761904
queue_len: 0.07264492888225138
wait_time: 0.6894013131335647
delay_time: 4.66984249049793
pressure: 0.8733421750663131
total_envstep_count: 581856
total_train_sample_count: 581856
total_episode_count: 5016
total_duration: 33491.34488376899
[2024-12-26 10:53:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.07519991349726
avg_train_sample_per_sec: 18.07519991349726
avg_episode_per_sec: 0.15582068890945913
collect_time: 38.50579818374663
reward_mean: -109.08590102707745
reward_std: 3.214302742354212
reward_max: -106.81442577030809
reward_min: -113.82282913165265
queue_len: 0.07233813065456066
wait_time: 0.6829152859198498
delay_time: 4.618115148134854
pressure: 0.8755526083112288
total_envstep_count: 582552
total_train_sample_count: 582552
total_episode_count: 5022
total_duration: 33529.85068195273
[2024-12-26 10:53:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.011868343814527
avg_train_sample_per_sec: 18.011868343814527
avg_episode_per_sec: 0.1552747271018494
collect_time: 38.641188504967836
reward_mean: -110.2000466853408
reward_std: 6.598929576994498
reward_max: -106.81442577030809
reward_min: -124.93627450980395
queue_len: 0.07307695403537189
wait_time: 0.6919179254371951
delay_time: 4.676033014238034
pressure: 0.8822944297082227
total_envstep_count: 583248
total_train_sample_count: 583248
total_episode_count: 5028
total_duration: 33568.4918704577
[2024-12-26 10:54:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.926840405129315
avg_train_sample_per_sec: 17.926840405129315
avg_episode_per_sec: 0.15454172763042515
collect_time: 38.82446567666531
reward_mean: -109.62441643323994
reward_std: 4.025393224531674
reward_max: -106.81442577030809
reward_min: -116.35574229691875
queue_len: 0.07269523636156495
wait_time: 0.6887900385618438
delay_time: 4.630585376884158
pressure: 0.8779840848806367
total_envstep_count: 583944
total_train_sample_count: 583944
total_episode_count: 5034
total_duration: 33607.31633613436
[2024-12-26 10:55:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.928501393524655
avg_train_sample_per_sec: 17.928501393524655
avg_episode_per_sec: 0.15455604649590218
collect_time: 38.82086877888068
reward_mean: -109.72677404295047
reward_std: 4.996208213034471
reward_max: -106.81442577030809
reward_min: -120.8571428571428
queue_len: 0.07276311276057724
wait_time: 0.6918174652708121
delay_time: 4.651122284696684
pressure: 0.8782051282051281
total_envstep_count: 584640
total_train_sample_count: 584640
total_episode_count: 5040
total_duration: 33646.13720491324
[2024-12-26 10:55:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97453708363559
avg_train_sample_per_sec: 17.97453708363559
avg_episode_per_sec: 0.15495290589341024
collect_time: 38.72144226922281
reward_mean: -116.75198412698411
reward_std: 9.545797544771984
reward_max: -106.81442577030809
reward_min: -132.65616246498598
queue_len: 0.07742174013725737
wait_time: 0.7374246780940492
delay_time: 4.891796678885751
pressure: 0.9339080459770116
total_envstep_count: 585336
total_train_sample_count: 585336
total_episode_count: 5046
total_duration: 33684.85864718246
[2024-12-26 10:56:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.668269550981332
avg_train_sample_per_sec: 17.668269550981332
avg_episode_per_sec: 0.1523126685429425
collect_time: 39.39265234728903
reward_mean: -118.10235760971055
reward_std: 10.282308513004379
reward_max: -106.81442577030809
reward_min: -135.34453781512607
queue_len: 0.07831721326903883
wait_time: 0.7524160747411255
delay_time: 4.947005329600311
pressure: 0.9461759504862952
total_envstep_count: 586032
total_train_sample_count: 586032
total_episode_count: 5052
total_duration: 33724.25129952975
[2024-12-26 10:57:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74434370055527
avg_train_sample_per_sec: 17.74434370055527
avg_episode_per_sec: 0.1529684801772006
collect_time: 39.22376683777942
reward_mean: -114.92028478057888
reward_std: 6.285006806649232
reward_max: -106.81442577030809
reward_min: -121.95238095238098
queue_len: 0.07620708539826186
wait_time: 0.7249930033905693
delay_time: 4.878558309500825
pressure: 0.9198717948717947
total_envstep_count: 586728
total_train_sample_count: 586728
total_episode_count: 5058
total_duration: 33763.47506636753
[2024-12-26 10:57:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.550513892848265
avg_train_sample_per_sec: 17.550513892848265
avg_episode_per_sec: 0.15129753355903677
collect_time: 39.656958437189466
reward_mean: -116.39659197012135
reward_std: 9.49083713334378
reward_max: -106.81442577030809
reward_min: -129.45658263305316
queue_len: 0.07718606894570383
wait_time: 0.7399943067412641
delay_time: 4.877128380960053
pressure: 0.9351237842617154
total_envstep_count: 587424
total_train_sample_count: 587424
total_episode_count: 5064
total_duration: 33803.13202480472
[2024-12-26 10:58:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56236508161139
avg_train_sample_per_sec: 17.56236508161139
avg_episode_per_sec: 0.15139969897940853
collect_time: 39.6301976849772
reward_mean: -117.63410364145655
reward_std: 11.400294897069553
reward_max: -106.81442577030809
reward_min: -134.28851540616247
queue_len: 0.07800670002749109
wait_time: 0.744640705530665
delay_time: 4.965004362925794
pressure: 0.9355658709106983
total_envstep_count: 588120
total_train_sample_count: 588120
total_episode_count: 5070
total_duration: 33842.7622224897
[2024-12-26 10:59:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.670498647219873
avg_train_sample_per_sec: 17.670498647219873
avg_episode_per_sec: 0.1523318848898265
collect_time: 39.387683047048746
reward_mean: -109.719304388422
reward_std: 5.316485539694537
reward_max: -106.81442577030809
reward_min: -121.51820728291317
queue_len: 0.0727581594087679
wait_time: 0.6909800392305462
delay_time: 4.63669182550256
pressure: 0.8817418213969938
total_envstep_count: 588816
total_train_sample_count: 588816
total_episode_count: 5076
total_duration: 33882.149905536746
[2024-12-26 10:59:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.097924443582382
avg_train_sample_per_sec: 18.097924443582382
avg_episode_per_sec: 0.1560165900308826
collect_time: 38.45744865217432
reward_mean: -108.84535480859007
reward_std: 3.0831478645043466
reward_max: -106.81442577030809
reward_min: -115.22759103641457
queue_len: 0.07217861724707565
wait_time: 0.6868528136276616
delay_time: 4.606663135803557
pressure: 0.8751105216622458
total_envstep_count: 589512
total_train_sample_count: 589512
total_episode_count: 5082
total_duration: 33920.60735418892
[2024-12-26 11:00:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.6659779136802
avg_train_sample_per_sec: 17.6659779136802
avg_episode_per_sec: 0.15229291304896728
collect_time: 39.397762376971535
reward_mean: -112.70226423902893
reward_std: 2.4938730972869125
reward_max: -109.77310924369745
reward_min: -117.5483193277311
queue_len: 0.07473624949537729
wait_time: 0.712537645473751
delay_time: 4.776919700093004
pressure: 0.9040671971706454
total_envstep_count: 590208
total_train_sample_count: 590208
total_episode_count: 5088
total_duration: 33960.005116565895
[2024-12-26 11:01:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.99251395894382
avg_train_sample_per_sec: 17.99251395894382
avg_episode_per_sec: 0.15510787895641226
collect_time: 38.68275448267908
reward_mean: -110.0954715219421
reward_std: 2.9952609386452345
reward_max: -106.81442577030809
reward_min: -116.09383753501399
queue_len: 0.07300760711004119
wait_time: 0.6933387634452542
delay_time: 4.6480199791472385
pressure: 0.8854995579133512
total_envstep_count: 590904
total_train_sample_count: 590904
total_episode_count: 5094
total_duration: 33998.687871048576
[2024-12-26 11:01:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.896250805748
avg_train_sample_per_sec: 17.896250805748
avg_episode_per_sec: 0.15427802418748277
collect_time: 38.89082733331249
reward_mean: -115.35445845004666
reward_std: 5.199238395525276
reward_max: -107.45658263305319
reward_min: -122.11484593837534
queue_len: 0.07649499897217948
wait_time: 0.727740101345578
delay_time: 4.86538868658949
pressure: 0.9184350132625995
total_envstep_count: 591600
total_train_sample_count: 591600
total_episode_count: 5100
total_duration: 34037.57869838189
[2024-12-26 11:02:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.786633733116854
avg_train_sample_per_sec: 17.786633733116854
avg_episode_per_sec: 0.15333304942342116
collect_time: 39.13050723612308
reward_mean: -109.27100840336131
reward_std: 4.441876327492465
reward_max: -106.81442577030809
reward_min: -119.09313725490195
queue_len: 0.07246088090408577
wait_time: 0.6891466024959939
delay_time: 4.59816286767309
pressure: 0.8768788682581787
total_envstep_count: 592296
total_train_sample_count: 592296
total_episode_count: 5106
total_duration: 34076.70920561801
[2024-12-26 11:03:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.706504288918115
avg_train_sample_per_sec: 17.706504288918115
avg_episode_per_sec: 0.15264227835274238
collect_time: 39.30758938316256
reward_mean: -110.5082866479925
reward_std: 5.938724164403092
reward_max: -106.81442577030809
reward_min: -123.01680672268907
queue_len: 0.07328135719362898
wait_time: 0.6975221786327263
delay_time: 4.626651404227853
pressure: 0.8867152961980548
total_envstep_count: 592992
total_train_sample_count: 592992
total_episode_count: 5112
total_duration: 34116.016795001175
[2024-12-26 11:03:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.883970221569232
avg_train_sample_per_sec: 17.883970221569232
avg_episode_per_sec: 0.15417215708249338
collect_time: 38.917532929046075
reward_mean: -115.52007469654528
reward_std: 7.319620085575001
reward_max: -106.81442577030809
reward_min: -125.99299719887958
queue_len: 0.07660482406932712
wait_time: 0.7305463299378109
delay_time: 4.883490126035078
pressure: 0.9228558797524314
total_envstep_count: 593688
total_train_sample_count: 593688
total_episode_count: 5118
total_duration: 34154.93432793022
[2024-12-26 11:04:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.859683997944842
avg_train_sample_per_sec: 17.859683997944842
avg_episode_per_sec: 0.1539627930857314
collect_time: 38.97045435294882
reward_mean: -112.53606442577029
reward_std: 7.944939098494964
reward_max: -106.81442577030809
reward_min: -125.09803921568626
queue_len: 0.07462603741761954
wait_time: 0.7114135441975199
delay_time: 4.762589384956828
pressure: 0.8989832007073386
total_envstep_count: 594384
total_train_sample_count: 594384
total_episode_count: 5124
total_duration: 34193.90478228317
[2024-12-26 11:05:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.953125003969692
avg_train_sample_per_sec: 17.953125003969692
avg_episode_per_sec: 0.15476831899973872
collect_time: 38.76762401231565
reward_mean: -106.81419234360408
reward_std: 0.17693759561865896
reward_max: -106.4600840336134
reward_min: -106.99089635854338
queue_len: 0.07083169253554647
wait_time: 0.6702737903295714
delay_time: 4.550289379415326
pressure: 0.8566534040671971
total_envstep_count: 595080
total_train_sample_count: 595080
total_episode_count: 5130
total_duration: 34232.67240629549
[2024-12-26 11:05:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.677198671954347
avg_train_sample_per_sec: 17.677198671954347
avg_episode_per_sec: 0.15238964372374436
collect_time: 39.3727542986907
reward_mean: -119.4940476190476
reward_std: 3.9364254130604555
reward_max: -114.51050420168066
reward_min: -125.4985994397759
queue_len: 0.07924008462801566
wait_time: 0.7597077181889557
delay_time: 5.013409955189808
pressure: 0.9564544650751546
total_envstep_count: 595776
total_train_sample_count: 595776
total_episode_count: 5136
total_duration: 34272.04516059418
[2024-12-26 11:06:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.550608282491368
avg_train_sample_per_sec: 17.550608282491368
avg_episode_per_sec: 0.15129834726285663
collect_time: 39.65674515648186
reward_mean: -120.36332866479925
reward_std: 3.7095108958705967
reward_max: -116.93347338935575
reward_min: -126.68767507002799
queue_len: 0.0798165309448271
wait_time: 0.7639991009666467
delay_time: 5.026182299309606
pressure: 0.9588859416445623
total_envstep_count: 596472
total_train_sample_count: 596472
total_episode_count: 5142
total_duration: 34311.70190575066
[2024-12-26 11:07:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.798481270824514
avg_train_sample_per_sec: 17.798481270824514
avg_episode_per_sec: 0.15343518336917683
collect_time: 39.10446006092057
reward_mean: -122.77602707749764
reward_std: 6.490537588438991
reward_max: -114.78361344537817
reward_min: -134.2913165266107
queue_len: 0.08141646357924248
wait_time: 0.7898260320927664
delay_time: 5.17643065494233
pressure: 0.9907161803713528
total_envstep_count: 597168
total_train_sample_count: 597168
total_episode_count: 5148
total_duration: 34350.806365811586
[2024-12-26 11:07:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.848496241795257
avg_train_sample_per_sec: 17.848496241795257
avg_episode_per_sec: 0.15386634691202808
collect_time: 38.99488172959909
reward_mean: -120.86157796451914
reward_std: 4.762651748866119
reward_max: -115.64495798319328
reward_min: -127.00140056022408
queue_len: 0.08014693498973417
wait_time: 0.7707046235824127
delay_time: 4.966995616566334
pressure: 0.9733642793987621
total_envstep_count: 597864
total_train_sample_count: 597864
total_episode_count: 5154
total_duration: 34389.80124754119
[2024-12-26 11:08:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.946043158952904
avg_train_sample_per_sec: 17.946043158952904
avg_episode_per_sec: 0.15470726861166298
collect_time: 38.78292244342342
reward_mean: -114.84267040149393
reward_std: 1.8453920825208447
reward_max: -112.5980392156863
reward_min: -117.49579831932775
queue_len: 0.076155616977118
wait_time: 0.7314972960890812
delay_time: 4.802658235268994
pressure: 0.914345711759505
total_envstep_count: 598560
total_train_sample_count: 598560
total_episode_count: 5160
total_duration: 34428.58416998461
[2024-12-26 11:09:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.777899681880932
avg_train_sample_per_sec: 17.777899681880932
avg_episode_per_sec: 0.15325775587828389
collect_time: 39.14973154614865
reward_mean: -117.20471521942112
reward_std: 5.200280138239582
reward_max: -113.64915966386556
reward_min: -128.08613445378154
queue_len: 0.07772195969457633
wait_time: 0.7418315358857956
delay_time: 4.883713210913927
pressure: 0.9395446507515474
total_envstep_count: 599256
total_train_sample_count: 599256
total_episode_count: 5166
total_duration: 34467.73390153076
[2024-12-26 11:09:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.560799900810714
avg_train_sample_per_sec: 17.560799900810714
avg_episode_per_sec: 0.15138620604147165
collect_time: 39.633729894494635
reward_mean: -117.4548319327731
reward_std: 5.209967879786888
reward_max: -106.81442577030809
reward_min: -122.2836134453782
queue_len: 0.07788781958406704
wait_time: 0.7457604726240629
delay_time: 4.960182474534239
pressure: 0.9347922192749779
total_envstep_count: 599952
total_train_sample_count: 599952
total_episode_count: 5172
total_duration: 34507.36763142525
[2024-12-26 11:10:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.909092231916514
avg_train_sample_per_sec: 17.909092231916514
avg_episode_per_sec: 0.15438872613721133
collect_time: 38.86294129188918
reward_mean: -114.16830065359476
reward_std: 6.000731861235496
reward_max: -106.81442577030809
reward_min: -122.89775910364148
queue_len: 0.0757084221840814
wait_time: 0.7257730789044176
delay_time: 4.7656921359275275
pressure: 0.9141246684350133
total_envstep_count: 600648
total_train_sample_count: 600648
total_episode_count: 5178
total_duration: 34546.23057271714
[2024-12-26 11:11:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.792158137937598
avg_train_sample_per_sec: 17.792158137937598
avg_episode_per_sec: 0.15338067360291033
collect_time: 39.11835734620318
reward_mean: -114.34500466853405
reward_std: 9.531110618208034
reward_max: -106.81442577030809
reward_min: -128.52521008403363
queue_len: 0.07582559991282099
wait_time: 0.7265105091550325
delay_time: 4.806540822899288
pressure: 0.9079354553492486
total_envstep_count: 601344
total_train_sample_count: 601344
total_episode_count: 5184
total_duration: 34585.348930063345
[2024-12-26 11:11:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.902320638485094
avg_train_sample_per_sec: 17.902320638485094
avg_episode_per_sec: 0.15433035033176803
collect_time: 38.877641287676994
reward_mean: -115.9109477124183
reward_std: 8.942478298418347
reward_max: -106.99089635854338
reward_min: -132.58053221288517
queue_len: 0.076864023681975
wait_time: 0.7423677362191561
delay_time: 4.835088304116755
pressure: 0.9236295313881521
total_envstep_count: 602040
total_train_sample_count: 602040
total_episode_count: 5190
total_duration: 34624.22657135102
[2024-12-26 11:12:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.534347938122718
avg_train_sample_per_sec: 17.534347938122718
avg_episode_per_sec: 0.15115817188036826
collect_time: 39.69352053786814
reward_mean: -114.01960784313724
reward_std: 7.179269602560451
reward_max: -106.81442577030809
reward_min: -126.8207282913165
queue_len: 0.07560981952462682
wait_time: 0.7210133721923784
delay_time: 4.8010791029490525
pressure: 0.9193191865605659
total_envstep_count: 602736
total_train_sample_count: 602736
total_episode_count: 5196
total_duration: 34663.92009188889
[2024-12-26 11:13:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.684106379789554
avg_train_sample_per_sec: 17.684106379789554
avg_episode_per_sec: 0.1524491929292203
collect_time: 39.35737464209275
reward_mean: -108.77649393090569
reward_std: 2.9800917040177946
reward_max: -106.81442577030809
reward_min: -114.58333333333333
queue_len: 0.07213295353508334
wait_time: 0.6858778546785645
delay_time: 4.618789031856039
pressure: 0.8725685234305923
total_envstep_count: 603432
total_train_sample_count: 603432
total_episode_count: 5202
total_duration: 34703.277466530984
[2024-12-26 11:13:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89660490136226
avg_train_sample_per_sec: 17.89660490136226
avg_episode_per_sec: 0.15428107673588154
collect_time: 38.89005785376765
reward_mean: -107.51552287581694
reward_std: 1.4901746013013069
reward_max: -106.81442577030809
reward_min: -110.844537815126
queue_len: 0.07129676583276987
wait_time: 0.6751151499503427
delay_time: 4.590597140633473
pressure: 0.8611847922192748
total_envstep_count: 604128
total_train_sample_count: 604128
total_episode_count: 5208
total_duration: 34742.16752438475
[2024-12-26 11:14:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.824209728775852
avg_train_sample_per_sec: 17.824209728775852
avg_episode_per_sec: 0.15365698042048148
collect_time: 39.04801450335047
reward_mean: -114.90604575163394
reward_std: 8.244019925707716
reward_max: -106.81442577030809
reward_min: -129.4201680672269
queue_len: 0.07619764307137532
wait_time: 0.7272669788516644
delay_time: 4.801493777892465
pressure: 0.9240716180371353
total_envstep_count: 604824
total_train_sample_count: 604824
total_episode_count: 5214
total_duration: 34781.2155388881
[2024-12-26 11:15:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.843994986686962
avg_train_sample_per_sec: 17.843994986686962
avg_episode_per_sec: 0.15382754298868068
collect_time: 39.0047184231598
reward_mean: -106.84383753501398
reward_std: 0.0657667052205805
reward_max: -106.81442577030809
reward_min: -106.99089635854338
queue_len: 0.07085135115053977
wait_time: 0.6694998291093626
delay_time: 4.548310282216636
pressure: 0.857316534040672
total_envstep_count: 605520
total_train_sample_count: 605520
total_episode_count: 5220
total_duration: 34820.22025731126
[2024-12-26 11:15:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.700920839293346
avg_train_sample_per_sec: 17.700920839293346
avg_episode_per_sec: 0.15259414516632194
collect_time: 39.31998828303814
reward_mean: -107.84628851540613
reward_std: 1.1510601252929107
reward_max: -106.81442577030809
reward_min: -109.49649859943976
queue_len: 0.07151610644257701
wait_time: 0.6772307729457832
delay_time: 4.60042801478566
pressure: 0.8630636604774536
total_envstep_count: 606216
total_train_sample_count: 606216
total_episode_count: 5226
total_duration: 34859.5402455943
[2024-12-26 11:16:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.81443014867242
avg_train_sample_per_sec: 17.81443014867242
avg_episode_per_sec: 0.1535726736954519
collect_time: 39.069450675180185
reward_mean: -113.11402894491128
reward_std: 9.297461882067621
reward_max: -106.81442577030809
reward_min: -131.94257703081234
queue_len: 0.0750093030138669
wait_time: 0.7112428857484637
delay_time: 4.789786434935261
pressure: 0.9074933687002652
total_envstep_count: 606912
total_train_sample_count: 606912
total_episode_count: 5232
total_duration: 34898.60969626948
[2024-12-26 11:17:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7182438657558
avg_train_sample_per_sec: 17.7182438657558
avg_episode_per_sec: 0.1527434816013431
collect_time: 39.281545353665955
reward_mean: -106.99778244631182
reward_std: 0.40999799167275114
reward_max: -106.81442577030809
reward_min: -107.91456582633049
queue_len: 0.0709534366354853
wait_time: 0.6711768482813106
delay_time: 4.550490399665419
pressure: 0.8587533156498672
total_envstep_count: 607608
total_train_sample_count: 607608
total_episode_count: 5238
total_duration: 34937.89124162315
[2024-12-26 11:17:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.92629357432233
avg_train_sample_per_sec: 17.92629357432233
avg_episode_per_sec: 0.15453701357174424
collect_time: 38.825649993646884
reward_mean: -106.81442577030809
reward_std: 0.0
reward_max: -106.81442577030809
reward_min: -106.81442577030809
queue_len: 0.0708318473277905
wait_time: 0.6694111331535266
delay_time: 4.545449964625422
pressure: 0.8574270557029177
total_envstep_count: 608304
total_train_sample_count: 608304
total_episode_count: 5244
total_duration: 34976.716891616794
[2024-12-26 11:18:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.00360721272579
avg_train_sample_per_sec: 18.00360721272579
avg_episode_per_sec: 0.15520351045453268
collect_time: 38.65891939188913
reward_mean: -107.28746498599435
reward_std: 1.0577478422976965
reward_max: -106.81442577030809
reward_min: -109.65266106442574
queue_len: 0.0711455338103411
wait_time: 0.6739406637986759
delay_time: 4.559775206251984
pressure: 0.8605216622458002
total_envstep_count: 609000
total_train_sample_count: 609000
total_episode_count: 5250
total_duration: 35015.375811008686
[2024-12-26 11:19:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84409467560866
avg_train_sample_per_sec: 17.84409467560866
avg_episode_per_sec: 0.15382840237593673
collect_time: 39.0045005169902
reward_mean: -113.75256769374414
reward_std: 7.486417246989049
reward_max: -106.81442577030809
reward_min: -123.94117647058826
queue_len: 0.07543273719744308
wait_time: 0.7234485637756429
delay_time: 4.772815068745694
pressure: 0.910919540229885
total_envstep_count: 609696
total_train_sample_count: 609696
total_episode_count: 5256
total_duration: 35054.380311525674
[2024-12-26 11:19:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.577294873634596
avg_train_sample_per_sec: 17.577294873634596
avg_episode_per_sec: 0.15152840408305684
collect_time: 39.59653661178426
reward_mean: -115.17740429505135
reward_std: 7.689695851312334
reward_max: -106.81442577030809
reward_min: -127.6120448179272
queue_len: 0.07637758905507384
wait_time: 0.7331613127125297
delay_time: 4.793694798227318
pressure: 0.9224137931034483
total_envstep_count: 610392
total_train_sample_count: 610392
total_episode_count: 5262
total_duration: 35093.976848137456
[2024-12-26 11:20:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8296334125426
avg_train_sample_per_sec: 17.8296334125426
avg_episode_per_sec: 0.1537037363150224
collect_time: 39.03613629601523
reward_mean: -111.72280578898226
reward_std: 7.570464841417887
reward_max: -106.81442577030809
reward_min: -126.7724089635854
queue_len: 0.07408674123937814
wait_time: 0.7038463705552954
delay_time: 4.682789642065619
pressure: 0.8986516357206012
total_envstep_count: 611088
total_train_sample_count: 611088
total_episode_count: 5268
total_duration: 35133.01298443347
[2024-12-26 11:21:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.78362524538593
avg_train_sample_per_sec: 17.78362524538593
avg_episode_per_sec: 0.15330711418436146
collect_time: 39.13712701410987
reward_mean: -113.44607843137253
reward_std: 8.958898687561438
reward_max: -106.81442577030809
reward_min: -131.7240896358543
queue_len: 0.07522949498101626
wait_time: 0.716720905868979
delay_time: 4.789213174908784
pressure: 0.9093722369584438
total_envstep_count: 611784
total_train_sample_count: 611784
total_episode_count: 5274
total_duration: 35172.15011144758
[2024-12-26 11:21:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.007164023458245
avg_train_sample_per_sec: 18.007164023458245
avg_episode_per_sec: 0.15523417261601935
collect_time: 38.65128340549954
reward_mean: -107.75011671335197
reward_std: 1.841769552373768
reward_max: -106.81442577030809
reward_min: -111.84033613445376
queue_len: 0.07145233203803182
wait_time: 0.6761450601460743
delay_time: 4.572325473951693
pressure: 0.8649425287356323
total_envstep_count: 612480
total_train_sample_count: 612480
total_episode_count: 5280
total_duration: 35210.801394853086
[2024-12-26 11:22:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.860495970437924
avg_train_sample_per_sec: 17.860495970437924
avg_episode_per_sec: 0.1539697928486028
collect_time: 38.96868268115259
reward_mean: -109.15674603174598
reward_std: 5.237587329650245
reward_max: -106.81442577030809
reward_min: -120.86834733893555
queue_len: 0.07238511010062731
wait_time: 0.6858992160082424
delay_time: 4.645597014126474
pressure: 0.8716843501326258
total_envstep_count: 613176
total_train_sample_count: 613176
total_episode_count: 5286
total_duration: 35249.77007753424
[2024-12-26 11:22:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.125426638690655
avg_train_sample_per_sec: 18.125426638690655
avg_episode_per_sec: 0.156253677919747
collect_time: 38.39909613571875
reward_mean: -110.83823529411764
reward_std: 4.549336282402972
reward_max: -106.78431372549016
reward_min: -118.78571428571429
queue_len: 0.07350015603058198
wait_time: 0.7001249328201661
delay_time: 4.645312527130867
pressure: 0.8909151193633952
total_envstep_count: 613872
total_train_sample_count: 613872
total_episode_count: 5292
total_duration: 35288.16917366996
[2024-12-26 11:23:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56960428577422
avg_train_sample_per_sec: 17.56960428577422
avg_episode_per_sec: 0.15146210591184672
collect_time: 39.61386885437928
reward_mean: -116.90091036414564
reward_std: 8.06017068879085
reward_max: -106.81442577030809
reward_min: -127.8648459383753
queue_len: 0.077520497588956
wait_time: 0.7412180168265362
delay_time: 4.976975019143947
pressure: 0.9279398762157381
total_envstep_count: 614568
total_train_sample_count: 614568
total_episode_count: 5298
total_duration: 35327.78304252434
[2024-12-26 11:24:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.751450192354188
avg_train_sample_per_sec: 17.751450192354188
avg_episode_per_sec: 0.15302974303753608
collect_time: 39.20806426844932
reward_mean: -115.77661064425769
reward_std: 4.27537655742951
reward_max: -106.53431372549016
reward_min: -118.83613445378148
queue_len: 0.07677494074552897
wait_time: 0.7350757057907159
delay_time: 4.894165831971231
pressure: 0.9272767462422635
total_envstep_count: 615264
total_train_sample_count: 615264
total_episode_count: 5304
total_duration: 35366.99110679279
[2024-12-26 11:24:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89205512244801
avg_train_sample_per_sec: 17.89205512244801
avg_episode_per_sec: 0.15424185450386216
collect_time: 38.899947224440055
reward_mean: -112.73062558356672
reward_std: 4.350629365327013
reward_max: -106.78851540616243
reward_min: -117.19677871148461
queue_len: 0.07475505675302835
wait_time: 0.712463964365587
delay_time: 4.712292803346455
pressure: 0.9034040671971706
total_envstep_count: 615960
total_train_sample_count: 615960
total_episode_count: 5310
total_duration: 35405.89105401723
[2024-12-26 11:25:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.691209994029713
avg_train_sample_per_sec: 17.691209994029713
avg_episode_per_sec: 0.15251043098301476
collect_time: 39.3415713359844
reward_mean: -109.58870214752564
reward_std: 2.58096994320782
reward_max: -106.53431372549016
reward_min: -113.46498599439774
queue_len: 0.07267155314822656
wait_time: 0.6937625072133186
delay_time: 4.6208153947620305
pressure: 0.8786472148541113
total_envstep_count: 616656
total_train_sample_count: 616656
total_episode_count: 5316
total_duration: 35445.232625353216
[2024-12-26 11:26:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.849278476561267
avg_train_sample_per_sec: 17.849278476561267
avg_episode_per_sec: 0.15387309031518334
collect_time: 38.99317280045524
reward_mean: -113.49661531279177
reward_std: 9.777474652861589
reward_max: -106.53431372549016
reward_min: -128.359243697479
queue_len: 0.0752630075018513
wait_time: 0.7222038019451813
delay_time: 4.793405868365253
pressure: 0.9113616268788682
total_envstep_count: 617352
total_train_sample_count: 617352
total_episode_count: 5322
total_duration: 35484.22579815367
[2024-12-26 11:26:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.714950092727527
avg_train_sample_per_sec: 17.714950092727527
avg_episode_per_sec: 0.1527150870062718
collect_time: 39.288849043143905
reward_mean: -115.84325396825396
reward_std: 5.658603315431064
reward_max: -106.53431372549016
reward_min: -123.20308123249296
queue_len: 0.07681913393120288
wait_time: 0.7398206298434492
delay_time: 4.879262774760443
pressure: 0.9271662245800177
total_envstep_count: 618048
total_train_sample_count: 618048
total_episode_count: 5328
total_duration: 35523.51464719681
[2024-12-26 11:27:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.953667598088128
avg_train_sample_per_sec: 17.953667598088128
avg_episode_per_sec: 0.15477299653524249
collect_time: 38.76645238068886
reward_mean: -106.58099906629315
reward_std: 0.10439159558822511
reward_max: -106.53431372549016
reward_min: -106.81442577030809
queue_len: 0.07067705508374877
wait_time: 0.6716316278943054
delay_time: 4.534947409809538
pressure: 0.8568744473916888
total_envstep_count: 618744
total_train_sample_count: 618744
total_episode_count: 5334
total_duration: 35562.2810995775
[2024-12-26 11:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.680909241613506
avg_train_sample_per_sec: 17.680909241613506
avg_episode_per_sec: 0.15242163139321988
collect_time: 39.36449141212181
reward_mean: -110.2829131652661
reward_std: 8.078488990455538
reward_max: -106.53431372549016
reward_min: -128.33823529411768
queue_len: 0.07313190528200669
wait_time: 0.698325937359913
delay_time: 4.648795095673487
pressure: 0.8871573828470379
total_envstep_count: 619440
total_train_sample_count: 619440
total_episode_count: 5340
total_duration: 35601.645590989625
[2024-12-26 11:28:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.852685040363586
avg_train_sample_per_sec: 17.852685040363586
avg_episode_per_sec: 0.15390245724451368
collect_time: 38.98573231009207
reward_mean: -107.44992997198877
reward_std: 1.8271971179274376
reward_max: -106.53431372549016
reward_min: -111.52801120448177
queue_len: 0.07125326921219413
wait_time: 0.6777415099549987
delay_time: 4.580519048786727
pressure: 0.8622900088417329
total_envstep_count: 620136
total_train_sample_count: 620136
total_episode_count: 5346
total_duration: 35640.63132329972
[2024-12-26 11:29:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.771439478974127
avg_train_sample_per_sec: 17.771439478974127
avg_episode_per_sec: 0.15320206447391488
collect_time: 39.16396310065127
reward_mean: -113.86963118580763
reward_std: 8.181675265033869
reward_max: -106.53431372549016
reward_min: -127.09243697478996
queue_len: 0.07551036550783
wait_time: 0.7168978334039187
delay_time: 4.854006436475546
pressure: 0.9073828470380194
total_envstep_count: 620832
total_train_sample_count: 620832
total_episode_count: 5352
total_duration: 35679.795286400375
[2024-12-26 11:30:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.163840417173027
avg_train_sample_per_sec: 17.163840417173027
avg_episode_per_sec: 0.14796414152735368
collect_time: 40.5503653659951
reward_mean: -113.66083099906626
reward_std: 7.420136065346642
reward_max: -106.53431372549016
reward_min: -123.61834733893554
queue_len: 0.07537190384553467
wait_time: 0.7220455268756486
delay_time: 4.8354972088434724
pressure: 0.9105879752431477
total_envstep_count: 621528
total_train_sample_count: 621528
total_episode_count: 5358
total_duration: 35720.34565176637
[2024-12-26 11:30:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18883694984266
avg_train_sample_per_sec: 17.18883694984266
avg_episode_per_sec: 0.14817962887795397
collect_time: 40.49139578384161
reward_mean: -106.53431372549016
reward_std: 0.0
reward_max: -106.53431372549016
reward_min: -106.53431372549016
queue_len: 0.07064609663494043
wait_time: 0.6720757268424612
delay_time: 4.532846898846361
pressure: 0.8567639257294429
total_envstep_count: 622224
total_train_sample_count: 622224
total_episode_count: 5364
total_duration: 35760.837047550216
[2024-12-26 11:31:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.935800557210424
avg_train_sample_per_sec: 16.935800557210424
avg_episode_per_sec: 0.1459982806656071
collect_time: 41.096374372670425
reward_mean: -107.70121381886086
reward_std: 2.4861029442862503
reward_max: -106.53431372549016
reward_min: -113.2556022408964
queue_len: 0.07141990306290508
wait_time: 0.6788113565496934
delay_time: 4.569600543166879
pressure: 0.867263483642794
total_envstep_count: 622920
total_train_sample_count: 622920
total_episode_count: 5370
total_duration: 35801.933421922884
[2024-12-26 11:32:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.827537343555537
avg_train_sample_per_sec: 16.827537343555537
avg_episode_per_sec: 0.14506497709961672
collect_time: 41.360775839641676
reward_mean: -109.52661064425769
reward_std: 3.953973570241739
reward_max: -105.94607843137253
reward_min: -116.15896358543415
queue_len: 0.07263037841131145
wait_time: 0.6891055051552007
delay_time: 4.649962571246246
pressure: 0.8787577365163571
total_envstep_count: 623616
total_train_sample_count: 623616
total_episode_count: 5376
total_duration: 35843.29419776252
[2024-12-26 11:33:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.758713853396902
avg_train_sample_per_sec: 16.758713853396902
avg_episode_per_sec: 0.1444716711499733
collect_time: 41.530633322373035
reward_mean: -112.24463118580765
reward_std: 9.346014883819581
reward_max: -105.94607843137253
reward_min: -131.44677871148463
queue_len: 0.07443277930093345
wait_time: 0.7145850824856911
delay_time: 4.795597680710584
pressure: 0.8908045977011495
total_envstep_count: 624312
total_train_sample_count: 624312
total_episode_count: 5382
total_duration: 35884.824831084894
[2024-12-26 11:33:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.610614226315562
avg_train_sample_per_sec: 16.610614226315562
avg_episode_per_sec: 0.1431949502268583
collect_time: 41.90091892552376
reward_mean: -107.69199346405226
reward_std: 2.4697062574340345
reward_max: -105.94607843137253
reward_min: -113.12184873949579
queue_len: 0.07141378876926542
wait_time: 0.6789908381566595
delay_time: 4.578900050821621
pressure: 0.8654951370468611
total_envstep_count: 625008
total_train_sample_count: 625008
total_episode_count: 5388
total_duration: 35926.72575001042
[2024-12-26 11:34:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.19780050340548
avg_train_sample_per_sec: 17.19780050340548
avg_episode_per_sec: 0.14825690089142657
collect_time: 40.47029152723217
reward_mean: -109.30823996265171
reward_std: 4.370120064546653
reward_max: -105.94607843137253
reward_min: -116.24649859943978
queue_len: 0.07248557026701041
wait_time: 0.690129455849537
delay_time: 4.650764686959273
pressure: 0.8800839964633068
total_envstep_count: 625704
total_train_sample_count: 625704
total_episode_count: 5394
total_duration: 35967.19604153765
[2024-12-26 11:35:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.178076651570308
avg_train_sample_per_sec: 17.178076651570308
avg_episode_per_sec: 0.14808686768595095
collect_time: 40.51675947879626
reward_mean: -105.94607843137253
reward_std: 0.0
reward_max: -105.94607843137253
reward_min: -105.94607843137253
queue_len: 0.07025602017995526
wait_time: 0.6692086648983199
delay_time: 4.533782694281361
pressure: 0.850132625994695
total_envstep_count: 626400
total_train_sample_count: 626400
total_episode_count: 5400
total_duration: 36007.712801016445
[2024-12-26 11:35:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.989795457672926
avg_train_sample_per_sec: 16.989795457672926
avg_episode_per_sec: 0.14646375394545624
collect_time: 40.96576687659137
reward_mean: -109.70564892623715
reward_std: 5.3195208157648075
reward_max: -105.94607843137253
reward_min: -117.51750700280117
queue_len: 0.07274910406249148
wait_time: 0.6914718141898667
delay_time: 4.684326081727082
pressure: 0.8785366931918656
total_envstep_count: 627096
total_train_sample_count: 627096
total_episode_count: 5406
total_duration: 36048.67856789304
[2024-12-26 11:36:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.967095424730925
avg_train_sample_per_sec: 16.967095424730925
avg_episode_per_sec: 0.14626806400630107
collect_time: 41.02057438691146
reward_mean: -114.19467787114843
reward_std: 10.925308292418256
reward_max: -105.94607843137253
reward_min: -130.8347338935574
queue_len: 0.07572591370765812
wait_time: 0.7290974745335802
delay_time: 4.835241909305181
pressure: 0.9182139699381078
total_envstep_count: 627792
total_train_sample_count: 627792
total_episode_count: 5412
total_duration: 36089.69914227995
[2024-12-26 11:37:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75944257631659
avg_train_sample_per_sec: 16.75944257631659
avg_episode_per_sec: 0.14447795324410853
collect_time: 41.528827515035864
reward_mean: -118.13328664799252
reward_std: 7.044107409445176
reward_max: -105.94607843137253
reward_min: -124.55602240896361
queue_len: 0.07833772324137436
wait_time: 0.7581799187402636
delay_time: 4.955719988942843
pressure: 0.9563439434129087
total_envstep_count: 628488
total_train_sample_count: 628488
total_episode_count: 5418
total_duration: 36131.227969794985
[2024-12-26 11:37:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.030159972471434
avg_train_sample_per_sec: 17.030159972471434
avg_episode_per_sec: 0.1468117239006158
collect_time: 40.86867070685513
reward_mean: -108.29995331465916
reward_std: 3.561305261055596
reward_max: -105.94607843137253
reward_min: -115.19957983193275
queue_len: 0.07181694516887213
wait_time: 0.6836583660873722
delay_time: 4.624645152022869
pressure: 0.8713527851458885
total_envstep_count: 629184
total_train_sample_count: 629184
total_episode_count: 5424
total_duration: 36172.09664050184
[2024-12-26 11:38:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.923149653819916
avg_train_sample_per_sec: 16.923149653819916
avg_episode_per_sec: 0.14588922115361996
collect_time: 41.12709597429448
reward_mean: -109.49544817927169
reward_std: 4.112548784198515
reward_max: -105.89985994397756
reward_min: -117.0462184873949
queue_len: 0.07260971364673188
wait_time: 0.6914736716967954
delay_time: 4.643692057700407
pressure: 0.8807471264367815
total_envstep_count: 629880
total_train_sample_count: 629880
total_episode_count: 5430
total_duration: 36213.22373647614
[2024-12-26 11:39:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.847175377033007
avg_train_sample_per_sec: 16.847175377033007
avg_episode_per_sec: 0.14523427049166385
collect_time: 41.31256334808655
reward_mean: -110.51622315592901
reward_std: 6.883660277513019
reward_max: -105.94607843137253
reward_min: -123.7598039215686
queue_len: 0.0732866201299264
wait_time: 0.6970388398507058
delay_time: 4.741884520519915
pressure: 0.8846153846153846
total_envstep_count: 630576
total_train_sample_count: 630576
total_episode_count: 5436
total_duration: 36254.53629982423
[2024-12-26 11:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.007298844144245
avg_train_sample_per_sec: 17.007298844144245
avg_episode_per_sec: 0.14661464520814005
collect_time: 40.92360617510044
reward_mean: -110.1800887021475
reward_std: 8.727488036406314
reward_max: -105.94607843137253
reward_min: -129.64565826330534
queue_len: 0.07306371929850632
wait_time: 0.6964410322042167
delay_time: 4.686448627308267
pressure: 0.8875994694960211
total_envstep_count: 631272
total_train_sample_count: 631272
total_episode_count: 5442
total_duration: 36295.45990599933
[2024-12-26 11:40:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.66886714411869
avg_train_sample_per_sec: 16.66886714411869
avg_episode_per_sec: 0.14369713055274733
collect_time: 41.75448721154221
reward_mean: -112.73459383753499
reward_std: 9.460117711001576
reward_max: -105.94607843137253
reward_min: -130.03851540616242
queue_len: 0.07475768822117705
wait_time: 0.7172870585015615
delay_time: 4.787749877363661
pressure: 0.9059460654288242
total_envstep_count: 631968
total_train_sample_count: 631968
total_episode_count: 5448
total_duration: 36337.21439321087
[2024-12-26 11:41:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.782221444480676
avg_train_sample_per_sec: 16.782221444480676
avg_episode_per_sec: 0.1446743227972472
collect_time: 41.472459549084306
reward_mean: -113.26178804855272
reward_std: 4.374029227031325
reward_max: -106.81442577030809
reward_min: -118.82212885154055
queue_len: 0.07510728650434531
wait_time: 0.7145825284136643
delay_time: 4.817347666386718
pressure: 0.9019672855879751
total_envstep_count: 632664
total_train_sample_count: 632664
total_episode_count: 5454
total_duration: 36378.68685275995
[2024-12-26 11:42:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.09863590555308
avg_train_sample_per_sec: 17.09863590555308
avg_episode_per_sec: 0.14740203366856103
collect_time: 40.70500148926862
reward_mean: -110.01867413632118
reward_std: 3.817907062095313
reward_max: -106.19607843137253
reward_min: -116.53431372549021
queue_len: 0.07295668046175145
wait_time: 0.695154863448474
delay_time: 4.669345074074141
pressure: 0.8840627763041556
total_envstep_count: 633360
total_train_sample_count: 633360
total_episode_count: 5460
total_duration: 36419.39185424922
[2024-12-26 11:42:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.69091775247016
avg_train_sample_per_sec: 16.69091775247016
avg_episode_per_sec: 0.1438872220040531
collect_time: 41.69932476582937
reward_mean: -118.49054621848738
reward_std: 6.82410159642332
reward_max: -105.94607843137253
reward_min: -127.91316526610642
queue_len: 0.07857463277088023
wait_time: 0.7579615842800426
delay_time: 4.890343571077326
pressure: 0.9586648983200708
total_envstep_count: 634056
total_train_sample_count: 634056
total_episode_count: 5466
total_duration: 36461.09117901505
[2024-12-26 11:43:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84874759002359
avg_train_sample_per_sec: 17.84874759002359
avg_episode_per_sec: 0.1538685137070999
collect_time: 38.99433259894512
reward_mean: -109.71802054154993
reward_std: 4.940010881260094
reward_max: -105.94607843137253
reward_min: -118.50070028011206
queue_len: 0.07275730805142569
wait_time: 0.6983057369720655
delay_time: 4.599570972711713
pressure: 0.8875994694960211
total_envstep_count: 634752
total_train_sample_count: 634752
total_episode_count: 5472
total_duration: 36500.085511613994
[2024-12-26 11:44:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.415667197678008
avg_train_sample_per_sec: 17.415667197678008
avg_episode_per_sec: 0.15013506204894836
collect_time: 39.964015854230155
reward_mean: -118.59477124183003
reward_std: 7.425940166446231
reward_max: -105.94607843137253
reward_min: -126.99649859943978
queue_len: 0.07864374750784486
wait_time: 0.7612426380808733
delay_time: 4.918195987812205
pressure: 0.9539124668435012
total_envstep_count: 635448
total_train_sample_count: 635448
total_episode_count: 5478
total_duration: 36540.049527468225
[2024-12-26 11:44:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.116028636121985
avg_train_sample_per_sec: 17.116028636121985
avg_episode_per_sec: 0.14755197100105158
collect_time: 40.66363844070398
reward_mean: -111.48541083099904
reward_std: 9.269186154356294
reward_max: -105.94607843137253
reward_min: -131.25700280112045
queue_len: 0.07392931752718769
wait_time: 0.7073100018079734
delay_time: 4.7069340966189275
pressure: 0.8967727674624225
total_envstep_count: 636144
total_train_sample_count: 636144
total_episode_count: 5484
total_duration: 36580.71316590893
[2024-12-26 11:45:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.49119150796261
avg_train_sample_per_sec: 17.49119150796261
avg_episode_per_sec: 0.15078613368933286
collect_time: 39.79145729913003
reward_mean: -116.15219421101773
reward_std: 7.745212880362975
reward_max: -105.24019607843134
reward_min: -123.96918767507002
queue_len: 0.07702400146619214
wait_time: 0.7452481876924067
delay_time: 4.900174269652081
pressure: 0.9290450928381961
total_envstep_count: 636840
total_train_sample_count: 636840
total_episode_count: 5490
total_duration: 36620.50462320806
[2024-12-26 11:46:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.019466597202236
avg_train_sample_per_sec: 17.019466597202236
avg_episode_per_sec: 0.14671953963105377
collect_time: 40.894348599292336
reward_mean: -110.60224089635852
reward_std: 6.620414525642978
reward_max: -105.94607843137253
reward_min: -121.10224089635855
queue_len: 0.0733436610718558
wait_time: 0.7041971297802941
delay_time: 4.632570060827587
pressure: 0.8894783377541997
total_envstep_count: 637536
total_train_sample_count: 637536
total_episode_count: 5496
total_duration: 36661.39897180735
[2024-12-26 11:46:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.006824972393495
avg_train_sample_per_sec: 17.006824972393495
avg_episode_per_sec: 0.14661056010684048
collect_time: 40.92474645501375
reward_mean: -113.74358076563958
reward_std: 6.864593010139515
reward_max: -105.94607843137253
reward_min: -125.5098039215686
queue_len: 0.07542677769604746
wait_time: 0.7266626699309255
delay_time: 4.838452268021527
pressure: 0.9062776304155614
total_envstep_count: 638232
total_train_sample_count: 638232
total_episode_count: 5502
total_duration: 36702.32371826236
[2024-12-26 11:47:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.866811043359718
avg_train_sample_per_sec: 16.866811043359718
avg_episode_per_sec: 0.14540354347723897
collect_time: 41.2644689153619
reward_mean: -115.10924369747899
reward_std: 8.308501339227535
reward_max: -105.94607843137253
reward_min: -131.00980392156868
queue_len: 0.07633238971981365
wait_time: 0.7307840908246588
delay_time: 4.8229540228174885
pressure: 0.9276083112290009
total_envstep_count: 638928
total_train_sample_count: 638928
total_episode_count: 5508
total_duration: 36743.588187177724
[2024-12-26 11:48:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.87387171799632
avg_train_sample_per_sec: 16.87387171799632
avg_episode_per_sec: 0.14546441136203725
collect_time: 41.247202280061316
reward_mean: -113.14670868347336
reward_std: 6.112049829191009
reward_max: -105.94607843137253
reward_min: -122.81652661064423
queue_len: 0.07503097392803272
wait_time: 0.7198275088107747
delay_time: 4.728635423313442
pressure: 0.9120247568523431
total_envstep_count: 639624
total_train_sample_count: 639624
total_episode_count: 5514
total_duration: 36784.83538945779
[2024-12-26 11:49:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8857929407879
avg_train_sample_per_sec: 16.8857929407879
avg_episode_per_sec: 0.14556718052403364
collect_time: 41.218082114391024
reward_mean: -114.08473389355743
reward_std: 8.834492100444633
reward_max: -105.24019607843134
reward_min: -127.42647058823535
queue_len: 0.07565300656071447
wait_time: 0.7285207960284025
delay_time: 4.7158981742425
pressure: 0.9217506631299734
total_envstep_count: 640320
total_train_sample_count: 640320
total_episode_count: 5520
total_duration: 36826.05347157218
[2024-12-26 11:49:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.94893774100584
avg_train_sample_per_sec: 16.94893774100584
avg_episode_per_sec: 0.14611153225005033
collect_time: 41.064520422192295
reward_mean: -109.37675070028007
reward_std: 5.981991243996686
reward_max: -105.94607843137253
reward_min: -122.55392156862746
queue_len: 0.07253100179063666
wait_time: 0.6926866237211065
delay_time: 4.601108332504892
pressure: 0.8786472148541113
total_envstep_count: 641016
total_train_sample_count: 641016
total_episode_count: 5526
total_duration: 36867.117991994375
[2024-12-26 11:50:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05592748023438
avg_train_sample_per_sec: 17.05592748023438
avg_episode_per_sec: 0.14703385758822743
collect_time: 40.80692772683128
reward_mean: -110.58730158730157
reward_std: 6.47213986526835
reward_max: -105.94607843137253
reward_min: -123.79411764705884
queue_len: 0.07333375436823711
wait_time: 0.6990236633999309
delay_time: 4.669828606092253
pressure: 0.8920203359858533
total_envstep_count: 641712
total_train_sample_count: 641712
total_episode_count: 5532
total_duration: 36907.924919721205
[2024-12-26 11:51:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.893112546281067
avg_train_sample_per_sec: 16.893112546281067
avg_episode_per_sec: 0.1456302805713885
collect_time: 41.20022275902145
reward_mean: -109.67903828197943
reward_std: 3.8784197818376787
reward_max: -105.94607843137253
reward_min: -115.20448179271708
queue_len: 0.07273145774667071
wait_time: 0.6892040304185333
delay_time: 4.614451140985513
pressure: 0.8785366931918656
total_envstep_count: 642408
total_train_sample_count: 642408
total_episode_count: 5538
total_duration: 36949.125142480225
[2024-12-26 11:51:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.114795170975146
avg_train_sample_per_sec: 17.114795170975146
avg_episode_per_sec: 0.14754133768082023
collect_time: 40.666569073542945
reward_mean: -110.0270774976657
reward_std: 4.34236947338078
reward_max: -105.94607843137253
reward_min: -116.90616246498594
queue_len: 0.07296225298253695
wait_time: 0.6981403414593069
delay_time: 4.681550368534287
pressure: 0.8825154730327144
total_envstep_count: 643104
total_train_sample_count: 643104
total_episode_count: 5544
total_duration: 36989.79171155377
[2024-12-26 11:52:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.72275250840426
avg_train_sample_per_sec: 16.72275250840426
avg_episode_per_sec: 0.14416165955520915
collect_time: 41.61994262907468
reward_mean: -107.88667133520072
reward_std: 3.9636635945752334
reward_max: -105.94607843137253
reward_min: -116.72128851540616
queue_len: 0.07154288550079624
wait_time: 0.6834513314609661
delay_time: 4.576462563504641
pressure: 0.8685897435897435
total_envstep_count: 643800
total_train_sample_count: 643800
total_episode_count: 5550
total_duration: 37031.41165418285
[2024-12-26 11:53:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.852094449421205
avg_train_sample_per_sec: 16.852094449421205
avg_episode_per_sec: 0.14527667628811383
collect_time: 41.300504343179995
reward_mean: -115.40464519140988
reward_std: 10.272955863678394
reward_max: -105.94607843137253
reward_min: -132.64285714285708
queue_len: 0.07652827930464846
wait_time: 0.739326455604346
delay_time: 4.865774981196112
pressure: 0.9226348364279398
total_envstep_count: 644496
total_train_sample_count: 644496
total_episode_count: 5556
total_duration: 37072.712158526025
[2024-12-26 11:53:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.745976612278593
avg_train_sample_per_sec: 17.745976612278593
avg_episode_per_sec: 0.15298255700240165
collect_time: 39.220157628204674
reward_mean: -113.16141456582632
reward_std: 6.157387916190241
reward_max: -105.94607843137253
reward_min: -122.88655462184873
queue_len: 0.07504072583940738
wait_time: 0.7243263131954816
delay_time: 4.765635709919805
pressure: 0.9104774535809018
total_envstep_count: 645192
total_train_sample_count: 645192
total_episode_count: 5562
total_duration: 37111.93231615423
[2024-12-26 11:54:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73879403249763
avg_train_sample_per_sec: 17.73879403249763
avg_episode_per_sec: 0.15292063821118645
collect_time: 39.2360381841585
reward_mean: -112.86076097105507
reward_std: 9.839019976450379
reward_max: -105.94607843137253
reward_min: -128.57212885154058
queue_len: 0.07484135342908162
wait_time: 0.7189932560115116
delay_time: 4.7733390370722875
pressure: 0.9073828470380194
total_envstep_count: 645888
total_train_sample_count: 645888
total_episode_count: 5568
total_duration: 37151.168354338384
[2024-12-26 11:55:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.046505795129185
avg_train_sample_per_sec: 18.046505795129185
avg_episode_per_sec: 0.15557332582007918
collect_time: 38.567022774450486
reward_mean: -107.86542950513535
reward_std: 4.291799473620928
reward_max: -105.94607843137253
reward_min: -117.46218487394958
queue_len: 0.07152879940658845
wait_time: 0.6844477291358629
delay_time: 4.575596296462289
pressure: 0.8667108753315649
total_envstep_count: 646584
total_train_sample_count: 646584
total_episode_count: 5574
total_duration: 37189.73537711283
[2024-12-26 11:55:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75453308023593
avg_train_sample_per_sec: 17.75453308023593
avg_episode_per_sec: 0.15305631965720629
collect_time: 39.20125620057992
reward_mean: -113.33846872082164
reward_std: 7.728315689936161
reward_max: -105.94607843137253
reward_min: -123.83193277310922
queue_len: 0.07515813575651302
wait_time: 0.7260799545282305
delay_time: 4.703240246238254
pressure: 0.9135720601237843
total_envstep_count: 647280
total_train_sample_count: 647280
total_episode_count: 5580
total_duration: 37228.93663331341
[2024-12-26 11:56:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.544642074843445
avg_train_sample_per_sec: 17.544642074843445
avg_episode_per_sec: 0.15124691443830557
collect_time: 39.67023077649252
reward_mean: -128.97070494864616
reward_std: 6.697166740914677
reward_max: -117.69257703081226
reward_min: -136.44677871148463
queue_len: 0.08552434015162212
wait_time: 0.8297052353213609
delay_time: 5.269852857186854
pressure: 1.0389036251105217
total_envstep_count: 647976
total_train_sample_count: 647976
total_episode_count: 5586
total_duration: 37268.6068640899
[2024-12-26 11:57:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52011780987058
avg_train_sample_per_sec: 17.52011780987058
avg_episode_per_sec: 0.15103549836095329
collect_time: 39.72576026902534
reward_mean: -117.36356209150325
reward_std: 6.642961987391681
reward_max: -106.62675070028008
reward_min: -125.97689075630255
queue_len: 0.07782729581664673
wait_time: 0.7486399953438494
delay_time: 4.937473809824053
pressure: 0.9370026525198939
total_envstep_count: 648672
total_train_sample_count: 648672
total_episode_count: 5592
total_duration: 37308.332624358925
[2024-12-26 11:57:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76907869957643
avg_train_sample_per_sec: 17.76907869957643
avg_episode_per_sec: 0.15318171292738303
collect_time: 39.16916637982986
reward_mean: -109.30847338935574
reward_std: 4.596209259537371
reward_max: -105.94607843137253
reward_min: -118.93767507002802
queue_len: 0.07248572505925446
wait_time: 0.691023690643366
delay_time: 4.601039655649951
pressure: 0.8773209549071618
total_envstep_count: 649368
total_train_sample_count: 649368
total_episode_count: 5598
total_duration: 37347.50179073875
[2024-12-26 11:58:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.93618643324507
avg_train_sample_per_sec: 17.93618643324507
avg_episode_per_sec: 0.15462229683831957
collect_time: 38.804235370231794
reward_mean: -111.02380952380952
reward_std: 5.305686706898784
reward_max: -105.24019607843134
reward_min: -118.86904761904763
queue_len: 0.07362321586459515
wait_time: 0.706662892831757
delay_time: 4.674812374030271
pressure: 0.8930150309460655
total_envstep_count: 650064
total_train_sample_count: 650064
total_episode_count: 5604
total_duration: 37386.306026108985
[2024-12-26 11:59:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89437310917102
avg_train_sample_per_sec: 17.89437310917102
avg_episode_per_sec: 0.15426183714802605
collect_time: 38.8949082347732
reward_mean: -106.4283380018674
reward_std: 0.8488587687201936
reward_max: -105.94607843137253
reward_min: -108.26820728291317
queue_len: 0.0705758209561455
wait_time: 0.6723053611364969
delay_time: 4.555530089697325
pressure: 0.8549955791335102
total_envstep_count: 650760
total_train_sample_count: 650760
total_episode_count: 5610
total_duration: 37425.20093434376
[2024-12-26 11:59:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.743581784659856
avg_train_sample_per_sec: 17.743581784659856
avg_episode_per_sec: 0.1529619119367229
collect_time: 39.225451120682074
reward_mean: -107.00245098039214
reward_std: 3.3241845687183376
reward_max: -105.24019607843134
reward_min: -114.40196078431373
queue_len: 0.07095653248036614
wait_time: 0.6747063436338282
delay_time: 4.622737403503366
pressure: 0.8576480990274092
total_envstep_count: 651456
total_train_sample_count: 651456
total_episode_count: 5616
total_duration: 37464.426385464445
[2024-12-26 12:00:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.672077710904418
avg_train_sample_per_sec: 17.672077710904418
avg_episode_per_sec: 0.1523454975077967
collect_time: 39.384163615947585
reward_mean: -109.90067693744162
reward_std: 6.544260429414586
reward_max: -105.24019607843134
reward_min: -122.484593837535
queue_len: 0.07287843298238833
wait_time: 0.697498495419388
delay_time: 4.704724981238411
pressure: 0.88052608311229
total_envstep_count: 652152
total_train_sample_count: 652152
total_episode_count: 5622
total_duration: 37503.810549080394
[2024-12-26 12:01:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.629489024670917
avg_train_sample_per_sec: 17.629489024670917
avg_episode_per_sec: 0.1519783536609562
collect_time: 39.47930646350608
reward_mean: -107.65721288515404
reward_std: 5.404613882591411
reward_max: -105.24019607843134
reward_min: -119.7422969187675
queue_len: 0.0713907247249032
wait_time: 0.6801585134495882
delay_time: 4.66413217115844
pressure: 0.860079575596817
total_envstep_count: 652848
total_train_sample_count: 652848
total_episode_count: 5628
total_duration: 37543.2898555439
[2024-12-26 12:01:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.908564745769315
avg_train_sample_per_sec: 17.908564745769315
avg_episode_per_sec: 0.15438417884283892
collect_time: 38.864085976762695
reward_mean: -105.67670401493928
reward_std: 0.617315443893018
reward_max: -105.24019607843134
reward_min: -106.54971988795515
queue_len: 0.07007738993033108
wait_time: 0.6669581404621971
delay_time: 4.551981739433655
pressure: 0.8459328028293545
total_envstep_count: 653544
total_train_sample_count: 653544
total_episode_count: 5634
total_duration: 37582.153941520664
[2024-12-26 12:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.916924894608634
avg_train_sample_per_sec: 17.916924894608634
avg_episode_per_sec: 0.15445624909145375
collect_time: 38.84595175199025
reward_mean: -105.28186274509801
reward_std: 0.09316949906249125
reward_max: -105.24019607843134
reward_min: -105.49019607843134
queue_len: 0.06981555884953448
wait_time: 0.6643519034492664
delay_time: 4.54631214967638
pressure: 0.8431697612732094
total_envstep_count: 654240
total_train_sample_count: 654240
total_episode_count: 5640
total_duration: 37620.99989327265
[2024-12-26 12:03:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.019510825712562
avg_train_sample_per_sec: 18.019510825712562
avg_episode_per_sec: 0.1553406105664876
collect_time: 38.624799903383476
reward_mean: -111.66946778711481
reward_std: 10.121236868170655
reward_max: -105.24019607843134
reward_min: -132.22899159663862
queue_len: 0.07405137121161459
wait_time: 0.7078177977645522
delay_time: 4.759648248379995
pressure: 0.8951149425287356
total_envstep_count: 654936
total_train_sample_count: 654936
total_episode_count: 5646
total_duration: 37659.62469317603
[2024-12-26 12:03:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89532248108742
avg_train_sample_per_sec: 17.89532248108742
avg_episode_per_sec: 0.15427002138868465
collect_time: 38.8928448054269
reward_mean: -105.82387955182071
reward_std: 1.022496075199964
reward_max: -105.24019607843134
reward_min: -108.0364145658263
queue_len: 0.0701749864401994
wait_time: 0.6673619934269021
delay_time: 4.55669936509975
pressure: 0.8468169761273209
total_envstep_count: 655632
total_train_sample_count: 655632
total_episode_count: 5652
total_duration: 37698.51753798146
[2024-12-26 12:04:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.253330478808973
avg_train_sample_per_sec: 18.253330478808973
avg_episode_per_sec: 0.15735629723111186
collect_time: 38.1300278767217
reward_mean: -107.37511671335199
reward_std: 4.773827666249562
reward_max: -105.24019607843134
reward_min: -118.04971988795518
queue_len: 0.07120365829797876
wait_time: 0.6773586313393615
delay_time: 4.608981785028511
pressure: 0.8582007073386383
total_envstep_count: 656328
total_train_sample_count: 656328
total_episode_count: 5658
total_duration: 37736.647565858184
[2024-12-26 12:05:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.883040492502154
avg_train_sample_per_sec: 17.883040492502154
avg_episode_per_sec: 0.1541641421767427
collect_time: 38.91955622936786
reward_mean: -110.1223155929038
reward_std: 5.472055869686
reward_max: -105.24019607843134
reward_min: -117.62324929971986
queue_len: 0.07302540821810595
wait_time: 0.6964733063870994
delay_time: 4.69661024711827
pressure: 0.8817418213969939
total_envstep_count: 657024
total_train_sample_count: 657024
total_episode_count: 5664
total_duration: 37775.56712208755
[2024-12-26 12:05:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.93146487138726
avg_train_sample_per_sec: 17.93146487138726
avg_episode_per_sec: 0.1545815937188557
collect_time: 38.814452973699204
reward_mean: -107.14355742296915
reward_std: 4.25604535213195
reward_max: -105.24019607843134
reward_min: -116.66036414565822
queue_len: 0.07105010439188934
wait_time: 0.6772700901757696
delay_time: 4.632581893566269
pressure: 0.8551061007957559
total_envstep_count: 657720
total_train_sample_count: 657720
total_episode_count: 5670
total_duration: 37814.38157506125
[2024-12-26 12:06:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.035480335165364
avg_train_sample_per_sec: 18.035480335165364
avg_episode_per_sec: 0.15547827875142556
collect_time: 38.59059958846494
reward_mean: -111.14157329598504
reward_std: 8.407352580962698
reward_max: -105.24019607843134
reward_min: -124.70308123249303
queue_len: 0.07370130855171422
wait_time: 0.7081536969341228
delay_time: 4.717048071191996
pressure: 0.8908045977011495
total_envstep_count: 658416
total_train_sample_count: 658416
total_episode_count: 5676
total_duration: 37852.972174649716
[2024-12-26 12:07:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.64874784982599
avg_train_sample_per_sec: 17.64874784982599
avg_episode_per_sec: 0.1521443780157413
collect_time: 39.43622550009191
reward_mean: -119.85924369747896
reward_std: 10.342385354943081
reward_max: -105.24019607843134
reward_min: -134.55742296918763
queue_len: 0.07948225709381894
wait_time: 0.768383900863617
delay_time: 5.070407304849744
pressure: 0.9504862953138815
total_envstep_count: 659112
total_train_sample_count: 659112
total_episode_count: 5682
total_duration: 37892.408400149805
[2024-12-26 12:07:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.854749698054764
avg_train_sample_per_sec: 17.854749698054764
avg_episode_per_sec: 0.15392025601771347
collect_time: 38.9812241431661
reward_mean: -108.63025210084032
reward_std: 7.01108397876761
reward_max: -105.24019607843134
reward_min: -124.27100840336139
queue_len: 0.07203597619419119
wait_time: 0.6884814602233466
delay_time: 4.640286641874584
pressure: 0.8681476569407603
total_envstep_count: 659808
total_train_sample_count: 659808
total_episode_count: 5688
total_duration: 37931.38962429297
[2024-12-26 12:08:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.907552111572606
avg_train_sample_per_sec: 17.907552111572606
avg_episode_per_sec: 0.1543754492376949
collect_time: 38.866283658625555
reward_mean: -109.26400560224086
reward_std: 7.77283913696972
reward_max: -105.24019607843134
reward_min: -126.48249299719885
queue_len: 0.0724562371367645
wait_time: 0.6912554146326965
delay_time: 4.6672818402469956
pressure: 0.8737842617152962
total_envstep_count: 660504
total_train_sample_count: 660504
total_episode_count: 5694
total_duration: 37970.25590795159
[2024-12-26 12:09:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.733962979540934
avg_train_sample_per_sec: 17.733962979540934
avg_episode_per_sec: 0.15287899120293907
collect_time: 39.2467267921418
reward_mean: -107.83076563958916
reward_std: 5.472250635026507
reward_max: -105.24019607843134
reward_min: -120.05252100840335
queue_len: 0.07150581275834823
wait_time: 0.6813621005431351
delay_time: 4.6151879328752825
pressure: 0.8672634836427938
total_envstep_count: 661200
total_train_sample_count: 661200
total_episode_count: 5700
total_duration: 38009.50263474373
[2024-12-26 12:09:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.746388014519
avg_train_sample_per_sec: 17.746388014519
avg_episode_per_sec: 0.15298610357343964
collect_time: 39.21924841441401
reward_mean: -117.56162464985994
reward_std: 8.959307981639531
reward_max: -105.24019607843134
reward_min: -131.59593837535016
queue_len: 0.07795863703571614
wait_time: 0.7428202713446121
delay_time: 4.947557349196916
pressure: 0.9441865605658708
total_envstep_count: 661896
total_train_sample_count: 661896
total_episode_count: 5706
total_duration: 38048.72188315814
[2024-12-26 12:10:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.561018523865176
avg_train_sample_per_sec: 17.561018523865176
avg_episode_per_sec: 0.15138809072297565
collect_time: 39.633236480796704
reward_mean: -110.96545284780579
reward_std: 7.456033514949731
reward_max: -105.24019607843134
reward_min: -126.53361344537818
queue_len: 0.07358451780358473
wait_time: 0.7007660048988648
delay_time: 4.734854334297539
pressure: 0.8888152077807251
total_envstep_count: 662592
total_train_sample_count: 662592
total_episode_count: 5712
total_duration: 38088.35511963894
[2024-12-26 12:11:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.67403979401731
avg_train_sample_per_sec: 17.67403979401731
avg_episode_per_sec: 0.1523624120173906
collect_time: 39.379791383948174
reward_mean: -107.95880018674133
reward_std: 3.7143577223958464
reward_max: -105.24019607843134
reward_min: -114.51470588235291
queue_len: 0.07159071630420512
wait_time: 0.6817987694635766
delay_time: 4.597322531191748
pressure: 0.8640583554376656
total_envstep_count: 663288
total_train_sample_count: 663288
total_episode_count: 5718
total_duration: 38127.73491102289
[2024-12-26 12:11:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.00815317087448
avg_train_sample_per_sec: 18.00815317087448
avg_episode_per_sec: 0.15524269974891794
collect_time: 38.64916037729382
reward_mean: -108.33286647992527
reward_std: 3.8715135443918727
reward_max: -105.24019607843134
reward_min: -114.8767507002801
queue_len: 0.07183877087528201
wait_time: 0.6850305993308021
delay_time: 4.64858542812334
pressure: 0.8705791335101679
total_envstep_count: 663984
total_train_sample_count: 663984
total_episode_count: 5724
total_duration: 38166.384071400185
[2024-12-26 12:12:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.931704575560847
avg_train_sample_per_sec: 17.931704575560847
avg_episode_per_sec: 0.15458366013414523
collect_time: 38.81393411692604
reward_mean: -105.35784313725487
reward_std: 0.26306682088233263
reward_max: -105.24019607843134
reward_min: -105.94607843137253
queue_len: 0.06986594372497007
wait_time: 0.6649004097660284
delay_time: 4.544205054289978
pressure: 0.8440539345711758
total_envstep_count: 664680
total_train_sample_count: 664680
total_episode_count: 5730
total_duration: 38205.19800551711
[2024-12-26 12:13:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85730797609933
avg_train_sample_per_sec: 17.85730797609933
avg_episode_per_sec: 0.15394231013878734
collect_time: 38.975639605451384
reward_mean: -115.50501867413631
reward_std: 8.303844849437821
reward_max: -105.24019607843134
reward_min: -127.41246498599445
queue_len: 0.07659483996958642
wait_time: 0.7325293733762294
delay_time: 4.871581617614603
pressure: 0.9286030061892131
total_envstep_count: 665376
total_train_sample_count: 665376
total_episode_count: 5736
total_duration: 38244.17364512256
[2024-12-26 12:13:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.02463058892685
avg_train_sample_per_sec: 18.02463058892685
avg_episode_per_sec: 0.15538474645626596
collect_time: 38.6138288141992
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 666072
total_train_sample_count: 666072
total_episode_count: 5742
total_duration: 38282.787473936754
[2024-12-26 12:14:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600472600925862
avg_train_sample_per_sec: 17.600472600925862
avg_episode_per_sec: 0.1517282120769471
collect_time: 39.544392686557025
reward_mean: -114.17098506069091
reward_std: 6.113243157449129
reward_max: -105.24019607843134
reward_min: -119.89845938375346
queue_len: 0.07571020229488788
wait_time: 0.7257011779070602
delay_time: 4.7951445363471725
pressure: 0.9103669319186561
total_envstep_count: 666768
total_train_sample_count: 666768
total_episode_count: 5748
total_duration: 38322.33186662331
[2024-12-26 12:15:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.833457427217652
avg_train_sample_per_sec: 17.833457427217652
avg_episode_per_sec: 0.15373670195877287
collect_time: 39.02776580708101
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 667464
total_train_sample_count: 667464
total_episode_count: 5754
total_duration: 38361.359632430394
[2024-12-26 12:15:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.228309031001242
avg_train_sample_per_sec: 18.228309031001242
avg_episode_per_sec: 0.1571405950948383
collect_time: 38.18236781131476
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 668160
total_train_sample_count: 668160
total_episode_count: 5760
total_duration: 38399.54200024171
[2024-12-26 12:16:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.851131363102844
avg_train_sample_per_sec: 17.851131363102844
avg_episode_per_sec: 0.15388906347502454
collect_time: 38.989125442132355
reward_mean: -106.37418300653592
reward_std: 2.5356718568380052
reward_max: -105.24019607843134
reward_min: -112.04411764705881
queue_len: 0.0705399091555278
wait_time: 0.6704868618534946
delay_time: 4.580232815894028
pressure: 0.8514588859416445
total_envstep_count: 668856
total_train_sample_count: 668856
total_episode_count: 5766
total_duration: 38438.53112568384
[2024-12-26 12:16:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.016809634276765
avg_train_sample_per_sec: 18.016809634276765
avg_episode_per_sec: 0.1553173244334204
collect_time: 38.63059077206812
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 669552
total_train_sample_count: 669552
total_episode_count: 5772
total_duration: 38477.16171645591
[2024-12-26 12:17:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.669379297737184
avg_train_sample_per_sec: 17.669379297737184
avg_episode_per_sec: 0.15232223532532055
collect_time: 39.39017824407294
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 670248
total_train_sample_count: 670248
total_episode_count: 5778
total_duration: 38516.55189469998
[2024-12-26 12:18:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.005065259753483
avg_train_sample_per_sec: 18.005065259753483
avg_episode_per_sec: 0.15521607982546104
collect_time: 38.6557887993753
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 670944
total_train_sample_count: 670944
total_episode_count: 5784
total_duration: 38555.20768349936
[2024-12-26 12:18:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.711278480528968
avg_train_sample_per_sec: 17.711278480528968
avg_episode_per_sec: 0.15268343517697386
collect_time: 39.29699376389757
reward_mean: -108.73225957049483
reward_std: 4.9442422664693755
reward_max: -105.24019607843134
reward_min: -116.1281512605042
queue_len: 0.07210362040483742
wait_time: 0.6880536918569371
delay_time: 4.655153149526045
pressure: 0.8736737400530504
total_envstep_count: 671640
total_train_sample_count: 671640
total_episode_count: 5790
total_duration: 38594.504677263256
[2024-12-26 12:19:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.648272918112088
avg_train_sample_per_sec: 17.648272918112088
avg_episode_per_sec: 0.15214028377682837
collect_time: 39.43728676621429
reward_mean: -108.53034547152193
reward_std: 6.224595294383281
reward_max: -105.24019607843134
reward_min: -122.38795518207287
queue_len: 0.07196972511374132
wait_time: 0.6873461365094223
delay_time: 4.590017127916679
pressure: 0.874336870026525
total_envstep_count: 672336
total_train_sample_count: 672336
total_episode_count: 5796
total_duration: 38633.94196402947
[2024-12-26 12:20:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.675309729318222
avg_train_sample_per_sec: 17.675309729318222
avg_episode_per_sec: 0.15237335973550192
collect_time: 39.376962025482214
reward_mean: -105.73377684407093
reward_std: 1.1036801443565156
reward_max: -105.24019607843134
reward_min: -108.20168067226888
queue_len: 0.07011523663399928
wait_time: 0.6676333442307071
delay_time: 4.568220359207186
pressure: 0.8457117595048628
total_envstep_count: 673032
total_train_sample_count: 673032
total_episode_count: 5802
total_duration: 38673.318926054955
[2024-12-26 12:20:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.669352921608773
avg_train_sample_per_sec: 17.669352921608773
avg_episode_per_sec: 0.15232200794490322
collect_time: 39.39023704421147
reward_mean: -110.30240429505132
reward_std: 8.223907670894699
reward_max: -105.24019607843134
reward_min: -127.43697478991595
queue_len: 0.07314483043438416
wait_time: 0.6965140941434044
delay_time: 4.696169617003892
pressure: 0.8820733863837312
total_envstep_count: 673728
total_train_sample_count: 673728
total_episode_count: 5808
total_duration: 38712.70916309916
[2024-12-26 12:21:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.703418242951592
avg_train_sample_per_sec: 17.703418242951592
avg_episode_per_sec: 0.15261567450820337
collect_time: 39.314441451277595
reward_mean: -113.39414098972922
reward_std: 8.598094211061149
reward_max: -105.24019607843134
reward_min: -127.37675070028013
queue_len: 0.07519505370671699
wait_time: 0.7193036918569374
delay_time: 4.774439681245664
pressure: 0.9072723253757736
total_envstep_count: 674424
total_train_sample_count: 674424
total_episode_count: 5814
total_duration: 38752.02360455044
[2024-12-26 12:22:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.784033796564888
avg_train_sample_per_sec: 17.784033796564888
avg_episode_per_sec: 0.15331063617728352
collect_time: 39.13622792003675
reward_mean: -114.53641456582632
reward_std: 9.749690846803892
reward_max: -105.24019607843134
reward_min: -129.33403361344543
queue_len: 0.07595252955293522
wait_time: 0.7305327856164571
delay_time: 4.868401090234543
pressure: 0.9177718832891246
total_envstep_count: 675120
total_train_sample_count: 675120
total_episode_count: 5820
total_duration: 38791.15983247048
[2024-12-26 12:22:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.772877556746536
avg_train_sample_per_sec: 17.772877556746536
avg_episode_per_sec: 0.15321446169609085
collect_time: 39.16079418078252
reward_mean: -105.57609710550885
reward_std: 0.5059883898459195
reward_max: -105.24019607843134
reward_min: -106.54971988795513
queue_len: 0.07001067447314908
wait_time: 0.6664787488823999
delay_time: 4.548089061216718
pressure: 0.8458222811671088
total_envstep_count: 675816
total_train_sample_count: 675816
total_episode_count: 5826
total_duration: 38830.320626651264
[2024-12-26 12:23:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94462278903037
avg_train_sample_per_sec: 17.94462278903037
avg_episode_per_sec: 0.15469502404336524
collect_time: 38.785992226343595
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 676512
total_train_sample_count: 676512
total_episode_count: 5832
total_duration: 38869.10661887761
[2024-12-26 12:24:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.930694971027563
avg_train_sample_per_sec: 17.930694971027563
avg_episode_per_sec: 0.15457495664678933
collect_time: 38.81611957175099
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 677208
total_train_sample_count: 677208
total_episode_count: 5838
total_duration: 38907.92273844936
[2024-12-26 12:24:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68045410089206
avg_train_sample_per_sec: 17.68045410089206
avg_episode_per_sec: 0.15241770776631086
collect_time: 39.36550475617499
reward_mean: -109.95996732026141
reward_std: 10.55372933498064
reward_max: -105.24019607843134
reward_min: -133.55882352941177
queue_len: 0.07291775021237494
wait_time: 0.6944609298184349
delay_time: 4.68498696530479
pressure: 0.8785366931918656
total_envstep_count: 677904
total_train_sample_count: 677904
total_episode_count: 5844
total_duration: 38947.288243205534
[2024-12-26 12:25:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83859757642869
avg_train_sample_per_sec: 17.83859757642869
avg_episode_per_sec: 0.1537810135899025
collect_time: 39.016520049741494
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 678600
total_train_sample_count: 678600
total_episode_count: 5850
total_duration: 38986.30476325528
[2024-12-26 12:26:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7251439799531
avg_train_sample_per_sec: 17.7251439799531
avg_episode_per_sec: 0.15280296534442325
collect_time: 39.26625367823058
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 679296
total_train_sample_count: 679296
total_episode_count: 5856
total_duration: 39025.57101693351
[2024-12-26 12:26:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.620790244397135
avg_train_sample_per_sec: 17.620790244397135
avg_episode_per_sec: 0.15190336417583736
collect_time: 39.49879604413919
reward_mean: -107.9095471521942
reward_std: 5.968850456745781
reward_max: -105.24019607843134
reward_min: -121.25630252100842
queue_len: 0.07155805514071233
wait_time: 0.6822284727330366
delay_time: 4.607596499779536
pressure: 0.8638373121131742
total_envstep_count: 679992
total_train_sample_count: 679992
total_episode_count: 5862
total_duration: 39065.06981297764
[2024-12-26 12:27:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84672500926082
avg_train_sample_per_sec: 17.84672500926082
avg_episode_per_sec: 0.15385107766604153
collect_time: 38.99875185160525
reward_mean: -107.24369747899156
reward_std: 4.479965324668693
reward_max: -105.24019607843134
reward_min: -117.26120448179267
queue_len: 0.07111651026458325
wait_time: 0.6769695610339626
delay_time: 4.599720223595191
pressure: 0.8615163572060123
total_envstep_count: 680688
total_train_sample_count: 680688
total_episode_count: 5868
total_duration: 39104.06856482925
[2024-12-26 12:28:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83987466509465
avg_train_sample_per_sec: 17.83987466509465
avg_episode_per_sec: 0.1537920229749539
collect_time: 39.01372700570524
reward_mean: -106.4911297852474
reward_std: 2.7971728037865042
reward_max: -105.24019607843134
reward_min: -112.7457983193277
queue_len: 0.0706174600697927
wait_time: 0.6722956866212444
delay_time: 4.564882385759339
pressure: 0.8546640141467727
total_envstep_count: 681384
total_train_sample_count: 681384
total_episode_count: 5874
total_duration: 39143.08229183495
[2024-12-26 12:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.796501841049775
avg_train_sample_per_sec: 17.796501841049775
avg_episode_per_sec: 0.15341811931939459
collect_time: 39.108809484940025
reward_mean: -109.53559757236225
reward_std: 6.513194862208528
reward_max: -105.24019607843134
reward_min: -122.19607843137251
queue_len: 0.07263633791270706
wait_time: 0.6938012052743289
delay_time: 4.679890129367617
pressure: 0.8729000884173298
total_envstep_count: 682080
total_train_sample_count: 682080
total_episode_count: 5880
total_duration: 39182.19110131989
[2024-12-26 12:29:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.835576837476008
avg_train_sample_per_sec: 17.835576837476008
avg_episode_per_sec: 0.15375497273686214
collect_time: 39.023128118714325
reward_mean: -106.83169934640519
reward_std: 3.5587094936025894
reward_max: -105.24019607843134
reward_min: -114.78921568627443
queue_len: 0.0708433019538496
wait_time: 0.6745595231903548
delay_time: 4.582738927700254
pressure: 0.857316534040672
total_envstep_count: 682776
total_train_sample_count: 682776
total_episode_count: 5886
total_duration: 39221.21422943861
[2024-12-26 12:30:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.805316541458275
avg_train_sample_per_sec: 17.805316541458275
avg_episode_per_sec: 0.1534941081160196
collect_time: 39.08944827683456
reward_mean: -107.59897292250231
reward_std: 3.6601968013385244
reward_max: -105.24019607843134
reward_min: -114.92577030812325
queue_len: 0.07135210406001478
wait_time: 0.6772895939985188
delay_time: 4.623875247207319
pressure: 0.8622900088417329
total_envstep_count: 683472
total_train_sample_count: 683472
total_episode_count: 5892
total_duration: 39260.30367771544
[2024-12-26 12:30:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.906618492207173
avg_train_sample_per_sec: 17.906618492207173
avg_episode_per_sec: 0.15436740079488942
collect_time: 38.86831007780135
reward_mean: -107.87208216619979
reward_std: 3.526111348004483
reward_max: -105.24019607843134
reward_min: -113.46708683473386
queue_len: 0.07153321098554362
wait_time: 0.6808724152791089
delay_time: 4.602811399795652
pressure: 0.8639478337754202
total_envstep_count: 684168
total_train_sample_count: 684168
total_episode_count: 5898
total_duration: 39299.17198779324
[2024-12-26 12:31:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82702790537632
avg_train_sample_per_sec: 17.82702790537632
avg_episode_per_sec: 0.15368127504634757
collect_time: 39.04184161792323
reward_mean: -112.06640989729222
reward_std: 9.734928308332723
reward_max: -105.24019607843134
reward_min: -127.8921568627451
queue_len: 0.07431459542260757
wait_time: 0.7100121326160879
delay_time: 4.740635765169118
pressure: 0.8964412024756854
total_envstep_count: 684864
total_train_sample_count: 684864
total_episode_count: 5904
total_duration: 39338.213829411165
[2024-12-26 12:32:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75080039563485
avg_train_sample_per_sec: 17.75080039563485
avg_episode_per_sec: 0.15302414134167974
collect_time: 39.20949954297021
reward_mean: -114.04318394024273
reward_std: 7.781380005976669
reward_max: -105.24019607843134
reward_min: -127.61414565826327
queue_len: 0.07562545354127502
wait_time: 0.7195045347935815
delay_time: 4.812576975884962
pressure: 0.9099248452696728
total_envstep_count: 685560
total_train_sample_count: 685560
total_episode_count: 5910
total_duration: 39377.42332895414
[2024-12-26 12:32:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.785679181707927
avg_train_sample_per_sec: 17.785679181707927
avg_episode_per_sec: 0.1533248205319649
collect_time: 39.132607357261705
reward_mean: -106.20506535947709
reward_std: 2.1575133018196526
reward_max: -105.24019607843134
reward_min: -111.02941176470586
queue_len: 0.07042776217471956
wait_time: 0.6699055395809959
delay_time: 4.545226312478977
pressure: 0.8516799292661362
total_envstep_count: 686256
total_train_sample_count: 686256
total_episode_count: 5916
total_duration: 39416.5559363114
[2024-12-26 12:33:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.79684519771162
avg_train_sample_per_sec: 17.79684519771162
avg_episode_per_sec: 0.1534210792906174
collect_time: 39.10805495400354
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 686952
total_train_sample_count: 686952
total_episode_count: 5922
total_duration: 39455.66399126541
[2024-12-26 12:34:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.947802295498537
avg_train_sample_per_sec: 17.947802295498537
avg_episode_per_sec: 0.15472243358188395
collect_time: 38.77912117265537
reward_mean: -105.35784313725487
reward_std: 0.2630668208823326
reward_max: -105.24019607843134
reward_min: -105.94607843137253
queue_len: 0.06986594372497007
wait_time: 0.6649004097660284
delay_time: 4.544205054289978
pressure: 0.8440539345711758
total_envstep_count: 687648
total_train_sample_count: 687648
total_episode_count: 5928
total_duration: 39494.443112438064
[2024-12-26 12:34:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.704774991391066
avg_train_sample_per_sec: 17.704774991391066
avg_episode_per_sec: 0.1526273706154402
collect_time: 39.31142871561087
reward_mean: -107.35399159663864
reward_std: 4.726590469245894
reward_max: -105.24019607843134
reward_min: -117.92296918767508
queue_len: 0.07118964959989298
wait_time: 0.6779137937226172
delay_time: 4.651221265359591
pressure: 0.8552166224580017
total_envstep_count: 688344
total_train_sample_count: 688344
total_episode_count: 5934
total_duration: 39533.75454115368
[2024-12-26 12:35:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74753133671289
avg_train_sample_per_sec: 17.74753133671289
avg_episode_per_sec: 0.15299595979924907
collect_time: 39.21672185247763
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 689040
total_train_sample_count: 689040
total_episode_count: 5940
total_duration: 39572.971263006155
[2024-12-26 12:36:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.87741804390717
avg_train_sample_per_sec: 17.87741804390717
avg_episode_per_sec: 0.1541156727923032
collect_time: 38.93179643115214
reward_mean: -106.79423436041083
reward_std: 3.4749352381430723
reward_max: -105.24019607843134
reward_min: -114.56442577030813
queue_len: 0.0708184577986809
wait_time: 0.6749858984265676
delay_time: 4.615428019150204
pressure: 0.8542219274977896
total_envstep_count: 689736
total_train_sample_count: 689736
total_episode_count: 5946
total_duration: 39611.9030594373
[2024-12-26 12:36:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.822326003990195
avg_train_sample_per_sec: 17.822326003990195
avg_episode_per_sec: 0.15364074141370856
collect_time: 39.05214167018235
reward_mean: -105.43557422969185
reward_std: 0.43687882753672275
reward_max: -105.24019607843134
reward_min: -106.41246498599436
queue_len: 0.06991748954223596
wait_time: 0.6654574296562125
delay_time: 4.546529589188311
pressure: 0.845048629531388
total_envstep_count: 690432
total_train_sample_count: 690432
total_episode_count: 5952
total_duration: 39650.955201107485
[2024-12-26 12:37:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.927491963657427
avg_train_sample_per_sec: 17.927491963657427
avg_episode_per_sec: 0.15454734451428814
collect_time: 38.82305463647284
reward_mean: -107.64274042950511
reward_std: 5.372252487959073
reward_max: -105.24019607843134
reward_min: -119.65546218487397
queue_len: 0.07138112760577262
wait_time: 0.6805375996552466
delay_time: 4.659267885266116
pressure: 0.8622900088417329
total_envstep_count: 691128
total_train_sample_count: 691128
total_episode_count: 5958
total_duration: 39689.77825574396
[2024-12-26 12:38:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.794199178943522
avg_train_sample_per_sec: 17.794199178943522
avg_episode_per_sec: 0.1533982687839959
collect_time: 39.1138703686986
reward_mean: -112.36111111111109
reward_std: 8.966377345042781
reward_max: -105.24019607843134
reward_min: -130.35854341736695
queue_len: 0.07451002063071027
wait_time: 0.7127144182164464
delay_time: 4.797324191599057
pressure: 0.9029619805481874
total_envstep_count: 691824
total_train_sample_count: 691824
total_episode_count: 5964
total_duration: 39728.89212611265
[2024-12-26 12:38:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.890962650197576
avg_train_sample_per_sec: 17.890962650197576
avg_episode_per_sec: 0.1542324366396343
collect_time: 38.90232256408594
reward_mean: -106.4766573295985
reward_std: 1.3664591304704667
reward_max: -105.24019607843134
reward_min: -108.29481792717087
queue_len: 0.07060786295066213
wait_time: 0.6718092519943432
delay_time: 4.577934914735802
pressure: 0.8532272325375775
total_envstep_count: 692520
total_train_sample_count: 692520
total_episode_count: 5970
total_duration: 39767.79444867674
[2024-12-26 12:39:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.6888514160211
avg_train_sample_per_sec: 17.6888514160211
avg_episode_per_sec: 0.152490098413975
collect_time: 39.34681702225282
reward_mean: -112.2223389355742
reward_std: 11.620101183269748
reward_max: -105.24019607843134
reward_min: -136.79691876750692
queue_len: 0.07441799664162745
wait_time: 0.7115880724526767
delay_time: 4.806162506226265
pressure: 0.8912466843501327
total_envstep_count: 693216
total_train_sample_count: 693216
total_episode_count: 5976
total_duration: 39807.14126569899
[2024-12-26 12:40:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.81175867739905
avg_train_sample_per_sec: 17.81175867739905
avg_episode_per_sec: 0.15354964377068148
collect_time: 39.075310451131315
reward_mean: -111.33356676003734
reward_std: 9.888451339134447
reward_max: -105.24019607843134
reward_min: -131.92086834733894
queue_len: 0.07382862517243854
wait_time: 0.7039872314973733
delay_time: 4.69969509186003
pressure: 0.8963306808134394
total_envstep_count: 693912
total_train_sample_count: 693912
total_episode_count: 5982
total_duration: 39846.216576150124
[2024-12-26 12:40:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.939056161093955
avg_train_sample_per_sec: 17.939056161093955
avg_episode_per_sec: 0.1546470358714996
collect_time: 38.798027819851406
reward_mean: -106.80625583566759
reward_std: 3.501816074007044
reward_max: -105.24019607843134
reward_min: -114.63655462184876
queue_len: 0.07082642959924905
wait_time: 0.6745263202540078
delay_time: 4.587855726251662
pressure: 0.8557692307692308
total_envstep_count: 694608
total_train_sample_count: 694608
total_episode_count: 5988
total_duration: 39885.014603969976
[2024-12-26 12:41:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.99335292785768
avg_train_sample_per_sec: 17.99335292785768
avg_episode_per_sec: 0.15511511144704895
collect_time: 38.68095083726383
reward_mean: -106.23436041083097
reward_std: 2.2230190280512687
reward_max: -105.24019607843134
reward_min: -111.20518207282912
queue_len: 0.07044718860134679
wait_time: 0.6699789885007936
delay_time: 4.583367567204313
pressure: 0.850132625994695
total_envstep_count: 695304
total_train_sample_count: 695304
total_episode_count: 5994
total_duration: 39923.69555480724
[2024-12-26 12:42:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.765458413494684
avg_train_sample_per_sec: 17.765458413494684
avg_episode_per_sec: 0.15315050356460935
collect_time: 39.17714836287685
reward_mean: -109.32563025210082
reward_std: 9.135308529925641
reward_max: -105.24019607843134
reward_min: -129.75280112044823
queue_len: 0.07249710228919153
wait_time: 0.6908542705322622
delay_time: 4.687108316882241
pressure: 0.873342175066313
total_envstep_count: 696000
total_train_sample_count: 696000
total_episode_count: 6000
total_duration: 39962.87270317011
[2024-12-26 12:42:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.703522306376048
avg_train_sample_per_sec: 17.703522306376048
avg_episode_per_sec: 0.15261657160669007
collect_time: 39.314210356282075
reward_mean: -105.35784313725487
reward_std: 0.2630668208823326
reward_max: -105.24019607843134
reward_min: -105.94607843137253
queue_len: 0.06986594372497007
wait_time: 0.6649004097660284
delay_time: 4.544205054289978
pressure: 0.8440539345711758
total_envstep_count: 696696
total_train_sample_count: 696696
total_episode_count: 6006
total_duration: 40002.18691352639
[2024-12-26 12:43:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.579608946888268
avg_train_sample_per_sec: 17.579608946888268
avg_episode_per_sec: 0.1515483529904161
collect_time: 39.59132436351479
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 697392
total_train_sample_count: 697392
total_episode_count: 6012
total_duration: 40041.77823788991
[2024-12-26 12:44:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.607212239515235
avg_train_sample_per_sec: 17.607212239515235
avg_episode_per_sec: 0.1517863124096141
collect_time: 39.52925599647127
reward_mean: -107.93405695611575
reward_std: 6.023656044429587
reward_max: -105.24019607843134
reward_min: -121.4033613445378
queue_len: 0.0715743083263367
wait_time: 0.6836344506856676
delay_time: 4.637244965466638
pressure: 0.8661582670203359
total_envstep_count: 698088
total_train_sample_count: 698088
total_episode_count: 6018
total_duration: 40081.30749388638
[2024-12-26 12:44:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.760595448760974
avg_train_sample_per_sec: 17.760595448760974
avg_episode_per_sec: 0.153108581454836
collect_time: 39.187875316903
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 698784
total_train_sample_count: 698784
total_episode_count: 6024
total_duration: 40120.49536920328
[2024-12-26 12:45:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.682935563285238
avg_train_sample_per_sec: 17.682935563285238
avg_episode_per_sec: 0.15243909968349342
collect_time: 39.35998055917211
reward_mean: -109.36496265172734
reward_std: 9.223258449208709
reward_max: -105.24019607843134
reward_min: -129.9887955182073
queue_len: 0.07252318478231255
wait_time: 0.6925294321972819
delay_time: 4.651724257324502
pressure: 0.8755526083112289
total_envstep_count: 699480
total_train_sample_count: 699480
total_episode_count: 6030
total_duration: 40159.85534976245
[2024-12-26 12:46:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.949643608931996
avg_train_sample_per_sec: 17.949643608931996
avg_episode_per_sec: 0.15473830697355168
collect_time: 38.7751431261655
reward_mean: -108.19432773109241
reward_std: 6.605639189833936
reward_max: -105.24019607843134
reward_min: -122.96498599439772
queue_len: 0.07174690167844323
wait_time: 0.6844193247590814
delay_time: 4.647419597332683
pressure: 0.8661582670203359
total_envstep_count: 700176
total_train_sample_count: 700176
total_episode_count: 6036
total_duration: 40198.63049288862
[2024-12-26 12:46:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.627600261352676
avg_train_sample_per_sec: 17.627600261352676
avg_episode_per_sec: 0.15196207121855754
collect_time: 39.48353659493477
reward_mean: -110.84150326797385
reward_std: 7.75236725919991
reward_max: -105.24019607843134
reward_min: -122.30812324929975
queue_len: 0.07350232312199857
wait_time: 0.7045672380357978
delay_time: 4.715552243137503
pressure: 0.886604774535809
total_envstep_count: 700872
total_train_sample_count: 700872
total_episode_count: 6042
total_duration: 40238.11402948355
[2024-12-26 12:47:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47963401752426
avg_train_sample_per_sec: 17.47963401752426
avg_episode_per_sec: 0.15068650015107118
collect_time: 39.817767311502244
reward_mean: -117.62301587301586
reward_std: 11.30939363665079
reward_max: -105.24019607843134
reward_min: -135.1995798319328
queue_len: 0.0779993473958991
wait_time: 0.7504050913026571
delay_time: 4.9523396121374965
pressure: 0.9372236958443855
total_envstep_count: 701568
total_train_sample_count: 701568
total_episode_count: 6048
total_duration: 40277.93179679505
[2024-12-26 12:48:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.793890704352297
avg_train_sample_per_sec: 17.793890704352297
avg_episode_per_sec: 0.15339560952027842
collect_time: 39.1145484461002
reward_mean: -105.35784313725487
reward_std: 0.2630668208823326
reward_max: -105.24019607843134
reward_min: -105.94607843137253
queue_len: 0.06986594372497007
wait_time: 0.6649004097660284
delay_time: 4.544205054289978
pressure: 0.8440539345711758
total_envstep_count: 702264
total_train_sample_count: 702264
total_episode_count: 6054
total_duration: 40317.04634524115
[2024-12-26 12:48:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.160226797821057
avg_train_sample_per_sec: 18.160226797821057
avg_episode_per_sec: 0.15655367929156086
collect_time: 38.32551254720613
reward_mean: -105.35784313725486
reward_std: 0.2630668208823326
reward_max: -105.24019607843134
reward_min: -105.94607843137253
queue_len: 0.06986594372497007
wait_time: 0.6649004097660284
delay_time: 4.544205054289978
pressure: 0.8440539345711758
total_envstep_count: 702960
total_train_sample_count: 702960
total_episode_count: 6060
total_duration: 40355.371857788356
[2024-12-26 12:49:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.998754827537176
avg_train_sample_per_sec: 17.998754827537176
avg_episode_per_sec: 0.1551616795477343
collect_time: 38.669341666633265
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 703656
total_train_sample_count: 703656
total_episode_count: 6066
total_duration: 40394.04119945499
[2024-12-26 12:50:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.967511451920537
avg_train_sample_per_sec: 17.967511451920537
avg_episode_per_sec: 0.15489234010276326
collect_time: 38.73658307453618
reward_mean: -111.23622782446311
reward_std: 8.487750104532276
reward_max: -105.24019607843134
reward_min: -126.4439775910364
queue_len: 0.07376407680667314
wait_time: 0.7047895196982417
delay_time: 4.741535243222116
pressure: 0.8859416445623342
total_envstep_count: 704352
total_train_sample_count: 704352
total_episode_count: 6072
total_duration: 40432.77778252952
[2024-12-26 12:50:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8597080798786
avg_train_sample_per_sec: 17.8597080798786
avg_episode_per_sec: 0.15396300068860863
collect_time: 38.97040180539899
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 705048
total_train_sample_count: 705048
total_episode_count: 6078
total_duration: 40471.748184334916
[2024-12-26 12:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.840237112614908
avg_train_sample_per_sec: 17.840237112614908
avg_episode_per_sec: 0.15379514752254234
collect_time: 39.01293439131789
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 705744
total_train_sample_count: 705744
total_episode_count: 6084
total_duration: 40510.76111872624
[2024-12-26 12:52:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.85675271214286
avg_train_sample_per_sec: 17.85675271214286
avg_episode_per_sec: 0.1539375233805419
collect_time: 38.976851570930336
reward_mean: -105.44129318394022
reward_std: 0.4496667979962741
reward_max: -105.24019607843134
reward_min: -106.44677871148454
queue_len: 0.06992128195221499
wait_time: 0.665414706996857
delay_time: 4.5446226415941355
pressure: 0.8447170645446507
total_envstep_count: 706440
total_train_sample_count: 706440
total_episode_count: 6090
total_duration: 40549.73797029717
[2024-12-26 12:52:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.864888548377333
avg_train_sample_per_sec: 17.864888548377333
avg_episode_per_sec: 0.1540076598998046
collect_time: 38.95910115057603
reward_mean: -108.3018207282913
reward_std: 6.846000838675831
reward_max: -105.24019607843134
reward_min: -123.60994397759102
queue_len: 0.07181818350682445
wait_time: 0.6846389749533763
delay_time: 4.631345272460764
pressure: 0.8684792219274976
total_envstep_count: 707136
total_train_sample_count: 707136
total_episode_count: 6096
total_duration: 40588.69707144774
[2024-12-26 12:53:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.01730066646065
avg_train_sample_per_sec: 18.01730066646065
avg_episode_per_sec: 0.15532155746948836
collect_time: 38.62953795823642
reward_mean: -108.59372082166198
reward_std: 7.49870929009121
reward_max: -105.24019607843134
reward_min: -125.3613445378151
queue_len: 0.07201175120799864
wait_time: 0.685427486644525
delay_time: 4.675261923603703
pressure: 0.868921308576481
total_envstep_count: 707832
total_train_sample_count: 707832
total_episode_count: 6102
total_duration: 40627.32660940598
[2024-12-26 12:54:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.121008509632222
avg_train_sample_per_sec: 18.121008509632222
avg_episode_per_sec: 0.15621559060027776
collect_time: 38.40845831676759
reward_mean: -106.23436041083097
reward_std: 2.2230190280512745
reward_max: -105.24019607843134
reward_min: -111.20518207282913
queue_len: 0.0704471886013468
wait_time: 0.6695976578075968
delay_time: 4.595275703102698
pressure: 0.8515694076038903
total_envstep_count: 708528
total_train_sample_count: 708528
total_episode_count: 6108
total_duration: 40665.735067722744
[2024-12-26 12:54:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.768665974831745
avg_train_sample_per_sec: 17.768665974831745
avg_episode_per_sec: 0.15317815495544607
collect_time: 39.17007618837804
reward_mean: -110.32457983193275
reward_std: 6.307200160927644
reward_max: -105.24019607843134
reward_min: -122.46218487394958
queue_len: 0.07315953569756814
wait_time: 0.696894960459869
delay_time: 4.689456444305946
pressure: 0.8820733863837312
total_envstep_count: 709224
total_train_sample_count: 709224
total_episode_count: 6114
total_duration: 40704.90514391112
[2024-12-26 12:55:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.943839900314572
avg_train_sample_per_sec: 17.943839900314572
avg_episode_per_sec: 0.15468827500271184
collect_time: 38.78768445698172
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 709920
total_train_sample_count: 709920
total_episode_count: 6120
total_duration: 40743.692828368105
[2024-12-26 12:56:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.822832992355078
avg_train_sample_per_sec: 17.822832992355078
avg_episode_per_sec: 0.153645112003061
collect_time: 39.05103079283423
reward_mean: -108.90838001867411
reward_std: 5.917251343031065
reward_max: -105.24019607843134
reward_min: -121.86274509803924
queue_len: 0.07222041115296692
wait_time: 0.6909551176792554
delay_time: 4.657397303822878
pressure: 0.8717948717948717
total_envstep_count: 710616
total_train_sample_count: 710616
total_episode_count: 6126
total_duration: 40782.74385916094
[2024-12-26 12:56:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.72151912146931
avg_train_sample_per_sec: 17.72151912146931
avg_episode_per_sec: 0.15277171656439062
collect_time: 39.27428541703336
reward_mean: -115.44852941176471
reward_std: 2.8177734075635383
reward_max: -111.95168067226895
reward_min: -119.48809523809526
queue_len: 0.0765573802465283
wait_time: 0.7194892103614213
delay_time: 5.0040755767796385
pressure: 0.920313881520778
total_envstep_count: 711312
total_train_sample_count: 711312
total_episode_count: 6132
total_duration: 40822.018144577974
[2024-12-26 12:57:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73002736797361
avg_train_sample_per_sec: 17.73002736797361
avg_episode_per_sec: 0.15284506351701388
collect_time: 39.255438559401775
reward_mean: -116.47957516339869
reward_std: 6.01426047467369
reward_max: -110.99929971988796
reward_min: -127.88305322128853
queue_len: 0.07724109758846068
wait_time: 0.7379320096738962
delay_time: 4.891045320162271
pressure: 0.9377763041556145
total_envstep_count: 712008
total_train_sample_count: 712008
total_episode_count: 6138
total_duration: 40861.27358313738
[2024-12-26 12:58:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.854702677755057
avg_train_sample_per_sec: 17.854702677755057
avg_episode_per_sec: 0.15391985067030223
collect_time: 38.981326800089334
reward_mean: -116.32749766573295
reward_std: 3.5873074047374853
reward_max: -112.20868347338936
reward_min: -121.11764705882348
queue_len: 0.07714025044146748
wait_time: 0.7359672317202742
delay_time: 4.9399440555012015
pressure: 0.9278293545534925
total_envstep_count: 712704
total_train_sample_count: 712704
total_episode_count: 6144
total_duration: 40900.25490993747
[2024-12-26 12:58:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.536044738705282
avg_train_sample_per_sec: 17.536044738705282
avg_episode_per_sec: 0.15117279947159726
collect_time: 39.689679763635624
reward_mean: -115.51178804855277
reward_std: 1.6278945420064206
reward_max: -113.22689075630254
reward_min: -118.46078431372551
queue_len: 0.07659932894466363
wait_time: 0.7353496880626699
delay_time: 4.944544562747915
pressure: 0.9244031830238727
total_envstep_count: 713400
total_train_sample_count: 713400
total_episode_count: 6150
total_duration: 40939.9445897011
[2024-12-26 12:59:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56100613941656
avg_train_sample_per_sec: 17.56100613941656
avg_episode_per_sec: 0.15138798396048758
collect_time: 39.63326443111896
reward_mean: -118.6516106442577
reward_std: 7.065637767706008
reward_max: -112.50210084033614
reward_min: -132.93417366946778
queue_len: 0.07868143941926904
wait_time: 0.7486207237094661
delay_time: 4.9392139666933845
pressure: 0.9564544650751547
total_envstep_count: 714096
total_train_sample_count: 714096
total_episode_count: 6156
total_duration: 40979.57785413222
[2024-12-26 13:00:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84978134293886
avg_train_sample_per_sec: 17.84978134293886
avg_episode_per_sec: 0.15387742537016258
collect_time: 38.99207427968458
reward_mean: -117.95226423902896
reward_std: 7.39381537970237
reward_max: -112.58823529411761
reward_min: -133.61484593837537
queue_len: 0.07821768185611999
wait_time: 0.7481250015479225
delay_time: 4.955147082919624
pressure: 0.9439655172413793
total_envstep_count: 714792
total_train_sample_count: 714792
total_episode_count: 6162
total_duration: 41018.569928411904
[2024-12-26 13:00:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89397973439387
avg_train_sample_per_sec: 17.89397973439387
avg_episode_per_sec: 0.15425844598615404
collect_time: 38.8957632863652
reward_mean: -111.39367413632118
reward_std: 3.532132208017847
reward_max: -106.4320728291316
reward_min: -114.67016806722688
queue_len: 0.07386848417527929
wait_time: 0.7010043849546891
delay_time: 4.6808173174204315
pressure: 0.8951149425287358
total_envstep_count: 715488
total_train_sample_count: 715488
total_episode_count: 6168
total_duration: 41057.46569169827
[2024-12-26 13:01:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83122062812072
avg_train_sample_per_sec: 17.83122062812072
avg_episode_per_sec: 0.15371741920793727
collect_time: 39.0326615611706
reward_mean: -108.93930905695608
reward_std: 0.4435778734385475
reward_max: -108.32492997198874
reward_min: -109.39495798319325
queue_len: 0.07224092112530243
wait_time: 0.688007873352701
delay_time: 4.622270138527114
pressure: 0.8759946949602121
total_envstep_count: 716184
total_train_sample_count: 716184
total_episode_count: 6174
total_duration: 41096.49835325944
[2024-12-26 13:02:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.022337150805352
avg_train_sample_per_sec: 18.022337150805352
avg_episode_per_sec: 0.15536497543797717
collect_time: 38.61874262899905
reward_mean: -109.94012605042015
reward_std: 6.185152125343472
reward_max: -105.24019607843134
reward_min: -123.16596638655467
queue_len: 0.0729045928716314
wait_time: 0.6950639230050996
delay_time: 4.6561427742072725
pressure: 0.8852785145888594
total_envstep_count: 716880
total_train_sample_count: 716880
total_episode_count: 6180
total_duration: 41135.11709588844
[2024-12-26 13:02:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.032447033895007
avg_train_sample_per_sec: 18.032447033895007
avg_episode_per_sec: 0.15545212960254318
collect_time: 38.59709104880504
reward_mean: -108.88001867413631
reward_std: 5.2001014031141
reward_max: -105.24019607843134
reward_min: -117.437675070028
queue_len: 0.07220160389531585
wait_time: 0.6851770327936656
delay_time: 4.689467100888204
pressure: 0.8670424403183024
total_envstep_count: 717576
total_train_sample_count: 717576
total_episode_count: 6186
total_duration: 41173.71418693724
[2024-12-26 13:03:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.045590765268283
avg_train_sample_per_sec: 18.045590765268283
avg_episode_per_sec: 0.15556543763162314
collect_time: 38.568978375568996
reward_mean: -107.45273109243693
reward_std: 4.947378693914972
reward_max: -105.24019607843134
reward_min: -118.51540616246494
queue_len: 0.07125512671912264
wait_time: 0.6794813747780278
delay_time: 4.573935995979831
pressure: 0.8621794871794872
total_envstep_count: 718272
total_train_sample_count: 718272
total_episode_count: 6192
total_duration: 41212.28316531281
[2024-12-26 13:03:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.933965908025215
avg_train_sample_per_sec: 17.933965908025215
avg_episode_per_sec: 0.1546031543795277
collect_time: 38.80903998420947
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 718968
total_train_sample_count: 718968
total_episode_count: 6198
total_duration: 41251.09220529702
[2024-12-26 13:04:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.93060926033757
avg_train_sample_per_sec: 17.93060926033757
avg_episode_per_sec: 0.15457421776153077
collect_time: 38.81630511794984
reward_mean: -113.61076097105507
reward_std: 8.727260681805207
reward_max: -105.24019607843134
reward_min: -127.66806722689074
queue_len: 0.07533870090918772
wait_time: 0.7181948376167444
delay_time: 4.829204356771863
pressure: 0.9089301503094607
total_envstep_count: 719664
total_train_sample_count: 719664
total_episode_count: 6204
total_duration: 41289.90851041497
[2024-12-26 13:05:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.733353866616167
avg_train_sample_per_sec: 17.733353866616167
avg_episode_per_sec: 0.15287374022944972
collect_time: 39.24807485572434
reward_mean: -109.36099439775906
reward_std: 5.665132955717912
reward_max: -105.24019607843134
reward_min: -120.13725490196079
queue_len: 0.07252055331416384
wait_time: 0.6961945255555803
delay_time: 4.673976942406584
pressure: 0.8746684350132626
total_envstep_count: 720360
total_train_sample_count: 720360
total_episode_count: 6210
total_duration: 41329.15658527069
[2024-12-26 13:05:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7513687974028
avg_train_sample_per_sec: 17.7513687974028
avg_episode_per_sec: 0.1530290413569207
collect_time: 39.208244048303
reward_mean: -108.51809056956114
reward_std: 4.940985689811716
reward_max: -105.24019607843134
reward_min: -118.03571428571426
queue_len: 0.07196159852092913
wait_time: 0.6827464075816002
delay_time: 4.662538764520636
pressure: 0.8691423519009726
total_envstep_count: 721056
total_train_sample_count: 721056
total_episode_count: 6216
total_duration: 41368.364829319
[2024-12-26 13:06:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68672980757926
avg_train_sample_per_sec: 17.68672980757926
avg_episode_per_sec: 0.15247180868602808
collect_time: 39.35153686249815
reward_mean: -114.7755602240896
reward_std: 10.369355511267008
reward_max: -105.24019607843134
reward_min: -131.1701680672269
queue_len: 0.07611111420695599
wait_time: 0.7333944298320564
delay_time: 4.810275766952334
pressure: 0.9147877984084881
total_envstep_count: 721752
total_train_sample_count: 721752
total_episode_count: 6222
total_duration: 41407.7163661815
[2024-12-26 13:07:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73943707230888
avg_train_sample_per_sec: 17.73943707230888
avg_episode_per_sec: 0.15292618165783517
collect_time: 39.23461591047049
reward_mean: -112.19992997198881
reward_std: 7.360519745566902
reward_max: -105.24019607843134
reward_min: -123.46358543417372
queue_len: 0.07440313658619947
wait_time: 0.7129195953359239
delay_time: 4.772322483582973
pressure: 0.8961096374889479
total_envstep_count: 722448
total_train_sample_count: 722448
total_episode_count: 6228
total_duration: 41446.95098209197
[2024-12-26 13:07:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.928963660661257
avg_train_sample_per_sec: 17.928963660661257
avg_episode_per_sec: 0.15456003155742462
collect_time: 38.81986785031668
reward_mean: -106.01774042950511
reward_std: 0.7622502823783474
reward_max: -105.24019607843134
reward_min: -107.52450980392155
queue_len: 0.07030354139887605
wait_time: 0.6701696151493312
delay_time: 4.560296159561133
pressure: 0.84736958443855
total_envstep_count: 723144
total_train_sample_count: 723144
total_episode_count: 6234
total_duration: 41485.77084994229
[2024-12-26 13:08:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.755861035050824
avg_train_sample_per_sec: 17.755861035050824
avg_episode_per_sec: 0.15306776754354157
collect_time: 39.1983243519459
reward_mean: -107.41083099906628
reward_std: 4.8536872368745625
reward_max: -105.24019607843134
reward_min: -118.26400560224091
queue_len: 0.07122734151131714
wait_time: 0.6782650947204699
delay_time: 4.6104739755225905
pressure: 0.8615163572060123
total_envstep_count: 723840
total_train_sample_count: 723840
total_episode_count: 6240
total_duration: 41524.96917429423
[2024-12-26 13:09:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.94697265605297
avg_train_sample_per_sec: 17.94697265605297
avg_episode_per_sec: 0.154715281517698
collect_time: 38.780913825333116
reward_mean: -113.4813258636788
reward_std: 8.365532712972
reward_max: -105.24019607843134
reward_min: -124.35924369747902
queue_len: 0.07525286860986656
wait_time: 0.7200241723568296
delay_time: 4.803263647767552
pressure: 0.9047303271441202
total_envstep_count: 724536
total_train_sample_count: 724536
total_episode_count: 6246
total_duration: 41563.75008811957
[2024-12-26 13:09:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.9345732664785
avg_train_sample_per_sec: 17.9345732664785
avg_episode_per_sec: 0.15460839022826292
collect_time: 38.80772570713423
reward_mean: -106.5690943043884
reward_std: 2.97150676841886
reward_max: -105.24019607843134
reward_min: -113.2135854341737
queue_len: 0.07066916067930265
wait_time: 0.673232489282185
delay_time: 4.589606430052101
pressure: 0.8519009725906277
total_envstep_count: 725232
total_train_sample_count: 725232
total_episode_count: 6252
total_duration: 41602.5578138267
[2024-12-26 13:10:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74274439410475
avg_train_sample_per_sec: 17.74274439410475
avg_episode_per_sec: 0.15295469305262716
collect_time: 39.22730241389572
reward_mean: -122.91643323996266
reward_std: 9.626829255989415
reward_max: -105.49019607843134
reward_min: -135.2871148459384
queue_len: 0.08150957111403359
wait_time: 0.8026282020323602
delay_time: 5.000164861447931
pressure: 0.9883952254641911
total_envstep_count: 725928
total_train_sample_count: 725928
total_episode_count: 6258
total_duration: 41641.78511624059
[2024-12-26 13:11:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.5043530363105
avg_train_sample_per_sec: 17.5043530363105
avg_episode_per_sec: 0.15089959514060777
collect_time: 39.76153809033894
reward_mean: -116.4316059757236
reward_std: 7.230554690860059
reward_max: -105.24019607843134
reward_min: -123.67296918767511
queue_len: 0.07720928778231008
wait_time: 0.7422209157756825
delay_time: 4.859142562703525
pressure: 0.9326923076923076
total_envstep_count: 726624
total_train_sample_count: 726624
total_episode_count: 6264
total_duration: 41681.54665433093
[2024-12-26 13:11:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89290301592996
avg_train_sample_per_sec: 17.89290301592996
avg_episode_per_sec: 0.1542491639304307
collect_time: 38.89810386723467
reward_mean: -107.13515406162463
reward_std: 2.511599212689655
reward_max: -105.24019607843134
reward_min: -111.62464985994397
queue_len: 0.07104453187110386
wait_time: 0.6772890522256647
delay_time: 4.571644038630814
pressure: 0.8568744473916888
total_envstep_count: 727320
total_train_sample_count: 727320
total_episode_count: 6270
total_duration: 41720.444758198166
[2024-12-26 13:12:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.7561482212997
avg_train_sample_per_sec: 17.7561482212997
avg_episode_per_sec: 0.15307024328706637
collect_time: 39.19769036198408
reward_mean: -112.62511671335199
reward_std: 7.087966828337512
reward_max: -105.24019607843134
reward_min: -123.45028011204481
queue_len: 0.07468509065872148
wait_time: 0.7122884299608437
delay_time: 4.738474609140407
pressure: 0.8937886825817861
total_envstep_count: 728016
total_train_sample_count: 728016
total_episode_count: 6276
total_duration: 41759.64244856015
[2024-12-26 13:13:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.000847355811423
avg_train_sample_per_sec: 18.000847355811423
avg_episode_per_sec: 0.15517971858458124
collect_time: 38.66484650653416
reward_mean: -105.28921568627447
reward_std: 0.10961117536763768
reward_max: -105.24019607843134
reward_min: -105.53431372549016
queue_len: 0.06982043480522179
wait_time: 0.6643833262748069
delay_time: 4.5467514934426125
pressure: 0.8430592396109636
total_envstep_count: 728712
total_train_sample_count: 728712
total_episode_count: 6282
total_duration: 41798.30729506669
[2024-12-26 13:13:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.014615302633583
avg_train_sample_per_sec: 18.014615302633583
avg_episode_per_sec: 0.155298407781324
collect_time: 38.63529630289972
reward_mean: -107.0016339869281
reward_std: 3.9386949015437764
reward_max: -105.24019607843134
reward_min: -115.80882352941181
queue_len: 0.07095599070751199
wait_time: 0.6749729732741901
delay_time: 4.62401353333505
pressure: 0.8574270557029178
total_envstep_count: 729408
total_train_sample_count: 729408
total_episode_count: 6288
total_duration: 41836.94259136959
[2024-12-26 13:14:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.659978110584394
avg_train_sample_per_sec: 17.659978110584394
avg_episode_per_sec: 0.15224119060848615
collect_time: 39.41114737751894
reward_mean: -110.06314192343602
reward_std: 7.958051393028001
reward_max: -105.24019607843134
reward_min: -126.8102240896358
queue_len: 0.07298616838424138
wait_time: 0.69728372118078
delay_time: 4.674281338109375
pressure: 0.8874889478337753
total_envstep_count: 730104
total_train_sample_count: 730104
total_episode_count: 6294
total_duration: 41876.35373874711
[2024-12-26 13:15:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.593197766433146
avg_train_sample_per_sec: 17.593197766433146
avg_episode_per_sec: 0.15166549798649265
collect_time: 39.56074439906142
reward_mean: -108.67471988795513
reward_std: 7.317111603439421
reward_max: -105.24019607843134
reward_min: -125.02240896358545
queue_len: 0.07206546411668113
wait_time: 0.6893721347955627
delay_time: 4.613622571513381
pressure: 0.8695844385499557
total_envstep_count: 730800
total_train_sample_count: 730800
total_episode_count: 6300
total_duration: 41915.91448314617
[2024-12-26 13:15:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.784538730789905
avg_train_sample_per_sec: 17.784538730789905
avg_episode_per_sec: 0.15331498905853366
collect_time: 39.13511677393316
reward_mean: -105.4863445378151
reward_std: 0.5504046877389146
reward_max: -105.24019607843134
reward_min: -106.71708683473385
queue_len: 0.06995115685531504
wait_time: 0.6658499053909803
delay_time: 4.547783950702198
pressure: 0.8450486295313882
total_envstep_count: 731496
total_train_sample_count: 731496
total_episode_count: 6306
total_duration: 41955.0495999201
[2024-12-26 13:16:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.782530400007232
avg_train_sample_per_sec: 17.782530400007232
avg_episode_per_sec: 0.15329767586213133
collect_time: 39.13953663195857
reward_mean: -109.60562558356675
reward_std: 9.101416524211798
reward_max: -105.24019607843134
reward_min: -129.91946778711494
queue_len: 0.0726827755859196
wait_time: 0.6971625188536953
delay_time: 4.668505105539204
pressure: 0.8741158267020337
total_envstep_count: 732192
total_train_sample_count: 732192
total_episode_count: 6312
total_duration: 41994.18913655206
[2024-12-26 13:17:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8029523335764
avg_train_sample_per_sec: 17.8029523335764
avg_episode_per_sec: 0.15347372701358966
collect_time: 39.09463930245675
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 732888
total_train_sample_count: 732888
total_episode_count: 6318
total_duration: 42033.283775854514
[2024-12-26 13:17:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.837997715816133
avg_train_sample_per_sec: 17.837997715816133
avg_episode_per_sec: 0.15377584237772526
collect_time: 39.01783210695721
reward_mean: -105.43837535014002
reward_std: 0.4431423232720136
reward_max: -105.24019607843134
reward_min: -106.42927170868343
queue_len: 0.06991934704916447
wait_time: 0.6653928038943251
delay_time: 4.549948797187503
pressure: 0.8444960212201592
total_envstep_count: 733584
total_train_sample_count: 733584
total_episode_count: 6324
total_duration: 42072.30160796147
[2024-12-26 13:18:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8723808143568
avg_train_sample_per_sec: 17.8723808143568
avg_episode_per_sec: 0.15407224839962758
collect_time: 38.94276913800463
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 734280
total_train_sample_count: 734280
total_episode_count: 6330
total_duration: 42111.24437709947
[2024-12-26 13:19:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82551863449867
avg_train_sample_per_sec: 17.82551863449867
avg_episode_per_sec: 0.1536682640905058
collect_time: 39.04514725608007
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 734976
total_train_sample_count: 734976
total_episode_count: 6336
total_duration: 42150.289524355554
[2024-12-26 13:19:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.908610005886416
avg_train_sample_per_sec: 17.908610005886416
avg_episode_per_sec: 0.1543845690162622
collect_time: 38.863987756237385
reward_mean: -108.38702147525674
reward_std: 7.036515500624332
reward_max: -105.24019607843134
reward_min: -124.1211484593837
queue_len: 0.07187468267589968
wait_time: 0.6859187972271136
delay_time: 4.610537353517318
pressure: 0.8700265251989389
total_envstep_count: 735672
total_train_sample_count: 735672
total_episode_count: 6342
total_duration: 42189.15351211179
[2024-12-26 13:20:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.806093417987775
avg_train_sample_per_sec: 17.806093417987775
avg_episode_per_sec: 0.1535008053274808
collect_time: 39.08774281150848
reward_mean: -109.94992997198877
reward_std: 4.738659102016011
reward_max: -105.24019607843134
reward_min: -115.34173669467785
queue_len: 0.07291109414588115
wait_time: 0.6951731289332708
delay_time: 4.68900634399026
pressure: 0.8782051282051282
total_envstep_count: 736368
total_train_sample_count: 736368
total_episode_count: 6348
total_duration: 42228.2412549233
[2024-12-26 13:21:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.923631325476318
avg_train_sample_per_sec: 17.923631325476318
avg_episode_per_sec: 0.1545140631506579
collect_time: 38.831416879832744
reward_mean: -107.82574696545282
reward_std: 5.7814675426649
reward_max: -105.24019607843134
reward_min: -120.7535014005602
queue_len: 0.07150248472510133
wait_time: 0.6843997435402099
delay_time: 4.611305270661028
pressure: 0.8669319186560566
total_envstep_count: 737064
total_train_sample_count: 737064
total_episode_count: 6354
total_duration: 42267.07267180313
[2024-12-26 13:21:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.803195373150558
avg_train_sample_per_sec: 17.803195373150558
avg_episode_per_sec: 0.1534758221823324
collect_time: 39.09410560362972
reward_mean: -107.08601774042945
reward_std: 2.98668207380593
reward_max: -105.24019607843134
reward_min: -113.2913165266106
queue_len: 0.07101194810373307
wait_time: 0.6774813815888866
delay_time: 4.577479580512442
pressure: 0.8580901856763927
total_envstep_count: 737760
total_train_sample_count: 737760
total_episode_count: 6360
total_duration: 42306.16677740676
[2024-12-26 13:22:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.898751519109858
avg_train_sample_per_sec: 17.898751519109858
avg_episode_per_sec: 0.15429958206129188
collect_time: 38.88539372463524
reward_mean: -107.14063958916898
reward_std: 2.453609914550451
reward_max: -105.24019607843134
reward_min: -111.73389355742297
queue_len: 0.07104816948883885
wait_time: 0.6773632751066828
delay_time: 4.616821683359325
pressure: 0.8608532272325374
total_envstep_count: 738456
total_train_sample_count: 738456
total_episode_count: 6366
total_duration: 42345.0521711314
[2024-12-26 13:23:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.375333345434388
avg_train_sample_per_sec: 18.375333345434388
avg_episode_per_sec: 0.15840804608133094
collect_time: 37.87686388682201
reward_mean: -106.81570961718019
reward_std: 3.522955372113653
reward_max: -105.24019607843134
reward_min: -114.69327731092437
queue_len: 0.07083269868513274
wait_time: 0.6736186185349471
delay_time: 4.5696338913606604
pressure: 0.8549955791335102
total_envstep_count: 739152
total_train_sample_count: 739152
total_episode_count: 6372
total_duration: 42382.92903501822
[2024-12-26 13:23:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.971660154272342
avg_train_sample_per_sec: 17.971660154272342
avg_episode_per_sec: 0.15492810477820984
collect_time: 38.72764085373283
reward_mean: -106.46895424836599
reward_std: 2.397663613129206
reward_max: -105.24019607843134
reward_min: -111.78781512605042
queue_len: 0.07060275480660873
wait_time: 0.6725638641840467
delay_time: 4.588953505651048
pressure: 0.8525641025641025
total_envstep_count: 739848
total_train_sample_count: 739848
total_episode_count: 6378
total_duration: 42421.65667587196
[2024-12-26 13:24:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.743190221312293
avg_train_sample_per_sec: 17.743190221312293
avg_episode_per_sec: 0.15295853639062323
collect_time: 39.226316762585185
reward_mean: -112.58274976657329
reward_std: 9.430853793097164
reward_max: -105.24019607843134
reward_min: -131.69957983193274
queue_len: 0.0746569958664279
wait_time: 0.7145689840923106
delay_time: 4.7075535896561815
pressure: 0.9018567639257293
total_envstep_count: 740544
total_train_sample_count: 740544
total_episode_count: 6384
total_duration: 42460.88299263454
[2024-12-26 13:25:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.689722141348003
avg_train_sample_per_sec: 17.689722141348003
avg_episode_per_sec: 0.15249760466679313
collect_time: 39.344880289169026
reward_mean: -107.66386554621846
reward_std: 5.419489684962724
reward_max: -105.24019607843134
reward_min: -119.78221288515402
queue_len: 0.07139513630385838
wait_time: 0.680542553007056
delay_time: 4.6389554906864285
pressure: 0.8647214854111405
total_envstep_count: 741240
total_train_sample_count: 741240
total_episode_count: 6390
total_duration: 42500.227872923715
[2024-12-26 13:25:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.17545198806165
avg_train_sample_per_sec: 18.17545198806165
avg_episode_per_sec: 0.15668493093156596
collect_time: 38.293408079048604
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 741936
total_train_sample_count: 741936
total_episode_count: 6396
total_duration: 42538.521281002766
[2024-12-26 13:26:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.87293876155211
avg_train_sample_per_sec: 17.87293876155211
avg_episode_per_sec: 0.15407705828924234
collect_time: 38.941553444877265
reward_mean: -106.5395658263305
reward_std: 2.905479084209294
reward_max: -105.24019607843134
reward_min: -113.03641456582632
queue_len: 0.07064957946043136
wait_time: 0.6726671880069445
delay_time: 4.565098752259321
pressure: 0.8538903625110521
total_envstep_count: 742632
total_train_sample_count: 742632
total_episode_count: 6402
total_duration: 42577.462834447644
[2024-12-26 13:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.014372641741627
avg_train_sample_per_sec: 18.014372641741627
avg_episode_per_sec: 0.155296315877083
collect_time: 38.63581673598103
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 743328
total_train_sample_count: 743328
total_episode_count: 6408
total_duration: 42616.09865118362
[2024-12-26 13:27:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.839728152788535
avg_train_sample_per_sec: 17.839728152788535
avg_episode_per_sec: 0.1537907599378322
collect_time: 39.014047413676984
reward_mean: -107.15884687208215
reward_std: 4.29023359968709
reward_max: -105.24019607843134
reward_min: -116.75210084033608
queue_len: 0.07106024328387409
wait_time: 0.6721579215240472
delay_time: 4.6533969399110955
pressure: 0.8530061892130858
total_envstep_count: 744024
total_train_sample_count: 744024
total_episode_count: 6414
total_duration: 42655.1126985973
[2024-12-26 13:28:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88620148612842
avg_train_sample_per_sec: 17.88620148612842
avg_episode_per_sec: 0.15419139212179672
collect_time: 38.91267805183679
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 744720
total_train_sample_count: 744720
total_episode_count: 6420
total_duration: 42694.02537664914
[2024-12-26 13:29:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.907338547084084
avg_train_sample_per_sec: 17.907338547084084
avg_episode_per_sec: 0.15437360816451795
collect_time: 38.86674718132987
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 745416
total_train_sample_count: 745416
total_episode_count: 6426
total_duration: 42732.89212383047
[2024-12-26 13:29:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.834533683842643
avg_train_sample_per_sec: 17.834533683842643
avg_episode_per_sec: 0.15374598003312623
collect_time: 39.0254106072057
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 746112
total_train_sample_count: 746112
total_episode_count: 6432
total_duration: 42771.91753443767
[2024-12-26 13:30:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.797902036256364
avg_train_sample_per_sec: 17.797902036256364
avg_episode_per_sec: 0.15343018996772728
collect_time: 39.105732719630005
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 746808
total_train_sample_count: 746808
total_episode_count: 6438
total_duration: 42811.0232671573
[2024-12-26 13:31:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.81176658908504
avg_train_sample_per_sec: 17.81176658908504
avg_episode_per_sec: 0.15354971197487102
collect_time: 39.075293094538154
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 747504
total_train_sample_count: 747504
total_episode_count: 6444
total_duration: 42850.09856025184
[2024-12-26 13:31:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74349537551585
avg_train_sample_per_sec: 17.74349537551585
avg_episode_per_sec: 0.15296116703030904
collect_time: 39.225642144918446
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 748200
total_train_sample_count: 748200
total_episode_count: 6450
total_duration: 42889.32420239676
[2024-12-26 13:32:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.023601625245732
avg_train_sample_per_sec: 18.023601625245732
avg_episode_per_sec: 0.15537587607970457
collect_time: 38.6160332696829
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 748896
total_train_sample_count: 748896
total_episode_count: 6456
total_duration: 42927.94023566644
[2024-12-26 13:33:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.756460308168016
avg_train_sample_per_sec: 17.756460308168016
avg_episode_per_sec: 0.15307293369110359
collect_time: 39.197001424875104
reward_mean: -108.12581699346403
reward_std: 6.4524445233082375
reward_max: -105.24019607843134
reward_min: -122.55392156862747
queue_len: 0.071701470154817
wait_time: 0.6831659719590754
delay_time: 4.6425689875112
pressure: 0.8648320070733863
total_envstep_count: 749592
total_train_sample_count: 749592
total_episode_count: 6462
total_duration: 42967.137237091316
[2024-12-26 13:33:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.83138619413857
avg_train_sample_per_sec: 17.83138619413857
avg_episode_per_sec: 0.15371884650119458
collect_time: 39.03229913941212
reward_mean: -108.67787114845937
reward_std: 4.890328451829895
reward_max: -105.24019607843134
reward_min: -116.46988795518209
queue_len: 0.0720675538119757
wait_time: 0.6877626050420167
delay_time: 4.650785574056362
pressure: 0.8743368700265252
total_envstep_count: 750288
total_train_sample_count: 750288
total_episode_count: 6468
total_duration: 43006.16953623073
[2024-12-26 13:34:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.08120182914258
avg_train_sample_per_sec: 18.08120182914258
avg_episode_per_sec: 0.15587242956157396
collect_time: 38.49301648069733
reward_mean: -111.36612978524742
reward_std: 6.21141520251558
reward_max: -105.24019607843134
reward_min: -118.68347338935573
queue_len: 0.07385021869048237
wait_time: 0.7044283119967704
delay_time: 4.761760053610914
pressure: 0.8868258178603005
total_envstep_count: 750984
total_train_sample_count: 750984
total_episode_count: 6474
total_duration: 43044.66255271142
[2024-12-26 13:35:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.665736228499924
avg_train_sample_per_sec: 17.665736228499924
avg_episode_per_sec: 0.15229082955603382
collect_time: 39.39830137830041
reward_mean: -114.7175536881419
reward_std: 9.425488506777187
reward_max: -105.24019607843134
reward_min: -132.45868347338936
queue_len: 0.07607264833431161
wait_time: 0.7242100642202063
delay_time: 4.854393376857884
pressure: 0.9169982316534041
total_envstep_count: 751680
total_train_sample_count: 751680
total_episode_count: 6480
total_duration: 43084.06085408972
[2024-12-26 13:35:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82758442510162
avg_train_sample_per_sec: 17.82758442510162
avg_episode_per_sec: 0.15368607263018638
collect_time: 39.04062285746448
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 752376
total_train_sample_count: 752376
total_episode_count: 6486
total_duration: 43123.10147694719
[2024-12-26 13:36:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.848071142526976
avg_train_sample_per_sec: 17.848071142526976
avg_episode_per_sec: 0.15386268226316357
collect_time: 38.99581049638614
reward_mean: -114.78909897292249
reward_std: 5.099878536676949
reward_max: -110.7738095238095
reward_min: -125.97969187675069
queue_len: 0.07612009215711041
wait_time: 0.7305310055056506
delay_time: 4.84096715392548
pressure: 0.9217506631299734
total_envstep_count: 753072
total_train_sample_count: 753072
total_episode_count: 6492
total_duration: 43162.097287443576
[2024-12-26 13:37:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.704217238296685
avg_train_sample_per_sec: 17.704217238296685
avg_episode_per_sec: 0.15262256239910935
collect_time: 39.31266718160548
reward_mean: -118.54166666666669
reward_std: 9.68655978123499
reward_max: -109.35784313725489
reward_min: -135.60574229691875
queue_len: 0.07860853227232538
wait_time: 0.7564245746928303
delay_time: 4.957209198146505
pressure: 0.9494916003536694
total_envstep_count: 753768
total_train_sample_count: 753768
total_episode_count: 6498
total_duration: 43201.40995462518
[2024-12-26 13:37:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.634645937776703
avg_train_sample_per_sec: 17.634645937776703
avg_episode_per_sec: 0.15202280980841987
collect_time: 39.46776149948313
reward_mean: -115.14285714285711
reward_std: 5.384866474674569
reward_max: -109.48249299719888
reward_min: -124.91386554621846
queue_len: 0.07635467980295566
wait_time: 0.7329473898312641
delay_time: 4.806992154992183
pressure: 0.925950486295314
total_envstep_count: 754464
total_train_sample_count: 754464
total_episode_count: 6504
total_duration: 43240.87771612466
[2024-12-26 13:38:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.624381027477014
avg_train_sample_per_sec: 17.624381027477014
avg_episode_per_sec: 0.15193431920238806
collect_time: 39.49074857805855
reward_mean: -114.71335200746962
reward_std: 6.855811414559174
reward_max: -109.37745098039211
reward_min: -126.43347338935574
queue_len: 0.07606986207391886
wait_time: 0.7286544591311327
delay_time: 4.804511239395256
pressure: 0.9217506631299734
total_envstep_count: 755160
total_train_sample_count: 755160
total_episode_count: 6510
total_duration: 43280.36846470272
[2024-12-26 13:39:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97747346723469
avg_train_sample_per_sec: 17.97747346723469
avg_episode_per_sec: 0.15497821954512667
collect_time: 38.715117631435405
reward_mean: -112.17577030812322
reward_std: 3.3283470225712843
reward_max: -109.6505602240896
reward_min: -118.32633053221286
queue_len: 0.07438711558894112
wait_time: 0.7057412598107323
delay_time: 4.801652728321458
pressure: 0.8953359858532272
total_envstep_count: 755856
total_train_sample_count: 755856
total_episode_count: 6516
total_duration: 43319.083582334155
[2024-12-26 13:39:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.82953650198851
avg_train_sample_per_sec: 17.82953650198851
avg_episode_per_sec: 0.1537029008792113
collect_time: 39.03634847279265
reward_mean: -118.9204014939309
reward_std: 8.567174436049905
reward_max: -109.99859943977587
reward_min: -134.9432773109244
queue_len: 0.0788596826882831
wait_time: 0.7641256436261509
delay_time: 4.875451968766548
pressure: 0.9602122015915121
total_envstep_count: 756552
total_train_sample_count: 756552
total_episode_count: 6522
total_duration: 43358.11993080695
[2024-12-26 13:40:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.896644561369023
avg_train_sample_per_sec: 17.896644561369023
avg_episode_per_sec: 0.1542814186324916
collect_time: 38.88997167113424
reward_mean: -114.58239962651726
reward_std: 8.200472269872161
reward_max: -109.47408963585431
reward_min: -132.4950980392157
queue_len: 0.07598302362501146
wait_time: 0.7280245320940049
delay_time: 4.803112847119551
pressure: 0.9211980548187446
total_envstep_count: 757248
total_train_sample_count: 757248
total_episode_count: 6528
total_duration: 43397.00990247808
[2024-12-26 13:40:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.95079350297375
avg_train_sample_per_sec: 17.95079350297375
avg_episode_per_sec: 0.15474821985322196
collect_time: 38.772659263486034
reward_mean: -110.26517273576093
reward_std: 1.9651518928317537
reward_max: -109.04901960784312
reward_min: -114.6456582633053
queue_len: 0.07312014107145952
wait_time: 0.6938058490416502
delay_time: 4.7034121060606795
pressure: 0.8787577365163571
total_envstep_count: 757944
total_train_sample_count: 757944
total_episode_count: 6534
total_duration: 43435.782561741566
[2024-12-26 13:41:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.99388382866047
avg_train_sample_per_sec: 17.99388382866047
avg_episode_per_sec: 0.15511968817810748
collect_time: 38.6798095745966
reward_mean: -111.6080765639589
reward_std: 4.089915970116851
reward_max: -109.59173669467783
reward_min: -120.75140056022406
queue_len: 0.07401066085143164
wait_time: 0.7101862738906349
delay_time: 4.76504328954175
pressure: 0.8885941644562334
total_envstep_count: 758640
total_train_sample_count: 758640
total_episode_count: 6540
total_duration: 43474.46237131616
[2024-12-26 13:42:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.86627255724066
avg_train_sample_per_sec: 17.86627255724066
avg_episode_per_sec: 0.15401959101069534
collect_time: 38.95608318803646
reward_mean: -117.50863678804855
reward_std: 8.193885870313167
reward_max: -109.80112044817926
reward_min: -130.93907563025212
queue_len: 0.07792349919631868
wait_time: 0.7514738543516434
delay_time: 4.917688451453006
pressure: 0.9353448275862069
total_envstep_count: 759336
total_train_sample_count: 759336
total_episode_count: 6546
total_duration: 43513.4184545042
[2024-12-26 13:42:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.077898054801214
avg_train_sample_per_sec: 18.077898054801214
avg_episode_per_sec: 0.15584394874828633
collect_time: 38.50005116137675
reward_mean: -112.24626517273573
reward_std: 3.51765818706499
reward_max: -109.59313725490193
reward_min: -119.58193277310923
queue_len: 0.07443386284664173
wait_time: 0.7138293093541573
delay_time: 4.745945408605484
pressure: 0.9011936339522547
total_envstep_count: 760032
total_train_sample_count: 760032
total_episode_count: 6552
total_duration: 43551.91850566558
[2024-12-26 13:43:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.834592328678102
avg_train_sample_per_sec: 17.834592328678102
avg_episode_per_sec: 0.1537464855920526
collect_time: 39.02528228138016
reward_mean: -110.07457983193274
reward_std: 0.7320922851920975
reward_max: -109.59313725490193
reward_min: -111.65196078431373
queue_len: 0.07299375320419944
wait_time: 0.6959687610676455
delay_time: 4.696232133543768
pressure: 0.878315649867374
total_envstep_count: 760728
total_train_sample_count: 760728
total_episode_count: 6558
total_duration: 43590.943787946955
[2024-12-26 13:44:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.827644356166115
avg_train_sample_per_sec: 17.827644356166115
avg_episode_per_sec: 0.1536865892772941
collect_time: 39.04049161488191
reward_mean: -113.51190476190476
reward_std: 3.8196830119246963
reward_max: -109.62254901960785
reward_min: -119.7731092436975
queue_len: 0.07527314639383605
wait_time: 0.7172307915208526
delay_time: 4.821743911897291
pressure: 0.9092617152961981
total_envstep_count: 761424
total_train_sample_count: 761424
total_episode_count: 6564
total_duration: 43629.98427956184
[2024-12-26 13:44:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.930047169102988
avg_train_sample_per_sec: 17.930047169102988
avg_episode_per_sec: 0.15456937214743954
collect_time: 38.817521975031134
reward_mean: -111.21358543417365
reward_std: 1.673400517127573
reward_max: -109.27941176470588
reward_min: -114.72058823529412
queue_len: 0.0737490619590011
wait_time: 0.700762599469496
delay_time: 4.7075876062095565
pressure: 0.8874889478337756
total_envstep_count: 762120
total_train_sample_count: 762120
total_episode_count: 6570
total_duration: 43668.80180153687
[2024-12-26 13:45:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.864158058855203
avg_train_sample_per_sec: 17.864158058855203
avg_episode_per_sec: 0.15400136257633798
collect_time: 38.96069424077868
reward_mean: -114.43183940242763
reward_std: 6.6179628278062586
reward_max: -109.27941176470588
reward_min: -128.68207282913167
queue_len: 0.07588318262760453
wait_time: 0.7268556958592455
delay_time: 4.836796384334451
pressure: 0.915893015030946
total_envstep_count: 762816
total_train_sample_count: 762816
total_episode_count: 6576
total_duration: 43707.76249577765
[2024-12-26 13:46:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.478464883390245
avg_train_sample_per_sec: 17.478464883390245
avg_episode_per_sec: 0.15067642140853657
collect_time: 39.82043072108739
reward_mean: -116.3220121381886
reward_std: 2.987197130144272
reward_max: -112.45518207282912
reward_min: -120.58683473389357
queue_len: 0.07713661282373249
wait_time: 0.737817618205549
delay_time: 4.961031013807704
pressure: 0.9288240495137047
total_envstep_count: 763512
total_train_sample_count: 763512
total_episode_count: 6582
total_duration: 43747.58292649874
[2024-12-26 13:46:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.760273829062157
avg_train_sample_per_sec: 17.760273829062157
avg_episode_per_sec: 0.1531058088712255
collect_time: 39.18858496771008
reward_mean: -113.8814192343604
reward_std: 3.445472129530859
reward_max: -109.78291316526611
reward_min: -117.96218487394958
queue_len: 0.07551818251615411
wait_time: 0.722844564439392
delay_time: 4.819775266655928
pressure: 0.91368258178603
total_envstep_count: 764208
total_train_sample_count: 764208
total_episode_count: 6588
total_duration: 43786.77151146645
[2024-12-26 13:47:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.845324065206174
avg_train_sample_per_sec: 17.845324065206174
avg_episode_per_sec: 0.15383900056212219
collect_time: 39.001813441820445
reward_mean: -113.31454248366015
reward_std: 1.4780763634843124
reward_max: -110.51610644257704
reward_min: -115.3879551820728
queue_len: 0.07514226955149877
wait_time: 0.7175729597763066
delay_time: 4.7885561511908525
pressure: 0.9071618037135277
total_envstep_count: 764904
total_train_sample_count: 764904
total_episode_count: 6594
total_duration: 43825.773324908274
[2024-12-26 13:48:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.764928924483222
avg_train_sample_per_sec: 17.764928924483222
avg_episode_per_sec: 0.1531459390041657
collect_time: 39.178316049482675
reward_mean: -111.5845004668534
reward_std: 4.243710068350446
reward_max: -105.24019607843134
reward_min: -117.24019607843134
queue_len: 0.07399502683478341
wait_time: 0.7052343926076178
delay_time: 4.7319034860204745
pressure: 0.8951149425287358
total_envstep_count: 765600
total_train_sample_count: 765600
total_episode_count: 6600
total_duration: 43864.951640957755
[2024-12-26 13:48:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.951280535324067
avg_train_sample_per_sec: 17.951280535324067
avg_episode_per_sec: 0.1547524184079661
collect_time: 38.771607330765576
reward_mean: -112.07154528478056
reward_std: 9.970065924991355
reward_max: -105.24019607843134
reward_min: -130.00070028011203
queue_len: 0.07431800085197648
wait_time: 0.710287353225994
delay_time: 4.788376748876612
pressure: 0.8920203359858533
total_envstep_count: 766296
total_train_sample_count: 766296
total_episode_count: 6606
total_duration: 43903.72324828852
[2024-12-26 13:49:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.899965449916298
avg_train_sample_per_sec: 17.899965449916298
avg_episode_per_sec: 0.15431004698203704
collect_time: 38.88275661466456
reward_mean: -118.40732959850605
reward_std: 10.39040251980163
reward_max: -105.24019607843134
reward_min: -133.15336134453776
queue_len: 0.07851944933587933
wait_time: 0.7582247310949136
delay_time: 4.91050282290362
pressure: 0.9647435897435898
total_envstep_count: 766992
total_train_sample_count: 766992
total_episode_count: 6612
total_duration: 43942.60600490319
[2024-12-26 13:50:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.000758863941584
avg_train_sample_per_sec: 18.000758863941584
avg_episode_per_sec: 0.15517895572363433
collect_time: 38.66503658321872
reward_mean: -107.26027077497662
reward_std: 3.542250287264821
reward_max: -105.24019607843134
reward_min: -114.92787114845935
queue_len: 0.07112750051391022
wait_time: 0.6768931710615279
delay_time: 4.595274059572803
pressure: 0.8618479221927497
total_envstep_count: 767688
total_train_sample_count: 767688
total_episode_count: 6618
total_duration: 43981.271041486405
[2024-12-26 13:50:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.839585504615304
avg_train_sample_per_sec: 17.839585504615304
avg_episode_per_sec: 0.1537895302122009
collect_time: 39.01435937622748
reward_mean: -110.72408963585433
reward_std: 6.602211866510015
reward_max: -105.24019607843134
reward_min: -122.38585434173673
queue_len: 0.07342446262324556
wait_time: 0.7028122809689746
delay_time: 4.692627313937824
pressure: 0.8903625110521661
total_envstep_count: 768384
total_train_sample_count: 768384
total_episode_count: 6624
total_duration: 44020.28540086263
[2024-12-26 13:51:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.06965777126029
avg_train_sample_per_sec: 18.06965777126029
avg_episode_per_sec: 0.1557729118212094
collect_time: 38.517608291784306
reward_mean: -106.06489262371612
reward_std: 1.276943625490221
reward_max: -105.24019607843134
reward_min: -108.61484593837534
queue_len: 0.07033480943217249
wait_time: 0.6682832394673165
delay_time: 4.576354071987944
pressure: 0.8498010610079576
total_envstep_count: 769080
total_train_sample_count: 769080
total_episode_count: 6630
total_duration: 44058.80300915441
[2024-12-26 13:52:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.72592292812578
avg_train_sample_per_sec: 17.72592292812578
avg_episode_per_sec: 0.1528096804148774
collect_time: 39.26452816150151
reward_mean: -111.59792250233424
reward_std: 6.605171528956481
reward_max: -105.24019607843134
reward_min: -122.422268907563
queue_len: 0.0740039273888158
wait_time: 0.709875064083989
delay_time: 4.729861168179432
pressure: 0.8942307692307692
total_envstep_count: 769776
total_train_sample_count: 769776
total_episode_count: 6636
total_duration: 44098.06753731592
[2024-12-26 13:52:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.17875372248204
avg_train_sample_per_sec: 18.17875372248204
avg_episode_per_sec: 0.15671339415932792
collect_time: 38.28645300030895
reward_mean: -110.74183006535947
reward_std: 7.801578955436269
reward_max: -105.24019607843134
reward_min: -122.73809523809524
queue_len: 0.07343622683379274
wait_time: 0.7011978752597413
delay_time: 4.679347918661869
pressure: 0.8883731211317417
total_envstep_count: 770472
total_train_sample_count: 770472
total_episode_count: 6642
total_duration: 44136.353990316224
[2024-12-26 13:53:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.876265555922018
avg_train_sample_per_sec: 17.876265555922018
avg_episode_per_sec: 0.15410573755105186
collect_time: 38.93430637527257
reward_mean: -112.39028944911297
reward_std: 8.204517203793113
reward_max: -105.24019607843134
reward_min: -126.37044817927172
queue_len: 0.07452936966121548
wait_time: 0.7136280794369029
delay_time: 4.667500403187488
pressure: 0.9072723253757736
total_envstep_count: 771168
total_train_sample_count: 771168
total_episode_count: 6648
total_duration: 44175.2882966915
[2024-12-26 13:54:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.066956756827008
avg_train_sample_per_sec: 18.066956756827008
avg_episode_per_sec: 0.15574962721402594
collect_time: 38.52336668360047
reward_mean: -108.4236694677871
reward_std: 7.118462903161101
reward_max: -105.24019607843134
reward_min: -124.3410364145658
queue_len: 0.07189898505821425
wait_time: 0.6860406961192963
delay_time: 4.665425027357835
pressure: 0.8662687886825817
total_envstep_count: 771864
total_train_sample_count: 771864
total_episode_count: 6654
total_duration: 44213.8116633751
[2024-12-26 13:54:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.03619359764228
avg_train_sample_per_sec: 18.03619359764228
avg_episode_per_sec: 0.15548442756588174
collect_time: 38.58907347784192
reward_mean: -114.50933706816056
reward_std: 8.233643040449106
reward_max: -105.24019607843134
reward_min: -127.79691876750701
queue_len: 0.07593457365262639
wait_time: 0.7325760432378078
delay_time: 4.801403743364141
pressure: 0.9189876215738284
total_envstep_count: 772560
total_train_sample_count: 772560
total_episode_count: 6660
total_duration: 44252.40073685294
[2024-12-26 13:55:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.902931120324293
avg_train_sample_per_sec: 17.902931120324293
avg_episode_per_sec: 0.1543356131062439
collect_time: 38.876315577724945
reward_mean: -109.5549719887955
reward_std: 6.558802915129686
reward_max: -105.24019607843134
reward_min: -123.5427170868347
queue_len: 0.07264918566896252
wait_time: 0.6916043163507665
delay_time: 4.657564690290587
pressure: 0.8770999115826701
total_envstep_count: 773256
total_train_sample_count: 773256
total_episode_count: 6666
total_duration: 44291.27705243067
[2024-12-26 13:56:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.804029750985936
avg_train_sample_per_sec: 17.804029750985936
avg_episode_per_sec: 0.15348301509470635
collect_time: 39.09227347597852
reward_mean: -105.43008870214749
reward_std: 0.42461281505509996
reward_max: -105.24019607843134
reward_min: -106.37955182072824
queue_len: 0.06991385192450099
wait_time: 0.6646426032835767
delay_time: 4.54733233744952
pressure: 0.844496021220159
total_envstep_count: 773952
total_train_sample_count: 773952
total_episode_count: 6672
total_duration: 44330.36932590665
[2024-12-26 13:56:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.810712608561552
avg_train_sample_per_sec: 17.810712608561552
avg_episode_per_sec: 0.15354062593587545
collect_time: 39.077605444345615
reward_mean: -109.69537815126046
reward_std: 9.502192273526703
reward_max: -105.24019607843134
reward_min: -130.92577030812322
queue_len: 0.07274229320375362
wait_time: 0.6970361309864352
delay_time: 4.674812582024432
pressure: 0.8800839964633068
total_envstep_count: 774648
total_train_sample_count: 774648
total_episode_count: 6678
total_duration: 44369.446931351
[2024-12-26 13:57:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.0936211630464
avg_train_sample_per_sec: 18.0936211630464
avg_episode_per_sec: 0.15597949278488277
collect_time: 38.46659514577873
reward_mean: -106.00326797385618
reward_std: 1.706280629889556
reward_max: -105.24019607843134
reward_min: -109.81862745098039
queue_len: 0.07029394427974547
wait_time: 0.6685582278888565
delay_time: 4.564705311106839
pressure: 0.8491379310344828
total_envstep_count: 775344
total_train_sample_count: 775344
total_episode_count: 6684
total_duration: 44407.91352649678
[2024-12-26 13:58:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.067785266564222
avg_train_sample_per_sec: 18.067785266564222
avg_episode_per_sec: 0.15575676953934675
collect_time: 38.52160017022118
reward_mean: -106.87873482726422
reward_std: 3.6638840261577554
reward_max: -105.24019607843134
reward_min: -115.07142857142857
queue_len: 0.070874492591024
wait_time: 0.6743680451844751
delay_time: 4.6342348946695235
pressure: 0.8578691423519009
total_envstep_count: 776040
total_train_sample_count: 776040
total_episode_count: 6690
total_duration: 44446.435126667
[2024-12-26 13:58:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.016351800800983
avg_train_sample_per_sec: 18.016351800800983
avg_episode_per_sec: 0.15531337759311195
collect_time: 38.63157245680875
reward_mean: -108.08566760037344
reward_std: 5.268152543347871
reward_max: -105.24019607843134
reward_min: -119.79061624649859
queue_len: 0.0716748458888418
wait_time: 0.6813681374406526
delay_time: 4.608746635088502
pressure: 0.867816091954023
total_envstep_count: 776736
total_train_sample_count: 776736
total_episode_count: 6696
total_duration: 44485.06669912381
[2024-12-26 13:59:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.927001042324154
avg_train_sample_per_sec: 17.927001042324154
avg_episode_per_sec: 0.1545431124338289
collect_time: 38.824117785055186
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 777432
total_train_sample_count: 777432
total_episode_count: 6702
total_duration: 44523.89081690887
[2024-12-26 14:00:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.982154934599404
avg_train_sample_per_sec: 17.982154934599404
avg_episode_per_sec: 0.15501857702240865
collect_time: 38.70503855246118
reward_mean: -105.4144491129785
reward_std: 0.38964163053304524
reward_max: -105.24019607843134
reward_min: -106.28571428571423
queue_len: 0.06990348084415018
wait_time: 0.6652794185755645
delay_time: 4.547169495741871
pressure: 0.8440539345711758
total_envstep_count: 778128
total_train_sample_count: 778128
total_episode_count: 6708
total_duration: 44562.59585546133
[2024-12-26 14:00:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.915108392248456
avg_train_sample_per_sec: 17.915108392248456
avg_episode_per_sec: 0.15444058958834878
collect_time: 38.84989053714833
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 778824
total_train_sample_count: 778824
total_episode_count: 6714
total_duration: 44601.44574599848
[2024-12-26 14:01:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.059195601592904
avg_train_sample_per_sec: 18.059195601592904
avg_episode_per_sec: 0.1556827207033871
collect_time: 38.53992256103642
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 779520
total_train_sample_count: 779520
total_episode_count: 6720
total_duration: 44639.985668559515
[2024-12-26 14:02:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.114633235942428
avg_train_sample_per_sec: 18.114633235942428
avg_episode_per_sec: 0.15616063134433125
collect_time: 38.42197581008822
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 780216
total_train_sample_count: 780216
total_episode_count: 6726
total_duration: 44678.4076443696
[2024-12-26 14:02:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.083993325943748
avg_train_sample_per_sec: 18.083993325943748
avg_episode_per_sec: 0.15589649418917026
collect_time: 38.487074588857595
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 780912
total_train_sample_count: 780912
total_episode_count: 6732
total_duration: 44716.89471895846
[2024-12-26 14:03:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.865142771209722
avg_train_sample_per_sec: 17.865142771209722
avg_episode_per_sec: 0.1540098514759459
collect_time: 38.95854675853066
reward_mean: -109.40732959850605
reward_std: 6.060823617396065
reward_max: -105.24019607843134
reward_min: -120.19327731092433
queue_len: 0.07255127957460612
wait_time: 0.6893241491999097
delay_time: 4.71561810005674
pressure: 0.8742263483642794
total_envstep_count: 781608
total_train_sample_count: 781608
total_episode_count: 6738
total_duration: 44755.853265716985
[2024-12-26 14:03:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.99474930284389
avg_train_sample_per_sec: 17.99474930284389
avg_episode_per_sec: 0.15512714916244733
collect_time: 38.677949233224616
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 782304
total_train_sample_count: 782304
total_episode_count: 6744
total_duration: 44794.53121495021
[2024-12-26 14:04:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.018251396177753
avg_train_sample_per_sec: 18.018251396177753
avg_episode_per_sec: 0.15532975341532546
collect_time: 38.627499677779156
reward_mean: -106.77754435107374
reward_std: 3.4376152427202857
reward_max: -105.24019607843134
reward_min: -114.46428571428574
queue_len: 0.07080739015323191
wait_time: 0.67529850136341
delay_time: 4.603222122059541
pressure: 0.8556587091069848
total_envstep_count: 783000
total_train_sample_count: 783000
total_episode_count: 6750
total_duration: 44833.15871462799
[2024-12-26 14:05:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.912292500260996
avg_train_sample_per_sec: 17.912292500260996
avg_episode_per_sec: 0.1544163146574224
collect_time: 38.855997912598774
reward_mean: -108.41970121381884
reward_std: 7.109589617536109
reward_max: -105.24019607843134
reward_min: -124.3172268907563
queue_len: 0.07189635359006553
wait_time: 0.6897016100870056
delay_time: 4.625429480945716
pressure: 0.872236958443855
total_envstep_count: 783696
total_train_sample_count: 783696
total_episode_count: 6756
total_duration: 44872.01471254059
[2024-12-26 14:05:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.049181682208275
avg_train_sample_per_sec: 18.049181682208275
avg_episode_per_sec: 0.1555963938121403
collect_time: 38.56130500841886
reward_mean: -105.51774042950512
reward_std: 0.6206080357720095
reward_max: -105.24019607843134
reward_min: -106.90546218487394
queue_len: 0.06997197641213866
wait_time: 0.6666459245059649
delay_time: 4.555465910397264
pressure: 0.8453801945181256
total_envstep_count: 784392
total_train_sample_count: 784392
total_episode_count: 6762
total_duration: 44910.576017549014
[2024-12-26 14:06:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88897008099191
avg_train_sample_per_sec: 17.88897008099191
avg_episode_per_sec: 0.1542152593188958
collect_time: 38.90665571292677
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 785088
total_train_sample_count: 785088
total_episode_count: 6768
total_duration: 44949.48267326194
[2024-12-26 14:07:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.259679406360522
avg_train_sample_per_sec: 18.259679406360522
avg_episode_per_sec: 0.15741102936517692
collect_time: 38.116769988719376
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 785784
total_train_sample_count: 785784
total_episode_count: 6774
total_duration: 44987.59944325066
[2024-12-26 14:07:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.687159185659745
avg_train_sample_per_sec: 17.687159185659745
avg_episode_per_sec: 0.1524755102212047
collect_time: 39.35058155434579
reward_mean: -105.56524276377213
reward_std: 0.7268264842830163
reward_max: -105.24019607843134
reward_min: -107.19047619047615
queue_len: 0.07000347663380115
wait_time: 0.6652336000713281
delay_time: 4.548608906210712
pressure: 0.8456012378426171
total_envstep_count: 786480
total_train_sample_count: 786480
total_episode_count: 6780
total_duration: 45026.95002480501
[2024-12-26 14:08:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.279322636657895
avg_train_sample_per_sec: 17.279322636657895
avg_episode_per_sec: 0.14895967790222323
collect_time: 40.279356699055064
reward_mean: -110.82644724556486
reward_std: 5.762345234659123
reward_max: -105.24019607843134
reward_min: -118.14845938375346
queue_len: 0.07349233902225787
wait_time: 0.6977378042286763
delay_time: 4.696892279402085
pressure: 0.8872679045092836
total_envstep_count: 787176
total_train_sample_count: 787176
total_episode_count: 6786
total_duration: 45067.22938150407
[2024-12-26 14:09:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.62926192101558
avg_train_sample_per_sec: 17.62926192101558
avg_episode_per_sec: 0.15197639587082398
collect_time: 39.47981504377723
reward_mean: -108.53676470588233
reward_std: 7.3713515434736046
reward_max: -105.24019607843134
reward_min: -125.01960784313731
queue_len: 0.07197398190045247
wait_time: 0.6872103063152757
delay_time: 4.604476324515228
pressure: 0.872236958443855
total_envstep_count: 787872
total_train_sample_count: 787872
total_episode_count: 6792
total_duration: 45106.70919654785
[2024-12-26 14:09:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.19405521987279
avg_train_sample_per_sec: 17.19405521987279
avg_episode_per_sec: 0.1482246139644206
collect_time: 40.47910694130883
reward_mean: -110.28991596638654
reward_std: 5.156383316854516
reward_max: -105.24019607843134
reward_min: -116.546218487395
queue_len: 0.07313654904932794
wait_time: 0.7022343641258447
delay_time: 4.733002586530145
pressure: 0.8791998231653403
total_envstep_count: 788568
total_train_sample_count: 788568
total_episode_count: 6798
total_duration: 45147.18830348916
[2024-12-26 14:10:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.644376426220912
avg_train_sample_per_sec: 17.644376426220912
avg_episode_per_sec: 0.15210669332949062
collect_time: 39.445995890548446
reward_mean: -109.95716619981323
reward_std: 6.9850259516290185
reward_max: -105.24019607843134
reward_min: -122.97899159663862
queue_len: 0.07291589270544643
wait_time: 0.695392082562468
delay_time: 4.713107534677046
pressure: 0.8784261715296197
total_envstep_count: 789264
total_train_sample_count: 789264
total_episode_count: 6804
total_duration: 45186.63429937971
[2024-12-26 14:11:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.87099469414199
avg_train_sample_per_sec: 17.87099469414199
avg_episode_per_sec: 0.15406029908743096
collect_time: 38.94578963912651
reward_mean: -107.0580065359477
reward_std: 4.064747753216546
reward_max: -105.24019607843134
reward_min: -116.14705882352942
queue_len: 0.07099337303444807
wait_time: 0.6773748845249857
delay_time: 4.6034634844448865
pressure: 0.8582007073386383
total_envstep_count: 789960
total_train_sample_count: 789960
total_episode_count: 6810
total_duration: 45225.58008901883
[2024-12-26 14:11:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.038278753276224
avg_train_sample_per_sec: 18.038278753276224
avg_episode_per_sec: 0.15550240304548468
collect_time: 38.584612729392944
reward_mean: -108.3458216619981
reward_std: 4.458586600743656
reward_max: -105.24019607843134
reward_min: -115.88655462184872
queue_len: 0.07184736184482632
wait_time: 0.684885094621403
delay_time: 4.671059685436592
pressure: 0.8637267904509282
total_envstep_count: 790656
total_train_sample_count: 790656
total_episode_count: 6816
total_duration: 45264.164701748225
[2024-12-26 14:12:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.969386398626348
avg_train_sample_per_sec: 17.969386398626348
avg_episode_per_sec: 0.15490850343643406
collect_time: 38.732541254341605
reward_mean: -106.54341736694674
reward_std: 0.7540349908168885
reward_max: -105.24019607843134
reward_min: -107.8522408963585
queue_len: 0.07065213353245804
wait_time: 0.6743816669019509
delay_time: 4.5483926560975645
pressure: 0.8561007957559682
total_envstep_count: 791352
total_train_sample_count: 791352
total_episode_count: 6822
total_duration: 45302.89724300257
[2024-12-26 14:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.895455340090013
avg_train_sample_per_sec: 17.895455340090013
avg_episode_per_sec: 0.1542711667249139
collect_time: 38.89255605811812
reward_mean: -108.97373949579828
reward_std: 5.19088387993349
reward_max: -105.24019607843134
reward_min: -116.94887955182071
queue_len: 0.0722637529812986
wait_time: 0.6919638213375534
delay_time: 4.6087895311850025
pressure: 0.876105216622458
total_envstep_count: 792048
total_train_sample_count: 792048
total_episode_count: 6828
total_duration: 45341.78979906069
[2024-12-26 14:13:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.990728472250133
avg_train_sample_per_sec: 17.990728472250133
avg_episode_per_sec: 0.1550924868297425
collect_time: 38.68659354586713
reward_mean: -111.09418767507002
reward_std: 6.271434601146378
reward_max: -105.24019607843134
reward_min: -121.07703081232495
queue_len: 0.07366988572617374
wait_time: 0.7076850634152865
delay_time: 4.695303666276035
pressure: 0.8937886825817859
total_envstep_count: 792744
total_train_sample_count: 792744
total_episode_count: 6834
total_duration: 45380.47639260656
[2024-12-26 14:14:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.266774721714604
avg_train_sample_per_sec: 18.266774721714604
avg_episode_per_sec: 0.15747219587685005
collect_time: 38.101964391810824
reward_mean: -108.19666199813257
reward_std: 6.61085876961336
reward_max: -105.24019607843134
reward_min: -122.97899159663865
queue_len: 0.07174844960088365
wait_time: 0.6852892571705956
delay_time: 4.621062975287091
pressure: 0.8695844385499557
total_envstep_count: 793440
total_train_sample_count: 793440
total_episode_count: 6840
total_duration: 45418.57835699837
[2024-12-26 14:15:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.128919592049378
avg_train_sample_per_sec: 18.128919592049378
avg_episode_per_sec: 0.15628378958663258
collect_time: 38.39169766659663
reward_mean: -105.28921568627447
reward_std: 0.10961117536763768
reward_max: -105.24019607843134
reward_min: -105.53431372549016
queue_len: 0.0698204348052218
wait_time: 0.6643833262748069
delay_time: 4.5467514934426125
pressure: 0.8430592396109637
total_envstep_count: 794136
total_train_sample_count: 794136
total_episode_count: 6846
total_duration: 45456.97005466496
[2024-12-26 14:15:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.124216743780615
avg_train_sample_per_sec: 18.124216743780615
avg_episode_per_sec: 0.1562432477912122
collect_time: 38.401659494545314
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 794832
total_train_sample_count: 794832
total_episode_count: 6852
total_duration: 45495.371714159504
[2024-12-26 14:16:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.097075008339502
avg_train_sample_per_sec: 18.097075008339502
avg_episode_per_sec: 0.15600926731327155
collect_time: 38.45925375671312
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 795528
total_train_sample_count: 795528
total_episode_count: 6858
total_duration: 45533.83096791622
[2024-12-26 14:17:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.17436625713026
avg_train_sample_per_sec: 18.17436625713026
avg_episode_per_sec: 0.1566755711821574
collect_time: 38.29569571521878
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 796224
total_train_sample_count: 796224
total_episode_count: 6864
total_duration: 45572.12666363144
[2024-12-26 14:17:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.825402381123496
avg_train_sample_per_sec: 17.825402381123496
avg_episode_per_sec: 0.15366726190623703
collect_time: 39.045401899989685
reward_mean: -107.86041083099904
reward_std: 5.858978302389174
reward_max: -105.24019607843134
reward_min: -120.96148459383755
queue_len: 0.07152547137334153
wait_time: 0.6818900968875612
delay_time: 4.611705508457089
pressure: 0.8641688770999115
total_envstep_count: 796920
total_train_sample_count: 796920
total_episode_count: 6870
total_duration: 45611.17206553143
[2024-12-26 14:18:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.984446991018277
avg_train_sample_per_sec: 17.984446991018277
avg_episode_per_sec: 0.1550383361294679
collect_time: 38.70010572733171
reward_mean: -108.5113211951447
reward_std: 7.31445812387799
reward_max: -105.24019607843134
reward_min: -124.86694677871145
queue_len: 0.07195710954585191
wait_time: 0.6857875334041662
delay_time: 4.649609477128057
pressure: 0.8696949602122016
total_envstep_count: 797616
total_train_sample_count: 797616
total_episode_count: 6876
total_duration: 45649.87217125876
[2024-12-26 14:19:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.663715099231737
avg_train_sample_per_sec: 17.663715099231737
avg_episode_per_sec: 0.1522734060278598
collect_time: 39.40280943674594
reward_mean: -107.92798786181136
reward_std: 5.44866861196614
reward_max: -105.24019607843134
reward_min: -120.06512605042015
queue_len: 0.07157028372799161
wait_time: 0.6815150352802481
delay_time: 4.626058977061127
pressure: 0.8664898320070734
total_envstep_count: 798312
total_train_sample_count: 798312
total_episode_count: 6882
total_duration: 45689.2749806955
[2024-12-26 14:19:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.92733462930274
avg_train_sample_per_sec: 17.92733462930274
avg_episode_per_sec: 0.15454598818364432
collect_time: 38.82339535640553
reward_mean: -105.36204481792714
reward_std: 0.27246206448527416
reward_max: -105.24019607843134
reward_min: -105.97128851540614
queue_len: 0.06986872998536282
wait_time: 0.6648771909294221
delay_time: 4.547882618063228
pressure: 0.8438328912466843
total_envstep_count: 799008
total_train_sample_count: 799008
total_episode_count: 6888
total_duration: 45728.09837605191
[2024-12-26 14:20:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.957352270665197
avg_train_sample_per_sec: 17.957352270665197
avg_episode_per_sec: 0.15480476095401033
collect_time: 38.758497884845355
reward_mean: -106.36671335200747
reward_std: 2.5189692015438894
reward_max: -105.24019607843134
reward_min: -111.99929971988794
queue_len: 0.07053495580371845
wait_time: 0.671037457865551
delay_time: 4.586433148472713
pressure: 0.8520114942528735
total_envstep_count: 799704
total_train_sample_count: 799704
total_episode_count: 6894
total_duration: 45766.856873936755
[2024-12-26 14:21:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.813816509860125
avg_train_sample_per_sec: 17.813816509860125
avg_episode_per_sec: 0.15356738370569073
collect_time: 39.07079651430995
reward_mean: -108.43265639589168
reward_std: 4.725919574067573
reward_max: -105.24019607843134
reward_min: -117.23669467787116
queue_len: 0.07190494455960986
wait_time: 0.6836312000485427
delay_time: 4.655622838917542
pressure: 0.86604774535809
total_envstep_count: 800400
total_train_sample_count: 800400
total_episode_count: 6900
total_duration: 45805.92767045106
[2024-12-26 14:21:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88832631459101
avg_train_sample_per_sec: 17.88832631459101
avg_episode_per_sec: 0.1542097096085432
collect_time: 38.90805588850938
reward_mean: -106.01248832866479
reward_std: 1.7268979700182363
reward_max: -105.24019607843134
reward_min: -109.87394957983194
queue_len: 0.07030005857338513
wait_time: 0.668923150604185
delay_time: 4.568865692701064
pressure: 0.8463748894783376
total_envstep_count: 801096
total_train_sample_count: 801096
total_episode_count: 6906
total_duration: 45844.835726339574
[2024-12-26 14:22:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.104751757675746
avg_train_sample_per_sec: 18.104751757675746
avg_episode_per_sec: 0.1560754461868599
collect_time: 38.44294632236102
reward_mean: -106.5410830999066
reward_std: 2.908871811065909
reward_max: -105.24019607843134
reward_min: -113.0455182072829
queue_len: 0.07065058561001764
wait_time: 0.6715163850686162
delay_time: 4.595719839702415
pressure: 0.85289566755084
total_envstep_count: 801792
total_train_sample_count: 801792
total_episode_count: 6912
total_duration: 45883.27867266194
[2024-12-26 14:23:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.963489426722127
avg_train_sample_per_sec: 17.963489426722127
avg_episode_per_sec: 0.15485766747174248
collect_time: 38.745256195304925
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 802488
total_train_sample_count: 802488
total_episode_count: 6918
total_duration: 45922.02392885724
[2024-12-26 14:23:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.083377709847454
avg_train_sample_per_sec: 18.083377709847454
avg_episode_per_sec: 0.15589118715385736
collect_time: 38.48838481214643
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 803184
total_train_sample_count: 803184
total_episode_count: 6924
total_duration: 45960.51231366939
[2024-12-26 14:24:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.886880121380052
avg_train_sample_per_sec: 17.886880121380052
avg_episode_per_sec: 0.1541972424256901
collect_time: 38.91120168955996
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 803880
total_train_sample_count: 803880
total_episode_count: 6930
total_duration: 45999.42351535895
[2024-12-26 14:25:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.682668841306768
avg_train_sample_per_sec: 17.682668841306768
avg_episode_per_sec: 0.1524368003560928
collect_time: 39.36057425755449
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 804576
total_train_sample_count: 804576
total_episode_count: 6936
total_duration: 46038.7840896165
[2024-12-26 14:25:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.74107488469598
avg_train_sample_per_sec: 17.74107488469598
avg_episode_per_sec: 0.15294030073013778
collect_time: 39.230993867253886
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 805272
total_train_sample_count: 805272
total_episode_count: 6942
total_duration: 46078.015083483755
[2024-12-26 14:26:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.043833393097533
avg_train_sample_per_sec: 18.043833393097533
avg_episode_per_sec: 0.15555028787153047
collect_time: 38.57273478629253
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 805968
total_train_sample_count: 805968
total_episode_count: 6948
total_duration: 46116.58781827005
[2024-12-26 14:27:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.939293715672072
avg_train_sample_per_sec: 17.939293715672072
avg_episode_per_sec: 0.15464908375579373
collect_time: 38.79751405106671
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 806664
total_train_sample_count: 806664
total_episode_count: 6954
total_duration: 46155.385332321115
[2024-12-26 14:27:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.041478810790014
avg_train_sample_per_sec: 18.041478810790014
avg_episode_per_sec: 0.15552998974818977
collect_time: 38.5777688901946
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 807360
total_train_sample_count: 807360
total_episode_count: 6960
total_duration: 46193.96310121131
[2024-12-26 14:28:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.04680959332411
avg_train_sample_per_sec: 18.04680959332411
avg_episode_per_sec: 0.15557594477003545
collect_time: 38.566373541031034
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 808056
total_train_sample_count: 808056
total_episode_count: 6966
total_duration: 46232.529474752344
[2024-12-26 14:29:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.03289863202436
avg_train_sample_per_sec: 18.03289863202436
avg_episode_per_sec: 0.15545602268986516
collect_time: 38.596124461321146
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 808752
total_train_sample_count: 808752
total_episode_count: 6972
total_duration: 46271.125599213665
[2024-12-26 14:29:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.031943461534436
avg_train_sample_per_sec: 18.031943461534436
avg_episode_per_sec: 0.15544778846150376
collect_time: 38.598168937513606
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 809448
total_train_sample_count: 809448
total_episode_count: 6978
total_duration: 46309.723768151176
[2024-12-26 14:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.96376244766785
avg_train_sample_per_sec: 17.96376244766785
avg_episode_per_sec: 0.15486002110058492
collect_time: 38.74466732832789
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 810144
total_train_sample_count: 810144
total_episode_count: 6984
total_duration: 46348.4684354795
[2024-12-26 14:30:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.029812369562688
avg_train_sample_per_sec: 18.029812369562688
avg_episode_per_sec: 0.15542941697898868
collect_time: 38.60273117289692
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 810840
total_train_sample_count: 810840
total_episode_count: 6990
total_duration: 46387.0711666524
[2024-12-26 14:31:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.021023733694893
avg_train_sample_per_sec: 18.021023733694893
avg_episode_per_sec: 0.1553536528766801
collect_time: 38.62155725918338
reward_mean: -106.8816526610644
reward_std: 2.382745555595473
reward_max: -105.24019607843134
reward_min: -111.09523809523809
queue_len: 0.07087642749407452
wait_time: 0.6733879006952028
delay_time: 4.603293868096397
pressure: 0.8576480990274092
total_envstep_count: 811536
total_train_sample_count: 811536
total_episode_count: 6996
total_duration: 46425.69272391158
[2024-12-26 14:32:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.22082316555402
avg_train_sample_per_sec: 18.22082316555402
avg_episode_per_sec: 0.1570760617720174
collect_time: 38.19805470236764
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 812232
total_train_sample_count: 812232
total_episode_count: 7002
total_duration: 46463.89077861395
[2024-12-26 14:32:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.885865533728378
avg_train_sample_per_sec: 17.885865533728378
avg_episode_per_sec: 0.15418849598041703
collect_time: 38.913408953428274
reward_mean: -109.34360410830998
reward_std: 9.175499294227093
reward_max: -105.24019607843134
reward_min: -129.8606442577031
queue_len: 0.07250902129198274
wait_time: 0.6907630979005216
delay_time: 4.728441367691385
pressure: 0.8747789566755083
total_envstep_count: 812928
total_train_sample_count: 812928
total_episode_count: 7008
total_duration: 46502.80418756738
[2024-12-26 14:33:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.947620761632987
avg_train_sample_per_sec: 17.947620761632987
avg_episode_per_sec: 0.1547208686347671
collect_time: 38.77951340981386
reward_mean: -109.39017273576094
reward_std: 9.279629910826337
reward_max: -105.24019607843134
reward_min: -130.14005602240894
queue_len: 0.07253990234466905
wait_time: 0.6893446591722453
delay_time: 4.716548104186783
pressure: 0.8747789566755083
total_envstep_count: 813624
total_train_sample_count: 813624
total_episode_count: 7014
total_duration: 46541.58370097719
[2024-12-26 14:34:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.008310611386868
avg_train_sample_per_sec: 18.008310611386868
avg_episode_per_sec: 0.15524405699471439
collect_time: 38.648822480877854
reward_mean: -105.28921568627447
reward_std: 0.10961117536763768
reward_max: -105.24019607843134
reward_min: -105.53431372549016
queue_len: 0.06982043480522179
wait_time: 0.6643833262748069
delay_time: 4.5467514934426125
pressure: 0.8430592396109636
total_envstep_count: 814320
total_train_sample_count: 814320
total_episode_count: 7020
total_duration: 46580.23252345807
[2024-12-26 14:34:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.88240916613931
avg_train_sample_per_sec: 17.88240916613931
avg_episode_per_sec: 0.1541586997080975
collect_time: 38.92093025798165
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 815016
total_train_sample_count: 815016
total_episode_count: 7026
total_duration: 46619.153453716055
[2024-12-26 14:35:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.776762517371942
avg_train_sample_per_sec: 17.776762517371942
avg_episode_per_sec: 0.15324795273596503
collect_time: 39.152235921464865
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 815712
total_train_sample_count: 815712
total_episode_count: 7032
total_duration: 46658.30568963752
[2024-12-26 14:36:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.673597303683362
avg_train_sample_per_sec: 17.673597303683362
avg_episode_per_sec: 0.15235859744554622
collect_time: 39.380777327938006
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 816408
total_train_sample_count: 816408
total_episode_count: 7038
total_duration: 46697.68646696546
[2024-12-26 14:36:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.943165519387183
avg_train_sample_per_sec: 17.943165519387183
avg_episode_per_sec: 0.1546824613740274
collect_time: 38.78914226411097
reward_mean: -106.86998132586366
reward_std: 3.3280801989974513
reward_max: -105.24019607843134
reward_min: -114.28781512605043
queue_len: 0.07086868788187245
wait_time: 0.6749304828032008
delay_time: 4.611716470502433
pressure: 0.8531167108753315
total_envstep_count: 817104
total_train_sample_count: 817104
total_episode_count: 7044
total_duration: 46736.47560922957
[2024-12-26 14:37:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.814806151858768
avg_train_sample_per_sec: 17.814806151858768
avg_episode_per_sec: 0.15357591510223076
collect_time: 39.06862606682815
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 817800
total_train_sample_count: 817800
total_episode_count: 7050
total_duration: 46775.5442352964
[2024-12-26 14:38:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.65892621806028
avg_train_sample_per_sec: 17.65892621806028
avg_episode_per_sec: 0.15223212256948518
collect_time: 39.41349498862401
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 818496
total_train_sample_count: 818496
total_episode_count: 7056
total_duration: 46814.95773028502
[2024-12-26 14:38:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.59256293920237
avg_train_sample_per_sec: 17.59256293920237
avg_episode_per_sec: 0.15166002533795145
collect_time: 39.56217194761709
reward_mean: -107.35667600373479
reward_std: 4.7325929859922
reward_max: -105.24019607843134
reward_min: -117.93907563025206
queue_len: 0.07119142971069946
wait_time: 0.6797371689613069
delay_time: 4.555947743756217
pressure: 0.8647214854111405
total_envstep_count: 819192
total_train_sample_count: 819192
total_episode_count: 7062
total_duration: 46854.51990223264
[2024-12-26 14:39:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.77004441904123
avg_train_sample_per_sec: 17.77004441904123
avg_episode_per_sec: 0.15319003809518303
collect_time: 39.16703771737404
reward_mean: -109.90441176470586
reward_std: 8.241629610185829
reward_max: -105.24019607843134
reward_min: -128.1582633053221
queue_len: 0.072880909658293
wait_time: 0.6990913076105773
delay_time: 4.677925089756417
pressure: 0.8790893015030945
total_envstep_count: 819888
total_train_sample_count: 819888
total_episode_count: 7068
total_duration: 46893.686939950014
[2024-12-26 14:40:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.195604065076175
avg_train_sample_per_sec: 17.195604065076175
avg_episode_per_sec: 0.14823796607824288
collect_time: 40.47546090070531
reward_mean: -109.08846872082164
reward_std: 6.375944174454114
reward_max: -105.24019607843134
reward_min: -122.53851540616246
queue_len: 0.07233983336924511
wait_time: 0.6900775230516608
delay_time: 4.654574614293305
pressure: 0.8753315649867374
total_envstep_count: 820584
total_train_sample_count: 820584
total_episode_count: 7074
total_duration: 46934.16240085072
[2024-12-26 14:40:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.149132153950745
avg_train_sample_per_sec: 17.149132153950745
avg_episode_per_sec: 0.1478373461547478
collect_time: 40.58514411994069
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 821280
total_train_sample_count: 821280
total_episode_count: 7080
total_duration: 46974.74754497066
[2024-12-26 14:41:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.628315430836647
avg_train_sample_per_sec: 17.628315430836647
avg_episode_per_sec: 0.15196823647272972
collect_time: 39.48193477310427
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 821976
total_train_sample_count: 821976
total_episode_count: 7086
total_duration: 47014.229479743764
[2024-12-26 14:42:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.829415557790767
avg_train_sample_per_sec: 16.829415557790767
avg_episode_per_sec: 0.14508116860164455
collect_time: 41.356159850589925
reward_mean: -107.82796451914095
reward_std: 5.055025812575307
reward_max: -105.24019607843134
reward_min: -119.0434173669468
queue_len: 0.07150395525141974
wait_time: 0.684285197279619
delay_time: 4.666268936987027
pressure: 0.8620689655172414
total_envstep_count: 822672
total_train_sample_count: 822672
total_episode_count: 7092
total_duration: 47055.585639594356
[2024-12-26 14:42:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90954519825475
avg_train_sample_per_sec: 16.90954519825475
avg_episode_per_sec: 0.1457719413642651
collect_time: 41.16018448987231
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 823368
total_train_sample_count: 823368
total_episode_count: 7098
total_duration: 47096.745824084224
[2024-12-26 14:43:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.26064361500026
avg_train_sample_per_sec: 17.26064361500026
avg_episode_per_sec: 0.1487986518534505
collect_time: 40.322945976078515
reward_mean: -106.35072362278243
reward_std: 2.483215080054915
reward_max: -105.24019607843134
reward_min: -111.90336134453779
queue_len: 0.0705243525350016
wait_time: 0.6714385245698632
delay_time: 4.584613403588252
pressure: 0.8509062776304156
total_envstep_count: 824064
total_train_sample_count: 824064
total_episode_count: 7104
total_duration: 47137.0687700603
[2024-12-26 14:44:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.956114888214742
avg_train_sample_per_sec: 17.956114888214742
avg_episode_per_sec: 0.15479409386392018
collect_time: 38.76116879029385
reward_mean: -105.28921568627447
reward_std: 0.10961117536763768
reward_max: -105.24019607843134
reward_min: -105.53431372549016
queue_len: 0.0698204348052218
wait_time: 0.6643833262748069
delay_time: 4.5467514934426125
pressure: 0.8430592396109637
total_envstep_count: 824760
total_train_sample_count: 824760
total_episode_count: 7110
total_duration: 47175.8299388506
[2024-12-26 14:45:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.16385652664703
avg_train_sample_per_sec: 16.16385652664703
avg_episode_per_sec: 0.13934359074695718
collect_time: 43.05903104575351
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 825456
total_train_sample_count: 825456
total_episode_count: 7116
total_duration: 47218.888969896354
[2024-12-26 14:45:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.377308913091916
avg_train_sample_per_sec: 16.377308913091916
avg_episode_per_sec: 0.14118369752665444
collect_time: 42.49782450177893
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 826152
total_train_sample_count: 826152
total_episode_count: 7122
total_duration: 47261.38679439813
[2024-12-26 14:46:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.484784718287646
avg_train_sample_per_sec: 17.484784718287646
avg_episode_per_sec: 0.150730902743859
collect_time: 39.80603771872818
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 826848
total_train_sample_count: 826848
total_episode_count: 7128
total_duration: 47301.19283211686
[2024-12-26 14:47:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.936146460196994
avg_train_sample_per_sec: 16.936146460196994
avg_episode_per_sec: 0.1460012625879051
collect_time: 41.095535022428265
reward_mean: -105.41678338001866
reward_std: 0.3948612103124632
reward_max: -105.24019607843134
reward_min: -106.29971988795515
queue_len: 0.0699050287665906
wait_time: 0.665222145445269
delay_time: 4.549126721736636
pressure: 0.8440539345711758
total_envstep_count: 827544
total_train_sample_count: 827544
total_episode_count: 7134
total_duration: 47342.288367139285
[2024-12-26 14:47:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.07237376438108
avg_train_sample_per_sec: 16.07237376438108
avg_episode_per_sec: 0.1385549462446645
collect_time: 43.30411986451223
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 828240
total_train_sample_count: 828240
total_episode_count: 7140
total_duration: 47385.5924870038
[2024-12-26 14:48:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.947918380672704
avg_train_sample_per_sec: 15.947918380672704
avg_episode_per_sec: 0.13748205500579916
collect_time: 43.642059320010254
reward_mean: -111.81711017740427
reward_std: 9.585576776548644
reward_max: -105.24019607843134
reward_min: -128.98529411764707
queue_len: 0.074149277305971
wait_time: 0.7090432105645087
delay_time: 4.78029741856901
pressure: 0.8925729442970821
total_envstep_count: 828936
total_train_sample_count: 828936
total_episode_count: 7146
total_duration: 47429.23454632381
[2024-12-26 14:49:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.01179716753146
avg_train_sample_per_sec: 16.01179716753146
avg_episode_per_sec: 0.1380327342028574
collect_time: 43.467950081914665
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 829632
total_train_sample_count: 829632
total_episode_count: 7152
total_duration: 47472.70249640572
[2024-12-26 14:50:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.15543162232998
avg_train_sample_per_sec: 16.15543162232998
avg_episode_per_sec: 0.13927096226146538
collect_time: 43.081485921923075
reward_mean: -109.43639122315591
reward_std: 9.38297759045868
reward_max: -105.24019607843134
reward_min: -130.41736694677869
queue_len: 0.07257055120898932
wait_time: 0.6912086673749959
delay_time: 4.674546001082427
pressure: 0.8766578249336869
total_envstep_count: 830328
total_train_sample_count: 830328
total_episode_count: 7158
total_duration: 47515.783982327644
[2024-12-26 14:50:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.171010626639077
avg_train_sample_per_sec: 16.171010626639077
avg_episode_per_sec: 0.13940526402275066
collect_time: 43.03998161088674
reward_mean: -107.00175070028008
reward_std: 3.938955880532731
reward_max: -105.24019607843134
reward_min: -115.80952380952381
queue_len: 0.070956068103634
wait_time: 0.6742379423033581
delay_time: 4.616741989847236
pressure: 0.854442970822281
total_envstep_count: 831024
total_train_sample_count: 831024
total_episode_count: 7164
total_duration: 47558.82396393853
[2024-12-26 14:51:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.08216689618422
avg_train_sample_per_sec: 16.08216689618422
avg_episode_per_sec: 0.13863936979469155
collect_time: 43.277750100027774
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 831720
total_train_sample_count: 831720
total_episode_count: 7170
total_duration: 47602.10171403856
[2024-12-26 14:52:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.959086087332162
avg_train_sample_per_sec: 15.959086087332162
avg_episode_per_sec: 0.13757832833907035
collect_time: 43.6115198697038
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 832416
total_train_sample_count: 832416
total_episode_count: 7176
total_duration: 47645.71323390826
[2024-12-26 14:52:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.686550563355883
avg_train_sample_per_sec: 16.686550563355883
avg_episode_per_sec: 0.14384957382203348
collect_time: 41.710238275874396
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 833112
total_train_sample_count: 833112
total_episode_count: 7182
total_duration: 47687.423472184135
[2024-12-26 14:53:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05387925330142
avg_train_sample_per_sec: 17.05387925330142
avg_episode_per_sec: 0.147016200459495
collect_time: 40.811828772932294
reward_mean: -108.74334733893555
reward_std: 7.833284353951484
reward_max: -105.24019607843134
reward_min: -126.25910364145659
queue_len: 0.0721109730364294
wait_time: 0.6869503327414077
delay_time: 4.679770882035833
pressure: 0.8705791335101679
total_envstep_count: 833808
total_train_sample_count: 833808
total_episode_count: 7188
total_duration: 47728.235300957065
[2024-12-26 14:54:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.010320012747492
avg_train_sample_per_sec: 17.010320012747492
avg_episode_per_sec: 0.14664068976506459
collect_time: 40.916337816009296
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 834504
total_train_sample_count: 834504
total_episode_count: 7194
total_duration: 47769.15163877307
[2024-12-26 14:55:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.435252859450124
avg_train_sample_per_sec: 17.435252859450124
avg_episode_per_sec: 0.15030390396077692
collect_time: 39.919122803129255
reward_mean: -110.53104575163395
reward_std: 7.893303818618358
reward_max: -105.24019607843134
reward_min: -125.4663865546219
queue_len: 0.07329644943742306
wait_time: 0.701278754207253
delay_time: 4.768189446419226
pressure: 0.8780946065428825
total_envstep_count: 835200
total_train_sample_count: 835200
total_episode_count: 7200
total_duration: 47809.0707615762
[2024-12-26 14:55:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.897590382523482
avg_train_sample_per_sec: 15.897590382523482
avg_episode_per_sec: 0.13704819295278864
collect_time: 43.78021972217411
reward_mean: -116.01050420168065
reward_std: 6.586726047875664
reward_max: -106.27521008403357
reward_min: -128.1701680672269
queue_len: 0.07693004257405879
wait_time: 0.7485579554545073
delay_time: 4.865153337036598
pressure: 0.9383289124668434
total_envstep_count: 835896
total_train_sample_count: 835896
total_episode_count: 7206
total_duration: 47852.850981298376
[2024-12-26 14:56:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.751198692001628
avg_train_sample_per_sec: 15.751198692001628
avg_episode_per_sec: 0.1357861956207037
collect_time: 44.18711322290823
reward_mean: -110.94012605042013
reward_std: 8.254979502818697
reward_max: -106.08053221288513
reward_min: -128.65826330532207
queue_len: 0.0735677228451062
wait_time: 0.7060955792573439
delay_time: 4.750543749751734
pressure: 0.8881520778072503
total_envstep_count: 836592
total_train_sample_count: 836592
total_episode_count: 7212
total_duration: 47897.03809452128
[2024-12-26 14:57:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.01593442701674
avg_train_sample_per_sec: 16.01593442701674
avg_episode_per_sec: 0.13806840023290295
collect_time: 43.45672137780116
reward_mean: -113.52054154995331
reward_std: 10.47222380136316
reward_max: -105.24019607843134
reward_min: -134.5189075630252
queue_len: 0.07527887370686558
wait_time: 0.7250347199003385
delay_time: 4.808982235283552
pressure: 0.9066091954022988
total_envstep_count: 837288
total_train_sample_count: 837288
total_episode_count: 7218
total_duration: 47940.49481589908
[2024-12-26 14:58:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.927384232229862
avg_train_sample_per_sec: 15.927384232229862
avg_episode_per_sec: 0.13730503648474018
collect_time: 43.69832421017439
reward_mean: -112.62476657329597
reward_std: 9.399507609794368
reward_max: -105.24019607843134
reward_min: -130.80322128851543
queue_len: 0.07468485847035541
wait_time: 0.7145248683027589
delay_time: 4.783656538045738
pressure: 0.9021883289124668
total_envstep_count: 837984
total_train_sample_count: 837984
total_episode_count: 7224
total_duration: 47984.19314010926
[2024-12-26 14:58:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.209676810427844
avg_train_sample_per_sec: 16.209676810427844
avg_episode_per_sec: 0.13973859319334347
collect_time: 42.93731504580378
reward_mean: -107.87289915966385
reward_std: 5.8869030542090295
reward_max: -105.24019607843134
reward_min: -121.03641456582636
queue_len: 0.07153375275839777
wait_time: 0.683031689687369
delay_time: 4.62822449945781
pressure: 0.8656056587091069
total_envstep_count: 838680
total_train_sample_count: 838680
total_episode_count: 7230
total_duration: 48027.130455155064
[2024-12-26 14:59:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.697793004985776
avg_train_sample_per_sec: 15.697793004985776
avg_episode_per_sec: 0.13532580176711875
collect_time: 44.33744283536822
reward_mean: -116.00758636788048
reward_std: 12.571860650567771
reward_max: -105.24019607843134
reward_min: -134.97899159663868
queue_len: 0.07692810767100826
wait_time: 0.7354697294479241
delay_time: 5.003843993968545
pressure: 0.9258399646330681
total_envstep_count: 839376
total_train_sample_count: 839376
total_episode_count: 7236
total_duration: 48071.467897990435
[2024-12-26 15:00:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.995464469935344
avg_train_sample_per_sec: 15.995464469935344
avg_episode_per_sec: 0.1378919350856495
collect_time: 43.51233446882292
reward_mean: -110.11484593837531
reward_std: 7.660829309836009
reward_max: -105.24019607843134
reward_min: -126.17086834733887
queue_len: 0.07302045486629662
wait_time: 0.7005030128762381
delay_time: 4.752731715811687
pressure: 0.8807471264367814
total_envstep_count: 840072
total_train_sample_count: 840072
total_episode_count: 7242
total_duration: 48114.98023245926
[2024-12-26 15:00:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.148602136400907
avg_train_sample_per_sec: 17.148602136400907
avg_episode_per_sec: 0.14783277703793885
collect_time: 40.58639849848859
reward_mean: -112.41818394024274
reward_std: 8.620613116288656
reward_max: -105.24019607843134
reward_min: -127.63235294117652
queue_len: 0.07454786733437847
wait_time: 0.713324377054093
delay_time: 4.829495800622966
pressure: 0.8930150309460654
total_envstep_count: 840768
total_train_sample_count: 840768
total_episode_count: 7248
total_duration: 48155.56663095775
[2024-12-26 15:01:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.917913646928497
avg_train_sample_per_sec: 16.917913646928497
avg_episode_per_sec: 0.14584408316317668
collect_time: 41.13982459807396
reward_mean: -108.60270774976657
reward_std: 4.278660265400027
reward_max: -105.24019607843134
reward_min: -117.1295518207283
queue_len: 0.07201771070939426
wait_time: 0.6822026224282817
delay_time: 4.7182129430146995
pressure: 0.8684792219274978
total_envstep_count: 841464
total_train_sample_count: 841464
total_episode_count: 7254
total_duration: 48196.706455555825
[2024-12-26 15:02:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.070386985560987
avg_train_sample_per_sec: 18.070386985560987
avg_episode_per_sec: 0.1557791981513878
collect_time: 38.51605394816026
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 842160
total_train_sample_count: 842160
total_episode_count: 7260
total_duration: 48235.22250950398
[2024-12-26 15:02:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.292324487240872
avg_train_sample_per_sec: 17.292324487240872
avg_episode_per_sec: 0.14907176282104198
collect_time: 40.249071228887885
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 842856
total_train_sample_count: 842856
total_episode_count: 7266
total_duration: 48275.47158073287
[2024-12-26 15:03:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.63639169262712
avg_train_sample_per_sec: 17.63639169262712
avg_episode_per_sec: 0.15203785941919934
collect_time: 39.46385474592074
reward_mean: -106.26633986928103
reward_std: 1.9856003756596172
reward_max: -105.24019607843134
reward_min: -110.6659663865546
queue_len: 0.0704683951387805
wait_time: 0.6709597521590421
delay_time: 4.559761049083524
pressure: 0.8509062776304156
total_envstep_count: 843552
total_train_sample_count: 843552
total_episode_count: 7272
total_duration: 48314.93543547879
[2024-12-26 15:04:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45658568633943
avg_train_sample_per_sec: 17.45658568633943
avg_episode_per_sec: 0.15048780764085715
collect_time: 39.87033962458372
reward_mean: -109.18020541549953
reward_std: 5.574827957438085
reward_max: -105.24019607843134
reward_min: -117.36694677871147
queue_len: 0.07240066672115351
wait_time: 0.6887891872045016
delay_time: 4.693357674555883
pressure: 0.872236958443855
total_envstep_count: 844248
total_train_sample_count: 844248
total_episode_count: 7278
total_duration: 48354.80577510337
[2024-12-26 15:04:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.715262117962247
avg_train_sample_per_sec: 17.715262117962247
avg_episode_per_sec: 0.1527177768789849
collect_time: 39.2881570346225
reward_mean: -108.4580999066293
reward_std: 7.19545170490743
reward_max: -105.24019607843134
reward_min: -124.54761904761907
queue_len: 0.0719218169142104
wait_time: 0.6867864851510895
delay_time: 4.691135740428044
pressure: 0.8603006189213086
total_envstep_count: 844944
total_train_sample_count: 844944
total_episode_count: 7284
total_duration: 48394.09393213799
[2024-12-26 15:05:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.861095924184088
avg_train_sample_per_sec: 17.861095924184088
avg_episode_per_sec: 0.15397496486365594
collect_time: 38.96737372411788
reward_mean: -115.86402894491128
reward_std: 10.871223193689467
reward_max: -105.24019607843134
reward_min: -130.52661064425772
queue_len: 0.0768329104409226
wait_time: 0.7425983766627781
delay_time: 4.859149306969491
pressure: 0.923076923076923
total_envstep_count: 845640
total_train_sample_count: 845640
total_episode_count: 7290
total_duration: 48433.06130586211
[2024-12-26 15:06:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.638769876361398
avg_train_sample_per_sec: 17.638769876361398
avg_episode_per_sec: 0.1520583610031155
collect_time: 39.45853394985013
reward_mean: -123.45366479925303
reward_std: 2.7427297140146796
reward_max: -118.32633053221285
reward_min: -126.62324929971994
queue_len: 0.08186582546369564
wait_time: 0.7970682968147472
delay_time: 5.139119378570812
pressure: 0.9881741821396993
total_envstep_count: 846336
total_train_sample_count: 846336
total_episode_count: 7296
total_duration: 48472.51983981196
[2024-12-26 15:06:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.672133990929595
avg_train_sample_per_sec: 17.672133990929595
avg_episode_per_sec: 0.15234598268042754
collect_time: 39.3840381901376
reward_mean: -112.19140989729222
reward_std: 3.1961981259533983
reward_max: -105.24019607843134
reward_min: -114.73669467787113
queue_len: 0.07439748666929194
wait_time: 0.7077078952712826
delay_time: 4.898204128256483
pressure: 0.8900309460654287
total_envstep_count: 847032
total_train_sample_count: 847032
total_episode_count: 7302
total_duration: 48511.9038780021
[2024-12-26 15:07:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.171061978620923
avg_train_sample_per_sec: 18.171061978620923
avg_episode_per_sec: 0.15664708602259414
collect_time: 38.30265951538086
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 847728
total_train_sample_count: 847728
total_episode_count: 7308
total_duration: 48550.20653751748
[2024-12-26 15:08:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.80807246930105
avg_train_sample_per_sec: 17.80807246930105
avg_episode_per_sec: 0.15351786611466423
collect_time: 39.08339890236966
reward_mean: -115.19444444444441
reward_std: 0.815413738841015
reward_max: -113.8949579831933
reward_min: -116.44817927170864
queue_len: 0.07638888888888885
wait_time: 0.7331169647346117
delay_time: 4.918049103362518
pressure: 0.9174403183023871
total_envstep_count: 848424
total_train_sample_count: 848424
total_episode_count: 7314
total_duration: 48589.289936419846
[2024-12-26 15:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.887275212601853
avg_train_sample_per_sec: 17.887275212601853
avg_episode_per_sec: 0.15420064838449873
collect_time: 38.910342225274064
reward_mean: -110.17728758169932
reward_std: 8.175335347293766
reward_max: -105.24019607843134
reward_min: -128.12254901960782
queue_len: 0.0730618617915778
wait_time: 0.6996433741489522
delay_time: 4.689199921761349
pressure: 0.8819628647214853
total_envstep_count: 849120
total_train_sample_count: 849120
total_episode_count: 7320
total_duration: 48628.20027864512
[2024-12-26 15:09:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.935094331451435
avg_train_sample_per_sec: 17.935094331451435
avg_episode_per_sec: 0.1546128821676848
collect_time: 38.806598233468826
reward_mean: -106.33648459383751
reward_std: 2.4513756434005267
reward_max: -105.24019607843134
reward_min: -111.81792717086837
queue_len: 0.07051491020811505
wait_time: 0.673625971166539
delay_time: 4.586422197023402
pressure: 0.8470380194518126
total_envstep_count: 849816
total_train_sample_count: 849816
total_episode_count: 7326
total_duration: 48667.006876878586
[2024-12-26 15:10:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.471878792111898
avg_train_sample_per_sec: 17.471878792111898
avg_episode_per_sec: 0.15061964475958534
collect_time: 39.83544118416309
reward_mean: -107.87896825396824
reward_std: 3.886463025322413
reward_max: -105.24019607843134
reward_min: -116.3249299719888
queue_len: 0.07153777735674285
wait_time: 0.6817466044773347
delay_time: 4.588312757488718
pressure: 0.8653846153846154
total_envstep_count: 850512
total_train_sample_count: 850512
total_episode_count: 7332
total_duration: 48706.84231806275
[2024-12-26 15:10:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.669536160186002
avg_train_sample_per_sec: 17.669536160186002
avg_episode_per_sec: 0.15232358758781037
collect_time: 39.38982855522074
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 851208
total_train_sample_count: 851208
total_episode_count: 7338
total_duration: 48746.23214661797
[2024-12-26 15:11:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.625164687761977
avg_train_sample_per_sec: 16.625164687761977
avg_episode_per_sec: 0.14332038523932739
collect_time: 41.86424694561586
reward_mean: -119.52100840336134
reward_std: 9.917949894790537
reward_max: -105.24019607843134
reward_min: -135.31232492997194
queue_len: 0.07925796313220247
wait_time: 0.7651006799713697
delay_time: 5.04115060839055
pressure: 0.9454022988505747
total_envstep_count: 851904
total_train_sample_count: 851904
total_episode_count: 7344
total_duration: 48788.09639356359
[2024-12-26 15:12:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.818174618724097
avg_train_sample_per_sec: 17.818174618724097
avg_episode_per_sec: 0.15360495360969048
collect_time: 39.06124027253687
reward_mean: -111.24591503267972
reward_std: 8.530388540281736
reward_max: -105.24019607843134
reward_min: -124.6323529411765
queue_len: 0.07377050068480087
wait_time: 0.7062165493960627
delay_time: 4.742106200414916
pressure: 0.8905835543766578
total_envstep_count: 852600
total_train_sample_count: 852600
total_episode_count: 7350
total_duration: 48827.15763383613
[2024-12-26 15:12:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.467672529938515
avg_train_sample_per_sec: 17.467672529938515
avg_episode_per_sec: 0.15058338387878029
collect_time: 39.845033664736896
reward_mean: -115.83426704014938
reward_std: 10.155398199701157
reward_max: -105.24019607843134
reward_min: -127.96988795518209
queue_len: 0.07681317442980727
wait_time: 0.7373342794235288
delay_time: 4.852615259121356
pressure: 0.9223032714412026
total_envstep_count: 853296
total_train_sample_count: 853296
total_episode_count: 7356
total_duration: 48867.00266750086
[2024-12-26 15:13:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.504053070213008
avg_train_sample_per_sec: 16.504053070213008
avg_episode_per_sec: 0.1422763195708018
collect_time: 42.171459158487615
reward_mean: -107.74719887955179
reward_std: 5.28562002353384
reward_max: -105.24019607843134
reward_min: -119.55112044817923
queue_len: 0.07145039713498129
wait_time: 0.6832489406018816
delay_time: 4.607781439871538
pressure: 0.8642793987621573
total_envstep_count: 853992
total_train_sample_count: 853992
total_episode_count: 7362
total_duration: 48909.17412665935
[2024-12-26 15:14:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.914099737127007
avg_train_sample_per_sec: 16.914099737127007
avg_episode_per_sec: 0.14581120463040523
collect_time: 41.14910109417512
reward_mean: -106.75735294117645
reward_std: 3.077113306096919
reward_max: -105.24019607843134
reward_min: -113.61204481792717
queue_len: 0.07079400062412232
wait_time: 0.676010700478246
delay_time: 4.59531771385315
pressure: 0.8537798408488064
total_envstep_count: 854688
total_train_sample_count: 854688
total_episode_count: 7368
total_duration: 48950.32322775353
[2024-12-26 15:15:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.155141097097694
avg_train_sample_per_sec: 17.155141097097694
avg_episode_per_sec: 0.1478891473887732
collect_time: 40.57092833341658
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 855384
total_train_sample_count: 855384
total_episode_count: 7374
total_duration: 48990.89415608694
[2024-12-26 15:15:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.248953117268076
avg_train_sample_per_sec: 17.248953117268076
avg_episode_per_sec: 0.14869787170058688
collect_time: 40.35027489889971
reward_mean: -107.49463118580763
reward_std: 5.041070150955408
reward_max: -105.24019607843134
reward_min: -118.76680672268904
queue_len: 0.07128291192692814
wait_time: 0.6804951865803792
delay_time: 4.625412620663428
pressure: 0.8577586206896552
total_envstep_count: 856080
total_train_sample_count: 856080
total_episode_count: 7380
total_duration: 49031.24443098584
[2024-12-26 15:16:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.47087379952311
avg_train_sample_per_sec: 17.47087379952311
avg_episode_per_sec: 0.15061098103037163
collect_time: 39.83773267362267
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 856776
total_train_sample_count: 856776
total_episode_count: 7386
total_duration: 49071.08216365946
[2024-12-26 15:17:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.8156300198086
avg_train_sample_per_sec: 17.8156300198086
avg_episode_per_sec: 0.1535830174121431
collect_time: 39.06681937299668
reward_mean: -105.4144491129785
reward_std: 0.38964163053304524
reward_max: -105.24019607843134
reward_min: -106.28571428571423
queue_len: 0.06990348084415018
wait_time: 0.6652794185755645
delay_time: 4.547169495741871
pressure: 0.8440539345711758
total_envstep_count: 857472
total_train_sample_count: 857472
total_episode_count: 7392
total_duration: 49110.14898303246
[2024-12-26 15:17:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.803386574494223
avg_train_sample_per_sec: 17.803386574494223
avg_episode_per_sec: 0.15347747046977778
collect_time: 39.09368574836851
reward_mean: -109.18312324929968
reward_std: 8.446418962638255
reward_max: -105.24019607843134
reward_min: -128.05742296918766
queue_len: 0.07240260162420405
wait_time: 0.6907908057122052
delay_time: 4.6801671139573955
pressure: 0.873894783377542
total_envstep_count: 858168
total_train_sample_count: 858168
total_episode_count: 7398
total_duration: 49149.242668780826
[2024-12-26 15:18:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.777758191442423
avg_train_sample_per_sec: 17.777758191442423
avg_episode_per_sec: 0.15325653613312432
collect_time: 39.15004313283041
reward_mean: -111.4768907563025
reward_std: 6.2494069895761495
reward_max: -105.24019607843134
reward_min: -119.1050420168067
queue_len: 0.07392366761028017
wait_time: 0.7082824066850435
delay_time: 4.726024234695344
pressure: 0.8942307692307692
total_envstep_count: 858864
total_train_sample_count: 858864
total_episode_count: 7404
total_duration: 49188.39271191366
[2024-12-26 15:19:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.601659666355765
avg_train_sample_per_sec: 17.601659666355765
avg_episode_per_sec: 0.15173844539961867
collect_time: 39.54172579136677
reward_mean: -105.25408496732022
reward_std: 0.031056499687490018
reward_max: -105.24019607843134
reward_min: -105.32352941176465
queue_len: 0.06979713857249352
wait_time: 0.664075831482018
delay_time: 4.5484676196459
pressure: 0.8430592396109637
total_envstep_count: 859560
total_train_sample_count: 859560
total_episode_count: 7410
total_duration: 49227.93443770502
[2024-12-26 15:19:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.635112888617343
avg_train_sample_per_sec: 17.635112888617343
avg_episode_per_sec: 0.15202683524670124
collect_time: 39.46671645347028
reward_mean: -106.19817927170867
reward_std: 2.14211554147039
reward_max: -105.24019607843134
reward_min: -110.98809523809521
queue_len: 0.07042319580352031
wait_time: 0.6712322639046775
delay_time: 4.577166911174386
pressure: 0.8499115826702033
total_envstep_count: 860256
total_train_sample_count: 860256
total_episode_count: 7416
total_duration: 49267.40115415849
[2024-12-26 15:20:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.830413005703623
avg_train_sample_per_sec: 17.830413005703623
avg_episode_per_sec: 0.15371045694572089
collect_time: 39.034429532134915
reward_mean: -108.797152194211
reward_std: 7.953595667866912
reward_max: -105.24019607843134
reward_min: -126.58193277310924
queue_len: 0.07214665264868103
wait_time: 0.6904650454346194
delay_time: 4.68520304045352
pressure: 0.8717948717948718
total_envstep_count: 860952
total_train_sample_count: 860952
total_episode_count: 7422
total_duration: 49306.435583690625
[2024-12-26 15:21:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.86376738460512
avg_train_sample_per_sec: 17.86376738460512
avg_episode_per_sec: 0.15399799469487171
collect_time: 38.961546297328546
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 861648
total_train_sample_count: 861648
total_episode_count: 7428
total_duration: 49345.397129987956
[2024-12-26 15:21:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.438404770134714
avg_train_sample_per_sec: 17.438404770134714
avg_episode_per_sec: 0.1503310756046096
collect_time: 39.911907607052484
reward_mean: -106.81547619047616
reward_std: 3.522433414135698
reward_max: -105.24019607843134
reward_min: -114.69187675070025
queue_len: 0.07083254389288869
wait_time: 0.6753033773190973
delay_time: 4.55297734053084
pressure: 0.8557692307692308
total_envstep_count: 862344
total_train_sample_count: 862344
total_episode_count: 7434
total_duration: 49385.309037595005
[2024-12-26 15:22:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51686243972272
avg_train_sample_per_sec: 17.51686243972272
avg_episode_per_sec: 0.15100743482519585
collect_time: 39.73314298693649
reward_mean: -106.63246965452846
reward_std: 2.261756079986236
reward_max: -105.24019607843134
reward_min: -111.58963585434172
queue_len: 0.07071118677355999
wait_time: 0.6713201085031711
delay_time: 4.582605831307752
pressure: 0.8535587975243146
total_envstep_count: 863040
total_train_sample_count: 863040
total_episode_count: 7440
total_duration: 49425.04218058194
[2024-12-26 15:23:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.625091793410565
avg_train_sample_per_sec: 17.625091793410565
avg_episode_per_sec: 0.15194044649491867
collect_time: 39.4891560372021
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 863736
total_train_sample_count: 863736
total_episode_count: 7446
total_duration: 49464.53133661915
[2024-12-26 15:23:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.24395998331514
avg_train_sample_per_sec: 18.24395998331514
avg_episode_per_sec: 0.15727551709754428
collect_time: 38.14961229012347
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 864432
total_train_sample_count: 864432
total_episode_count: 7452
total_duration: 49502.68094890927
[2024-12-26 15:24:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75348606958907
avg_train_sample_per_sec: 17.75348606958907
avg_episode_per_sec: 0.15304729370335404
collect_time: 39.20356809202768
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 865128
total_train_sample_count: 865128
total_episode_count: 7458
total_duration: 49541.8845170013
[2024-12-26 15:25:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.676430045122284
avg_train_sample_per_sec: 17.676430045122284
avg_episode_per_sec: 0.1523830176303645
collect_time: 39.374466350011524
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 865824
total_train_sample_count: 865824
total_episode_count: 7464
total_duration: 49581.25898335131
[2024-12-26 15:25:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.195648064716018
avg_train_sample_per_sec: 18.195648064716018
avg_episode_per_sec: 0.15685903504065535
collect_time: 38.250904695702715
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 866520
total_train_sample_count: 866520
total_episode_count: 7470
total_duration: 49619.50988804702
[2024-12-26 15:26:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.773784335716925
avg_train_sample_per_sec: 17.773784335716925
avg_episode_per_sec: 0.1532222787561804
collect_time: 39.158796284107495
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 867216
total_train_sample_count: 867216
total_episode_count: 7476
total_duration: 49658.668684331125
[2024-12-26 15:27:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.811655670646658
avg_train_sample_per_sec: 17.811655670646658
avg_episode_per_sec: 0.1535487557814367
collect_time: 39.07553642792442
reward_mean: -107.45681605975722
reward_std: 4.956512958528966
reward_max: -105.24019607843134
reward_min: -118.53991596638657
queue_len: 0.07125783558339337
wait_time: 0.6783740684602751
delay_time: 4.652046812767301
pressure: 0.8548850574712642
total_envstep_count: 867912
total_train_sample_count: 867912
total_episode_count: 7482
total_duration: 49697.74422075905
[2024-12-26 15:27:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.734540151317265
avg_train_sample_per_sec: 17.734540151317265
avg_episode_per_sec: 0.15288396682170058
collect_time: 39.24544950483553
reward_mean: -106.03478057889821
reward_std: 1.7767449569116045
reward_max: -105.24019607843134
reward_min: -110.00770308123248
queue_len: 0.0703148412326911
wait_time: 0.6681500407413186
delay_time: 4.580766519253049
pressure: 0.8464854111405834
total_envstep_count: 868608
total_train_sample_count: 868608
total_episode_count: 7488
total_duration: 49736.98967026389
[2024-12-26 15:28:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.603956526266796
avg_train_sample_per_sec: 17.603956526266796
avg_episode_per_sec: 0.15175824591609308
collect_time: 39.53656662134453
reward_mean: -105.36204481792714
reward_std: 0.27246206448527416
reward_max: -105.24019607843134
reward_min: -105.97128851540614
queue_len: 0.06986872998536282
wait_time: 0.6648771909294221
delay_time: 4.547882618063228
pressure: 0.8438328912466843
total_envstep_count: 869304
total_train_sample_count: 869304
total_episode_count: 7494
total_duration: 49776.526236885235
[2024-12-26 15:29:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.823738947758233
avg_train_sample_per_sec: 17.823738947758233
avg_episode_per_sec: 0.15365292196343303
collect_time: 39.04904588425533
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 870000
total_train_sample_count: 870000
total_episode_count: 7500
total_duration: 49815.57528276949
[2024-12-26 15:29:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.380858166457525
avg_train_sample_per_sec: 17.380858166457525
avg_episode_per_sec: 0.14983498419359934
collect_time: 40.04405267762766
reward_mean: -108.937908496732
reward_std: 8.26833632856542
reward_max: -105.24019607843134
reward_min: -127.42647058823532
queue_len: 0.07223999237183819
wait_time: 0.6892212897537441
delay_time: 4.670798652718774
pressure: 0.8770999115826701
total_envstep_count: 870696
total_train_sample_count: 870696
total_episode_count: 7506
total_duration: 49855.61933544712
[2024-12-26 15:30:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.63403338999164
avg_train_sample_per_sec: 17.63403338999164
avg_episode_per_sec: 0.15201752922406586
collect_time: 39.469132478507234
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 871392
total_train_sample_count: 871392
total_episode_count: 7512
total_duration: 49895.08846792563
[2024-12-26 15:31:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.621035636761423
avg_train_sample_per_sec: 17.621035636761423
avg_episode_per_sec: 0.15190547962725365
collect_time: 39.49824597982131
reward_mean: -114.99124649859944
reward_std: 9.868983607864665
reward_max: -105.24019607843134
reward_min: -127.7422969187675
queue_len: 0.07625414224045053
wait_time: 0.7337242147079874
delay_time: 4.835367647915602
pressure: 0.9251768346595931
total_envstep_count: 872088
total_train_sample_count: 872088
total_episode_count: 7518
total_duration: 49934.586713905446
[2024-12-26 15:31:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.02629365530375
avg_train_sample_per_sec: 18.02629365530375
avg_episode_per_sec: 0.15539908323537716
collect_time: 38.61026638691314
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 872784
total_train_sample_count: 872784
total_episode_count: 7524
total_duration: 49973.196980292356
[2024-12-26 15:32:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.763662797763526
avg_train_sample_per_sec: 17.763662797763526
avg_episode_per_sec: 0.15313502411865107
collect_time: 39.18110853171721
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 873480
total_train_sample_count: 873480
total_episode_count: 7530
total_duration: 50012.37808882407
[2024-12-26 15:33:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.81994332373158
avg_train_sample_per_sec: 17.81994332373158
avg_episode_per_sec: 0.15362020106665156
collect_time: 39.057363278653476
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 874176
total_train_sample_count: 874176
total_episode_count: 7536
total_duration: 50051.43545210273
[2024-12-26 15:33:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.724314834061715
avg_train_sample_per_sec: 17.724314834061715
avg_episode_per_sec: 0.15279581753501478
collect_time: 39.268090558990835
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 874872
total_train_sample_count: 874872
total_episode_count: 7542
total_duration: 50090.703542661715
[2024-12-26 15:34:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.587088398672815
avg_train_sample_per_sec: 17.587088398672815
avg_episode_per_sec: 0.15161283102304152
collect_time: 39.57448693170398
reward_mean: -107.10772642390286
reward_std: 4.175924802518001
reward_max: -105.24019607843134
reward_min: -116.4453781512605
queue_len: 0.07102634378242896
wait_time: 0.676289016933033
delay_time: 4.601133011389394
pressure: 0.8594164456233422
total_envstep_count: 875568
total_train_sample_count: 875568
total_episode_count: 7548
total_duration: 50130.27802959342
[2024-12-26 15:35:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.914080716274555
avg_train_sample_per_sec: 17.914080716274555
avg_episode_per_sec: 0.15443173031271168
collect_time: 38.852119236445056
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 876264
total_train_sample_count: 876264
total_episode_count: 7554
total_duration: 50169.13014882986
[2024-12-26 15:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.97473689903765
avg_train_sample_per_sec: 17.97473689903765
avg_episode_per_sec: 0.15495462843997976
collect_time: 38.72101182394848
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 876960
total_train_sample_count: 876960
total_episode_count: 7560
total_duration: 50207.85116065381
[2024-12-26 15:36:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.615714214764264
avg_train_sample_per_sec: 17.615714214764264
avg_episode_per_sec: 0.15185960529969192
collect_time: 39.51017776030116
reward_mean: -108.00151727357608
reward_std: 6.174501900054587
reward_max: -105.24019607843134
reward_min: -121.80812324929974
queue_len: 0.07161904328486476
wait_time: 0.680750438990804
delay_time: 4.649417743701637
pressure: 0.8646109637488948
total_envstep_count: 877656
total_train_sample_count: 877656
total_episode_count: 7566
total_duration: 50247.361338414106
[2024-12-26 15:37:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.780951791839612
avg_train_sample_per_sec: 17.780951791839612
avg_episode_per_sec: 0.15328406717103113
collect_time: 39.14301147362776
reward_mean: -105.24019607843134
reward_std: 0.0
reward_max: -105.24019607843134
reward_min: -105.24019607843134
queue_len: 0.06978792843397304
wait_time: 0.66403875873957
delay_time: 4.546289526291701
pressure: 0.842838196286472
total_envstep_count: 878352
total_train_sample_count: 878352
total_episode_count: 7572
total_duration: 50286.504349887735
[2024-12-26 15:37:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.75892456184786
avg_train_sample_per_sec: 17.75892456184786
avg_episode_per_sec: 0.15309417725730912
collect_time: 39.191562393099076
reward_mean: -117.82481325863678
reward_std: 0.5673507110689701
reward_max: -117.13585434173675
reward_min: -118.8795518207283
queue_len: 0.0781331652908732
wait_time: 0.7537072742447998
delay_time: 4.961964940027496
pressure: 0.9562334217506631
total_envstep_count: 879048
total_train_sample_count: 879048
total_episode_count: 7578
total_duration: 50325.69591228083
[2024-12-26 15:38:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.441840407473975
avg_train_sample_per_sec: 17.441840407473975
avg_episode_per_sec: 0.1503606931678791
collect_time: 39.90404588851519
reward_mean: -126.26914098972924
reward_std: 5.1096586507710535
reward_max: -117.41666666666671
reward_min: -132.6148459383753
queue_len: 0.08373285211520505
wait_time: 0.8183130679327436
delay_time: 5.2820277516049625
pressure: 1.0216622458001767
total_envstep_count: 879744
total_train_sample_count: 879744
total_episode_count: 7584
total_duration: 50365.59995816935
[2024-12-26 15:39:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.43911202908321
avg_train_sample_per_sec: 17.43911202908321
avg_episode_per_sec: 0.1503371726645104
collect_time: 39.91028894357011
reward_mean: -122.94187675070027
reward_std: 5.640357463465529
reward_max: -117.44117647058822
reward_min: -133.7878151260504
queue_len: 0.08152644346863415
wait_time: 0.7857273656589072
delay_time: 5.124793885141181
pressure: 0.9878426171529621
total_envstep_count: 880440
total_train_sample_count: 880440
total_episode_count: 7590
total_duration: 50405.510247112914
[2024-12-26 15:39:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.574801311022572
avg_train_sample_per_sec: 17.574801311022572
avg_episode_per_sec: 0.15150690785364285
collect_time: 39.60215468060412
reward_mean: -121.18218954248364
reward_std: 3.3988677336996
reward_max: -116.13305322128848
reward_min: -126.03221288515404
queue_len: 0.08035954213692549
wait_time: 0.7736604588785116
delay_time: 5.071865886303283
pressure: 0.9690539345711758
total_envstep_count: 881136
total_train_sample_count: 881136
total_episode_count: 7596
total_duration: 50445.112401793514
[2024-12-26 15:40:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35012658487083
avg_train_sample_per_sec: 17.35012658487083
avg_episode_per_sec: 0.14957005676612783
collect_time: 40.114981097999966
reward_mean: -115.6824229691877
reward_std: 2.3855525105490076
reward_max: -113.42226890756302
reward_min: -120.65196078431369
queue_len: 0.07671248207505814
wait_time: 0.7352116133809846
delay_time: 4.842781995638142
pressure: 0.9325817860300619
total_envstep_count: 881832
total_train_sample_count: 881832
total_episode_count: 7602
total_duration: 50485.22738289151
[2024-12-26 15:41:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.316790175719152
avg_train_sample_per_sec: 17.316790175719152
avg_episode_per_sec: 0.14928267392861339
collect_time: 40.19220611542091
reward_mean: -119.031045751634
reward_std: 6.699750217189878
reward_max: -110.07843137254905
reward_min: -131.6330532212885
queue_len: 0.07893305421195888
wait_time: 0.7637418362570493
delay_time: 4.928866428519648
pressure: 0.9561229000884174
total_envstep_count: 882528
total_train_sample_count: 882528
total_episode_count: 7608
total_duration: 50525.41958900693
[2024-12-26 15:41:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.348665317053168
avg_train_sample_per_sec: 17.348665317053168
avg_episode_per_sec: 0.1495574596297687
collect_time: 40.118359959129236
reward_mean: -118.2954014939309
reward_std: 2.6413093073383487
reward_max: -115.9362745098039
reward_min: -123.85224089635857
queue_len: 0.07844522645486135
wait_time: 0.7533411131915191
delay_time: 4.950979251610557
pressure: 0.9491600353669319
total_envstep_count: 883224
total_train_sample_count: 883224
total_episode_count: 7614
total_duration: 50565.53794896606
[2024-12-26 15:42:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.471401101383766
avg_train_sample_per_sec: 17.471401101383766
avg_episode_per_sec: 0.15061552673606696
collect_time: 39.83653033670411
reward_mean: -121.68919234360408
reward_std: 6.069509032236962
reward_max: -114.02941176470584
reward_min: -130.8543417366947
queue_len: 0.08069575089098414
wait_time: 0.7714006469077463
delay_time: 5.113158748559718
pressure: 0.9815428824049514
total_envstep_count: 883920
total_train_sample_count: 883920
total_episode_count: 7620
total_duration: 50605.374479302765
[2024-12-26 15:43:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.43710884653021
avg_train_sample_per_sec: 17.43710884653021
avg_episode_per_sec: 0.15031990384939836
collect_time: 39.9148738547042
reward_mean: -123.8314659197012
reward_std: 4.600364019151824
reward_max: -115.67086834733895
reward_min: -131.53011204481797
queue_len: 0.08211635671067719
wait_time: 0.7824086199466525
delay_time: 5.166817059069932
pressure: 0.9953580901856763
total_envstep_count: 884616
total_train_sample_count: 884616
total_episode_count: 7626
total_duration: 50645.28935315747
[2024-12-26 15:43:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.58696523353085
avg_train_sample_per_sec: 17.58696523353085
avg_episode_per_sec: 0.1516117692545763
collect_time: 39.57476407999172
reward_mean: -117.8046218487395
reward_std: 3.0252181080659084
reward_max: -113.86344537815127
reward_min: -123.09663865546216
queue_len: 0.07811977576176359
wait_time: 0.74505988292753
delay_time: 4.906158999154434
pressure: 0.9426392572944297
total_envstep_count: 885312
total_train_sample_count: 885312
total_episode_count: 7632
total_duration: 50684.864117237456
[2024-12-26 15:44:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.89373061055705
avg_train_sample_per_sec: 17.89373061055705
avg_episode_per_sec: 0.15425629836687113
collect_time: 38.89630480909161
reward_mean: -117.43615779645192
reward_std: 3.3811341524381056
reward_max: -113.55252100840333
reward_min: -122.34313725490193
queue_len: 0.07787543620454371
wait_time: 0.7441416553358744
delay_time: 4.826988900879715
pressure: 0.9450707338638372
total_envstep_count: 886008
total_train_sample_count: 886008
total_episode_count: 7638
total_duration: 50723.760422046544
[2024-12-26 15:45:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.403502617847195
avg_train_sample_per_sec: 17.403502617847195
avg_episode_per_sec: 0.15003019498144135
collect_time: 39.99194962548837
reward_mean: -122.9813258636788
reward_std: 6.5595482644163505
reward_max: -116.29761904761907
reward_min: -131.68837535014003
queue_len: 0.08155260335787719
wait_time: 0.7817320230479462
delay_time: 5.084027217981532
pressure: 0.998342175066313
total_envstep_count: 886704
total_train_sample_count: 886704
total_episode_count: 7644
total_duration: 50763.75237167203
[2024-12-26 15:45:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.449023450714165
avg_train_sample_per_sec: 17.449023450714165
avg_episode_per_sec: 0.15042261595443246
collect_time: 39.887619038732716
reward_mean: -126.17296918767506
reward_std: 3.6760085521773562
reward_max: -121.04341736694677
reward_min: -131.42857142857142
queue_len: 0.08366907771065984
wait_time: 0.8034693430864831
delay_time: 5.327034198516652
pressure: 1.0129310344827587
total_envstep_count: 887400
total_train_sample_count: 887400
total_episode_count: 7650
total_duration: 50803.63999071076
[2024-12-26 15:46:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.306682870579518
avg_train_sample_per_sec: 17.306682870579518
avg_episode_per_sec: 0.14919554198775448
collect_time: 40.215678833704445
reward_mean: -125.26937441643325
reward_std: 3.003872108343465
reward_max: -121.74649859943978
reward_min: -130.89775910364142
queue_len: 0.08306987693397429
wait_time: 0.797924452716542
delay_time: 5.228817875166897
pressure: 0.9945844385499557
total_envstep_count: 888096
total_train_sample_count: 888096
total_episode_count: 7656
total_duration: 50843.855669544464
[2024-12-26 15:47:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.383677005088913
avg_train_sample_per_sec: 17.383677005088913
avg_episode_per_sec: 0.14985928452662856
collect_time: 40.03755936078727
reward_mean: -122.30917366946778
reward_std: 7.558691922986696
reward_max: -114.33263305322127
reward_min: -137.46218487394958
queue_len: 0.081106879091159
wait_time: 0.7738501567735848
delay_time: 5.206770069380048
pressure: 0.9820954907161803
total_envstep_count: 888792
total_train_sample_count: 888792
total_episode_count: 7662
total_duration: 50883.89322890525
[2024-12-26 15:47:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.56270679072377
avg_train_sample_per_sec: 17.56270679072377
avg_episode_per_sec: 0.1514026447476187
collect_time: 39.6294266193416
reward_mean: -116.4919467787115
reward_std: 2.703113003434441
reward_max: -113.60714285714285
reward_min: -120.90966386554625
queue_len: 0.07724930157739489
wait_time: 0.7316136224604786
delay_time: 4.877033184391219
pressure: 0.9347922192749779
total_envstep_count: 889488
total_train_sample_count: 889488
total_episode_count: 7668
total_duration: 50923.5226555246
[2024-12-26 15:48:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.278962129813863
avg_train_sample_per_sec: 17.278962129813863
avg_episode_per_sec: 0.14895657008460225
collect_time: 40.28019708423874
reward_mean: -118.01307189542484
reward_std: 2.4803770212058978
reward_max: -113.89985994397759
reward_min: -121.03431372549025
queue_len: 0.07825800523569287
wait_time: 0.7467523813238824
delay_time: 4.970856320481967
pressure: 0.9503757736516358
total_envstep_count: 890184
total_train_sample_count: 890184
total_episode_count: 7674
total_duration: 50963.80285260884
[2024-12-26 15:49:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.3723986496643
avg_train_sample_per_sec: 17.3723986496643
avg_episode_per_sec: 0.14976205732469225
collect_time: 40.06355219193921
reward_mean: -118.02684407096173
reward_std: 3.4745042991444555
reward_max: -113.39495798319328
reward_min: -123.83753501400562
queue_len: 0.07826713797809133
wait_time: 0.7458006412113916
delay_time: 4.878724209340652
pressure: 0.9521441202475686
total_envstep_count: 890880
total_train_sample_count: 890880
total_episode_count: 7680
total_duration: 51003.86640480078
[2024-12-26 15:49:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.68779539350623
avg_train_sample_per_sec: 17.68779539350623
avg_episode_per_sec: 0.15248099477160545
collect_time: 39.34916616321355
reward_mean: -118.61659663865544
reward_std: 2.8633152964674236
reward_max: -113.52731092436973
reward_min: -121.45868347338934
queue_len: 0.07865822058266275
wait_time: 0.7544631247724553
delay_time: 5.008632265882538
pressure: 0.9447391688771
total_envstep_count: 891576
total_train_sample_count: 891576
total_episode_count: 7686
total_duration: 51043.21557096399
[2024-12-26 15:50:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.49425017376157
avg_train_sample_per_sec: 17.49425017376157
avg_episode_per_sec: 0.1508125014979446
collect_time: 39.784500226473426
reward_mean: -121.81886087768441
reward_std: 3.2714884062529346
reward_max: -117.76120448179272
reward_min: -128.31582633053216
queue_len: 0.08078173798254935
wait_time: 0.7798961096374891
delay_time: 5.093076098239192
pressure: 0.9773430592396108
total_envstep_count: 892272
total_train_sample_count: 892272
total_episode_count: 7692
total_duration: 51083.000071190465
[2024-12-26 15:51:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.160396842087053
avg_train_sample_per_sec: 17.160396842087053
avg_episode_per_sec: 0.1479344555352332
collect_time: 40.55850260368176
reward_mean: -117.12231559290382
reward_std: 6.337434287218022
reward_max: -112.39355742296917
reward_min: -130.5182072829132
queue_len: 0.0776673180324296
wait_time: 0.7378175408094272
delay_time: 4.968649355674542
pressure: 0.9414235190097258
total_envstep_count: 892968
total_train_sample_count: 892968
total_episode_count: 7698
total_duration: 51123.558573794144
[2024-12-26 15:51:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.490396350782312
avg_train_sample_per_sec: 17.490396350782312
avg_episode_per_sec: 0.1507792788860544
collect_time: 39.79326631833985
reward_mean: -118.57236227824463
reward_std: 3.977868727785995
reward_max: -112.71638655462182
reward_min: -122.19607843137258
queue_len: 0.07862888745241686
wait_time: 0.7485220436538896
delay_time: 5.011615056856858
pressure: 0.9510389036251105
total_envstep_count: 893664
total_train_sample_count: 893664
total_episode_count: 7704
total_duration: 51163.35184011248
[2024-12-26 15:52:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.77881641649281
avg_train_sample_per_sec: 16.77881641649281
avg_episode_per_sec: 0.1446449691076966
collect_time: 41.4808758093249
reward_mean: -124.14437441643325
reward_std: 8.769070201663077
reward_max: -112.71638655462182
reward_min: -135.500700280112
queue_len: 0.08232385571381515
wait_time: 0.7945647644557378
delay_time: 5.228343515323272
pressure: 0.9912687886825817
total_envstep_count: 894360
total_train_sample_count: 894360
total_episode_count: 7710
total_duration: 51204.83271592181
[2024-12-26 15:53:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.287281359695882
avg_train_sample_per_sec: 17.287281359695882
avg_episode_per_sec: 0.1490282875835852
collect_time: 40.26081287845968
reward_mean: -121.0374649859944
reward_std: 8.427405230135285
reward_max: -113.82282913165264
reward_min: -136.4600840336134
queue_len: 0.08026357094561963
wait_time: 0.7645288000257574
delay_time: 5.010952898639082
pressure: 0.9686118479221927
total_envstep_count: 895056
total_train_sample_count: 895056
total_episode_count: 7716
total_duration: 51245.09352880027
[2024-12-26 15:53:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25370481314665
avg_train_sample_per_sec: 17.25370481314665
avg_episode_per_sec: 0.14873883459609183
collect_time: 40.33916237338633
reward_mean: -115.79668534080297
reward_std: 2.6262068321507073
reward_max: -112.71638655462182
reward_min: -121.06232492997194
queue_len: 0.07678825287851655
wait_time: 0.7300987481641639
delay_time: 4.873870276920463
pressure: 0.9328028293545535
total_envstep_count: 895752
total_train_sample_count: 895752
total_episode_count: 7722
total_duration: 51285.43269117366
[2024-12-26 15:54:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.325224880014613
avg_train_sample_per_sec: 17.325224880014613
avg_episode_per_sec: 0.1493553868966777
collect_time: 40.17263872879744
reward_mean: -117.50560224089635
reward_std: 2.455831500403902
reward_max: -115.11204481792716
reward_min: -122.39145658263307
queue_len: 0.07792148689714613
wait_time: 0.7483430264236554
delay_time: 4.9750057749136145
pressure: 0.9387709991158267
total_envstep_count: 896448
total_train_sample_count: 896448
total_episode_count: 7728
total_duration: 51325.60532990246
[2024-12-26 15:55:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.634861362130078
avg_train_sample_per_sec: 17.634861362130078
avg_episode_per_sec: 0.15202466691491445
collect_time: 39.467279368275776
reward_mean: -117.80929038281978
reward_std: 1.636411516465733
reward_max: -115.84383753501399
reward_min: -119.88585434173667
queue_len: 0.07812287160664443
wait_time: 0.7529543647697805
delay_time: 4.969036859099087
pressure: 0.9406498673740052
total_envstep_count: 897144
total_train_sample_count: 897144
total_episode_count: 7734
total_duration: 51365.072609270734
[2024-12-26 15:55:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.554307982878132
avg_train_sample_per_sec: 17.554307982878132
avg_episode_per_sec: 0.15133024123170805
collect_time: 39.64838720380515
reward_mean: -118.50630252100841
reward_std: 2.1150095626192433
reward_max: -115.44467787114846
reward_min: -122.57002801120449
queue_len: 0.07858508124735307
wait_time: 0.7545174568501141
delay_time: 4.9699505272581135
pressure: 0.9556808134394341
total_envstep_count: 897840
total_train_sample_count: 897840
total_episode_count: 7740
total_duration: 51404.72099647454
[2024-12-26 15:56:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.739967983728317
avg_train_sample_per_sec: 17.739967983728317
avg_episode_per_sec: 0.1529307584804165
collect_time: 39.233441719759256
reward_mean: -115.53828197945846
reward_std: 1.536441252558213
reward_max: -113.5714285714286
reward_min: -117.86834733893558
queue_len: 0.07661689786436236
wait_time: 0.7341687780328755
delay_time: 4.85956372400441
pressure: 0.931366047745358
total_envstep_count: 898536
total_train_sample_count: 898536
total_episode_count: 7746
total_duration: 51443.9544381943
[2024-12-26 15:57:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.60035980442947
avg_train_sample_per_sec: 17.60035980442947
avg_episode_per_sec: 0.1517272396933575
collect_time: 39.54464611711166
reward_mean: -117.01073762838469
reward_std: 5.736998544357178
reward_max: -111.62955182072827
reward_min: -129.43627450980395
queue_len: 0.07759332733977764
wait_time: 0.7419565306228594
delay_time: 4.899853634783793
pressure: 0.9333554376657824
total_envstep_count: 899232
total_train_sample_count: 899232
total_episode_count: 7752
total_duration: 51483.49908431141
[2024-12-26 15:57:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.461690971242035
avg_train_sample_per_sec: 17.461690971242035
avg_episode_per_sec: 0.15053181871760374
collect_time: 39.858682709839194
reward_mean: -118.12593370681607
reward_std: 4.918681224382936
reward_max: -113.0826330532213
reward_min: -127.52170868347339
queue_len: 0.07833284728568704
wait_time: 0.7538114494250397
delay_time: 4.942339972522388
pressure: 0.9566755083996464
total_envstep_count: 899928
total_train_sample_count: 899928
total_episode_count: 7758
total_duration: 51523.35776702125
[2024-12-26 15:58:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52495415686101
avg_train_sample_per_sec: 17.52495415686101
avg_episode_per_sec: 0.1510771910074225
collect_time: 39.714797184078016
reward_mean: -118.53688141923436
reward_std: 3.456460423942357
reward_max: -113.75630252100841
reward_min: -124.92717086834736
queue_len: 0.07860535903132251
wait_time: 0.7578386792382736
delay_time: 4.982996322423781
pressure: 0.9473916887709991
total_envstep_count: 900624
total_train_sample_count: 900624
total_episode_count: 7764
total_duration: 51563.07256420532
[2024-12-26 15:59:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.691516563830085
avg_train_sample_per_sec: 17.691516563830085
avg_episode_per_sec: 0.15251307382612142
collect_time: 39.34088960032724
reward_mean: -119.83169934640522
reward_std: 5.325259667280587
reward_max: -113.34103641456585
reward_min: -128.90616246498593
queue_len: 0.07946399160902202
wait_time: 0.7587040452785888
delay_time: 5.09174496117651
pressure: 0.9451812555260831
total_envstep_count: 901320
total_train_sample_count: 901320
total_episode_count: 7770
total_duration: 51602.413453805646
[2024-12-26 15:59:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.542593418448597
avg_train_sample_per_sec: 17.542593418448597
avg_episode_per_sec: 0.15122925360731548
collect_time: 39.67486353916488
reward_mean: -121.03326330532211
reward_std: 9.600032219652322
reward_max: -109.34593837535012
reward_min: -131.55252100840337
queue_len: 0.08026078468522688
wait_time: 0.7644751645131969
delay_time: 5.026941896915164
pressure: 0.9556808134394342
total_envstep_count: 902016
total_train_sample_count: 902016
total_episode_count: 7776
total_duration: 51642.08831734481
[2024-12-26 16:00:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.701067495238842
avg_train_sample_per_sec: 17.701067495238842
avg_episode_per_sec: 0.15259540944171415
collect_time: 39.319662511156864
reward_mean: -113.52637721755367
reward_std: 2.6205559908308658
reward_max: -109.86274509803923
reward_min: -117.38235294117644
queue_len: 0.07528274351296664
wait_time: 0.7166796537359419
delay_time: 4.739418058933687
pressure: 0.9216401414677278
total_envstep_count: 902712
total_train_sample_count: 902712
total_episode_count: 7782
total_duration: 51681.40797985597
[2024-12-26 16:01:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.540908824945088
avg_train_sample_per_sec: 17.540908824945088
avg_episode_per_sec: 0.1512147312495266
collect_time: 39.67867383303492
reward_mean: -118.10235760971055
reward_std: 6.926126297316701
reward_max: -109.12605042016807
reward_min: -129.23109243697482
queue_len: 0.07831721326903883
wait_time: 0.7565025899838274
delay_time: 4.917676465687891
pressure: 0.9442970822281166
total_envstep_count: 903408
total_train_sample_count: 903408
total_episode_count: 7788
total_duration: 51721.086653689
[2024-12-26 16:01:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.910541108623594
avg_train_sample_per_sec: 17.910541108623594
avg_episode_per_sec: 0.15440121645365165
collect_time: 38.85979746669345
reward_mean: -115.25116713352007
reward_std: 5.330173131928205
reward_max: -110.28711484593839
reward_min: -123.9733893557423
queue_len: 0.07642650340419103
wait_time: 0.7294240087723862
delay_time: 4.850364827663456
pressure: 0.9267241379310344
total_envstep_count: 904104
total_train_sample_count: 904104
total_episode_count: 7794
total_duration: 51759.946451155694
[2024-12-26 16:02:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.44697531541321
avg_train_sample_per_sec: 17.44697531541321
avg_episode_per_sec: 0.1504049596156311
collect_time: 39.89230152604914
reward_mean: -120.17086834733895
reward_std: 10.142244314780964
reward_max: -109.74789915966387
reward_min: -135.97549019607845
queue_len: 0.0796889047396147
wait_time: 0.7617778322646477
delay_time: 5.056558897077472
pressure: 0.9575596816976127
total_envstep_count: 904800
total_train_sample_count: 904800
total_episode_count: 7800
total_duration: 51799.838752681746
[2024-12-26 16:03:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.562206681093635
avg_train_sample_per_sec: 17.562206681093635
avg_episode_per_sec: 0.15139833345770376
collect_time: 39.630555125471204
reward_mean: -114.26762371615315
reward_std: 5.201356407340231
reward_max: -108.76050420168067
reward_min: -121.69677871148463
queue_len: 0.07577428628392119
wait_time: 0.721601582719737
delay_time: 4.762139695931887
pressure: 0.9178824049513704
total_envstep_count: 905496
total_train_sample_count: 905496
total_episode_count: 7806
total_duration: 51839.469307807216
[2024-12-26 16:03:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.694614798254673
avg_train_sample_per_sec: 17.694614798254673
avg_episode_per_sec: 0.15253978274357477
collect_time: 39.33400121649728
reward_mean: -112.48809523809523
reward_std: 3.185186991842881
reward_max: -108.76050420168067
reward_min: -118.10224089635852
queue_len: 0.07459422761146899
wait_time: 0.7057303469575276
delay_time: 4.738653618233411
pressure: 0.9116931918656057
total_envstep_count: 906192
total_train_sample_count: 906192
total_episode_count: 7812
total_duration: 51878.803309023715
[2024-12-26 16:04:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.129061158712833
avg_train_sample_per_sec: 17.129061158712833
avg_episode_per_sec: 0.14766432033373134
collect_time: 40.63269980479777
reward_mean: -113.31279178338002
reward_std: 4.578346571010161
reward_max: -108.76050420168067
reward_min: -118.68067226890756
queue_len: 0.07514110860966845
wait_time: 0.7156330259778536
delay_time: 4.707693558618057
pressure: 0.9101458885941645
total_envstep_count: 906888
total_train_sample_count: 906888
total_episode_count: 7818
total_duration: 51919.43600882851
[2024-12-26 16:05:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.854750785242196
avg_train_sample_per_sec: 16.854750785242196
avg_episode_per_sec: 0.1452995757348465
collect_time: 41.29399531729705
reward_mean: -115.44164332399625
reward_std: 5.670838681296548
reward_max: -108.76050420168067
reward_min: -122.25560224089635
queue_len: 0.07655281387532908
wait_time: 0.724305803223146
delay_time: 4.891161048180192
pressure: 0.917661361626879
total_envstep_count: 907584
total_train_sample_count: 907584
total_episode_count: 7824
total_duration: 51960.73000414581
[2024-12-26 16:06:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.977499477451925
avg_train_sample_per_sec: 16.977499477451925
avg_episode_per_sec: 0.14635775411596488
collect_time: 40.9954363965299
reward_mean: -109.59885620915033
reward_std: 1.100531166913517
reward_max: -108.76050420168067
reward_min: -111.55532212885154
queue_len: 0.0726782866108424
wait_time: 0.6884430717468243
delay_time: 4.6061262264578895
pressure: 0.8871573828470379
total_envstep_count: 908280
total_train_sample_count: 908280
total_episode_count: 7830
total_duration: 52001.72544054234
[2024-12-26 16:06:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.03203603689899
avg_train_sample_per_sec: 17.03203603689899
avg_episode_per_sec: 0.1468278968698189
collect_time: 40.86416905719042
reward_mean: -111.80532212885156
reward_std: 3.5998300405693944
reward_max: -108.76050420168067
reward_min: -118.12254901960782
queue_len: 0.07414146029764691
wait_time: 0.7084625848571083
delay_time: 4.682704948730718
pressure: 0.9003094606542882
total_envstep_count: 908976
total_train_sample_count: 908976
total_episode_count: 7836
total_duration: 52042.58960959953
[2024-12-26 16:07:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.958612582387254
avg_train_sample_per_sec: 16.958612582387254
avg_episode_per_sec: 0.14619493605506254
collect_time: 41.041093227334315
reward_mean: -110.68685807656396
reward_std: 2.859327834381054
reward_max: -107.7310924369748
reward_min: -116.44047619047622
queue_len: 0.07339977326032093
wait_time: 0.6944004834471368
delay_time: 4.624708714497362
pressure: 0.8973253757736517
total_envstep_count: 909672
total_train_sample_count: 909672
total_episode_count: 7842
total_duration: 52083.630702826864
[2024-12-26 16:08:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.762615564139303
avg_train_sample_per_sec: 16.762615564139303
avg_episode_per_sec: 0.1445053065874078
collect_time: 41.52096654229611
reward_mean: -116.2603874883287
reward_std: 4.18597296179188
reward_max: -111.38165266106441
reward_min: -124.59943977591041
queue_len: 0.07709574767130549
wait_time: 0.7383084644114056
delay_time: 4.97442040402218
pressure: 0.9341290893015031
total_envstep_count: 910368
total_train_sample_count: 910368
total_episode_count: 7848
total_duration: 52125.15166936916
[2024-12-26 16:08:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.047759062479603
avg_train_sample_per_sec: 17.047759062479603
avg_episode_per_sec: 0.14696344019378968
collect_time: 40.82648032795265
reward_mean: -112.62931839402427
reward_std: 2.030375515125255
reward_max: -110.04691876750702
reward_min: -114.87184873949575
queue_len: 0.07468787691911423
wait_time: 0.7122169933402186
delay_time: 4.750864803055569
pressure: 0.8986516357206012
total_envstep_count: 911064
total_train_sample_count: 911064
total_episode_count: 7854
total_duration: 52165.97814969711
[2024-12-26 16:09:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.306523345628705
avg_train_sample_per_sec: 16.306523345628705
avg_episode_per_sec: 0.14057347711748885
collect_time: 42.682304820455606
reward_mean: -119.43697478991595
reward_std: 7.153795301667178
reward_max: -112.55182072829129
reward_min: -129.30532212885157
queue_len: 0.07920223792434744
wait_time: 0.7631426354803637
delay_time: 4.998383244706279
pressure: 0.9601016799292661
total_envstep_count: 911760
total_train_sample_count: 911760
total_episode_count: 7860
total_duration: 52208.660454517565
[2024-12-26 16:10:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.282895504424033
avg_train_sample_per_sec: 16.282895504424033
avg_episode_per_sec: 0.14036978883124165
collect_time: 42.744240409262474
reward_mean: -115.06477591036413
reward_std: 3.564857233915374
reward_max: -109.65826330532214
reward_min: -120.12394957983194
queue_len: 0.0763029017973237
wait_time: 0.7300659322084271
delay_time: 4.906949635439083
pressure: 0.9271662245800179
total_envstep_count: 912456
total_train_sample_count: 912456
total_episode_count: 7866
total_duration: 52251.40469492683
[2024-12-26 16:11:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.406687874625078
avg_train_sample_per_sec: 16.406687874625078
avg_episode_per_sec: 0.1414369644364231
collect_time: 42.421724928189064
reward_mean: -120.24941643323996
reward_std: 8.349025972300012
reward_max: -109.32703081232494
reward_min: -132.54971988795518
queue_len: 0.07974099232973472
wait_time: 0.7690025280669297
delay_time: 5.056337824351718
pressure: 0.9528072502210433
total_envstep_count: 913152
total_train_sample_count: 913152
total_episode_count: 7872
total_duration: 52293.82641985502
[2024-12-26 16:11:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.455888061244938
avg_train_sample_per_sec: 16.455888061244938
avg_episode_per_sec: 0.14186110397624946
collect_time: 42.294891494743524
reward_mean: -111.9905462184874
reward_std: 3.316972998085227
reward_max: -109.41036414565826
reward_min: -119.10644257703083
queue_len: 0.07426428794329404
wait_time: 0.7094029477396617
delay_time: 4.702261695605509
pressure: 0.9016357206012379
total_envstep_count: 913848
total_train_sample_count: 913848
total_episode_count: 7878
total_duration: 52336.12131134976
[2024-12-26 16:12:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.404025239311846
avg_train_sample_per_sec: 16.404025239311846
avg_episode_per_sec: 0.1414140106837228
collect_time: 42.42861065173522
reward_mean: -112.69316059757234
reward_std: 3.6960884357291457
reward_max: -109.41036414565826
reward_min: -118.35924369747895
queue_len: 0.07473021259785965
wait_time: 0.711565550181169
delay_time: 4.7363225454041915
pressure: 0.9060565870910698
total_envstep_count: 914544
total_train_sample_count: 914544
total_episode_count: 7884
total_duration: 52378.54992200149
[2024-12-26 16:13:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.384134132828
avg_train_sample_per_sec: 16.384134132828
avg_episode_per_sec: 0.14124253562782757
collect_time: 42.48012097297609
reward_mean: -112.8308823529412
reward_std: 4.465977595407276
reward_max: -109.32703081232494
reward_min: -122.4705882352941
queue_len: 0.07482154002184428
wait_time: 0.7164862408270115
delay_time: 4.709346033342036
pressure: 0.9061671087533156
total_envstep_count: 915240
total_train_sample_count: 915240
total_episode_count: 7890
total_duration: 52421.03004297447
[2024-12-26 16:13:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.3897179850465
avg_train_sample_per_sec: 16.3897179850465
avg_episode_per_sec: 0.14129067228488362
collect_time: 42.46564831896498
reward_mean: -115.0346638655462
reward_std: 5.510085592134885
reward_max: -109.41036414565826
reward_min: -123.03571428571428
queue_len: 0.07628293359784231
wait_time: 0.7380964764331904
delay_time: 4.788275090370429
pressure: 0.9148983200707339
total_envstep_count: 915936
total_train_sample_count: 915936
total_episode_count: 7896
total_duration: 52463.495691293436
[2024-12-26 16:14:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.275596951660237
avg_train_sample_per_sec: 16.275596951660237
avg_episode_per_sec: 0.14030687027293307
collect_time: 42.7634084370099
reward_mean: -114.97373949579831
reward_std: 5.085618140124667
reward_max: -109.41036414565826
reward_min: -124.00070028011201
queue_len: 0.07624253282214742
wait_time: 0.7293360093816483
delay_time: 4.803362618298353
pressure: 0.923187444739169
total_envstep_count: 916632
total_train_sample_count: 916632
total_episode_count: 7902
total_duration: 52506.25909973044
[2024-12-26 16:15:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.537517355984434
avg_train_sample_per_sec: 16.537517355984434
avg_episode_per_sec: 0.14256480479296926
collect_time: 42.08612363137677
reward_mean: -112.77684407096172
reward_std: 4.396517523289264
reward_max: -109.41036414565826
reward_min: -122.25560224089632
queue_len: 0.07478570561734861
wait_time: 0.7138106568887501
delay_time: 4.733937115161701
pressure: 0.9064986737400531
total_envstep_count: 917328
total_train_sample_count: 917328
total_episode_count: 7908
total_duration: 52548.34522336182
[2024-12-26 16:16:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.261540995416645
avg_train_sample_per_sec: 16.261540995416645
avg_episode_per_sec: 0.1401856982363504
collect_time: 42.80037176034973
reward_mean: -118.03933239962652
reward_std: 8.104426222245861
reward_max: -109.41036414565826
reward_min: -128.7296918767507
queue_len: 0.07827541936314755
wait_time: 0.7539010741343399
delay_time: 4.945826697644858
pressure: 0.9503757736516357
total_envstep_count: 918024
total_train_sample_count: 918024
total_episode_count: 7914
total_duration: 52591.14559512217
[2024-12-26 16:16:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.426646802807436
avg_train_sample_per_sec: 16.426646802807436
avg_episode_per_sec: 0.14160902416213308
collect_time: 42.37018110604584
reward_mean: -114.45553221288515
reward_std: 7.033757020276666
reward_max: -109.41036414565826
reward_min: -125.24929971988792
queue_len: 0.07589889404037477
wait_time: 0.7259815066610199
delay_time: 4.841018920742106
pressure: 0.9223032714412026
total_envstep_count: 918720
total_train_sample_count: 918720
total_episode_count: 7920
total_duration: 52633.51577622822
[2024-12-26 16:17:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.44958835186385
avg_train_sample_per_sec: 16.44958835186385
avg_episode_per_sec: 0.1418067961367573
collect_time: 42.311089196413754
reward_mean: -117.22432306255837
reward_std: 7.347583634264715
reward_max: -109.41036414565826
reward_min: -128.87254901960785
queue_len: 0.07773496224307581
wait_time: 0.7466080375563134
delay_time: 4.890737564983911
pressure: 0.9397656940760389
total_envstep_count: 919416
total_train_sample_count: 919416
total_episode_count: 7926
total_duration: 52675.826865424635
[2024-12-26 16:18:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.431089347370055
avg_train_sample_per_sec: 16.431089347370055
avg_episode_per_sec: 0.14164732196008667
collect_time: 42.358725297261024
reward_mean: -113.29073295985059
reward_std: 6.513009590768723
reward_max: -109.41036414565826
reward_min: -127.23039215686273
queue_len: 0.0751264807426065
wait_time: 0.7220593033853683
delay_time: 4.707153691848898
pressure: 0.9109195402298851
total_envstep_count: 920112
total_train_sample_count: 920112
total_episode_count: 7932
total_duration: 52718.18559072189
[2024-12-26 16:18:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.378402035577846
avg_train_sample_per_sec: 16.378402035577846
avg_episode_per_sec: 0.14119312099636072
collect_time: 42.494988124489794
reward_mean: -115.09593837535014
reward_std: 5.540971611917715
reward_max: -109.71288515406162
reward_min: -123.11834733893558
queue_len: 0.07632356656190327
wait_time: 0.7286529886048142
delay_time: 4.843189886839265
pressure: 0.9177718832891246
total_envstep_count: 920808
total_train_sample_count: 920808
total_episode_count: 7938
total_duration: 52760.68057884638
[2024-12-26 16:19:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.36488546357695
avg_train_sample_per_sec: 16.36488546357695
avg_episode_per_sec: 0.14107659882393925
collect_time: 42.53008684656397
reward_mean: -117.09943977591035
reward_std: 6.59389739123944
reward_max: -109.41036414565826
reward_min: -126.92647058823528
queue_len: 0.0776521483925135
wait_time: 0.7477567507993471
delay_time: 4.958526638919751
pressure: 0.9299292661361626
total_envstep_count: 921504
total_train_sample_count: 921504
total_episode_count: 7944
total_duration: 52803.210665692946
[2024-12-26 16:20:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.626501139788314
avg_train_sample_per_sec: 16.626501139788314
avg_episode_per_sec: 0.14333190637748547
collect_time: 41.860881862536075
reward_mean: -111.20751633986929
reward_std: 3.480388908300461
reward_max: -109.41036414565826
reward_min: -118.9201680672269
queue_len: 0.07374503736065602
wait_time: 0.7031497280609859
delay_time: 4.7092545008876625
pressure: 0.8898099027409373
total_envstep_count: 922200
total_train_sample_count: 922200
total_episode_count: 7950
total_duration: 52845.07154755548
[2024-12-26 16:21:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.44580134473791
avg_train_sample_per_sec: 16.44580134473791
avg_episode_per_sec: 0.14177414952360268
collect_time: 42.32083225440979
reward_mean: -118.16946778711485
reward_std: 6.982389030123336
reward_max: -109.41036414565826
reward_min: -126.2941176470588
queue_len: 0.07836171603920082
wait_time: 0.7585932140318551
delay_time: 4.88008444672807
pressure: 0.9398762157382846
total_envstep_count: 922896
total_train_sample_count: 922896
total_episode_count: 7956
total_duration: 52887.39237980989
[2024-12-26 16:21:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.240744126434684
avg_train_sample_per_sec: 16.240744126434684
avg_episode_per_sec: 0.14000641488305762
collect_time: 42.855179207406934
reward_mean: -116.40838001867412
reward_std: 4.645018273556483
reward_max: -109.41036414565826
reward_min: -124.92016806722685
queue_len: 0.07719388595402793
wait_time: 0.7433002820933856
delay_time: 4.896270246019569
pressure: 0.9324712643678161
total_envstep_count: 923592
total_train_sample_count: 923592
total_episode_count: 7962
total_duration: 52930.2475590173
[2024-12-26 16:22:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30773624325699
avg_train_sample_per_sec: 17.30773624325699
avg_episode_per_sec: 0.1492046227866982
collect_time: 40.21323125207424
reward_mean: -112.22070494864612
reward_std: 4.071581504735531
reward_max: -109.41036414565826
reward_min: -120.5910364145658
queue_len: 0.07441691309591918
wait_time: 0.7085073972117583
delay_time: 4.770377911422618
pressure: 0.8999778956675509
total_envstep_count: 924288
total_train_sample_count: 924288
total_episode_count: 7968
total_duration: 52970.460790269375
[2024-12-26 16:23:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.979645196689123
avg_train_sample_per_sec: 17.979645196689123
avg_episode_per_sec: 0.15499694135076833
collect_time: 38.710441301042216
reward_mean: -117.38422035480862
reward_std: 8.694505729157148
reward_max: -109.41036414565826
reward_min: -134.373949579832
queue_len: 0.07784099493024442
wait_time: 0.7481671050383017
delay_time: 4.937542143477553
pressure: 0.9314765694076038
total_envstep_count: 924984
total_train_sample_count: 924984
total_episode_count: 7974
total_duration: 53009.17123157042
[2024-12-26 16:23:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.706765949600285
avg_train_sample_per_sec: 17.706765949600285
avg_episode_per_sec: 0.15264453404827832
collect_time: 39.30700851759502
reward_mean: -114.6025910364146
reward_std: 3.3957348458007397
reward_max: -109.41036414565826
reward_min: -118.90196078431381
queue_len: 0.07599641315412108
wait_time: 0.7279148617891011
delay_time: 4.791231878128883
pressure: 0.9203138815207782
total_envstep_count: 925680
total_train_sample_count: 925680
total_episode_count: 7980
total_duration: 53048.478240088014
[2024-12-26 16:24:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.708111673843945
avg_train_sample_per_sec: 17.708111673843945
avg_episode_per_sec: 0.15265613511934434
collect_time: 39.304021389702335
reward_mean: -122.44887955182075
reward_std: 2.4765315157895738
reward_max: -118.88585434173669
reward_min: -126.47058823529413
queue_len: 0.08119952224921799
wait_time: 0.7753908039785321
delay_time: 5.1087979770777645
pressure: 0.9648541114058355
total_envstep_count: 926376
total_train_sample_count: 926376
total_episode_count: 7986
total_duration: 53087.78226147772
[2024-12-26 16:25:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.702349824148147
avg_train_sample_per_sec: 17.702349824148147
avg_episode_per_sec: 0.15260646400127714
collect_time: 39.31681425991095
reward_mean: -115.94596171802056
reward_std: 2.1417986962858198
reward_max: -112.24999999999999
reward_min: -118.53221288515408
queue_len: 0.07688724251858127
wait_time: 0.7325189248997567
delay_time: 4.848007444815435
pressure: 0.9271662245800177
total_envstep_count: 927072
total_train_sample_count: 927072
total_episode_count: 7992
total_duration: 53127.09907573763
[2024-12-26 16:25:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.698427441986116
avg_train_sample_per_sec: 17.698427441986116
avg_episode_per_sec: 0.15257265036194928
collect_time: 39.32552777818405
reward_mean: -114.79330065359477
reward_std: 5.460839308766073
reward_max: -109.58403361344533
reward_min: -125.01890756302521
queue_len: 0.07612287841750316
wait_time: 0.7282605902661684
delay_time: 4.851906893050143
pressure: 0.9161140583554378
total_envstep_count: 927768
total_train_sample_count: 927768
total_episode_count: 7998
total_duration: 53166.424603515814
[2024-12-26 16:26:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.805607443215518
avg_train_sample_per_sec: 17.805607443215518
avg_episode_per_sec: 0.15349661588978897
collect_time: 39.08880964716524
reward_mean: -111.52824463118579
reward_std: 2.985793472868642
reward_max: -109.0581232492997
reward_min: -117.94817927170868
queue_len: 0.07395772190396938
wait_time: 0.7041712020794172
delay_time: 4.721615199412565
pressure: 0.8923519009725908
total_envstep_count: 928464
total_train_sample_count: 928464
total_episode_count: 8004
total_duration: 53205.51341316298
[2024-12-26 16:27:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.873070336998946
avg_train_sample_per_sec: 17.873070336998946
avg_episode_per_sec: 0.15407819256033572
collect_time: 38.94126677044482
reward_mean: -112.33671802054153
reward_std: 3.452236192040338
reward_max: -108.59173669467785
reward_min: -117.72268907563023
queue_len: 0.07449384484120791
wait_time: 0.712134179489656
delay_time: 4.7469700867534135
pressure: 0.9001989389920425
total_envstep_count: 929160
total_train_sample_count: 929160
total_episode_count: 8010
total_duration: 53244.45467993343
[2024-12-26 16:27:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.638472780686918
avg_train_sample_per_sec: 17.638472780686918
avg_episode_per_sec: 0.1520557998335079
collect_time: 39.459198574271056
reward_mean: -112.03139589169001
reward_std: 2.4472476049263
reward_max: -109.0581232492997
reward_min: -114.54131652661066
queue_len: 0.07429137658600134
wait_time: 0.7107196879636026
delay_time: 4.69974889708422
pressure: 0.9056145004420867
total_envstep_count: 929856
total_train_sample_count: 929856
total_episode_count: 8016
total_duration: 53283.9138785077
[2024-12-26 16:28:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.614386623512953
avg_train_sample_per_sec: 17.614386623512953
avg_episode_per_sec: 0.15184816054752545
collect_time: 39.51315563102998
reward_mean: -112.12441643323996
reward_std: 4.233478296716834
reward_max: -109.0581232492997
reward_min: -121.21988795518207
queue_len: 0.07435306129525197
wait_time: 0.7054551263476211
delay_time: 4.772854588588888
pressure: 0.9001989389920424
total_envstep_count: 930552
total_train_sample_count: 930552
total_episode_count: 8022
total_duration: 53323.42703413873
[2024-12-26 16:29:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.787933713037994
avg_train_sample_per_sec: 17.787933713037994
avg_episode_per_sec: 0.15334425614687924
collect_time: 39.12764749566466
reward_mean: -115.81442577030812
reward_std: 7.039341095117109
reward_max: -109.0581232492997
reward_min: -126.10434173669465
queue_len: 0.07680001708906374
wait_time: 0.735269041303524
delay_time: 4.852000104439534
pressure: 0.9270557029177718
total_envstep_count: 931248
total_train_sample_count: 931248
total_episode_count: 8028
total_duration: 53362.55468163439
[2024-12-26 16:29:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.953092776972913
avg_train_sample_per_sec: 17.953092776972913
avg_episode_per_sec: 0.15476804118080098
collect_time: 38.76769360278175
reward_mean: -116.11683006535948
reward_std: 5.226544239021861
reward_max: -109.0581232492997
reward_min: -123.49719887955185
queue_len: 0.07700055044121983
wait_time: 0.7326037510494915
delay_time: 4.8879237164149245
pressure: 0.9341290893015031
total_envstep_count: 931944
total_train_sample_count: 931944
total_episode_count: 8034
total_duration: 53401.32237523717
[2024-12-26 16:30:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.071790226083362
avg_train_sample_per_sec: 18.071790226083362
avg_episode_per_sec: 0.1557912950524428
collect_time: 38.51306324901059
reward_mean: -115.44817927170867
reward_std: 6.30567417751309
reward_max: -109.0581232492997
reward_min: -125.12114845938372
queue_len: 0.07655714805816226
wait_time: 0.7286833278846463
delay_time: 4.889487415551766
pressure: 0.9281609195402298
total_envstep_count: 932640
total_train_sample_count: 932640
total_episode_count: 8040
total_duration: 53439.83543848618
[2024-12-26 16:31:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.46241239236756
avg_train_sample_per_sec: 17.46241239236756
avg_episode_per_sec: 0.15053803786523762
collect_time: 39.857036036109555
reward_mean: -120.10422502334266
reward_std: 6.441391931362466
reward_max: -107.37394957983192
reward_min: -127.74089635854337
queue_len: 0.07964471155394075
wait_time: 0.764802240524857
delay_time: 4.969820856975957
pressure: 0.9503757736516357
total_envstep_count: 933336
total_train_sample_count: 933336
total_episode_count: 8046
total_duration: 53479.69247452229
[2024-12-26 16:31:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.76096499147885
avg_train_sample_per_sec: 17.76096499147885
avg_episode_per_sec: 0.15311176716792113
collect_time: 39.18705995614083
reward_mean: -117.7734593837535
reward_std: 9.562801051755287
reward_max: -108.73459383753497
reward_min: -132.3165266106443
queue_len: 0.07809911099718402
wait_time: 0.7454950039255314
delay_time: 5.044989050299911
pressure: 0.9394341290893015
total_envstep_count: 934032
total_train_sample_count: 934032
total_episode_count: 8052
total_duration: 53518.87953447844
[2024-12-26 16:32:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.535042747084116
avg_train_sample_per_sec: 17.535042747084116
avg_episode_per_sec: 0.15116416161279408
collect_time: 39.691947720842435
reward_mean: -110.32014472455649
reward_std: 2.792646508216101
reward_max: -108.59173669467785
reward_min: -116.11624649859945
queue_len: 0.07315659464493134
wait_time: 0.6997256462266601
delay_time: 4.687583959448603
pressure: 0.8850574712643678
total_envstep_count: 934728
total_train_sample_count: 934728
total_episode_count: 8058
total_duration: 53558.57148219928
[2024-12-26 16:33:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.709053431171274
avg_train_sample_per_sec: 17.709053431171274
avg_episode_per_sec: 0.15266425371699374
collect_time: 39.301931224336855
reward_mean: -113.86169467787113
reward_std: 7.770916255851398
reward_max: -107.37394957983192
reward_min: -129.51470588235293
queue_len: 0.07550510257153259
wait_time: 0.7197196186166774
delay_time: 4.7908423805647296
pressure: 0.910919540229885
total_envstep_count: 935424
total_train_sample_count: 935424
total_episode_count: 8064
total_duration: 53597.873413423615
[2024-12-26 16:33:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7647959717905
avg_train_sample_per_sec: 16.7647959717905
avg_episode_per_sec: 0.14452410320509052
collect_time: 41.51556637916342
reward_mean: -111.61379551820728
reward_std: 5.357828946594952
reward_max: -107.37394957983192
reward_min: -122.99859943977597
queue_len: 0.07401445326141066
wait_time: 0.7006447251756582
delay_time: 4.746503297487981
pressure: 0.8963306808134396
total_envstep_count: 936120
total_train_sample_count: 936120
total_episode_count: 8070
total_duration: 53639.38897980278
[2024-12-26 16:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.677036655044358
avg_train_sample_per_sec: 16.677036655044358
avg_episode_per_sec: 0.14376755737107205
collect_time: 41.734033113699404
reward_mean: -111.3328664799253
reward_std: 4.097899417883356
reward_max: -107.98809523809523
reward_min: -120.328431372549
queue_len: 0.07382816079570644
wait_time: 0.6981438242847978
delay_time: 4.696467179610468
pressure: 0.8964412024756854
total_envstep_count: 936816
total_train_sample_count: 936816
total_episode_count: 8076
total_duration: 53681.12301291648
[2024-12-26 16:35:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.755527260612954
avg_train_sample_per_sec: 16.755527260612954
avg_episode_per_sec: 0.14444420052252546
collect_time: 41.538531684173265
reward_mean: -110.40896358543415
reward_std: 1.6719780763919465
reward_max: -107.37394957983192
reward_min: -112.40406162464986
queue_len: 0.07321549309378923
wait_time: 0.6927117000646411
delay_time: 4.667862460250278
pressure: 0.8891467727674623
total_envstep_count: 937512
total_train_sample_count: 937512
total_episode_count: 8082
total_duration: 53722.661544600654
[2024-12-26 16:35:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81532028829727
avg_train_sample_per_sec: 16.81532028829727
avg_episode_per_sec: 0.14495965765773508
collect_time: 41.39082622674667
reward_mean: -114.65651260504201
reward_std: 6.385521071560028
reward_max: -107.37394957983192
reward_min: -125.51470588235296
queue_len: 0.07603217016249471
wait_time: 0.7273093145304098
delay_time: 4.830606783621502
pressure: 0.9211980548187445
total_envstep_count: 938208
total_train_sample_count: 938208
total_episode_count: 8088
total_duration: 53764.0523708274
[2024-12-26 16:36:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.712094473158594
avg_train_sample_per_sec: 16.712094473158594
avg_episode_per_sec: 0.14406977994102235
collect_time: 41.64648549096286
reward_mean: -110.62651727357608
reward_std: 3.9324220529532887
reward_max: -107.37394957983192
reward_min: -118.80742296918766
queue_len: 0.07335975946523614
wait_time: 0.6986055695487744
delay_time: 4.725789641244948
pressure: 0.8953359858532273
total_envstep_count: 938904
total_train_sample_count: 938904
total_episode_count: 8094
total_duration: 53805.69885631836
[2024-12-26 16:37:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.67081691297692
avg_train_sample_per_sec: 16.67081691297692
avg_episode_per_sec: 0.14371393890497347
collect_time: 41.74960373166948
reward_mean: -111.4878618113912
reward_std: 8.379526896613083
reward_max: -107.37394957983192
reward_min: -130.2149859943977
queue_len: 0.07393094284575014
wait_time: 0.7005344357017783
delay_time: 4.724315983279642
pressure: 0.8962201591511937
total_envstep_count: 939600
total_train_sample_count: 939600
total_episode_count: 8100
total_duration: 53847.44846005003
[2024-12-26 16:38:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.541581007951475
avg_train_sample_per_sec: 16.541581007951475
avg_episode_per_sec: 0.14259983627544376
collect_time: 42.075784634215765
reward_mean: -112.91398225957046
reward_std: 5.893974536634557
reward_max: -107.0189075630252
reward_min: -123.32142857142854
queue_len: 0.07487664606072313
wait_time: 0.7154748283044428
delay_time: 4.711850755747793
pressure: 0.9093722369584438
total_envstep_count: 940296
total_train_sample_count: 940296
total_episode_count: 8106
total_duration: 53889.524244684246
[2024-12-26 16:38:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.732115592837353
avg_train_sample_per_sec: 16.732115592837353
avg_episode_per_sec: 0.144242375800322
collect_time: 41.59665262520313
reward_mean: -119.51750700280111
reward_std: 7.082496282408131
reward_max: -108.95238095238095
reward_min: -126.57072829131654
queue_len: 0.07925564124854186
wait_time: 0.7633638335970994
delay_time: 5.022388336916861
pressure: 0.949049513704686
total_envstep_count: 940992
total_train_sample_count: 940992
total_episode_count: 8112
total_duration: 53931.12089730945
[2024-12-26 16:39:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.660013405002985
avg_train_sample_per_sec: 16.660013405002985
avg_episode_per_sec: 0.14362080521554296
collect_time: 41.77667706983909
reward_mean: -115.6700513538749
reward_std: 5.468570560124178
reward_max: -108.60434173669466
reward_min: -122.61344537815121
queue_len: 0.07670427808612393
wait_time: 0.7354304122179373
delay_time: 4.835813825563729
pressure: 0.9273872679045092
total_envstep_count: 941688
total_train_sample_count: 941688
total_episode_count: 8118
total_duration: 53972.89757437928
[2024-12-26 16:40:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.634724034006165
avg_train_sample_per_sec: 16.634724034006165
avg_episode_per_sec: 0.1434027933966049
collect_time: 41.84018914754315
reward_mean: -116.6343370681606
reward_std: 9.83147809938788
reward_max: -107.0189075630252
reward_min: -130.59523809523807
queue_len: 0.07734372484626034
wait_time: 0.741988882201864
delay_time: 4.988491627526573
pressure: 0.9290450928381963
total_envstep_count: 942384
total_train_sample_count: 942384
total_episode_count: 8124
total_duration: 54014.73776352683
[2024-12-26 16:40:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93588329519145
avg_train_sample_per_sec: 16.93588329519145
avg_episode_per_sec: 0.1459989939240642
collect_time: 41.09617360185831
reward_mean: -110.5673436041083
reward_std: 3.6605824361379224
reward_max: -107.49999999999999
reward_min: -117.89915966386553
queue_len: 0.07332051963137155
wait_time: 0.7004712030700874
delay_time: 4.62477455942054
pressure: 0.8922413793103448
total_envstep_count: 943080
total_train_sample_count: 943080
total_episode_count: 8130
total_duration: 54055.833937128686
[2024-12-26 16:41:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90230508836435
avg_train_sample_per_sec: 16.90230508836435
avg_episode_per_sec: 0.1457095266238306
collect_time: 41.17781547317654
reward_mean: -113.34955648926235
reward_std: 7.7677512364518595
reward_max: -106.94957983193275
reward_min: -129.26120448179273
queue_len: 0.07516548838810504
wait_time: 0.7223118469315222
delay_time: 4.7751817657742075
pressure: 0.9120247568523431
total_envstep_count: 943776
total_train_sample_count: 943776
total_episode_count: 8136
total_duration: 54097.011752601866
[2024-12-26 16:42:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.823625335008632
avg_train_sample_per_sec: 16.823625335008632
avg_episode_per_sec: 0.14503125288800545
collect_time: 41.37039348776266
reward_mean: -108.88725490196076
reward_std: 2.0531311640855363
reward_max: -107.82142857142856
reward_min: -113.4334733893557
queue_len: 0.07220640245488115
wait_time: 0.6880595739622106
delay_time: 4.600143058601361
pressure: 0.8807471264367815
total_envstep_count: 944472
total_train_sample_count: 944472
total_episode_count: 8142
total_duration: 54138.38214608963
[2024-12-26 16:42:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.783954930665157
avg_train_sample_per_sec: 16.783954930665157
avg_episode_per_sec: 0.14468926664366513
collect_time: 41.46817617630585
reward_mean: -113.24591503267975
reward_std: 8.550160932566914
reward_max: -107.23529411764704
reward_min: -126.8641456582633
queue_len: 0.07509676063175048
wait_time: 0.7157285327924271
delay_time: 4.761199429928608
pressure: 0.9174403183023871
total_envstep_count: 945168
total_train_sample_count: 945168
total_episode_count: 8148
total_duration: 54179.850322265935
[2024-12-26 16:43:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.620841232601446
avg_train_sample_per_sec: 16.620841232601446
avg_episode_per_sec: 0.1432831140741504
collect_time: 41.87513677916675
reward_mean: -113.88363678804855
reward_std: 6.173647033478997
reward_max: -107.23529411764704
reward_min: -124.97619047619048
queue_len: 0.07551965304247252
wait_time: 0.7204609960695153
delay_time: 4.797379323460587
pressure: 0.911472148541114
total_envstep_count: 945864
total_train_sample_count: 945864
total_episode_count: 8154
total_duration: 54221.725459045105
[2024-12-26 16:44:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71050229240434
avg_train_sample_per_sec: 16.71050229240434
avg_episode_per_sec: 0.144056054244865
collect_time: 41.650453578308216
reward_mean: -110.81057422969188
reward_std: 3.041417644700616
reward_max: -107.00840336134452
reward_min: -114.72549019607843
queue_len: 0.07348181314966305
wait_time: 0.7012655194703875
delay_time: 4.666277523502654
pressure: 0.8986516357206011
total_envstep_count: 946560
total_train_sample_count: 946560
total_episode_count: 8160
total_duration: 54263.375912623414
[2024-12-26 16:45:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.78771131944792
avg_train_sample_per_sec: 16.78771131944792
avg_episode_per_sec: 0.1447216493055855
collect_time: 41.45889733007922
reward_mean: -114.85901027077496
reward_std: 1.5968268531824337
reward_max: -112.45518207282912
reward_min: -117.26960784313725
queue_len: 0.07616645243420091
wait_time: 0.7268226477151427
delay_time: 4.7793481281748855
pressure: 0.9211980548187445
total_envstep_count: 947256
total_train_sample_count: 947256
total_episode_count: 8166
total_duration: 54304.83480995349
[2024-12-26 16:45:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.889182516789084
avg_train_sample_per_sec: 16.889182516789084
avg_episode_per_sec: 0.14559640100680243
collect_time: 41.20980984770134
reward_mean: -115.2903828197946
reward_std: 1.4771339398269092
reward_max: -114.26400560224089
reward_min: -118.50350140056024
queue_len: 0.07645250850119006
wait_time: 0.726935181676561
delay_time: 4.7486284742331355
pressure: 0.9205349248452697
total_envstep_count: 947952
total_train_sample_count: 947952
total_episode_count: 8172
total_duration: 54346.04461980119
[2024-12-26 16:46:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.430811457594427
avg_train_sample_per_sec: 16.430811457594427
avg_episode_per_sec: 0.14164492635857262
collect_time: 42.35944169868156
reward_mean: -124.87348272642392
reward_std: 5.109271622650509
reward_max: -116.3340336134454
reward_min: -131.63165266106446
queue_len: 0.08280734928807953
wait_time: 0.7986580905571778
delay_time: 5.261411829443305
pressure: 0.9932581786030061
total_envstep_count: 948648
total_train_sample_count: 948648
total_episode_count: 8178
total_duration: 54388.404061499874
[2024-12-26 16:47:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.388887562743182
avg_train_sample_per_sec: 16.388887562743182
avg_episode_per_sec: 0.14128351347192397
collect_time: 42.46780004655198
reward_mean: -118.57551353874884
reward_std: 5.625953091615469
reward_max: -112.78221288515407
reward_min: -128.29621848739495
queue_len: 0.07863097714771143
wait_time: 0.7571635528658858
delay_time: 4.997089290827453
pressure: 0.9392130857648099
total_envstep_count: 949344
total_train_sample_count: 949344
total_episode_count: 8184
total_duration: 54430.871861546424
[2024-12-26 16:47:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.474147473758592
avg_train_sample_per_sec: 16.474147473758592
avg_episode_per_sec: 0.14201851270481547
collect_time: 42.24801320424303
reward_mean: -120.91304855275445
reward_std: 3.247030800340017
reward_max: -115.83683473389358
reward_min: -124.67997198879549
queue_len: 0.08018106667954537
wait_time: 0.767427671776049
delay_time: 5.186028739509125
pressure: 0.9560123784261715
total_envstep_count: 950040
total_train_sample_count: 950040
total_episode_count: 8190
total_duration: 54473.119874750664
[2024-12-26 16:48:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55845330572803
avg_train_sample_per_sec: 16.55845330572803
avg_episode_per_sec: 0.14274528711834508
collect_time: 42.032911356475196
reward_mean: -119.55485527544351
reward_std: 4.412315885764656
reward_max: -114.86484593837535
reward_min: -125.73949579831933
queue_len: 0.07928040800758854
wait_time: 0.7609497711551465
delay_time: 5.042276280684967
pressure: 0.9483863837312114
total_envstep_count: 950736
total_train_sample_count: 950736
total_episode_count: 8196
total_duration: 54515.15278610714
[2024-12-26 16:49:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.408607461267387
avg_train_sample_per_sec: 16.408607461267387
avg_episode_per_sec: 0.14145351259713265
collect_time: 42.41676215625927
reward_mean: -122.18720821661996
reward_std: 5.344110363926988
reward_max: -116.8690476190476
reward_min: -129.63585434173672
queue_len: 0.08102600014364719
wait_time: 0.7723113670755658
delay_time: 5.281859415430115
pressure: 0.9515915119363395
total_envstep_count: 951432
total_train_sample_count: 951432
total_episode_count: 8202
total_duration: 54557.5695482634
[2024-12-26 16:50:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.473389326071395
avg_train_sample_per_sec: 16.473389326071395
avg_episode_per_sec: 0.14201197694889134
collect_time: 42.249957566320894
reward_mean: -125.32142857142856
reward_std: 3.5842761537365773
reward_max: -119.00420168067225
reward_min: -130.3466386554622
queue_len: 0.08310439560439559
wait_time: 0.7942970512696678
delay_time: 5.298328662492391
pressure: 0.9841954022988505
total_envstep_count: 952128
total_train_sample_count: 952128
total_episode_count: 8208
total_duration: 54599.81950582972
[2024-12-26 16:50:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.289872136361993
avg_train_sample_per_sec: 16.289872136361993
avg_episode_per_sec: 0.14042993221001718
collect_time: 42.7259338915497
reward_mean: -131.53629785247432
reward_std: 5.2003991723937135
reward_max: -123.57002801120449
reward_min: -139.3319327731093
queue_len: 0.08722566170588482
wait_time: 0.8469336894793283
delay_time: 5.505183584592889
pressure: 1.03315649867374
total_envstep_count: 952824
total_train_sample_count: 952824
total_episode_count: 8214
total_duration: 54642.54543972127
[2024-12-26 16:51:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.505334203334463
avg_train_sample_per_sec: 16.505334203334463
avg_episode_per_sec: 0.1422873638218488
collect_time: 42.16818583772704
reward_mean: -119.85562558356675
reward_std: 5.882082263022611
reward_max: -112.93137254901961
reward_min: -129.6995798319327
queue_len: 0.07947985781403631
wait_time: 0.7663149477297551
delay_time: 4.993337849380324
pressure: 0.9589964633068081
total_envstep_count: 953520
total_train_sample_count: 953520
total_episode_count: 8220
total_duration: 54684.713625558994
[2024-12-26 16:52:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56983057586088
avg_train_sample_per_sec: 16.56983057586088
avg_episode_per_sec: 0.14284336703328346
collect_time: 42.00405048280583
reward_mean: -119.94456115779646
reward_std: 4.6927520961233355
reward_max: -110.48949579831934
reward_min: -125.68697478991602
queue_len: 0.07953883365901622
wait_time: 0.7701786395371588
delay_time: 5.039304605291776
pressure: 0.9628647214854111
total_envstep_count: 954216
total_train_sample_count: 954216
total_episode_count: 8226
total_duration: 54726.7176760418
[2024-12-26 16:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.728718490574913
avg_train_sample_per_sec: 16.728718490574913
avg_episode_per_sec: 0.14421309043599062
collect_time: 41.6050996609293
reward_mean: -120.26050420168069
reward_std: 5.686832665453403
reward_max: -113.59173669467793
reward_min: -130.60994397759103
queue_len: 0.07974834496132671
wait_time: 0.7613386092721789
delay_time: 5.132135102295899
pressure: 0.9540229885057472
total_envstep_count: 954912
total_train_sample_count: 954912
total_episode_count: 8232
total_duration: 54768.32277570273
[2024-12-26 16:53:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.858376726379507
avg_train_sample_per_sec: 16.858376726379507
avg_episode_per_sec: 0.1453308338480992
collect_time: 41.28511370320246
reward_mean: -114.23622782446313
reward_std: 1.877641110644429
reward_max: -110.84033613445379
reward_min: -117.0098039215686
queue_len: 0.07575346672709755
wait_time: 0.7196521291982751
delay_time: 4.74939358201051
pressure: 0.9256189213085766
total_envstep_count: 955608
total_train_sample_count: 955608
total_episode_count: 8238
total_duration: 54809.60788940593
[2024-12-26 16:54:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.650038269998326
avg_train_sample_per_sec: 16.650038269998326
avg_episode_per_sec: 0.14353481267239937
collect_time: 41.80170572064817
reward_mean: -123.41818394024274
reward_std: 5.232948856330889
reward_max: -114.5441176470588
reward_min: -128.0385154061625
queue_len: 0.0818422970426013
wait_time: 0.7919815914871694
delay_time: 5.152743680491128
pressure: 0.9790008841732979
total_envstep_count: 956304
total_train_sample_count: 956304
total_episode_count: 8244
total_duration: 54851.40959512658
[2024-12-26 16:55:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.41284801158748
avg_train_sample_per_sec: 16.41284801158748
avg_episode_per_sec: 0.1414900690654093
collect_time: 42.40580303361266
reward_mean: -126.77275910364143
reward_std: 3.985161646508668
reward_max: -121.40756302521007
reward_min: -133.96638655462186
queue_len: 0.0840668163817251
wait_time: 0.8154395821104745
delay_time: 5.347160865706901
pressure: 0.996131741821397
total_envstep_count: 957000
total_train_sample_count: 957000
total_episode_count: 8250
total_duration: 54893.815398160186
[2024-12-26 16:55:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.439284400811182
avg_train_sample_per_sec: 16.439284400811182
avg_episode_per_sec: 0.1417179689725102
collect_time: 42.337609291901806
reward_mean: -122.62476657329599
reward_std: 8.40561697878989
reward_max: -111.51960784313727
reward_min: -135.24929971988797
queue_len: 0.08131615820510345
wait_time: 0.7747325499607447
delay_time: 5.1590357163571445
pressure: 0.9709328028293546
total_envstep_count: 957696
total_train_sample_count: 957696
total_episode_count: 8256
total_duration: 54936.153007452085
[2024-12-26 16:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.58795261777589
avg_train_sample_per_sec: 16.58795261777589
avg_episode_per_sec: 0.1429995915325508
collect_time: 41.958161807995296
reward_mean: -117.24381419234362
reward_std: 5.26476426069834
reward_max: -111.47058823529413
reward_min: -125.51890756302522
queue_len: 0.07774788739545332
wait_time: 0.74692156924662
delay_time: 4.909540109772525
pressure: 0.9363395225464192
total_envstep_count: 958392
total_train_sample_count: 958392
total_episode_count: 8262
total_duration: 54978.11116926008
[2024-12-26 16:57:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.460928646884557
avg_train_sample_per_sec: 17.460928646884557
avg_episode_per_sec: 0.15052524695590136
collect_time: 39.86042289475725
reward_mean: -116.66059757236228
reward_std: 7.075577262685279
reward_max: -108.06792717086836
reward_min: -127.08613445378154
queue_len: 0.07736113897371505
wait_time: 0.738554584079432
delay_time: 4.986409167851598
pressure: 0.9255083996463306
total_envstep_count: 959088
total_train_sample_count: 959088
total_episode_count: 8268
total_duration: 55017.97159215484
[2024-12-26 16:57:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.704961764062688
avg_train_sample_per_sec: 17.704961764062688
avg_episode_per_sec: 0.15262898072467831
collect_time: 39.31101401262172
reward_mean: -116.07329598506067
reward_std: 5.551869083839664
reward_max: -108.4124649859944
reward_min: -122.43977591036409
queue_len: 0.07697168168770603
wait_time: 0.7453272091329901
delay_time: 4.819825090152256
pressure: 0.9259504862953137
total_envstep_count: 959784
total_train_sample_count: 959784
total_episode_count: 8274
total_duration: 55057.282606167464
[2024-12-26 16:58:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.49302120617695
avg_train_sample_per_sec: 17.49302120617695
avg_episode_per_sec: 0.1508019069498013
collect_time: 39.787295276029035
reward_mean: -120.41701680672269
reward_std: 5.751263221799696
reward_max: -114.28641456582632
reward_min: -130.39495798319325
queue_len: 0.07985213316095667
wait_time: 0.7713265014228504
delay_time: 5.042959601386099
pressure: 0.9673961096374889
total_envstep_count: 960480
total_train_sample_count: 960480
total_episode_count: 8280
total_duration: 55097.069901443494
[2024-12-26 16:59:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.55321933173339
avg_train_sample_per_sec: 17.55321933173339
avg_episode_per_sec: 0.15132085630804648
collect_time: 39.65084619786777
reward_mean: -111.19070961718019
reward_std: 3.043841347586921
reward_max: -107.64005602240896
reward_min: -116.58753501400561
queue_len: 0.07373389231908502
wait_time: 0.7017481616873097
delay_time: 4.710322777176397
pressure: 0.8947833775419983
total_envstep_count: 961176
total_train_sample_count: 961176
total_episode_count: 8286
total_duration: 55136.72074764136
[2024-12-26 16:59:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 18.106229295482617
avg_train_sample_per_sec: 18.106229295482617
avg_episode_per_sec: 0.1560881835817467
collect_time: 38.43980923038721
reward_mean: -111.17822128851542
reward_std: 5.990014193724669
reward_max: -107.64005602240896
reward_min: -123.95798319327731
queue_len: 0.07372561093402878
wait_time: 0.704125770555791
delay_time: 4.711214447459255
pressure: 0.890473032714412
total_envstep_count: 961872
total_train_sample_count: 961872
total_episode_count: 8292
total_duration: 55175.16055687175
[2024-12-26 17:00:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.381177634205468
avg_train_sample_per_sec: 17.381177634205468
avg_episode_per_sec: 0.1498377382259092
collect_time: 40.04331666401588
reward_mean: -112.52439309056957
reward_std: 5.9038110187878985
reward_max: -107.64005602240896
reward_min: -120.94117647058829
queue_len: 0.0746182978054175
wait_time: 0.7147117025413171
delay_time: 4.7322515216720396
pressure: 0.8972148541114059
total_envstep_count: 962568
total_train_sample_count: 962568
total_episode_count: 8298
total_duration: 55215.203873535764
[2024-12-26 17:01:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.643677973295244
avg_train_sample_per_sec: 16.643677973295244
avg_episode_per_sec: 0.14347998252840727
collect_time: 41.81768002942204
reward_mean: -109.33041549953315
reward_std: 3.7797586972606685
reward_max: -107.64005602240896
reward_min: -117.78221288515404
queue_len: 0.07250027553019438
wait_time: 0.693366471256938
delay_time: 4.62603884575913
pressure: 0.8757736516357206
total_envstep_count: 963264
total_train_sample_count: 963264
total_episode_count: 8304
total_duration: 55257.02155356519
[2024-12-26 17:01:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.542379916757355
avg_train_sample_per_sec: 16.542379916757355
avg_episode_per_sec: 0.14260672342032202
collect_time: 42.07375259801373
reward_mean: -109.85889355742297
reward_std: 3.485886258042865
reward_max: -107.64005602240896
reward_min: -117.25210084033614
queue_len: 0.07285072517070489
wait_time: 0.694951002063071
delay_time: 4.626452694142345
pressure: 0.8846153846153847
total_envstep_count: 963960
total_train_sample_count: 963960
total_episode_count: 8310
total_duration: 55299.0953061632
[2024-12-26 17:02:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.227074598402446
avg_train_sample_per_sec: 17.227074598402446
avg_episode_per_sec: 0.14850926377933144
collect_time: 40.40152006217838
reward_mean: -113.94561157796453
reward_std: 9.19908216015392
reward_max: -107.562324929972
reward_min: -133.7254901960784
queue_len: 0.07556075038326558
wait_time: 0.7203928100860151
delay_time: 4.767957303522625
pressure: 0.9160035366931919
total_envstep_count: 964656
total_train_sample_count: 964656
total_episode_count: 8316
total_duration: 55339.49682622538
[2024-12-26 17:03:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.13452870552855
avg_train_sample_per_sec: 16.13452870552855
avg_episode_per_sec: 0.13909076470283233
collect_time: 43.13729968211054
reward_mean: -116.36414565826333
reward_std: 8.092864680149114
reward_max: -107.64005602240896
reward_min: -130.92226890756305
queue_len: 0.07716455282378204
wait_time: 0.7395887510618748
delay_time: 4.936980869096279
pressure: 0.9281609195402298
total_envstep_count: 965352
total_train_sample_count: 965352
total_episode_count: 8322
total_duration: 55382.63412590749
[2024-12-26 17:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.518204085215732
avg_train_sample_per_sec: 16.518204085215732
avg_episode_per_sec: 0.14239831107944598
collect_time: 42.13533120243623
reward_mean: -109.66993464052287
reward_std: 2.7392302168235227
reward_max: -107.64005602240896
reward_min: -113.65686274509802
queue_len: 0.07272542084915311
wait_time: 0.6927992350786468
delay_time: 4.67357097202522
pressure: 0.8862732095490718
total_envstep_count: 966048
total_train_sample_count: 966048
total_episode_count: 8328
total_duration: 55424.76945710993
[2024-12-26 17:04:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55205157119368
avg_train_sample_per_sec: 16.55205157119368
avg_episode_per_sec: 0.14269009975166966
collect_time: 42.04916816543043
reward_mean: -113.03221288515408
reward_std: 7.64530653303973
reward_max: -107.64005602240896
reward_min: -129.75420168067225
queue_len: 0.07495504833233028
wait_time: 0.7138224984954192
delay_time: 4.7870346041986105
pressure: 0.9063881520778073
total_envstep_count: 966744
total_train_sample_count: 966744
total_episode_count: 8334
total_duration: 55466.81862527536
[2024-12-26 17:05:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56622280278157
avg_train_sample_per_sec: 16.56622280278157
avg_episode_per_sec: 0.14281226554122045
collect_time: 42.013198076941066
reward_mean: -111.44152661064429
reward_std: 4.779501607491235
reward_max: -108.03711484593839
reward_min: -118.64635854341738
queue_len: 0.07390021658530786
wait_time: 0.7021576645689221
delay_time: 4.721080025215911
pressure: 0.89710433244916
total_envstep_count: 967440
total_train_sample_count: 967440
total_episode_count: 8340
total_duration: 55508.8318233523
[2024-12-26 17:06:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.531644141090588
avg_train_sample_per_sec: 16.531644141090588
avg_episode_per_sec: 0.14251417363009128
collect_time: 42.10107561352849
reward_mean: -112.74101307189544
reward_std: 7.240854305682522
reward_max: -107.64005602240896
reward_min: -124.0252100840336
queue_len: 0.07476194500788821
wait_time: 0.7151146267525577
delay_time: 4.7355262430408755
pressure: 0.9013041556145004
total_envstep_count: 968136
total_train_sample_count: 968136
total_episode_count: 8346
total_duration: 55550.93289896583
[2024-12-26 17:06:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.044760386037634
avg_train_sample_per_sec: 17.044760386037634
avg_episode_per_sec: 0.1469375895348072
collect_time: 40.83366291086934
reward_mean: -107.77999533146591
reward_std: 0.19833980783376462
reward_max: -107.64005602240896
reward_min: -108.0826330532213
queue_len: 0.07147214544526918
wait_time: 0.680316014557901
delay_time: 4.581571945881306
pressure: 0.8703580901856763
total_envstep_count: 968832
total_train_sample_count: 968832
total_episode_count: 8352
total_duration: 55591.7665618767
[2024-12-26 17:07:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.991048580916438
avg_train_sample_per_sec: 16.991048580916438
avg_episode_per_sec: 0.14647455673203824
collect_time: 40.96274557073041
reward_mean: -119.92401960784314
reward_std: 3.683573986681628
reward_max: -115.50840336134455
reward_min: -124.12324929971989
queue_len: 0.07952521194154054
wait_time: 0.7585288978544557
delay_time: 5.176363376317637
pressure: 0.9429708222811671
total_envstep_count: 969528
total_train_sample_count: 969528
total_episode_count: 8358
total_duration: 55632.72930744743
[2024-12-26 17:08:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.061835919735735
avg_train_sample_per_sec: 17.061835919735735
avg_episode_per_sec: 0.14708479241151495
collect_time: 40.79279646540993
reward_mean: -112.05742296918767
reward_std: 6.078587320025097
reward_max: -107.64005602240896
reward_min: -122.64215686274511
queue_len: 0.07430863592121198
wait_time: 0.7087521237495883
delay_time: 4.728183426727868
pressure: 0.9067197170645446
total_envstep_count: 970224
total_train_sample_count: 970224
total_episode_count: 8364
total_duration: 55673.52210391284
[2024-12-26 17:08:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.96681143298518
avg_train_sample_per_sec: 16.96681143298518
avg_episode_per_sec: 0.14626561580159636
collect_time: 41.02126099232213
reward_mean: -110.16456582633053
reward_std: 5.644975531433297
reward_max: -107.64005602240896
reward_min: -122.78711484593838
queue_len: 0.07305342561427754
wait_time: 0.698656031820332
delay_time: 4.664105641649527
pressure: 0.883841732979664
total_envstep_count: 970920
total_train_sample_count: 970920
total_episode_count: 8370
total_duration: 55714.54336490516
[2024-12-26 17:09:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.802633469750923
avg_train_sample_per_sec: 16.802633469750923
avg_episode_per_sec: 0.14485028853233553
collect_time: 41.42207834581286
reward_mean: -111.71743697478992
reward_std: 5.778363225756186
reward_max: -107.64005602240896
reward_min: -120.51890756302522
queue_len: 0.07408318101776519
wait_time: 0.7094181947756999
delay_time: 4.7444655980583335
pressure: 0.8941202475685235
total_envstep_count: 971616
total_train_sample_count: 971616
total_episode_count: 8376
total_duration: 55755.96544325098
[2024-12-26 17:10:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.908265569320044
avg_train_sample_per_sec: 16.908265569320044
avg_episode_per_sec: 0.14576091008034522
collect_time: 41.16329952037707
reward_mean: -109.24253034547151
reward_std: 2.1642199883559936
reward_max: -107.64005602240896
reward_min: -113.32422969187677
queue_len: 0.07244199625031268
wait_time: 0.688727889475861
delay_time: 4.586065495189814
pressure: 0.881078691423519
total_envstep_count: 972312
total_train_sample_count: 972312
total_episode_count: 8382
total_duration: 55797.128742771354
[2024-12-26 17:11:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.936706423128552
avg_train_sample_per_sec: 16.936706423128552
avg_episode_per_sec: 0.1460060898545565
collect_time: 41.09417631810345
reward_mean: -110.96755368814193
reward_std: 3.8978359681807158
reward_max: -107.64005602240896
reward_min: -118.3319327731092
queue_len: 0.0735859109337811
wait_time: 0.7010524479464642
delay_time: 4.688144926425699
pressure: 0.8936781609195403
total_envstep_count: 973008
total_train_sample_count: 973008
total_episode_count: 8388
total_duration: 55838.22291908946
[2024-12-26 17:11:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81650886939734
avg_train_sample_per_sec: 16.81650886939734
avg_episode_per_sec: 0.1449699040465288
collect_time: 41.387900747139014
reward_mean: -113.27579365079366
reward_std: 8.000928528502154
reward_max: -107.64005602240896
reward_min: -125.76190476190476
queue_len: 0.07511657403898783
wait_time: 0.7168592127390303
delay_time: 4.736885209989816
pressure: 0.907051282051282
total_envstep_count: 973704
total_train_sample_count: 973704
total_episode_count: 8394
total_duration: 55879.6108198366
[2024-12-26 17:12:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.051358734710654
avg_train_sample_per_sec: 17.051358734710654
avg_episode_per_sec: 0.14699447185095393
collect_time: 40.81786154573039
reward_mean: -109.3313492063492
reward_std: 3.500456044797882
reward_max: -107.64005602240896
reward_min: -117.14075630252101
queue_len: 0.07250089469917056
wait_time: 0.693571106603561
delay_time: 4.6394483456859845
pressure: 0.8819628647214856
total_envstep_count: 974400
total_train_sample_count: 974400
total_episode_count: 8400
total_duration: 55920.42868138233
[2024-12-26 17:13:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.002960375381768
avg_train_sample_per_sec: 17.002960375381768
avg_episode_per_sec: 0.1465772446153601
collect_time: 40.93404822655023
reward_mean: -117.35130718954248
reward_std: 7.375565718242792
reward_max: -107.64005602240896
reward_min: -125.6967787114846
queue_len: 0.07781916922383454
wait_time: 0.7549746357428914
delay_time: 4.913902312781281
pressure: 0.9416445623342176
total_envstep_count: 975096
total_train_sample_count: 975096
total_episode_count: 8406
total_duration: 55961.362729608874
[2024-12-26 17:13:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.98395231418636
avg_train_sample_per_sec: 16.98395231418636
avg_episode_per_sec: 0.14641338201884793
collect_time: 40.97986070171929
reward_mean: -113.67436974789916
reward_std: 8.03521648657767
reward_max: -107.64005602240896
reward_min: -126.98669467787114
queue_len: 0.0753808817956891
wait_time: 0.7199634937971652
delay_time: 4.790564291439763
pressure: 0.9111405835543768
total_envstep_count: 975792
total_train_sample_count: 975792
total_episode_count: 8412
total_duration: 56002.342590310596
[2024-12-26 17:14:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.858436908203608
avg_train_sample_per_sec: 16.858436908203608
avg_episode_per_sec: 0.14533135265692765
collect_time: 41.284966322192915
reward_mean: -114.06851073762839
reward_std: 8.017249579074251
reward_max: -107.64005602240896
reward_min: -128.36904761904762
queue_len: 0.07564224849975355
wait_time: 0.7244085078770678
delay_time: 4.87579716986336
pressure: 0.920424403183024
total_envstep_count: 976488
total_train_sample_count: 976488
total_episode_count: 8418
total_duration: 56043.62755663279
[2024-12-26 17:15:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.045110742705432
avg_train_sample_per_sec: 17.045110742705432
avg_episode_per_sec: 0.1469406098509089
collect_time: 40.832823588304215
reward_mean: -108.59955648926235
reward_std: 2.112175784229246
reward_max: -107.64005602240896
reward_min: -113.32212885154057
queue_len: 0.07201562101409971
wait_time: 0.6856038724066108
delay_time: 4.612113468262799
pressure: 0.875
total_envstep_count: 977184
total_train_sample_count: 977184
total_episode_count: 8424
total_duration: 56084.46038022109
[2024-12-26 17:15:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83806465681604
avg_train_sample_per_sec: 16.83806465681604
avg_episode_per_sec: 0.14515572980013827
collect_time: 41.33491670126469
reward_mean: -110.37780112044815
reward_std: 4.80645003987088
reward_max: -108.2282913165266
reward_min: -121.12535014005603
queue_len: 0.07319482832920966
wait_time: 0.6996988671684413
delay_time: 4.663986338978144
pressure: 0.8895888594164455
total_envstep_count: 977880
total_train_sample_count: 977880
total_episode_count: 8430
total_duration: 56125.795296922355
[2024-12-26 17:16:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.700583338776266
avg_train_sample_per_sec: 16.700583338776266
avg_episode_per_sec: 0.14397054602393333
collect_time: 41.67519097276032
reward_mean: -110.40021008403359
reward_std: 3.765037939556608
reward_max: -108.2282913165266
reward_min: -118.51540616246497
queue_len: 0.07320968838463766
wait_time: 0.7007482037908002
delay_time: 4.668994944727346
pressure: 0.888262599469496
total_envstep_count: 978576
total_train_sample_count: 978576
total_episode_count: 8436
total_duration: 56167.470487895116
[2024-12-26 17:17:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7741026241008
avg_train_sample_per_sec: 16.7741026241008
avg_episode_per_sec: 0.1446043329663862
collect_time: 41.492532602012155
reward_mean: -108.21440242763771
reward_std: 0.031056499687495312
reward_max: -108.14495798319327
reward_min: -108.2282913165266
queue_len: 0.07176021381143084
wait_time: 0.6827695490220846
delay_time: 4.584329883512756
pressure: 0.8738947833775419
total_envstep_count: 979272
total_train_sample_count: 979272
total_episode_count: 8442
total_duration: 56208.963020497125
[2024-12-26 17:18:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.710352589763993
avg_train_sample_per_sec: 16.710352589763993
avg_episode_per_sec: 0.144054763704862
collect_time: 41.65082671124116
reward_mean: -114.6659663865546
reward_std: 8.901375270213995
reward_max: -107.64005602240896
reward_min: -127.8018207282913
queue_len: 0.0760384392483784
wait_time: 0.72607763264457
delay_time: 4.902009042568217
pressure: 0.9166666666666666
total_envstep_count: 979968
total_train_sample_count: 979968
total_episode_count: 8448
total_duration: 56250.61384720837
[2024-12-26 17:18:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.753903587943448
avg_train_sample_per_sec: 16.753903587943448
avg_episode_per_sec: 0.14443020334434006
collect_time: 41.54255731188879
reward_mean: -109.67495331465916
reward_std: 2.633616129730084
reward_max: -107.64005602240896
reward_min: -114.72268907563023
queue_len: 0.0727287488824
wait_time: 0.6906845408366706
delay_time: 4.6370439191747455
pressure: 0.8863837312113173
total_envstep_count: 980664
total_train_sample_count: 980664
total_episode_count: 8454
total_duration: 56292.15640452026
[2024-12-26 17:19:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.608102673273248
avg_train_sample_per_sec: 16.608102673273248
avg_episode_per_sec: 0.143173298907528
collect_time: 41.907255373610184
reward_mean: -114.88048552754431
reward_std: 9.914235874936477
reward_max: -107.64005602240896
reward_min: -131.05252100840332
queue_len: 0.07618069332065275
wait_time: 0.7280067309859399
delay_time: 4.9127160973597
pressure: 0.9152298850574713
total_envstep_count: 981360
total_train_sample_count: 981360
total_episode_count: 8460
total_duration: 56334.06365989387
[2024-12-26 17:20:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.38521018010935
avg_train_sample_per_sec: 17.38521018010935
avg_episode_per_sec: 0.14987250155266682
collect_time: 40.034028509836645
reward_mean: -114.25093370681606
reward_std: 9.380171430757185
reward_max: -107.64005602240896
reward_min: -128.79201680672267
queue_len: 0.07576321863847219
wait_time: 0.729245920295616
delay_time: 4.759896585495496
pressure: 0.9189876215738285
total_envstep_count: 982056
total_train_sample_count: 982056
total_episode_count: 8466
total_duration: 56374.09768840371
[2024-12-26 17:20:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.861468999294466
avg_train_sample_per_sec: 17.861468999294466
avg_episode_per_sec: 0.15397818102840055
collect_time: 38.96655980689451
reward_mean: -107.96895424836602
reward_std: 0.7354387909190544
reward_max: -107.64005602240896
reward_min: -109.61344537815127
queue_len: 0.07159744976682096
wait_time: 0.6820656312923048
delay_time: 4.589990594776382
pressure: 0.870579133510168
total_envstep_count: 982752
total_train_sample_count: 982752
total_episode_count: 8472
total_duration: 56413.064248210605
[2024-12-26 17:21:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.803304543388762
avg_train_sample_per_sec: 17.803304543388762
avg_episode_per_sec: 0.15347676330507554
collect_time: 39.09386587775126
reward_mean: -109.61799719887955
reward_std: 3.273853880824147
reward_max: -107.64005602240896
reward_min: -116.91946778711484
queue_len: 0.07269097957485382
wait_time: 0.6935396837780207
delay_time: 4.647164876301529
pressure: 0.8807471264367815
total_envstep_count: 983448
total_train_sample_count: 983448
total_episode_count: 8478
total_duration: 56452.15811408836
[2024-12-26 17:22:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.799502061363494
avg_train_sample_per_sec: 17.799502061363494
avg_episode_per_sec: 0.15344398328761633
collect_time: 39.10221744409205
reward_mean: -107.85842670401495
reward_std: 0.28407917192947485
reward_max: -107.64005602240896
reward_min: -108.28711484593836
queue_len: 0.0715241556392672
wait_time: 0.6808197085200128
delay_time: 4.58516968866498
pressure: 0.870579133510168
total_envstep_count: 984144
total_train_sample_count: 984144
total_episode_count: 8484
total_duration: 56491.26033153245
[2024-12-26 17:22:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.862488653568374
avg_train_sample_per_sec: 17.862488653568374
avg_episode_per_sec: 0.1539869711514515
collect_time: 38.96433545730822
reward_mean: -109.64028944911297
reward_std: 3.623545191551187
reward_max: -107.64005602240896
reward_min: -117.71708683473392
queue_len: 0.0727057622341598
wait_time: 0.6916150744117276
delay_time: 4.681260681892543
pressure: 0.8858311229000884
total_envstep_count: 984840
total_train_sample_count: 984840
total_episode_count: 8490
total_duration: 56530.22466698976
[2024-12-26 17:23:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.73677509587579
avg_train_sample_per_sec: 17.73677509587579
avg_episode_per_sec: 0.15290323358513613
collect_time: 39.240504332821814
reward_mean: -109.89624183006536
reward_std: 5.044984835789973
reward_max: -107.64005602240896
reward_min: -121.17717086834735
queue_len: 0.07287549192975157
wait_time: 0.6973223418456684
delay_time: 4.64572180556635
pressure: 0.8845048629531389
total_envstep_count: 985536
total_train_sample_count: 985536
total_episode_count: 8496
total_duration: 56569.46517132258
[2024-12-26 17:24:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8804238402327
avg_train_sample_per_sec: 16.8804238402327
avg_episode_per_sec: 0.14552089517441985
collect_time: 41.23119221338256
reward_mean: -113.16269841269842
reward_std: 8.146312769609036
reward_max: -107.64005602240896
reward_min: -128.21918767507
queue_len: 0.0750415771967496
wait_time: 0.7187320440996912
delay_time: 4.768318850454134
pressure: 0.9046198054818745
total_envstep_count: 986232
total_train_sample_count: 986232
total_episode_count: 8502
total_duration: 56610.696363535964
[2024-12-26 17:24:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.01393781788127
avg_train_sample_per_sec: 17.01393781788127
avg_episode_per_sec: 0.14667187774035578
collect_time: 40.90763745877333
reward_mean: -121.02626050420167
reward_std: 12.13926692099025
reward_max: -107.64005602240896
reward_min: -143.5707282913165
queue_len: 0.08025614091790562
wait_time: 0.768046453771606
delay_time: 5.19116094090387
pressure: 0.959106984969054
total_envstep_count: 986928
total_train_sample_count: 986928
total_episode_count: 8508
total_duration: 56651.60400099474
[2024-12-26 17:25:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.19125923239465
avg_train_sample_per_sec: 17.19125923239465
avg_episode_per_sec: 0.1482005106240918
collect_time: 40.48569046579672
reward_mean: -109.36858076563959
reward_std: 3.8650988266540613
reward_max: -107.64005602240896
reward_min: -118.01120448179275
queue_len: 0.07252558406209521
wait_time: 0.6943284276575352
delay_time: 4.6347219359234835
pressure: 0.8850574712643678
total_envstep_count: 987624
total_train_sample_count: 987624
total_episode_count: 8514
total_duration: 56692.08969146053
[2024-12-26 17:26:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.00521967466015
avg_train_sample_per_sec: 17.00521967466015
avg_episode_per_sec: 0.14659672133327717
collect_time: 40.92860976310261
reward_mean: -107.75490196078431
reward_std: 0.2568033251470364
reward_max: -107.64005602240896
reward_min: -108.32913165266106
queue_len: 0.07145550527903469
wait_time: 0.6814598518452475
delay_time: 4.587032414674305
pressure: 0.8683687002652519
total_envstep_count: 988320
total_train_sample_count: 988320
total_episode_count: 8520
total_duration: 56733.01830122364
[2024-12-26 17:26:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.2030393679523
avg_train_sample_per_sec: 17.2030393679523
avg_episode_per_sec: 0.14830206351683017
collect_time: 40.457967055320744
reward_mean: -110.44222689075629
reward_std: 4.178540186557282
reward_max: -107.55672268907561
reward_min: -118.22408963585433
queue_len: 0.07323755098856517
wait_time: 0.698626389105598
delay_time: 4.677017327549245
pressure: 0.8862732095490716
total_envstep_count: 989016
total_train_sample_count: 989016
total_episode_count: 8526
total_duration: 56773.47626827896
[2024-12-26 17:27:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.110771695395407
avg_train_sample_per_sec: 17.110771695395407
avg_episode_per_sec: 0.14750665254651213
collect_time: 40.67613152639381
reward_mean: -111.86169467787117
reward_std: 4.408200132261281
reward_max: -107.64005602240896
reward_min: -118.40056022408965
queue_len: 0.07417884262458299
wait_time: 0.7085675339985685
delay_time: 4.734441041275783
pressure: 0.8905835543766578
total_envstep_count: 989712
total_train_sample_count: 989712
total_episode_count: 8532
total_duration: 56814.15239980535
[2024-12-26 17:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.015369176575874
avg_train_sample_per_sec: 17.015369176575874
avg_episode_per_sec: 0.14668421703944717
collect_time: 40.90419624618813
reward_mean: -112.12850140056024
reward_std: 10.036468978840961
reward_max: -107.64005602240896
reward_min: -134.5707282913165
queue_len: 0.07435577015952269
wait_time: 0.7117851229793422
delay_time: 4.761537397616956
pressure: 0.9005305039787799
total_envstep_count: 990408
total_train_sample_count: 990408
total_episode_count: 8538
total_duration: 56855.05659605154
[2024-12-26 17:28:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.093358306594478
avg_train_sample_per_sec: 17.093358306594478
avg_episode_per_sec: 0.14735653712581445
collect_time: 40.71756921701506
reward_mean: -109.0264939309057
reward_std: 2.0524277238702986
reward_max: -107.64005602240896
reward_min: -112.85014005602241
queue_len: 0.07229873602845205
wait_time: 0.6880569424940622
delay_time: 4.622231282327427
pressure: 0.8800839964633068
total_envstep_count: 991104
total_train_sample_count: 991104
total_episode_count: 8544
total_duration: 56895.77416526855
[2024-12-26 17:29:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.19644053450932
avg_train_sample_per_sec: 17.19644053450932
avg_episode_per_sec: 0.1482451770216321
collect_time: 40.47349209292977
reward_mean: -116.24836601307187
reward_std: 8.028325905591402
reward_max: -107.64005602240896
reward_min: -126.79971988795518
queue_len: 0.07708777587073733
wait_time: 0.729056764173397
delay_time: 5.003425694462458
pressure: 0.9293766578249337
total_envstep_count: 991800
total_train_sample_count: 991800
total_episode_count: 8550
total_duration: 56936.247657361484
[2024-12-26 17:30:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.13142267197512
avg_train_sample_per_sec: 17.13142267197512
avg_episode_per_sec: 0.14768467820668205
collect_time: 40.627098713673654
reward_mean: -113.04143323996266
reward_std: 9.085281263108241
reward_max: -107.64005602240896
reward_min: -132.36344537815125
queue_len: 0.07496116262596993
wait_time: 0.719105712576808
delay_time: 4.742226572188037
pressure: 0.9150088417329797
total_envstep_count: 992496
total_train_sample_count: 992496
total_episode_count: 8556
total_duration: 56976.87475607516
[2024-12-26 17:31:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.970532385011584
avg_train_sample_per_sec: 16.970532385011584
avg_episode_per_sec: 0.14629769297423778
collect_time: 41.01226668732614
reward_mean: -112.02602707749769
reward_std: 8.634663412587026
reward_max: -107.64005602240896
reward_min: -131.20238095238102
queue_len: 0.07428781636438839
wait_time: 0.7079718934434959
delay_time: 4.763057348843372
pressure: 0.8988726790450929
total_envstep_count: 993192
total_train_sample_count: 993192
total_episode_count: 8562
total_duration: 57017.88702276249
[2024-12-26 17:31:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.085443214288443
avg_train_sample_per_sec: 17.085443214288443
avg_episode_per_sec: 0.1472883035714521
collect_time: 40.73643225233629
reward_mean: -119.26038748832867
reward_std: 9.401223124702195
reward_max: -107.64005602240896
reward_min: -133.7044817927171
queue_len: 0.0790851375917299
wait_time: 0.7525854174561073
delay_time: 5.0816469602538366
pressure: 0.9497126436781609
total_envstep_count: 993888
total_train_sample_count: 993888
total_episode_count: 8568
total_duration: 57058.62345501482
[2024-12-26 17:32:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90336267709194
avg_train_sample_per_sec: 16.90336267709194
avg_episode_per_sec: 0.14571864376803398
collect_time: 41.17523911045492
reward_mean: -120.47362278244633
reward_std: 9.622673416216557
reward_max: -109.08403361344536
reward_min: -133.01260504201682
queue_len: 0.07988967028013681
wait_time: 0.7688242074017936
delay_time: 5.038901736824889
pressure: 0.9715959328028293
total_envstep_count: 994584
total_train_sample_count: 994584
total_episode_count: 8574
total_duration: 57099.798694125275
[2024-12-26 17:33:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.998830135431025
avg_train_sample_per_sec: 16.998830135431025
avg_episode_per_sec: 0.1465416390985433
collect_time: 40.943994054585694
reward_mean: -119.9237861811391
reward_std: 4.970117304974981
reward_max: -113.63655462184875
reward_min: -126.45798319327731
queue_len: 0.07952505714929649
wait_time: 0.7673572413050099
delay_time: 5.074515357408637
pressure: 0.9514809902740936
total_envstep_count: 995280
total_train_sample_count: 995280
total_episode_count: 8580
total_duration: 57140.74268817986
[2024-12-26 17:33:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.84830562397285
avg_train_sample_per_sec: 16.84830562397285
avg_episode_per_sec: 0.14524401399976591
collect_time: 41.30979194784351
reward_mean: -120.26015406162465
reward_std: 3.589899275090775
reward_max: -115.8970588235294
reward_min: -125.56232492997198
queue_len: 0.07974811277296064
wait_time: 0.7636161449548874
delay_time: 5.112646312042411
pressure: 0.9655172413793104
total_envstep_count: 995976
total_train_sample_count: 995976
total_episode_count: 8586
total_duration: 57182.052480127706
[2024-12-26 17:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.086635343683728
avg_train_sample_per_sec: 17.086635343683728
avg_episode_per_sec: 0.14729858054899767
collect_time: 40.73359008374252
reward_mean: -120.70833333333336
reward_std: 6.852971168730937
reward_max: -114.87745098039214
reward_min: -135.421568627451
queue_len: 0.0800453138815208
wait_time: 0.7676214716655894
delay_time: 5.112343357706297
pressure: 0.9679487179487177
total_envstep_count: 996672
total_train_sample_count: 996672
total_episode_count: 8592
total_duration: 57222.78607021145
[2024-12-26 17:35:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.037143815498823
avg_train_sample_per_sec: 17.037143815498823
avg_episode_per_sec: 0.14687192944395538
collect_time: 40.851917876448475
reward_mean: -118.36519607843138
reward_std: 3.5459521328671832
reward_max: -115.29621848739495
reward_min: -124.21218487394958
queue_len: 0.07849150933582984
wait_time: 0.7536332061560258
delay_time: 4.941455027112162
pressure: 0.9487179487179488
total_envstep_count: 997368
total_train_sample_count: 997368
total_episode_count: 8598
total_duration: 57263.637988087896
[2024-12-26 17:35:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.02175414444222
avg_train_sample_per_sec: 17.02175414444222
avg_episode_per_sec: 0.1467392598658812
collect_time: 40.888852822918444
reward_mean: -120.65277777777777
reward_std: 6.464571838577062
reward_max: -113.3060224089636
reward_min: -130.5392156862745
queue_len: 0.08000847332743882
wait_time: 0.7673275985902762
delay_time: 5.069626696305076
pressure: 0.9592175066312997
total_envstep_count: 998064
total_train_sample_count: 998064
total_episode_count: 8604
total_duration: 57304.52684091082
[2024-12-26 17:36:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.958312949809475
avg_train_sample_per_sec: 16.958312949809475
avg_episode_per_sec: 0.1461923530155989
collect_time: 41.04181837308407
reward_mean: -118.21381886087767
reward_std: 4.938273244210281
reward_max: -113.54201680672269
reward_min: -125.62605042016804
queue_len: 0.07839112656556875
wait_time: 0.755344511810029
delay_time: 4.903361559648606
pressure: 0.9562334217506631
total_envstep_count: 998760
total_train_sample_count: 998760
total_episode_count: 8610
total_duration: 57345.568659283905
[2024-12-26 17:37:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.180420767928624
avg_train_sample_per_sec: 17.180420767928624
avg_episode_per_sec: 0.14810707558559158
collect_time: 40.51123132555932
reward_mean: -114.40172735760972
reward_std: 3.3043624590664717
reward_max: -107.64005602240896
reward_min: -118.30042016806725
queue_len: 0.07586321442812315
wait_time: 0.725496000787583
delay_time: 4.77635356069795
pressure: 0.9206454465075155
total_envstep_count: 999456
total_train_sample_count: 999456
total_episode_count: 8616
total_duration: 57386.079890609464
[2024-12-26 17:37:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.011653760559646
avg_train_sample_per_sec: 17.011653760559646
avg_episode_per_sec: 0.14665218759103144
collect_time: 40.91312989296951
reward_mean: -122.21767040149393
reward_std: 9.592209359893854
reward_max: -114.0994397759104
reward_min: -141.5511204481793
queue_len: 0.08104620053149465
wait_time: 0.7809161131296021
delay_time: 5.1720731540712865
pressure: 0.9714854111405836
total_envstep_count: 1000152
total_train_sample_count: 1000152
total_episode_count: 8622
total_duration: 57426.993020502436
[2024-12-26 17:38:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.961586026202756
avg_train_sample_per_sec: 16.961586026202756
avg_episode_per_sec: 0.14622056919140308
collect_time: 41.03389853547886
reward_mean: -123.64670868347339
reward_std: 8.926515707303844
reward_max: -115.89495798319328
reward_min: -140.09593837535016
queue_len: 0.08199383864951816
wait_time: 0.7855469552984764
delay_time: 5.31450568355485
pressure: 0.9750221043324493
total_envstep_count: 1000848
total_train_sample_count: 1000848
total_episode_count: 8628
total_duration: 57468.02691903791
[2024-12-26 17:39:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.91693931435254
avg_train_sample_per_sec: 16.91693931435254
avg_episode_per_sec: 0.14583568374441844
collect_time: 41.142194049812844
reward_mean: -120.77882819794587
reward_std: 4.993775425040533
reward_max: -113.29411764705884
reward_min: -127.02591036414573
queue_len: 0.0800920611392214
wait_time: 0.7606861599635434
delay_time: 5.205015551997229
pressure: 0.9602122015915119
total_envstep_count: 1001544
total_train_sample_count: 1001544
total_episode_count: 8634
total_duration: 57509.16911308772
[2024-12-26 17:40:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.968723250574843
avg_train_sample_per_sec: 16.968723250574843
avg_episode_per_sec: 0.14628209698771416
collect_time: 41.01663924399391
reward_mean: -119.77322595704949
reward_std: 4.304130519891533
reward_max: -113.25350140056022
reward_min: -125.97829131652664
queue_len: 0.07942521615188959
wait_time: 0.7594707312633276
delay_time: 5.112832255397979
pressure: 0.951923076923077
total_envstep_count: 1002240
total_train_sample_count: 1002240
total_episode_count: 8640
total_duration: 57550.185752331716
[2024-12-26 17:40:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.910425824741736
avg_train_sample_per_sec: 16.910425824741736
avg_episode_per_sec: 0.1457795329719115
collect_time: 41.1580410341695
reward_mean: -120.63690476190477
reward_std: 7.596435251642266
reward_max: -113.29411764705884
reward_min: -133.11834733893556
queue_len: 0.07999794745484401
wait_time: 0.7711271290125246
delay_time: 5.065290772770617
pressure: 0.9670645446507516
total_envstep_count: 1002936
total_train_sample_count: 1002936
total_episode_count: 8646
total_duration: 57591.343793365886
[2024-12-26 17:41:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.223791891086904
avg_train_sample_per_sec: 17.223791891086904
avg_episode_per_sec: 0.14848096457833537
collect_time: 40.40922024610453
reward_mean: -113.68872549019606
reward_std: 1.018036352537764
reward_max: -112.67156862745097
reward_min: -115.77521008403362
queue_len: 0.07539040151869766
wait_time: 0.7216659762932581
delay_time: 4.7572715214557775
pressure: 0.9089301503094607
total_envstep_count: 1003632
total_train_sample_count: 1003632
total_episode_count: 8652
total_duration: 57631.75301361199
[2024-12-26 17:42:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.145117930457783
avg_train_sample_per_sec: 17.145117930457783
avg_episode_per_sec: 0.14780274077980846
collect_time: 40.59464640739374
reward_mean: -116.7009803921569
reward_std: 4.738729598075164
reward_max: -113.08053221288517
reward_min: -126.7296918767507
queue_len: 0.07738791803193427
wait_time: 0.7412497492365646
delay_time: 4.903560737696652
pressure: 0.9376657824933687
total_envstep_count: 1004328
total_train_sample_count: 1004328
total_episode_count: 8658
total_duration: 57672.34766001938
