[2024-12-26 20:12:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 10
envstep_count: 1240
train_sample_count: 1240
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.667021643677491
avg_train_sample_per_sec: 3.667021643677491
avg_episode_per_sec: 0.029572755190947507
collect_time: 338.1490813226998
reward_mean: -2116.2071428571426
reward_std: 177.0112629011996
reward_max: -1777.7857142857138
reward_min: -2432.6428571428573
queue_len: 1.3127835873803615
wait_time: 6.185173697270471
delay_time: 509.7041526135816
pressure: 15.126426799007444
total_envstep_count: 1240
total_train_sample_count: 1240
total_episode_count: 10
total_duration: 338.1490813226998
[2024-12-26 20:15:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.647948400607296
avg_train_sample_per_sec: 3.647948400607296
avg_episode_per_sec: 0.02941893871457497
collect_time: 169.95854434146733
reward_mean: -2272.071428571429
reward_std: 110.1657934243492
reward_max: -2146.285714285715
reward_min: -2415.000000000001
queue_len: 1.409473590925204
wait_time: 6.135501595179013
delay_time: 581.6498739357809
pressure: 15.799875930521091
total_envstep_count: 1860
total_train_sample_count: 1860
total_episode_count: 15
total_duration: 508.10762566416713
[2024-12-26 20:18:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5152754224896396
avg_train_sample_per_sec: 3.5152754224896396
avg_episode_per_sec: 0.028348995342658383
collect_time: 176.37309328123558
reward_mean: -2183.5571428571434
reward_std: 376.79927098157276
reward_max: -1734.9285714285722
reward_min: -2856.0
queue_len: 1.3545639844026944
wait_time: 5.95170152428217
delay_time: 566.6826861550068
pressure: 14.873325062034741
total_envstep_count: 2480
total_train_sample_count: 2480
total_episode_count: 20
total_duration: 684.4807189454027
[2024-12-26 20:21:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6046798891529885
avg_train_sample_per_sec: 3.6046798891529885
avg_episode_per_sec: 0.02906999910607249
collect_time: 171.99862930011375
reward_mean: -2137.1000000000004
reward_std: 122.37804925220667
reward_max: -1949.2142857142862
reward_min: -2312.785714285715
queue_len: 1.3257444168734493
wait_time: 5.899991137894362
delay_time: 564.513371873186
pressure: 14.371712158808933
total_envstep_count: 3100
total_train_sample_count: 3100
total_episode_count: 25
total_duration: 856.4793482455165
[2024-12-26 20:24:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.359772033400727
avg_train_sample_per_sec: 3.359772033400727
avg_episode_per_sec: 0.02709493575323167
collect_time: 184.536329797484
reward_mean: -2398.5857142857144
reward_std: 379.3042540532033
reward_max: -1822.9285714285722
reward_min: -2900.285714285714
queue_len: 1.4879563984402697
wait_time: 6.0507266926621766
delay_time: 674.532902920785
pressure: 15.563151364764266
total_envstep_count: 3720
total_train_sample_count: 3720
total_episode_count: 30
total_duration: 1041.0156780430004
[2024-12-26 20:27:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.4410565410390874
avg_train_sample_per_sec: 3.4410565410390874
avg_episode_per_sec: 0.027750455976121673
collect_time: 180.17721958523242
reward_mean: -2584.157142857143
reward_std: 254.54224379766768
reward_max: -2230.7857142857138
reward_min: -2926.4285714285716
queue_len: 1.6030751506557954
wait_time: 6.223511166253102
delay_time: 698.2639781458671
pressure: 18.254838709677422
total_envstep_count: 4340
total_train_sample_count: 4340
total_episode_count: 35
total_duration: 1221.192897628233
[2024-12-26 20:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.414503859931389
avg_train_sample_per_sec: 3.414503859931389
avg_episode_per_sec: 0.027536321451059588
collect_time: 181.57835674915836
reward_mean: -2353.8142857142857
reward_std: 427.5069508922926
reward_max: -1889.785714285714
reward_min: -3056.5714285714303
queue_len: 1.4601825593761077
wait_time: 6.019815668202763
delay_time: 632.7849148461435
pressure: 16.512655086848635
total_envstep_count: 4960
total_train_sample_count: 4960
total_episode_count: 40
total_duration: 1402.7712543773912
[2024-12-26 20:33:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3550774029118466
avg_train_sample_per_sec: 3.3550774029118466
avg_episode_per_sec: 0.027057075829934246
collect_time: 184.79454437084124
reward_mean: -2708.957142857143
reward_std: 60.92217517925193
reward_max: -2644.928571428571
reward_min: -2810.7857142857147
queue_len: 1.6804945054945055
wait_time: 6.111086494151009
delay_time: 765.9935571801377
pressure: 17.34776674937965
total_envstep_count: 5580
total_train_sample_count: 5580
total_episode_count: 45
total_duration: 1587.5657987482325
[2024-12-26 20:36:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.4552478521670467
avg_train_sample_per_sec: 3.4552478521670467
avg_episode_per_sec: 0.027864902033605216
collect_time: 179.43720002926887
reward_mean: -2394.914285714286
reward_std: 183.7687510910135
reward_max: -2186.0000000000014
reward_min: -2724.0714285714284
queue_len: 1.4856788372917407
wait_time: 5.88441155618575
delay_time: 701.517588473602
pressure: 14.227915632754343
total_envstep_count: 6200
total_train_sample_count: 6200
total_episode_count: 50
total_duration: 1767.0029987775015
[2024-12-26 20:39:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3455894644203106
avg_train_sample_per_sec: 3.3455894644203106
avg_episode_per_sec: 0.026980560196937987
collect_time: 185.3186132350005
reward_mean: -2521.271428571428
reward_std: 147.19157584590235
reward_max: -2287.714285714285
reward_min: -2734.142857142857
queue_len: 1.5640641616448063
wait_time: 5.892112725983694
delay_time: 706.5881850790555
pressure: 15.14739454094293
total_envstep_count: 6820
total_train_sample_count: 6820
total_episode_count: 55
total_duration: 1952.321612012502
[2024-12-26 20:42:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.634649057222282
avg_train_sample_per_sec: 3.634649057222282
avg_episode_per_sec: 0.029311685945340987
collect_time: 170.58043025309968
reward_mean: -2382.3857142857146
reward_std: 351.730339659141
reward_max: -2019.7857142857147
reward_min: -3049.571428571429
queue_len: 1.4779067706487063
wait_time: 5.591979794399149
delay_time: 646.7196193360762
pressure: 15.539454094292804
total_envstep_count: 7440
total_train_sample_count: 7440
total_episode_count: 60
total_duration: 2122.9020422656017
[2024-12-26 20:45:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.235671494602906
avg_train_sample_per_sec: 3.235671494602906
avg_episode_per_sec: 0.026094124956475048
collect_time: 191.61401305236296
reward_mean: -2755.6
reward_std: 206.28911057750244
reward_max: -2465.0714285714284
reward_min: -3111.4285714285706
queue_len: 1.7094292803970224
wait_time: 6.0434331797235
delay_time: 784.6318708147728
pressure: 14.999627791563276
total_envstep_count: 8060
total_train_sample_count: 8060
total_episode_count: 65
total_duration: 2314.516055317965
[2024-12-26 20:48:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.487959051001126
avg_train_sample_per_sec: 3.487959051001126
avg_episode_per_sec: 0.02812870202420263
collect_time: 177.75438040823485
reward_mean: -2329.0142857142855
reward_std: 176.2881071845005
reward_max: -2101.642857142857
reward_min: -2517.0
queue_len: 1.4447979439914924
wait_time: 5.848280751506559
delay_time: 652.0267669942294
pressure: 14.335359801488835
total_envstep_count: 8680
total_train_sample_count: 8680
total_episode_count: 70
total_duration: 2492.2704357261996
[2024-12-26 20:51:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.2670020047285537
avg_train_sample_per_sec: 3.2670020047285537
avg_episode_per_sec: 0.026346790360714144
collect_time: 189.77643696044015
reward_mean: -2714.7999999999997
reward_std: 152.73499391870547
reward_max: -2515.285714285714
reward_min: -2940.2142857142862
queue_len: 1.6841191066997516
wait_time: 5.947483161999292
delay_time: 757.3129870838509
pressure: 15.706451612903226
total_envstep_count: 9300
total_train_sample_count: 9300
total_episode_count: 75
total_duration: 2682.0468726866397
[2024-12-26 20:54:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3960748415505986
avg_train_sample_per_sec: 3.3960748415505986
avg_episode_per_sec: 0.02738770033508547
collect_time: 182.56370337142422
reward_mean: -2656.7857142857147
reward_std: 179.81644836343793
reward_max: -2410.8571428571427
reward_min: -2866.2857142857133
queue_len: 1.6481300957107412
wait_time: 6.185457284650833
delay_time: 760.7099631416171
pressure: 15.074317617866006
total_envstep_count: 9920
total_train_sample_count: 9920
total_episode_count: 80
total_duration: 2864.610576058064
[2024-12-26 20:57:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3470532849241796
avg_train_sample_per_sec: 3.3470532849241796
avg_episode_per_sec: 0.02699236520100145
collect_time: 185.2375648731403
reward_mean: -2989.9142857142856
reward_std: 313.501513194929
reward_max: -2402.3571428571427
reward_min: -3308.2857142857138
queue_len: 1.8547855370436015
wait_time: 6.38663594470046
delay_time: 853.9021238632989
pressure: 16.056699751861043
total_envstep_count: 10540
total_train_sample_count: 10540
total_episode_count: 85
total_duration: 3049.8481409312044
[2024-12-26 21:00:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3747692621030723
avg_train_sample_per_sec: 3.3747692621030723
avg_episode_per_sec: 0.027215881145992517
collect_time: 183.71626379387828
reward_mean: -2654.1428571428573
reward_std: 137.72444390513817
reward_max: -2417.9285714285716
reward_min: -2803.7142857142853
queue_len: 1.6464906061680253
wait_time: 6.048378234668558
delay_time: 757.8825162648751
pressure: 14.81848635235732
total_envstep_count: 11160
total_train_sample_count: 11160
total_episode_count: 90
total_duration: 3233.5644047250826
[2024-12-26 21:03:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.802232750793396
avg_train_sample_per_sec: 3.802232750793396
avg_episode_per_sec: 0.030663167345108034
collect_time: 163.06208500009032
reward_mean: -2075.9142857142856
reward_std: 140.75352172344046
reward_max: -1834.857142857143
reward_min: -2243.5714285714294
queue_len: 1.2877880184331798
wait_time: 5.682922722438851
delay_time: 534.0273373601813
pressure: 13.101116625310175
total_envstep_count: 11780
total_train_sample_count: 11780
total_episode_count: 95
total_duration: 3396.626489725173
[2024-12-26 21:06:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3001347464442508
avg_train_sample_per_sec: 3.3001347464442508
avg_episode_per_sec: 0.02661398989067944
collect_time: 187.87111667728797
reward_mean: -2590.471428571429
reward_std: 262.48718763678636
reward_max: -2108.785714285714
reward_min: -2867.571428571429
queue_len: 1.60699220134704
wait_time: 5.920462601914214
delay_time: 735.0292768327588
pressure: 14.542928039702232
total_envstep_count: 12400
total_train_sample_count: 12400
total_episode_count: 100
total_duration: 3584.497606402461
[2024-12-26 21:09:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.3995485922325086
avg_train_sample_per_sec: 3.3995485922325086
avg_episode_per_sec: 0.027415714453487974
collect_time: 182.3771548424438
reward_mean: -2522.7571428571428
reward_std: 600.2364476281202
reward_max: -1889.9999999999998
reward_min: -3344.7857142857147
queue_len: 1.564985820630982
wait_time: 6.0312123360510475
delay_time: 658.2957517447114
pressure: 14.92667493796526
total_envstep_count: 13020
total_train_sample_count: 13020
total_episode_count: 105
total_duration: 3766.8747612449047
[2024-12-26 21:12:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5381184307414357
avg_train_sample_per_sec: 3.5381184307414357
avg_episode_per_sec: 0.028533213151140612
collect_time: 175.23438294576107
reward_mean: -2037.7142857142858
reward_std: 197.68264094404498
reward_max: -1738.428571428572
reward_min: -2349.857142857143
queue_len: 1.2640907479617156
wait_time: 5.668344558667141
delay_time: 559.8940925120152
pressure: 13.048138957816377
total_envstep_count: 13640
total_train_sample_count: 13640
total_episode_count: 110
total_duration: 3942.1091441906656
[2024-12-26 21:15:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.533163167305103
avg_train_sample_per_sec: 3.533163167305103
avg_episode_per_sec: 0.0284932513492347
collect_time: 175.48014927170797
reward_mean: -2138.228571428571
reward_std: 273.4074682108547
reward_max: -1807.2142857142849
reward_min: -2510.571428571429
queue_len: 1.3264445232187165
wait_time: 5.555015951790146
delay_time: 593.2112508695484
pressure: 13.391315136476425
total_envstep_count: 14260
total_train_sample_count: 14260
total_episode_count: 115
total_duration: 4117.5892934623735
[2024-12-26 21:18:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.524511587263111
avg_train_sample_per_sec: 3.524511587263111
avg_episode_per_sec: 0.02842348054244444
collect_time: 175.91089847471565
reward_mean: -2099.2
reward_std: 142.54191220372306
reward_max: -2010.4999999999995
reward_min: -2383.6428571428573
queue_len: 1.3022332506203476
wait_time: 5.5140021269053525
delay_time: 602.6628658682093
pressure: 12.786228287841192
total_envstep_count: 14880
total_train_sample_count: 14880
total_episode_count: 120
total_duration: 4293.500191937089
[2024-12-26 21:21:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.770466789412009
avg_train_sample_per_sec: 3.770466789412009
avg_episode_per_sec: 0.03040699023719362
collect_time: 164.43587349477406
reward_mean: -1958.6857142857145
reward_std: 306.27132362248574
reward_max: -1696.285714285714
reward_min: -2512.214285714286
queue_len: 1.2150655795817087
wait_time: 5.479041120170151
delay_time: 539.0756428393051
pressure: 13.041935483870967
total_envstep_count: 15500
total_train_sample_count: 15500
total_episode_count: 125
total_duration: 4457.9360654318625
[2024-12-26 21:24:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6599218769009303
avg_train_sample_per_sec: 3.6599218769009303
avg_episode_per_sec: 0.029515499007265564
collect_time: 169.40252301914987
reward_mean: -1777.4714285714279
reward_std: 116.42701664167826
reward_max: -1653.7142857142856
reward_min: -1962.7857142857138
queue_len: 1.102649769585253
wait_time: 5.25354484225452
delay_time: 475.0280450482572
pressure: 12.223697270471465
total_envstep_count: 16120
total_train_sample_count: 16120
total_episode_count: 130
total_duration: 4627.338588451013
[2024-12-26 21:27:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7280081486853796
avg_train_sample_per_sec: 3.7280081486853796
avg_episode_per_sec: 0.030064581844236934
collect_time: 166.30864935706558
reward_mean: -2045.8428571428565
reward_std: 160.7363756247469
reward_max: -1867.6428571428562
reward_min: -2245.8571428571427
queue_len: 1.2691332860687696
wait_time: 5.381132577100319
delay_time: 588.1226105498264
pressure: 12.93411910669975
total_envstep_count: 16740
total_train_sample_count: 16740
total_episode_count: 135
total_duration: 4793.647237808078
[2024-12-26 21:29:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7793537126846544
avg_train_sample_per_sec: 3.7793537126846544
avg_episode_per_sec: 0.030478658973263344
collect_time: 164.04921241404116
reward_mean: -2017.542857142857
reward_std: 157.52299864477192
reward_max: -1795.357142857143
reward_min: -2213.9999999999995
queue_len: 1.2515774548032614
wait_time: 5.491563275434244
delay_time: 566.8998136631293
pressure: 12.28771712158809
total_envstep_count: 17360
total_train_sample_count: 17360
total_episode_count: 140
total_duration: 4957.696450222119
[2024-12-26 21:32:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.37135699819956
avg_train_sample_per_sec: 3.37135699819956
avg_episode_per_sec: 0.02718836288870613
collect_time: 183.90220920866727
reward_mean: -2382.9857142857145
reward_std: 202.04803631708938
reward_max: -2177.142857142857
reward_min: -2696.0
queue_len: 1.478278979085431
wait_time: 5.6428394186458695
delay_time: 698.0894631180232
pressure: 13.529032258064515
total_envstep_count: 17980
total_train_sample_count: 17980
total_episode_count: 145
total_duration: 5141.598659430786
[2024-12-26 21:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.604439871631721
avg_train_sample_per_sec: 3.604439871631721
avg_episode_per_sec: 0.029068063480900977
collect_time: 172.01008258720861
reward_mean: -2210.1
reward_std: 299.23423901004094
reward_max: -1953.0714285714291
reward_min: -2778.9285714285716
queue_len: 1.3710297766749382
wait_time: 5.5663860333215185
delay_time: 640.5841221644152
pressure: 13.021464019851118
total_envstep_count: 18600
total_train_sample_count: 18600
total_episode_count: 150
total_duration: 5313.608742017995
[2024-12-26 21:38:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5254082426757662
avg_train_sample_per_sec: 3.5254082426757662
avg_episode_per_sec: 0.028430711634481985
collect_time: 175.86615714310105
reward_mean: -1991.8
reward_std: 77.10003308715741
reward_max: -1840.5000000000005
reward_min: -2051.7142857142853
queue_len: 1.2356079404466498
wait_time: 5.428775257001062
delay_time: 558.5852104062744
pressure: 12.339330024813897
total_envstep_count: 19220
total_train_sample_count: 19220
total_episode_count: 155
total_duration: 5489.474899161096
[2024-12-26 21:41:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5283083504765895
avg_train_sample_per_sec: 3.5283083504765895
avg_episode_per_sec: 0.028454099600617656
collect_time: 175.72160321992632
reward_mean: -2132.8
reward_std: 143.41077294233688
reward_max: -1916.285714285714
reward_min: -2299.5714285714294
queue_len: 1.323076923076923
wait_time: 5.6992910315490946
delay_time: 610.197405788375
pressure: 13.354342431761788
total_envstep_count: 19840
total_train_sample_count: 19840
total_episode_count: 160
total_duration: 5665.196502381023
[2024-12-26 21:44:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5932443957342044
avg_train_sample_per_sec: 3.5932443957342044
avg_episode_per_sec: 0.02897777738495326
collect_time: 172.54601460898292
reward_mean: -2019.014285714286
reward_std: 151.09270299375555
reward_max: -1836.428571428571
reward_min: -2216.142857142858
queue_len: 1.2524902516838003
wait_time: 5.628677773839065
delay_time: 573.6467644213423
pressure: 13.09776674937965
total_envstep_count: 20460
total_train_sample_count: 20460
total_episode_count: 165
total_duration: 5837.742516990005
[2024-12-26 21:47:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.485832912139944
avg_train_sample_per_sec: 3.485832912139944
avg_episode_per_sec: 0.028111555743064065
collect_time: 177.86279940176007
reward_mean: -2427.6
reward_std: 144.3172426656361
reward_max: -2273.7142857142867
reward_min: -2674.6428571428564
queue_len: 1.505955334987593
wait_time: 5.907506203473946
delay_time: 689.9143855189857
pressure: 13.704218362282878
total_envstep_count: 21080
total_train_sample_count: 21080
total_episode_count: 170
total_duration: 6015.605316391765
[2024-12-26 21:50:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.522511711808248
avg_train_sample_per_sec: 3.522511711808248
avg_episode_per_sec: 0.028407352514582648
collect_time: 176.01077036071197
reward_mean: -2230.8142857142857
reward_std: 158.40940628636898
reward_max: -2008.4285714285713
reward_min: -2449.6428571428564
queue_len: 1.3838798298475719
wait_time: 5.760891527827011
delay_time: 642.3000459354116
pressure: 13.515012406947893
total_envstep_count: 21700
total_train_sample_count: 21700
total_episode_count: 175
total_duration: 6191.616086752477
[2024-12-26 21:53:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.448363872264377
avg_train_sample_per_sec: 3.448363872264377
avg_episode_per_sec: 0.0278093860666482
collect_time: 179.79541108951344
reward_mean: -2262.785714285714
reward_std: 269.4317413841696
reward_max: -1919.9285714285713
reward_min: -2634.9999999999995
queue_len: 1.4037132222616093
wait_time: 5.82516838000709
delay_time: 630.374256186873
pressure: 13.697766749379653
total_envstep_count: 22320
total_train_sample_count: 22320
total_episode_count: 180
total_duration: 6371.41149784199
[2024-12-26 21:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.4611661751176754
avg_train_sample_per_sec: 3.4611661751176754
avg_episode_per_sec: 0.027912630444497384
collect_time: 179.13037647749482
reward_mean: -2412.085714285714
reward_std: 140.48651907146262
reward_max: -2198.8571428571418
reward_min: -2579.0
queue_len: 1.496331088266572
wait_time: 5.754298121233605
delay_time: 664.8571591523148
pressure: 13.116501240694788
total_envstep_count: 22940
total_train_sample_count: 22940
total_episode_count: 185
total_duration: 6550.541874319485
[2024-12-26 21:59:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.328162303245209
avg_train_sample_per_sec: 3.328162303245209
avg_episode_per_sec: 0.026840018574558134
collect_time: 186.28899179449672
reward_mean: -2424.042857142858
reward_std: 309.3338055649693
reward_max: -1989.7142857142858
reward_min: -2914.571428571429
queue_len: 1.5037486706841547
wait_time: 5.749627791563276
delay_time: 689.4861827358758
pressure: 14.044789081885856
total_envstep_count: 23560
total_train_sample_count: 23560
total_episode_count: 190
total_duration: 6736.830866113982
[2024-12-26 22:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5915928751912025
avg_train_sample_per_sec: 3.5915928751912025
avg_episode_per_sec: 0.028964458670896795
collect_time: 172.6253563655913
reward_mean: -2217.028571428571
reward_std: 160.1434471761783
reward_max: -2067.0714285714284
reward_min: -2516.1428571428573
queue_len: 1.375327897908543
wait_time: 5.751098901098901
delay_time: 626.6393277344789
pressure: 14.13970223325062
total_envstep_count: 24180
total_train_sample_count: 24180
total_episode_count: 195
total_duration: 6909.456222479573
[2024-12-26 22:05:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5467401695994814
avg_train_sample_per_sec: 3.5467401695994814
avg_episode_per_sec: 0.028602743303221625
collect_time: 174.80840725640581
reward_mean: -1984.8
reward_std: 108.44970055754156
reward_max: -1804.8571428571424
reward_min: -2141.428571428571
queue_len: 1.2312655086848636
wait_time: 5.680494505494504
delay_time: 575.6570584316149
pressure: 13.375806451612902
total_envstep_count: 24800
total_train_sample_count: 24800
total_episode_count: 200
total_duration: 7084.264629735979
[2024-12-26 22:08:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6915159955096253
avg_train_sample_per_sec: 3.6915159955096253
avg_episode_per_sec: 0.029770290286367945
collect_time: 167.952678724451
reward_mean: -1961.7857142857144
reward_std: 135.38257959258596
reward_max: -1811.071428571429
reward_min: -2172.1428571428573
queue_len: 1.2169886565047858
wait_time: 5.4575327897908545
delay_time: 540.7776452314151
pressure: 13.634491315136477
total_envstep_count: 25420
total_train_sample_count: 25420
total_episode_count: 205
total_duration: 7252.21730846043
[2024-12-26 22:11:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.565681266745669
avg_train_sample_per_sec: 3.565681266745669
avg_episode_per_sec: 0.028755494086658624
collect_time: 173.87981527744975
reward_mean: -1961.1714285714286
reward_std: 212.61111668672353
reward_max: -1718.3571428571431
reward_min: -2298.7142857142862
queue_len: 1.2166075859624246
wait_time: 5.41440978376462
delay_time: 563.1757676728679
pressure: 13.116873449131514
total_envstep_count: 26040
total_train_sample_count: 26040
total_episode_count: 210
total_duration: 7426.09712373788
[2024-12-26 22:13:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.693781956940518
avg_train_sample_per_sec: 3.693781956940518
avg_episode_per_sec: 0.029788564168875143
collect_time: 167.8496476585567
reward_mean: -1975.5285714285715
reward_std: 120.14295566498402
reward_max: -1846.2857142857142
reward_min: -2201.857142857142
queue_len: 1.2255140021269053
wait_time: 5.380990783410139
delay_time: 547.2099272098408
pressure: 13.141439205955333
total_envstep_count: 26660
total_train_sample_count: 26660
total_episode_count: 215
total_duration: 7593.946771396437
[2024-12-26 22:16:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.821791808847084
avg_train_sample_per_sec: 3.821791808847084
avg_episode_per_sec: 0.030820901684250678
collect_time: 162.22757047224786
reward_mean: -1938.1285714285714
reward_std: 204.27749434011974
reward_max: -1636.7142857142853
reward_min: -2253.7142857142862
queue_len: 1.2023130095710741
wait_time: 5.480113434952145
delay_time: 521.8651469661908
pressure: 12.703349875930522
total_envstep_count: 27280
total_train_sample_count: 27280
total_episode_count: 220
total_duration: 7756.174341868685
[2024-12-26 22:19:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6002129244775967
avg_train_sample_per_sec: 3.6002129244775967
avg_episode_per_sec: 0.02903397519739997
collect_time: 172.21203662279618
reward_mean: -1914.6285714285718
reward_std: 128.83768779327912
reward_max: -1726.6428571428569
reward_min: -2082.7142857142867
queue_len: 1.187734845799362
wait_time: 5.484819213045019
delay_time: 514.0803128792421
pressure: 12.802853598014888
total_envstep_count: 27900
total_train_sample_count: 27900
total_episode_count: 225
total_duration: 7928.386378491481
[2024-12-26 22:22:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7052367116150693
avg_train_sample_per_sec: 3.7052367116150693
avg_episode_per_sec: 0.029880941222702174
collect_time: 167.33073977606932
reward_mean: -1939.9857142857145
reward_std: 97.15835380596845
reward_max: -1772.3571428571424
reward_min: -2063.2857142857138
queue_len: 1.203465083303793
wait_time: 5.402782701169796
delay_time: 528.4730167090414
pressure: 12.378411910669977
total_envstep_count: 28520
total_train_sample_count: 28520
total_episode_count: 230
total_duration: 8095.71711826755
[2024-12-26 22:25:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6442189652497117
avg_train_sample_per_sec: 3.6442189652497117
avg_episode_per_sec: 0.029388862622981547
collect_time: 170.13247719529278
reward_mean: -2047.6
reward_std: 310.19247678346585
reward_max: -1828.714285714286
reward_min: -2659.999999999999
queue_len: 1.2702233250620347
wait_time: 5.39441687344913
delay_time: 561.0778985876761
pressure: 12.92940446650124
total_envstep_count: 29140
total_train_sample_count: 29140
total_episode_count: 235
total_duration: 8265.849595462843
[2024-12-26 22:28:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6218385612996724
avg_train_sample_per_sec: 3.6218385612996724
avg_episode_per_sec: 0.029208375494352196
collect_time: 171.18377572784945
reward_mean: -2021.4142857142856
reward_std: 61.83753235829562
reward_max: -1964.4285714285709
reward_min: -2136.142857142857
queue_len: 1.2539790854306982
wait_time: 5.540225097483163
delay_time: 565.3073003829226
pressure: 12.882009925558313
total_envstep_count: 29760
total_train_sample_count: 29760
total_episode_count: 240
total_duration: 8437.033371190693
[2024-12-26 22:30:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.595702271180613
avg_train_sample_per_sec: 3.595702271180613
avg_episode_per_sec: 0.028997598961133974
collect_time: 172.4280691895075
reward_mean: -2071.9571428571426
reward_std: 129.45905191391205
reward_max: -1856.7142857142862
reward_min: -2234.5000000000005
queue_len: 1.2853332151719248
wait_time: 5.581637717121588
delay_time: 591.4060106748902
pressure: 12.952605459057072
total_envstep_count: 30380
total_train_sample_count: 30380
total_episode_count: 245
total_duration: 8609.4614403802
[2024-12-26 22:33:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.6966479974562563
avg_train_sample_per_sec: 3.6966479974562563
avg_episode_per_sec: 0.029811677398840775
collect_time: 167.71951249527558
reward_mean: -1941.0571428571427
reward_std: 133.85764903090723
reward_max: -1802.6428571428573
reward_min: -2170.714285714285
queue_len: 1.2041297412265153
wait_time: 5.5473502304147475
delay_time: 519.3427114048548
pressure: 13.027543424317619
total_envstep_count: 31000
total_train_sample_count: 31000
total_episode_count: 250
total_duration: 8777.180952875477
[2024-12-26 22:36:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.529924096702505
avg_train_sample_per_sec: 3.529924096702505
avg_episode_per_sec: 0.028467129812116975
collect_time: 175.64117046572642
reward_mean: -2019.7
reward_std: 70.58928923783046
reward_max: -1935.7857142857138
reward_min: -2106.285714285715
queue_len: 1.2529156327543423
wait_time: 5.820746189294576
delay_time: 558.9675102262247
pressure: 13.732506203473946
total_envstep_count: 31620
total_train_sample_count: 31620
total_episode_count: 255
total_duration: 8952.822123341202
[2024-12-26 22:39:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.5750626592027643
avg_train_sample_per_sec: 3.5750626592027643
avg_episode_per_sec: 0.02883115047744165
collect_time: 173.42353382367273
reward_mean: -2125.557142857143
reward_std: 125.58109340345833
reward_max: -1936.4999999999998
reward_min: -2314.357142857142
queue_len: 1.3185838355193193
wait_time: 5.8540233959588805
delay_time: 584.3256366455823
pressure: 13.711910669975186
total_envstep_count: 32240
total_train_sample_count: 32240
total_episode_count: 260
total_duration: 9126.245657164875
[2024-12-26 22:42:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.534408931476571
avg_train_sample_per_sec: 3.534408931476571
avg_episode_per_sec: 0.028503297834488475
collect_time: 175.4182982275858
reward_mean: -2153.3
reward_std: 112.7427304321931
reward_max: -2013.5714285714287
reward_min: -2337.5714285714284
queue_len: 1.3357940446650125
wait_time: 5.561733427862459
delay_time: 591.4112786864065
pressure: 13.15533498759305
total_envstep_count: 32860
total_train_sample_count: 32860
total_episode_count: 265
total_duration: 9301.66395539246
[2024-12-26 22:45:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.680584715924385
avg_train_sample_per_sec: 3.680584715924385
avg_episode_per_sec: 0.029682134805841816
collect_time: 168.45149557827415
reward_mean: -1969.4
reward_std: 121.26263956842625
reward_max: -1759.7857142857147
reward_min: -2110.500000000001
queue_len: 1.2217121588089328
wait_time: 5.547385678837292
delay_time: 530.1179502383841
pressure: 12.608684863523573
total_envstep_count: 33480
total_train_sample_count: 33480
total_episode_count: 270
total_duration: 9470.115450970734
[2024-12-26 22:48:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.56024395597938
avg_train_sample_per_sec: 3.56024395597938
avg_episode_per_sec: 0.02871164480628532
collect_time: 174.1453697179146
reward_mean: -2158.471428571429
reward_std: 262.4446592782441
reward_max: -1869.857142857143
reward_min: -2641.285714285715
queue_len: 1.339002126905353
wait_time: 5.628323289613613
delay_time: 587.6392536944186
pressure: 13.815136476426797
total_envstep_count: 34100
total_train_sample_count: 34100
total_episode_count: 275
total_duration: 9644.260820688649
[2024-12-26 22:51:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.599925868663286
avg_train_sample_per_sec: 3.599925868663286
avg_episode_per_sec: 0.029031660231155533
collect_time: 172.2257687017918
reward_mean: -1940.4142857142856
reward_std: 79.19450867378114
reward_max: -1828.285714285715
reward_min: -2052.0714285714284
queue_len: 1.203730946472882
wait_time: 5.663479262672812
delay_time: 491.17027940460264
pressure: 13.000248138957815
total_envstep_count: 34720
total_train_sample_count: 34720
total_episode_count: 280
total_duration: 9816.48658939044
[2024-12-26 22:54:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.4844379139960733
avg_train_sample_per_sec: 3.4844379139960733
avg_episode_per_sec: 0.02810030575803285
collect_time: 177.93400694832948
reward_mean: -2202.942857142857
reward_std: 32.92921908256833
reward_max: -2164.1428571428564
reward_min: -2256.2142857142862
queue_len: 1.3665898617511523
wait_time: 5.5919620701878765
delay_time: 619.6663062775845
pressure: 13.287717121588091
total_envstep_count: 35340
total_train_sample_count: 35340
total_episode_count: 285
total_duration: 9994.42059633877
[2024-12-26 22:56:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.608310066504805
avg_train_sample_per_sec: 3.608310066504805
avg_episode_per_sec: 0.02909927472987746
collect_time: 171.8255883149654
reward_mean: -1987.1
reward_std: 164.67818090234698
reward_max: -1823.4999999999993
reward_min: -2262.428571428571
queue_len: 1.2326923076923078
wait_time: 5.468211627082594
delay_time: 518.6979213892771
pressure: 13.380645161290323
total_envstep_count: 35960
total_train_sample_count: 35960
total_episode_count: 290
total_duration: 10166.246184653735
[2024-12-26 22:59:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.898168737570339
avg_train_sample_per_sec: 3.898168737570339
avg_episode_per_sec: 0.031436844657825314
collect_time: 159.04904116244984
reward_mean: -1702.2142857142858
reward_std: 119.4288875593901
reward_max: -1533.3571428571433
reward_min: -1906.5714285714287
queue_len: 1.0559641970932296
wait_time: 5.050363346331088
delay_time: 428.68661931588724
pressure: 12.207071960297766
total_envstep_count: 36580
total_train_sample_count: 36580
total_episode_count: 295
total_duration: 10325.295225816186
[2024-12-26 23:02:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.030144552054083
avg_train_sample_per_sec: 4.030144552054083
avg_episode_per_sec: 0.03250116574237164
collect_time: 153.8406357369982
reward_mean: -1659.6571428571428
reward_std: 70.65771763384699
reward_max: -1584.6428571428569
reward_min: -1782.9999999999993
queue_len: 1.029563984402694
wait_time: 5.150584898971996
delay_time: 389.69810760073165
pressure: 11.692555831265508
total_envstep_count: 37200
total_train_sample_count: 37200
total_episode_count: 300
total_duration: 10479.135861553184
[2024-12-26 23:04:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7598935481801212
avg_train_sample_per_sec: 3.7598935481801212
avg_episode_per_sec: 0.030321722162742912
collect_time: 164.89828556451948
reward_mean: -1781.9428571428573
reward_std: 140.61418049080984
reward_max: -1652.3571428571436
reward_min: -1976.0714285714287
queue_len: 1.105423608649415
wait_time: 4.890526409074797
delay_time: 462.82771616168856
pressure: 12.26426799007444
total_envstep_count: 37820
total_train_sample_count: 37820
total_episode_count: 305
total_duration: 10644.034147117703
[2024-12-26 23:07:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.8142646548599393
avg_train_sample_per_sec: 3.8142646548599393
avg_episode_per_sec: 0.03076019882951564
collect_time: 162.54771393747626
reward_mean: -1718.1000000000004
reward_std: 213.7030583376315
reward_max: -1423.9285714285722
reward_min: -2074.0714285714294
queue_len: 1.0658188585607944
wait_time: 5.0995657568238215
delay_time: 433.83221208325693
pressure: 11.94528535980149
total_envstep_count: 38440
total_train_sample_count: 38440
total_episode_count: 310
total_duration: 10806.58186105518
[2024-12-26 23:10:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7911647000828603
avg_train_sample_per_sec: 3.7911647000828603
avg_episode_per_sec: 0.03057390887163597
collect_time: 163.53813380527868
reward_mean: -1752.4428571428573
reward_std: 217.08522449461552
reward_max: -1505.6428571428573
reward_min: -2058.714285714286
queue_len: 1.087123360510457
wait_time: 5.039737681673165
delay_time: 432.11623478271883
pressure: 12.267990074441688
total_envstep_count: 39060
total_train_sample_count: 39060
total_episode_count: 315
total_duration: 10970.119994860459
[2024-12-26 23:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.693828641944299
avg_train_sample_per_sec: 3.693828641944299
avg_episode_per_sec: 0.02978894066084112
collect_time: 167.8475262657702
reward_mean: -1962.185714285714
reward_std: 254.05716293939915
reward_max: -1630.7857142857144
reward_min: -2343.7142857142862
queue_len: 1.2172367954626018
wait_time: 5.1597660404112
delay_time: 541.6443223386274
pressure: 12.172084367245658
total_envstep_count: 39680
total_train_sample_count: 39680
total_episode_count: 320
total_duration: 11137.96752112623
[2024-12-26 23:16:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.664906261295269
avg_train_sample_per_sec: 3.664906261295269
avg_episode_per_sec: 0.02955569565560701
collect_time: 169.17213041647526
reward_mean: -1872.1285714285714
reward_std: 109.50622384697829
reward_max: -1778.5000000000005
reward_min: -2083.7857142857147
queue_len: 1.161370081531372
wait_time: 5.216173342786247
delay_time: 477.04686946446816
pressure: 12.430645161290323
total_envstep_count: 40300
total_train_sample_count: 40300
total_episode_count: 325
total_duration: 11307.139651542704
[2024-12-26 23:18:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7457460821829494
avg_train_sample_per_sec: 3.7457460821829494
avg_episode_per_sec: 0.030207629695023785
collect_time: 165.52109683811665
reward_mean: -1721.3285714285714
reward_std: 136.24110980170425
reward_max: -1509.9999999999995
reward_min: -1901.4285714285716
queue_len: 1.0678216944345977
wait_time: 5.170303084012761
delay_time: 428.56456764904686
pressure: 12.139330024813896
total_envstep_count: 40920
total_train_sample_count: 40920
total_episode_count: 330
total_duration: 11472.66074838082
[2024-12-26 23:21:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.9428559735361115
avg_train_sample_per_sec: 3.9428559735361115
avg_episode_per_sec: 0.031797225593033156
collect_time: 157.24642344568298
reward_mean: -1733.7571428571428
reward_std: 216.34964897647728
reward_max: -1518.071428571428
reward_min: -2124.714285714286
queue_len: 1.075531726338178
wait_time: 4.9559376107763216
delay_time: 425.76036458309426
pressure: 11.700372208436724
total_envstep_count: 41540
total_train_sample_count: 41540
total_episode_count: 335
total_duration: 11629.907171826504
[2024-12-26 23:24:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.9142048262202893
avg_train_sample_per_sec: 3.9142048262202893
avg_episode_per_sec: 0.03156616795338943
collect_time: 158.3974338406548
reward_mean: -1767.3428571428572
reward_std: 125.06431325114161
reward_max: -1602.9285714285713
reward_min: -1987.642857142858
queue_len: 1.0963665366891173
wait_time: 4.983622828784119
delay_time: 461.3444922225024
pressure: 12.98759305210918
total_envstep_count: 42160
total_train_sample_count: 42160
total_episode_count: 340
total_duration: 11788.30460566716
[2024-12-26 23:26:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7533957960618904
avg_train_sample_per_sec: 3.7533957960618904
avg_episode_per_sec: 0.030269320935982988
collect_time: 165.18375191087273
reward_mean: -2054.4142857142856
reward_std: 368.8080895788154
reward_max: -1725.4285714285716
reward_min: -2744.0
queue_len: 1.2744505494505496
wait_time: 4.781150301311592
delay_time: 561.4789987481543
pressure: 12.545037220843671
total_envstep_count: 42780
total_train_sample_count: 42780
total_episode_count: 345
total_duration: 11953.488357578031
[2024-12-26 23:29:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.749395958019024
avg_train_sample_per_sec: 3.749395958019024
avg_episode_per_sec: 0.030237064177572773
collect_time: 165.35996916355938
reward_mean: -1872.0
reward_std: 200.0528195558488
reward_max: -1688.9285714285704
reward_min: -2255.357142857143
queue_len: 1.1612903225806452
wait_time: 4.741439205955335
delay_time: 504.6881357533037
pressure: 12.765880893300247
total_envstep_count: 43400
total_train_sample_count: 43400
total_episode_count: 350
total_duration: 12118.84832674159
[2024-12-26 23:32:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.956856039577971
avg_train_sample_per_sec: 3.956856039577971
avg_episode_per_sec: 0.031910129351435244
collect_time: 156.69005740884316
reward_mean: -1632.9285714285716
reward_std: 120.61146931619854
reward_max: -1457.7857142857144
reward_min: -1830.6428571428578
queue_len: 1.0129829847571783
wait_time: 4.700292449485998
delay_time: 391.53403554170757
pressure: 11.596153846153845
total_envstep_count: 44020
total_train_sample_count: 44020
total_episode_count: 355
total_duration: 12275.538384150434
[2024-12-26 23:34:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.1575027956572015
avg_train_sample_per_sec: 4.1575027956572015
avg_episode_per_sec: 0.03352824835207421
collect_time: 149.1279815007299
reward_mean: -1439.9428571428568
reward_std: 42.234317219773004
reward_max: -1384.8571428571427
reward_min: -1496.2142857142858
queue_len: 0.8932647997164125
wait_time: 4.5635501595179
delay_time: 284.5137646992963
pressure: 10.773076923076923
total_envstep_count: 44640
total_train_sample_count: 44640
total_episode_count: 360
total_duration: 12424.666365651163
[2024-12-26 23:37:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.10487191651593
avg_train_sample_per_sec: 4.10487191651593
avg_episode_per_sec: 0.03310380577835427
collect_time: 151.04003550157884
reward_mean: -1431.1714285714284
reward_std: 47.489882918278575
reward_max: -1361.642857142857
reward_min: -1500.357142857142
queue_len: 0.8878234668557248
wait_time: 4.686272598369373
delay_time: 290.4496867204595
pressure: 10.638585607940445
total_envstep_count: 45260
total_train_sample_count: 45260
total_episode_count: 365
total_duration: 12575.706401152742
[2024-12-26 23:39:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.979366227203221
avg_train_sample_per_sec: 3.979366227203221
avg_episode_per_sec: 0.03209166312260662
collect_time: 155.8037045601979
reward_mean: -1612.0714285714284
reward_std: 108.07627691891068
reward_max: -1484.642857142857
reward_min: -1777.9285714285716
queue_len: 1.0000443105281813
wait_time: 4.909712867777384
delay_time: 371.78939806123367
pressure: 11.909429280397022
total_envstep_count: 45880
total_train_sample_count: 45880
total_episode_count: 370
total_duration: 12731.51010571294
[2024-12-26 23:42:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.0980411608020795
avg_train_sample_per_sec: 4.0980411608020795
avg_episode_per_sec: 0.03304871903872644
collect_time: 151.29179421874133
reward_mean: -1565.7857142857142
reward_std: 76.55622183755439
reward_max: -1484.3571428571424
reward_min: -1660.642857142857
queue_len: 0.9713310882665723
wait_time: 4.812185395249912
delay_time: 342.25134658939703
pressure: 11.100124069478909
total_envstep_count: 46500
total_train_sample_count: 46500
total_episode_count: 375
total_duration: 12882.801899931681
[2024-12-26 23:45:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.9579388820611663
avg_train_sample_per_sec: 3.9579388820611663
avg_episode_per_sec: 0.03191886195210618
collect_time: 156.6471889725402
reward_mean: -1568.9
reward_std: 110.1765799773718
reward_max: -1464.0714285714287
reward_min: -1781.8571428571431
queue_len: 0.9732630272952856
wait_time: 4.7425026586316905
delay_time: 369.02976121663914
pressure: 10.88846153846154
total_envstep_count: 47120
total_train_sample_count: 47120
total_episode_count: 380
total_duration: 13039.44908890422
[2024-12-26 23:47:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.152437347539753
avg_train_sample_per_sec: 4.152437347539753
avg_episode_per_sec: 0.03348739796403027
collect_time: 149.30989876760916
reward_mean: -1497.1571428571428
reward_std: 137.48730850518498
reward_max: -1326.4285714285716
reward_min: -1732.2857142857135
queue_len: 0.9287575327897908
wait_time: 4.662096774193548
delay_time: 303.6528944955038
pressure: 10.885980148883375
total_envstep_count: 47740
total_train_sample_count: 47740
total_episode_count: 385
total_duration: 13188.75898767183
[2024-12-26 23:50:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.897391214812017
avg_train_sample_per_sec: 3.897391214812017
avg_episode_per_sec: 0.031430574313000136
collect_time: 159.0807711691074
reward_mean: -1482.3714285714284
reward_std: 135.72372448380196
reward_max: -1294.0714285714291
reward_min: -1646.4285714285706
queue_len: 0.9195852534562212
wait_time: 4.588098192130451
delay_time: 337.36676446906125
pressure: 10.490198511166252
total_envstep_count: 48360
total_train_sample_count: 48360
total_episode_count: 390
total_duration: 13347.839758840937
[2024-12-26 23:52:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.070985235959073
avg_train_sample_per_sec: 4.070985235959073
avg_episode_per_sec: 0.032830526096444136
collect_time: 152.297285316471
reward_mean: -1339.6142857142856
reward_std: 83.79476385180406
reward_max: -1201.5714285714282
reward_min: -1439.7142857142858
queue_len: 0.8310262318326833
wait_time: 4.390482098546615
delay_time: 287.42080933208433
pressure: 9.937468982630273
total_envstep_count: 48980
total_train_sample_count: 48980
total_episode_count: 395
total_duration: 13500.137044157407
[2024-12-26 23:55:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.993528445052487
avg_train_sample_per_sec: 3.993528445052487
avg_episode_per_sec: 0.03220587455687489
collect_time: 155.25117913410816
reward_mean: -1382.6285714285714
reward_std: 82.7530553107574
reward_max: -1253.7142857142858
reward_min: -1474.9999999999998
queue_len: 0.8577100319035802
wait_time: 4.344275079758951
delay_time: 298.3196962089135
pressure: 10.127667493796526
total_envstep_count: 49600
total_train_sample_count: 49600
total_episode_count: 400
total_duration: 13655.388223291515
[2024-12-26 23:57:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.327347638351688
avg_train_sample_per_sec: 4.327347638351688
avg_episode_per_sec: 0.034897964825416836
collect_time: 143.27483063878864
reward_mean: -1248.0714285714287
reward_std: 15.311060427957566
reward_max: -1233.2857142857147
reward_min: -1277.2857142857142
queue_len: 0.7742378589152783
wait_time: 4.042414037575328
delay_time: 257.8112812972065
pressure: 9.253722084367245
total_envstep_count: 50220
total_train_sample_count: 50220
total_episode_count: 405
total_duration: 13798.663053930304
[2024-12-27 00:00:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.230008134021016
avg_train_sample_per_sec: 4.230008134021016
avg_episode_per_sec: 0.03411296882275013
collect_time: 146.57182217061893
reward_mean: -1261.5285714285715
reward_std: 80.4464785951961
reward_max: -1170.4999999999998
reward_min: -1371.6428571428573
queue_len: 0.7825859624246723
wait_time: 3.967777383906416
delay_time: 254.88074821396594
pressure: 9.137096774193548
total_envstep_count: 50840
total_train_sample_count: 50840
total_episode_count: 410
total_duration: 13945.234876100923
[2024-12-27 00:02:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.351050914486159
avg_train_sample_per_sec: 4.351050914486159
avg_episode_per_sec: 0.03508912027811418
collect_time: 142.4943104976788
reward_mean: -1232.5857142857144
reward_std: 59.71788095807189
reward_max: -1160.642857142857
reward_min: -1325.6428571428573
queue_len: 0.76463133640553
wait_time: 4.021800779865297
delay_time: 255.94971059442577
pressure: 8.803722084367246
total_envstep_count: 51460
total_train_sample_count: 51460
total_episode_count: 415
total_duration: 14087.729186598603
[2024-12-27 00:05:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.2028797608654616
avg_train_sample_per_sec: 4.2028797608654616
avg_episode_per_sec: 0.03389419161988275
collect_time: 147.51790088620783
reward_mean: -1260.2285714285715
reward_std: 63.921498411595735
reward_max: -1176.8571428571436
reward_min: -1369.7142857142853
queue_len: 0.7817795108117689
wait_time: 3.9768699042892584
delay_time: 255.6155390366328
pressure: 9.399131513647642
total_envstep_count: 52080
total_train_sample_count: 52080
total_episode_count: 420
total_duration: 14235.247087484811
[2024-12-27 00:07:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.229300509710516
avg_train_sample_per_sec: 4.229300509710516
avg_episode_per_sec: 0.03410726217508481
collect_time: 146.5963457967751
reward_mean: -1260.8714285714282
reward_std: 34.01396471919118
reward_max: -1208.7857142857138
reward_min: -1308.8571428571431
queue_len: 0.7821783055654021
wait_time: 3.9573466855724924
delay_time: 262.22207723538565
pressure: 9.152481389578163
total_envstep_count: 52700
total_train_sample_count: 52700
total_episode_count: 425
total_duration: 14381.843433281587
[2024-12-27 00:09:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.357010269093299
avg_train_sample_per_sec: 4.357010269093299
avg_episode_per_sec: 0.03513717958946208
collect_time: 142.29941214460877
reward_mean: -1230.2285714285717
reward_std: 117.99635414637498
reward_max: -1108.142857142857
reward_min: -1392.3571428571433
queue_len: 0.7631690889755408
wait_time: 3.7685926976249555
delay_time: 259.33388680326783
pressure: 9.333746898263026
total_envstep_count: 53320
total_train_sample_count: 53320
total_episode_count: 430
total_duration: 14524.142845426195
[2024-12-27 00:12:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.905816702037413
avg_train_sample_per_sec: 4.905816702037413
avg_episode_per_sec: 0.039563037919656555
collect_time: 126.38058811747096
reward_mean: -1111.171428571429
reward_std: 40.65212297089559
reward_max: -1035.9285714285716
reward_min: -1152.1428571428573
queue_len: 0.6893123006026234
wait_time: 3.699884792626728
delay_time: 210.7637913002364
pressure: 8.663895781637716
total_envstep_count: 53940
total_train_sample_count: 53940
total_episode_count: 435
total_duration: 14650.523433543665
[2024-12-27 00:14:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.087315865028054
avg_train_sample_per_sec: 5.087315865028054
avg_episode_per_sec: 0.041026740847000434
collect_time: 121.87173284483703
reward_mean: -1128.5857142857144
reward_std: 140.8967736192938
reward_max: -949.2142857142857
reward_min: -1341.357142857143
queue_len: 0.700115207373272
wait_time: 3.7501861042183626
delay_time: 223.70364592230982
pressure: 9.205086848635236
total_envstep_count: 54560
total_train_sample_count: 54560
total_episode_count: 440
total_duration: 14772.395166388502
[2024-12-27 00:16:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.457980555446326
avg_train_sample_per_sec: 4.457980555446326
avg_episode_per_sec: 0.035951456092309084
collect_time: 139.07642536541448
reward_mean: -1131.0285714285712
reward_std: 92.64444430846608
reward_max: -1029.3571428571424
reward_min: -1296.6428571428567
queue_len: 0.7016306274370789
wait_time: 3.6022686990428925
delay_time: 227.646934966236
pressure: 8.83002481389578
total_envstep_count: 55180
total_train_sample_count: 55180
total_episode_count: 445
total_duration: 14911.471591753916
[2024-12-27 00:18:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.448966897439545
avg_train_sample_per_sec: 4.448966897439545
avg_episode_per_sec: 0.03587876530193182
collect_time: 139.35819579975305
reward_mean: -1065.1285714285711
reward_std: 56.021741406386795
reward_max: -959.3571428571429
reward_min: -1123.0714285714287
queue_len: 0.6607497341368308
wait_time: 3.5585962424672104
delay_time: 200.82161540238613
pressure: 8.633995037220844
total_envstep_count: 55800
total_train_sample_count: 55800
total_episode_count: 450
total_duration: 15050.82978755367
[2024-12-27 00:21:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.5279475671380105
avg_train_sample_per_sec: 4.5279475671380105
avg_episode_per_sec: 0.03651570618659686
collect_time: 136.9273806304
reward_mean: -1051.485714285714
reward_std: 25.8818508627501
reward_max: -1025.7142857142853
reward_min: -1097.9285714285713
queue_len: 0.6522864232541651
wait_time: 3.577738390641617
delay_time: 204.46463059546028
pressure: 8.382754342431761
total_envstep_count: 56420
total_train_sample_count: 56420
total_episode_count: 455
total_duration: 15187.75716818407
[2024-12-27 00:23:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.630446946031106
avg_train_sample_per_sec: 4.630446946031106
avg_episode_per_sec: 0.03734231408089602
collect_time: 133.89636189038305
reward_mean: -1052.7142857142856
reward_std: 99.18024202512939
reward_max: -917.5
reward_min: -1179.9999999999995
queue_len: 0.6530485643388869
wait_time: 3.474929103154909
delay_time: 208.39075499149803
pressure: 8.605086848635235
total_envstep_count: 57040
total_train_sample_count: 57040
total_episode_count: 460
total_duration: 15321.653530074454
[2024-12-27 00:25:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.606761589224787
avg_train_sample_per_sec: 4.606761589224787
avg_episode_per_sec: 0.037151303138909575
collect_time: 134.58478108573703
reward_mean: -970.5285714285717
reward_std: 41.85893706539736
reward_max: -940.357142857143
reward_min: -1053.1428571428573
queue_len: 0.6020648706132579
wait_time: 3.33175292449486
delay_time: 174.5074652478387
pressure: 8.149627791563276
total_envstep_count: 57660
total_train_sample_count: 57660
total_episode_count: 465
total_duration: 15456.238311160192
[2024-12-27 00:27:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.544064879064658
avg_train_sample_per_sec: 4.544064879064658
avg_episode_per_sec: 0.036645684508585956
collect_time: 136.4417138620652
reward_mean: -961.5428571428571
reward_std: 29.930518177394504
reward_max: -911.2142857142859
reward_min: -1004.5
queue_len: 0.5964906061680255
wait_time: 3.409083658277207
delay_time: 178.35422237484696
pressure: 8.138089330024814
total_envstep_count: 58280
total_train_sample_count: 58280
total_episode_count: 470
total_duration: 15592.680025022257
[2024-12-27 00:30:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.720138993932991
avg_train_sample_per_sec: 4.720138993932991
avg_episode_per_sec: 0.038065637047846705
collect_time: 131.3520641652532
reward_mean: -945.8857142857144
reward_std: 45.47133207655478
reward_max: -898.4999999999999
reward_min: -1026.9999999999998
queue_len: 0.5867777383906417
wait_time: 3.353518255937611
delay_time: 180.13969624995696
pressure: 7.947394540942928
total_envstep_count: 58900
total_train_sample_count: 58900
total_episode_count: 475
total_duration: 15724.03208918751
[2024-12-27 00:32:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.927883970960088
avg_train_sample_per_sec: 4.927883970960088
avg_episode_per_sec: 0.03974099976580716
collect_time: 125.81465059925242
reward_mean: -940.9857142857145
reward_std: 34.82698929958595
reward_max: -892.0000000000003
reward_min: -986.2857142857148
queue_len: 0.5837380361573912
wait_time: 3.334978730946473
delay_time: 163.1323307437703
pressure: 8.051240694789083
total_envstep_count: 59520
total_train_sample_count: 59520
total_episode_count: 480
total_duration: 15849.846739786763
[2024-12-27 00:34:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.627414418945083
avg_train_sample_per_sec: 4.627414418945083
avg_episode_per_sec: 0.037317858217299056
collect_time: 133.98410945465787
reward_mean: -925.7714285714286
reward_std: 37.18073343514779
reward_max: -863.4999999999997
reward_min: -980.2857142857142
queue_len: 0.5742998936547323
wait_time: 3.2562034739454107
delay_time: 171.38161419747635
pressure: 7.9564516129032254
total_envstep_count: 60140
total_train_sample_count: 60140
total_episode_count: 485
total_duration: 15983.83084924142
[2024-12-27 00:36:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.766078629962119
avg_train_sample_per_sec: 4.766078629962119
avg_episode_per_sec: 0.03843611798356548
collect_time: 130.08597804122417
reward_mean: -947.6142857142856
reward_std: 24.70927281943566
reward_max: -924.5000000000002
reward_min: -992.8571428571428
queue_len: 0.5878500531726338
wait_time: 3.2564959234314066
delay_time: 167.330449231665
pressure: 8.151612903225807
total_envstep_count: 60760
total_train_sample_count: 60760
total_episode_count: 490
total_duration: 16113.916827282645
[2024-12-27 00:38:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.614193049090689
avg_train_sample_per_sec: 4.614193049090689
avg_episode_per_sec: 0.0372112342668604
collect_time: 134.36802348835022
reward_mean: -978.5142857142857
reward_std: 65.03547540553897
reward_max: -878.2142857142858
reward_min: -1056.4999999999993
queue_len: 0.607018787663949
wait_time: 3.2236884083658275
delay_time: 178.4473611392712
pressure: 8.377791563275434
total_envstep_count: 61380
total_train_sample_count: 61380
total_episode_count: 495
total_duration: 16248.284850770995
[2024-12-27 00:41:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.688877797995209
avg_train_sample_per_sec: 4.688877797995209
avg_episode_per_sec: 0.03781353062899362
collect_time: 132.22780091754345
reward_mean: -942.8
reward_std: 60.006128938668354
reward_max: -890.0714285714286
reward_min: -1056.2857142857144
queue_len: 0.5848635235732009
wait_time: 3.1967919177596595
delay_time: 169.94815261004607
pressure: 8.06923076923077
total_envstep_count: 62000
total_train_sample_count: 62000
total_episode_count: 500
total_duration: 16380.51265168854
[2024-12-27 00:43:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.7536648877028735
avg_train_sample_per_sec: 4.7536648877028735
avg_episode_per_sec: 0.03833600715889414
collect_time: 130.42568516006696
reward_mean: -933.5857142857143
reward_std: 15.655370076906419
reward_max: -912.4285714285713
reward_min: -960.2857142857141
queue_len: 0.579147465437788
wait_time: 3.314081885856079
delay_time: 171.03586148312147
pressure: 7.992928039702233
total_envstep_count: 62620
total_train_sample_count: 62620
total_episode_count: 505
total_duration: 16510.938336848605
[2024-12-27 00:45:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.774908419177275
avg_train_sample_per_sec: 4.774908419177275
avg_episode_per_sec: 0.03850732596110706
collect_time: 129.8454222723767
reward_mean: -924.2142857142859
reward_std: 17.05656854740274
reward_max: -908.2142857142858
reward_min: -955.2857142857146
queue_len: 0.5733339241403759
wait_time: 3.258259482453032
delay_time: 170.23529435492202
pressure: 7.972704714640199
total_envstep_count: 63240
total_train_sample_count: 63240
total_episode_count: 510
total_duration: 16640.783759120983
[2024-12-27 00:47:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.787874721980845
avg_train_sample_per_sec: 4.787874721980845
avg_episode_per_sec: 0.03861189291920037
collect_time: 129.49378085304053
reward_mean: -928.5999999999997
reward_std: 37.02174209508657
reward_max: -886.8571428571423
reward_min: -983.4999999999998
queue_len: 0.5760545905707194
wait_time: 3.3086139666784833
delay_time: 167.69752324649903
pressure: 8.054590570719602
total_envstep_count: 63860
total_train_sample_count: 63860
total_episode_count: 515
total_duration: 16770.277539974024
[2024-12-27 00:49:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.833812543783001
avg_train_sample_per_sec: 4.833812543783001
avg_episode_per_sec: 0.03898235922405646
collect_time: 128.2631451642476
reward_mean: -918.4285714285713
reward_std: 42.9339549750069
reward_max: -838.0714285714284
reward_min: -961.4285714285712
queue_len: 0.5697447713576745
wait_time: 3.178704360155973
delay_time: 160.3535559044379
pressure: 7.975558312655087
total_envstep_count: 64480
total_train_sample_count: 64480
total_episode_count: 520
total_duration: 16898.540685138272
[2024-12-27 00:51:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.909889996080808
avg_train_sample_per_sec: 4.909889996080808
avg_episode_per_sec: 0.039595887065167805
collect_time: 126.27574151251838
reward_mean: -941.7428571428575
reward_std: 59.73671144177215
reward_max: -849.0000000000001
reward_min: -1009.6428571428572
queue_len: 0.584207727756115
wait_time: 3.28199220134704
delay_time: 172.48452514481886
pressure: 8.036972704714639
total_envstep_count: 65100
total_train_sample_count: 65100
total_episode_count: 525
total_duration: 17024.816426650792
[2024-12-27 00:54:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.847065518731176
avg_train_sample_per_sec: 4.847065518731176
avg_episode_per_sec: 0.03908923805428367
collect_time: 127.9124446748346
reward_mean: -887.742857142857
reward_std: 22.25178736228489
reward_max: -849.0714285714281
reward_min: -918.2142857142863
queue_len: 0.5507089684509039
wait_time: 3.222952853598015
delay_time: 159.56618174310842
pressure: 7.707444168734492
total_envstep_count: 65720
total_train_sample_count: 65720
total_episode_count: 530
total_duration: 17152.728871325628
[2024-12-27 00:56:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.874246529708669
avg_train_sample_per_sec: 4.874246529708669
avg_episode_per_sec: 0.039308439755715074
collect_time: 127.19914682630076
reward_mean: -905.2285714285712
reward_std: 33.523382031906145
reward_max: -868.5714285714287
reward_min: -956.214285714285
queue_len: 0.561556185749734
wait_time: 3.212256292095
delay_time: 172.1725879063869
pressure: 7.8029776674937965
total_envstep_count: 66340
total_train_sample_count: 66340
total_episode_count: 535
total_duration: 17279.928018151928
[2024-12-27 00:58:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.826633393295967
avg_train_sample_per_sec: 4.826633393295967
avg_episode_per_sec: 0.03892446284916102
collect_time: 128.4539241909608
reward_mean: -917.1857142857141
reward_std: 16.45603914949745
reward_max: -886.4285714285714
reward_min: -932.9285714285712
queue_len: 0.5689737681673164
wait_time: 3.201222970577809
delay_time: 170.59064118006626
pressure: 7.864764267990074
total_envstep_count: 66960
total_train_sample_count: 66960
total_episode_count: 540
total_duration: 17408.38194234289
[2024-12-27 01:00:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.651100336031164
avg_train_sample_per_sec: 4.651100336031164
avg_episode_per_sec: 0.037508873677670675
collect_time: 133.30178994354978
reward_mean: -967.4428571428571
reward_std: 48.2264936925499
reward_max: -920.3571428571425
reward_min: -1057.9285714285713
queue_len: 0.6001506557958171
wait_time: 3.216350584898972
delay_time: 183.13639316745895
pressure: 8.160794044665012
total_envstep_count: 67580
total_train_sample_count: 67580
total_episode_count: 545
total_duration: 17541.68373228644
[2024-12-27 01:02:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.689763763713781
avg_train_sample_per_sec: 4.689763763713781
avg_episode_per_sec: 0.03782067551382082
collect_time: 132.20282113080845
reward_mean: -921.1142857142859
reward_std: 23.99509303578362
reward_max: -875.214285714286
reward_min: -938.9285714285716
queue_len: 0.571410847217299
wait_time: 3.180131159163416
delay_time: 170.75089165887542
pressure: 7.898263027295286
total_envstep_count: 68200
total_train_sample_count: 68200
total_episode_count: 550
total_duration: 17673.88655341725
[2024-12-27 01:05:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.549526376550925
avg_train_sample_per_sec: 4.549526376550925
avg_episode_per_sec: 0.03668972884315262
collect_time: 136.2779218504131
reward_mean: -962.6142857142855
reward_std: 17.32737600399092
reward_max: -929.7857142857138
reward_min: -978.5
queue_len: 0.5971552640907478
wait_time: 3.277304147465437
delay_time: 177.7562873122809
pressure: 8.279652605459058
total_envstep_count: 68820
total_train_sample_count: 68820
total_episode_count: 555
total_duration: 17810.164475267666
[2024-12-27 01:07:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.717768071639736
avg_train_sample_per_sec: 4.717768071639736
avg_episode_per_sec: 0.03804651670677207
collect_time: 131.41807536641136
reward_mean: -917.3142857142857
reward_std: 29.150160149383094
reward_max: -870.8571428571431
reward_min: -949.2857142857137
queue_len: 0.5690535271180432
wait_time: 3.200053172633818
delay_time: 168.0658854557936
pressure: 7.890446650124071
total_envstep_count: 69440
total_train_sample_count: 69440
total_episode_count: 560
total_duration: 17941.582550634077
[2024-12-27 01:09:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.77871733363098
avg_train_sample_per_sec: 4.77871733363098
avg_episode_per_sec: 0.03853804301315307
collect_time: 129.74192795138808
reward_mean: -913.3714285714286
reward_std: 33.40021385731356
reward_max: -872.0714285714288
reward_min: -972.7142857142858
queue_len: 0.5666075859624247
wait_time: 3.1723059198865653
delay_time: 168.74212990545206
pressure: 7.968858560794045
total_envstep_count: 70060
total_train_sample_count: 70060
total_episode_count: 565
total_duration: 18071.324478585466
[2024-12-27 01:11:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.909228740058901
avg_train_sample_per_sec: 4.909228740058901
avg_episode_per_sec: 0.039590554355313716
collect_time: 126.29275041532517
reward_mean: -890.4428571428568
reward_std: 30.540284536851377
reward_max: -843.4999999999998
reward_min: -926.7142857142856
queue_len: 0.5523839064161643
wait_time: 3.017936901807869
delay_time: 166.68424517638354
pressure: 7.767493796526054
total_envstep_count: 70680
total_train_sample_count: 70680
total_episode_count: 570
total_duration: 18197.617229000793
[2024-12-27 01:13:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.6968850984371215
avg_train_sample_per_sec: 4.6968850984371215
avg_episode_per_sec: 0.03787810563255743
collect_time: 132.00237753448636
reward_mean: -913.757142857143
reward_std: 44.4064850935913
reward_max: -884.5000000000003
reward_min: -1002.1428571428572
queue_len: 0.5668468628146047
wait_time: 3.0836316908897548
delay_time: 171.189683216019
pressure: 8.033995037220844
total_envstep_count: 71300
total_train_sample_count: 71300
total_episode_count: 575
total_duration: 18329.619606535278
[2024-12-27 01:15:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.855763735280486
avg_train_sample_per_sec: 4.855763735280486
avg_episode_per_sec: 0.0391593849619394
collect_time: 127.68331282168255
reward_mean: -868.1571428571426
reward_std: 20.796604903449943
reward_max: -834.5714285714287
reward_min: -893.2857142857141
queue_len: 0.5385590216235376
wait_time: 3.0058755760368667
delay_time: 164.2128775366316
pressure: 7.605459057071961
total_envstep_count: 71920
total_train_sample_count: 71920
total_episode_count: 580
total_duration: 18457.30291935696
[2024-12-27 01:18:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.6816632722585885
avg_train_sample_per_sec: 4.6816632722585885
avg_episode_per_sec: 0.037755348969827324
collect_time: 132.4315662926547
reward_mean: -872.2000000000002
reward_std: 17.417174259439193
reward_max: -853.3571428571427
reward_min: -904.285714285714
queue_len: 0.5410669975186104
wait_time: 3.0383640552995392
delay_time: 161.76337418424447
pressure: 7.684615384615386
total_envstep_count: 72540
total_train_sample_count: 72540
total_episode_count: 585
total_duration: 18589.734485649617
[2024-12-27 01:20:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.783311452487136
avg_train_sample_per_sec: 4.783311452487136
avg_episode_per_sec: 0.03857509235876722
collect_time: 129.6173176592179
reward_mean: -877.342857142857
reward_std: 49.82257090344247
reward_max: -837.8571428571429
reward_min: -972.7857142857138
queue_len: 0.5442573555476781
wait_time: 3.0965969514356617
delay_time: 149.7732455581085
pressure: 7.623697270471465
total_envstep_count: 73160
total_train_sample_count: 73160
total_episode_count: 590
total_duration: 18719.351803308833
[2024-12-27 01:22:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.87470412707249
avg_train_sample_per_sec: 4.87470412707249
avg_episode_per_sec: 0.03931213005703621
collect_time: 127.18720641048256
reward_mean: -863.9142857142857
reward_std: 41.32952198798213
reward_max: -801.1428571428572
reward_min: -921.857142857143
queue_len: 0.5359269762495569
wait_time: 2.9835873803615742
delay_time: 154.91978106978678
pressure: 7.483126550868486
total_envstep_count: 73780
total_train_sample_count: 73780
total_episode_count: 595
total_duration: 18846.539009719316
[2024-12-27 01:24:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.81387250512612
avg_train_sample_per_sec: 4.81387250512612
avg_episode_per_sec: 0.03882155246069452
collect_time: 128.79443718955667
reward_mean: -875.0428571428572
reward_std: 13.358219971849723
reward_max: -859.3571428571429
reward_min: -898.5714285714286
queue_len: 0.542830556540234
wait_time: 3.095843672456575
delay_time: 161.26116914939365
pressure: 7.687344913151366
total_envstep_count: 74400
total_train_sample_count: 74400
total_episode_count: 600
total_duration: 18975.333446908873
[2024-12-27 01:26:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.921655871041205
avg_train_sample_per_sec: 4.921655871041205
avg_episode_per_sec: 0.0396907731535581
collect_time: 125.97386250592027
reward_mean: -836.4857142857142
reward_std: 28.27934271672176
reward_max: -805.285714285714
reward_min: -872.8571428571429
queue_len: 0.5189117334278625
wait_time: 2.9916430343849694
delay_time: 157.66848313011752
pressure: 7.280521091811414
total_envstep_count: 75020
total_train_sample_count: 75020
total_episode_count: 605
total_duration: 19101.307309414795
[2024-12-27 01:28:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.965306101485945
avg_train_sample_per_sec: 4.965306101485945
avg_episode_per_sec: 0.04004279114101568
collect_time: 124.8664205847159
reward_mean: -893.8142857142857
reward_std: 17.452828552695856
reward_max: -867.0
reward_min: -916.9285714285718
queue_len: 0.5544753633463311
wait_time: 3.15593761077632
delay_time: 165.42589262022972
pressure: 7.823325062034739
total_envstep_count: 75640
total_train_sample_count: 75640
total_episode_count: 610
total_duration: 19226.17372999951
[2024-12-27 01:30:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.8067231700154744
avg_train_sample_per_sec: 4.8067231700154744
avg_episode_per_sec: 0.03876389653238286
collect_time: 128.98600108023362
reward_mean: -889.5
reward_std: 17.304299336008828
reward_max: -859.1428571428573
reward_min: -908.7142857142852
queue_len: 0.5517990074441688
wait_time: 3.112920950017725
delay_time: 163.49445948424903
pressure: 7.774937965260546
total_envstep_count: 76260
total_train_sample_count: 76260
total_episode_count: 615
total_duration: 19355.159731079744
[2024-12-27 01:33:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.825482518202604
avg_train_sample_per_sec: 4.825482518202604
avg_episode_per_sec: 0.0389151815984081
collect_time: 128.48456038567053
reward_mean: -873.3285714285715
reward_std: 18.816330293505295
reward_max: -855.2857142857141
reward_min: -905.3571428571427
queue_len: 0.5417671038638782
wait_time: 3.0351116625310164
delay_time: 160.7618739374715
pressure: 7.644292803970224
total_envstep_count: 76880
total_train_sample_count: 76880
total_episode_count: 620
total_duration: 19483.644291465414
[2024-12-27 01:35:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.761240792710586
avg_train_sample_per_sec: 4.761240792710586
avg_episode_per_sec: 0.03839710316702086
collect_time: 130.21815677737072
reward_mean: -866.8714285714286
reward_std: 50.04484519520718
reward_max: -805.7142857142856
reward_min: -948.2857142857143
queue_len: 0.5377614321162707
wait_time: 3.022651542006381
delay_time: 162.48460936416478
pressure: 7.62940446650124
total_envstep_count: 77500
total_train_sample_count: 77500
total_episode_count: 625
total_duration: 19613.862448242784
[2024-12-27 01:37:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.886213623258931
avg_train_sample_per_sec: 4.886213623258931
avg_episode_per_sec: 0.0394049485746688
collect_time: 126.88761642526836
reward_mean: -862.8714285714286
reward_std: 22.751111208564836
reward_max: -842.2857142857146
reward_min: -906.7142857142856
queue_len: 0.5352800425381071
wait_time: 3.0023927685218004
delay_time: 162.9092345193805
pressure: 7.563399503722084
total_envstep_count: 78120
total_train_sample_count: 78120
total_episode_count: 630
total_duration: 19740.750064668053
[2024-12-27 01:39:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.7088003013057875
avg_train_sample_per_sec: 4.7088003013057875
avg_episode_per_sec: 0.03797419597827248
collect_time: 131.66835718815025
reward_mean: -1120.0142857142857
reward_std: 499.29996995794016
reward_max: -812.7857142857144
reward_min: -2116.5714285714284
queue_len: 0.6947979439914923
wait_time: 3.186848635235732
delay_time: 217.4956665595393
pressure: 9.166873449131513
total_envstep_count: 78740
total_train_sample_count: 78740
total_episode_count: 635
total_duration: 19872.418421856204
[2024-12-27 01:41:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.996841791253222
avg_train_sample_per_sec: 4.996841791253222
avg_episode_per_sec: 0.04029711121978405
collect_time: 124.07837308062985
reward_mean: -942.7714285714286
reward_std: 70.32277478215173
reward_max: -882.8571428571431
reward_min: -1080.6428571428573
queue_len: 0.5848457993619284
wait_time: 2.9560262318326833
delay_time: 169.3408327901935
pressure: 8.210545905707196
total_envstep_count: 79360
total_train_sample_count: 79360
total_episode_count: 640
total_duration: 19996.496794936833
[2024-12-27 01:43:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.925378489168966
avg_train_sample_per_sec: 4.925378489168966
avg_episode_per_sec: 0.039720794267491664
collect_time: 125.87865102415904
reward_mean: -900.1142857142856
reward_std: 43.97969383008213
reward_max: -814.9999999999999
reward_min: -939.0714285714288
queue_len: 0.5583835519319391
wait_time: 2.9321783055654027
delay_time: 163.24694553245178
pressure: 7.835980148883374
total_envstep_count: 79980
total_train_sample_count: 79980
total_episode_count: 645
total_duration: 20122.37544596099
[2024-12-27 01:45:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.90860682125905
avg_train_sample_per_sec: 4.90860682125905
avg_episode_per_sec: 0.039585538881121374
collect_time: 126.30875166346506
reward_mean: -871.7428571428572
reward_std: 24.518406247102668
reward_max: -836.0000000000002
reward_min: -897.5000000000001
queue_len: 0.5407834101382489
wait_time: 2.928438496986884
delay_time: 157.57964982092588
pressure: 7.645657568238214
total_envstep_count: 80600
total_train_sample_count: 80600
total_episode_count: 650
total_duration: 20248.684197624458
[2024-12-27 01:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.836521698678714
avg_train_sample_per_sec: 4.836521698678714
avg_episode_per_sec: 0.03900420724740899
collect_time: 128.19129916637763
reward_mean: -873.3571428571429
reward_std: 15.01557015030654
reward_max: -843.857142857143
reward_min: -884.6428571428577
queue_len: 0.5417848280751507
wait_time: 2.972243885147111
delay_time: 162.01593239662867
pressure: 7.632009925558313
total_envstep_count: 81220
total_train_sample_count: 81220
total_episode_count: 655
total_duration: 20376.875496790835
[2024-12-27 01:50:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.004378202155249
avg_train_sample_per_sec: 5.004378202155249
avg_episode_per_sec: 0.040357888727058464
collect_time: 123.8915155798942
reward_mean: -827.0571428571432
reward_std: 12.615296837003775
reward_max: -809.9285714285716
reward_min: -842.5000000000003
queue_len: 0.5130627437079051
wait_time: 2.8363789436370075
delay_time: 154.0318327247312
pressure: 7.239702233250621
total_envstep_count: 81840
total_train_sample_count: 81840
total_episode_count: 660
total_duration: 20500.76701237073
[2024-12-27 01:52:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.915287861150992
avg_train_sample_per_sec: 4.915287861150992
avg_episode_per_sec: 0.03963941823508864
collect_time: 126.13706816650557
reward_mean: -849.6285714285714
reward_std: 7.50868884448304
reward_max: -839.0
reward_min: -861.1428571428569
queue_len: 0.5270648706132578
wait_time: 2.9225629209500177
delay_time: 155.19413145974414
pressure: 7.406079404466501
total_envstep_count: 82460
total_train_sample_count: 82460
total_episode_count: 665
total_duration: 20626.904080537235
[2024-12-27 01:54:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.0352884853918
avg_train_sample_per_sec: 5.0352884853918
avg_episode_per_sec: 0.04060716520477258
collect_time: 123.13097885031254
reward_mean: -834.7
reward_std: 18.478636313321246
reward_max: -815.7142857142859
reward_min: -861.0714285714283
queue_len: 0.5178039702233251
wait_time: 2.9608915278270116
delay_time: 156.71671153941645
pressure: 7.355707196029776
total_envstep_count: 83080
total_train_sample_count: 83080
total_episode_count: 670
total_duration: 20750.03505938755
[2024-12-27 01:56:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.955295092745345
avg_train_sample_per_sec: 4.955295092745345
avg_episode_per_sec: 0.03996205719955923
collect_time: 125.11868383130056
reward_mean: -867.4714285714284
reward_std: 52.13126289884571
reward_max: -819.2857142857141
reward_min: -968.9999999999998
queue_len: 0.5381336405529954
wait_time: 3.0182913860333214
delay_time: 159.9943149554794
pressure: 7.6282878411910655
total_envstep_count: 83700
total_train_sample_count: 83700
total_episode_count: 675
total_duration: 20875.15374321885
[2024-12-27 01:58:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.885532427865609
avg_train_sample_per_sec: 4.885532427865609
avg_episode_per_sec: 0.039399455063432336
collect_time: 126.90530851124971
reward_mean: -836.5285714285716
reward_std: 13.184065831022643
reward_max: -813.8571428571425
reward_min: -851.2857142857144
queue_len: 0.5189383197447713
wait_time: 2.9026497695852536
delay_time: 155.6219031071042
pressure: 7.317617866004963
total_envstep_count: 84320
total_train_sample_count: 84320
total_episode_count: 680
total_duration: 21002.0590517301
[2024-12-27 02:00:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.095517995978854
avg_train_sample_per_sec: 5.095517995978854
avg_episode_per_sec: 0.0410928870643456
collect_time: 121.67555889102445
reward_mean: -842.9857142857143
reward_std: 12.75030211726898
reward_max: -823.6428571428569
reward_min: -854.5714285714283
queue_len: 0.5229439914923786
wait_time: 2.958383551931939
delay_time: 155.77593670598753
pressure: 7.3777915632754345
total_envstep_count: 84940
total_train_sample_count: 84940
total_episode_count: 685
total_duration: 21123.734610621123
[2024-12-27 02:02:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.953781320610499
avg_train_sample_per_sec: 4.953781320610499
avg_episode_per_sec: 0.03994984935976209
collect_time: 125.15691748855636
reward_mean: -843.1428571428569
reward_std: 27.484281221922373
reward_max: -791.6428571428569
reward_min: -873.4285714285712
queue_len: 0.5230414746543779
wait_time: 2.976772421127259
delay_time: 155.576292391125
pressure: 7.42196029776675
total_envstep_count: 85560
total_train_sample_count: 85560
total_episode_count: 690
total_duration: 21248.891528109678
[2024-12-27 02:04:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.92338841862005
avg_train_sample_per_sec: 4.92338841862005
avg_episode_per_sec: 0.03970474531145201
collect_time: 125.92953211962434
reward_mean: -830.8999999999999
reward_std: 23.643206730259617
reward_max: -802.7142857142857
reward_min: -871.785714285714
queue_len: 0.5154466501240694
wait_time: 2.879103154909607
delay_time: 149.22073402964858
pressure: 7.270843672456576
total_envstep_count: 86180
total_train_sample_count: 86180
total_episode_count: 695
total_duration: 21374.821060229304
[2024-12-27 02:06:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.042513083290857
avg_train_sample_per_sec: 5.042513083290857
avg_episode_per_sec: 0.040665428091055306
collect_time: 122.95456447192281
reward_mean: -839.1142857142856
reward_std: 17.881218056488123
reward_max: -814.4285714285716
reward_min: -867.0714285714289
queue_len: 0.5205423608649415
wait_time: 2.9138248847926262
delay_time: 156.58436879473066
pressure: 7.320099255583126
total_envstep_count: 86800
total_train_sample_count: 86800
total_episode_count: 700
total_duration: 21497.775624701226
[2024-12-27 02:08:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.996550547206489
avg_train_sample_per_sec: 4.996550547206489
avg_episode_per_sec: 0.04029476247747169
collect_time: 124.0856054876968
reward_mean: -870.842857142857
reward_std: 58.88739513785965
reward_max: -799.7142857142861
reward_min: -978.6428571428565
queue_len: 0.5402250974831619
wait_time: 2.8673520028358737
delay_time: 156.96042864406337
pressure: 7.514888337468983
total_envstep_count: 87420
total_train_sample_count: 87420
total_episode_count: 705
total_duration: 21621.861230188922
[2024-12-27 02:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.7723594670466705
avg_train_sample_per_sec: 4.7723594670466705
avg_episode_per_sec: 0.03848676989553766
collect_time: 129.9147736630328
reward_mean: -1262.2142857142858
reward_std: 826.1424791876806
reward_max: -832.1428571428568
reward_min: -2914.3571428571427
queue_len: 0.7830113434952144
wait_time: 3.3579758950726686
delay_time: 252.93375109464333
pressure: 9.770223325062034
total_envstep_count: 88040
total_train_sample_count: 88040
total_episode_count: 710
total_duration: 21751.776003851955
[2024-12-27 02:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.911477665025777
avg_train_sample_per_sec: 4.911477665025777
avg_episode_per_sec: 0.03960869084698208
collect_time: 126.23492201032863
reward_mean: -852.757142857143
reward_std: 10.01932825969417
reward_max: -840.3571428571431
reward_min: -869.2142857142854
queue_len: 0.5290056717476073
wait_time: 2.953766394895427
delay_time: 156.72625359495206
pressure: 7.414640198511167
total_envstep_count: 88660
total_train_sample_count: 88660
total_episode_count: 715
total_duration: 21878.010925862283
[2024-12-27 02:15:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.047115235515875
avg_train_sample_per_sec: 5.047115235515875
avg_episode_per_sec: 0.04070254222190221
collect_time: 122.8424498091787
reward_mean: -813.3142857142859
reward_std: 16.91561288229513
reward_max: -791.2142857142862
reward_min: -834.5714285714287
queue_len: 0.5045373980857852
wait_time: 2.8105459057071958
delay_time: 152.30857646836222
pressure: 7.13287841191067
total_envstep_count: 89280
total_train_sample_count: 89280
total_episode_count: 720
total_duration: 22000.85337567146
[2024-12-27 02:17:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.014525241915884
avg_train_sample_per_sec: 5.014525241915884
avg_episode_per_sec: 0.04043971969287003
collect_time: 123.640817443192
reward_mean: -839.7285714285715
reward_std: 16.50815506570828
reward_max: -812.4285714285714
reward_min: -861.6428571428572
queue_len: 0.5209234314073025
wait_time: 2.865739099610068
delay_time: 156.47007899989944
pressure: 7.319354838709678
total_envstep_count: 89900
total_train_sample_count: 89900
total_episode_count: 725
total_duration: 22124.494193114653
[2024-12-27 02:19:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.0504394805127495
avg_train_sample_per_sec: 5.0504394805127495
avg_episode_per_sec: 0.040729350649296364
collect_time: 122.7615937963985
reward_mean: -851.1
reward_std: 54.98728238865587
reward_max: -783.0714285714288
reward_min: -937.2142857142857
queue_len: 0.5279776674937965
wait_time: 2.8963842609003896
delay_time: 154.5650751887386
pressure: 7.363151364764268
total_envstep_count: 90520
total_train_sample_count: 90520
total_episode_count: 730
total_duration: 22247.255786911053
[2024-12-27 02:21:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.002019069146027
avg_train_sample_per_sec: 5.002019069146027
avg_episode_per_sec: 0.04033886346085506
collect_time: 123.94994729715212
reward_mean: -844.2285714285714
reward_std: 26.78136726631153
reward_max: -804.5000000000001
reward_min: -888.6428571428573
queue_len: 0.5237149946827367
wait_time: 2.894487770294222
delay_time: 151.59436243092665
pressure: 7.383870967741936
total_envstep_count: 91140
total_train_sample_count: 91140
total_episode_count: 735
total_duration: 22371.205734208204
[2024-12-27 02:23:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.907039995248997
avg_train_sample_per_sec: 4.907039995248997
avg_episode_per_sec: 0.03957290318749191
collect_time: 126.3490822573863
reward_mean: -828.8285714285715
reward_std: 29.07925833487032
reward_max: -783.3571428571429
reward_min: -863.1428571428571
queue_len: 0.5141616448068062
wait_time: 2.845001772421127
delay_time: 145.18937923062725
pressure: 7.202977667493796
total_envstep_count: 91760
total_train_sample_count: 91760
total_episode_count: 740
total_duration: 22497.554816465592
[2024-12-27 02:25:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.93394513251716
avg_train_sample_per_sec: 4.93394513251716
avg_episode_per_sec: 0.03978988010094484
collect_time: 125.66009214692936
reward_mean: -821.3714285714289
reward_std: 29.38996774550176
reward_max: -774.5714285714288
reward_min: -866.214285714286
queue_len: 0.509535625664658
wait_time: 2.85392591279688
delay_time: 150.14909592791832
pressure: 7.256947890818859
total_envstep_count: 92380
total_train_sample_count: 92380
total_episode_count: 745
total_duration: 22623.21490861252
[2024-12-27 02:27:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.88557387319598
avg_train_sample_per_sec: 4.88557387319598
avg_episode_per_sec: 0.03939978929996758
collect_time: 126.90423194735496
reward_mean: -807.7571428571426
reward_std: 17.16305952459813
reward_max: -778.4285714285713
reward_min: -823.4285714285712
queue_len: 0.5010900389932647
wait_time: 2.859606522509748
delay_time: 149.9328714988084
pressure: 7.031141439205956
total_envstep_count: 93000
total_train_sample_count: 93000
total_episode_count: 750
total_duration: 22750.119140559877
[2024-12-27 02:29:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.933344100269921
avg_train_sample_per_sec: 4.933344100269921
avg_episode_per_sec: 0.03978503306669291
collect_time: 125.67540139072756
reward_mean: -806.0000000000001
reward_std: 35.08755811814042
reward_max: -761.1428571428573
reward_min: -868.4285714285717
queue_len: 0.5000000000000001
wait_time: 2.9292006380716065
delay_time: 140.98465403320995
pressure: 7.04863523573201
total_envstep_count: 93620
total_train_sample_count: 93620
total_episode_count: 755
total_duration: 22875.794541950603
[2024-12-27 02:32:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.068758856176092
avg_train_sample_per_sec: 5.068758856176092
avg_episode_per_sec: 0.04087708754980719
collect_time: 122.31791205544397
reward_mean: -798.6714285714286
reward_std: 15.739823404864742
reward_max: -772.0714285714283
reward_min: -817.4285714285713
queue_len: 0.49545373980857843
wait_time: 2.8722084367245655
delay_time: 150.05843633700948
pressure: 7.024317617866005
total_envstep_count: 94240
total_train_sample_count: 94240
total_episode_count: 760
total_duration: 22998.11245400605
[2024-12-27 02:34:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.933862504578764
avg_train_sample_per_sec: 4.933862504578764
avg_episode_per_sec: 0.039789213746602936
collect_time: 125.66219659032299
reward_mean: -815.1571428571428
reward_std: 28.69314787007303
reward_max: -777.9285714285714
reward_min: -864.2857142857142
queue_len: 0.5056806097128678
wait_time: 2.867352002835873
delay_time: 152.5102297472992
pressure: 7.147146401985113
total_envstep_count: 94860
total_train_sample_count: 94860
total_episode_count: 765
total_duration: 23123.77465059637
[2024-12-27 02:36:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.991479854362342
avg_train_sample_per_sec: 4.991479854362342
avg_episode_per_sec: 0.0402538697932447
collect_time: 124.21166028710829
reward_mean: -814.3714285714284
reward_std: 30.061311497996734
reward_max: -780.2142857142856
reward_min: -866.6428571428569
queue_len: 0.5051931939028711
wait_time: 2.895772775611486
delay_time: 154.34957006101519
pressure: 7.1786600496277915
total_envstep_count: 95480
total_train_sample_count: 95480
total_episode_count: 770
total_duration: 23247.986310883476
[2024-12-27 02:38:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.02909646821809
avg_train_sample_per_sec: 5.02909646821809
avg_episode_per_sec: 0.04055722958240395
collect_time: 123.28258245157076
reward_mean: -775.2285714285715
reward_std: 16.088619377354487
reward_max: -754.7142857142858
reward_min: -799.357142857143
queue_len: 0.4809110244594116
wait_time: 2.8173963133640547
delay_time: 139.06936092875267
pressure: 6.788957816377172
total_envstep_count: 96100
total_train_sample_count: 96100
total_episode_count: 775
total_duration: 23371.268893335047
[2024-12-27 02:40:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.975326493007119
avg_train_sample_per_sec: 4.975326493007119
avg_episode_per_sec: 0.04012360075005741
collect_time: 124.61493750639632
reward_mean: -784.9428571428573
reward_std: 12.225133027947855
reward_max: -776.3571428571428
reward_min: -809.0714285714287
queue_len: 0.486937256292095
wait_time: 2.8568947181850404
delay_time: 142.11806713728834
pressure: 6.894913151364764
total_envstep_count: 96720
total_train_sample_count: 96720
total_episode_count: 780
total_duration: 23495.883830841445
[2024-12-27 02:42:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.847428727420863
avg_train_sample_per_sec: 4.847428727420863
avg_episode_per_sec: 0.03909216715661987
collect_time: 127.9028604366668
reward_mean: -802.0428571428571
reward_std: 25.981571176823145
reward_max: -768.4285714285712
reward_min: -848.2142857142857
queue_len: 0.49754519673874514
wait_time: 2.8463488124778435
delay_time: 153.24665407203813
pressure: 7.0885856079404475
total_envstep_count: 97340
total_train_sample_count: 97340
total_episode_count: 785
total_duration: 23623.786691278114
[2024-12-27 02:44:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.859019279554839
avg_train_sample_per_sec: 4.859019279554839
avg_episode_per_sec: 0.0391856393512487
collect_time: 127.597764966432
reward_mean: -805.4571428571428
reward_std: 7.000233232266
reward_max: -796.2142857142859
reward_min: -814.3571428571428
queue_len: 0.49966323998582063
wait_time: 2.8340304856433893
delay_time: 151.5908842416536
pressure: 7.1287841191067
total_envstep_count: 97960
total_train_sample_count: 97960
total_episode_count: 790
total_duration: 23751.384456244545
[2024-12-27 02:46:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.781377222005168
avg_train_sample_per_sec: 4.781377222005168
avg_episode_per_sec: 0.038559493725848125
collect_time: 129.66975229366872
reward_mean: -856.7285714285715
reward_std: 129.0942022757974
reward_max: -787.4285714285716
reward_min: -1114.7857142857144
queue_len: 0.5314693371144985
wait_time: 2.960962424672102
delay_time: 155.38704820308243
pressure: 7.676054590570719
total_envstep_count: 98580
total_train_sample_count: 98580
total_episode_count: 795
total_duration: 23881.054208538215
[2024-12-27 02:48:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.997707169648396
avg_train_sample_per_sec: 4.997707169648396
avg_episode_per_sec: 0.04030409007780965
collect_time: 124.05688827975467
reward_mean: -805.7857142857143
reward_std: 22.98144770843453
reward_max: -769.0714285714282
reward_min: -829.142857142857
queue_len: 0.4998670684154555
wait_time: 2.9491846862814604
delay_time: 145.82371345300268
pressure: 7.0529776674937965
total_envstep_count: 99200
total_train_sample_count: 99200
total_episode_count: 800
total_duration: 24005.11109681797
[2024-12-27 02:51:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.935697099278766
avg_train_sample_per_sec: 4.935697099278766
avg_episode_per_sec: 0.039804008865151334
collect_time: 125.61548805144429
reward_mean: -823.0
reward_std: 73.41988553407558
reward_max: -764.9285714285713
reward_min: -968.0714285714289
queue_len: 0.5105459057071959
wait_time: 2.894239631336405
delay_time: 155.50381437964407
pressure: 7.243672456575682
total_envstep_count: 99820
total_train_sample_count: 99820
total_episode_count: 805
total_duration: 24130.726584869415
[2024-12-27 02:53:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.9315788193573695
avg_train_sample_per_sec: 4.9315788193573695
avg_episode_per_sec: 0.03977079693030137
collect_time: 125.72038746828582
reward_mean: -805.6142857142856
reward_std: 22.40192229361103
reward_max: -777.0
reward_min: -837.6428571428573
queue_len: 0.49976072314781994
wait_time: 2.917174760723147
delay_time: 153.2568429254149
pressure: 7.116377171215882
total_envstep_count: 100440
total_train_sample_count: 100440
total_episode_count: 810
total_duration: 24256.4469723377
[2024-12-27 02:55:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.003230541486134
avg_train_sample_per_sec: 5.003230541486134
avg_episode_per_sec: 0.04034863339908173
collect_time: 123.91993430225551
reward_mean: -804.4857142857143
reward_std: 17.10712943632047
reward_max: -774.3571428571428
reward_min: -825.357142857143
queue_len: 0.4990606168025523
wait_time: 2.840809996455158
delay_time: 154.43328524392592
pressure: 7.063151364764269
total_envstep_count: 101060
total_train_sample_count: 101060
total_episode_count: 815
total_duration: 24380.366906639956
[2024-12-27 02:57:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.070509082883055
avg_train_sample_per_sec: 5.070509082883055
avg_episode_per_sec: 0.04089120228131495
collect_time: 122.27569063883277
reward_mean: -806.2285714285715
reward_std: 14.23178391732361
reward_max: -791.0714285714286
reward_min: -830.6428571428575
queue_len: 0.5001417936901807
wait_time: 2.8886830911024464
delay_time: 150.99220647898878
pressure: 7.084739454094293
total_envstep_count: 101680
total_train_sample_count: 101680
total_episode_count: 820
total_duration: 24502.642597278787
[2024-12-27 02:59:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.054050555934815
avg_train_sample_per_sec: 5.054050555934815
avg_episode_per_sec: 0.04075847222528076
collect_time: 122.67388169909643
reward_mean: -791.6000000000001
reward_std: 18.03095976935457
reward_max: -775.2142857142857
reward_min: -825.5714285714287
queue_len: 0.4910669975186105
wait_time: 2.7997429989365474
delay_time: 153.5350099612982
pressure: 6.955707196029778
total_envstep_count: 102300
total_train_sample_count: 102300
total_episode_count: 825
total_duration: 24625.316478977882
[2024-12-27 03:01:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.974401176092414
avg_train_sample_per_sec: 4.974401176092414
avg_episode_per_sec: 0.0401161385168743
collect_time: 124.63811784618349
reward_mean: -814.0428571428572
reward_std: 22.001697522635656
reward_max: -783.357142857143
reward_min: -843.0000000000001
queue_len: 0.5049893654732365
wait_time: 2.8550779865295994
delay_time: 156.83254694557053
pressure: 7.1681141439205955
total_envstep_count: 102920
total_train_sample_count: 102920
total_episode_count: 830
total_duration: 24749.954596824067
[2024-12-27 03:03:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.913256806962496
avg_train_sample_per_sec: 4.913256806962496
avg_episode_per_sec: 0.03962303876582658
collect_time: 126.18921101811901
reward_mean: -797.4857142857143
reward_std: 17.355079242406106
reward_max: -765.7142857142862
reward_min: -816.4285714285713
queue_len: 0.49471818504076576
wait_time: 2.855060262318326
delay_time: 151.79311164592946
pressure: 7.071836228287841
total_envstep_count: 103540
total_train_sample_count: 103540
total_episode_count: 835
total_duration: 24876.143807842185
[2024-12-27 03:05:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.045000979252086
avg_train_sample_per_sec: 5.045000979252086
avg_episode_per_sec: 0.04068549176816198
collect_time: 122.89393055616694
reward_mean: -803.2142857142857
reward_std: 15.991387988411706
reward_max: -779.7857142857142
reward_min: -827.5714285714284
queue_len: 0.4982718894009216
wait_time: 2.870613257710031
delay_time: 152.70654625071847
pressure: 7.100124069478909
total_envstep_count: 104160
total_train_sample_count: 104160
total_episode_count: 840
total_duration: 24999.03773839835
[2024-12-27 03:07:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.963129229334795
avg_train_sample_per_sec: 4.963129229334795
avg_episode_per_sec: 0.04002523572044189
collect_time: 124.92118809549882
reward_mean: -800.1285714285715
reward_std: 15.19938237198466
reward_max: -775.7142857142857
reward_min: -823.4285714285716
queue_len: 0.49635767458348107
wait_time: 2.8009836937256285
delay_time: 154.76918575502765
pressure: 7.080272952853598
total_envstep_count: 104780
total_train_sample_count: 104780
total_episode_count: 845
total_duration: 25123.958926493848
[2024-12-27 03:09:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.951171944670394
avg_train_sample_per_sec: 4.951171944670394
avg_episode_per_sec: 0.0399288060054064
collect_time: 125.22287792234495
reward_mean: -789.5571428571427
reward_std: 5.109095530801762
reward_max: -783.9999999999999
reward_min: -798.5714285714289
queue_len: 0.48979971641261955
wait_time: 2.8112460120524636
delay_time: 151.60053184809726
pressure: 6.979776674937964
total_envstep_count: 105400
total_train_sample_count: 105400
total_episode_count: 850
total_duration: 25249.181804416192
[2024-12-27 03:11:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.9534295123668075
avg_train_sample_per_sec: 4.9534295123668075
avg_episode_per_sec: 0.03994701219650651
collect_time: 125.16580652901159
reward_mean: -808.6428571428571
reward_std: 15.890762301746406
reward_max: -787.2857142857148
reward_min: -831.6428571428565
queue_len: 0.5016394895427154
wait_time: 2.8766306274370788
delay_time: 152.45668418140124
pressure: 7.1542183622828786
total_envstep_count: 106020
total_train_sample_count: 106020
total_episode_count: 855
total_duration: 25374.347610945202
[2024-12-27 03:14:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.913580593519228
avg_train_sample_per_sec: 4.913580593519228
avg_episode_per_sec: 0.039625649947735715
collect_time: 126.1808956217691
reward_mean: -792.242857142857
reward_std: 14.48247357381751
reward_max: -772.7142857142858
reward_min: -807.9999999999997
queue_len: 0.4914657922722438
wait_time: 2.785864941510103
delay_time: 154.06106466028638
pressure: 7.056203473945409
total_envstep_count: 106640
total_train_sample_count: 106640
total_episode_count: 860
total_duration: 25500.52850656697
[2024-12-27 03:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.932996063741577
avg_train_sample_per_sec: 4.932996063741577
avg_episode_per_sec: 0.039782226320496585
collect_time: 125.68426813820376
reward_mean: -790.8000000000002
reward_std: 7.384678015171485
reward_max: -779.9999999999998
reward_min: -800.714285714286
queue_len: 0.4905707196029777
wait_time: 2.807027649769585
delay_time: 152.59483386870883
pressure: 7.004838709677419
total_envstep_count: 107260
total_train_sample_count: 107260
total_episode_count: 865
total_duration: 25626.212774705175
[2024-12-27 03:18:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.838402501482391
avg_train_sample_per_sec: 4.838402501482391
avg_episode_per_sec: 0.03901937501195477
collect_time: 128.14146814161165
reward_mean: -794.2428571428571
reward_std: 17.592588884910306
reward_max: -772.9285714285712
reward_min: -813.2142857142854
queue_len: 0.49270648706132575
wait_time: 2.8042715349166962
delay_time: 152.82211438620644
pressure: 7.057816377171216
total_envstep_count: 107880
total_train_sample_count: 107880
total_episode_count: 870
total_duration: 25754.354242846784
[2024-12-27 03:20:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.88541007949337
avg_train_sample_per_sec: 4.88541007949337
avg_episode_per_sec: 0.03939846838301105
collect_time: 126.90848668005688
reward_mean: -809.5857142857145
reward_std: 13.455095385642352
reward_max: -794.9285714285717
reward_min: -831.7857142857144
queue_len: 0.5022243885147112
wait_time: 2.9078872740163058
delay_time: 154.31245056520794
pressure: 7.171960297766749
total_envstep_count: 108500
total_train_sample_count: 108500
total_episode_count: 875
total_duration: 25881.262729526843
[2024-12-27 03:22:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.919498788370841
avg_train_sample_per_sec: 4.919498788370841
avg_episode_per_sec: 0.0396733773255713
collect_time: 126.0290990345627
reward_mean: -797.7428571428571
reward_std: 14.646069334083181
reward_max: -785.0000000000002
reward_min: -821.8571428571427
queue_len: 0.49487770294221917
wait_time: 2.8433002481389575
delay_time: 153.7808045841619
pressure: 7.081761786600497
total_envstep_count: 109120
total_train_sample_count: 109120
total_episode_count: 880
total_duration: 26007.291828561407
[2024-12-27 03:24:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.9028766950304155
avg_train_sample_per_sec: 4.9028766950304155
avg_episode_per_sec: 0.03953932818572916
collect_time: 126.45637215972322
reward_mean: -796.5285714285716
reward_std: 15.884313915666102
reward_max: -782.3571428571433
reward_min: -816.2142857142856
queue_len: 0.4941244239631337
wait_time: 2.805583126550869
delay_time: 154.76759669076074
pressure: 7.044168734491317
total_envstep_count: 109740
total_train_sample_count: 109740
total_episode_count: 885
total_duration: 26133.74820072113
[2024-12-27 03:26:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.047480418186806
avg_train_sample_per_sec: 5.047480418186806
avg_episode_per_sec: 0.04070548724344199
collect_time: 122.83356221968683
reward_mean: -799.4857142857143
reward_std: 15.059026718692147
reward_max: -774.9285714285716
reward_min: -820.4285714285714
queue_len: 0.49595887982984754
wait_time: 2.806442750797589
delay_time: 154.15755550294455
pressure: 7.081265508684863
total_envstep_count: 110360
total_train_sample_count: 110360
total_episode_count: 890
total_duration: 26256.581762940816
[2024-12-27 03:28:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.99165664976186
avg_train_sample_per_sec: 4.99165664976186
avg_episode_per_sec: 0.04025529556259565
collect_time: 124.20726093602184
reward_mean: -795.0571428571427
reward_std: 17.479515708043884
reward_max: -775.0714285714284
reward_min: -823.2142857142853
queue_len: 0.4932116270825947
wait_time: 2.8058046791917755
delay_time: 152.46050008692558
pressure: 7.0746898263027305
total_envstep_count: 110980
total_train_sample_count: 110980
total_episode_count: 895
total_duration: 26380.789023876838
[2024-12-27 03:30:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.005204686128971
avg_train_sample_per_sec: 5.005204686128971
avg_episode_per_sec: 0.04036455392039493
collect_time: 123.87105800452457
reward_mean: -810.6857142857143
reward_std: 50.9337625084316
reward_max: -754.2857142857142
reward_min: -877.5714285714288
queue_len: 0.5029067706487063
wait_time: 2.8239010989010986
delay_time: 153.0776323771882
pressure: 7.142183622828784
total_envstep_count: 111600
total_train_sample_count: 111600
total_episode_count: 900
total_duration: 26504.660081881364
[2024-12-27 03:32:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.992329415479543
avg_train_sample_per_sec: 4.992329415479543
avg_episode_per_sec: 0.04026072109257696
collect_time: 124.19052278032525
reward_mean: -801.8000000000002
reward_std: 11.845898282631397
reward_max: -789.1428571428573
reward_min: -821.2142857142859
queue_len: 0.49739454094292823
wait_time: 2.855414746543779
delay_time: 154.09571841293263
pressure: 7.068734491315136
total_envstep_count: 112220
total_train_sample_count: 112220
total_episode_count: 905
total_duration: 26628.85060466169
[2024-12-27 03:35:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.836537781990958
avg_train_sample_per_sec: 4.836537781990958
avg_episode_per_sec: 0.03900433695153998
collect_time: 128.19087288196008
reward_mean: -794.3571428571429
reward_std: 6.510117714224686
reward_max: -787.9285714285716
reward_min: -806.5000000000002
queue_len: 0.49277738390641623
wait_time: 2.8345356256646577
delay_time: 153.52392262316283
pressure: 7.07394540942928
total_envstep_count: 112840
total_train_sample_count: 112840
total_episode_count: 910
total_duration: 26757.04147754365
[2024-12-27 03:37:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.103358300310131
avg_train_sample_per_sec: 5.103358300310131
avg_episode_per_sec: 0.0411561153250817
collect_time: 121.48862837287413
reward_mean: -835.7714285714285
reward_std: 89.56776479178161
reward_max: -773.4999999999997
reward_min: -1013.9285714285713
queue_len: 0.5184686281460475
wait_time: 2.797828784119106
delay_time: 160.58406417680143
pressure: 7.396401985111662
total_envstep_count: 113460
total_train_sample_count: 113460
total_episode_count: 915
total_duration: 26878.530105916525
[2024-12-27 03:39:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.004245996059511
avg_train_sample_per_sec: 5.004245996059511
avg_episode_per_sec: 0.04035682254886703
collect_time: 123.89478864312545
reward_mean: -795.0000000000002
reward_std: 10.754970374440894
reward_max: -775.2857142857146
reward_min: -805.357142857143
queue_len: 0.4931761786600498
wait_time: 2.840597305919886
delay_time: 153.0844487643422
pressure: 7.0807692307692305
total_envstep_count: 114080
total_train_sample_count: 114080
total_episode_count: 920
total_duration: 27002.424894559652
[2024-12-27 03:41:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.995388819915763
avg_train_sample_per_sec: 4.995388819915763
avg_episode_per_sec: 0.040285393708998085
collect_time: 124.1144628278315
reward_mean: -787.5714285714284
reward_std: 17.901202787089353
reward_max: -769.4999999999997
reward_min: -817.8571428571429
queue_len: 0.4885678837291739
wait_time: 2.821224742998937
delay_time: 149.28819669617488
pressure: 6.971091811414392
total_envstep_count: 114700
total_train_sample_count: 114700
total_episode_count: 925
total_duration: 27126.539357387483
[2024-12-27 03:43:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.022144944833344
avg_train_sample_per_sec: 5.022144944833344
avg_episode_per_sec: 0.040501168909946324
collect_time: 123.4532270196304
reward_mean: -855.2999999999998
reward_std: 87.93168034424943
reward_max: -790.0714285714284
reward_min: -1029.2142857142856
queue_len: 0.5305831265508685
wait_time: 2.9170329670329678
delay_time: 160.8116097562844
pressure: 7.55272952853598
total_envstep_count: 115320
total_train_sample_count: 115320
total_episode_count: 930
total_duration: 27249.99258440711
[2024-12-27 03:45:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.702237055698962
avg_train_sample_per_sec: 4.702237055698962
avg_episode_per_sec: 0.03792126657821744
collect_time: 131.85213604843244
reward_mean: -803.8714285714284
reward_std: 9.749034489085833
reward_max: -789.4285714285714
reward_min: -814.9285714285709
queue_len: 0.4986795462601914
wait_time: 2.884526763559022
delay_time: 153.01927366678106
pressure: 7.13287841191067
total_envstep_count: 115940
total_train_sample_count: 115940
total_episode_count: 935
total_duration: 27381.844720455545
[2024-12-27 03:47:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.94597339120283
avg_train_sample_per_sec: 4.94597339120283
avg_episode_per_sec: 0.03988688218711959
collect_time: 125.3544956595935
reward_mean: -778.9000000000002
reward_std: 26.03775124306863
reward_max: -758.5000000000002
reward_min: -828.4285714285717
queue_len: 0.48318858560794065
wait_time: 2.8109801488833748
delay_time: 149.52647104826139
pressure: 6.9035980148883365
total_envstep_count: 116560
total_train_sample_count: 116560
total_episode_count: 940
total_duration: 27507.19921611514
[2024-12-27 03:49:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.037118501914599
avg_train_sample_per_sec: 5.037118501914599
avg_episode_per_sec: 0.04062192340253709
collect_time: 123.08624459883943
reward_mean: -780.1285714285715
reward_std: 16.367862987436908
reward_max: -749.2142857142859
reward_min: -797.3571428571429
queue_len: 0.48395072669266226
wait_time: 2.82902339595888
delay_time: 151.53606663636702
pressure: 6.896526054590571
total_envstep_count: 117180
total_train_sample_count: 117180
total_episode_count: 945
total_duration: 27630.285460713978
[2024-12-27 03:51:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.162147514950856
avg_train_sample_per_sec: 5.162147514950856
avg_episode_per_sec: 0.04163022189476497
collect_time: 120.10505283011123
reward_mean: -770.2285714285714
reward_std: 11.677066307554519
reward_max: -760.857142857143
reward_min: -790.8571428571432
queue_len: 0.47780928748670676
wait_time: 2.754333569656151
delay_time: 150.6313249621132
pressure: 6.850868486352357
total_envstep_count: 117800
total_train_sample_count: 117800
total_episode_count: 950
total_duration: 27750.39051354409
[2024-12-27 03:53:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.192949222756036
avg_train_sample_per_sec: 5.192949222756036
avg_episode_per_sec: 0.041878622764161585
collect_time: 119.39265596572683
reward_mean: -782.8571428571429
reward_std: 5.302098159970215
reward_max: -775.8571428571428
reward_min: -790.4285714285716
queue_len: 0.4856433888691953
wait_time: 2.7587468982630274
delay_time: 153.80337253843794
pressure: 6.989826302729528
total_envstep_count: 118420
total_train_sample_count: 118420
total_episode_count: 955
total_duration: 27869.783169509818
[2024-12-27 03:55:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.38018351487991
avg_train_sample_per_sec: 5.38018351487991
avg_episode_per_sec: 0.0433885767329025
collect_time: 115.23770486364886
reward_mean: -780.6285714285714
reward_std: 13.627807705465413
reward_max: -764.5714285714287
reward_min: -798.7142857142856
queue_len: 0.4842609003899326
wait_time: 2.8111042183622823
delay_time: 152.59035184296505
pressure: 6.947146401985113
total_envstep_count: 119040
total_train_sample_count: 119040
total_episode_count: 960
total_duration: 27985.020874373466
[2024-12-27 03:57:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.286206524843241
avg_train_sample_per_sec: 5.286206524843241
avg_episode_per_sec: 0.042630697780993876
collect_time: 117.2863748486228
reward_mean: -794.4571428571428
reward_std: 24.25420645191765
reward_max: -768.9285714285717
reward_min: -839.3571428571429
queue_len: 0.4928394186458703
wait_time: 2.8137539879475364
delay_time: 152.94857436870979
pressure: 7.044168734491317
total_envstep_count: 119660
total_train_sample_count: 119660
total_episode_count: 965
total_duration: 28102.30724922209
[2024-12-27 03:59:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.477401232563628
avg_train_sample_per_sec: 5.477401232563628
avg_episode_per_sec: 0.04417259058519055
collect_time: 113.19236507890747
reward_mean: -786.7714285714285
reward_std: 7.825964112217343
reward_max: -775.5714285714286
reward_min: -798.2857142857142
queue_len: 0.48807160581354125
wait_time: 2.816518964906062
delay_time: 151.79595345218667
pressure: 6.923573200992555
total_envstep_count: 120280
total_train_sample_count: 120280
total_episode_count: 970
total_duration: 28215.499614300996
[2024-12-27 04:01:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4283646040610645
avg_train_sample_per_sec: 5.4283646040610645
avg_episode_per_sec: 0.04377713390371826
collect_time: 114.21487781719121
reward_mean: -794.157142857143
reward_std: 22.066661528659164
reward_max: -763.5714285714287
reward_min: -830.8571428571429
queue_len: 0.492653314427508
wait_time: 2.823865650478554
delay_time: 152.9259964594516
pressure: 7.03362282878412
total_envstep_count: 120900
total_train_sample_count: 120900
total_episode_count: 975
total_duration: 28329.714492118186
[2024-12-27 04:03:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.47918511705345
avg_train_sample_per_sec: 5.47918511705345
avg_episode_per_sec: 0.044186976750431047
collect_time: 113.15551249953359
reward_mean: -776.2428571428572
reward_std: 11.069778678907664
reward_max: -758.357142857143
reward_min: -790.3571428571428
queue_len: 0.4815402339595888
wait_time: 2.741527827011698
delay_time: 148.37228797417728
pressure: 6.901861042183623
total_envstep_count: 121520
total_train_sample_count: 121520
total_episode_count: 980
total_duration: 28442.87000461772
[2024-12-27 04:05:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7405537245264435
avg_train_sample_per_sec: 5.7405537245264435
avg_episode_per_sec: 0.0462947881010197
collect_time: 108.00351843256128
reward_mean: -779.4857142857143
reward_std: 13.547979742457759
reward_max: -759.9999999999997
reward_min: -801.0000000000003
queue_len: 0.4835519319390286
wait_time: 2.6759127968805387
delay_time: 152.71558397023307
pressure: 6.950372208436724
total_envstep_count: 122140
total_train_sample_count: 122140
total_episode_count: 985
total_duration: 28550.87352305028
[2024-12-27 04:07:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.330497789202094
avg_train_sample_per_sec: 5.330497789202094
avg_episode_per_sec: 0.04298788539679108
collect_time: 116.31183887852356
reward_mean: -832.7571428571428
reward_std: 73.1165214864993
reward_max: -786.0000000000005
reward_min: -978.2142857142857
queue_len: 0.5165987238567883
wait_time: 2.8562034739454094
delay_time: 159.06862516852212
pressure: 7.342803970223325
total_envstep_count: 122760
total_train_sample_count: 122760
total_episode_count: 990
total_duration: 28667.1853619288
[2024-12-27 04:09:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4194018506878665
avg_train_sample_per_sec: 5.4194018506878665
avg_episode_per_sec: 0.043704853634579564
collect_time: 114.40376947158947
reward_mean: -772.0142857142855
reward_std: 12.07387126595843
reward_max: -750.5
reward_min: -786.9999999999997
queue_len: 0.47891705069124413
wait_time: 2.70969514356611
delay_time: 150.82052744108302
pressure: 6.877171215880894
total_envstep_count: 123380
total_train_sample_count: 123380
total_episode_count: 995
total_duration: 28781.58913140039
[2024-12-27 04:10:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.425280358340631
avg_train_sample_per_sec: 5.425280358340631
avg_episode_per_sec: 0.043752260954359926
collect_time: 114.2798084244318
reward_mean: -787.8428571428569
reward_std: 11.56140659474359
reward_max: -776.0714285714284
reward_min: -807.4285714285712
queue_len: 0.48873626373626367
wait_time: 2.775124069478907
delay_time: 152.15328887297136
pressure: 6.9942928039702235
total_envstep_count: 124000
total_train_sample_count: 124000
total_episode_count: 1000
total_duration: 28895.86893982482
[2024-12-27 04:12:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.293229101517947
avg_train_sample_per_sec: 5.293229101517947
avg_episode_per_sec: 0.04268733146385441
collect_time: 117.13076991551371
reward_mean: -784.7
reward_std: 5.771923599703679
reward_max: -776.6428571428573
reward_min: -794.1428571428571
queue_len: 0.48678660049627787
wait_time: 2.7805742644452325
delay_time: 152.3586199054996
pressure: 6.942679900744416
total_envstep_count: 124620
total_train_sample_count: 124620
total_episode_count: 1005
total_duration: 29012.999709740336
[2024-12-27 04:14:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.27080337556698
avg_train_sample_per_sec: 5.27080337556698
avg_episode_per_sec: 0.042506478835217576
collect_time: 117.62912706515193
reward_mean: -806.7142857142856
reward_std: 7.830213592103184
reward_max: -796.0
reward_min: -815.5714285714283
queue_len: 0.5004431052818148
wait_time: 2.86851293867423
delay_time: 152.97908375838892
pressure: 7.1378411910669985
total_envstep_count: 125240
total_train_sample_count: 125240
total_episode_count: 1010
total_duration: 29130.62883680549
[2024-12-27 04:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.266538174200513
avg_train_sample_per_sec: 5.266538174200513
avg_episode_per_sec: 0.04247208205000414
collect_time: 117.72439114506544
reward_mean: -790.8857142857144
reward_std: 23.455846492801868
reward_max: -753.3571428571425
reward_min: -818.9285714285716
queue_len: 0.4906238922367955
wait_time: 2.851001417936902
delay_time: 153.83072193941436
pressure: 7.003598014888337
total_envstep_count: 125860
total_train_sample_count: 125860
total_episode_count: 1015
total_duration: 29248.353227950553
[2024-12-27 04:18:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.204826427937908
avg_train_sample_per_sec: 5.204826427937908
avg_episode_per_sec: 0.04197440667691862
collect_time: 119.12020671276002
reward_mean: -787.1000000000001
reward_std: 26.342237364881495
reward_max: -752.8571428571431
reward_min: -831.4285714285719
queue_len: 0.4882754342431762
wait_time: 2.836237149946828
delay_time: 142.31201630385107
pressure: 6.929900744416874
total_envstep_count: 126480
total_train_sample_count: 126480
total_episode_count: 1020
total_duration: 29367.473434663312
[2024-12-27 04:20:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.528256808840226
avg_train_sample_per_sec: 5.528256808840226
avg_episode_per_sec: 0.044582716200324404
collect_time: 112.15108513203639
reward_mean: -803.8999999999999
reward_std: 15.239154725072364
reward_max: -783.9999999999997
reward_min: -830.2857142857142
queue_len: 0.49869727047146395
wait_time: 2.8125753278979087
delay_time: 153.33905971192064
pressure: 7.157071960297766
total_envstep_count: 127100
total_train_sample_count: 127100
total_episode_count: 1025
total_duration: 29479.62451979535
[2024-12-27 04:22:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.447914444048008
avg_train_sample_per_sec: 5.447914444048008
avg_episode_per_sec: 0.04393479390361297
collect_time: 113.80501774901524
reward_mean: -800.4142857142858
reward_std: 16.844511005677997
reward_max: -771.5714285714288
reward_min: -822.5714285714287
queue_len: 0.4965349166962071
wait_time: 2.826488833746899
delay_time: 153.845960801339
pressure: 7.092803970223325
total_envstep_count: 127720
total_train_sample_count: 127720
total_episode_count: 1030
total_duration: 29593.429537544365
[2024-12-27 04:24:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.50165007964279
avg_train_sample_per_sec: 5.50165007964279
avg_episode_per_sec: 0.04436814580357089
collect_time: 112.69346305649727
reward_mean: -793.1000000000001
reward_std: 10.396879437639774
reward_max: -775.7857142857146
reward_min: -804.1428571428575
queue_len: 0.4919975186104219
wait_time: 2.79269762495569
delay_time: 152.37312797802366
pressure: 7.104218362282879
total_envstep_count: 128340
total_train_sample_count: 128340
total_episode_count: 1035
total_duration: 29706.123000600863
[2024-12-27 04:26:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.408466396450565
avg_train_sample_per_sec: 5.408466396450565
avg_episode_per_sec: 0.04361666448750455
collect_time: 114.63508406133204
reward_mean: -781.6857142857143
reward_std: 20.46074389694393
reward_max: -758.2857142857146
reward_min: -813.0000000000002
queue_len: 0.48491669620701894
wait_time: 2.7387096774193553
delay_time: 151.5233919903765
pressure: 6.94937965260546
total_envstep_count: 128960
total_train_sample_count: 128960
total_episode_count: 1040
total_duration: 29820.758084662193
[2024-12-27 04:28:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.321173413236542
avg_train_sample_per_sec: 5.321173413236542
avg_episode_per_sec: 0.042912688816423725
collect_time: 116.51565394537522
reward_mean: -800.5999999999997
reward_std: 18.676494011763207
reward_max: -771.7142857142854
reward_min: -819.7857142857139
queue_len: 0.49665012406947867
wait_time: 2.843840836582772
delay_time: 153.04064968058233
pressure: 7.11712158808933
total_envstep_count: 129580
total_train_sample_count: 129580
total_episode_count: 1045
total_duration: 29937.273738607568
[2024-12-27 04:30:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4182313508767175
avg_train_sample_per_sec: 5.4182313508767175
avg_episode_per_sec: 0.043695414119973526
collect_time: 114.42848410296813
reward_mean: -789.8
reward_std: 9.756463059355656
reward_max: -782.1428571428571
reward_min: -808.5714285714286
queue_len: 0.48995037220843674
wait_time: 2.799202410492733
delay_time: 151.2568659882995
pressure: 7.04528535980149
total_envstep_count: 130200
total_train_sample_count: 130200
total_episode_count: 1050
total_duration: 30051.702222710537
[2024-12-27 04:32:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.370212155998963
avg_train_sample_per_sec: 5.370212155998963
avg_episode_per_sec: 0.04330816254837873
collect_time: 115.45167713856699
reward_mean: -793.5142857142857
reward_std: 8.694051449827345
reward_max: -779.9999999999999
reward_min: -802.4285714285713
queue_len: 0.4922545196738744
wait_time: 2.8552020560085074
delay_time: 152.11831334218977
pressure: 7.062531017369726
total_envstep_count: 130820
total_train_sample_count: 130820
total_episode_count: 1055
total_duration: 30167.153899849105
[2024-12-27 04:34:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.080935813947653
avg_train_sample_per_sec: 5.080935813947653
avg_episode_per_sec: 0.04097528882215849
collect_time: 122.02476526037604
reward_mean: -795.8714285714284
reward_std: 7.923537655592411
reward_max: -785.6428571428569
reward_min: -805.9999999999998
queue_len: 0.49371676710386386
wait_time: 2.8102889046437425
delay_time: 152.6132051971537
pressure: 7.080024813895781
total_envstep_count: 131440
total_train_sample_count: 131440
total_episode_count: 1060
total_duration: 30289.17866510948
[2024-12-27 04:36:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.166447786661092
avg_train_sample_per_sec: 5.166447786661092
avg_episode_per_sec: 0.041664901505331385
collect_time: 120.00508388001846
reward_mean: -788.3571428571429
reward_std: 16.119135541717007
reward_max: -768.6428571428572
reward_min: -810.2857142857146
queue_len: 0.48905529953917054
wait_time: 2.785209145693017
delay_time: 152.9591703240914
pressure: 6.984615384615384
total_envstep_count: 132060
total_train_sample_count: 132060
total_episode_count: 1065
total_duration: 30409.1837489895
[2024-12-27 04:38:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.200228215896761
avg_train_sample_per_sec: 5.200228215896761
avg_episode_per_sec: 0.04193732432174807
collect_time: 119.22553669946642
reward_mean: -785.6428571428573
reward_std: 12.285797341911959
reward_max: -763.5000000000002
reward_min: -800.9285714285718
queue_len: 0.4873714994682737
wait_time: 2.792786246012052
delay_time: 152.88770925084887
pressure: 6.985111662531017
total_envstep_count: 132680
total_train_sample_count: 132680
total_episode_count: 1070
total_duration: 30528.409285688966
[2024-12-27 04:40:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.991600333975726
avg_train_sample_per_sec: 4.991600333975726
avg_episode_per_sec: 0.040254841403030046
collect_time: 124.20866225605454
reward_mean: -773.8285714285715
reward_std: 8.927211324978158
reward_max: -764.0000000000003
reward_min: -789.5000000000005
queue_len: 0.4800425381070543
wait_time: 2.744390287132223
delay_time: 151.47222945924926
pressure: 6.853225806451613
total_envstep_count: 133300
total_train_sample_count: 133300
total_episode_count: 1075
total_duration: 30652.61794794502
[2024-12-27 04:42:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.126605352121899
avg_train_sample_per_sec: 5.126605352121899
avg_episode_per_sec: 0.04134359154937015
collect_time: 120.93772729031743
reward_mean: -784.9857142857147
reward_std: 6.923105354904201
reward_max: -774.4285714285716
reward_min: -792.3571428571432
queue_len: 0.48696384260900405
wait_time: 2.768681318681319
delay_time: 151.3745472694841
pressure: 6.985359801488833
total_envstep_count: 133920
total_train_sample_count: 133920
total_episode_count: 1080
total_duration: 30773.555675235337
[2024-12-27 04:44:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.897769397165048
avg_train_sample_per_sec: 4.897769397165048
avg_episode_per_sec: 0.039498140299718126
collect_time: 126.58823838436976
reward_mean: -776.3000000000001
reward_std: 12.177128108860007
reward_max: -760.7142857142863
reward_min: -792.1428571428571
queue_len: 0.48157568238213405
wait_time: 2.7328075150655793
delay_time: 151.93733241425292
pressure: 6.883250620347394
total_envstep_count: 134540
total_train_sample_count: 134540
total_episode_count: 1085
total_duration: 30900.143913619708
[2024-12-27 04:46:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.045750983176975
avg_train_sample_per_sec: 5.045750983176975
avg_episode_per_sec: 0.040691540186911096
collect_time: 122.87566351711376
reward_mean: -778.5428571428572
reward_std: 17.266435530194663
reward_max: -754.5000000000001
reward_min: -802.7142857142857
queue_len: 0.4829670329670329
wait_time: 2.7858294930875576
delay_time: 150.89090769058143
pressure: 6.947146401985111
total_envstep_count: 135160
total_train_sample_count: 135160
total_episode_count: 1090
total_duration: 31023.01957713682
[2024-12-27 04:48:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1229823915779304
avg_train_sample_per_sec: 5.1229823915779304
avg_episode_per_sec: 0.04131437412562847
collect_time: 121.02325415353101
reward_mean: -754.0857142857143
reward_std: 11.796609682446855
reward_max: -738.0714285714289
reward_min: -770.7142857142857
queue_len: 0.46779510811768876
wait_time: 2.6508064516129037
delay_time: 149.6930784644892
pressure: 6.704342431761786
total_envstep_count: 135780
total_train_sample_count: 135780
total_episode_count: 1095
total_duration: 31144.04283129035
[2024-12-27 04:50:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.093710099203404
avg_train_sample_per_sec: 5.093710099203404
avg_episode_per_sec: 0.041078307251640356
collect_time: 121.71874486868828
reward_mean: -777.7571428571428
reward_std: 10.902405651029062
reward_max: -758.4285714285716
reward_min: -789.7142857142854
queue_len: 0.4824796171570365
wait_time: 2.685395249911379
delay_time: 152.82892041761662
pressure: 6.90545905707196
total_envstep_count: 136400
total_train_sample_count: 136400
total_episode_count: 1100
total_duration: 31265.76157615904
[2024-12-27 04:52:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.863421719132967
avg_train_sample_per_sec: 4.863421719132967
avg_episode_per_sec: 0.03922114289623361
collect_time: 127.48226162680609
reward_mean: -764.6285714285716
reward_std: 12.355235195442255
reward_max: -742.8571428571428
reward_min: -777.857142857143
queue_len: 0.47433534207727757
wait_time: 2.6910226869904292
delay_time: 151.27623869688122
pressure: 6.796029776674938
total_envstep_count: 137020
total_train_sample_count: 137020
total_episode_count: 1105
total_duration: 31393.243837785845
[2024-12-27 04:54:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.074257969868295
avg_train_sample_per_sec: 5.074257969868295
avg_episode_per_sec: 0.040921435240873355
collect_time: 122.18535275140778
reward_mean: -771.2999999999998
reward_std: 26.49348784058417
reward_max: -755.8571428571427
reward_min: -823.9285714285712
queue_len: 0.4784739454094292
wait_time: 2.662832328961361
delay_time: 151.50520477500635
pressure: 6.861786600496278
total_envstep_count: 137640
total_train_sample_count: 137640
total_episode_count: 1110
total_duration: 31515.429190537252
[2024-12-27 04:56:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.985634045760945
avg_train_sample_per_sec: 4.985634045760945
avg_episode_per_sec: 0.040206726175491495
collect_time: 124.35730226271971
reward_mean: -768.9999999999999
reward_std: 9.822921964383537
reward_max: -754.2142857142856
reward_min: -782.3571428571427
queue_len: 0.4770471464019851
wait_time: 2.699512584190004
delay_time: 151.77248311376408
pressure: 6.865508684863523
total_envstep_count: 138260
total_train_sample_count: 138260
total_episode_count: 1115
total_duration: 31639.786492799973
[2024-12-27 04:59:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.031985533163857
avg_train_sample_per_sec: 5.031985533163857
avg_episode_per_sec: 0.040580528493256905
collect_time: 123.21180097077416
reward_mean: -767.0714285714287
reward_std: 20.47557031176033
reward_max: -744.5714285714283
reward_min: -804.8571428571429
queue_len: 0.4758507621410847
wait_time: 2.6478021978021973
delay_time: 151.17792291480137
pressure: 6.8352357320099255
total_envstep_count: 138880
total_train_sample_count: 138880
total_episode_count: 1120
total_duration: 31762.998293770746
[2024-12-27 05:01:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.975727095537306
avg_train_sample_per_sec: 4.975727095537306
avg_episode_per_sec: 0.04012683141562343
collect_time: 124.60490458893406
reward_mean: -763.6571428571426
reward_std: 3.6087761507362437
reward_max: -761.142857142857
reward_min: -770.5714285714284
queue_len: 0.47373271889400914
wait_time: 2.6738922367954627
delay_time: 150.73336810084018
pressure: 6.819230769230769
total_envstep_count: 139500
total_train_sample_count: 139500
total_episode_count: 1125
total_duration: 31887.60319835968
[2024-12-27 05:03:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.126602332558443
avg_train_sample_per_sec: 5.126602332558443
avg_episode_per_sec: 0.04134356719805196
collect_time: 120.93779852251336
reward_mean: -752.9285714285714
reward_std: 11.724995104650683
reward_max: -731.6428571428571
reward_min: -765.357142857143
queue_len: 0.4670772775611486
wait_time: 2.6324530308401277
delay_time: 150.04300431752716
pressure: 6.759305210918114
total_envstep_count: 140120
total_train_sample_count: 140120
total_episode_count: 1130
total_duration: 32008.540996882195
[2024-12-27 05:05:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.278900361087274
avg_train_sample_per_sec: 5.278900361087274
avg_episode_per_sec: 0.04257177710554253
collect_time: 117.44870287195592
reward_mean: -768.9857142857143
reward_std: 10.560844122106397
reward_max: -751.7857142857142
reward_min: -779.2142857142857
queue_len: 0.4770382842963488
wait_time: 2.6996100673520025
delay_time: 151.09537253085622
pressure: 6.893424317617866
total_envstep_count: 140740
total_train_sample_count: 140740
total_episode_count: 1135
total_duration: 32125.98969975415
[2024-12-27 05:07:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.147140070089638
avg_train_sample_per_sec: 5.147140070089638
avg_episode_per_sec: 0.041509194113626115
collect_time: 120.45524146561696
reward_mean: -775.0571428571429
reward_std: 7.3866122692563465
reward_max: -760.9999999999998
reward_min: -782.1428571428573
queue_len: 0.480804679191776
wait_time: 2.7167139312300597
delay_time: 151.744727870576
pressure: 6.957444168734492
total_envstep_count: 141360
total_train_sample_count: 141360
total_episode_count: 1140
total_duration: 32246.44494121977
[2024-12-27 05:09:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.358616467762185
avg_train_sample_per_sec: 5.358616467762185
avg_episode_per_sec: 0.04321464893356601
collect_time: 115.70150685908644
reward_mean: -767.342857142857
reward_std: 11.528173121106597
reward_max: -758.5000000000001
reward_min: -789.7857142857143
queue_len: 0.4760191421481744
wait_time: 2.671065225097484
delay_time: 150.7764896875201
pressure: 6.854962779156327
total_envstep_count: 141980
total_train_sample_count: 141980
total_episode_count: 1145
total_duration: 32362.146448078856
[2024-12-27 05:10:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.640259501566327
avg_train_sample_per_sec: 5.640259501566327
avg_episode_per_sec: 0.04548596372230909
collect_time: 109.92402030931787
reward_mean: -764.8428571428569
reward_std: 14.098805854774135
reward_max: -744.1428571428572
reward_min: -784.5000000000001
queue_len: 0.474468273661822
wait_time: 2.6813895781637713
delay_time: 150.0188527521002
pressure: 6.843796526054591
total_envstep_count: 142600
total_train_sample_count: 142600
total_episode_count: 1150
total_duration: 32472.070468388174
[2024-12-27 05:12:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.273636033401162
avg_train_sample_per_sec: 5.273636033401162
avg_episode_per_sec: 0.04252932285000936
collect_time: 117.56594426941126
reward_mean: -764.7142857142856
reward_std: 18.29179586367521
reward_max: -733.2857142857142
reward_min: -788.142857142857
queue_len: 0.4743885147110952
wait_time: 2.7199308755760367
delay_time: 148.9705786836833
pressure: 6.850868486352357
total_envstep_count: 143220
total_train_sample_count: 143220
total_episode_count: 1155
total_duration: 32589.636412657586
[2024-12-27 05:14:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.374795637338296
avg_train_sample_per_sec: 5.374795637338296
avg_episode_per_sec: 0.0433451261075669
collect_time: 115.35322304961835
reward_mean: -768.5
reward_std: 8.452508382674537
reward_max: -757.2142857142852
reward_min: -779.785714285714
queue_len: 0.47673697270471455
wait_time: 2.735590216235378
delay_time: 150.43141505339835
pressure: 6.858064516129032
total_envstep_count: 143840
total_train_sample_count: 143840
total_episode_count: 1160
total_duration: 32704.989635707203
[2024-12-27 05:16:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.474762922272757
avg_train_sample_per_sec: 5.474762922272757
avg_episode_per_sec: 0.044151313889296426
collect_time: 113.24691293529425
reward_mean: -777.2142857142856
reward_std: 8.05199937143263
reward_max: -768.7857142857139
reward_min: -790.9285714285711
queue_len: 0.4821428571428571
wait_time: 2.7545728465083306
delay_time: 151.04677988457019
pressure: 6.930769230769231
total_envstep_count: 144460
total_train_sample_count: 144460
total_episode_count: 1165
total_duration: 32818.2365486425
[2024-12-27 05:18:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.108879178589493
avg_train_sample_per_sec: 5.108879178589493
avg_episode_per_sec: 0.041200638537012044
collect_time: 121.35734244769814
reward_mean: -771.7428571428571
reward_std: 24.01107737555101
reward_max: -746.2142857142854
reward_min: -809.8571428571428
queue_len: 0.47874867068415455
wait_time: 2.7251329315845454
delay_time: 150.80081730793532
pressure: 6.919602977667493
total_envstep_count: 145080
total_train_sample_count: 145080
total_episode_count: 1170
total_duration: 32939.5938910902
[2024-12-27 05:20:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.523077114482024
avg_train_sample_per_sec: 5.523077114482024
avg_episode_per_sec: 0.04454094447162922
collect_time: 112.25626351917161
reward_mean: -778.9428571428573
reward_std: 16.03996284793901
reward_max: -756.7142857142858
reward_min: -802.8571428571429
queue_len: 0.4832151719248493
wait_time: 2.7846331088266565
delay_time: 151.1220940394316
pressure: 6.9667493796526045
total_envstep_count: 145700
total_train_sample_count: 145700
total_episode_count: 1175
total_duration: 33051.85015460937
[2024-12-27 05:22:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.256366009373271
avg_train_sample_per_sec: 5.256366009373271
avg_episode_per_sec: 0.04239004846268767
collect_time: 117.9522124019526
reward_mean: -779.9714285714286
reward_std: 23.522529365591176
reward_max: -755.6428571428573
reward_min: -823.7857142857143
queue_len: 0.48385324353066295
wait_time: 2.725159517901453
delay_time: 148.95919523443496
pressure: 6.9461538461538455
total_envstep_count: 146320
total_train_sample_count: 146320
total_episode_count: 1180
total_duration: 33169.80236701132
[2024-12-27 05:24:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.258346209285479
avg_train_sample_per_sec: 5.258346209285479
avg_episode_per_sec: 0.042406017816818374
collect_time: 117.90779369094597
reward_mean: -760.3714285714285
reward_std: 13.906348572225655
reward_max: -736.357142857143
reward_min: -778.4999999999999
queue_len: 0.4716944345976605
wait_time: 2.7590482098546616
delay_time: 141.89409901429588
pressure: 6.766253101736973
total_envstep_count: 146940
total_train_sample_count: 146940
total_episode_count: 1185
total_duration: 33287.71016070226
[2024-12-27 05:26:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.465227443782602
avg_train_sample_per_sec: 5.465227443782602
avg_episode_per_sec: 0.04407441486921453
collect_time: 113.4445009613149
reward_mean: -773.842857142857
reward_std: 16.91047254315066
reward_max: -755.9285714285716
reward_min: -805.7142857142857
queue_len: 0.48005140021269044
wait_time: 2.710944700460829
delay_time: 150.6045867640344
pressure: 6.95
total_envstep_count: 147560
total_train_sample_count: 147560
total_episode_count: 1190
total_duration: 33401.154661663575
[2024-12-27 05:28:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.375075408255159
avg_train_sample_per_sec: 5.375075408255159
avg_episode_per_sec: 0.04334738232463838
collect_time: 115.34721895208955
reward_mean: -775.842857142857
reward_std: 21.11578382467979
reward_max: -745.8571428571431
reward_min: -811.4999999999999
queue_len: 0.48129209500177234
wait_time: 2.801905352711804
delay_time: 148.43637612498378
pressure: 6.944416873449131
total_envstep_count: 148180
total_train_sample_count: 148180
total_episode_count: 1195
total_duration: 33516.501880615666
[2024-12-27 05:30:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.378432170420936
avg_train_sample_per_sec: 5.378432170420936
avg_episode_per_sec: 0.04337445298726561
collect_time: 115.27522898024695
reward_mean: -782.0142857142855
reward_std: 14.749223431649854
reward_max: -759.9285714285716
reward_min: -802.928571428571
queue_len: 0.4851205246366536
wait_time: 2.7859447004608286
delay_time: 150.4853140762198
pressure: 7.015508684863524
total_envstep_count: 148800
total_train_sample_count: 148800
total_episode_count: 1200
total_duration: 33631.77710959591
[2024-12-27 05:32:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.398695544279061
avg_train_sample_per_sec: 5.398695544279061
avg_episode_per_sec: 0.04353786729257307
collect_time: 114.84255685746297
reward_mean: -759.4857142857143
reward_std: 18.52920474740968
reward_max: -725.7857142857141
reward_min: -779.0714285714284
queue_len: 0.4711449840482098
wait_time: 2.720985466146756
delay_time: 148.45400595769723
pressure: 6.873076923076923
total_envstep_count: 149420
total_train_sample_count: 149420
total_episode_count: 1205
total_duration: 33746.61966645337
[2024-12-27 05:34:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.145896617142078
avg_train_sample_per_sec: 5.145896617142078
avg_episode_per_sec: 0.041499166267274824
collect_time: 120.48434823479505
reward_mean: -770.1714285714285
reward_std: 13.825412862418506
reward_max: -748.9285714285712
reward_min: -790.8571428571427
queue_len: 0.47777383906416154
wait_time: 2.725150655795818
delay_time: 150.03665992574327
pressure: 6.9035980148883365
total_envstep_count: 150040
total_train_sample_count: 150040
total_episode_count: 1210
total_duration: 33867.104014688164
[2024-12-27 05:36:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5452019891015345
avg_train_sample_per_sec: 5.5452019891015345
avg_episode_per_sec: 0.04471937087985108
collect_time: 111.80837077144163
reward_mean: -761.7857142857143
reward_std: 14.357320539056749
reward_max: -742.7142857142859
reward_min: -782.2142857142856
queue_len: 0.47257178305565406
wait_time: 2.7634704005671744
delay_time: 145.71530407820407
pressure: 6.766501240694789
total_envstep_count: 150660
total_train_sample_count: 150660
total_episode_count: 1215
total_duration: 33978.912385459604
[2024-12-27 05:38:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.378061220449407
avg_train_sample_per_sec: 5.378061220449407
avg_episode_per_sec: 0.043371461455237154
collect_time: 115.28318005055935
reward_mean: -770.4571428571429
reward_std: 11.575184575599055
reward_max: -747.7142857142856
reward_min: -779.2857142857144
queue_len: 0.4779510811768876
wait_time: 2.7320453739808577
delay_time: 149.80667073695062
pressure: 6.899503722084367
total_envstep_count: 151280
total_train_sample_count: 151280
total_episode_count: 1220
total_duration: 34094.19556551016
[2024-12-27 05:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.28261923559203
avg_train_sample_per_sec: 5.28261923559203
avg_episode_per_sec: 0.042601768028967986
collect_time: 117.366020973593
reward_mean: -775.2428571428571
reward_std: 17.428489461165576
reward_max: -753.1428571428572
reward_min: -804.4285714285714
queue_len: 0.4809198865650478
wait_time: 2.843743353420773
delay_time: 141.1515853454672
pressure: 6.8287841191067
total_envstep_count: 151900
total_train_sample_count: 151900
total_episode_count: 1225
total_duration: 34211.56158648375
[2024-12-27 05:42:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.257766188856241
avg_train_sample_per_sec: 5.257766188856241
avg_episode_per_sec: 0.042401340232711617
collect_time: 117.92080091238766
reward_mean: -788.4428571428571
reward_std: 16.695923980152273
reward_max: -763.9285714285714
reward_min: -806.8571428571428
queue_len: 0.48910847217298825
wait_time: 2.808800070896845
delay_time: 151.42342325898787
pressure: 7.054590570719602
total_envstep_count: 152520
total_train_sample_count: 152520
total_episode_count: 1230
total_duration: 34329.48238739614
[2024-12-27 05:44:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.303100523804625
avg_train_sample_per_sec: 5.303100523804625
avg_episode_per_sec: 0.04276693970810182
collect_time: 116.91273759886997
reward_mean: -789.9571428571428
reward_std: 23.517930632274854
reward_max: -760.8571428571427
reward_min: -829.4285714285714
queue_len: 0.49004785537043605
wait_time: 2.8637805742644455
delay_time: 151.58183961246553
pressure: 7.053349875930522
total_envstep_count: 153140
total_train_sample_count: 153140
total_episode_count: 1235
total_duration: 34446.39512499501
[2024-12-27 05:45:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.376184231970594
avg_train_sample_per_sec: 5.376184231970594
avg_episode_per_sec: 0.043356324451375765
collect_time: 115.32342889461292
reward_mean: -803.4857142857145
reward_std: 43.744443378909295
reward_max: -756.5000000000001
reward_min: -860.2142857142857
queue_len: 0.49844026940801145
wait_time: 2.846729883020206
delay_time: 148.44274666399406
pressure: 7.136228287841192
total_envstep_count: 153760
total_train_sample_count: 153760
total_episode_count: 1240
total_duration: 34561.71855388962
[2024-12-27 05:47:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.507947306125639
avg_train_sample_per_sec: 5.507947306125639
avg_episode_per_sec: 0.04441892988811
collect_time: 112.5646208180804
reward_mean: -780.4142857142857
reward_std: 28.356563506136442
reward_max: -754.1428571428572
reward_min: -825.4285714285712
queue_len: 0.48412796880538805
wait_time: 2.8025345622119824
delay_time: 150.45291001135143
pressure: 6.944665012406948
total_envstep_count: 154380
total_train_sample_count: 154380
total_episode_count: 1245
total_duration: 34674.2831747077
[2024-12-27 05:49:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.228244389708561
avg_train_sample_per_sec: 5.228244389708561
avg_episode_per_sec: 0.0421632612073271
collect_time: 118.58665237998962
reward_mean: -780.3285714285713
reward_std: 20.270849684677458
reward_max: -759.4285714285711
reward_min: -817.4285714285719
queue_len: 0.4840747961715703
wait_time: 2.818282523927685
delay_time: 150.5595213916068
pressure: 7.012034739454094
total_envstep_count: 155000
total_train_sample_count: 155000
total_episode_count: 1250
total_duration: 34792.86982708769
[2024-12-27 05:51:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.469830962640314
avg_train_sample_per_sec: 5.469830962640314
avg_episode_per_sec: 0.04411154002129286
collect_time: 113.34902380616218
reward_mean: -777.8857142857144
reward_std: 15.984980195068529
reward_max: -756.8571428571432
reward_min: -805.4285714285716
queue_len: 0.48255937610776334
wait_time: 2.837743707904998
delay_time: 148.54813314019935
pressure: 6.962158808933003
total_envstep_count: 155620
total_train_sample_count: 155620
total_episode_count: 1255
total_duration: 34906.218850893856
[2024-12-27 05:53:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.388452610580947
avg_train_sample_per_sec: 5.388452610580947
avg_episode_per_sec: 0.04345526298855602
collect_time: 115.06086158808321
reward_mean: -777.9571428571428
reward_std: 22.258435685907365
reward_max: -765.0
reward_min: -822.3571428571429
queue_len: 0.4826036866359448
wait_time: 2.8349610067352002
delay_time: 142.78837466080935
pressure: 6.887468982630272
total_envstep_count: 156240
total_train_sample_count: 156240
total_episode_count: 1260
total_duration: 35021.27971248194
[2024-12-27 05:55:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.330983243631757
avg_train_sample_per_sec: 5.330983243631757
avg_episode_per_sec: 0.04299180035186901
collect_time: 116.30124719312043
reward_mean: -764.3571428571429
reward_std: 15.781221079989749
reward_max: -738.0714285714286
reward_min: -781.2142857142857
queue_len: 0.47416696207018794
wait_time: 2.7708702587734844
delay_time: 143.82043508729157
pressure: 6.788213399503722
total_envstep_count: 156860
total_train_sample_count: 156860
total_episode_count: 1265
total_duration: 35137.58095967506
[2024-12-27 05:57:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.435581804833913
avg_train_sample_per_sec: 5.435581804833913
avg_episode_per_sec: 0.043835337135757366
collect_time: 114.06322676417605
reward_mean: -783.7857142857144
reward_std: 5.888764812794613
reward_max: -776.2857142857144
reward_min: -790.857142857143
queue_len: 0.4862194257355549
wait_time: 2.8542892591279694
delay_time: 150.44859840153615
pressure: 6.977047146401986
total_envstep_count: 157480
total_train_sample_count: 157480
total_episode_count: 1270
total_duration: 35251.64418643924
[2024-12-27 05:59:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.107116511827838
avg_train_sample_per_sec: 5.107116511827838
avg_episode_per_sec: 0.04118642348248256
collect_time: 121.39922763933613
reward_mean: -771.3142857142857
reward_std: 16.469675287680477
reward_max: -750.3571428571427
reward_min: -800.142857142857
queue_len: 0.47848280751506556
wait_time: 2.808259482453031
delay_time: 150.2812379056428
pressure: 6.885111662531017
total_envstep_count: 158100
total_train_sample_count: 158100
total_episode_count: 1275
total_duration: 35373.04341407857
[2024-12-27 06:01:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.337375081812467
avg_train_sample_per_sec: 5.337375081812467
avg_episode_per_sec: 0.04304334743397151
collect_time: 116.16196922579034
reward_mean: -800.0285714285712
reward_std: 34.088378533166015
reward_max: -767.2857142857139
reward_min: -850.6428571428571
queue_len: 0.49629563984402686
wait_time: 2.8534207727756105
delay_time: 152.94390938380175
pressure: 7.132754342431762
total_envstep_count: 158720
total_train_sample_count: 158720
total_episode_count: 1280
total_duration: 35489.20538330436
[2024-12-27 06:03:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.0026088792301575
avg_train_sample_per_sec: 5.0026088792301575
avg_episode_per_sec: 0.040343619993791595
collect_time: 123.9353335364908
reward_mean: -778.4428571428572
reward_std: 13.035148715715408
reward_max: -761.9285714285717
reward_min: -799.6428571428572
queue_len: 0.48290499822757893
wait_time: 2.838975540588444
delay_time: 150.01010196841625
pressure: 7.001116625310173
total_envstep_count: 159340
total_train_sample_count: 159340
total_episode_count: 1285
total_duration: 35613.140716840855
[2024-12-27 06:05:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.001298407945259
avg_train_sample_per_sec: 5.001298407945259
avg_episode_per_sec: 0.0403330516769779
collect_time: 123.96780784266814
reward_mean: -761.3142857142857
reward_std: 7.401819963732509
reward_max: -753.3571428571429
reward_min: -774.4999999999999
queue_len: 0.47227933356965623
wait_time: 2.72703828429635
delay_time: 148.5083984222835
pressure: 6.834615384615385
total_envstep_count: 159960
total_train_sample_count: 159960
total_episode_count: 1290
total_duration: 35737.10852468352
[2024-12-27 06:07:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.174228211739889
avg_train_sample_per_sec: 5.174228211739889
avg_episode_per_sec: 0.04172764686887007
collect_time: 119.82463367063558
reward_mean: -767.5142857142854
reward_std: 7.876910199165517
reward_max: -755.9999999999995
reward_min: -775.5714285714286
queue_len: 0.4761254874158098
wait_time: 2.7911999291031546
delay_time: 149.67129833843018
pressure: 6.865508684863523
total_envstep_count: 160580
total_train_sample_count: 160580
total_episode_count: 1295
total_duration: 35856.93315835416
[2024-12-27 06:09:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.117569702293861
avg_train_sample_per_sec: 5.117569702293861
avg_episode_per_sec: 0.041270723405595656
collect_time: 121.15125656658782
reward_mean: -770.1285714285711
reward_std: 9.977055309712304
reward_max: -759.8571428571428
reward_min: -787.9999999999994
queue_len: 0.47774725274725266
wait_time: 2.789888337468983
delay_time: 149.10797606558722
pressure: 6.902481389578165
total_envstep_count: 161200
total_train_sample_count: 161200
total_episode_count: 1300
total_duration: 35978.08441492075
[2024-12-27 06:11:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.933670295868893
avg_train_sample_per_sec: 4.933670295868893
avg_episode_per_sec: 0.03978766367636204
collect_time: 125.66709220904855
reward_mean: -754.3714285714289
reward_std: 5.5896040530067115
reward_max: -745.5714285714283
reward_min: -760.7857142857146
queue_len: 0.46797235023041484
wait_time: 2.7033587380361577
delay_time: 148.42213487277158
pressure: 6.806823821339951
total_envstep_count: 161820
total_train_sample_count: 161820
total_episode_count: 1305
total_duration: 36103.7515071298
[2024-12-27 06:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1298211517954835
avg_train_sample_per_sec: 5.1298211517954835
avg_episode_per_sec: 0.04136952541770551
collect_time: 120.86191343785825
reward_mean: -770.1999999999999
reward_std: 12.604453375611344
reward_max: -757.5000000000001
reward_min: -794.2142857142858
queue_len: 0.47779156327543415
wait_time: 2.799335342077277
delay_time: 146.3432622883201
pressure: 6.906947890818858
total_envstep_count: 162440
total_train_sample_count: 162440
total_episode_count: 1310
total_duration: 36224.61342056766
[2024-12-27 06:15:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.013417676423955
avg_train_sample_per_sec: 5.013417676423955
avg_episode_per_sec: 0.040430787713096404
collect_time: 123.66813220362738
reward_mean: -763.7142857142857
reward_std: 14.44518138709643
reward_max: -739.3571428571432
reward_min: -782.0714285714284
queue_len: 0.47376816731655447
wait_time: 2.733782346685572
delay_time: 149.52662436211477
pressure: 6.873573200992555
total_envstep_count: 163060
total_train_sample_count: 163060
total_episode_count: 1315
total_duration: 36348.28155277128
[2024-12-27 06:17:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.187664658468698
avg_train_sample_per_sec: 5.187664658468698
avg_episode_per_sec: 0.04183600531023144
collect_time: 119.51427873963858
reward_mean: -746.9428571428572
reward_std: 26.16148438651984
reward_max: -698.2857142857146
reward_min: -777.1428571428577
queue_len: 0.46336405529953917
wait_time: 2.8997607231478204
delay_time: 124.83259919186116
pressure: 6.515880893300249
total_envstep_count: 163680
total_train_sample_count: 163680
total_episode_count: 1320
total_duration: 36467.79583151092
[2024-12-27 06:19:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2637303299549085
avg_train_sample_per_sec: 5.2637303299549085
avg_episode_per_sec: 0.04244943814479765
collect_time: 117.78718914829194
reward_mean: -756.8285714285714
reward_std: 20.00584608435791
reward_max: -728.2857142857143
reward_min: -787.357142857143
queue_len: 0.46949663239985817
wait_time: 2.8132133995037223
delay_time: 140.06804792309734
pressure: 6.687220843672456
total_envstep_count: 164300
total_train_sample_count: 164300
total_episode_count: 1325
total_duration: 36585.583020659215
[2024-12-27 06:21:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.123835209384853
avg_train_sample_per_sec: 5.123835209384853
avg_episode_per_sec: 0.041321251688587524
collect_time: 121.0031108854562
reward_mean: -775.0428571428571
reward_std: 20.272913466203217
reward_max: -749.1428571428571
reward_min: -801.5714285714287
queue_len: 0.4807958170861396
wait_time: 2.813204537398086
delay_time: 139.07387515419055
pressure: 6.705583126550868
total_envstep_count: 164920
total_train_sample_count: 164920
total_episode_count: 1330
total_duration: 36706.58613154467
[2024-12-27 06:24:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.049283052739417
avg_train_sample_per_sec: 5.049283052739417
avg_episode_per_sec: 0.040720024618866264
collect_time: 122.78970965266599
reward_mean: -759.9428571428572
reward_std: 8.915178526718504
reward_max: -749.7857142857147
reward_min: -772.5714285714286
queue_len: 0.47142857142857153
wait_time: 2.7746543778801835
delay_time: 145.79258170243008
pressure: 6.715384615384616
total_envstep_count: 165540
total_train_sample_count: 165540
total_episode_count: 1335
total_duration: 36829.37584119733
[2024-12-27 06:26:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.083458956393821
avg_train_sample_per_sec: 5.083458956393821
avg_episode_per_sec: 0.04099563674511146
collect_time: 121.96419904604181
reward_mean: -744.8428571428569
reward_std: 22.038343209700972
reward_max: -715.0714285714283
reward_min: -771.7857142857139
queue_len: 0.4620613257710032
wait_time: 2.7274282169443453
delay_time: 138.10797894746383
pressure: 6.557692307692308
total_envstep_count: 166160
total_train_sample_count: 166160
total_episode_count: 1340
total_duration: 36951.340040243376
[2024-12-27 06:28:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.022247109435554
avg_train_sample_per_sec: 5.022247109435554
avg_episode_per_sec: 0.04050199281802866
collect_time: 123.45071568365765
reward_mean: -740.2142857142857
reward_std: 33.88675618730661
reward_max: -683.9999999999999
reward_min: -783.5714285714288
queue_len: 0.4591900035448423
wait_time: 2.8208436724565753
delay_time: 123.16915820161095
pressure: 6.313895781637717
total_envstep_count: 166780
total_train_sample_count: 166780
total_episode_count: 1345
total_duration: 37074.79075592703
[2024-12-27 06:30:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.214068921363627
avg_train_sample_per_sec: 5.214068921363627
avg_episode_per_sec: 0.0420489429142228
collect_time: 118.90905343803018
reward_mean: -732.8571428571429
reward_std: 16.105709470588774
reward_max: -701.7142857142862
reward_min: -745.7857142857143
queue_len: 0.4546260191421482
wait_time: 2.6942573555476783
delay_time: 131.51430207341483
pressure: 6.346650124069479
total_envstep_count: 167400
total_train_sample_count: 167400
total_episode_count: 1350
total_duration: 37193.69980936506
[2024-12-27 06:32:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.109328060915726
avg_train_sample_per_sec: 5.109328060915726
avg_episode_per_sec: 0.04120425855577199
collect_time: 121.34668054352329
reward_mean: -746.9142857142857
reward_std: 22.8289737136018
reward_max: -702.7142857142859
reward_min: -766.0714285714284
queue_len: 0.4633463310882666
wait_time: 2.7586671393123003
delay_time: 137.60487166466314
pressure: 6.545037220843673
total_envstep_count: 168020
total_train_sample_count: 168020
total_episode_count: 1355
total_duration: 37315.046489908585
[2024-12-27 06:34:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.0211647415126945
avg_train_sample_per_sec: 5.0211647415126945
avg_episode_per_sec: 0.04049326404445722
collect_time: 123.4773268588707
reward_mean: -738.742857142857
reward_std: 33.39258135867783
reward_max: -688.8571428571427
reward_min: -784.5714285714286
queue_len: 0.4582772066643034
wait_time: 2.75586671393123
delay_time: 124.75379824008887
pressure: 6.333002481389578
total_envstep_count: 168640
total_train_sample_count: 168640
total_episode_count: 1360
total_duration: 37438.523816767454
[2024-12-27 06:36:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.164201699537564
avg_train_sample_per_sec: 5.164201699537564
avg_episode_per_sec: 0.04164678789949648
collect_time: 120.05727817631887
reward_mean: -746.9428571428571
reward_std: 25.417268756111675
reward_max: -706.3571428571428
reward_min: -786.2142857142858
queue_len: 0.46336405529953917
wait_time: 2.811697979439915
delay_time: 124.98171444774748
pressure: 6.396774193548387
total_envstep_count: 169260
total_train_sample_count: 169260
total_episode_count: 1365
total_duration: 37558.58109494377
[2024-12-27 06:38:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.022958188425065
avg_train_sample_per_sec: 5.022958188425065
avg_episode_per_sec: 0.04050772732600859
collect_time: 123.43323928690701
reward_mean: -722.5571428571429
reward_std: 16.21635606668871
reward_max: -703.0714285714284
reward_min: -747.0714285714287
queue_len: 0.44823644097837645
wait_time: 2.827702942219071
delay_time: 111.83920190002075
pressure: 6.000992555831266
total_envstep_count: 169880
total_train_sample_count: 169880
total_episode_count: 1370
total_duration: 37682.01433423068
[2024-12-27 06:40:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.17790525728647
avg_train_sample_per_sec: 5.17790525728647
avg_episode_per_sec: 0.04175730046198766
collect_time: 119.73954122229668
reward_mean: -723.257142857143
reward_std: 26.459734522863513
reward_max: -690.1428571428572
reward_min: -768.9285714285719
queue_len: 0.44867068415455524
wait_time: 2.879626019142147
delay_time: 114.29650065607004
pressure: 6.090694789081886
total_envstep_count: 170500
total_train_sample_count: 170500
total_episode_count: 1375
total_duration: 37801.753875452974
[2024-12-27 06:42:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.229309693346938
avg_train_sample_per_sec: 5.229309693346938
avg_episode_per_sec: 0.04217185236570111
collect_time: 118.56249416415395
reward_mean: -689.9857142857143
reward_std: 17.489262011711215
reward_max: -661.4285714285713
reward_min: -710.2857142857141
queue_len: 0.42803084012761416
wait_time: 2.837513293158454
delay_time: 95.12414679370775
pressure: 5.93151364764268
total_envstep_count: 171120
total_train_sample_count: 171120
total_episode_count: 1380
total_duration: 37920.316369617125
[2024-12-27 06:44:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.156498330761182
avg_train_sample_per_sec: 5.156498330761182
avg_episode_per_sec: 0.04158466395775147
collect_time: 120.23663351181149
reward_mean: -702.0428571428569
reward_std: 47.68610373888701
reward_max: -646.4285714285717
reward_min: -763.2142857142852
queue_len: 0.43551045728465076
wait_time: 2.818300248138958
delay_time: 101.16732247808223
pressure: 5.958436724565757
total_envstep_count: 171740
total_train_sample_count: 171740
total_episode_count: 1385
total_duration: 38040.55300312894
[2024-12-27 06:46:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2497696449231945
avg_train_sample_per_sec: 5.2497696449231945
avg_episode_per_sec: 0.04233685197518705
collect_time: 118.10042000596596
reward_mean: -698.4000000000002
reward_std: 21.803557096052582
reward_max: -669.7857142857143
reward_min: -727.3571428571433
queue_len: 0.43325062034739464
wait_time: 2.837061325771003
delay_time: 98.9933823279982
pressure: 5.93014888337469
total_envstep_count: 172360
total_train_sample_count: 172360
total_episode_count: 1390
total_duration: 38158.65342313491
[2024-12-27 06:48:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.177659967483704
avg_train_sample_per_sec: 5.177659967483704
avg_episode_per_sec: 0.04175532231841697
collect_time: 119.74521384055167
reward_mean: -697.9857142857142
reward_std: 35.25873462486902
reward_max: -656.2142857142857
reward_min: -751.9999999999999
queue_len: 0.43299361928394176
wait_time: 2.8520205600850765
delay_time: 102.92823854631122
pressure: 5.946526054590571
total_envstep_count: 172980
total_train_sample_count: 172980
total_episode_count: 1395
total_duration: 38278.39863697546
[2024-12-27 06:50:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.050755660052025
avg_train_sample_per_sec: 5.050755660052025
avg_episode_per_sec: 0.040731900484290526
collect_time: 122.75390886630491
reward_mean: -704.2285714285715
reward_std: 27.059812811395368
reward_max: -664.5000000000001
reward_min: -736.6428571428577
queue_len: 0.43686635944700464
wait_time: 2.8759216589861767
delay_time: 99.38406657244593
pressure: 6.021215880893299
total_envstep_count: 173600
total_train_sample_count: 173600
total_episode_count: 1400
total_duration: 38401.15254584176
[2024-12-27 06:52:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.221512301030449
avg_train_sample_per_sec: 5.221512301030449
avg_episode_per_sec: 0.0421089701696004
collect_time: 118.73954598893599
reward_mean: -690.1285714285716
reward_std: 34.09025834876746
reward_max: -651.7857142857144
reward_min: -730.7142857142857
queue_len: 0.42811946118397737
wait_time: 2.8647110953562565
delay_time: 95.87419150816258
pressure: 5.919354838709677
total_envstep_count: 174220
total_train_sample_count: 174220
total_episode_count: 1405
total_duration: 38519.8920918307
[2024-12-27 06:54:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.240585080307098
avg_train_sample_per_sec: 5.240585080307098
avg_episode_per_sec: 0.0422627829057024
collect_time: 118.30740089113638
reward_mean: -701.6142857142858
reward_std: 17.95553464784039
reward_max: -679.7857142857144
reward_min: -725.7142857142859
queue_len: 0.43524459411556193
wait_time: 2.842812832328962
delay_time: 101.55174142745996
pressure: 5.933002481389579
total_envstep_count: 174840
total_train_sample_count: 174840
total_episode_count: 1410
total_duration: 38638.19949272183
[2024-12-27 06:56:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.196897844320882
avg_train_sample_per_sec: 5.196897844320882
avg_episode_per_sec: 0.04191046648645873
collect_time: 119.30194099880754
reward_mean: -682.7142857142859
reward_std: 28.71997100788717
reward_max: -639.7857142857143
reward_min: -729.3571428571431
queue_len: 0.4235200283587382
wait_time: 2.8117245657568235
delay_time: 97.79112558932809
pressure: 5.805210918114144
total_envstep_count: 175460
total_train_sample_count: 175460
total_episode_count: 1415
total_duration: 38757.50143372064
[2024-12-27 06:58:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.092538844236434
avg_train_sample_per_sec: 5.092538844236434
avg_episode_per_sec: 0.041068861647068015
collect_time: 121.74673948765171
reward_mean: -663.6428571428571
reward_std: 19.50959993941233
reward_max: -637.0000000000001
reward_min: -697.1428571428571
queue_len: 0.4116891173342786
wait_time: 2.8021534916696207
delay_time: 90.75915404188868
pressure: 5.751116625310173
total_envstep_count: 176080
total_train_sample_count: 176080
total_episode_count: 1420
total_duration: 38879.24817320829
[2024-12-27 07:00:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.293881107486466
avg_train_sample_per_sec: 5.293881107486466
avg_episode_per_sec: 0.04269258957650376
collect_time: 117.11634383386746
reward_mean: -653.8857142857144
reward_std: 15.834707423368156
reward_max: -624.0714285714287
reward_min: -667.8571428571425
queue_len: 0.40563629918468624
wait_time: 2.7891793690180795
delay_time: 89.1453935838846
pressure: 5.664888337468983
total_envstep_count: 176700
total_train_sample_count: 176700
total_episode_count: 1425
total_duration: 38996.36451704216
[2024-12-27 07:02:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3077224254014626
avg_train_sample_per_sec: 5.3077224254014626
avg_episode_per_sec: 0.04280421310807631
collect_time: 116.81093137667325
reward_mean: -665.7714285714285
reward_std: 20.07625259771729
reward_max: -644.142857142857
reward_min: -700.9285714285717
queue_len: 0.41300957107408715
wait_time: 2.800629209500177
delay_time: 90.90946711693388
pressure: 5.775186104218362
total_envstep_count: 177320
total_train_sample_count: 177320
total_episode_count: 1430
total_duration: 39113.175448418835
[2024-12-27 07:04:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.533298710454954
avg_train_sample_per_sec: 5.533298710454954
avg_episode_per_sec: 0.044623376697217366
collect_time: 112.04889387745035
reward_mean: -660.1428571428571
reward_std: 28.537658614253424
reward_max: -639.5000000000001
reward_min: -715.4999999999999
queue_len: 0.4095179014533853
wait_time: 2.7918114143920603
delay_time: 92.62037652227255
pressure: 5.674813895781638
total_envstep_count: 177940
total_train_sample_count: 177940
total_episode_count: 1435
total_duration: 39225.224342296286
[2024-12-27 07:06:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.570137902109296
avg_train_sample_per_sec: 5.570137902109296
avg_episode_per_sec: 0.04492046695249432
collect_time: 111.30783669919893
reward_mean: -654.5714285714284
reward_std: 9.888562760552695
reward_max: -645.4999999999998
reward_min: -673.2142857142857
queue_len: 0.40606168025522854
wait_time: 2.7908808933002485
delay_time: 90.13404695623376
pressure: 5.678535980148884
total_envstep_count: 178560
total_train_sample_count: 178560
total_episode_count: 1440
total_duration: 39336.53217899548
[2024-12-27 07:07:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.717392395664616
avg_train_sample_per_sec: 5.717392395664616
avg_episode_per_sec: 0.046108003190843676
collect_time: 108.44104393991456
reward_mean: -648.914285714286
reward_std: 9.78309662590723
reward_max: -630.5714285714287
reward_min: -657.8571428571431
queue_len: 0.40255228642325436
wait_time: 2.796853952499115
delay_time: 89.07374312444414
pressure: 5.623449131513648
total_envstep_count: 179180
total_train_sample_count: 179180
total_episode_count: 1445
total_duration: 39444.9732229354
[2024-12-27 07:09:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8839850740173585
avg_train_sample_per_sec: 5.8839850740173585
avg_episode_per_sec: 0.04745149253239805
collect_time: 105.3707635557763
reward_mean: -657.1142857142856
reward_std: 6.538207955189615
reward_max: -649.6428571428572
reward_min: -666.5714285714283
queue_len: 0.4076391350584899
wait_time: 2.8265508684863527
delay_time: 90.68827364830682
pressure: 5.696029776674939
total_envstep_count: 179800
total_train_sample_count: 179800
total_episode_count: 1450
total_duration: 39550.34398649117
[2024-12-27 07:11:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5538374183192705
avg_train_sample_per_sec: 5.5538374183192705
avg_episode_per_sec: 0.04478901143805863
collect_time: 111.63452461804823
reward_mean: -641.0714285714286
reward_std: 9.148881943512306
reward_max: -632.2857142857143
reward_min: -654.4285714285712
queue_len: 0.3976869904289259
wait_time: 2.8260102800425377
delay_time: 87.91320580063056
pressure: 5.561910669975186
total_envstep_count: 180420
total_train_sample_count: 180420
total_episode_count: 1455
total_duration: 39661.97851110922
[2024-12-27 07:13:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.758464927811798
avg_train_sample_per_sec: 5.758464927811798
avg_episode_per_sec: 0.046439233288804824
collect_time: 107.66758290140328
reward_mean: -646.6857142857145
reward_std: 19.544903819310974
reward_max: -627.2857142857148
reward_min: -683.9285714285713
queue_len: 0.40116979794399155
wait_time: 2.824618929457639
delay_time: 88.37139339489067
pressure: 5.604466501240695
total_envstep_count: 181040
total_train_sample_count: 181040
total_episode_count: 1460
total_duration: 39769.646094010626
[2024-12-27 07:15:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.50353902478106
avg_train_sample_per_sec: 5.50353902478106
avg_episode_per_sec: 0.04438337923210532
collect_time: 112.65478398686646
reward_mean: -651.142857142857
reward_std: 13.658666980107022
reward_max: -638.9285714285714
reward_min: -677.7142857142853
queue_len: 0.4039347749025167
wait_time: 2.8059287486706843
delay_time: 89.71282766949462
pressure: 5.643548387096774
total_envstep_count: 181660
total_train_sample_count: 181660
total_episode_count: 1465
total_duration: 39882.30087799749
[2024-12-27 07:17:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.531843034698349
avg_train_sample_per_sec: 5.531843034698349
avg_episode_per_sec: 0.04461163737659959
collect_time: 112.07837896177915
reward_mean: -655.6857142857141
reward_std: 9.556769157759003
reward_max: -643.4285714285714
reward_min: -667.857142857143
queue_len: 0.40675292449485995
wait_time: 2.8029688053881605
delay_time: 89.68140836249594
pressure: 5.686600496277915
total_envstep_count: 182280
total_train_sample_count: 182280
total_episode_count: 1470
total_duration: 39994.37925695927
[2024-12-27 07:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.512962104890199
avg_train_sample_per_sec: 5.512962104890199
avg_episode_per_sec: 0.04445937181363064
collect_time: 112.46222778314353
reward_mean: -660.1285714285714
reward_std: 28.121870347413385
reward_max: -635.8571428571429
reward_min: -702.3571428571424
queue_len: 0.40950903934774896
wait_time: 2.8117245657568235
delay_time: 90.25749633214642
pressure: 5.725682382133995
total_envstep_count: 182900
total_train_sample_count: 182900
total_episode_count: 1475
total_duration: 40106.841484742414
[2024-12-27 07:20:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5774921070339945
avg_train_sample_per_sec: 5.5774921070339945
avg_episode_per_sec: 0.04497977505672576
collect_time: 111.16107169709727
reward_mean: -663.3
reward_std: 18.20480986005658
reward_max: -642.5714285714286
reward_min: -689.5
queue_len: 0.4114764267990075
wait_time: 2.830299539170507
delay_time: 90.9312727994316
pressure: 5.750000000000001
total_envstep_count: 183520
total_train_sample_count: 183520
total_episode_count: 1480
total_duration: 40218.00255643951
[2024-12-27 07:22:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.615688810297492
avg_train_sample_per_sec: 5.615688810297492
avg_episode_per_sec: 0.04528781298627009
collect_time: 110.40497807911038
reward_mean: -667.242857142857
reward_std: 17.41742032024953
reward_max: -640.2142857142858
reward_min: -691.3571428571427
queue_len: 0.41392236795462595
wait_time: 2.817121588089331
delay_time: 92.8692933084772
pressure: 5.774441687344913
total_envstep_count: 184140
total_train_sample_count: 184140
total_episode_count: 1485
total_duration: 40328.40753451862
[2024-12-27 07:24:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5452278907967045
avg_train_sample_per_sec: 5.5452278907967045
avg_episode_per_sec: 0.04471957976448955
collect_time: 111.8078485158384
reward_mean: -657.5857142857142
reward_std: 11.587678184791095
reward_max: -644.7857142857143
reward_min: -677.785714285714
queue_len: 0.4079315845444877
wait_time: 2.84427507975895
delay_time: 90.64263892719096
pressure: 5.697518610421836
total_envstep_count: 184760
total_train_sample_count: 184760
total_episode_count: 1490
total_duration: 40440.21538303446
[2024-12-27 07:26:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.622955451437444
avg_train_sample_per_sec: 5.622955451437444
avg_episode_per_sec: 0.045346414930947126
collect_time: 110.26229984473808
reward_mean: -662.4714285714285
reward_std: 9.519539518961185
reward_max: -647.7142857142858
reward_min: -677.4285714285719
queue_len: 0.410962424672102
wait_time: 2.859491315136476
delay_time: 90.82849843164593
pressure: 5.743548387096775
total_envstep_count: 185380
total_train_sample_count: 185380
total_episode_count: 1495
total_duration: 40550.4776828792
[2024-12-27 07:28:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.639726959010481
avg_train_sample_per_sec: 5.639726959010481
avg_episode_per_sec: 0.045481669024278075
collect_time: 109.93440010591969
reward_mean: -667.9571428571428
reward_std: 5.265521273882823
reward_max: -660.8571428571431
reward_min: -676.8571428571425
queue_len: 0.41436547323644096
wait_time: 2.857009925558313
delay_time: 92.14012419715131
pressure: 5.7859801488833735
total_envstep_count: 186000
total_train_sample_count: 186000
total_episode_count: 1500
total_duration: 40660.41208298512
[2024-12-27 07:30:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.519914143009474
avg_train_sample_per_sec: 5.519914143009474
avg_episode_per_sec: 0.044515436637173174
collect_time: 112.32058759196102
reward_mean: -662.9571428571428
reward_std: 15.032726204613338
reward_max: -647.4285714285708
reward_min: -688.0000000000007
queue_len: 0.4112637362637363
wait_time: 2.8146490606168033
delay_time: 92.29109951169612
pressure: 5.739081885856081
total_envstep_count: 186620
total_train_sample_count: 186620
total_episode_count: 1505
total_duration: 40772.73267057708
[2024-12-27 07:32:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.425410907051523
avg_train_sample_per_sec: 5.425410907051523
avg_episode_per_sec: 0.04375331376654454
collect_time: 114.27705857157707
reward_mean: -642.057142857143
reward_std: 15.31695072760355
reward_max: -616.0714285714289
reward_min: -663.9285714285716
queue_len: 0.3982984757178306
wait_time: 2.8254696915987236
delay_time: 88.76584313617641
pressure: 5.5635235732009924
total_envstep_count: 187240
total_train_sample_count: 187240
total_episode_count: 1510
total_duration: 40887.00972914866
[2024-12-27 07:33:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.514831421194043
avg_train_sample_per_sec: 5.514831421194043
avg_episode_per_sec: 0.04447444694511325
collect_time: 112.42410740195587
reward_mean: -635.7142857142859
reward_std: 13.255803503771983
reward_max: -612.0000000000001
reward_min: -652.4285714285716
queue_len: 0.39436370081531386
wait_time: 2.8157213753987946
delay_time: 86.66246976401767
pressure: 5.512406947890819
total_envstep_count: 187860
total_train_sample_count: 187860
total_episode_count: 1515
total_duration: 40999.43383655062
[2024-12-27 07:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.730762271308543
avg_train_sample_per_sec: 5.730762271308543
avg_episode_per_sec: 0.046215824768617284
collect_time: 108.18805084693057
reward_mean: -632.0571428571428
reward_std: 14.603005002465736
reward_max: -607.714285714286
reward_min: -649.1428571428575
queue_len: 0.3920950017724212
wait_time: 2.7854927330733776
delay_time: 87.925994237904
pressure: 5.474069478908189
total_envstep_count: 188480
total_train_sample_count: 188480
total_episode_count: 1520
total_duration: 41107.62188739755
[2024-12-27 07:37:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.850340217701902
avg_train_sample_per_sec: 5.850340217701902
avg_episode_per_sec: 0.047180163045983076
collect_time: 105.97674270703268
reward_mean: -632.9142857142856
reward_std: 15.860450105561855
reward_max: -617.5714285714286
reward_min: -662.3571428571425
queue_len: 0.39262672811059907
wait_time: 2.7743176178660045
delay_time: 87.54694145440013
pressure: 5.483746898263027
total_envstep_count: 189100
total_train_sample_count: 189100
total_episode_count: 1525
total_duration: 41213.598630104585
[2024-12-27 07:39:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.60032592340407
avg_train_sample_per_sec: 5.60032592340407
avg_episode_per_sec: 0.045163918737129605
collect_time: 110.70784245055914
reward_mean: -629.7142857142857
reward_std: 8.88819441731574
reward_max: -617.4285714285713
reward_min: -639.3571428571429
queue_len: 0.39064161644806805
wait_time: 2.773183268344559
delay_time: 87.2405877816447
pressure: 5.463771712158808
total_envstep_count: 189720
total_train_sample_count: 189720
total_episode_count: 1530
total_duration: 41324.306472555145
[2024-12-27 07:41:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.524253698348637
avg_train_sample_per_sec: 5.524253698348637
avg_episode_per_sec: 0.04455043305119869
collect_time: 112.23235460481047
reward_mean: -630.5
reward_std: 18.594710680893137
reward_max: -608.2857142857143
reward_min: -663.4285714285713
queue_len: 0.3911290322580645
wait_time: 2.7797943991492384
delay_time: 86.94097868149001
pressure: 5.463151364764268
total_envstep_count: 190340
total_train_sample_count: 190340
total_episode_count: 1535
total_duration: 41436.53882715996
[2024-12-27 07:43:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.373127464489601
avg_train_sample_per_sec: 5.373127464489601
avg_episode_per_sec: 0.043331673100722584
collect_time: 115.38903629171479
reward_mean: -634.4000000000001
reward_std: 26.7385909295526
reward_max: -599.4285714285716
reward_min: -672.0714285714283
queue_len: 0.39354838709677425
wait_time: 2.783401276143212
delay_time: 88.51664035032786
pressure: 5.493672456575682
total_envstep_count: 190960
total_train_sample_count: 190960
total_episode_count: 1540
total_duration: 41551.927863451674
[2024-12-27 07:45:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.556266702282701
avg_train_sample_per_sec: 5.556266702282701
avg_episode_per_sec: 0.04480860243776372
collect_time: 111.58571631294862
reward_mean: -700.7857142857142
reward_std: 164.07564208782074
reward_max: -612.9999999999998
reward_min: -1028.6428571428573
queue_len: 0.4347305919886565
wait_time: 2.8041917759659696
delay_time: 100.8049729504944
pressure: 6.045285359801489
total_envstep_count: 191580
total_train_sample_count: 191580
total_episode_count: 1545
total_duration: 41663.51357976462
[2024-12-27 07:46:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.582759529561602
avg_train_sample_per_sec: 5.582759529561602
avg_episode_per_sec: 0.04502225427065808
collect_time: 111.05618945559112
reward_mean: -621.9714285714286
reward_std: 19.311760189911677
reward_max: -592.3571428571428
reward_min: -643.7142857142858
queue_len: 0.385838355193194
wait_time: 2.734615384615384
delay_time: 86.03243210269791
pressure: 5.395161290322581
total_envstep_count: 192200
total_train_sample_count: 192200
total_episode_count: 1550
total_duration: 41774.569769220216
[2024-12-27 07:48:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.443629480037108
avg_train_sample_per_sec: 5.443629480037108
avg_episode_per_sec: 0.04390023774223475
collect_time: 113.89459960007666
reward_mean: -624.1285714285714
reward_std: 15.242488949897856
reward_max: -612.7857142857142
reward_min: -654.357142857143
queue_len: 0.387176533144275
wait_time: 2.71930166607586
delay_time: 86.56477735016861
pressure: 5.411786600496278
total_envstep_count: 192820
total_train_sample_count: 192820
total_episode_count: 1555
total_duration: 41888.46436882029
[2024-12-27 07:50:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.795132144798662
avg_train_sample_per_sec: 5.795132144798662
avg_episode_per_sec: 0.04673493665160211
collect_time: 106.9863437982984
reward_mean: -623.8999999999999
reward_std: 22.91695745022691
reward_max: -591.3571428571428
reward_min: -659.2142857142858
queue_len: 0.3870347394540942
wait_time: 2.75031017369727
delay_time: 85.88205775812904
pressure: 5.410173697270471
total_envstep_count: 193440
total_train_sample_count: 193440
total_episode_count: 1560
total_duration: 41995.45071261859
[2024-12-27 07:52:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3718518004247535
avg_train_sample_per_sec: 5.3718518004247535
avg_episode_per_sec: 0.043321385487296395
collect_time: 115.41643794994056
reward_mean: -720.2571428571429
reward_std: 185.2685452999269
reward_max: -623.4999999999999
reward_min: -1090.714285714286
queue_len: 0.44680964197093226
wait_time: 2.7575771003190352
delay_time: 101.17592862687818
pressure: 6.248014888337469
total_envstep_count: 194060
total_train_sample_count: 194060
total_episode_count: 1565
total_duration: 42110.867150568534
[2024-12-27 07:54:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.398225544268156
avg_train_sample_per_sec: 5.398225544268156
avg_episode_per_sec: 0.04353407696990448
collect_time: 114.85255569921804
reward_mean: -629.8142857142858
reward_std: 15.942729134150735
reward_max: -611.9285714285713
reward_min: -657.7142857142858
queue_len: 0.3907036511875222
wait_time: 2.7249734136830916
delay_time: 87.49611118166874
pressure: 5.461414392059553
total_envstep_count: 194680
total_train_sample_count: 194680
total_episode_count: 1570
total_duration: 42225.71970626775
[2024-12-27 07:56:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.471655304749544
avg_train_sample_per_sec: 5.471655304749544
avg_episode_per_sec: 0.04412625245765761
collect_time: 113.31123133100569
reward_mean: -608.3428571428572
reward_std: 14.525515902882667
reward_max: -584.8571428571429
reward_min: -626.2857142857143
queue_len: 0.37738390641616454
wait_time: 2.694904289259127
delay_time: 84.37416101970055
pressure: 5.27605459057072
total_envstep_count: 195300
total_train_sample_count: 195300
total_episode_count: 1575
total_duration: 42339.030937598756
[2024-12-27 07:58:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.295943239334767
avg_train_sample_per_sec: 5.295943239334767
avg_episode_per_sec: 0.04270921967205458
collect_time: 117.07074112785983
reward_mean: -611.7857142857141
reward_std: 10.040631738804363
reward_max: -597.2857142857139
reward_min: -624.9285714285713
queue_len: 0.37951967387451246
wait_time: 2.655095710740872
delay_time: 84.63204903550798
pressure: 5.304714640198511
total_envstep_count: 195920
total_train_sample_count: 195920
total_episode_count: 1580
total_duration: 42456.10167872661
[2024-12-27 08:00:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.414726755858522
avg_train_sample_per_sec: 5.414726755858522
avg_episode_per_sec: 0.04366715125692357
collect_time: 114.50254610339927
reward_mean: -641.8714285714285
reward_std: 21.46955129137679
reward_max: -606.5000000000001
reward_min: -673.8571428571428
queue_len: 0.39818326834455864
wait_time: 2.7793247075505136
delay_time: 86.45577904721722
pressure: 5.568610421836228
total_envstep_count: 196540
total_train_sample_count: 196540
total_episode_count: 1585
total_duration: 42570.604224830015
[2024-12-27 08:02:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.423139338524308
avg_train_sample_per_sec: 5.423139338524308
avg_episode_per_sec: 0.04373499466551861
collect_time: 114.32492534272748
reward_mean: -608.4428571428572
reward_std: 17.991006823705455
reward_max: -590.3571428571428
reward_min: -638.5714285714287
queue_len: 0.3774459411556186
wait_time: 2.639817440623892
delay_time: 84.59558976980263
pressure: 5.2799007444168735
total_envstep_count: 197160
total_train_sample_count: 197160
total_episode_count: 1590
total_duration: 42684.92915017274
[2024-12-27 08:04:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.53790709986408
avg_train_sample_per_sec: 5.53790709986408
avg_episode_per_sec: 0.04466054112793613
collect_time: 111.9556519854255
reward_mean: -610.0714285714286
reward_std: 14.287928399848106
reward_max: -590.8571428571427
reward_min: -626.0
queue_len: 0.3784562211981567
wait_time: 2.6493353420772783
delay_time: 84.8585066695452
pressure: 5.293548387096774
total_envstep_count: 197780
total_train_sample_count: 197780
total_episode_count: 1595
total_duration: 42796.884802158165
[2024-12-27 08:05:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.693269087480978
avg_train_sample_per_sec: 5.693269087480978
avg_episode_per_sec: 0.04591346038291111
collect_time: 108.90052630101889
reward_mean: -628.1285714285714
reward_std: 33.339117185280756
reward_max: -601.3571428571429
reward_min: -688.8571428571429
queue_len: 0.3896579227224388
wait_time: 2.714906061680255
delay_time: 86.48815789149691
pressure: 5.4506203473945405
total_envstep_count: 198400
total_train_sample_count: 198400
total_episode_count: 1600
total_duration: 42905.785328459184
[2024-12-27 08:07:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7872013320782605
avg_train_sample_per_sec: 5.7872013320782605
avg_episode_per_sec: 0.0466709784845021
collect_time: 107.13295847569033
reward_mean: -628.6285714285714
reward_std: 23.560057863481784
reward_max: -598.9999999999998
reward_min: -661.4285714285712
queue_len: 0.3899680964197093
wait_time: 2.724140375753279
delay_time: 86.27340896873596
pressure: 5.45074441687345
total_envstep_count: 199020
total_train_sample_count: 199020
total_episode_count: 1605
total_duration: 43012.91828693487
[2024-12-27 08:09:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.529344462963862
avg_train_sample_per_sec: 5.529344462963862
avg_episode_per_sec: 0.04459148760454727
collect_time: 112.12902436316385
reward_mean: -612.5428571428572
reward_std: 24.10049537978466
reward_max: -574.9999999999999
reward_min: -648.5714285714286
queue_len: 0.37998936547323653
wait_time: 2.702100319035803
delay_time: 85.30859378025833
pressure: 5.3160049627791555
total_envstep_count: 199640
total_train_sample_count: 199640
total_episode_count: 1610
total_duration: 43125.04731129804
[2024-12-27 08:11:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.38192246745202
avg_train_sample_per_sec: 5.38192246745202
avg_episode_per_sec: 0.0434026005439679
collect_time: 115.20047041731698
reward_mean: -608.8142857142858
reward_std: 16.34641569648982
reward_max: -583.0714285714284
reward_min: -632.6428571428571
queue_len: 0.37767635590216236
wait_time: 2.662717121588089
delay_time: 84.73742034959609
pressure: 5.28089330024814
total_envstep_count: 200260
total_train_sample_count: 200260
total_episode_count: 1615
total_duration: 43240.247781715356
[2024-12-27 08:13:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.295271776058889
avg_train_sample_per_sec: 5.295271776058889
avg_episode_per_sec: 0.0427038046456362
collect_time: 117.08558620223404
reward_mean: -619.5428571428572
reward_std: 9.262454384475461
reward_max: -608.5714285714288
reward_min: -629.5000000000002
queue_len: 0.3843317972350231
wait_time: 2.7502658631690884
delay_time: 85.20405834920442
pressure: 5.371339950372208
total_envstep_count: 200880
total_train_sample_count: 200880
total_episode_count: 1620
total_duration: 43357.33336791759
[2024-12-27 08:15:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.396210705658063
avg_train_sample_per_sec: 5.396210705658063
avg_episode_per_sec: 0.04351782827143599
collect_time: 114.89543937747175
reward_mean: -609.1428571428572
reward_std: 16.444588465386403
reward_max: -587.2857142857143
reward_min: -635.5000000000001
queue_len: 0.37788018433179726
wait_time: 2.6719602977667494
delay_time: 85.15631706866343
pressure: 5.28287841191067
total_envstep_count: 201500
total_train_sample_count: 201500
total_episode_count: 1625
total_duration: 43472.22880729506
[2024-12-27 08:17:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.370764688252529
avg_train_sample_per_sec: 5.370764688252529
avg_episode_per_sec: 0.04331261845364943
collect_time: 115.43979972835632
reward_mean: -632.6
reward_std: 52.21864550881707
reward_max: -587.8571428571425
reward_min: -733.285714285714
queue_len: 0.3924317617866005
wait_time: 2.7178394186458705
delay_time: 86.69791260603071
pressure: 5.489205955334987
total_envstep_count: 202120
total_train_sample_count: 202120
total_episode_count: 1630
total_duration: 43587.66860702342
[2024-12-27 08:19:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.545068240472339
avg_train_sample_per_sec: 5.545068240472339
avg_episode_per_sec: 0.044718292261873696
collect_time: 111.81106762126832
reward_mean: -587.1857142857143
reward_std: 10.828401807944063
reward_max: -565.7857142857142
reward_min: -595.0714285714286
queue_len: 0.36425912796880544
wait_time: 2.6046260191421484
delay_time: 82.05949258613006
pressure: 5.096774193548387
total_envstep_count: 202740
total_train_sample_count: 202740
total_episode_count: 1635
total_duration: 43699.47967464469
[2024-12-27 08:21:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.644431648520694
avg_train_sample_per_sec: 5.644431648520694
avg_episode_per_sec: 0.04551961006871528
collect_time: 109.84276869797706
reward_mean: -615.0571428571427
reward_std: 43.98365651939734
reward_max: -580.0
reward_min: -701.3571428571428
queue_len: 0.38154909606522514
wait_time: 2.627694080113435
delay_time: 85.7140094477633
pressure: 5.338213399503722
total_envstep_count: 203360
total_train_sample_count: 203360
total_episode_count: 1640
total_duration: 43809.322443342666
[2024-12-27 08:22:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.55035343492074
avg_train_sample_per_sec: 5.55035343492074
avg_episode_per_sec: 0.0447609147977479
collect_time: 111.70459814310072
reward_mean: -616.0857142857143
reward_std: 13.898054481377967
reward_max: -594.6428571428569
reward_min: -633.3571428571429
queue_len: 0.3821871676710386
wait_time: 2.669771357674583
delay_time: 85.58623415495708
pressure: 5.347146401985112
total_envstep_count: 203980
total_train_sample_count: 203980
total_episode_count: 1645
total_duration: 43921.027041485766
[2024-12-27 08:24:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.686335765630095
avg_train_sample_per_sec: 5.686335765630095
avg_episode_per_sec: 0.04585754649701689
collect_time: 109.03330818898604
reward_mean: -608.0857142857142
reward_std: 10.694400594780205
reward_max: -589.6428571428568
reward_min: -622.7142857142857
queue_len: 0.377224388514711
wait_time: 2.6887096774193546
delay_time: 84.36330783111327
pressure: 5.275682382133995
total_envstep_count: 204600
total_train_sample_count: 204600
total_episode_count: 1650
total_duration: 44030.06034967475
[2024-12-27 08:26:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.612152751182861
avg_train_sample_per_sec: 5.612152751182861
avg_episode_per_sec: 0.04525929638050694
collect_time: 110.47454114097732
reward_mean: -593.2285714285714
reward_std: 12.918456974896129
reward_max: -574.857142857143
reward_min: -608.9999999999998
queue_len: 0.36800779865295985
wait_time: 2.591102445941156
delay_time: 82.57598758916359
pressure: 5.149255583126551
total_envstep_count: 205220
total_train_sample_count: 205220
total_episode_count: 1655
total_duration: 44140.534890815725
[2024-12-27 08:28:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.75731697793385
avg_train_sample_per_sec: 5.75731697793385
avg_episode_per_sec: 0.046429975628498786
collect_time: 107.68905071169137
reward_mean: -589.1285714285714
reward_std: 7.648582635137864
reward_max: -578.142857142857
reward_min: -597.5714285714289
queue_len: 0.36546437433534207
wait_time: 2.594009216589862
delay_time: 82.74397985564931
pressure: 5.114019851116625
total_envstep_count: 205840
total_train_sample_count: 205840
total_episode_count: 1660
total_duration: 44248.223941527416
[2024-12-27 08:30:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.707405129409642
avg_train_sample_per_sec: 5.707405129409642
avg_episode_per_sec: 0.04602746072104549
collect_time: 108.630802605059
reward_mean: -595.5714285714284
reward_std: 6.193973371144652
reward_max: -585.8571428571428
reward_min: -602.5714285714288
queue_len: 0.36946118397731303
wait_time: 2.620303084012761
delay_time: 82.67724341191158
pressure: 5.171091811414392
total_envstep_count: 206460
total_train_sample_count: 206460
total_episode_count: 1665
total_duration: 44356.85474413248
[2024-12-27 08:32:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.834672560780354
avg_train_sample_per_sec: 5.834672560780354
avg_episode_per_sec: 0.04705381097403511
collect_time: 106.2613186158091
reward_mean: -607.8999999999999
reward_std: 12.664718790435986
reward_max: -589.7142857142853
reward_min: -626.0000000000003
queue_len: 0.3771091811414391
wait_time: 2.6960829493087552
delay_time: 84.71903361638859
pressure: 5.268982630272952
total_envstep_count: 207080
total_train_sample_count: 207080
total_episode_count: 1670
total_duration: 44463.11606274829
[2024-12-27 08:33:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.737392014342862
avg_train_sample_per_sec: 5.737392014342862
avg_episode_per_sec: 0.046269290438248886
collect_time: 108.06303603624553
reward_mean: -591.1714285714287
reward_std: 11.603535703238139
reward_max: -579.5000000000002
reward_min: -608.5714285714284
queue_len: 0.3667316554413329
wait_time: 2.6025345622119813
delay_time: 82.14342300536399
pressure: 5.1325062034739455
total_envstep_count: 207700
total_train_sample_count: 207700
total_episode_count: 1675
total_duration: 44571.17909878454
[2024-12-27 08:35:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.514147785617796
avg_train_sample_per_sec: 5.514147785617796
avg_episode_per_sec: 0.044468933754982225
collect_time: 112.43804557017984
reward_mean: -595.8142857142858
reward_std: 18.292777653645583
reward_max: -560.6428571428571
reward_min: -611.7142857142858
queue_len: 0.3696118397731301
wait_time: 2.5771534916696206
delay_time: 82.67167079361951
pressure: 5.171960297766749
total_envstep_count: 208320
total_train_sample_count: 208320
total_episode_count: 1680
total_duration: 44683.61714435472
[2024-12-27 08:37:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.487128842928328
avg_train_sample_per_sec: 5.487128842928328
avg_episode_per_sec: 0.04425103905587362
collect_time: 112.99169706923142
reward_mean: -590.5142857142857
reward_std: 7.957335211832356
reward_max: -582.4999999999999
reward_min: -602.6428571428569
queue_len: 0.36632399858206305
wait_time: 2.554900744416874
delay_time: 82.79682781760722
pressure: 5.127171215880893
total_envstep_count: 208940
total_train_sample_count: 208940
total_episode_count: 1685
total_duration: 44796.60884142395
[2024-12-27 08:39:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.533808103562561
avg_train_sample_per_sec: 5.533808103562561
avg_episode_per_sec: 0.04462748470614968
collect_time: 112.0385796538293
reward_mean: -597.0571428571428
reward_std: 7.830005082491131
reward_max: -588.9285714285716
reward_min: -609.2857142857144
queue_len: 0.3703828429634881
wait_time: 2.6120524636653673
delay_time: 82.99161566873744
pressure: 5.183746898263027
total_envstep_count: 209560
total_train_sample_count: 209560
total_episode_count: 1690
total_duration: 44908.64742107778
[2024-12-27 08:41:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4282106764119975
avg_train_sample_per_sec: 5.4282106764119975
avg_episode_per_sec: 0.043775892551709654
collect_time: 114.21811660593374
reward_mean: -676.4571428571428
reward_std: 137.48605569367416
reward_max: -595.7857142857141
reward_min: -950.642857142857
queue_len: 0.41963842609003893
wait_time: 2.6334190003544835
delay_time: 96.20008813466181
pressure: 5.902605459057073
total_envstep_count: 210180
total_train_sample_count: 210180
total_episode_count: 1695
total_duration: 45022.86553768371
[2024-12-27 08:43:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.610532277455172
avg_train_sample_per_sec: 5.610532277455172
avg_episode_per_sec: 0.04524622804399332
collect_time: 110.50644918154181
reward_mean: -605.742857142857
reward_std: 32.23683404721632
reward_max: -571.4285714285712
reward_min: -666.8571428571431
queue_len: 0.37577100319035805
wait_time: 2.609526763559022
delay_time: 83.81462380907436
pressure: 5.2570719602977665
total_envstep_count: 210800
total_train_sample_count: 210800
total_episode_count: 1700
total_duration: 45133.371986865255
[2024-12-27 08:45:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5154490656001505
avg_train_sample_per_sec: 5.5154490656001505
avg_episode_per_sec: 0.04447942794838831
collect_time: 112.41151765264941
reward_mean: -599.3571428571427
reward_std: 14.108110274242975
reward_max: -580.1428571428571
reward_min: -619.4285714285711
queue_len: 0.37180964197093214
wait_time: 2.636051045728465
delay_time: 83.42080652818251
pressure: 5.200124069478909
total_envstep_count: 211420
total_train_sample_count: 211420
total_episode_count: 1705
total_duration: 45245.7835045179
[2024-12-27 08:47:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.485948436780166
avg_train_sample_per_sec: 5.485948436780166
avg_episode_per_sec: 0.044241519651452954
collect_time: 113.01600938194248
reward_mean: -593.8714285714286
reward_std: 9.331797735677103
reward_max: -580.1428571428576
reward_min: -608.9285714285713
queue_len: 0.3684065934065935
wait_time: 2.586680255228642
delay_time: 83.06644643388748
pressure: 5.1553349875930525
total_envstep_count: 212040
total_train_sample_count: 212040
total_episode_count: 1710
total_duration: 45358.799513899845
[2024-12-27 08:49:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.433620779016676
avg_train_sample_per_sec: 5.433620779016676
avg_episode_per_sec: 0.043819522411424804
collect_time: 114.10439285610241
reward_mean: -604.4857142857144
reward_std: 12.440011155582711
reward_max: -590.0714285714287
reward_min: -620.9285714285716
queue_len: 0.3749911378943637
wait_time: 2.626214108472173
delay_time: 84.16226480431716
pressure: 5.245037220843672
total_envstep_count: 212660
total_train_sample_count: 212660
total_episode_count: 1715
total_duration: 45472.90390675595
[2024-12-27 08:50:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.768069469028749
avg_train_sample_per_sec: 5.768069469028749
avg_episode_per_sec: 0.04651668926636088
collect_time: 107.48830320595951
reward_mean: -602.8857142857145
reward_std: 21.2395760747886
reward_max: -562.2857142857144
reward_min: -621.1428571428569
queue_len: 0.3739985820630983
wait_time: 2.6542538107054234
delay_time: 83.64272518525087
pressure: 5.231017369727047
total_envstep_count: 213280
total_train_sample_count: 213280
total_episode_count: 1720
total_duration: 45580.39220996191
[2024-12-27 08:52:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.486087737744581
avg_train_sample_per_sec: 5.486087737744581
avg_episode_per_sec: 0.04424264304632727
collect_time: 113.01313971600679
reward_mean: -595.2
reward_std: 6.43989478935469
reward_max: -586.2857142857143
reward_min: -605.2142857142854
queue_len: 0.36923076923076925
wait_time: 2.6232364409783764
delay_time: 82.74923803798075
pressure: 5.162655086848635
total_envstep_count: 213900
total_train_sample_count: 213900
total_episode_count: 1725
total_duration: 45693.405349677916
[2024-12-27 08:54:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.793225693344961
avg_train_sample_per_sec: 5.793225693344961
avg_episode_per_sec: 0.04671956204310452
collect_time: 107.02155117350816
reward_mean: -585.0142857142856
reward_std: 6.622226026874981
reward_max: -576.142857142857
reward_min: -592.5714285714286
queue_len: 0.36291208791208784
wait_time: 2.5359801488833744
delay_time: 82.65916931293104
pressure: 5.077915632754342
total_envstep_count: 214520
total_train_sample_count: 214520
total_episode_count: 1730
total_duration: 45800.426900851424
[2024-12-27 08:56:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.536984132602105
avg_train_sample_per_sec: 5.536984132602105
avg_episode_per_sec: 0.044653097843565366
collect_time: 111.97431402221322
reward_mean: -592.0142857142856
reward_std: 14.435458045368438
reward_max: -574.5
reward_min: -609.7142857142858
queue_len: 0.3672545196738744
wait_time: 2.5504696915987237
delay_time: 84.38854059229418
pressure: 5.135980148883375
total_envstep_count: 215140
total_train_sample_count: 215140
total_episode_count: 1735
total_duration: 45912.40121487364
[2024-12-27 08:58:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7048712877334085
avg_train_sample_per_sec: 5.7048712877334085
avg_episode_per_sec: 0.0460070265139791
collect_time: 108.67905141578242
reward_mean: -590.9142857142858
reward_std: 11.277429146896203
reward_max: -576.714285714286
reward_min: -610.7857142857142
queue_len: 0.3665721375398795
wait_time: 2.517555831265508
delay_time: 83.2289722406985
pressure: 5.129776674937966
total_envstep_count: 215760
total_train_sample_count: 215760
total_episode_count: 1740
total_duration: 46021.08026628942
[2024-12-27 09:00:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.767094123997282
avg_train_sample_per_sec: 5.767094123997282
avg_episode_per_sec: 0.046508823580623235
collect_time: 107.50648189009725
reward_mean: -586.7285714285713
reward_std: 11.695839134548116
reward_max: -572.285714285714
reward_min: -600.7142857142858
queue_len: 0.3639755405884438
wait_time: 2.5776852180077983
delay_time: 82.30243236249096
pressure: 5.093424317617865
total_envstep_count: 216380
total_train_sample_count: 216380
total_episode_count: 1745
total_duration: 46128.586748179514
[2024-12-27 09:01:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.896622007690632
avg_train_sample_per_sec: 5.896622007690632
avg_episode_per_sec: 0.04755340328782768
collect_time: 105.14494556228446
reward_mean: -602.5285714285714
reward_std: 7.462778385058155
reward_max: -592.4285714285712
reward_min: -612.8571428571429
queue_len: 0.37377702942219065
wait_time: 2.619629563984403
delay_time: 84.27139970357521
pressure: 5.229156327543424
total_envstep_count: 217000
total_train_sample_count: 217000
total_episode_count: 1750
total_duration: 46233.7316937418
[2024-12-27 09:03:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.790780729660842
avg_train_sample_per_sec: 5.790780729660842
avg_episode_per_sec: 0.046699844594039044
collect_time: 107.0667374477349
reward_mean: -589.1142857142856
reward_std: 10.975724605338941
reward_max: -570.9285714285716
reward_min: -603.2857142857141
queue_len: 0.36545551222970574
wait_time: 2.5903757532789795
delay_time: 83.48631667670307
pressure: 5.110173697270471
total_envstep_count: 217620
total_train_sample_count: 217620
total_episode_count: 1755
total_duration: 46340.798431189534
[2024-12-27 09:05:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.530365663201555
avg_train_sample_per_sec: 5.530365663201555
avg_episode_per_sec: 0.04459972309033512
collect_time: 112.10831936944275
reward_mean: -591.0571428571427
reward_std: 9.634271309936661
reward_max: -575.0714285714282
reward_min: -603.2857142857138
queue_len: 0.3666607585962423
wait_time: 2.5775700106345267
delay_time: 83.48091645353284
pressure: 5.121712158808933
total_envstep_count: 218240
total_train_sample_count: 218240
total_episode_count: 1760
total_duration: 46452.90675055898
[2024-12-27 09:07:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.047983302335839
avg_train_sample_per_sec: 6.047983302335839
avg_episode_per_sec: 0.048774058889805155
collect_time: 102.51351053838805
reward_mean: -596.7285714285715
reward_std: 17.926175138663545
reward_max: -566.8571428571431
reward_min: -612.9999999999997
queue_len: 0.37017901453385327
wait_time: 2.5860510457284653
delay_time: 84.16771187370917
pressure: 5.175806451612903
total_envstep_count: 218860
total_train_sample_count: 218860
total_episode_count: 1765
total_duration: 46555.420261097366
[2024-12-27 09:08:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.831548014038074
avg_train_sample_per_sec: 5.831548014038074
avg_episode_per_sec: 0.047028613016436085
collect_time: 106.31825349075348
reward_mean: -584.542857142857
reward_std: 6.971165100407784
reward_max: -576.8571428571428
reward_min: -595.7142857142857
queue_len: 0.36261963842608996
wait_time: 2.594691598723857
delay_time: 83.12780720099782
pressure: 5.066253101736973
total_envstep_count: 219480
total_train_sample_count: 219480
total_episode_count: 1770
total_duration: 46661.73851458812
[2024-12-27 09:10:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.551165911837744
avg_train_sample_per_sec: 5.551165911837744
avg_episode_per_sec: 0.04476746703094955
collect_time: 111.68824889161809
reward_mean: -667.9285714285713
reward_std: 121.61101420311472
reward_max: -588.2142857142858
reward_min: -909.3571428571424
queue_len: 0.41434774902516835
wait_time: 2.7590570719602985
delay_time: 93.74503345837267
pressure: 5.6578163771712155
total_envstep_count: 220100
total_train_sample_count: 220100
total_episode_count: 1775
total_duration: 46773.426763479736
[2024-12-27 09:12:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.667623554265261
avg_train_sample_per_sec: 5.667623554265261
avg_episode_per_sec: 0.04570664156665533
collect_time: 109.39329227916153
reward_mean: -601.3285714285714
reward_std: 13.320584040636989
reward_max: -578.857142857143
reward_min: -615.3571428571429
queue_len: 0.3730326125487416
wait_time: 2.5859092520382845
delay_time: 84.66933964286096
pressure: 5.213895781637717
total_envstep_count: 220720
total_train_sample_count: 220720
total_episode_count: 1780
total_duration: 46882.8200557589
[2024-12-27 09:14:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.753715999557795
avg_train_sample_per_sec: 5.753715999557795
avg_episode_per_sec: 0.0464009354803048
collect_time: 107.75644818890095
reward_mean: -609.6714285714285
reward_std: 14.76175422350275
reward_max: -595.1428571428571
reward_min: -636.1428571428571
queue_len: 0.3782080822403403
wait_time: 2.63148706132577
delay_time: 84.85928210603555
pressure: 5.28697270471464
total_envstep_count: 221340
total_train_sample_count: 221340
total_episode_count: 1785
total_duration: 46990.5765039478
[2024-12-27 09:16:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9279529130078705
avg_train_sample_per_sec: 5.9279529130078705
avg_episode_per_sec: 0.047806071879095725
collect_time: 104.5892248299606
reward_mean: -615.6857142857143
reward_std: 30.549411297310446
reward_max: -579.2857142857144
reward_min: -667.5714285714287
queue_len: 0.38193902871322233
wait_time: 2.677552286423254
delay_time: 84.951766313021
pressure: 5.374937965260545
total_envstep_count: 221960
total_train_sample_count: 221960
total_episode_count: 1790
total_duration: 47095.16572877776
[2024-12-27 09:18:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.785000052411522
avg_train_sample_per_sec: 5.785000052411522
avg_episode_per_sec: 0.04665322622912518
collect_time: 107.17372418027
reward_mean: -612.242857142857
reward_std: 9.116323104123506
reward_max: -595.1428571428569
reward_min: -620.9999999999995
queue_len: 0.3798032612548741
wait_time: 2.643131868131868
delay_time: 85.28577862461916
pressure: 5.30893300248139
total_envstep_count: 222580
total_train_sample_count: 222580
total_episode_count: 1795
total_duration: 47202.33945295803
[2024-12-27 09:19:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.79124115653645
avg_train_sample_per_sec: 5.79124115653645
avg_episode_per_sec: 0.04670355771400363
collect_time: 107.0582252131254
reward_mean: -612.3714285714286
reward_std: 20.830628940116362
reward_max: -586.4285714285717
reward_min: -648.1428571428571
queue_len: 0.3798830202056009
wait_time: 2.6087114498404826
delay_time: 85.45543091398834
pressure: 5.313895781637717
total_envstep_count: 223200
total_train_sample_count: 223200
total_episode_count: 1800
total_duration: 47309.39767817116
[2024-12-27 09:21:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.676541212421275
avg_train_sample_per_sec: 5.676541212421275
avg_episode_per_sec: 0.0457785581646877
collect_time: 109.2214390416704
reward_mean: -600.7285714285715
reward_std: 12.871531631108022
reward_max: -587.7857142857143
reward_min: -624.0714285714289
queue_len: 0.37266040411201706
wait_time: 2.5729705778092873
delay_time: 84.35924349619236
pressure: 5.209305210918114
total_envstep_count: 223820
total_train_sample_count: 223820
total_episode_count: 1805
total_duration: 47418.61911721283
[2024-12-27 09:23:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.756812279806906
avg_train_sample_per_sec: 5.756812279806906
avg_episode_per_sec: 0.046425905482313755
collect_time: 107.69849178073181
reward_mean: -605.8714285714284
reward_std: 23.40327031046058
reward_max: -586.2142857142858
reward_min: -651.5714285714283
queue_len: 0.37585076214108465
wait_time: 2.614471818504076
delay_time: 84.70693473597498
pressure: 5.2575682382134
total_envstep_count: 224440
total_train_sample_count: 224440
total_episode_count: 1810
total_duration: 47526.317608993566
[2024-12-27 09:25:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.887454948466654
avg_train_sample_per_sec: 5.887454948466654
avg_episode_per_sec: 0.04747947539086011
collect_time: 105.30866145506127
reward_mean: -615.2285714285715
reward_std: 15.308954295857442
reward_max: -590.5714285714288
reward_min: -633.2142857142857
queue_len: 0.3816554413328607
wait_time: 2.6503278979085425
delay_time: 84.65345094087368
pressure: 5.335732009925559
total_envstep_count: 225060
total_train_sample_count: 225060
total_episode_count: 1815
total_duration: 47631.62627044863
[2024-12-27 09:27:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.415292298114736
avg_train_sample_per_sec: 5.415292298114736
avg_episode_per_sec: 0.043671712081570446
collect_time: 114.4905881102383
reward_mean: -678.3857142857144
reward_std: 146.93387795126074
reward_max: -589.2142857142856
reward_min: -968.2142857142862
queue_len: 0.4208348103509395
wait_time: 2.6864321162708267
delay_time: 95.12049023676896
pressure: 5.884863523573201
total_envstep_count: 225680
total_train_sample_count: 225680
total_episode_count: 1820
total_duration: 47746.11685855887
[2024-12-27 09:29:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.245983173196102
avg_train_sample_per_sec: 5.245983173196102
avg_episode_per_sec: 0.04230631591287179
collect_time: 118.1856631122716
reward_mean: -612.7
reward_std: 21.666366298284206
reward_max: -599.8571428571427
reward_min: -655.6428571428571
queue_len: 0.38008684863523584
wait_time: 2.672350230414747
delay_time: 85.43902028953843
pressure: 5.317245657568238
total_envstep_count: 226300
total_train_sample_count: 226300
total_episode_count: 1825
total_duration: 47864.30252167114
[2024-12-27 09:31:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.313912559516913
avg_train_sample_per_sec: 5.313912559516913
avg_episode_per_sec: 0.04285413354449123
collect_time: 116.67485925970226
reward_mean: -599.7
reward_std: 7.715396745390036
reward_max: -588.8571428571429
reward_min: -611.2857142857142
queue_len: 0.3720223325062034
wait_time: 2.6459677419354835
delay_time: 84.49095350774908
pressure: 5.203598014888337
total_envstep_count: 226920
total_train_sample_count: 226920
total_episode_count: 1830
total_duration: 47980.97738093084
[2024-12-27 09:33:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2018153269856455
avg_train_sample_per_sec: 5.2018153269856455
avg_episode_per_sec: 0.041950123604722944
collect_time: 119.18916013484824
reward_mean: -599.4428571428573
reward_std: 8.315881044785389
reward_max: -584.5000000000001
reward_min: -607.357142857143
queue_len: 0.3718628146047502
wait_time: 2.6398883374689825
delay_time: 84.14545842215041
pressure: 5.199379652605459
total_envstep_count: 227540
total_train_sample_count: 227540
total_episode_count: 1835
total_duration: 48100.166541065686
[2024-12-27 09:35:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.387401739831453
avg_train_sample_per_sec: 5.387401739831453
avg_episode_per_sec: 0.0434467882244472
collect_time: 115.08330544872211
reward_mean: -603.1571428571431
reward_std: 11.557787373870156
reward_max: -584.5714285714287
reward_min: -616.6428571428575
queue_len: 0.37416696207018796
wait_time: 2.653810705423608
delay_time: 85.0692947426263
pressure: 5.233498759305211
total_envstep_count: 228160
total_train_sample_count: 228160
total_episode_count: 1840
total_duration: 48215.24984651441
[2024-12-27 09:36:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.253853475936626
avg_train_sample_per_sec: 5.253853475936626
avg_episode_per_sec: 0.042369786096263115
collect_time: 118.0086203088239
reward_mean: -682.3857142857141
reward_std: 176.20568106850666
reward_max: -589.2142857142853
reward_min: -1034.5714285714282
queue_len: 0.42331619992910297
wait_time: 2.835076214108472
delay_time: 94.12507291907414
pressure: 5.828287841191067
total_envstep_count: 228780
total_train_sample_count: 228780
total_episode_count: 1845
total_duration: 48333.25846682323
[2024-12-27 09:38:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.354131242485006
avg_train_sample_per_sec: 5.354131242485006
avg_episode_per_sec: 0.04317847776197586
collect_time: 115.79843151402471
reward_mean: -602.7142857142856
reward_std: 8.85380121294602
reward_max: -590.5714285714288
reward_min: -616.3571428571425
queue_len: 0.3738922367954626
wait_time: 2.70126728110599
delay_time: 83.9743260185295
pressure: 5.22406947890819
total_envstep_count: 229400
total_train_sample_count: 229400
total_episode_count: 1850
total_duration: 48449.05689833726
[2024-12-27 09:40:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.184105212000912
avg_train_sample_per_sec: 5.184105212000912
avg_episode_per_sec: 0.04180730009678155
collect_time: 119.59633816164357
reward_mean: -604.8571428571429
reward_std: 8.3251524469711
reward_max: -596.1428571428575
reward_min: -616.0000000000001
queue_len: 0.3752215526409075
wait_time: 2.7073200992555826
delay_time: 83.63453963809243
pressure: 5.248883374689826
total_envstep_count: 230020
total_train_sample_count: 230020
total_episode_count: 1855
total_duration: 48568.6532364989
[2024-12-27 09:42:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.00528224535803
avg_train_sample_per_sec: 7.00528224535803
avg_episode_per_sec: 0.056494211656113145
collect_time: 88.50464239479228
reward_mean: -597.4285714285712
reward_std: 5.66784701592396
reward_max: -590.7142857142856
reward_min: -607.8571428571427
queue_len: 0.3706132577100318
wait_time: 2.700850762141085
delay_time: 83.18731631466062
pressure: 5.1808933002481385
total_envstep_count: 230640
total_train_sample_count: 230640
total_episode_count: 1860
total_duration: 48657.1578788937
[2024-12-27 09:44:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.265585714863455
avg_train_sample_per_sec: 5.265585714863455
avg_episode_per_sec: 0.04246440092631818
collect_time: 117.74568558439611
reward_mean: -595.7714285714287
reward_std: 6.414492519733209
reward_max: -589.7142857142858
reward_min: -607.5714285714286
queue_len: 0.3695852534562213
wait_time: 2.686981566820278
delay_time: 83.37391115749838
pressure: 5.16786600496278
total_envstep_count: 231260
total_train_sample_count: 231260
total_episode_count: 1865
total_duration: 48774.903564478096
[2024-12-27 09:46:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.211826754410905
avg_train_sample_per_sec: 5.211826754410905
avg_episode_per_sec: 0.04203086092266859
collect_time: 118.9602090045065
reward_mean: -604.5285714285715
reward_std: 13.290137512533224
reward_max: -588.3571428571428
reward_min: -628.0000000000001
queue_len: 0.3750177242112726
wait_time: 2.7197802197802203
delay_time: 84.06918265007172
pressure: 5.243300248138958
total_envstep_count: 231880
total_train_sample_count: 231880
total_episode_count: 1870
total_duration: 48893.863773482604
[2024-12-27 09:48:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.467456492612471
avg_train_sample_per_sec: 5.467456492612471
avg_episode_per_sec: 0.044092391069455415
collect_time: 113.39825032677129
reward_mean: -598.0428571428572
reward_std: 14.455180555702503
reward_max: -573.2142857142857
reward_min: -615.6428571428571
queue_len: 0.37099432825239276
wait_time: 2.664338886919532
delay_time: 83.8891357875527
pressure: 5.1853598014888345
total_envstep_count: 232500
total_train_sample_count: 232500
total_episode_count: 1875
total_duration: 49007.26202380937
[2024-12-27 09:50:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.775352043872122
avg_train_sample_per_sec: 5.775352043872122
avg_episode_per_sec: 0.04657541970864614
collect_time: 107.35276313724367
reward_mean: -604.9428571428571
reward_std: 10.927628343995101
reward_max: -593.5714285714287
reward_min: -623.7857142857138
queue_len: 0.3752747252747253
wait_time: 2.6895958879829847
delay_time: 84.32683457710637
pressure: 5.247270471464019
total_envstep_count: 233120
total_train_sample_count: 233120
total_episode_count: 1880
total_duration: 49114.614786946615
[2024-12-27 09:51:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.111930051416469
avg_train_sample_per_sec: 6.111930051416469
avg_episode_per_sec: 0.04928975847916508
collect_time: 101.44095151355863
reward_mean: -586.8999999999999
reward_std: 16.648748190976118
reward_max: -566.142857142857
reward_min: -613.4285714285716
queue_len: 0.36408188585607937
wait_time: 2.6137185395249913
delay_time: 82.84871472047409
pressure: 5.092803970223325
total_envstep_count: 233740
total_train_sample_count: 233740
total_episode_count: 1885
total_duration: 49216.05573846017
[2024-12-27 09:53:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.876951406514551
avg_train_sample_per_sec: 5.876951406514551
avg_episode_per_sec: 0.047394769407375414
collect_time: 105.49687365335967
reward_mean: -591.7142857142857
reward_std: 10.25202817166702
reward_max: -573.8571428571428
reward_min: -603.8571428571429
queue_len: 0.3670684154555122
wait_time: 2.652428216944346
delay_time: 82.17029125077241
pressure: 5.135732009925558
total_envstep_count: 234360
total_train_sample_count: 234360
total_episode_count: 1890
total_duration: 49321.55261211353
[2024-12-27 09:55:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.30893935991582
avg_train_sample_per_sec: 5.30893935991582
avg_episode_per_sec: 0.04281402709609533
collect_time: 116.78415554737676
reward_mean: -603.8000000000002
reward_std: 40.716826988359486
reward_max: -571.1428571428573
reward_min: -683.9285714285716
queue_len: 0.3745657568238214
wait_time: 2.660590216235378
delay_time: 84.37271031685324
pressure: 5.234491315136476
total_envstep_count: 234980
total_train_sample_count: 234980
total_episode_count: 1895
total_duration: 49438.33676766091
[2024-12-27 09:57:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.292710824222109
avg_train_sample_per_sec: 5.292710824222109
avg_episode_per_sec: 0.042683151808242815
collect_time: 117.14223969361181
reward_mean: -592.1428571428571
reward_std: 10.52072784011228
reward_max: -582.0714285714288
reward_min: -610.9285714285714
queue_len: 0.3673342786246012
wait_time: 2.661937256292095
delay_time: 82.49923577647239
pressure: 5.139330024813896
total_envstep_count: 235600
total_train_sample_count: 235600
total_episode_count: 1900
total_duration: 49555.47900735452
[2024-12-27 09:59:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.268263780683451
avg_train_sample_per_sec: 5.268263780683451
avg_episode_per_sec: 0.042485998231318156
collect_time: 117.68583081835881
reward_mean: -598.9428571428572
reward_std: 18.634584918962815
reward_max: -584.5714285714286
reward_min: -635.6428571428569
queue_len: 0.3715526409074796
wait_time: 2.6508862105636295
delay_time: 83.76307337079619
pressure: 5.197146401985112
total_envstep_count: 236220
total_train_sample_count: 236220
total_episode_count: 1905
total_duration: 49673.16483817288
[2024-12-27 10:01:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.55253232065702
avg_train_sample_per_sec: 5.55253232065702
avg_episode_per_sec: 0.04477848645691145
collect_time: 111.66076380923013
reward_mean: -581.8999999999999
reward_std: 21.4225039028911
reward_max: -560.7857142857143
reward_min: -610.5714285714283
queue_len: 0.3609801488833747
wait_time: 2.6139755405884437
delay_time: 81.70740714203842
pressure: 5.052109181141439
total_envstep_count: 236840
total_train_sample_count: 236840
total_episode_count: 1910
total_duration: 49784.82560198211
[2024-12-27 10:03:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.404944880728589
avg_train_sample_per_sec: 5.404944880728589
avg_episode_per_sec: 0.043588265167166046
collect_time: 114.70977293600517
reward_mean: -586.1714285714286
reward_std: 13.65968296760612
reward_max: -563.3571428571428
reward_min: -602.2857142857141
queue_len: 0.36362991846862813
wait_time: 2.6154643743353416
delay_time: 82.34474895593851
pressure: 5.088213399503722
total_envstep_count: 237460
total_train_sample_count: 237460
total_episode_count: 1915
total_duration: 49899.535374918116
[2024-12-27 10:05:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.435781976692607
avg_train_sample_per_sec: 5.435781976692607
avg_episode_per_sec: 0.04383695142494038
collect_time: 114.05902640290184
reward_mean: -574.6428571428572
reward_std: 9.412648893041414
reward_max: -567.7142857142857
reward_min: -593.0714285714287
queue_len: 0.35647819922013474
wait_time: 2.579927330733782
delay_time: 81.87481671514703
pressure: 4.987841191066998
total_envstep_count: 238080
total_train_sample_count: 238080
total_episode_count: 1920
total_duration: 50013.59440132102
[2024-12-27 10:07:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.214078975628246
avg_train_sample_per_sec: 5.214078975628246
avg_episode_per_sec: 0.042049023997001986
collect_time: 118.90882414670291
reward_mean: -582.3428571428572
reward_std: 14.55674330027872
reward_max: -559.285714285714
reward_min: -600.0714285714288
queue_len: 0.36125487415810004
wait_time: 2.6073821339950376
delay_time: 82.48435108178549
pressure: 5.049627791563276
total_envstep_count: 238700
total_train_sample_count: 238700
total_episode_count: 1925
total_duration: 50132.50322546772
[2024-12-27 10:09:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.27909056680547
avg_train_sample_per_sec: 5.27909056680547
avg_episode_per_sec: 0.04257331102262476
collect_time: 117.44447119329871
reward_mean: -584.4285714285714
reward_std: 5.771852883978085
reward_max: -575.2857142857142
reward_min: -591.0000000000001
queue_len: 0.3625487415809997
wait_time: 2.6301843317972358
delay_time: 82.83641271555537
pressure: 5.066253101736973
total_envstep_count: 239320
total_train_sample_count: 239320
total_episode_count: 1930
total_duration: 50249.94769666102
[2024-12-27 10:11:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.531900960221513
avg_train_sample_per_sec: 5.531900960221513
avg_episode_per_sec: 0.04461210451791543
collect_time: 112.07720536905154
reward_mean: -579.8285714285714
reward_std: 15.994935422929155
reward_max: -561.4999999999999
reward_min: -607.5714285714287
queue_len: 0.35969514356611126
wait_time: 2.5830290677064878
delay_time: 82.05088805131159
pressure: 5.028535980148884
total_envstep_count: 239940
total_train_sample_count: 239940
total_episode_count: 1935
total_duration: 50362.02490203007
[2024-12-27 10:12:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.330747434648211
avg_train_sample_per_sec: 5.330747434648211
avg_episode_per_sec: 0.04298989866651783
collect_time: 116.30639185233042
reward_mean: -578.9142857142857
reward_std: 10.395289357027465
reward_max: -570.785714285714
reward_min: -598.2142857142858
queue_len: 0.3591279688053881
wait_time: 2.5861662531017364
delay_time: 82.2228775581987
pressure: 5.017617866004963
total_envstep_count: 240560
total_train_sample_count: 240560
total_episode_count: 1940
total_duration: 50478.3312938824
[2024-12-27 10:14:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.541018479934726
avg_train_sample_per_sec: 5.541018479934726
avg_episode_per_sec: 0.044685632902699404
collect_time: 111.89278690283373
reward_mean: -581.1142857142856
reward_std: 7.963257460848165
reward_max: -574.2857142857144
reward_min: -596.642857142857
queue_len: 0.36049273307337826
wait_time: 2.5939471818504076
delay_time: 83.09323963560954
pressure: 5.040074441687344
total_envstep_count: 241180
total_train_sample_count: 241180
total_episode_count: 1945
total_duration: 50590.224080785236
[2024-12-27 10:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.495963343726315
avg_train_sample_per_sec: 5.495963343726315
avg_episode_per_sec: 0.04432228503005093
collect_time: 112.81006826723741
reward_mean: -755.0142857142856
reward_std: 369.8772670130745
reward_max: -552.142857142857
reward_min: -1494.2857142857142
queue_len: 0.4683711449840482
wait_time: 2.8538638780574264
delay_time: 110.93944547381727
pressure: 6.487841191066996
total_envstep_count: 241800
total_train_sample_count: 241800
total_episode_count: 1950
total_duration: 50703.03414905247
[2024-12-27 10:18:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.453954164477824
avg_train_sample_per_sec: 5.453954164477824
avg_episode_per_sec: 0.04398350132643406
collect_time: 113.67898983055727
reward_mean: -587.6857142857142
reward_std: 3.642324891088925
reward_max: -582.8571428571427
reward_min: -591.6428571428571
queue_len: 0.3645693016660759
wait_time: 2.6449397376816735
delay_time: 82.35325877146815
pressure: 5.099875930521092
total_envstep_count: 242420
total_train_sample_count: 242420
total_episode_count: 1955
total_duration: 50816.71313888303
[2024-12-27 10:20:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.756941750098866
avg_train_sample_per_sec: 5.756941750098866
avg_episode_per_sec: 0.046426949597571494
collect_time: 107.69606970391051
reward_mean: -574.8857142857142
reward_std: 12.218303432781017
reward_max: -553.2857142857144
reward_min: -588.0000000000001
queue_len: 0.35662885501595176
wait_time: 2.5688408365827726
delay_time: 81.16144749312782
pressure: 4.991191066997518
total_envstep_count: 243040
total_train_sample_count: 243040
total_episode_count: 1960
total_duration: 50924.40920858694
[2024-12-27 10:22:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.800450848649648
avg_train_sample_per_sec: 5.800450848649648
avg_episode_per_sec: 0.04677782942459393
collect_time: 106.88824303102867
reward_mean: -575.0285714285714
reward_std: 8.291205077228085
reward_max: -568.5714285714287
reward_min: -590.2142857142857
queue_len: 0.35671747607231474
wait_time: 2.55225097483162
delay_time: 81.97329243700082
pressure: 4.987965260545905
total_envstep_count: 243660
total_train_sample_count: 243660
total_episode_count: 1965
total_duration: 51031.29745161797
[2024-12-27 10:24:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.716974845127683
avg_train_sample_per_sec: 5.716974845127683
avg_episode_per_sec: 0.046104635847803895
collect_time: 108.44896414550394
reward_mean: -580.6000000000001
reward_std: 12.162387654954525
reward_max: -564.7142857142853
reward_min: -601.5
queue_len: 0.3601736972704715
wait_time: 2.597704714640199
delay_time: 82.01812504309775
pressure: 5.038957816377172
total_envstep_count: 244280
total_train_sample_count: 244280
total_episode_count: 1970
total_duration: 51139.746415763475
[2024-12-27 10:25:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.784397046360052
avg_train_sample_per_sec: 5.784397046360052
avg_episode_per_sec: 0.0466483632770972
collect_time: 107.18489671972767
reward_mean: -581.0714285714287
reward_std: 6.484675813652124
reward_max: -575.4285714285714
reward_min: -593.3571428571431
queue_len: 0.3604661467564694
wait_time: 2.5649060616802553
delay_time: 81.58348678108307
pressure: 5.043300248138958
total_envstep_count: 244900
total_train_sample_count: 244900
total_episode_count: 1975
total_duration: 51246.931312483204
[2024-12-27 10:27:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.292009437125001
avg_train_sample_per_sec: 6.292009437125001
avg_episode_per_sec: 0.05074201158971775
collect_time: 98.53767801773922
reward_mean: -580.9857142857143
reward_std: 11.445647956444247
reward_max: -565.2142857142858
reward_min: -600.142857142857
queue_len: 0.3604129741226515
wait_time: 2.5276320453739816
delay_time: 82.36244389014882
pressure: 5.043920595533499
total_envstep_count: 245520
total_train_sample_count: 245520
total_episode_count: 1980
total_duration: 51345.46899050094
[2024-12-27 10:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.800698382835218
avg_train_sample_per_sec: 5.800698382835218
avg_episode_per_sec: 0.04677982566802596
collect_time: 106.88368177091142
reward_mean: -576.4285714285713
reward_std: 8.892555932936672
reward_max: -566.3571428571428
reward_min: -589.7142857142857
queue_len: 0.35758596242467205
wait_time: 2.545763913505848
delay_time: 81.07950834074546
pressure: 5.00347394540943
total_envstep_count: 246140
total_train_sample_count: 246140
total_episode_count: 1985
total_duration: 51452.35267227185
[2024-12-27 10:31:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.974538600367848
avg_train_sample_per_sec: 5.974538600367848
avg_episode_per_sec: 0.04818176290619232
collect_time: 103.77370395796373
reward_mean: -567.1000000000001
reward_std: 11.134300744151954
reward_max: -552.5000000000001
reward_min: -583.5714285714286
queue_len: 0.3517990074441688
wait_time: 2.5299805033675997
delay_time: 80.98317879149134
pressure: 4.918982630272952
total_envstep_count: 246760
total_train_sample_count: 246760
total_episode_count: 1990
total_duration: 51556.12637622982
[2024-12-27 10:32:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.902197474324958
avg_train_sample_per_sec: 5.902197474324958
avg_episode_per_sec: 0.047598366728427086
collect_time: 105.0456211770363
reward_mean: -572.7857142857143
reward_std: 7.238220550293656
reward_max: -564.8571428571429
reward_min: -584.4285714285714
queue_len: 0.3553261254874158
wait_time: 2.556566820276497
delay_time: 80.98282654251639
pressure: 4.972828784119107
total_envstep_count: 247380
total_train_sample_count: 247380
total_episode_count: 1995
total_duration: 51661.171997406855
[2024-12-27 10:34:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.617269354978858
avg_train_sample_per_sec: 7.617269354978858
avg_episode_per_sec: 0.061429591572410146
collect_time: 81.39399712769128
reward_mean: -570.8
reward_std: 11.800415073986544
reward_max: -556.5
reward_min: -588.6428571428571
queue_len: 0.3540942928039702
wait_time: 2.5249113789436377
delay_time: 80.77088423649535
pressure: 4.954218362282878
total_envstep_count: 248000
total_train_sample_count: 248000
total_episode_count: 2000
total_duration: 51742.56599453455
[2024-12-27 10:36:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.494311580136255
avg_train_sample_per_sec: 5.494311580136255
avg_episode_per_sec: 0.04430896435593754
collect_time: 112.84398253668468
reward_mean: -569.9714285714285
reward_std: 11.848241064670043
reward_max: -556.2857142857142
reward_min: -587.0000000000001
queue_len: 0.3535802906770648
wait_time: 2.513124778447359
delay_time: 80.71798698301471
pressure: 4.948511166253102
total_envstep_count: 248620
total_train_sample_count: 248620
total_episode_count: 2005
total_duration: 51855.409977071235
[2024-12-27 10:37:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.905230226338934
avg_train_sample_per_sec: 5.905230226338934
avg_episode_per_sec: 0.04762282440595915
collect_time: 104.99167284530775
reward_mean: -571.6142857142856
reward_std: 12.209781959978006
reward_max: -555.8571428571427
reward_min: -589.3571428571425
queue_len: 0.3545994328252392
wait_time: 2.5538461538461545
delay_time: 79.98019202678793
pressure: 4.962406947890818
total_envstep_count: 249240
total_train_sample_count: 249240
total_episode_count: 2010
total_duration: 51960.401649916545
[2024-12-27 10:39:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.974613531494557
avg_train_sample_per_sec: 6.974613531494557
avg_episode_per_sec: 0.05624688331850449
collect_time: 88.89381428810768
reward_mean: -578.4
reward_std: 11.891224684186138
reward_max: -558.0000000000001
reward_min: -594.4285714285717
queue_len: 0.35880893300248146
wait_time: 2.559438142502659
delay_time: 81.59582240980384
pressure: 5.020471464019852
total_envstep_count: 249860
total_train_sample_count: 249860
total_episode_count: 2015
total_duration: 52049.29546420465
[2024-12-27 10:41:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8793526216263565
avg_train_sample_per_sec: 5.8793526216263565
avg_episode_per_sec: 0.04741413404537384
collect_time: 105.4537871600725
reward_mean: -571.8
reward_std: 9.50675377544493
reward_max: -554.714285714286
reward_min: -582.4285714285712
queue_len: 0.3547146401985112
wait_time: 2.4820099255583132
delay_time: 80.16623357790165
pressure: 4.964143920595533
total_envstep_count: 250480
total_train_sample_count: 250480
total_episode_count: 2020
total_duration: 52154.74925136472
[2024-12-27 10:42:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.943181645459938
avg_train_sample_per_sec: 5.943181645459938
avg_episode_per_sec: 0.04792888423758015
collect_time: 104.32122674117235
reward_mean: -563.3714285714285
reward_std: 10.48627869247838
reward_max: -548.8571428571429
reward_min: -576.8571428571428
queue_len: 0.3494859978730946
wait_time: 2.4858472172988293
delay_time: 79.71462404871058
pressure: 4.887344913151365
total_envstep_count: 251100
total_train_sample_count: 251100
total_episode_count: 2025
total_duration: 52259.070478105896
[2024-12-27 10:44:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.003919639094742
avg_train_sample_per_sec: 6.003919639094742
avg_episode_per_sec: 0.04841870676689308
collect_time: 103.26587250816073
reward_mean: -571.8857142857141
reward_std: 12.865600392884422
reward_max: -547.3571428571428
reward_min: -582.0714285714286
queue_len: 0.35476781283232894
wait_time: 2.518468628146047
delay_time: 80.63881262246218
pressure: 4.9645161290322575
total_envstep_count: 251720
total_train_sample_count: 251720
total_episode_count: 2030
total_duration: 52362.33635061406
[2024-12-27 10:46:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.61569472604755
avg_train_sample_per_sec: 5.61569472604755
avg_episode_per_sec: 0.045287860693931856
collect_time: 110.40486177502204
reward_mean: -567.557142857143
reward_std: 10.423129695684644
reward_max: -557.4285714285716
reward_min: -586.2857142857147
queue_len: 0.3520825948245304
wait_time: 2.4707284650833046
delay_time: 79.4968952515299
pressure: 4.9275434243176175
total_envstep_count: 252340
total_train_sample_count: 252340
total_episode_count: 2035
total_duration: 52472.74121238908
[2024-12-27 10:48:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7407983816407215
avg_train_sample_per_sec: 5.7407983816407215
avg_episode_per_sec: 0.04629676114226388
collect_time: 107.99891561821474
reward_mean: -571.0
reward_std: 15.313259560503264
reward_max: -551.2857142857146
reward_min: -591.9285714285712
queue_len: 0.3542183622828784
wait_time: 2.5214728819567527
delay_time: 80.45543892183271
pressure: 4.956947890818858
total_envstep_count: 252960
total_train_sample_count: 252960
total_episode_count: 2040
total_duration: 52580.740128007295
[2024-12-27 10:50:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.592946878071089
avg_train_sample_per_sec: 5.592946878071089
avg_episode_per_sec: 0.04510441030702492
collect_time: 110.85390466176344
reward_mean: -735.9428571428572
reward_std: 339.3651227374618
reward_max: -548.2142857142854
reward_min: -1414.3571428571436
queue_len: 0.4565402339595888
wait_time: 2.779891882311237
delay_time: 107.69756324405537
pressure: 6.310794044665012
total_envstep_count: 253580
total_train_sample_count: 253580
total_episode_count: 2045
total_duration: 52691.59403266906
[2024-12-27 10:51:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.737257386441306
avg_train_sample_per_sec: 5.737257386441306
avg_episode_per_sec: 0.046268204729365374
collect_time: 108.06557179484888
reward_mean: -579.8142857142857
reward_std: 31.544286975874563
reward_max: -546.5714285714283
reward_min: -638.2142857142858
queue_len: 0.359686281460475
wait_time: 2.62684331797235
delay_time: 81.2097113648118
pressure: 5.0321339950372215
total_envstep_count: 254200
total_train_sample_count: 254200
total_episode_count: 2050
total_duration: 52799.65960446391
[2024-12-27 10:53:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3708781903570095
avg_train_sample_per_sec: 5.3708781903570095
avg_episode_per_sec: 0.04331353379320169
collect_time: 115.43736015334724
reward_mean: -564.5714285714286
reward_std: 11.164265149418945
reward_max: -550.6428571428572
reward_min: -577.7857142857143
queue_len: 0.3502304147465437
wait_time: 2.5202764976958525
delay_time: 79.84523518063773
pressure: 4.900372208436724
total_envstep_count: 254820
total_train_sample_count: 254820
total_episode_count: 2055
total_duration: 52915.09696461725
[2024-12-27 10:55:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.225828105230933
avg_train_sample_per_sec: 5.225828105230933
avg_episode_per_sec: 0.042143775042184944
collect_time: 118.64148370655252
reward_mean: -555.2571428571426
reward_std: 11.09629465641747
reward_max: -544.9999999999998
reward_min: -574.5714285714282
queue_len: 0.34445232187167657
wait_time: 2.4954094292803974
delay_time: 78.55737555224769
pressure: 4.817493796526055
total_envstep_count: 255440
total_train_sample_count: 255440
total_episode_count: 2060
total_duration: 53033.738448323806
[2024-12-27 10:57:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.276104426567195
avg_train_sample_per_sec: 5.276104426567195
avg_episode_per_sec: 0.04254922924650964
collect_time: 117.51094176189233
reward_mean: -560.3571428571429
reward_std: 10.650189228940686
reward_max: -546.8571428571429
reward_min: -572.9285714285716
queue_len: 0.3476160935838356
wait_time: 2.4845976604041113
delay_time: 79.92007118892211
pressure: 4.860794044665012
total_envstep_count: 256060
total_train_sample_count: 256060
total_episode_count: 2065
total_duration: 53151.2493900857
[2024-12-27 10:59:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.507622866927305
avg_train_sample_per_sec: 5.507622866927305
avg_episode_per_sec: 0.04441631344296213
collect_time: 112.57125169608739
reward_mean: -569.8857142857144
reward_std: 9.738163930366715
reward_max: -551.9285714285714
reward_min: -578.0000000000002
queue_len: 0.3535271180432472
wait_time: 2.5328252392768524
delay_time: 79.80513360386138
pressure: 4.946277915632755
total_envstep_count: 256680
total_train_sample_count: 256680
total_episode_count: 2070
total_duration: 53263.820641781786
[2024-12-27 11:01:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.714251835093678
avg_train_sample_per_sec: 5.714251835093678
avg_episode_per_sec: 0.04608267608946515
collect_time: 108.50064328497274
reward_mean: -560.2857142857143
reward_std: 18.5914726996777
reward_max: -534.2857142857141
reward_min: -579.3571428571431
queue_len: 0.34757178305565406
wait_time: 2.5427507975895067
delay_time: 78.83495878202861
pressure: 4.862655086848635
total_envstep_count: 257300
total_train_sample_count: 257300
total_episode_count: 2075
total_duration: 53372.321285066755
[2024-12-27 11:03:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.54245926543633
avg_train_sample_per_sec: 5.54245926543633
avg_episode_per_sec: 0.04469725214061556
collect_time: 111.86369990419597
reward_mean: -569.5285714285714
reward_std: 10.499426612138103
reward_max: -558.2142857142857
reward_min: -587.4285714285714
queue_len: 0.3533055654023396
wait_time: 2.5356788372917403
delay_time: 80.67900570102441
pressure: 4.942183622828784
total_envstep_count: 257920
total_train_sample_count: 257920
total_episode_count: 2080
total_duration: 53484.184984970954
[2024-12-27 11:05:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.570652453505313
avg_train_sample_per_sec: 5.570652453505313
avg_episode_per_sec: 0.044924616560526716
collect_time: 111.29755538956074
reward_mean: -562.8428571428572
reward_std: 13.646065441760642
reward_max: -546.6428571428573
reward_min: -580.2857142857142
queue_len: 0.3491580999645516
wait_time: 2.4800159517901457
delay_time: 80.3609398571038
pressure: 4.883995037220844
total_envstep_count: 258540
total_train_sample_count: 258540
total_episode_count: 2085
total_duration: 53595.482540360514
[2024-12-27 11:07:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.385419824478499
avg_train_sample_per_sec: 5.385419824478499
avg_episode_per_sec: 0.04343080503611693
collect_time: 115.12565783300619
reward_mean: -568.2571428571428
reward_std: 7.020320360153324
reward_max: -560.7857142857143
reward_min: -576.9285714285713
queue_len: 0.352516838000709
wait_time: 2.534766040411202
delay_time: 80.53712195913741
pressure: 4.931017369727047
total_envstep_count: 259160
total_train_sample_count: 259160
total_episode_count: 2090
total_duration: 53710.60819819352
[2024-12-27 11:09:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.359603358721321
avg_train_sample_per_sec: 5.359603358721321
avg_episode_per_sec: 0.04322260773162356
collect_time: 115.68020215360076
reward_mean: -571.4285714285713
reward_std: 7.968560672020632
reward_max: -557.4285714285714
reward_min: -580.0714285714288
queue_len: 0.35448422545196734
wait_time: 2.5393743353420772
delay_time: 80.9299402710955
pressure: 4.957071960297766
total_envstep_count: 259780
total_train_sample_count: 259780
total_episode_count: 2095
total_duration: 53826.28840034712
[2024-12-27 11:11:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5231807618042925
avg_train_sample_per_sec: 5.5231807618042925
avg_episode_per_sec: 0.04454178033713139
collect_time: 112.25415693211183
reward_mean: -569.4857142857143
reward_std: 10.439368187934713
reward_max: -550.9285714285716
reward_min: -580.9285714285713
queue_len: 0.3532789790854307
wait_time: 2.4897642679900747
delay_time: 80.37269834081475
pressure: 4.944789081885856
total_envstep_count: 260400
total_train_sample_count: 260400
total_episode_count: 2100
total_duration: 53938.54255727923
[2024-12-27 11:12:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.381609421809524
avg_train_sample_per_sec: 5.381609421809524
avg_episode_per_sec: 0.043400075982334876
collect_time: 115.20717157350482
reward_mean: -579.2142857142857
reward_std: 25.245731100039595
reward_max: -559.5
reward_min: -621.4999999999999
queue_len: 0.3593140730237504
wait_time: 2.527286423254165
delay_time: 81.90184850338146
pressure: 5.020347394540943
total_envstep_count: 261020
total_train_sample_count: 261020
total_episode_count: 2105
total_duration: 54053.74972885274
[2024-12-27 11:14:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.411775494796345
avg_train_sample_per_sec: 5.411775494796345
avg_episode_per_sec: 0.04364335076448665
collect_time: 114.56498899412156
reward_mean: -575.2571428571428
reward_std: 6.363415845635748
reward_max: -566.3571428571429
reward_min: -584.2142857142854
queue_len: 0.3568592697624955
wait_time: 2.495054945054945
delay_time: 81.44614408058753
pressure: 4.993300248138958
total_envstep_count: 261640
total_train_sample_count: 261640
total_episode_count: 2110
total_duration: 54168.31471784686
[2024-12-27 11:16:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.293753906325903
avg_train_sample_per_sec: 5.293753906325903
avg_episode_per_sec: 0.04269156376069277
collect_time: 117.11915796824547
reward_mean: -560.3857142857142
reward_std: 8.792923871163696
reward_max: -550.4285714285714
reward_min: -576.142857142857
queue_len: 0.34763381779510816
wait_time: 2.4743264799716416
delay_time: 79.96546289894073
pressure: 4.862903225806452
total_envstep_count: 262260
total_train_sample_count: 262260
total_episode_count: 2115
total_duration: 54285.433875815106
[2024-12-27 11:18:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.38749403242435
avg_train_sample_per_sec: 5.38749403242435
avg_episode_per_sec: 0.043447532519551205
collect_time: 115.08133396873623
reward_mean: -571.0857142857142
reward_std: 8.389911337129643
reward_max: -559.642857142857
reward_min: -583.7142857142853
queue_len: 0.3542715349166961
wait_time: 2.490047855370436
delay_time: 80.8479688756195
pressure: 4.95347394540943
total_envstep_count: 262880
total_train_sample_count: 262880
total_episode_count: 2120
total_duration: 54400.51520978384
[2024-12-27 11:20:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.558938540478405
avg_train_sample_per_sec: 5.558938540478405
avg_episode_per_sec: 0.044830149519987136
collect_time: 111.53208395548164
reward_mean: -568.5142857142858
reward_std: 8.90441303110835
reward_max: -556.0714285714286
reward_min: -581.0000000000003
queue_len: 0.35267635590216245
wait_time: 2.4836937256292093
delay_time: 80.70285480590675
pressure: 4.933995037220844
total_envstep_count: 263500
total_train_sample_count: 263500
total_episode_count: 2125
total_duration: 54512.04729373933
[2024-12-27 11:22:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.328263366467235
avg_train_sample_per_sec: 5.328263366467235
avg_episode_per_sec: 0.04296986585860674
collect_time: 116.36061458633841
reward_mean: -556.5285714285715
reward_std: 6.421043211065308
reward_max: -547.5
reward_min: -567.0714285714287
queue_len: 0.34524104927330734
wait_time: 2.4595179014533857
delay_time: 79.27265981398338
pressure: 4.830024813895781
total_envstep_count: 264120
total_train_sample_count: 264120
total_episode_count: 2130
total_duration: 54628.407908325666
[2024-12-27 11:24:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.278219091572174
avg_train_sample_per_sec: 5.278219091572174
avg_episode_per_sec: 0.04256628299654979
collect_time: 117.46386219358817
reward_mean: -562.9428571428572
reward_std: 7.59838865839867
reward_max: -554.3571428571429
reward_min: -575.0714285714286
queue_len: 0.3492201347040057
wait_time: 2.4646667848280748
delay_time: 81.08234618654201
pressure: 4.8847394540942926
total_envstep_count: 264740
total_train_sample_count: 264740
total_episode_count: 2135
total_duration: 54745.871770519254
[2024-12-27 11:26:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.264892036949992
avg_train_sample_per_sec: 5.264892036949992
avg_episode_per_sec: 0.04245880674959671
collect_time: 117.76119921334086
reward_mean: -571.342857142857
reward_std: 16.91861672350112
reward_max: -555.1428571428571
reward_min: -602.3571428571427
queue_len: 0.35443105281814963
wait_time: 2.514267990074442
delay_time: 81.42136387623194
pressure: 4.955459057071961
total_envstep_count: 265360
total_train_sample_count: 265360
total_episode_count: 2140
total_duration: 54863.63296973259
[2024-12-27 11:28:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.202309290452313
avg_train_sample_per_sec: 5.202309290452313
avg_episode_per_sec: 0.04195410718106705
collect_time: 119.17784302787854
reward_mean: -568.5857142857142
reward_std: 11.096828007891903
reward_max: -556.2142857142858
reward_min: -587.7857142857142
queue_len: 0.35272066643034383
wait_time: 2.542803970223325
delay_time: 80.29389675874731
pressure: 4.930521091811414
total_envstep_count: 265980
total_train_sample_count: 265980
total_episode_count: 2145
total_duration: 54982.81081276047
[2024-12-27 11:30:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.207082997684642
avg_train_sample_per_sec: 5.207082997684642
avg_episode_per_sec: 0.04199260482003744
collect_time: 119.06858413351321
reward_mean: -563.9857142857142
reward_std: 13.722794979187528
reward_max: -542.4285714285713
reward_min: -582.7142857142854
queue_len: 0.3498670684154555
wait_time: 2.453757532789791
delay_time: 81.36930693738142
pressure: 4.89106699751861
total_envstep_count: 266600
total_train_sample_count: 266600
total_episode_count: 2150
total_duration: 55101.879396893986
[2024-12-27 11:32:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3554408334174495
avg_train_sample_per_sec: 5.3554408334174495
avg_episode_per_sec: 0.04318903897917298
collect_time: 115.77011478331681
reward_mean: -555.942857142857
reward_std: 11.072433134149131
reward_max: -542.2857142857143
reward_min: -569.8571428571428
queue_len: 0.344877702942219
wait_time: 2.447314781992201
delay_time: 79.62336233172762
pressure: 4.824069478908188
total_envstep_count: 267220
total_train_sample_count: 267220
total_episode_count: 2155
total_duration: 55217.6495116773
[2024-12-27 11:34:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.180122322243104
avg_train_sample_per_sec: 5.180122322243104
avg_episode_per_sec: 0.041775180018089546
collect_time: 119.68829333194718
reward_mean: -568.2285714285714
reward_std: 7.9098749957871295
reward_max: -556.357142857143
reward_min: -578.8571428571427
queue_len: 0.3524991137894363
wait_time: 2.5098280751506556
delay_time: 81.42746966393835
pressure: 4.930521091811415
total_envstep_count: 267840
total_train_sample_count: 267840
total_episode_count: 2160
total_duration: 55337.33780500925
[2024-12-27 11:36:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.412429672544169
avg_train_sample_per_sec: 5.412429672544169
avg_episode_per_sec: 0.043648626391485236
collect_time: 114.55114200284149
reward_mean: -556.9857142857142
reward_std: 10.380063308367394
reward_max: -539.2857142857142
reward_min: -568.7857142857143
queue_len: 0.3455246366536689
wait_time: 2.424432825239277
delay_time: 80.34322258960715
pressure: 4.832258064516129
total_envstep_count: 268460
total_train_sample_count: 268460
total_episode_count: 2165
total_duration: 55451.88894701209
[2024-12-27 11:38:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.472209390488977
avg_train_sample_per_sec: 5.472209390488977
avg_episode_per_sec: 0.044130720891040136
collect_time: 113.2997580607198
reward_mean: -566.1428571428571
reward_std: 12.826948672419958
reward_max: -549.5
reward_min: -584.3571428571425
queue_len: 0.3512052463665366
wait_time: 2.4544044665012406
delay_time: 80.62146519784679
pressure: 4.911166253101736
total_envstep_count: 269080
total_train_sample_count: 269080
total_episode_count: 2170
total_duration: 55565.18870507281
[2024-12-27 11:40:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.142684821552487
avg_train_sample_per_sec: 5.142684821552487
avg_episode_per_sec: 0.04147326468993942
collect_time: 120.55959513630717
reward_mean: -590.8571428571428
reward_std: 61.04043490898108
reward_max: -548.9285714285713
reward_min: -711.9285714285714
queue_len: 0.3665366891173342
wait_time: 2.544337114498405
delay_time: 83.11242004233057
pressure: 5.171215880893301
total_envstep_count: 269700
total_train_sample_count: 269700
total_episode_count: 2175
total_duration: 55685.74830020912
[2024-12-27 11:42:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.333157025716971
avg_train_sample_per_sec: 5.333157025716971
avg_episode_per_sec: 0.04300933085255621
collect_time: 116.25384308211878
reward_mean: -570.4285714285714
reward_std: 4.675817073637985
reward_max: -562.4285714285712
reward_min: -576.8571428571435
queue_len: 0.3538638780574265
wait_time: 2.4812211981566827
delay_time: 81.4145663183654
pressure: 4.94727047146402
total_envstep_count: 270320
total_train_sample_count: 270320
total_episode_count: 2180
total_duration: 55802.00214329124
[2024-12-27 11:44:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.381853896032546
avg_train_sample_per_sec: 5.381853896032546
avg_episode_per_sec: 0.04340204754864957
collect_time: 115.20193821260334
reward_mean: -586.3
reward_std: 41.74566823427945
reward_max: -558.4285714285718
reward_min: -668.5
queue_len: 0.36370967741935484
wait_time: 2.501107763204538
delay_time: 84.21720937493555
pressure: 5.061910669975186
total_envstep_count: 270940
total_train_sample_count: 270940
total_episode_count: 2185
total_duration: 55917.20408150384
[2024-12-27 11:46:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.68016516175104
avg_train_sample_per_sec: 5.68016516175104
avg_episode_per_sec: 0.045807783562508385
collect_time: 109.15175568748268
reward_mean: -555.6285714285713
reward_std: 13.342765371357636
reward_max: -540.5
reward_min: -579.142857142857
queue_len: 0.3446827366182204
wait_time: 2.3878943637008154
delay_time: 80.37235470671234
pressure: 4.815880893300248
total_envstep_count: 271560
total_train_sample_count: 271560
total_episode_count: 2190
total_duration: 56026.355837191324
[2024-12-27 11:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.137150796974406
avg_train_sample_per_sec: 5.137150796974406
avg_episode_per_sec: 0.041428635459471015
collect_time: 120.68946863797679
reward_mean: -570.5
reward_std: 25.73590361137281
reward_max: -546.0714285714287
reward_min: -618.4285714285712
queue_len: 0.35390818858560785
wait_time: 2.4734136830911027
delay_time: 80.94471766392954
pressure: 4.953722084367246
total_envstep_count: 272180
total_train_sample_count: 272180
total_episode_count: 2195
total_duration: 56147.0453058293
[2024-12-27 11:50:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.215136183208218
avg_train_sample_per_sec: 5.215136183208218
avg_episode_per_sec: 0.0420575498645824
collect_time: 118.88471905993296
reward_mean: -561.5714285714287
reward_std: 12.041340355251913
reward_max: -543.2857142857146
reward_min: -579.2142857142858
queue_len: 0.34836937256292105
wait_time: 2.4354838709677415
delay_time: 80.23669563320185
pressure: 4.870719602977668
total_envstep_count: 272800
total_train_sample_count: 272800
total_episode_count: 2200
total_duration: 56265.93002488923
[2024-12-27 11:52:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1354006401260355
avg_train_sample_per_sec: 5.1354006401260355
avg_episode_per_sec: 0.04141452129133899
collect_time: 120.73059989819679
reward_mean: -550.6
reward_std: 11.014887884224732
reward_max: -540.7142857142857
reward_min: -566.7857142857144
queue_len: 0.3415632754342432
wait_time: 2.3803704360155975
delay_time: 79.26938727645056
pressure: 4.778039702233251
total_envstep_count: 273420
total_train_sample_count: 273420
total_episode_count: 2205
total_duration: 56386.66062478743
[2024-12-27 11:54:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.178427346921672
avg_train_sample_per_sec: 5.178427346921672
avg_episode_per_sec: 0.04176151086227155
collect_time: 119.72746906810625
reward_mean: -570.0285714285716
reward_std: 6.7107285410020205
reward_max: -558.2857142857146
reward_min: -578.4285714285714
queue_len: 0.35361573909961014
wait_time: 2.45931407302375
delay_time: 81.19639210813367
pressure: 4.9467741935483875
total_envstep_count: 274040
total_train_sample_count: 274040
total_episode_count: 2210
total_duration: 56506.38809385554
[2024-12-27 11:56:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.266660107817311
avg_train_sample_per_sec: 5.266660107817311
avg_episode_per_sec: 0.04247306538562348
collect_time: 117.72166559215262
reward_mean: -574.8571428571428
reward_std: 22.271973786050786
reward_max: -543.7142857142856
reward_min: -600.1428571428572
queue_len: 0.35661113080467916
wait_time: 2.4544221907125134
delay_time: 81.74105240560091
pressure: 4.98833746898263
total_envstep_count: 274660
total_train_sample_count: 274660
total_episode_count: 2215
total_duration: 56624.10975944769
[2024-12-27 11:58:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.434978830193995
avg_train_sample_per_sec: 5.434978830193995
avg_episode_per_sec: 0.04383047443704835
collect_time: 114.0758813181743
reward_mean: -555.5285714285714
reward_std: 5.706530451677001
reward_max: -549.0714285714284
reward_min: -562.0714285714284
queue_len: 0.34462070187876637
wait_time: 2.4188053881602274
delay_time: 79.61196796725831
pressure: 4.821588089330025
total_envstep_count: 275280
total_train_sample_count: 275280
total_episode_count: 2220
total_duration: 56738.18564076586
[2024-12-27 12:00:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.052471916642046
avg_train_sample_per_sec: 5.052471916642046
avg_episode_per_sec: 0.04074574126324231
collect_time: 122.71221101849525
reward_mean: -883.242857142857
reward_std: 654.8544324925213
reward_max: -536.7142857142857
reward_min: -2192.785714285714
queue_len: 0.5479174051754696
wait_time: 2.790455512229706
delay_time: 144.23107889921462
pressure: 7.349131513647643
total_envstep_count: 275900
total_train_sample_count: 275900
total_episode_count: 2225
total_duration: 56860.89785178436
[2024-12-27 12:02:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1350674385715624
avg_train_sample_per_sec: 5.1350674385715624
avg_episode_per_sec: 0.041411834182028734
collect_time: 120.73843380184843
reward_mean: -555.3857142857141
reward_std: 5.36135072837553
reward_max: -548.2142857142854
reward_min: -563.2142857142854
queue_len: 0.3445320808224033
wait_time: 2.386892945763913
delay_time: 79.51646029688534
pressure: 4.821836228287841
total_envstep_count: 276520
total_train_sample_count: 276520
total_episode_count: 2230
total_duration: 56981.6362855862
[2024-12-27 12:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.307815669991508
avg_train_sample_per_sec: 5.307815669991508
avg_episode_per_sec: 0.04280496508057668
collect_time: 116.8088793107979
reward_mean: -558.9714285714286
reward_std: 12.015432253768406
reward_max: -543.7142857142857
reward_min: -579.4285714285713
queue_len: 0.3467564693371145
wait_time: 2.416226515420065
delay_time: 79.8261486954568
pressure: 4.852605459057072
total_envstep_count: 277140
total_train_sample_count: 277140
total_episode_count: 2235
total_duration: 57098.445164897
[2024-12-27 12:06:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2584286282284705
avg_train_sample_per_sec: 5.2584286282284705
avg_episode_per_sec: 0.04240668248571347
collect_time: 117.90594564157351
reward_mean: -557.6571428571427
reward_std: 9.609667751057462
reward_max: -545.8571428571428
reward_min: -575.2142857142856
queue_len: 0.3459411556185749
wait_time: 2.424964551577455
delay_time: 79.48521076991622
pressure: 4.8354838709677415
total_envstep_count: 277760
total_train_sample_count: 277760
total_episode_count: 2240
total_duration: 57216.35111053857
[2024-12-27 12:08:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.212962016848578
avg_train_sample_per_sec: 5.212962016848578
avg_episode_per_sec: 0.04204001626490789
collect_time: 118.93430222513153
reward_mean: -580.0714285714287
reward_std: 9.818038375919201
reward_max: -565.4285714285713
reward_min: -593.2857142857146
queue_len: 0.35984579936192845
wait_time: 2.4649946827366183
delay_time: 81.61969065698244
pressure: 5.033870967741935
total_envstep_count: 278380
total_train_sample_count: 278380
total_episode_count: 2245
total_duration: 57335.285412763704
[2024-12-27 12:10:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.125146565702252
avg_train_sample_per_sec: 5.125146565702252
avg_episode_per_sec: 0.0413318271427601
collect_time: 120.97215017206968
reward_mean: -571.0285714285714
reward_std: 15.337934831585498
reward_max: -551.2142857142854
reward_min: -598.4285714285717
queue_len: 0.35423608649415106
wait_time: 2.4946472881956754
delay_time: 80.91532908561128
pressure: 4.952233250620347
total_envstep_count: 279000
total_train_sample_count: 279000
total_episode_count: 2250
total_duration: 57456.257562935774
[2024-12-27 12:11:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.350142333681563
avg_train_sample_per_sec: 5.350142333681563
avg_episode_per_sec: 0.04314630914259325
collect_time: 115.88476741951703
reward_mean: -558.4142857142858
reward_std: 12.001649546488684
reward_max: -542.5714285714288
reward_min: -573.7857142857142
queue_len: 0.3464108472172989
wait_time: 2.395471464019851
delay_time: 80.05900021930745
pressure: 4.847518610421836
total_envstep_count: 279620
total_train_sample_count: 279620
total_episode_count: 2255
total_duration: 57572.142330355295
[2024-12-27 12:14:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.144302115091842
avg_train_sample_per_sec: 5.144302115091842
avg_episode_per_sec: 0.04148630737977292
collect_time: 120.52169295833261
reward_mean: -593.9857142857143
reward_std: 60.944929976134425
reward_max: -548.1428571428571
reward_min: -714.7857142857144
queue_len: 0.3684774902516838
wait_time: 2.537052463665366
delay_time: 83.88344919899365
pressure: 5.150744416873449
total_envstep_count: 280240
total_train_sample_count: 280240
total_episode_count: 2260
total_duration: 57692.66402331363
[2024-12-27 12:15:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.252260053309498
avg_train_sample_per_sec: 5.252260053309498
avg_episode_per_sec: 0.042356935913786274
collect_time: 118.0444215836823
reward_mean: -575.5285714285714
reward_std: 24.417817181688648
reward_max: -549.4285714285713
reward_min: -613.5000000000001
queue_len: 0.35702764976958523
wait_time: 2.4300425381070534
delay_time: 81.65852376994265
pressure: 4.993424317617865
total_envstep_count: 280860
total_train_sample_count: 280860
total_episode_count: 2265
total_duration: 57810.70844489731
[2024-12-27 12:18:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.061506105038348
avg_train_sample_per_sec: 5.061506105038348
avg_episode_per_sec: 0.040818597621277
collect_time: 122.49318426838144
reward_mean: -565.8999999999999
reward_std: 13.848789824090716
reward_max: -543.4285714285712
reward_min: -581.7857142857146
queue_len: 0.3510545905707195
wait_time: 2.444416873449131
delay_time: 81.59632295104834
pressure: 4.904838709677419
total_envstep_count: 281480
total_train_sample_count: 281480
total_episode_count: 2270
total_duration: 57933.20162916569
[2024-12-27 12:20:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.264387695769534
avg_train_sample_per_sec: 5.264387695769534
avg_episode_per_sec: 0.042454739482012366
collect_time: 117.7724810234308
reward_mean: -573.1714285714286
reward_std: 8.021730690150909
reward_max: -566.357142857143
reward_min: -588.4285714285718
queue_len: 0.3555654023395959
wait_time: 2.462841191066997
delay_time: 81.69270323887473
pressure: 4.971215880893301
total_envstep_count: 282100
total_train_sample_count: 282100
total_episode_count: 2275
total_duration: 58050.97411018912
[2024-12-27 12:22:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.075457033232124
avg_train_sample_per_sec: 5.075457033232124
avg_episode_per_sec: 0.04093110510671068
collect_time: 122.15648678345231
reward_mean: -571.0857142857143
reward_std: 11.020796667377365
reward_max: -553.642857142857
reward_min: -582.3571428571429
queue_len: 0.3542715349166962
wait_time: 2.4792272243885147
delay_time: 81.83613559699704
pressure: 4.949875930521093
total_envstep_count: 282720
total_train_sample_count: 282720
total_episode_count: 2280
total_duration: 58173.13059697257
[2024-12-27 12:24:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.125785613132873
avg_train_sample_per_sec: 5.125785613132873
avg_episode_per_sec: 0.041336980751071555
collect_time: 120.95706820267438
reward_mean: -571.0142857142857
reward_std: 7.880407116801251
reward_max: -563.3571428571428
reward_min: -582.1428571428571
queue_len: 0.35422722438851467
wait_time: 2.510475008862106
delay_time: 81.40201538993605
pressure: 4.956575682382134
total_envstep_count: 283340
total_train_sample_count: 283340
total_episode_count: 2285
total_duration: 58294.08766517525
[2024-12-27 12:26:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.158380597650388
avg_train_sample_per_sec: 5.158380597650388
avg_episode_per_sec: 0.04159984352943861
collect_time: 120.19275977472589
reward_mean: -558.8857142857144
reward_std: 6.444994893999097
reward_max: -551.6428571428572
reward_min: -568.5000000000003
queue_len: 0.3467032967032967
wait_time: 2.4668734491315134
delay_time: 80.50097756296834
pressure: 4.847518610421837
total_envstep_count: 283960
total_train_sample_count: 283960
total_episode_count: 2290
total_duration: 58414.280424949975
[2024-12-27 12:28:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.440874034670829
avg_train_sample_per_sec: 5.440874034670829
avg_episode_per_sec: 0.043878016408635714
collect_time: 113.95227973468602
reward_mean: -565.742857142857
reward_std: 12.363755456154438
reward_max: -543.2857142857143
reward_min: -578.9999999999998
queue_len: 0.3509571074087202
wait_time: 2.4326834455866715
delay_time: 81.96285538318946
pressure: 4.910669975186105
total_envstep_count: 284580
total_train_sample_count: 284580
total_episode_count: 2295
total_duration: 58528.23270468466
[2024-12-27 12:30:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.189212255509399
avg_train_sample_per_sec: 5.189212255509399
avg_episode_per_sec: 0.04184848593152741
collect_time: 119.47863557551429
reward_mean: -563.6428571428571
reward_std: 8.667203018463637
reward_max: -550.8571428571428
reward_min: -577.4999999999999
queue_len: 0.3496543778801843
wait_time: 2.4861485288904643
delay_time: 80.3741491429839
pressure: 4.890694789081886
total_envstep_count: 285200
total_train_sample_count: 285200
total_episode_count: 2300
total_duration: 58647.711340260175
[2024-12-27 12:32:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.11618548091191
avg_train_sample_per_sec: 5.11618548091191
avg_episode_per_sec: 0.04125956032993476
collect_time: 121.18403492468593
reward_mean: -570.6571428571427
reward_std: 6.3771594981862165
reward_max: -561.7857142857139
reward_min: -578.785714285714
queue_len: 0.3540056717476071
wait_time: 2.4684065934065926
delay_time: 81.07292829144454
pressure: 4.9526054590570725
total_envstep_count: 285820
total_train_sample_count: 285820
total_episode_count: 2305
total_duration: 58768.89537518486
[2024-12-27 12:34:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.176474580766357
avg_train_sample_per_sec: 5.176474580766357
avg_episode_per_sec: 0.04174576274811578
collect_time: 119.77263489396125
reward_mean: -560.3857142857144
reward_std: 6.067746782818704
reward_max: -554.857142857143
reward_min: -571.4999999999998
queue_len: 0.3476338177951081
wait_time: 2.4603332151719246
delay_time: 80.2882480004748
pressure: 4.861538461538461
total_envstep_count: 286440
total_train_sample_count: 286440
total_episode_count: 2310
total_duration: 58888.66801007882
[2024-12-27 12:36:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.216990057328746
avg_train_sample_per_sec: 5.216990057328746
avg_episode_per_sec: 0.0420725004623286
collect_time: 118.84247299437224
reward_mean: -565.7857142857143
reward_std: 3.60130361884435
reward_max: -559.5714285714287
reward_min: -569.7857142857143
queue_len: 0.35098369372562926
wait_time: 2.4690003544842263
delay_time: 81.13015921872534
pressure: 4.911538461538461
total_envstep_count: 287060
total_train_sample_count: 287060
total_episode_count: 2315
total_duration: 59007.510483073194
[2024-12-27 12:38:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.308788450030317
avg_train_sample_per_sec: 5.308788450030317
avg_episode_per_sec: 0.042812810080889656
collect_time: 116.78747530360893
reward_mean: -564.1999999999998
reward_std: 8.57373778417786
reward_max: -553.9999999999997
reward_min: -575.0714285714288
queue_len: 0.35
wait_time: 2.454767812832329
delay_time: 80.57716039212369
pressure: 4.898883374689826
total_envstep_count: 287680
total_train_sample_count: 287680
total_episode_count: 2320
total_duration: 59124.2979583768
[2024-12-27 12:40:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1050558872448555
avg_train_sample_per_sec: 5.1050558872448555
avg_episode_per_sec: 0.041169805542297225
collect_time: 121.44822969501465
reward_mean: -558.1142857142856
reward_std: 12.936785078344098
reward_max: -543.2857142857143
reward_min: -581.2142857142858
queue_len: 0.3462247429989366
wait_time: 2.439267990074442
delay_time: 80.08351928733865
pressure: 4.841439205955335
total_envstep_count: 288300
total_train_sample_count: 288300
total_episode_count: 2325
total_duration: 59245.74618807182
[2024-12-27 12:41:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4005895586883685
avg_train_sample_per_sec: 5.4005895586883685
avg_episode_per_sec: 0.043553141602325554
collect_time: 114.80228098477794
reward_mean: -569.5285714285714
reward_std: 9.789790600416284
reward_max: -556.5714285714287
reward_min: -583.4999999999999
queue_len: 0.35330556540233954
wait_time: 2.4333037929812122
delay_time: 81.563449837455
pressure: 4.944044665012408
total_envstep_count: 288920
total_train_sample_count: 288920
total_episode_count: 2330
total_duration: 59360.54846905659
[2024-12-27 12:44:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.099865223132903
avg_train_sample_per_sec: 5.099865223132903
avg_episode_per_sec: 0.04112794534784599
collect_time: 121.57184021014722
reward_mean: -564.5714285714287
reward_std: 8.147492415035758
reward_max: -550.3571428571425
reward_min: -572.0000000000005
queue_len: 0.3502304147465438
wait_time: 2.4437344913151358
delay_time: 81.24259807819813
pressure: 4.894416873449131
total_envstep_count: 289540
total_train_sample_count: 289540
total_episode_count: 2335
total_duration: 59482.12030926674
[2024-12-27 12:46:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.111120224605703
avg_train_sample_per_sec: 5.111120224605703
avg_episode_per_sec: 0.041218711488755666
collect_time: 121.30413153171914
reward_mean: -573.6
reward_std: 12.643995106172014
reward_max: -554.5714285714282
reward_min: -586.9285714285717
queue_len: 0.3558312655086848
wait_time: 2.491350584898972
delay_time: 81.74350419586149
pressure: 4.9723325062034744
total_envstep_count: 290160
total_train_sample_count: 290160
total_episode_count: 2340
total_duration: 59603.42444079846
[2024-12-27 12:48:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.242745876093555
avg_train_sample_per_sec: 5.242745876093555
avg_episode_per_sec: 0.04228020867817383
collect_time: 118.25864053932953
reward_mean: -554.0142857142857
reward_std: 10.624231064612992
reward_max: -534.4285714285713
reward_min: -564.7142857142859
queue_len: 0.3436813186813186
wait_time: 2.395710740872031
delay_time: 79.97823566634676
pressure: 4.8032258064516125
total_envstep_count: 290780
total_train_sample_count: 290780
total_episode_count: 2345
total_duration: 59721.68308133779
[2024-12-27 12:50:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.909201946690944
avg_train_sample_per_sec: 4.909201946690944
avg_episode_per_sec: 0.03959033827976567
collect_time: 126.29343969398369
reward_mean: -819.2857142857143
reward_std: 505.82268813956426
reward_max: -552.7142857142857
reward_min: -1830.6428571428576
queue_len: 0.5082417582417582
wait_time: 2.760067352002836
delay_time: 125.45797305952836
pressure: 7.01439205955335
total_envstep_count: 291400
total_train_sample_count: 291400
total_episode_count: 2350
total_duration: 59847.97652103177
[2024-12-27 12:52:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.313931406382931
avg_train_sample_per_sec: 5.313931406382931
avg_episode_per_sec: 0.042854285535346225
collect_time: 116.67444545017555
reward_mean: -559.2571428571429
reward_std: 9.577780408373357
reward_max: -547.0
reward_min: -570.4285714285716
queue_len: 0.3469337114498404
wait_time: 2.4094292803970223
delay_time: 80.41054400014298
pressure: 4.853846153846154
total_envstep_count: 292020
total_train_sample_count: 292020
total_episode_count: 2355
total_duration: 59964.650966481946
[2024-12-27 12:54:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.219702802822936
avg_train_sample_per_sec: 5.219702802822936
avg_episode_per_sec: 0.042094377442120454
collect_time: 118.78070905965942
reward_mean: -566.4571428571429
reward_std: 11.37869473522998
reward_max: -551.4285714285716
reward_min: -582.3571428571429
queue_len: 0.35140021269053534
wait_time: 2.410377525700107
delay_time: 82.24329604685728
pressure: 4.911910669975186
total_envstep_count: 292640
total_train_sample_count: 292640
total_episode_count: 2360
total_duration: 60083.43167554161
[2024-12-27 12:56:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.150762036945078
avg_train_sample_per_sec: 5.150762036945078
avg_episode_per_sec: 0.041538403523750635
collect_time: 120.37053848593683
reward_mean: -569.3
reward_std: 10.741717264754229
reward_max: -551.4999999999998
reward_min: -583.9285714285711
queue_len: 0.35316377171215874
wait_time: 2.4449929103154915
delay_time: 82.33542831257115
pressure: 4.93560794044665
total_envstep_count: 293260
total_train_sample_count: 293260
total_episode_count: 2365
total_duration: 60203.80221402754
[2024-12-27 12:58:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.16458315726306
avg_train_sample_per_sec: 5.16458315726306
avg_episode_per_sec: 0.041649864171476286
collect_time: 120.04841070824492
reward_mean: -561.5142857142857
reward_std: 7.699642186226458
reward_max: -548.7857142857144
reward_min: -570.0000000000001
queue_len: 0.34833392414037573
wait_time: 2.4128323289613616
delay_time: 81.43363668227076
pressure: 4.868362282878412
total_envstep_count: 293880
total_train_sample_count: 293880
total_episode_count: 2370
total_duration: 60323.85062473579
[2024-12-27 13:00:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3358465611419295
avg_train_sample_per_sec: 5.3358465611419295
avg_episode_per_sec: 0.0430310206543704
collect_time: 116.19524528968337
reward_mean: -569.7285714285713
reward_std: 20.554675718131573
reward_max: -538.4285714285712
reward_min: -598.2857142857141
queue_len: 0.3534296348812477
wait_time: 2.434234314073023
delay_time: 82.13806548968076
pressure: 4.940570719602978
total_envstep_count: 294500
total_train_sample_count: 294500
total_episode_count: 2375
total_duration: 60440.04587002547
[2024-12-27 13:02:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.233246301093302
avg_train_sample_per_sec: 5.233246301093302
avg_episode_per_sec: 0.042203599202365334
collect_time: 118.47330783389135
reward_mean: -567.4428571428573
reward_std: 12.544321424453367
reward_max: -550.6428571428572
reward_min: -589.2142857142858
queue_len: 0.35201169797944
wait_time: 2.4733870967741938
delay_time: 82.3268053437351
pressure: 4.914267990074441
total_envstep_count: 295120
total_train_sample_count: 295120
total_episode_count: 2380
total_duration: 60558.51917785936
[2024-12-27 13:04:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.310001560870494
avg_train_sample_per_sec: 5.310001560870494
avg_episode_per_sec: 0.04282259323282656
collect_time: 116.76079430348801
reward_mean: -568.8
reward_std: 13.072279441471567
reward_max: -550.2857142857142
reward_min: -583.9285714285714
queue_len: 0.35285359801488836
wait_time: 2.4658631690889754
delay_time: 82.41619467884877
pressure: 4.92741935483871
total_envstep_count: 295740
total_train_sample_count: 295740
total_episode_count: 2385
total_duration: 60675.27997216285
[2024-12-27 13:06:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.298174741268049
avg_train_sample_per_sec: 5.298174741268049
avg_episode_per_sec: 0.04272721565538749
collect_time: 117.02143290419505
reward_mean: -567.7428571428571
reward_std: 5.983241903305455
reward_max: -557.9999999999999
reward_min: -575.357142857143
queue_len: 0.35219780219780217
wait_time: 2.4637894363700816
delay_time: 81.70122723956294
pressure: 4.923573200992555
total_envstep_count: 296360
total_train_sample_count: 296360
total_episode_count: 2390
total_duration: 60792.30140506704
[2024-12-27 13:07:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.218677806223171
avg_train_sample_per_sec: 5.218677806223171
avg_episode_per_sec: 0.04208611134050944
collect_time: 118.80403868977352
reward_mean: -565.7142857142856
reward_std: 12.196185419036244
reward_max: -550.3571428571427
reward_min: -582.8571428571432
queue_len: 0.3509393831974476
wait_time: 2.4439028713222255
delay_time: 80.75529479874328
pressure: 4.911538461538461
total_envstep_count: 296980
total_train_sample_count: 296980
total_episode_count: 2395
total_duration: 60911.10544375681
[2024-12-27 13:09:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.251655094201538
avg_train_sample_per_sec: 5.251655094201538
avg_episode_per_sec: 0.042352057211302724
collect_time: 118.05801959168167
reward_mean: -552.642857142857
reward_std: 9.183058936355144
reward_max: -542.8571428571427
reward_min: -568.9285714285714
queue_len: 0.3428305565402339
wait_time: 2.380999645515774
delay_time: 80.0239282848355
pressure: 4.791811414392059
total_envstep_count: 297600
total_train_sample_count: 297600
total_episode_count: 2400
total_duration: 61029.163463348494
[2024-12-27 13:12:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.852289948662654
avg_train_sample_per_sec: 4.852289948662654
avg_episode_per_sec: 0.03913137055373108
collect_time: 127.7747221537903
reward_mean: -820.8
reward_std: 516.613089739116
reward_max: -557.3571428571428
reward_min: -1854.0
queue_len: 0.5091811414392059
wait_time: 2.714897199574619
delay_time: 127.44087551860835
pressure: 7.063895781637717
total_envstep_count: 298220
total_train_sample_count: 298220
total_episode_count: 2405
total_duration: 61156.93818550229
[2024-12-27 13:13:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.617547585606658
avg_train_sample_per_sec: 5.617547585606658
avg_episode_per_sec: 0.045302803109731116
collect_time: 110.36844647094236
reward_mean: -563.4714285714288
reward_std: 7.328668893810177
reward_max: -549.2857142857146
reward_min: -569.2857142857144
queue_len: 0.3495480326125489
wait_time: 2.3946738745125846
delay_time: 80.75714845894643
pressure: 4.885732009925557
total_envstep_count: 298840
total_train_sample_count: 298840
total_episode_count: 2410
total_duration: 61267.30663197323
[2024-12-27 13:15:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.294748631678169
avg_train_sample_per_sec: 5.294748631678169
avg_episode_per_sec: 0.04269958573934007
collect_time: 117.09715477153658
reward_mean: -620.5857142857143
reward_std: 107.43180466259155
reward_max: -564.5714285714287
reward_min: -835.4285714285714
queue_len: 0.3849787309464729
wait_time: 2.4528447359092516
delay_time: 88.64623923985604
pressure: 5.386724565756825
total_envstep_count: 299460
total_train_sample_count: 299460
total_episode_count: 2415
total_duration: 61384.40378674477
[2024-12-27 13:17:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.167354837898474
avg_train_sample_per_sec: 5.167354837898474
avg_episode_per_sec: 0.041672216434665114
collect_time: 119.98401879677176
reward_mean: -570.5142857142857
reward_std: 22.95103038903425
reward_max: -547.7142857142858
reward_min: -599.7857142857146
queue_len: 0.35391705069124424
wait_time: 2.4290765685926976
delay_time: 82.67179290217057
pressure: 4.948014888337469
total_envstep_count: 300080
total_train_sample_count: 300080
total_episode_count: 2420
total_duration: 61504.38780554154
[2024-12-27 13:19:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.442557299137773
avg_train_sample_per_sec: 5.442557299137773
avg_episode_per_sec: 0.04389159112207881
collect_time: 113.91703677574921
reward_mean: -556.9
reward_std: 18.913044844924553
reward_max: -534.0714285714287
reward_min: -590.8571428571432
queue_len: 0.3454714640198512
wait_time: 2.393902871322226
delay_time: 79.95325361144253
pressure: 4.834491315136477
total_envstep_count: 300700
total_train_sample_count: 300700
total_episode_count: 2425
total_duration: 61618.30484231729
[2024-12-27 13:21:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.236578228378095
avg_train_sample_per_sec: 5.236578228378095
avg_episode_per_sec: 0.042230469583694315
collect_time: 118.39792569890247
reward_mean: -558.5428571428571
reward_std: 10.028591778571082
reward_max: -546.142857142857
reward_min: -573.9285714285713
queue_len: 0.34649060616802546
wait_time: 2.390021269053527
delay_time: 81.18563251771705
pressure: 4.846277915632755
total_envstep_count: 301320
total_train_sample_count: 301320
total_episode_count: 2430
total_duration: 61736.70276801619
[2024-12-27 13:23:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4611080595605905
avg_train_sample_per_sec: 5.4611080595605905
avg_episode_per_sec: 0.04404119402871444
collect_time: 113.53007361108438
reward_mean: -644.3285714285714
reward_std: 146.4806221077081
reward_max: -550.2142857142858
reward_min: -936.1428571428569
queue_len: 0.3997075505140022
wait_time: 2.57274902516838
delay_time: 90.01696489630012
pressure: 5.525062034739454
total_envstep_count: 301940
total_train_sample_count: 301940
total_episode_count: 2435
total_duration: 61850.23284162728
[2024-12-27 13:25:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3308356827775265
avg_train_sample_per_sec: 5.3308356827775265
avg_episode_per_sec: 0.04299061034498005
collect_time: 116.30446648412942
reward_mean: -555.6999999999998
reward_std: 6.122791146901234
reward_max: -544.642857142857
reward_min: -562.0
queue_len: 0.34472704714640184
wait_time: 2.4019496632399853
delay_time: 80.45383107582948
pressure: 4.822828784119106
total_envstep_count: 302560
total_train_sample_count: 302560
total_episode_count: 2440
total_duration: 61966.53730811141
[2024-12-27 13:27:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.1026481781902895
avg_train_sample_per_sec: 5.1026481781902895
avg_episode_per_sec: 0.04115038853379266
collect_time: 121.50553562559938
reward_mean: -575.1714285714286
reward_std: 14.472324045062924
reward_max: -555.7142857142858
reward_min: -597.3571428571429
queue_len: 0.35680609712867783
wait_time: 2.4327011697979444
delay_time: 82.30563904656984
pressure: 4.993052109181141
total_envstep_count: 303180
total_train_sample_count: 303180
total_episode_count: 2445
total_duration: 62088.04284373701
[2024-12-27 13:29:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.367454454455067
avg_train_sample_per_sec: 5.367454454455067
avg_episode_per_sec: 0.04328592301979893
collect_time: 115.51099413342777
reward_mean: -559.2
reward_std: 9.6354362980128
reward_max: -543.4999999999998
reward_min: -572.8571428571428
queue_len: 0.3468982630272953
wait_time: 2.3840304856433887
delay_time: 81.34054141613005
pressure: 4.85272952853598
total_envstep_count: 303800
total_train_sample_count: 303800
total_episode_count: 2450
total_duration: 62203.55383787044
[2024-12-27 13:31:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.404944098876819
avg_train_sample_per_sec: 5.404944098876819
avg_episode_per_sec: 0.04358825886190983
collect_time: 114.70978952933848
reward_mean: -570.2857142857143
reward_std: 11.606032913963311
reward_max: -551.2857142857143
reward_min: -587.0714285714286
queue_len: 0.35377525700106355
wait_time: 2.454244948599787
delay_time: 81.78024129472529
pressure: 4.945533498759305
total_envstep_count: 304420
total_train_sample_count: 304420
total_episode_count: 2455
total_duration: 62318.26362739978
[2024-12-27 13:33:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.164499732576213
avg_train_sample_per_sec: 5.164499732576213
avg_episode_per_sec: 0.04164919139174366
collect_time: 120.05034990886226
reward_mean: -564.7571428571429
reward_std: 8.910965498892455
reward_max: -551.7142857142854
reward_min: -579.5000000000002
queue_len: 0.3503456221198157
wait_time: 2.4277472527472526
delay_time: 81.0330839687779
pressure: 4.8997518610421835
total_envstep_count: 305040
total_train_sample_count: 305040
total_episode_count: 2460
total_duration: 62438.31397730864
[2024-12-27 13:35:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.198457374456941
avg_train_sample_per_sec: 5.198457374456941
avg_episode_per_sec: 0.04192304334239469
collect_time: 119.26615057890487
reward_mean: -566.7285714285714
reward_std: 8.100944767275411
reward_max: -557.714285714286
reward_min: -579.7142857142853
queue_len: 0.35156859269762497
wait_time: 2.447261609358384
delay_time: 81.11096476078039
pressure: 4.917990074441687
total_envstep_count: 305660
total_train_sample_count: 305660
total_episode_count: 2465
total_duration: 62557.580127887544
[2024-12-27 13:37:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.202741178945635
avg_train_sample_per_sec: 5.202741178945635
avg_episode_per_sec: 0.041957590152787376
collect_time: 119.16794987015797
reward_mean: -570.3999999999999
reward_std: 11.207741493617476
reward_max: -548.1428571428571
reward_min: -577.7142857142856
queue_len: 0.3538461538461538
wait_time: 2.4652782701169795
delay_time: 81.3244605749503
pressure: 4.95210918114144
total_envstep_count: 306280
total_train_sample_count: 306280
total_episode_count: 2470
total_duration: 62676.7480777577
[2024-12-27 13:39:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2889901033823055
avg_train_sample_per_sec: 5.2889901033823055
avg_episode_per_sec: 0.04265314599501859
collect_time: 117.2246474054679
reward_mean: -568.5714285714286
reward_std: 6.498665483099042
reward_max: -556.0714285714288
reward_min: -574.7857142857143
queue_len: 0.35271180432470756
wait_time: 2.4627525700106347
delay_time: 81.20799925836603
pressure: 4.934739454094293
total_envstep_count: 306900
total_train_sample_count: 306900
total_episode_count: 2475
total_duration: 62793.97272516317
[2024-12-27 13:41:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.315123176705249
avg_train_sample_per_sec: 5.315123176705249
avg_episode_per_sec: 0.042863896586332655
collect_time: 116.648284411788
reward_mean: -562.4857142857143
reward_std: 17.03186689109322
reward_max: -542.0000000000001
reward_min: -582.357142857143
queue_len: 0.34893654732364415
wait_time: 2.443991492378589
delay_time: 80.91905002640833
pressure: 4.883995037220844
total_envstep_count: 307520
total_train_sample_count: 307520
total_episode_count: 2480
total_duration: 62910.621009574956
[2024-12-27 13:43:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.199465265855695
avg_train_sample_per_sec: 5.199465265855695
avg_episode_per_sec: 0.041931171498836246
collect_time: 119.24303140776234
reward_mean: -570.5142857142856
reward_std: 8.293272414851645
reward_max: -560.7857142857143
reward_min: -584.0000000000001
queue_len: 0.35391705069124424
wait_time: 2.5208702587734844
delay_time: 81.12569706264486
pressure: 4.952233250620347
total_envstep_count: 308140
total_train_sample_count: 308140
total_episode_count: 2485
total_duration: 63029.86404098272
[2024-12-27 13:45:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.187092983378108
avg_train_sample_per_sec: 5.187092983378108
avg_episode_per_sec: 0.041831395027242806
collect_time: 119.52745053670185
reward_mean: -561.7142857142857
reward_std: 9.427380877215102
reward_max: -548.2142857142857
reward_min: -576.9999999999999
queue_len: 0.3484579936192839
wait_time: 2.4639489542715354
delay_time: 80.97223414084996
pressure: 4.873945409429281
total_envstep_count: 308760
total_train_sample_count: 308760
total_episode_count: 2490
total_duration: 63149.391491519425
[2024-12-27 13:47:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.175713545870078
avg_train_sample_per_sec: 5.175713545870078
avg_episode_per_sec: 0.04173962536991998
collect_time: 119.79024621536955
reward_mean: -559.1428571428571
reward_std: 8.114989909081261
reward_max: -549.9285714285712
reward_min: -573.2142857142856
queue_len: 0.3468628146047501
wait_time: 2.4513647642679897
delay_time: 80.65585106166972
pressure: 4.85
total_envstep_count: 309380
total_train_sample_count: 309380
total_episode_count: 2495
total_duration: 63269.1817377348
[2024-12-27 13:49:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.201116931901378
avg_train_sample_per_sec: 5.201116931901378
avg_episode_per_sec: 0.041944491386301436
collect_time: 119.20516460554674
reward_mean: -552.4
reward_std: 6.886484841294996
reward_max: -540.7142857142859
reward_min: -559.2142857142856
queue_len: 0.3426799007444169
wait_time: 2.4292892591279687
delay_time: 79.74896582460966
pressure: 4.793300248138958
total_envstep_count: 310000
total_train_sample_count: 310000
total_episode_count: 2500
total_duration: 63388.386902340346
[2024-12-27 13:51:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.159336469296804
avg_train_sample_per_sec: 5.159336469296804
avg_episode_per_sec: 0.04160755217174841
collect_time: 120.17049163000286
reward_mean: -552.342857142857
reward_std: 11.295872462712959
reward_max: -532.6428571428571
reward_min: -564.9999999999998
queue_len: 0.3426444523218716
wait_time: 2.4486706841545547
delay_time: 80.20502713168828
pressure: 4.78833746898263
total_envstep_count: 310620
total_train_sample_count: 310620
total_episode_count: 2505
total_duration: 63508.557393970346
[2024-12-27 13:53:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.186952264717522
avg_train_sample_per_sec: 5.186952264717522
avg_episode_per_sec: 0.041830260199334855
collect_time: 119.53069323913756
reward_mean: -562.4285714285713
reward_std: 12.721747409175155
reward_max: -542.8571428571429
reward_min: -579.7142857142856
queue_len: 0.3489010989010989
wait_time: 2.4847040056717473
delay_time: 80.55200600794647
pressure: 4.877295285359802
total_envstep_count: 311240
total_train_sample_count: 311240
total_episode_count: 2510
total_duration: 63628.088087209486
[2024-12-27 13:55:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.120598097190068
avg_train_sample_per_sec: 5.120598097190068
avg_episode_per_sec: 0.04129514594508119
collect_time: 121.0796059820093
reward_mean: -550.2142857142856
reward_std: 13.869287755942773
reward_max: -535.0000000000001
reward_min: -572.7857142857143
queue_len: 0.341323998582063
wait_time: 2.399822757887274
delay_time: 79.68999252002662
pressure: 4.776054590570719
total_envstep_count: 311860
total_train_sample_count: 311860
total_episode_count: 2515
total_duration: 63749.16769319149
[2024-12-27 13:57:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.072633727654456
avg_train_sample_per_sec: 5.072633727654456
avg_episode_per_sec: 0.04090833651334239
collect_time: 122.22447613750398
reward_mean: -559.4857142857143
reward_std: 11.676105025710672
reward_max: -544.5000000000003
reward_min: -579.3571428571428
queue_len: 0.3470755051400213
wait_time: 2.456611130804679
delay_time: 80.46174375394693
pressure: 4.851116625310174
total_envstep_count: 312480
total_train_sample_count: 312480
total_episode_count: 2520
total_duration: 63871.392169328996
[2024-12-27 13:59:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.273573099420659
avg_train_sample_per_sec: 5.273573099420659
avg_episode_per_sec: 0.042528815317908544
collect_time: 117.56734728264439
reward_mean: -563.6714285714285
reward_std: 5.067020216808933
reward_max: -557.9285714285716
reward_min: -570.7857142857142
queue_len: 0.34967210209145694
wait_time: 2.44679191775966
delay_time: 80.90083029414673
pressure: 4.893548387096774
total_envstep_count: 313100
total_train_sample_count: 313100
total_episode_count: 2525
total_duration: 63988.95951661164
[2024-12-27 14:01:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.0507809477101535
avg_train_sample_per_sec: 5.0507809477101535
avg_episode_per_sec: 0.04073210441701736
collect_time: 122.75329427642001
reward_mean: -556.8
reward_std: 11.325913937983719
reward_max: -546.2857142857143
reward_min: -578.1428571428573
queue_len: 0.34540942928039703
wait_time: 2.450345622119816
delay_time: 79.69033424550433
pressure: 4.833002481389578
total_envstep_count: 313720
total_train_sample_count: 313720
total_episode_count: 2530
total_duration: 64111.712810888064
[2024-12-27 14:03:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.088440496681671
avg_train_sample_per_sec: 5.088440496681671
avg_episode_per_sec: 0.04103581045711025
collect_time: 121.84479712484033
reward_mean: -561.6285714285714
reward_std: 4.72107735888458
reward_max: -556.3571428571428
reward_min: -569.7142857142859
queue_len: 0.34840482098546616
wait_time: 2.4385235732009924
delay_time: 80.61916378515015
pressure: 4.872456575682382
total_envstep_count: 314340
total_train_sample_count: 314340
total_episode_count: 2535
total_duration: 64233.5576080129
[2024-12-27 14:05:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.205349190081212
avg_train_sample_per_sec: 5.205349190081212
avg_episode_per_sec: 0.041978622500654934
collect_time: 119.10824372386188
reward_mean: -558.6000000000001
reward_std: 10.077718400673138
reward_max: -545.1428571428571
reward_min: -569.5
queue_len: 0.3465260545905708
wait_time: 2.4223679546260195
delay_time: 80.27237881656721
pressure: 4.848263027295285
total_envstep_count: 314960
total_train_sample_count: 314960
total_episode_count: 2540
total_duration: 64352.66585173676
[2024-12-27 14:07:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.417458479911544
avg_train_sample_per_sec: 5.417458479911544
avg_episode_per_sec: 0.043689181289609226
collect_time: 114.44480881561336
reward_mean: -550.7142857142858
reward_std: 8.090937232862581
reward_max: -537.2857142857143
reward_min: -562.2142857142857
queue_len: 0.34163417227933357
wait_time: 2.371295639844026
delay_time: 79.54193688866398
pressure: 4.780397022332506
total_envstep_count: 315580
total_train_sample_count: 315580
total_episode_count: 2545
total_duration: 64467.110660552375
[2024-12-27 14:09:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.268883732275085
avg_train_sample_per_sec: 5.268883732275085
avg_episode_per_sec: 0.04249099784092811
collect_time: 117.67198357445747
reward_mean: -557.042857142857
reward_std: 4.8055240322456205
reward_max: -548.5714285714286
reward_min: -562.7142857142859
queue_len: 0.34556008507621405
wait_time: 2.4146313364055296
delay_time: 79.79058796523358
pressure: 4.83498759305211
total_envstep_count: 316200
total_train_sample_count: 316200
total_episode_count: 2550
total_duration: 64584.78264412683
[2024-12-27 14:11:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2324730489132465
avg_train_sample_per_sec: 5.2324730489132465
avg_episode_per_sec: 0.042197363297687474
collect_time: 118.4908157584816
reward_mean: -553.4285714285713
reward_std: 8.357814380834856
reward_max: -544.7857142857143
reward_min: -568.3571428571429
queue_len: 0.3433179723502304
wait_time: 2.404572846508331
delay_time: 80.14357401083461
pressure: 4.80272952853598
total_envstep_count: 316820
total_train_sample_count: 316820
total_episode_count: 2555
total_duration: 64703.27345988531
[2024-12-27 14:13:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.490760839172388
avg_train_sample_per_sec: 5.490760839172388
avg_episode_per_sec: 0.04428032934816442
collect_time: 112.91695598481965
reward_mean: -565.3285714285714
reward_std: 10.848267048666358
reward_max: -551.6428571428572
reward_min: -583.8571428571425
queue_len: 0.3507001063452676
wait_time: 2.4350584898971994
delay_time: 80.80144248285538
pressure: 4.906079404466501
total_envstep_count: 317440
total_train_sample_count: 317440
total_episode_count: 2560
total_duration: 64816.190415870136
[2024-12-27 14:15:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.189776531964025
avg_train_sample_per_sec: 5.189776531964025
avg_episode_per_sec: 0.04185303654809698
collect_time: 119.46564484643936
reward_mean: -561.5714285714287
reward_std: 6.059231445842433
reward_max: -553.357142857143
reward_min: -571.0714285714287
queue_len: 0.348369372562921
wait_time: 2.420276497695852
delay_time: 80.65056756364746
pressure: 4.873449131513647
total_envstep_count: 318060
total_train_sample_count: 318060
total_episode_count: 2565
total_duration: 64935.656060716574
[2024-12-27 14:17:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3739686088968375
avg_train_sample_per_sec: 5.3739686088968375
avg_episode_per_sec: 0.043338456523361595
collect_time: 115.3709753669873
reward_mean: -563.7142857142858
reward_std: 10.021507483652215
reward_max: -551.4285714285716
reward_min: -581.7857142857143
queue_len: 0.3496986884083658
wait_time: 2.442573555476781
delay_time: 80.64009374125317
pressure: 4.894292803970224
total_envstep_count: 318680
total_train_sample_count: 318680
total_episode_count: 2570
total_duration: 65051.027036083564
[2024-12-27 14:19:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.24417480147006
avg_train_sample_per_sec: 5.24417480147006
avg_episode_per_sec: 0.042291732269919835
collect_time: 118.22641759122905
reward_mean: -557.9571428571428
reward_std: 8.421619408960996
reward_max: -551.5714285714283
reward_min: -574.0714285714286
queue_len: 0.34612725983693726
wait_time: 2.385944700460829
delay_time: 80.34361898984098
pressure: 4.843548387096774
total_envstep_count: 319300
total_train_sample_count: 319300
total_episode_count: 2575
total_duration: 65169.25345367479
[2024-12-27 14:21:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.337818527300693
avg_train_sample_per_sec: 5.337818527300693
avg_episode_per_sec: 0.04304692360726366
collect_time: 116.15231893496588
reward_mean: -555.142857142857
reward_std: 11.133512565260583
reward_max: -541.5
reward_min: -572.9285714285712
queue_len: 0.34438142502658625
wait_time: 2.4246455157745483
delay_time: 81.03443957894193
pressure: 4.811538461538461
total_envstep_count: 319920
total_train_sample_count: 319920
total_episode_count: 2580
total_duration: 65285.40577260976
[2024-12-27 14:23:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.141648672240232
avg_train_sample_per_sec: 5.141648672240232
avg_episode_per_sec: 0.04146490864709865
collect_time: 120.58389040608333
reward_mean: -565.8428571428573
reward_std: 11.444221427499125
reward_max: -551.714285714286
reward_min: -577.0714285714286
queue_len: 0.3510191421481744
wait_time: 2.4477933356965607
delay_time: 81.18985575827544
pressure: 4.909429280397022
total_envstep_count: 320540
total_train_sample_count: 320540
total_episode_count: 2585
total_duration: 65405.98966301584
[2024-12-27 14:25:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.180305401670026
avg_train_sample_per_sec: 5.180305401670026
avg_episode_per_sec: 0.04177665646508085
collect_time: 119.68406337590146
reward_mean: -563.942857142857
reward_std: 8.753005314794262
reward_max: -550.4285714285712
reward_min: -576.7142857142857
queue_len: 0.34984048209854646
wait_time: 2.441900035448423
delay_time: 81.13459376731132
pressure: 4.89106699751861
total_envstep_count: 321160
total_train_sample_count: 321160
total_episode_count: 2590
total_duration: 65525.67372639174
[2024-12-27 14:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.237255314794858
avg_train_sample_per_sec: 5.237255314794858
avg_episode_per_sec: 0.04223592995802305
collect_time: 118.38261889744919
reward_mean: -566.0142857142857
reward_std: 11.152321987563203
reward_max: -545.9285714285716
reward_min: -578.2857142857144
queue_len: 0.35112548741581007
wait_time: 2.4458702587734846
delay_time: 81.82433993306385
pressure: 4.91091811414392
total_envstep_count: 321780
total_train_sample_count: 321780
total_episode_count: 2595
total_duration: 65644.0563452892
[2024-12-27 14:29:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.140521421473196
avg_train_sample_per_sec: 5.140521421473196
avg_episode_per_sec: 0.04145581791510642
collect_time: 120.61033291488889
reward_mean: -567.0428571428571
reward_std: 11.344026568000853
reward_max: -555.2142857142858
reward_min: -584.7142857142857
queue_len: 0.35176355902162343
wait_time: 2.460404112017015
delay_time: 80.94342865395564
pressure: 4.9217121588089325
total_envstep_count: 322400
total_train_sample_count: 322400
total_episode_count: 2600
total_duration: 65764.66667820408
[2024-12-27 14:31:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.333245749898561
avg_train_sample_per_sec: 5.333245749898561
avg_episode_per_sec: 0.04301004637014968
collect_time: 116.25190907653047
reward_mean: -558.0428571428571
reward_std: 10.811803829186678
reward_max: -539.7142857142856
reward_min: -571.3571428571427
queue_len: 0.34618043247075503
wait_time: 2.4137451258419
delay_time: 80.8562718287199
pressure: 4.84516129032258
total_envstep_count: 323020
total_train_sample_count: 323020
total_episode_count: 2605
total_duration: 65880.91858728061
[2024-12-27 14:33:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.32093257587001
avg_train_sample_per_sec: 5.32093257587001
avg_episode_per_sec: 0.04291074657959686
collect_time: 116.52092770572752
reward_mean: -563.5571428571429
reward_std: 10.084075139970414
reward_max: -551.6428571428575
reward_min: -579.1428571428571
queue_len: 0.34960120524636656
wait_time: 2.416403757532789
delay_time: 80.9706357425303
pressure: 4.891066997518611
total_envstep_count: 323640
total_train_sample_count: 323640
total_episode_count: 2610
total_duration: 65997.43951498634
[2024-12-27 14:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.211220074089503
avg_train_sample_per_sec: 5.211220074089503
avg_episode_per_sec: 0.04202596833943148
collect_time: 118.97405812559651
reward_mean: -555.3285714285714
reward_std: 9.974927752794514
reward_max: -542.3571428571429
reward_min: -571.6428571428572
queue_len: 0.3444966323998582
wait_time: 2.373537752570011
delay_time: 80.77948734965139
pressure: 4.821712158808934
total_envstep_count: 324260
total_train_sample_count: 324260
total_episode_count: 2615
total_duration: 66116.41357311193
[2024-12-27 14:37:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.315262360226299
avg_train_sample_per_sec: 5.315262360226299
avg_episode_per_sec: 0.04286501903408306
collect_time: 116.64522990236803
reward_mean: -553.2142857142857
reward_std: 4.176464670370962
reward_max: -547.9999999999999
reward_min: -559.9999999999998
queue_len: 0.3431850407656859
wait_time: 2.3771446295639844
delay_time: 80.32467843722613
pressure: 4.800868486352357
total_envstep_count: 324880
total_train_sample_count: 324880
total_episode_count: 2620
total_duration: 66233.0588030143
[2024-12-27 14:39:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.11144591773535
avg_train_sample_per_sec: 5.11144591773535
avg_episode_per_sec: 0.04122133804625282
collect_time: 121.29640222715962
reward_mean: -556.3
reward_std: 6.444329891858653
reward_max: -546.1428571428571
reward_min: -564.7142857142859
queue_len: 0.3450992555831266
wait_time: 2.3491669620701883
delay_time: 80.79651465076148
pressure: 4.82667493796526
total_envstep_count: 325500
total_train_sample_count: 325500
total_episode_count: 2625
total_duration: 66354.35520524146
[2024-12-27 14:41:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.13918910372204
avg_train_sample_per_sec: 5.13918910372204
avg_episode_per_sec: 0.041445073417113225
collect_time: 120.64160074416549
reward_mean: -564.1142857142859
reward_std: 11.685120487882088
reward_max: -549.6428571428573
reward_min: -581.9285714285712
queue_len: 0.34994682736618227
wait_time: 2.391527827011698
delay_time: 80.69030410866984
pressure: 4.897890818858561
total_envstep_count: 326120
total_train_sample_count: 326120
total_episode_count: 2630
total_duration: 66474.99680598562
[2024-12-27 14:43:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.387375355583866
avg_train_sample_per_sec: 5.387375355583866
avg_episode_per_sec: 0.04344657544825698
collect_time: 115.08386906016993
reward_mean: -551.9428571428572
reward_std: 9.43110355609098
reward_max: -540.9285714285716
reward_min: -567.142857142857
queue_len: 0.3423963133640553
wait_time: 2.3511432116270825
delay_time: 80.34388995498671
pressure: 4.785856079404466
total_envstep_count: 326740
total_train_sample_count: 326740
total_episode_count: 2635
total_duration: 66590.08067504579
[2024-12-27 14:45:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.279788344546429
avg_train_sample_per_sec: 5.279788344546429
avg_episode_per_sec: 0.0425789382624712
collect_time: 117.42894971166925
reward_mean: -551.5428571428572
reward_std: 13.307861724314304
reward_max: -538.2142857142856
reward_min: -574.7142857142857
queue_len: 0.34214817440623896
wait_time: 2.3526586316908906
delay_time: 80.45946657665635
pressure: 4.787468982630273
total_envstep_count: 327360
total_train_sample_count: 327360
total_episode_count: 2640
total_duration: 66707.50962475745
[2024-12-27 14:47:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.132402239270094
avg_train_sample_per_sec: 5.132402239270094
avg_episode_per_sec: 0.04139034063927496
collect_time: 120.80113192534446
reward_mean: -795.6000000000001
reward_std: 492.4957010068253
reward_max: -535.9285714285712
reward_min: -1780.3571428571433
queue_len: 0.4935483870967743
wait_time: 2.678509393831974
delay_time: 123.09863859281545
pressure: 6.869602977667495
total_envstep_count: 327980
total_train_sample_count: 327980
total_episode_count: 2645
total_duration: 66828.3107566828
[2024-12-27 14:49:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.292368555300096
avg_train_sample_per_sec: 5.292368555300096
avg_episode_per_sec: 0.04268039157500078
collect_time: 117.14981553563473
reward_mean: -549.3428571428572
reward_std: 5.9630494869382
reward_max: -541.9285714285712
reward_min: -557.2142857142857
queue_len: 0.34078341013824887
wait_time: 2.3687167671038636
delay_time: 79.87177593437339
pressure: 4.764764267990074
total_envstep_count: 328600
total_train_sample_count: 328600
total_episode_count: 2650
total_duration: 66945.46057221844
[2024-12-27 14:51:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.152169515284991
avg_train_sample_per_sec: 5.152169515284991
avg_episode_per_sec: 0.04154975415552413
collect_time: 120.337655459635
reward_mean: -567.1285714285715
reward_std: 11.289276110630015
reward_max: -555.7142857142857
reward_min: -587.7142857142858
queue_len: 0.35181673165544136
wait_time: 2.3991758241758236
delay_time: 81.49894290047862
pressure: 4.916997518610422
total_envstep_count: 329220
total_train_sample_count: 329220
total_episode_count: 2655
total_duration: 67065.79822767807
[2024-12-27 14:53:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.514624524464851
avg_train_sample_per_sec: 5.514624524464851
avg_episode_per_sec: 0.04447277842310363
collect_time: 112.4283253101744
reward_mean: -555.6857142857142
reward_std: 4.96263590262685
reward_max: -549.6428571428571
reward_min: -563.2142857142856
queue_len: 0.34471818504076573
wait_time: 2.3760900389932655
delay_time: 80.50119678596761
pressure: 4.819354838709677
total_envstep_count: 329840
total_train_sample_count: 329840
total_episode_count: 2660
total_duration: 67178.22655298824
[2024-12-27 14:55:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.213141199006974
avg_train_sample_per_sec: 5.213141199006974
avg_episode_per_sec: 0.042041461282314306
collect_time: 118.9302143049762
reward_mean: -561.9428571428572
reward_std: 3.205670995378636
reward_max: -556.7142857142858
reward_min: -566.0714285714284
queue_len: 0.3485997873094647
wait_time: 2.3641173342786246
delay_time: 81.12988605191624
pressure: 4.876178660049628
total_envstep_count: 330460
total_train_sample_count: 330460
total_episode_count: 2665
total_duration: 67297.15676729321
[2024-12-27 14:57:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.01544523216706
avg_train_sample_per_sec: 5.01544523216706
avg_episode_per_sec: 0.04044713896908919
collect_time: 123.61813783222433
reward_mean: -614.9142857142857
reward_std: 113.72312779693645
reward_max: -546.4285714285713
reward_min: -841.8571428571425
queue_len: 0.3814604750088621
wait_time: 2.492378589152782
delay_time: 87.52672569151919
pressure: 5.261166253101736
total_envstep_count: 331080
total_train_sample_count: 331080
total_episode_count: 2670
total_duration: 67420.77490512544
[2024-12-27 14:59:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.486052094256652
avg_train_sample_per_sec: 5.486052094256652
avg_episode_per_sec: 0.04424235559884397
collect_time: 113.01387397488952
reward_mean: -558.6000000000001
reward_std: 8.748014351956718
reward_max: -546.1428571428572
reward_min: -572.7857142857143
queue_len: 0.34652605459057073
wait_time: 2.3599964551577455
delay_time: 80.71918747173477
pressure: 4.849503722084367
total_envstep_count: 331700
total_train_sample_count: 331700
total_episode_count: 2675
total_duration: 67533.78877910033
[2024-12-27 15:01:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.167378729003169
avg_train_sample_per_sec: 5.167378729003169
avg_episode_per_sec: 0.041672409104864264
collect_time: 119.98346405695006
reward_mean: -561.6428571428572
reward_std: 9.036772947580541
reward_max: -553.9285714285713
reward_min: -578.9285714285716
queue_len: 0.3484136830911025
wait_time: 2.3878677773839065
delay_time: 81.51314583978238
pressure: 4.8710918114143915
total_envstep_count: 332320
total_train_sample_count: 332320
total_episode_count: 2680
total_duration: 67653.77224315728
[2024-12-27 15:03:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.354716728415993
avg_train_sample_per_sec: 5.354716728415993
avg_episode_per_sec: 0.04318319942270962
collect_time: 115.78577008748798
reward_mean: -560.6714285714286
reward_std: 12.678327965469128
reward_max: -546.2857142857146
reward_min: -582.4999999999998
queue_len: 0.3478110599078341
wait_time: 2.3802463665366895
delay_time: 80.8857087160747
pressure: 4.86712158808933
total_envstep_count: 332940
total_train_sample_count: 332940
total_episode_count: 2685
total_duration: 67769.55801324476
[2024-12-27 15:05:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.215137585971711
avg_train_sample_per_sec: 5.215137585971711
avg_episode_per_sec: 0.04205756117719121
collect_time: 118.8846870824173
reward_mean: -552.3285714285712
reward_std: 13.647127230030973
reward_max: -531.6428571428569
reward_min: -574.7142857142854
queue_len: 0.34263559021623524
wait_time: 2.3583126550868485
delay_time: 80.26969182256968
pressure: 4.791315136476426
total_envstep_count: 333560
total_train_sample_count: 333560
total_episode_count: 2690
total_duration: 67888.44270032718
[2024-12-27 15:07:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.158181002778842
avg_train_sample_per_sec: 5.158181002778842
avg_episode_per_sec: 0.04159823389337776
collect_time: 120.19741061160715
reward_mean: -547.9
reward_std: 9.983210395254467
reward_max: -534.0
reward_min: -559.1428571428569
queue_len: 0.3398883374689826
wait_time: 2.342963488124778
delay_time: 79.94143044190523
pressure: 4.754962779156328
total_envstep_count: 334180
total_train_sample_count: 334180
total_episode_count: 2695
total_duration: 68008.6401109388
[2024-12-27 15:09:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3482986952622875
avg_train_sample_per_sec: 5.3482986952622875
avg_episode_per_sec: 0.043131441090824896
collect_time: 115.92471462919937
reward_mean: -551.0
reward_std: 10.224420546427277
reward_max: -538.0714285714287
reward_min: -565.3571428571431
queue_len: 0.3418114143920596
wait_time: 2.3667316554413333
delay_time: 80.10009022284812
pressure: 4.774441687344913
total_envstep_count: 334800
total_train_sample_count: 334800
total_episode_count: 2700
total_duration: 68124.564825568
[2024-12-27 15:10:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.323026155539554
avg_train_sample_per_sec: 5.323026155539554
avg_episode_per_sec: 0.04292763028660931
collect_time: 116.47509929192813
reward_mean: -550.9285714285714
reward_std: 6.167558310239556
reward_max: -542.7857142857143
reward_min: -561.9285714285717
queue_len: 0.34176710386387804
wait_time: 2.3677419354838714
delay_time: 79.78383681309845
pressure: 4.782382133995037
total_envstep_count: 335420
total_train_sample_count: 335420
total_episode_count: 2705
total_duration: 68241.03992485993
[2024-12-27 15:12:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.313459214613352
avg_train_sample_per_sec: 5.313459214613352
avg_episode_per_sec: 0.04285047753720445
collect_time: 116.68481397106498
reward_mean: -551.5571428571429
reward_std: 3.972969896175791
reward_max: -545.1428571428572
reward_min: -555.7142857142862
queue_len: 0.34215703651187523
wait_time: 2.3255760368663596
delay_time: 80.35528152966715
pressure: 4.78498759305211
total_envstep_count: 336040
total_train_sample_count: 336040
total_episode_count: 2710
total_duration: 68357.72473883099
[2024-12-27 15:14:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2851697789514
avg_train_sample_per_sec: 5.2851697789514
avg_episode_per_sec: 0.04262233692702742
collect_time: 117.30938189898805
reward_mean: -553.6142857142859
reward_std: 5.273847683404839
reward_max: -544.5714285714288
reward_min: -560.5714285714287
queue_len: 0.34343317972350235
wait_time: 2.3199397376816737
delay_time: 80.71619621350229
pressure: 4.804714640198512
total_envstep_count: 336660
total_train_sample_count: 336660
total_episode_count: 2715
total_duration: 68475.03412072998
[2024-12-27 15:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5571793491690995
avg_train_sample_per_sec: 5.5571793491690995
avg_episode_per_sec: 0.04481596249329919
collect_time: 111.56739076501128
reward_mean: -552.9285714285714
reward_std: 14.37862642811149
reward_max: -530.7857142857142
reward_min: -574.9285714285717
queue_len: 0.34300779865295994
wait_time: 2.3641527827011695
delay_time: 80.2356921284389
pressure: 4.80136476426799
total_envstep_count: 337280
total_train_sample_count: 337280
total_episode_count: 2720
total_duration: 68586.60151149498
[2024-12-27 15:18:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5126677279474015
avg_train_sample_per_sec: 5.5126677279474015
avg_episode_per_sec: 0.04445699780602743
collect_time: 112.46823327602445
reward_mean: -552.7142857142859
reward_std: 8.876821457237792
reward_max: -542.1428571428569
reward_min: -566.0714285714289
queue_len: 0.3428748670684155
wait_time: 2.380521091811415
delay_time: 79.81781092869474
pressure: 4.796774193548387
total_envstep_count: 337900
total_train_sample_count: 337900
total_episode_count: 2725
total_duration: 68699.06974477101
[2024-12-27 15:20:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3307312265532145
avg_train_sample_per_sec: 5.3307312265532145
avg_episode_per_sec: 0.042989767956074315
collect_time: 116.30674548206107
reward_mean: -549.9857142857143
reward_std: 15.865338937187587
reward_max: -526.3571428571427
reward_min: -574.7857142857144
queue_len: 0.34118220489188233
wait_time: 2.3469248493442043
delay_time: 80.22445804833505
pressure: 4.772704714640199
total_envstep_count: 338520
total_train_sample_count: 338520
total_episode_count: 2730
total_duration: 68815.37649025307
[2024-12-27 15:22:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3196429462774715
avg_train_sample_per_sec: 5.3196429462774715
avg_episode_per_sec: 0.04290034634094735
collect_time: 116.54917562349887
reward_mean: -556.0000000000002
reward_std: 10.622559743781414
reward_max: -542.8571428571428
reward_min: -571.5714285714288
queue_len: 0.3449131513647644
wait_time: 2.3584898971995747
delay_time: 80.84436952152119
pressure: 4.8263027295285355
total_envstep_count: 339140
total_train_sample_count: 339140
total_episode_count: 2735
total_duration: 68931.92566587657
[2024-12-27 15:24:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.32001108679484
avg_train_sample_per_sec: 5.32001108679484
avg_episode_per_sec: 0.042903315216087416
collect_time: 116.54111051364988
reward_mean: -548.4714285714285
reward_std: 9.549185241449067
reward_max: -538.1428571428573
reward_min: -563.142857142857
queue_len: 0.3402428216944346
wait_time: 2.325301311591635
delay_time: 80.19868615081896
pressure: 4.761166253101736
total_envstep_count: 339760
total_train_sample_count: 339760
total_episode_count: 2740
total_duration: 69048.46677639021
[2024-12-27 15:26:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.592831279019139
avg_train_sample_per_sec: 5.592831279019139
avg_episode_per_sec: 0.04510347805660596
collect_time: 110.85619591741636
reward_mean: -553.0714285714287
reward_std: 13.863695063594209
reward_max: -536.7857142857144
reward_min: -571.9285714285717
queue_len: 0.34309641970932303
wait_time: 2.341580999645516
delay_time: 79.88902201148542
pressure: 4.80272952853598
total_envstep_count: 340380
total_train_sample_count: 340380
total_episode_count: 2745
total_duration: 69159.32297230762
[2024-12-27 15:28:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.278365987125184
avg_train_sample_per_sec: 5.278365987125184
avg_episode_per_sec: 0.04256746763810632
collect_time: 117.46059320484474
reward_mean: -544.3571428571429
reward_std: 19.11821441581252
reward_max: -525.5714285714289
reward_min: -580.9285714285717
queue_len: 0.33769053527118054
wait_time: 2.2765863169088982
delay_time: 79.3923803474241
pressure: 4.726054590570719
total_envstep_count: 341000
total_train_sample_count: 341000
total_episode_count: 2750
total_duration: 69276.78356551247
[2024-12-27 15:30:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.512349381715607
avg_train_sample_per_sec: 5.512349381715607
avg_episode_per_sec: 0.044454430497706504
collect_time: 112.47472848084197
reward_mean: -556.5428571428571
reward_std: 16.662165378546653
reward_max: -540.0714285714287
reward_min: -587.642857142857
queue_len: 0.34524991137894356
wait_time: 2.3715349166962065
delay_time: 79.9702954582109
pressure: 4.8318858560794045
total_envstep_count: 341620
total_train_sample_count: 341620
total_episode_count: 2755
total_duration: 69389.2582939933
[2024-12-27 15:32:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.323407074043554
avg_train_sample_per_sec: 5.323407074043554
avg_episode_per_sec: 0.04293070221002866
collect_time: 116.46676487001403
reward_mean: -545.4428571428573
reward_std: 6.374118586526549
reward_max: -538.7142857142857
reward_min: -553.5000000000001
queue_len: 0.33836405529953917
wait_time: 2.339879475363346
delay_time: 78.80847103696138
pressure: 4.735483870967742
total_envstep_count: 342240
total_train_sample_count: 342240
total_episode_count: 2760
total_duration: 69505.72505886332
[2024-12-27 15:34:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.395063750179507
avg_train_sample_per_sec: 5.395063750179507
avg_episode_per_sec: 0.0435085786304799
collect_time: 114.91986540091784
reward_mean: -537.9428571428571
reward_std: 8.965625966969228
reward_max: -523.4285714285713
reward_min: -550.2142857142858
queue_len: 0.333711449840482
wait_time: 2.3263824884792634
delay_time: 78.27570146006482
pressure: 4.667990074441687
total_envstep_count: 342860
total_train_sample_count: 342860
total_episode_count: 2765
total_duration: 69620.64492426424
[2024-12-27 15:36:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.402655070482818
avg_train_sample_per_sec: 5.402655070482818
avg_episode_per_sec: 0.0435697989555066
collect_time: 114.75839044164495
reward_mean: -629.8571428571431
reward_std: 165.9080332901458
reward_max: -524.7142857142858
reward_min: -960.6428571428576
queue_len: 0.39073023750443114
wait_time: 2.421481744062389
delay_time: 91.7391928745844
pressure: 5.468734491315137
total_envstep_count: 343480
total_train_sample_count: 343480
total_episode_count: 2770
total_duration: 69735.40331470588
[2024-12-27 15:37:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4518906781815035
avg_train_sample_per_sec: 5.4518906781815035
avg_episode_per_sec: 0.04396686030791535
collect_time: 113.7220161954537
reward_mean: -536.4142857142857
reward_std: 17.28922042363802
reward_max: -513.0
reward_min: -553.3571428571428
queue_len: 0.332763204537398
wait_time: 2.335864941510103
delay_time: 77.99824878217592
pressure: 4.657196029776675
total_envstep_count: 344100
total_train_sample_count: 344100
total_episode_count: 2775
total_duration: 69849.12533090133
[2024-12-27 15:39:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4654801373005
avg_train_sample_per_sec: 5.4654801373005
avg_episode_per_sec: 0.044076452720165325
collect_time: 113.4392559161745
reward_mean: -546.6714285714286
reward_std: 11.829968861552718
reward_max: -536.4285714285714
reward_min: -566.857142857143
queue_len: 0.3391261963842609
wait_time: 2.3356788372917405
delay_time: 79.61750356725994
pressure: 4.746650124069479
total_envstep_count: 344720
total_train_sample_count: 344720
total_episode_count: 2780
total_duration: 69962.5645868175
[2024-12-27 15:41:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.20925610866516
avg_train_sample_per_sec: 5.20925610866516
avg_episode_per_sec: 0.04201012990859
collect_time: 119.01891307833417
reward_mean: -546.7428571428571
reward_std: 6.869126433483655
reward_max: -537.0000000000002
reward_min: -554.6428571428573
queue_len: 0.33917050691244244
wait_time: 2.3674140375753274
delay_time: 78.85187851369622
pressure: 4.746153846153847
total_envstep_count: 345340
total_train_sample_count: 345340
total_episode_count: 2785
total_duration: 70081.58349989585
[2024-12-27 15:43:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.322444861583851
avg_train_sample_per_sec: 5.322444861583851
avg_episode_per_sec: 0.04292294243212783
collect_time: 116.48782018861547
reward_mean: -554.5571428571428
reward_std: 11.761871987615754
reward_max: -545.0714285714286
reward_min: -577.2142857142857
queue_len: 0.34401807869549805
wait_time: 2.4061237149946826
delay_time: 79.69390106893763
pressure: 4.813647642679901
total_envstep_count: 345960
total_train_sample_count: 345960
total_episode_count: 2790
total_duration: 70198.07132008446
[2024-12-27 15:45:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.368595648051232
avg_train_sample_per_sec: 5.368595648051232
avg_episode_per_sec: 0.04329512619396155
collect_time: 115.48644015033173
reward_mean: -541.7285714285714
reward_std: 10.685427803646391
reward_max: -523.9999999999999
reward_min: -553.2142857142857
queue_len: 0.33605990783410133
wait_time: 2.334260900389933
delay_time: 78.10779670705745
pressure: 4.7028535980148884
total_envstep_count: 346580
total_train_sample_count: 346580
total_episode_count: 2795
total_duration: 70313.55776023479
[2024-12-27 15:47:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.403559589973072
avg_train_sample_per_sec: 5.403559589973072
avg_episode_per_sec: 0.04357709346752477
collect_time: 114.73918065981572
reward_mean: -542.342857142857
reward_std: 11.026535711451704
reward_max: -527.7857142857142
reward_min: -559.5
queue_len: 0.3364409783764622
wait_time: 2.3582949308755756
delay_time: 78.72410628614045
pressure: 4.708188585607941
total_envstep_count: 347200
total_train_sample_count: 347200
total_episode_count: 2800
total_duration: 70428.29694089461
[2024-12-27 15:49:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.151518728486201
avg_train_sample_per_sec: 5.151518728486201
avg_episode_per_sec: 0.04154450587488872
collect_time: 120.35285760907833
reward_mean: -540.3428571428573
reward_std: 9.675806141598603
reward_max: -529.142857142857
reward_min: -555.1428571428572
queue_len: 0.33520028358738035
wait_time: 2.3226604041120167
delay_time: 78.26494351708443
pressure: 4.690818858560794
total_envstep_count: 347820
total_train_sample_count: 347820
total_episode_count: 2805
total_duration: 70548.64979850368
[2024-12-27 15:51:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4918090421946975
avg_train_sample_per_sec: 5.4918090421946975
avg_episode_per_sec: 0.04428878259834434
collect_time: 112.89540390723941
reward_mean: -550.6142857142855
reward_std: 18.24401495375001
reward_max: -534.2142857142854
reward_min: -585.4999999999999
queue_len: 0.3415721375398794
wait_time: 2.38021978021978
delay_time: 78.8383150386612
pressure: 4.781761786600496
total_envstep_count: 348440
total_train_sample_count: 348440
total_episode_count: 2810
total_duration: 70661.54520241093
[2024-12-27 15:53:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.534883974704167
avg_train_sample_per_sec: 5.534883974704167
avg_episode_per_sec: 0.04463616108632393
collect_time: 112.01680158672852
reward_mean: -541.3285714285714
reward_std: 13.865873538280567
reward_max: -526.357142857143
reward_min: -565.3571428571428
queue_len: 0.33581176887628506
wait_time: 2.3170329670329677
delay_time: 78.14046743080986
pressure: 4.698387096774193
total_envstep_count: 349060
total_train_sample_count: 349060
total_episode_count: 2815
total_duration: 70773.56200399765
[2024-12-27 15:55:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3845060290407725
avg_train_sample_per_sec: 5.3845060290407725
avg_episode_per_sec: 0.043423435718070745
collect_time: 115.14519561424848
reward_mean: -544.1428571428571
reward_std: 10.092328871019644
reward_max: -528.0
reward_min: -555.8571428571427
queue_len: 0.337557603686636
wait_time: 2.321109535625664
delay_time: 78.49351149371999
pressure: 4.723076923076923
total_envstep_count: 349680
total_train_sample_count: 349680
total_episode_count: 2820
total_duration: 70888.7071996119
[2024-12-27 15:57:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.282682332563165
avg_train_sample_per_sec: 5.282682332563165
avg_episode_per_sec: 0.042602276875509396
collect_time: 117.3646191402115
reward_mean: -578.3
reward_std: 52.90330802511313
reward_max: -539.1428571428573
reward_min: -681.5000000000001
queue_len: 0.35874689826302736
wait_time: 2.4008064516129033
delay_time: 81.8469283314617
pressure: 5.020595533498759
total_envstep_count: 350300
total_train_sample_count: 350300
total_episode_count: 2825
total_duration: 71006.07181875211
[2024-12-27 15:59:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.528339894686227
avg_train_sample_per_sec: 5.528339894686227
avg_episode_per_sec: 0.044583386247469575
collect_time: 112.14939960474146
reward_mean: -545.1428571428572
reward_std: 11.70304338579478
reward_max: -530.857142857143
reward_min: -565.5714285714286
queue_len: 0.3381779510811769
wait_time: 2.330370436015597
delay_time: 78.7757432908144
pressure: 4.73287841191067
total_envstep_count: 350920
total_train_sample_count: 350920
total_episode_count: 2830
total_duration: 71118.22121835685
[2024-12-27 16:01:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6598072407685
avg_train_sample_per_sec: 5.6598072407685
avg_episode_per_sec: 0.04564360678039113
collect_time: 109.54436672931907
reward_mean: -539.6
reward_std: 10.019633786945013
reward_max: -528.2857142857142
reward_min: -552.4285714285716
queue_len: 0.33473945409429284
wait_time: 2.329360155973059
delay_time: 78.23733365968229
pressure: 4.681637717121588
total_envstep_count: 351540
total_train_sample_count: 351540
total_episode_count: 2835
total_duration: 71227.76558508616
[2024-12-27 16:02:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.570874089756292
avg_train_sample_per_sec: 5.570874089756292
avg_episode_per_sec: 0.04492640394964751
collect_time: 111.29312743579223
reward_mean: -614.9714285714286
reward_std: 162.94624504882026
reward_max: -507.42857142857144
reward_min: -939.5714285714284
queue_len: 0.3814959234314073
wait_time: 2.4500177242112726
delay_time: 86.47483997120737
pressure: 5.271464019851116
total_envstep_count: 352160
total_train_sample_count: 352160
total_episode_count: 2840
total_duration: 71339.05871252196
[2024-12-27 16:04:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.674352916256988
avg_train_sample_per_sec: 5.674352916256988
avg_episode_per_sec: 0.04576091061497571
collect_time: 109.26355994243917
reward_mean: -835.8285714285714
reward_std: 548.4946739458268
reward_max: -536.6428571428573
reward_min: -1930.2142857142858
queue_len: 0.5185040765685927
wait_time: 2.6642325416518973
delay_time: 131.19140193817512
pressure: 7.2070719602977675
total_envstep_count: 352780
total_train_sample_count: 352780
total_episode_count: 2845
total_duration: 71448.3222724644
[2024-12-27 16:06:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.672501360870623
avg_train_sample_per_sec: 5.672501360870623
avg_episode_per_sec: 0.04574597871669857
collect_time: 109.29922454965117
reward_mean: -546.9571428571429
reward_std: 14.074916174035312
reward_max: -522.7857142857147
reward_min: -563.357142857143
queue_len: 0.33930343849698696
wait_time: 2.3416253101736975
delay_time: 78.09579450223207
pressure: 4.7478908188585605
total_envstep_count: 353400
total_train_sample_count: 353400
total_episode_count: 2850
total_duration: 71557.62149701406
[2024-12-27 16:08:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.788872727620144
avg_train_sample_per_sec: 5.788872727620144
avg_episode_per_sec: 0.046684457480807615
collect_time: 107.10202645185592
reward_mean: -543.7428571428572
reward_std: 7.201842167962651
reward_max: -534.3571428571429
reward_min: -556.0000000000001
queue_len: 0.3373094647288197
wait_time: 2.3658365827720673
delay_time: 77.55837580519122
pressure: 4.720223325062035
total_envstep_count: 354020
total_train_sample_count: 354020
total_episode_count: 2855
total_duration: 71664.72352346592
[2024-12-27 16:10:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.738738182469879
avg_train_sample_per_sec: 5.738738182469879
avg_episode_per_sec: 0.0462801466328216
collect_time: 108.0376870814413
reward_mean: -539.8857142857144
reward_std: 10.635385680426895
reward_max: -531.8571428571429
reward_min: -560.6428571428572
queue_len: 0.3349166962070188
wait_time: 2.318477490251684
delay_time: 77.61028605397787
pressure: 4.6869727047146394
total_envstep_count: 354640
total_train_sample_count: 354640
total_episode_count: 2860
total_duration: 71772.76121054735
[2024-12-27 16:11:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.850665521605467
avg_train_sample_per_sec: 5.850665521605467
avg_episode_per_sec: 0.047182786464560214
collect_time: 105.97085027514397
reward_mean: -540.2571428571428
reward_std: 9.007661138368489
reward_max: -531.7857142857142
reward_min: -557.6428571428571
queue_len: 0.33514711095356253
wait_time: 2.337265154200638
delay_time: 77.8927224931764
pressure: 4.69106699751861
total_envstep_count: 355260
total_train_sample_count: 355260
total_episode_count: 2865
total_duration: 71878.7320608225
[2024-12-27 16:13:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.682442736389316
avg_train_sample_per_sec: 5.682442736389316
avg_episode_per_sec: 0.04582615109991384
collect_time: 109.10800667284059
reward_mean: -537.4714285714286
reward_std: 6.735771095049021
reward_max: -527.0
reward_min: -548.1428571428572
queue_len: 0.33341900035448424
wait_time: 2.3558224034030486
delay_time: 77.38930830506987
pressure: 4.665508684863523
total_envstep_count: 355880
total_train_sample_count: 355880
total_episode_count: 2870
total_duration: 71987.84006749534
[2024-12-27 16:15:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.745136463495018
avg_train_sample_per_sec: 5.745136463495018
avg_episode_per_sec: 0.04633174567334692
collect_time: 107.91736696587131
reward_mean: -546.0285714285714
reward_std: 8.552669949513117
reward_max: -533.857142857143
reward_min: -556.785714285714
queue_len: 0.3387274016306274
wait_time: 2.3779510811768874
delay_time: 78.4018295679243
pressure: 4.739454094292804
total_envstep_count: 356500
total_train_sample_count: 356500
total_episode_count: 2875
total_duration: 72095.75743446122
[2024-12-27 16:17:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.73989022638144
avg_train_sample_per_sec: 5.73989022638144
avg_episode_per_sec: 0.04628943730952774
collect_time: 108.01600301524624
reward_mean: -555.2142857142857
reward_std: 36.07862728733983
reward_max: -529.7142857142859
reward_min: -626.0714285714288
queue_len: 0.3444257355547678
wait_time: 2.3566643034384964
delay_time: 79.36316504291469
pressure: 4.818114143920596
total_envstep_count: 357120
total_train_sample_count: 357120
total_episode_count: 2880
total_duration: 72203.77343747647
[2024-12-27 16:19:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.670002737434752
avg_train_sample_per_sec: 5.670002737434752
avg_episode_per_sec: 0.04572582852769961
collect_time: 109.34738988865166
reward_mean: -540.9142857142856
reward_std: 10.49765765904599
reward_max: -521.5714285714288
reward_min: -551.6428571428568
queue_len: 0.3355547678128323
wait_time: 2.369292803970223
delay_time: 77.41549579896578
pressure: 4.695781637717121
total_envstep_count: 357740
total_train_sample_count: 357740
total_episode_count: 2885
total_duration: 72313.12082736513
[2024-12-27 16:21:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.591263377298462
avg_train_sample_per_sec: 5.591263377298462
avg_episode_per_sec: 0.045090833687890824
collect_time: 110.88728220482545
reward_mean: -536.9428571428571
reward_std: 1.6887382078623914
reward_max: -534.4999999999997
reward_min: -539.3571428571428
queue_len: 0.3330911024459411
wait_time: 2.347190712513293
delay_time: 77.60810736665351
pressure: 4.659801488833747
total_envstep_count: 358360
total_train_sample_count: 358360
total_episode_count: 2890
total_duration: 72424.00810956996
[2024-12-27 16:22:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7598058624638275
avg_train_sample_per_sec: 5.7598058624638275
avg_episode_per_sec: 0.046450047277934094
collect_time: 107.64251691892744
reward_mean: -539.4571428571428
reward_std: 12.729012338042589
reward_max: -529.3571428571428
reward_min: -561.0714285714286
queue_len: 0.3346508330379298
wait_time: 2.3281194611839773
delay_time: 77.58240611487153
pressure: 4.681389578163772
total_envstep_count: 358980
total_train_sample_count: 358980
total_episode_count: 2895
total_duration: 72531.65062648889
[2024-12-27 16:24:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.612886600885716
avg_train_sample_per_sec: 5.612886600885716
avg_episode_per_sec: 0.0452652145232719
collect_time: 110.46009728793803
reward_mean: -540.3571428571429
reward_std: 13.350456691722151
reward_max: -522.5000000000002
reward_min: -555.642857142857
queue_len: 0.3352091456930167
wait_time: 2.3387805742644456
delay_time: 77.31151578636704
pressure: 4.69106699751861
total_envstep_count: 359600
total_train_sample_count: 359600
total_episode_count: 2900
total_duration: 72642.11072377683
[2024-12-27 16:26:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.053165689983292
avg_train_sample_per_sec: 6.053165689983292
avg_episode_per_sec: 0.04881585233857493
collect_time: 102.42574410708248
reward_mean: -531.9714285714286
reward_std: 9.445720335319251
reward_max: -523.5714285714284
reward_min: -546.5714285714287
queue_len: 0.33000708968450904
wait_time: 2.3147465437788015
delay_time: 76.7429608603819
pressure: 4.618238213399503
total_envstep_count: 360220
total_train_sample_count: 360220
total_episode_count: 2905
total_duration: 72744.53646788391
[2024-12-27 16:28:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.922803606798987
avg_train_sample_per_sec: 5.922803606798987
avg_episode_per_sec: 0.04776454521612086
collect_time: 104.68015506850185
reward_mean: -537.8
reward_std: 6.030094594309974
reward_max: -529.4285714285713
reward_min: -543.7857142857143
queue_len: 0.3336228287841191
wait_time: 2.3361573909961004
delay_time: 77.4799640955951
pressure: 4.669727047146402
total_envstep_count: 360840
total_train_sample_count: 360840
total_episode_count: 2910
total_duration: 72849.21662295242
[2024-12-27 16:30:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.761522708667834
avg_train_sample_per_sec: 5.761522708667834
avg_episode_per_sec: 0.046463892811837375
collect_time: 107.61044108482824
reward_mean: -531.1571428571428
reward_std: 10.289423934213167
reward_max: -524.3571428571428
reward_min: -551.5714285714286
queue_len: 0.32950194966324
wait_time: 2.3226692662176536
delay_time: 76.84224936321763
pressure: 4.611166253101737
total_envstep_count: 361460
total_train_sample_count: 361460
total_episode_count: 2915
total_duration: 72956.82706403725
[2024-12-27 16:31:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.796754874167539
avg_train_sample_per_sec: 5.796754874167539
avg_episode_per_sec: 0.04674802317877048
collect_time: 106.95639430312067
reward_mean: -536.7142857142857
reward_std: 12.60684945024827
reward_max: -518.7857142857143
reward_min: -556.2857142857144
queue_len: 0.33294930875576034
wait_time: 2.3448245303084017
delay_time: 77.20476182502638
pressure: 4.65955334987593
total_envstep_count: 362080
total_train_sample_count: 362080
total_episode_count: 2920
total_duration: 73063.78345834037
[2024-12-27 16:33:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.051300105881219
avg_train_sample_per_sec: 6.051300105881219
avg_episode_per_sec: 0.0488008073054937
collect_time: 102.45732142708079
reward_mean: -524.8
reward_std: 8.177046021189666
reward_max: -511.9999999999998
reward_min: -533.1428571428572
queue_len: 0.32555831265508683
wait_time: 2.31149415101028
delay_time: 75.92881055702318
pressure: 4.556947890818859
total_envstep_count: 362700
total_train_sample_count: 362700
total_episode_count: 2925
total_duration: 73166.24077976745
[2024-12-27 16:35:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.848707058285427
avg_train_sample_per_sec: 5.848707058285427
avg_episode_per_sec: 0.04716699240552764
collect_time: 106.00633504488692
reward_mean: -517.9857142857142
reward_std: 10.8672321542274
reward_max: -502.4285714285717
reward_min: -530.642857142857
queue_len: 0.3213310882665721
wait_time: 2.277472527472528
delay_time: 75.2079122719794
pressure: 4.497022332506203
total_envstep_count: 363320
total_train_sample_count: 363320
total_episode_count: 2930
total_duration: 73272.24711481234
[2024-12-27 16:37:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.812609636604311
avg_train_sample_per_sec: 5.812609636604311
avg_episode_per_sec: 0.04687588416616379
collect_time: 106.66465473539009
reward_mean: -529.1714285714285
reward_std: 3.087697775207337
reward_max: -525.5
reward_min: -533.642857142857
queue_len: 0.32827011697979436
wait_time: 2.3152516838000703
delay_time: 75.7522445091667
pressure: 4.595161290322581
total_envstep_count: 363940
total_train_sample_count: 363940
total_episode_count: 2935
total_duration: 73378.91176954773
[2024-12-27 16:38:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.823301339139908
avg_train_sample_per_sec: 5.823301339139908
avg_episode_per_sec: 0.04696210757370894
collect_time: 106.468816207882
reward_mean: -535.5142857142857
reward_std: 6.857053570847099
reward_max: -525.0
reward_min: -544.4999999999994
queue_len: 0.3322048918823112
wait_time: 2.3493530662885505
delay_time: 76.3418613541981
pressure: 4.647890818858562
total_envstep_count: 364560
total_train_sample_count: 364560
total_episode_count: 2940
total_duration: 73485.38058575561
[2024-12-27 16:40:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.635794855540608
avg_train_sample_per_sec: 5.635794855540608
avg_episode_per_sec: 0.045449958512424254
collect_time: 110.01110152021798
reward_mean: -530.1857142857141
reward_std: 8.387137868942734
reward_max: -521.2857142857141
reward_min: -544.6428571428571
queue_len: 0.32889932647997155
wait_time: 2.3254076568592703
delay_time: 76.5243627929194
pressure: 4.598138957816377
total_envstep_count: 365180
total_train_sample_count: 365180
total_episode_count: 2945
total_duration: 73595.39168727583
[2024-12-27 16:42:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.94870820856387
avg_train_sample_per_sec: 5.94870820856387
avg_episode_per_sec: 0.04797345329486992
collect_time: 104.22430858306961
reward_mean: -542.3428571428573
reward_std: 11.120160034085542
reward_max: -526.0000000000002
reward_min: -555.2142857142859
queue_len: 0.33644097837646225
wait_time: 2.351905352711804
delay_time: 78.09117379415463
pressure: 4.706823821339951
total_envstep_count: 365800
total_train_sample_count: 365800
total_episode_count: 2950
total_duration: 73699.6159958589
[2024-12-27 16:44:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.802886621134704
avg_train_sample_per_sec: 5.802886621134704
avg_episode_per_sec: 0.04679747275108632
collect_time: 106.84337649160625
reward_mean: -534.3571428571429
reward_std: 11.928186477963086
reward_max: -520.9999999999998
reward_min: -549.5714285714286
queue_len: 0.331487061325771
wait_time: 2.3236440978376467
delay_time: 76.85727733612681
pressure: 4.639454094292804
total_envstep_count: 366420
total_train_sample_count: 366420
total_episode_count: 2955
total_duration: 73806.45937235051
[2024-12-27 16:46:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.884022997011635
avg_train_sample_per_sec: 5.884022997011635
avg_episode_per_sec: 0.04745179836299706
collect_time: 105.37008443285899
reward_mean: -529.0857142857143
reward_std: 6.91218976496866
reward_max: -520.5714285714287
reward_min: -539.7142857142856
queue_len: 0.32821694434597665
wait_time: 2.326958525345622
delay_time: 76.57676729566535
pressure: 4.590942928039702
total_envstep_count: 367040
total_train_sample_count: 367040
total_episode_count: 2960
total_duration: 73911.82945678337
[2024-12-27 16:47:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.946672134178052
avg_train_sample_per_sec: 5.946672134178052
avg_episode_per_sec: 0.04795703334014558
collect_time: 104.25999382689967
reward_mean: -527.7857142857143
reward_std: 7.027497014279987
reward_max: -519.9285714285714
reward_min: -537.2142857142857
queue_len: 0.3274104927330734
wait_time: 2.322119815668203
delay_time: 77.10739237275176
pressure: 4.580645161290322
total_envstep_count: 367660
total_train_sample_count: 367660
total_episode_count: 2965
total_duration: 74016.08945061026
[2024-12-27 16:49:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.710547957585992
avg_train_sample_per_sec: 5.710547957585992
avg_episode_per_sec: 0.04605280610956445
collect_time: 108.57101710815354
reward_mean: -523.1285714285714
reward_std: 6.218373040056818
reward_max: -514.9285714285714
reward_min: -530.3571428571428
queue_len: 0.32452144629563984
wait_time: 2.2920506912442398
delay_time: 76.3292334016926
pressure: 4.540818858560794
total_envstep_count: 368280
total_train_sample_count: 368280
total_episode_count: 2970
total_duration: 74124.66046771842
[2024-12-27 16:51:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5634458375531235
avg_train_sample_per_sec: 5.5634458375531235
avg_episode_per_sec: 0.044866498689944544
collect_time: 111.44172480569779
reward_mean: -531.2857142857143
reward_std: 3.769101013368997
reward_max: -526.1428571428571
reward_min: -536.4285714285713
queue_len: 0.32958170861396663
wait_time: 2.3271091811414393
delay_time: 77.01063893768068
pressure: 4.612282878411911
total_envstep_count: 368900
total_train_sample_count: 368900
total_episode_count: 2975
total_duration: 74236.10219252412
[2024-12-27 16:53:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.472043181443016
avg_train_sample_per_sec: 5.472043181443016
avg_episode_per_sec: 0.0441293804955082
collect_time: 113.30319945254921
reward_mean: -562.9857142857143
reward_std: 58.59421856275226
reward_max: -524.4285714285713
reward_min: -679.2857142857141
queue_len: 0.3492467210209146
wait_time: 2.39805919886565
delay_time: 79.27538385662822
pressure: 4.885980148883374
total_envstep_count: 369520
total_train_sample_count: 369520
total_episode_count: 2980
total_duration: 74349.40539197667
[2024-12-27 16:55:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.929107495833571
avg_train_sample_per_sec: 4.929107495833571
avg_episode_per_sec: 0.03975086690188363
collect_time: 125.78342032996191
reward_mean: -762.8
reward_std: 455.84554849382135
reward_max: -523.2142857142856
reward_min: -1674.3571428571433
queue_len: 0.4732009925558313
wait_time: 2.618406593406593
delay_time: 115.58020342899292
pressure: 6.519478908188586
total_envstep_count: 370140
total_train_sample_count: 370140
total_episode_count: 2985
total_duration: 74475.18881230663
[2024-12-27 16:57:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.704299212463353
avg_train_sample_per_sec: 5.704299212463353
avg_episode_per_sec: 0.04600241300373672
collect_time: 108.68995066832377
reward_mean: -539.0714285714284
reward_std: 8.954875538965794
reward_max: -529.5714285714283
reward_min: -553.4999999999999
queue_len: 0.3344115561857497
wait_time: 2.328057426444523
delay_time: 77.29833194827481
pressure: 4.679528535980149
total_envstep_count: 370760
total_train_sample_count: 370760
total_episode_count: 2990
total_duration: 74583.87876297496
[2024-12-27 16:59:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.477461901646303
avg_train_sample_per_sec: 5.477461901646303
avg_episode_per_sec: 0.04417307985198632
collect_time: 113.19111134550349
reward_mean: -531.0428571428572
reward_std: 6.078835817651227
reward_max: -522.7142857142859
reward_min: -541.6428571428573
queue_len: 0.32943105281814966
wait_time: 2.3034562211981564
delay_time: 76.954026465059
pressure: 4.610049627791564
total_envstep_count: 371380
total_train_sample_count: 371380
total_episode_count: 2995
total_duration: 74697.06987432046
[2024-12-27 17:01:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.450464950724306
avg_train_sample_per_sec: 5.450464950724306
avg_episode_per_sec: 0.04395536250584118
collect_time: 113.75176349269229
reward_mean: -525.4857142857143
reward_std: 9.311546485905762
reward_max: -512.285714285714
reward_min: -540.9285714285712
queue_len: 0.3259836937256292
wait_time: 2.306735200283587
delay_time: 76.37483287628156
pressure: 4.559305210918113
total_envstep_count: 372000
total_train_sample_count: 372000
total_episode_count: 3000
total_duration: 74810.82163781315
[2024-12-27 17:03:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.509878520784084
avg_train_sample_per_sec: 5.509878520784084
avg_episode_per_sec: 0.04443450419987164
collect_time: 112.5251668727845
reward_mean: -542.9714285714286
reward_std: 10.470327363652103
reward_max: -531.5000000000001
reward_min: -562.6428571428573
queue_len: 0.3368309110244594
wait_time: 2.389374335342077
delay_time: 78.0457492692583
pressure: 4.711042183622828
total_envstep_count: 372620
total_train_sample_count: 372620
total_episode_count: 3005
total_duration: 74923.34680468593
[2024-12-27 17:05:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.39229371096335
avg_train_sample_per_sec: 5.39229371096335
avg_episode_per_sec: 0.04348623960454314
collect_time: 114.9789001180418
reward_mean: -538.3285714285714
reward_std: 6.235612010288662
reward_max: -531.2857142857142
reward_min: -548.9285714285712
queue_len: 0.3339507266926621
wait_time: 2.3664923785891525
delay_time: 77.15883010330926
pressure: 4.672704714640199
total_envstep_count: 373240
total_train_sample_count: 373240
total_episode_count: 3010
total_duration: 75038.32570480398
[2024-12-27 17:06:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.731319907068994
avg_train_sample_per_sec: 5.731319907068994
avg_episode_per_sec: 0.04622032183120157
collect_time: 108.17752455857396
reward_mean: -618.8142857142858
reward_std: 115.05832238921442
reward_max: -507.2857142857144
reward_min: -818.4285714285716
queue_len: 0.3838798298475718
wait_time: 2.354147465437788
delay_time: 87.77013560573059
pressure: 5.372952853598015
total_envstep_count: 373860
total_train_sample_count: 373860
total_episode_count: 3015
total_duration: 75146.50322936256
[2024-12-27 17:08:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.006714832260478
avg_train_sample_per_sec: 6.006714832260478
avg_episode_per_sec: 0.048441248647261924
collect_time: 103.2178182773292
reward_mean: -537.342857142857
reward_std: 7.402757346187376
reward_max: -529.7857142857142
reward_min: -550.357142857143
queue_len: 0.33333924140375754
wait_time: 2.327259836937256
delay_time: 77.39327134581112
pressure: 4.662655086848635
total_envstep_count: 374480
total_train_sample_count: 374480
total_episode_count: 3020
total_duration: 75249.72104763989
[2024-12-27 17:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.012105288869309
avg_train_sample_per_sec: 6.012105288869309
avg_episode_per_sec: 0.04848472007152668
collect_time: 103.12527312983948
reward_mean: -604.6857142857142
reward_std: 150.83718482698688
reward_max: -518.7857142857143
reward_min: -906.0714285714284
queue_len: 0.37511520737327186
wait_time: 2.34758064516129
delay_time: 89.03642242227582
pressure: 5.248263027295286
total_envstep_count: 375100
total_train_sample_count: 375100
total_episode_count: 3025
total_duration: 75352.84632076974
[2024-12-27 17:12:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.737583627341948
avg_train_sample_per_sec: 5.737583627341948
avg_episode_per_sec: 0.046270835704370544
collect_time: 108.05942715073377
reward_mean: -540.8285714285714
reward_std: 17.639392372338143
reward_max: -518.7857142857144
reward_min: -566.285714285714
queue_len: 0.33550159517901446
wait_time: 2.3327454803261256
delay_time: 78.01734597970093
pressure: 4.6936724565756816
total_envstep_count: 375720
total_train_sample_count: 375720
total_episode_count: 3030
total_duration: 75460.90574792046
[2024-12-27 17:13:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.108218196836412
avg_train_sample_per_sec: 6.108218196836412
avg_episode_per_sec: 0.04925982416803558
collect_time: 101.50259535933284
reward_mean: -531.9714285714284
reward_std: 6.569813466118488
reward_max: -523.7857142857141
reward_min: -543.642857142857
queue_len: 0.330007089684509
wait_time: 2.3414923785891535
delay_time: 76.68201935230789
pressure: 4.617617866004963
total_envstep_count: 376340
total_train_sample_count: 376340
total_episode_count: 3035
total_duration: 75562.40834327979
[2024-12-27 17:15:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.649165406705206
avg_train_sample_per_sec: 5.649165406705206
avg_episode_per_sec: 0.04555778553794521
collect_time: 109.7507251715623
reward_mean: -538.0999999999998
reward_std: 6.115987747081277
reward_max: -527.8571428571429
reward_min: -544.785714285714
queue_len: 0.33380893300248127
wait_time: 2.3711095356256653
delay_time: 77.76294680638762
pressure: 4.666873449131513
total_envstep_count: 376960
total_train_sample_count: 376960
total_episode_count: 3040
total_duration: 75672.15906845135
[2024-12-27 17:17:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.507314619681319
avg_train_sample_per_sec: 5.507314619681319
avg_episode_per_sec: 0.044413827578075146
collect_time: 112.57755236723273
reward_mean: -529.3285714285714
reward_std: 14.213862161672301
reward_max: -507.49999999999994
reward_min: -552.0714285714284
queue_len: 0.32836760014179367
wait_time: 2.339649060616803
delay_time: 76.29094842388497
pressure: 4.594292803970224
total_envstep_count: 377580
total_train_sample_count: 377580
total_episode_count: 3045
total_duration: 75784.73662081858
[2024-12-27 17:19:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.700779289271065
avg_train_sample_per_sec: 5.700779289271065
avg_episode_per_sec: 0.04597402652637956
collect_time: 108.75706084023415
reward_mean: -530.0571428571427
reward_std: 10.98685671191543
reward_max: -520.0714285714284
reward_min: -549.785714285714
queue_len: 0.32881956752924485
wait_time: 2.3243530662885505
delay_time: 76.84240845876464
pressure: 4.599131513647643
total_envstep_count: 378200
total_train_sample_count: 378200
total_episode_count: 3050
total_duration: 75893.49368165882
[2024-12-27 17:21:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.445841940934625
avg_train_sample_per_sec: 5.445841940934625
avg_episode_per_sec: 0.04391808016882762
collect_time: 113.84832808673006
reward_mean: -527.7142857142858
reward_std: 8.396306282150254
reward_max: -515.9999999999999
reward_min: -541.1428571428575
queue_len: 0.32736618220489194
wait_time: 2.3133108826657214
delay_time: 76.43486046302871
pressure: 4.579156327543424
total_envstep_count: 378820
total_train_sample_count: 378820
total_episode_count: 3055
total_duration: 76007.34200974555
[2024-12-27 17:23:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.72329865684594
avg_train_sample_per_sec: 5.72329865684594
avg_episode_per_sec: 0.04615563432940274
collect_time: 108.32913625054063
reward_mean: -522.485714285714
reward_std: 3.3302570839046814
reward_max: -516.4999999999999
reward_min: -526.4999999999995
queue_len: 0.32412265154200626
wait_time: 2.2859003899326478
delay_time: 76.46552206332207
pressure: 4.533374689826303
total_envstep_count: 379440
total_train_sample_count: 379440
total_episode_count: 3060
total_duration: 76115.6711459961
[2024-12-27 17:24:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8075150596526885
avg_train_sample_per_sec: 5.8075150596526885
avg_episode_per_sec: 0.04683479886816684
collect_time: 106.75822509827093
reward_mean: -529.7857142857143
reward_std: 3.2607749172894476
reward_max: -526.8571428571432
reward_min: -536.0714285714286
queue_len: 0.3286511875221553
wait_time: 2.3144718185040767
delay_time: 76.48575515050663
pressure: 4.598883374689826
total_envstep_count: 380060
total_train_sample_count: 380060
total_episode_count: 3065
total_duration: 76222.42937109436
[2024-12-27 17:26:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5651756908631596
avg_train_sample_per_sec: 5.5651756908631596
avg_episode_per_sec: 0.04488044911986419
collect_time: 111.40708477863669
reward_mean: -528.6999999999999
reward_std: 14.313073800992365
reward_max: -505.21428571428544
reward_min: -544.2857142857141
queue_len: 0.3279776674937965
wait_time: 2.273963133640553
delay_time: 77.28941188704215
pressure: 4.588213399503722
total_envstep_count: 380680
total_train_sample_count: 380680
total_episode_count: 3070
total_duration: 76333.836455873
[2024-12-27 17:28:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.918171039165512
avg_train_sample_per_sec: 5.918171039165512
avg_episode_per_sec: 0.04772718579972187
collect_time: 104.762095569212
reward_mean: -524.0571428571429
reward_std: 2.907204281555317
reward_max: -520.3571428571431
reward_min: -527.7142857142858
queue_len: 0.3250974831619993
wait_time: 2.296171570365119
delay_time: 76.0152387597729
pressure: 4.549007444168734
total_envstep_count: 381300
total_train_sample_count: 381300
total_episode_count: 3075
total_duration: 76438.5985514422
[2024-12-27 17:30:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.631672338073444
avg_train_sample_per_sec: 5.631672338073444
avg_episode_per_sec: 0.045416712403818095
collect_time: 110.09163225076722
reward_mean: -530.1142857142856
reward_std: 6.670923810822323
reward_max: -522.9285714285713
reward_min: -540.5000000000001
queue_len: 0.3288550159517901
wait_time: 2.3032612548741582
delay_time: 76.54279749272847
pressure: 4.601488833746898
total_envstep_count: 381920
total_train_sample_count: 381920
total_episode_count: 3080
total_duration: 76548.69018369298
[2024-12-27 17:32:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.731877160170006
avg_train_sample_per_sec: 5.731877160170006
avg_episode_per_sec: 0.04622481580782263
collect_time: 108.16700753957032
reward_mean: -536.8000000000002
reward_std: 3.0587445737339003
reward_max: -531.9285714285718
reward_min: -541.357142857143
queue_len: 0.3330024813895783
wait_time: 2.311334633108827
delay_time: 77.4937471754294
pressure: 4.658560794044665
total_envstep_count: 382540
total_train_sample_count: 382540
total_episode_count: 3085
total_duration: 76656.85719123254
[2024-12-27 17:33:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.719501070199915
avg_train_sample_per_sec: 5.719501070199915
avg_episode_per_sec: 0.046125008630644476
collect_time: 108.40106372745709
reward_mean: -541.0571428571427
reward_std: 9.096018415790901
reward_max: -533.0714285714286
reward_min: -556.4285714285713
queue_len: 0.3356433888691953
wait_time: 2.328465083303793
delay_time: 77.68306854661562
pressure: 4.695533498759305
total_envstep_count: 383160
total_train_sample_count: 383160
total_episode_count: 3090
total_duration: 76765.25825496
[2024-12-27 17:35:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.529375794144917
avg_train_sample_per_sec: 5.529375794144917
avg_episode_per_sec: 0.04459174027536223
collect_time: 112.12838900487122
reward_mean: -533.1571428571427
reward_std: 5.218374131032437
reward_max: -525.3571428571429
reward_min: -538.2142857142858
queue_len: 0.3307426444523219
wait_time: 2.354555122297058
delay_time: 76.88000568655256
pressure: 4.625186104218362
total_envstep_count: 383780
total_train_sample_count: 383780
total_episode_count: 3095
total_duration: 76877.38664396487
[2024-12-27 17:37:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.3981063012724295
avg_train_sample_per_sec: 5.3981063012724295
avg_episode_per_sec: 0.043533115332842175
collect_time: 114.85509276722746
reward_mean: -532.5571428571429
reward_std: 3.7014613771496987
reward_max: -527.5000000000002
reward_min: -536.7857142857142
queue_len: 0.33037043601559735
wait_time: 2.366492378589153
delay_time: 76.53197966311032
pressure: 4.619975186104218
total_envstep_count: 384400
total_train_sample_count: 384400
total_episode_count: 3100
total_duration: 76992.2417367321
[2024-12-27 17:39:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.619279754221399
avg_train_sample_per_sec: 5.619279754221399
avg_episode_per_sec: 0.045316772211462894
collect_time: 110.33442489390822
reward_mean: -538.6142857142856
reward_std: 13.39293142836539
reward_max: -525.5714285714284
reward_min: -561.2857142857141
queue_len: 0.3341279688053881
wait_time: 2.3499911378943636
delay_time: 76.86906335349649
pressure: 4.6739454094292805
total_envstep_count: 385020
total_train_sample_count: 385020
total_episode_count: 3105
total_duration: 77102.57616162601
[2024-12-27 17:41:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.645804770833195
avg_train_sample_per_sec: 5.645804770833195
avg_episode_per_sec: 0.04553068363575157
collect_time: 109.81605371885749
reward_mean: -523.8428571428572
reward_std: 5.450968833564364
reward_max: -517.7857142857141
reward_min: -533.1428571428571
queue_len: 0.32496455157745485
wait_time: 2.299273307337824
delay_time: 75.60974815589051
pressure: 4.545657568238214
total_envstep_count: 385640
total_train_sample_count: 385640
total_episode_count: 3110
total_duration: 77212.39221534487
[2024-12-27 17:43:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.604602332247905
avg_train_sample_per_sec: 5.604602332247905
avg_episode_per_sec: 0.04519840590522504
collect_time: 110.62337044550478
reward_mean: -526.6285714285715
reward_std: 6.74951245404785
reward_max: -516.4285714285716
reward_min: -536.9285714285716
queue_len: 0.3266926621765332
wait_time: 2.323865650478554
delay_time: 76.42935351181025
pressure: 4.569975186104218
total_envstep_count: 386260
total_train_sample_count: 386260
total_episode_count: 3115
total_duration: 77323.01558579037
[2024-12-27 17:45:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.656378009833889
avg_train_sample_per_sec: 5.656378009833889
avg_episode_per_sec: 0.045615951692208785
collect_time: 109.61077900417895
reward_mean: -527.8428571428573
reward_std: 13.037731742124146
reward_max: -516.1428571428569
reward_min: -550.2857142857143
queue_len: 0.32744594115561865
wait_time: 2.3200726692662177
delay_time: 76.68079033907925
pressure: 4.580645161290322
total_envstep_count: 386880
total_train_sample_count: 386880
total_episode_count: 3120
total_duration: 77432.62636479456
[2024-12-27 17:47:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.707464472666772
avg_train_sample_per_sec: 5.707464472666772
avg_episode_per_sec: 0.046027939295699774
collect_time: 108.62967311828214
reward_mean: -529.5
reward_std: 14.398908688805934
reward_max: -510.21428571428584
reward_min: -553.8571428571429
queue_len: 0.3284739454094293
wait_time: 2.334402694080113
delay_time: 76.39621624655373
pressure: 4.596277915632754
total_envstep_count: 387500
total_train_sample_count: 387500
total_episode_count: 3125
total_duration: 77541.25603791284
[2024-12-27 17:48:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.575928289794603
avg_train_sample_per_sec: 5.575928289794603
avg_episode_per_sec: 0.04496716362737583
collect_time: 111.19224777957798
reward_mean: -531.8571428571428
reward_std: 8.883486169889139
reward_max: -525.0714285714287
reward_min: -549.1428571428571
queue_len: 0.3299361928394186
wait_time: 2.3215703651187516
delay_time: 77.2937481462059
pressure: 4.616129032258065
total_envstep_count: 388120
total_train_sample_count: 388120
total_episode_count: 3130
total_duration: 77652.44828569242
[2024-12-27 17:50:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.233744746255825
avg_train_sample_per_sec: 5.233744746255825
avg_episode_per_sec: 0.042207618921417944
collect_time: 118.46202481378988
reward_mean: -937.1428571428571
reward_std: 822.8437684924997
reward_max: -517.9285714285713
reward_min: -2582.7857142857138
queue_len: 0.5813541297412265
wait_time: 2.7157479617157043
delay_time: 156.77365177806337
pressure: 7.556203473945411
total_envstep_count: 388740
total_train_sample_count: 388740
total_episode_count: 3135
total_duration: 77770.91031050621
[2024-12-27 17:52:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4216817025628234
avg_train_sample_per_sec: 5.4216817025628234
avg_episode_per_sec: 0.04372323953679696
collect_time: 114.3556619539149
reward_mean: -527.9857142857143
reward_std: 8.028571428571505
reward_max: -519.7142857142856
reward_min: -538.5714285714287
queue_len: 0.3275345622119815
wait_time: 2.294558667139312
delay_time: 76.32420547736675
pressure: 4.58213399503722
total_envstep_count: 389360
total_train_sample_count: 389360
total_episode_count: 3140
total_duration: 77885.26597246013
[2024-12-27 17:54:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.664683210516007
avg_train_sample_per_sec: 5.664683210516007
avg_episode_per_sec: 0.04568292911706457
collect_time: 109.45007460417597
reward_mean: -534.0285714285715
reward_std: 6.914728439191041
reward_max: -523.0714285714283
reward_min: -544.2857142857147
queue_len: 0.33128323289613615
wait_time: 2.318424317617866
delay_time: 76.54462477798367
pressure: 4.636352357320099
total_envstep_count: 389980
total_train_sample_count: 389980
total_episode_count: 3145
total_duration: 77994.7160470643
[2024-12-27 17:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.602264452931863
avg_train_sample_per_sec: 5.602264452931863
avg_episode_per_sec: 0.045179552039773085
collect_time: 110.66953465139122
reward_mean: -529.8428571428572
reward_std: 13.36148897971715
reward_max: -509.4285714285715
reward_min: -550.357142857143
queue_len: 0.3286866359447005
wait_time: 2.3032258064516133
delay_time: 76.85556514464584
pressure: 4.59181141439206
total_envstep_count: 390600
total_train_sample_count: 390600
total_episode_count: 3150
total_duration: 78105.38558171569
[2024-12-27 17:58:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.714687464408326
avg_train_sample_per_sec: 5.714687464408326
avg_episode_per_sec: 0.0460861892290994
collect_time: 108.49237230582166
reward_mean: -528.757142857143
reward_std: 4.51292927179731
reward_max: -521.8571428571429
reward_min: -534.2857142857143
queue_len: 0.32801311591634175
wait_time: 2.2871499468273657
delay_time: 76.7924290331275
pressure: 4.5888337468982625
total_envstep_count: 391220
total_train_sample_count: 391220
total_episode_count: 3155
total_duration: 78213.8779540215
[2024-12-27 18:00:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.558591709315679
avg_train_sample_per_sec: 5.558591709315679
avg_episode_per_sec: 0.04482735249448128
collect_time: 111.5390430567041
reward_mean: -563.9714285714286
reward_std: 54.31960596172195
reward_max: -517.9285714285716
reward_min: -670.5000000000001
queue_len: 0.3498582063098192
wait_time: 2.3639578163771717
delay_time: 80.25494654598934
pressure: 4.895781637717122
total_envstep_count: 391840
total_train_sample_count: 391840
total_episode_count: 3160
total_duration: 78325.41699707821
[2024-12-27 18:01:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.692608304713708
avg_train_sample_per_sec: 5.692608304713708
avg_episode_per_sec: 0.045908131489626684
collect_time: 108.9131671832427
reward_mean: -529.1428571428572
reward_std: 8.551047196879729
reward_max: -515.5714285714287
reward_min: -537.6428571428572
queue_len: 0.3282523927685218
wait_time: 2.301648351648352
delay_time: 76.75232791530968
pressure: 4.589081885856079
total_envstep_count: 392460
total_train_sample_count: 392460
total_episode_count: 3165
total_duration: 78434.33016426145
[2024-12-27 18:03:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.562204153678359
avg_train_sample_per_sec: 5.562204153678359
avg_episode_per_sec: 0.044856485110309346
collect_time: 111.466602603931
reward_mean: -549.2142857142857
reward_std: 4.649336138698889
reward_max: -542.7857142857144
reward_min: -555.3571428571429
queue_len: 0.3407036511875222
wait_time: 2.4199485997873094
delay_time: 78.04716198721631
pressure: 4.760794044665012
total_envstep_count: 393080
total_train_sample_count: 393080
total_episode_count: 3170
total_duration: 78545.79676686539
[2024-12-27 18:05:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.712644448964486
avg_train_sample_per_sec: 5.712644448964486
avg_episode_per_sec: 0.046069713298100695
collect_time: 108.53117247869076
reward_mean: -532.4142857142858
reward_std: 11.224917617078821
reward_max: -516.7857142857142
reward_min: -549.7857142857146
queue_len: 0.3302818149592343
wait_time: 2.32073732718894
delay_time: 77.12615931732212
pressure: 4.6183622828784126
total_envstep_count: 393700
total_train_sample_count: 393700
total_episode_count: 3175
total_duration: 78654.32793934408
[2024-12-27 18:07:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.576289172212757
avg_train_sample_per_sec: 5.576289172212757
avg_episode_per_sec: 0.044970073969457715
collect_time: 111.18505171674491
reward_mean: -542.5428571428571
reward_std: 11.339528118893824
reward_max: -527.0714285714284
reward_min: -561.8571428571428
queue_len: 0.33656504785537045
wait_time: 2.3542981212336054
delay_time: 77.34092083163509
pressure: 4.708312655086848
total_envstep_count: 394320
total_train_sample_count: 394320
total_episode_count: 3180
total_duration: 78765.51299106082
[2024-12-27 18:09:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.187181274969323
avg_train_sample_per_sec: 5.187181274969323
avg_episode_per_sec: 0.041832107056204215
collect_time: 119.52541604663058
reward_mean: -930.2857142857143
reward_std: 637.3259410239324
reward_max: -532.2142857142854
reward_min: -2179.1428571428573
queue_len: 0.5771003190358029
wait_time: 2.772261609358383
delay_time: 140.0791504518324
pressure: 7.528908188585609
total_envstep_count: 394940
total_train_sample_count: 394940
total_episode_count: 3185
total_duration: 78885.03840710745
[2024-12-27 18:11:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.404634412424925
avg_train_sample_per_sec: 5.404634412424925
avg_episode_per_sec: 0.04358576139052359
collect_time: 114.71636241938174
reward_mean: -579.5714285714286
reward_std: 111.66241945420738
reward_max: -512.7142857142859
reward_min: -802.5
queue_len: 0.3595356256646579
wait_time: 2.315756823821341
delay_time: 83.65864390555753
pressure: 5.030645161290322
total_envstep_count: 395560
total_train_sample_count: 395560
total_episode_count: 3190
total_duration: 78999.75476952683
[2024-12-27 18:13:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.471070151032325
avg_train_sample_per_sec: 5.471070151032325
avg_episode_per_sec: 0.04412153347606714
collect_time: 113.32335043867303
reward_mean: -539.0
reward_std: 8.796799046777586
reward_max: -530.357142857143
reward_min: -554.9285714285713
queue_len: 0.3343672456575682
wait_time: 2.373528890464374
delay_time: 77.09517347276616
pressure: 4.669851116625311
total_envstep_count: 396180
total_train_sample_count: 396180
total_episode_count: 3195
total_duration: 79113.0781199655
[2024-12-27 18:15:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.592420377784892
avg_train_sample_per_sec: 5.592420377784892
avg_episode_per_sec: 0.04510016433697493
collect_time: 110.86434103967994
reward_mean: -528.5714285714284
reward_std: 9.338094023943036
reward_max: -518.9285714285712
reward_min: -540.7142857142856
queue_len: 0.32789790854306977
wait_time: 2.3046437433534206
delay_time: 76.17799205383724
pressure: 4.588709677419355
total_envstep_count: 396800
total_train_sample_count: 396800
total_episode_count: 3200
total_duration: 79223.94246100518
[2024-12-27 18:17:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.499680119583836
avg_train_sample_per_sec: 5.499680119583836
avg_episode_per_sec: 0.0443522590289019
collect_time: 112.73382933531701
reward_mean: -549.242857142857
reward_std: 20.84200037404854
reward_max: -522.5714285714284
reward_min: -581.9285714285716
queue_len: 0.3407213753987947
wait_time: 2.3156504785537035
delay_time: 78.78081102822954
pressure: 4.767866004962779
total_envstep_count: 397420
total_train_sample_count: 397420
total_episode_count: 3205
total_duration: 79336.6762903405
[2024-12-27 18:18:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.730825359906958
avg_train_sample_per_sec: 5.730825359906958
avg_episode_per_sec: 0.046216333547636754
collect_time: 108.18685984352976
reward_mean: -525.1000000000001
reward_std: 4.8074347183738935
reward_max: -519.6428571428576
reward_min: -533.2142857142856
queue_len: 0.32574441687344924
wait_time: 2.2787309464728818
delay_time: 76.16050731849634
pressure: 4.55893300248139
total_envstep_count: 398040
total_train_sample_count: 398040
total_episode_count: 3210
total_duration: 79444.86315018403
[2024-12-27 18:20:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.458805922262379
avg_train_sample_per_sec: 5.458805922262379
avg_episode_per_sec: 0.04402262840534177
collect_time: 113.57795254663378
reward_mean: -548.7142857142858
reward_std: 24.690037650511254
reward_max: -522.2142857142859
reward_min: -589.5714285714283
queue_len: 0.3403934774902517
wait_time: 2.3334544487770295
delay_time: 78.90939762785163
pressure: 4.76166253101737
total_envstep_count: 398660
total_train_sample_count: 398660
total_episode_count: 3215
total_duration: 79558.44110273066
[2024-12-27 18:22:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.587022359871232
avg_train_sample_per_sec: 5.587022359871232
avg_episode_per_sec: 0.04505663193444542
collect_time: 110.9714549297579
reward_mean: -531.8857142857142
reward_std: 11.123848254987875
reward_max: -511.71428571428595
reward_min: -543.2857142857141
queue_len: 0.3299539170506912
wait_time: 2.340411201701525
delay_time: 76.88786687739153
pressure: 4.611166253101738
total_envstep_count: 399280
total_train_sample_count: 399280
total_episode_count: 3220
total_duration: 79669.41255766043
[2024-12-27 18:24:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.510746890775204
avg_train_sample_per_sec: 5.510746890775204
avg_episode_per_sec: 0.044441507183671
collect_time: 112.50743543272839
reward_mean: -544.2857142857143
reward_std: 10.927124087166106
reward_max: -532.6428571428575
reward_min: -561.2142857142858
queue_len: 0.337646224742999
wait_time: 2.350850762141085
delay_time: 77.28038236115432
pressure: 4.725310173697271
total_envstep_count: 399900
total_train_sample_count: 399900
total_episode_count: 3225
total_duration: 79781.91999309315
[2024-12-27 18:26:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5166578498410175
avg_train_sample_per_sec: 5.5166578498410175
avg_episode_per_sec: 0.044489176208395306
collect_time: 112.38688656717537
reward_mean: -537.8285714285714
reward_std: 8.205597890141469
reward_max: -523.7142857142857
reward_min: -547.2142857142857
queue_len: 0.33364055299539175
wait_time: 2.3608294930875586
delay_time: 77.10813380749194
pressure: 4.668238213399503
total_envstep_count: 400520
total_train_sample_count: 400520
total_episode_count: 3230
total_duration: 79894.30687966032
[2024-12-27 18:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.77685936038995
avg_train_sample_per_sec: 5.77685936038995
avg_episode_per_sec: 0.046587575487015725
collect_time: 107.32475231284646
reward_mean: -544.6
reward_std: 4.872580508962816
reward_max: -537.6428571428575
reward_min: -552.2857142857139
queue_len: 0.3378411910669975
wait_time: 2.3803084012761424
delay_time: 77.62861045436334
pressure: 4.725806451612903
total_envstep_count: 401140
total_train_sample_count: 401140
total_episode_count: 3235
total_duration: 80001.63163197317
[2024-12-27 18:30:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.667400535074033
avg_train_sample_per_sec: 5.667400535074033
avg_episode_per_sec: 0.04570484302479059
collect_time: 109.3975970399454
reward_mean: -545.1428571428571
reward_std: 14.507914799747597
reward_max: -520.3571428571428
reward_min: -563.8571428571428
queue_len: 0.3381779510811769
wait_time: 2.3408454448777034
delay_time: 77.93911982067057
pressure: 4.732133995037221
total_envstep_count: 401760
total_train_sample_count: 401760
total_episode_count: 3240
total_duration: 80111.02922901312
[2024-12-27 18:32:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4273412900642315
avg_train_sample_per_sec: 5.4273412900642315
avg_episode_per_sec: 0.04376888137148574
collect_time: 114.23641279663516
reward_mean: -560.0857142857142
reward_std: 17.637355996027534
reward_max: -531.5714285714286
reward_min: -575.8571428571424
queue_len: 0.34744771357674575
wait_time: 2.394345976604041
delay_time: 79.90263475419172
pressure: 4.862406947890818
total_envstep_count: 402380
total_train_sample_count: 402380
total_episode_count: 3245
total_duration: 80225.26564180975
[2024-12-27 18:33:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.433617246880932
avg_train_sample_per_sec: 5.433617246880932
avg_episode_per_sec: 0.043819493926459126
collect_time: 114.10446702993289
reward_mean: -540.9571428571427
reward_std: 8.741012877375592
reward_max: -530.357142857143
reward_min: -556.2857142857139
queue_len: 0.3355813541297411
wait_time: 2.3515154200638073
delay_time: 77.91422296319598
pressure: 4.693300248138958
total_envstep_count: 403000
total_train_sample_count: 403000
total_episode_count: 3250
total_duration: 80339.37010883968
[2024-12-27 18:35:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4911240045307235
avg_train_sample_per_sec: 5.4911240045307235
avg_episode_per_sec: 0.04428325810105422
collect_time: 112.90948801892624
reward_mean: -549.7
reward_std: 10.473620896990623
reward_max: -531.5714285714286
reward_min: -562.357142857143
queue_len: 0.34100496277915643
wait_time: 2.401409074796171
delay_time: 78.36191959573061
pressure: 4.771464019851118
total_envstep_count: 403620
total_train_sample_count: 403620
total_episode_count: 3255
total_duration: 80452.2795968586
[2024-12-27 18:37:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.419490736431562
avg_train_sample_per_sec: 5.419490736431562
avg_episode_per_sec: 0.04370557045509324
collect_time: 114.40189312109354
reward_mean: -629.0428571428572
reward_std: 172.22323316212695
reward_max: -528.0000000000001
reward_min: -973.0714285714287
queue_len: 0.39022509748316203
wait_time: 2.435253456221198
delay_time: 91.28971960517569
pressure: 5.459181141439205
total_envstep_count: 404240
total_train_sample_count: 404240
total_episode_count: 3260
total_duration: 80566.68148997969
[2024-12-27 18:39:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.648318396880057
avg_train_sample_per_sec: 5.648318396880057
avg_episode_per_sec: 0.04555095481354885
collect_time: 109.76718315710872
reward_mean: -541.3
reward_std: 6.949291551030399
reward_max: -532.1428571428575
reward_min: -552.9285714285712
queue_len: 0.33579404466501245
wait_time: 2.3830645161290325
delay_time: 78.52014025164041
pressure: 4.694044665012407
total_envstep_count: 404860
total_train_sample_count: 404860
total_episode_count: 3265
total_duration: 80676.4486731368
[2024-12-27 18:41:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.601317100887032
avg_train_sample_per_sec: 5.601317100887032
avg_episode_per_sec: 0.04517191210392768
collect_time: 110.68825221514703
reward_mean: -547.0571428571427
reward_std: 4.555194388647741
reward_max: -541.1428571428569
reward_min: -554.2857142857142
queue_len: 0.33936547323644095
wait_time: 2.3890641616448063
delay_time: 79.20247826854025
pressure: 4.739081885856079
total_envstep_count: 405480
total_train_sample_count: 405480
total_episode_count: 3270
total_duration: 80787.13692535194
[2024-12-27 18:43:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.555715908146709
avg_train_sample_per_sec: 5.555715908146709
avg_episode_per_sec: 0.04480416054957023
collect_time: 111.59677893012015
reward_mean: -533.1
reward_std: 8.390543754119632
reward_max: -519.5000000000001
reward_min: -540.8571428571429
queue_len: 0.33070719602977666
wait_time: 2.3252658631690886
delay_time: 77.33303913265595
pressure: 4.627915632754343
total_envstep_count: 406100
total_train_sample_count: 406100
total_episode_count: 3275
total_duration: 80898.73370428206
[2024-12-27 18:45:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.10781705305554
avg_train_sample_per_sec: 5.10781705305554
avg_episode_per_sec: 0.04119207300851242
collect_time: 121.38257763737067
reward_mean: -942.4285714285713
reward_std: 797.537573806183
reward_max: -541.5714285714283
reward_min: -2537.4999999999995
queue_len: 0.5846331088266571
wait_time: 2.828925912796881
delay_time: 154.63616463434164
pressure: 7.761290322580645
total_envstep_count: 406720
total_train_sample_count: 406720
total_episode_count: 3280
total_duration: 81020.11628191943
[2024-12-27 18:47:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.670258845410669
avg_train_sample_per_sec: 5.670258845410669
avg_episode_per_sec: 0.04572789391460217
collect_time: 109.34245100676641
reward_mean: -537.8428571428573
reward_std: 3.388275101473553
reward_max: -533.4285714285717
reward_min: -542.2142857142857
queue_len: 0.3336494151010281
wait_time: 2.360732009925558
delay_time: 77.67963160239685
pressure: 4.666749379652606
total_envstep_count: 407340
total_train_sample_count: 407340
total_episode_count: 3285
total_duration: 81129.4587329262
[2024-12-27 18:49:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.492616125766461
avg_train_sample_per_sec: 5.492616125766461
avg_episode_per_sec: 0.044295291336826303
collect_time: 112.87881508622318
reward_mean: -539.0
reward_std: 4.9674450378522
reward_max: -532.4999999999998
reward_min: -546.4285714285716
queue_len: 0.33436724565756826
wait_time: 2.3923874512584193
delay_time: 77.75797265148675
pressure: 4.675806451612903
total_envstep_count: 407960
total_train_sample_count: 407960
total_episode_count: 3290
total_duration: 81242.33754801242
[2024-12-27 18:50:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.1996161043763225
avg_train_sample_per_sec: 7.1996161043763225
avg_episode_per_sec: 0.058061420196583245
collect_time: 86.11570270019396
reward_mean: -542.242857142857
reward_std: 11.768220783455808
reward_max: -529.3571428571427
reward_min: -559.642857142857
queue_len: 0.33637894363700804
wait_time: 2.397093229351294
delay_time: 77.44941556526354
pressure: 4.704714640198511
total_envstep_count: 408580
total_train_sample_count: 408580
total_episode_count: 3295
total_duration: 81328.45325071261
[2024-12-27 18:52:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.829253475471696
avg_train_sample_per_sec: 5.829253475471696
avg_episode_per_sec: 0.04701010867315884
collect_time: 106.36010298897327
reward_mean: -542.7714285714285
reward_std: 10.73972218695909
reward_max: -530.9285714285711
reward_min: -559.9999999999999
queue_len: 0.33670684154555114
wait_time: 2.393158454448776
delay_time: 77.18048986817962
pressure: 4.711290322580645
total_envstep_count: 409200
total_train_sample_count: 409200
total_episode_count: 3300
total_duration: 81434.81335370158
[2024-12-27 18:53:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.298918065631358
avg_train_sample_per_sec: 7.298918065631358
avg_episode_per_sec: 0.05886224246476902
collect_time: 84.94409642977269
reward_mean: -550.8571428571427
reward_std: 10.825423590713063
reward_max: -534.8571428571429
reward_min: -566.7857142857142
queue_len: 0.34172279333569644
wait_time: 2.426993973768167
delay_time: 78.60521189228123
pressure: 4.779404466501241
total_envstep_count: 409820
total_train_sample_count: 409820
total_episode_count: 3305
total_duration: 81519.75745013135
[2024-12-27 18:55:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.982606654894424
avg_train_sample_per_sec: 6.982606654894424
avg_episode_per_sec: 0.05631134399108406
collect_time: 88.79205583854764
reward_mean: -541.3714285714285
reward_std: 9.444942497204979
reward_max: -531.2857142857143
reward_min: -556.6428571428569
queue_len: 0.33583835519319394
wait_time: 2.3903846153846153
delay_time: 77.24390543756822
pressure: 4.69801488833747
total_envstep_count: 410440
total_train_sample_count: 410440
total_episode_count: 3310
total_duration: 81608.5495059699
[2024-12-27 18:57:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.696759921591269
avg_train_sample_per_sec: 5.696759921591269
avg_episode_per_sec: 0.04594161227089733
collect_time: 108.83379474183917
reward_mean: -552.5857142857144
reward_std: 9.192432557627452
reward_max: -539.6428571428572
reward_min: -565.9999999999999
queue_len: 0.34279510811768876
wait_time: 2.418255937610776
delay_time: 78.25878720719228
pressure: 4.7949131513647645
total_envstep_count: 411060
total_train_sample_count: 411060
total_episode_count: 3315
total_duration: 81717.38330071174
[2024-12-27 18:58:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.676368442736304
avg_train_sample_per_sec: 5.676368442736304
avg_episode_per_sec: 0.04577716486077665
collect_time: 109.22476337725672
reward_mean: -549.5285714285712
reward_std: 16.251568213183514
reward_max: -527.2857142857141
reward_min: -564.5714285714283
queue_len: 0.3408986175115206
wait_time: 2.4462336051045726
delay_time: 77.63616798689657
pressure: 4.770099255583126
total_envstep_count: 411680
total_train_sample_count: 411680
total_episode_count: 3320
total_duration: 81826.60806408898
[2024-12-27 19:00:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.53082790175023
avg_train_sample_per_sec: 5.53082790175023
avg_episode_per_sec: 0.044603450820566375
collect_time: 112.09894992462178
reward_mean: -539.5
reward_std: 7.132993189169227
reward_max: -526.7142857142856
reward_min: -548.2142857142853
queue_len: 0.3346774193548387
wait_time: 2.3820276497695856
delay_time: 77.47975957728218
pressure: 4.680645161290323
total_envstep_count: 412300
total_train_sample_count: 412300
total_episode_count: 3325
total_duration: 81938.7070140136
[2024-12-27 19:02:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.637639292000629
avg_train_sample_per_sec: 5.637639292000629
avg_episode_per_sec: 0.045464833000005075
collect_time: 109.97510977329317
reward_mean: -555.442857142857
reward_std: 15.845259382476533
reward_max: -530.4999999999999
reward_min: -572.4285714285713
queue_len: 0.3445675292449485
wait_time: 2.4331885856079403
delay_time: 78.94724704880683
pressure: 4.817493796526054
total_envstep_count: 412920
total_train_sample_count: 412920
total_episode_count: 3330
total_duration: 82048.6821237869
[2024-12-27 19:04:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.615964037592846
avg_train_sample_per_sec: 5.615964037592846
avg_episode_per_sec: 0.04529003256123263
collect_time: 110.39956734939292
reward_mean: -553.5285714285715
reward_std: 9.782074401262573
reward_max: -538.5714285714287
reward_min: -569.1428571428572
queue_len: 0.3433800070896845
wait_time: 2.441279688053881
delay_time: 78.38538854642336
pressure: 4.80409429280397
total_envstep_count: 413540
total_train_sample_count: 413540
total_episode_count: 3335
total_duration: 82159.08169113629
[2024-12-27 19:06:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.349181961526165
avg_train_sample_per_sec: 5.349181961526165
avg_episode_per_sec: 0.04313856420585617
collect_time: 115.90557293794302
reward_mean: -552.9857142857143
reward_std: 8.68230666237889
reward_max: -539.214285714286
reward_min: -563.8571428571425
queue_len: 0.34304324707550515
wait_time: 2.4069213045019504
delay_time: 78.88176530228147
pressure: 4.799627791563276
total_envstep_count: 414160
total_train_sample_count: 414160
total_episode_count: 3340
total_duration: 82274.98726407424
[2024-12-27 19:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.531691369728864
avg_train_sample_per_sec: 5.531691369728864
avg_episode_per_sec: 0.04461041427200697
collect_time: 112.0814518671148
reward_mean: -540.5714285714284
reward_std: 13.604471053777154
reward_max: -525.2142857142858
reward_min: -564.5714285714286
queue_len: 0.33534207727756116
wait_time: 2.3761697979439917
delay_time: 77.81903697816685
pressure: 4.690570719602978
total_envstep_count: 414780
total_train_sample_count: 414780
total_episode_count: 3345
total_duration: 82387.06871594135
[2024-12-27 19:10:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.467510942715539
avg_train_sample_per_sec: 5.467510942715539
avg_episode_per_sec: 0.04409283018318983
collect_time: 113.39712101098524
reward_mean: -543.6999999999999
reward_std: 10.152249172735301
reward_max: -527.8571428571429
reward_min: -558.6428571428569
queue_len: 0.3372828784119106
wait_time: 2.427445941155619
delay_time: 77.19478464206816
pressure: 4.71848635235732
total_envstep_count: 415400
total_train_sample_count: 415400
total_episode_count: 3350
total_duration: 82500.46583695234
[2024-12-27 19:12:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.149315593728157
avg_train_sample_per_sec: 5.149315593728157
avg_episode_per_sec: 0.04152673865909804
collect_time: 120.4043505811058
reward_mean: -906.9428571428571
reward_std: 734.7006851328599
reward_max: -530.3571428571429
reward_min: -2376.285714285714
queue_len: 0.5626196384260901
wait_time: 2.782967032967033
delay_time: 147.98023549415126
pressure: 7.545533498759307
total_envstep_count: 416020
total_train_sample_count: 416020
total_episode_count: 3355
total_duration: 82620.87018753344
[2024-12-27 19:14:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6288150278354765
avg_train_sample_per_sec: 5.6288150278354765
avg_episode_per_sec: 0.045393669579318355
collect_time: 110.14751718327773
reward_mean: -546.2285714285714
reward_std: 13.856214991026619
reward_max: -533.2142857142856
reward_min: -572.2857142857142
queue_len: 0.3388514711095356
wait_time: 2.425150655795817
delay_time: 77.41903089219414
pressure: 4.741439205955335
total_envstep_count: 416640
total_train_sample_count: 416640
total_episode_count: 3360
total_duration: 82731.01770471671
[2024-12-27 19:16:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.377990419245583
avg_train_sample_per_sec: 5.377990419245583
avg_episode_per_sec: 0.04337089047778696
collect_time: 115.2846977527663
reward_mean: -546.3142857142856
reward_std: 11.23983440941282
reward_max: -534.3571428571428
reward_min: -567.5714285714284
queue_len: 0.33890464374335333
wait_time: 2.438789436370082
delay_time: 77.7883909531706
pressure: 4.742803970223326
total_envstep_count: 417260
total_train_sample_count: 417260
total_episode_count: 3365
total_duration: 82846.30240246948
[2024-12-27 19:17:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.442898007503992
avg_train_sample_per_sec: 5.442898007503992
avg_episode_per_sec: 0.04389433877019348
collect_time: 113.90990592607486
reward_mean: -552.3285714285714
reward_std: 8.520874727541205
reward_max: -543.9999999999999
reward_min: -565.0714285714288
queue_len: 0.3426355902162353
wait_time: 2.4362814604750085
delay_time: 78.08288498709825
pressure: 4.795533498759306
total_envstep_count: 417880
total_train_sample_count: 417880
total_episode_count: 3370
total_duration: 82960.21230839555
[2024-12-27 19:19:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.655536016340795
avg_train_sample_per_sec: 5.655536016340795
avg_episode_per_sec: 0.04560916142210319
collect_time: 109.6270978044532
reward_mean: -588.3857142857141
reward_std: 87.89419195596378
reward_max: -530.7857142857141
reward_min: -763.0714285714281
queue_len: 0.3650035448422545
wait_time: 2.4464108472172987
delay_time: 82.73545719205165
pressure: 5.106575682382133
total_envstep_count: 418500
total_train_sample_count: 418500
total_episode_count: 3375
total_duration: 83069.8394062
[2024-12-27 19:21:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.735430704806304
avg_train_sample_per_sec: 5.735430704806304
avg_episode_per_sec: 0.04625347342585729
collect_time: 108.09998968001455
reward_mean: -561.3285714285713
reward_std: 12.910808634312382
reward_max: -542.9285714285714
reward_min: -577.5
queue_len: 0.34821871676710375
wait_time: 2.469930875576037
delay_time: 78.99568132526747
pressure: 4.869106699751861
total_envstep_count: 419120
total_train_sample_count: 419120
total_episode_count: 3380
total_duration: 83177.93939588002
[2024-12-27 19:23:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7795558374392115
avg_train_sample_per_sec: 5.7795558374392115
avg_episode_per_sec: 0.046609321269671065
collect_time: 107.27467948033663
reward_mean: -553.657142857143
reward_std: 13.844132331063442
reward_max: -539.714285714286
reward_min: -571.2857142857144
queue_len: 0.34345976604041123
wait_time: 2.4221995746189284
delay_time: 78.52524503630872
pressure: 4.803722084367246
total_envstep_count: 419740
total_train_sample_count: 419740
total_episode_count: 3385
total_duration: 83285.21407536036
[2024-12-27 19:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5034327465236075
avg_train_sample_per_sec: 5.5034327465236075
avg_episode_per_sec: 0.04438252214938393
collect_time: 112.6569594934434
reward_mean: -544.5857142857143
reward_std: 12.672274090006352
reward_max: -523.6428571428571
reward_min: -559.5714285714289
queue_len: 0.3378323289613613
wait_time: 2.4088089330024816
delay_time: 77.7254955971305
pressure: 4.724317617866005
total_envstep_count: 420360
total_train_sample_count: 420360
total_episode_count: 3390
total_duration: 83397.8710348538
[2024-12-27 19:27:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.505775766347501
avg_train_sample_per_sec: 5.505775766347501
avg_episode_per_sec: 0.044401417470544366
collect_time: 112.6090175683461
reward_mean: -544.6428571428571
reward_std: 16.143678866570024
reward_max: -530.7857142857142
reward_min: -575.2142857142858
queue_len: 0.3378677773839064
wait_time: 2.4059376107763204
delay_time: 78.03910972973227
pressure: 4.723573200992556
total_envstep_count: 420980
total_train_sample_count: 420980
total_episode_count: 3395
total_duration: 83510.48005242215
[2024-12-27 19:29:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.42338087341693
avg_train_sample_per_sec: 5.42338087341693
avg_episode_per_sec: 0.04373694252755589
collect_time: 114.31983378467335
reward_mean: -555.3142857142858
reward_std: 13.293208331892721
reward_max: -540.9285714285712
reward_min: -577.3571428571429
queue_len: 0.3444877702942219
wait_time: 2.423271889400922
delay_time: 78.87248394890273
pressure: 4.819230769230769
total_envstep_count: 421600
total_train_sample_count: 421600
total_episode_count: 3400
total_duration: 83624.79988620682
[2024-12-27 19:31:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.432721665482329
avg_train_sample_per_sec: 5.432721665482329
avg_episode_per_sec: 0.04381227149582523
collect_time: 114.12327709318697
reward_mean: -620.9428571428568
reward_std: 164.7005098935144
reward_max: -530.428571428571
reward_min: -949.9999999999995
queue_len: 0.38520028358738023
wait_time: 2.5406061680255236
delay_time: 86.28138212469067
pressure: 5.316625310173697
total_envstep_count: 422220
total_train_sample_count: 422220
total_episode_count: 3405
total_duration: 83738.9231633
[2024-12-27 19:32:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.512532125530459
avg_train_sample_per_sec: 5.512532125530459
avg_episode_per_sec: 0.044455904238148866
collect_time: 112.47099987473338
reward_mean: -546.4285714285713
reward_std: 13.234154946306813
reward_max: -528.5
reward_min: -558.3571428571427
queue_len: 0.3389755405884437
wait_time: 2.398316199929103
delay_time: 77.63486841281085
pressure: 4.743920595533499
total_envstep_count: 422840
total_train_sample_count: 422840
total_episode_count: 3410
total_duration: 83851.39416317473
[2024-12-27 19:34:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.38301163715389
avg_train_sample_per_sec: 5.38301163715389
avg_episode_per_sec: 0.04341138417059589
collect_time: 115.17716137203205
reward_mean: -541.2714285714285
reward_std: 11.908014793681215
reward_max: -533.3571428571427
reward_min: -564.9285714285713
queue_len: 0.33577632045373973
wait_time: 2.373998582063098
delay_time: 77.74766743164817
pressure: 4.696029776674939
total_envstep_count: 423460
total_train_sample_count: 423460
total_episode_count: 3415
total_duration: 83966.57132454676
[2024-12-27 19:36:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.457290960302097
avg_train_sample_per_sec: 5.457290960302097
avg_episode_per_sec: 0.0440104109701782
collect_time: 113.6094821606651
reward_mean: -542.9142857142857
reward_std: 10.208379911041787
reward_max: -533.7857142857144
reward_min: -562.7142857142856
queue_len: 0.33679546260191423
wait_time: 2.395710740872032
delay_time: 77.52539789703462
pressure: 4.708188585607941
total_envstep_count: 424080
total_train_sample_count: 424080
total_episode_count: 3420
total_duration: 84080.18080670743
[2024-12-27 19:38:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.588864430534256
avg_train_sample_per_sec: 5.588864430534256
avg_episode_per_sec: 0.0450714873430182
collect_time: 110.93487911653143
reward_mean: -540.1285714285713
reward_std: 10.287638708862213
reward_max: -530.3571428571429
reward_min: -558.5714285714283
queue_len: 0.33506735200283577
wait_time: 2.4018964906061684
delay_time: 77.61536563090645
pressure: 4.688709677419355
total_envstep_count: 424700
total_train_sample_count: 424700
total_episode_count: 3425
total_duration: 84191.11568582396
[2024-12-27 19:40:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.589495289857708
avg_train_sample_per_sec: 5.589495289857708
avg_episode_per_sec: 0.045076574918207324
collect_time: 110.92235843279212
reward_mean: -542.9142857142858
reward_std: 11.448767868827083
reward_max: -528.5714285714286
reward_min: -556.8571428571428
queue_len: 0.3367954626019143
wait_time: 2.3977313009571075
delay_time: 77.36738751689354
pressure: 4.712406947890819
total_envstep_count: 425320
total_train_sample_count: 425320
total_episode_count: 3430
total_duration: 84302.03804425675
[2024-12-27 19:42:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.625421620347591
avg_train_sample_per_sec: 5.625421620347591
avg_episode_per_sec: 0.04536630338989993
collect_time: 110.21396116469055
reward_mean: -547.2857142857143
reward_std: 6.784135154602808
reward_max: -539.0714285714287
reward_min: -556.0000000000001
queue_len: 0.33950726692662175
wait_time: 2.4360067352002837
delay_time: 77.91231029529744
pressure: 4.749875930521092
total_envstep_count: 425940
total_train_sample_count: 425940
total_episode_count: 3435
total_duration: 84412.25200542144
[2024-12-27 19:44:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.395879808889725
avg_train_sample_per_sec: 5.395879808889725
avg_episode_per_sec: 0.04351515974911069
collect_time: 114.90248522188142
reward_mean: -549.7571428571429
reward_std: 12.411285187280173
reward_max: -529.2857142857142
reward_min: -562.8571428571428
queue_len: 0.3410404112017016
wait_time: 2.412601914214818
delay_time: 78.38366948747648
pressure: 4.770967741935484
total_envstep_count: 426560
total_train_sample_count: 426560
total_episode_count: 3440
total_duration: 84527.15449064333
[2024-12-27 19:46:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.239880600519085
avg_train_sample_per_sec: 5.239880600519085
avg_episode_per_sec: 0.0422571016170894
collect_time: 118.32330682088063
reward_mean: -547.0285714285715
reward_std: 7.146798912371906
reward_max: -539.7142857142854
reward_min: -559.0714285714288
queue_len: 0.33934774902516845
wait_time: 2.4558578518255936
delay_time: 77.83012850489662
pressure: 4.746277915632755
total_envstep_count: 427180
total_train_sample_count: 427180
total_episode_count: 3445
total_duration: 84645.4777974642
[2024-12-27 19:48:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.345134265777266
avg_train_sample_per_sec: 5.345134265777266
avg_episode_per_sec: 0.043105921498203754
collect_time: 115.99334444592148
reward_mean: -546.1571428571428
reward_std: 11.101240967585806
reward_max: -537.5714285714287
reward_min: -567.142857142857
queue_len: 0.3388071605813542
wait_time: 2.43434065934066
delay_time: 78.37464429848424
pressure: 4.734119106699752
total_envstep_count: 427800
total_train_sample_count: 427800
total_episode_count: 3450
total_duration: 84761.47114191012
[2024-12-27 19:50:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.454039993256309
avg_train_sample_per_sec: 5.454039993256309
avg_episode_per_sec: 0.04398419349400249
collect_time: 113.67720089449361
reward_mean: -542.8
reward_std: 12.105775312567484
reward_max: -530.2857142857141
reward_min: -559.1428571428571
queue_len: 0.3367245657568238
wait_time: 2.4190446650124064
delay_time: 77.48763693631386
pressure: 4.706327543424317
total_envstep_count: 428420
total_train_sample_count: 428420
total_episode_count: 3455
total_duration: 84875.14834280462
[2024-12-27 19:52:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.346505649313344
avg_train_sample_per_sec: 5.346505649313344
avg_episode_per_sec: 0.04311698104284955
collect_time: 115.96359204813093
reward_mean: -540.8
reward_std: 7.672559107970665
reward_max: -528.5000000000002
reward_min: -549.7142857142856
queue_len: 0.3354838709677419
wait_time: 2.4080379298121235
delay_time: 77.6568384195823
pressure: 4.692679900744417
total_envstep_count: 429040
total_train_sample_count: 429040
total_episode_count: 3460
total_duration: 84991.11193485276
[2024-12-27 19:53:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.493514921289196
avg_train_sample_per_sec: 5.493514921289196
avg_episode_per_sec: 0.0443025396878161
collect_time: 112.86034695151076
reward_mean: -548.4999999999999
reward_std: 11.779262303224396
reward_max: -535.7142857142856
reward_min: -569.7142857142856
queue_len: 0.3402605459057071
wait_time: 2.4333126550868487
delay_time: 78.12062927453962
pressure: 4.755831265508684
total_envstep_count: 429660
total_train_sample_count: 429660
total_episode_count: 3465
total_duration: 85103.97228180426
[2024-12-27 19:55:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4906813958325005
avg_train_sample_per_sec: 5.4906813958325005
avg_episode_per_sec: 0.04427968867606855
collect_time: 112.91858975291996
reward_mean: -553.4571428571428
reward_std: 6.947411792332745
reward_max: -548.2142857142857
reward_min: -567.2142857142856
queue_len: 0.343335696561503
wait_time: 2.4445498050336765
delay_time: 78.69865247274458
pressure: 4.801612903225806
total_envstep_count: 430280
total_train_sample_count: 430280
total_episode_count: 3470
total_duration: 85216.89087155719
[2024-12-27 19:57:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.532158427081889
avg_train_sample_per_sec: 5.532158427081889
avg_episode_per_sec: 0.04461418086356362
collect_time: 112.07198929171638
reward_mean: -548.1857142857142
reward_std: 14.18080047249863
reward_max: -532.2857142857143
reward_min: -571.5000000000001
queue_len: 0.3400655795817086
wait_time: 2.4271357674583487
delay_time: 78.42384898232231
pressure: 4.757692307692308
total_envstep_count: 430900
total_train_sample_count: 430900
total_episode_count: 3475
total_duration: 85328.9628608489
[2024-12-27 19:59:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.519381472382756
avg_train_sample_per_sec: 5.519381472382756
avg_episode_per_sec: 0.04451114090631255
collect_time: 112.33142755257713
reward_mean: -542.4857142857143
reward_std: 13.64688796101184
reward_max: -526.0714285714284
reward_min: -566.2142857142858
queue_len: 0.3365295994328253
wait_time: 2.388975540588444
delay_time: 77.85062164165996
pressure: 4.70483870967742
total_envstep_count: 431520
total_train_sample_count: 431520
total_episode_count: 3480
total_duration: 85441.29428840148
[2024-12-27 20:01:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4361057073812535
avg_train_sample_per_sec: 5.4361057073812535
avg_episode_per_sec: 0.04383956215630043
collect_time: 114.05223396560365
reward_mean: -542.7285714285715
reward_std: 7.730327236519407
reward_max: -536.357142857143
reward_min: -557.7142857142858
queue_len: 0.33668025522864237
wait_time: 2.4169354838709673
delay_time: 77.61912178063328
pressure: 4.709677419354839
total_envstep_count: 432140
total_train_sample_count: 432140
total_episode_count: 3485
total_duration: 85555.34652236708
[2024-12-27 20:03:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.605971551738057
avg_train_sample_per_sec: 5.605971551738057
avg_episode_per_sec: 0.04520944799788756
collect_time: 110.59635145807638
reward_mean: -621.9000000000002
reward_std: 153.09125996460756
reward_max: -528.6428571428572
reward_min: -927.3571428571431
queue_len: 0.38579404466501244
wait_time: 2.551692662176533
delay_time: 86.12864105263563
pressure: 5.332506203473946
total_envstep_count: 432760
total_train_sample_count: 432760
total_episode_count: 3490
total_duration: 85665.94287382516
[2024-12-27 20:05:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.667836849679674
avg_train_sample_per_sec: 5.667836849679674
avg_episode_per_sec: 0.04570836169096511
collect_time: 109.38917552558702
reward_mean: -545.0428571428571
reward_std: 11.611183911933082
reward_max: -525.7142857142857
reward_min: -558.2142857142854
queue_len: 0.33811591634172267
wait_time: 2.4125576036866363
delay_time: 77.43659912394781
pressure: 4.731761786600496
total_envstep_count: 433380
total_train_sample_count: 433380
total_episode_count: 3495
total_duration: 85775.33204935075
[2024-12-27 20:07:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.529263899203008
avg_train_sample_per_sec: 5.529263899203008
avg_episode_per_sec: 0.044590837896798456
collect_time: 112.13065813143177
reward_mean: -544.3571428571428
reward_std: 7.013398256340574
reward_max: -533.4285714285714
reward_min: -555.1428571428572
queue_len: 0.3376905352711804
wait_time: 2.4026231832683447
delay_time: 77.76559488559462
pressure: 4.724069478908188
total_envstep_count: 434000
total_train_sample_count: 434000
total_episode_count: 3500
total_duration: 85887.46270748218
[2024-12-27 20:08:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.459039911387322
avg_train_sample_per_sec: 5.459039911387322
avg_episode_per_sec: 0.044024515414413885
collect_time: 113.57308429028092
reward_mean: -543.5428571428571
reward_std: 4.5947174637215795
reward_max: -535.3571428571429
reward_min: -548.2142857142856
queue_len: 0.3371853952499114
wait_time: 2.4177951081176894
delay_time: 77.13523282872795
pressure: 4.718858560794045
total_envstep_count: 434620
total_train_sample_count: 434620
total_episode_count: 3505
total_duration: 86001.03579177246
[2024-12-27 20:10:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.428063923146305
avg_train_sample_per_sec: 5.428063923146305
avg_episode_per_sec: 0.04377470905763149
collect_time: 114.22120460965854
reward_mean: -552.6142857142856
reward_std: 10.39786084750507
reward_max: -544.1428571428572
reward_min: -572.785714285714
queue_len: 0.3428128323289613
wait_time: 2.4610155973059196
delay_time: 78.2910693232406
pressure: 4.792803970223325
total_envstep_count: 435240
total_train_sample_count: 435240
total_episode_count: 3510
total_duration: 86115.25699638212
[2024-12-27 20:12:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.807708628877903
avg_train_sample_per_sec: 5.807708628877903
avg_episode_per_sec: 0.04683635991030568
collect_time: 106.7546668779403
reward_mean: -543.3714285714287
reward_std: 15.93900363055025
reward_max: -520.2857142857142
reward_min: -561.2857142857144
queue_len: 0.3370790499822759
wait_time: 2.391891173342787
delay_time: 77.52895015801946
pressure: 4.71637717121588
total_envstep_count: 435860
total_train_sample_count: 435860
total_episode_count: 3515
total_duration: 86222.01166326005
[2024-12-27 20:14:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.511207116073559
avg_train_sample_per_sec: 5.511207116073559
avg_episode_per_sec: 0.04444521867801257
collect_time: 112.49804025541992
reward_mean: -543.9142857142857
reward_std: 9.079849859407712
reward_max: -531.1428571428573
reward_min: -558.1428571428571
queue_len: 0.33741580999645515
wait_time: 2.439064161644807
delay_time: 77.35305795826744
pressure: 4.718610421836228
total_envstep_count: 436480
total_train_sample_count: 436480
total_episode_count: 3520
total_duration: 86334.50970351548
[2024-12-27 20:16:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.496118243393328
avg_train_sample_per_sec: 5.496118243393328
avg_episode_per_sec: 0.04432353422091394
collect_time: 112.80688888840376
reward_mean: -542.5857142857143
reward_std: 6.588549126464532
reward_max: -537.9285714285714
reward_min: -555.3571428571429
queue_len: 0.3365916341722794
wait_time: 2.420462601914215
delay_time: 77.43820870334832
pressure: 4.703598014888337
total_envstep_count: 437100
total_train_sample_count: 437100
total_episode_count: 3525
total_duration: 86447.31659240388
[2024-12-27 20:18:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.518164144343868
avg_train_sample_per_sec: 5.518164144343868
avg_episode_per_sec: 0.04450132374470862
collect_time: 112.35620829356834
reward_mean: -540.7999999999998
reward_std: 13.370802793659644
reward_max: -523.9285714285713
reward_min: -558.8571428571428
queue_len: 0.33548387096774185
wait_time: 2.4086405529953923
delay_time: 77.74521292761663
pressure: 4.686352357320098
total_envstep_count: 437720
total_train_sample_count: 437720
total_episode_count: 3530
total_duration: 86559.67280069744
[2024-12-27 20:20:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.961086915992882
avg_train_sample_per_sec: 5.961086915992882
avg_episode_per_sec: 0.04807328158058776
collect_time: 104.00787788156792
reward_mean: -537.4857142857143
reward_std: 8.871808135427425
reward_max: -525.7142857142857
reward_min: -548.2142857142857
queue_len: 0.33342786246012046
wait_time: 2.3573378234668554
delay_time: 77.74057553448021
pressure: 4.663275434243177
total_envstep_count: 438340
total_train_sample_count: 438340
total_episode_count: 3535
total_duration: 86663.68067857901
[2024-12-27 20:21:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.707505818585538
avg_train_sample_per_sec: 5.707505818585538
avg_episode_per_sec: 0.04602827273052853
collect_time: 108.6288861907199
reward_mean: -543.242857142857
reward_std: 10.213896096465112
reward_max: -530.1428571428573
reward_min: -556.0714285714283
queue_len: 0.336999291031549
wait_time: 2.4224388514711093
delay_time: 77.87414853716237
pressure: 4.711042183622829
total_envstep_count: 438960
total_train_sample_count: 438960
total_episode_count: 3540
total_duration: 86772.30956476973
[2024-12-27 20:23:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.85270824646593
avg_train_sample_per_sec: 5.85270824646593
avg_episode_per_sec: 0.047199260052144594
collect_time: 105.93386410032957
reward_mean: -543.7714285714286
reward_std: 15.373207544428869
reward_max: -520.3571428571429
reward_min: -567.0714285714289
queue_len: 0.33732718894009217
wait_time: 2.4349344204182914
delay_time: 77.68607451982321
pressure: 4.716004962779157
total_envstep_count: 439580
total_train_sample_count: 439580
total_episode_count: 3545
total_duration: 86878.24342887006
[2024-12-27 20:25:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.569356155194667
avg_train_sample_per_sec: 5.569356155194667
avg_episode_per_sec: 0.04491416254189247
collect_time: 111.32346050839499
reward_mean: -541.6714285714286
reward_std: 8.62407640721903
reward_max: -531.5714285714283
reward_min: -557.1428571428571
queue_len: 0.3360244594115561
wait_time: 2.404599432825239
delay_time: 77.82161977535557
pressure: 4.700248138957816
total_envstep_count: 440200
total_train_sample_count: 440200
total_episode_count: 3550
total_duration: 86989.56688937846
[2024-12-27 20:27:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8107015750951865
avg_train_sample_per_sec: 5.8107015750951865
avg_episode_per_sec: 0.04686049657334828
collect_time: 106.69968023436888
reward_mean: -553.0142857142856
reward_std: 5.579371627262367
reward_max: -544.6428571428575
reward_min: -560.2142857142853
queue_len: 0.3430609712867777
wait_time: 2.4615384615384612
delay_time: 78.9590463239438
pressure: 4.790818858560794
total_envstep_count: 440820
total_train_sample_count: 440820
total_episode_count: 3555
total_duration: 87096.26656961282
[2024-12-27 20:29:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.690685897803362
avg_train_sample_per_sec: 5.690685897803362
avg_episode_per_sec: 0.045892628208091625
collect_time: 108.94995983512702
reward_mean: -615.6428571428571
reward_std: 149.43341975199365
reward_max: -534.7142857142854
reward_min: -914.4285714285714
queue_len: 0.38191244239631333
wait_time: 2.5122474299893653
delay_time: 86.37752620353947
pressure: 5.2660049627791565
total_envstep_count: 441440
total_train_sample_count: 441440
total_episode_count: 3560
total_duration: 87205.21652944795
[2024-12-27 20:31:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.580812232763232
avg_train_sample_per_sec: 5.580812232763232
avg_episode_per_sec: 0.04500655026421961
collect_time: 111.09493997310476
reward_mean: -560.6428571428571
reward_std: 9.31873250556121
reward_max: -542.1428571428573
reward_min: -567.0714285714287
queue_len: 0.34779333569656157
wait_time: 2.5140641616448063
delay_time: 79.28799210187076
pressure: 4.857320099255583
total_envstep_count: 442060
total_train_sample_count: 442060
total_episode_count: 3565
total_duration: 87316.31146942105
[2024-12-27 20:32:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.496033373078585
avg_train_sample_per_sec: 5.496033373078585
avg_episode_per_sec: 0.04432284978289181
collect_time: 112.80863086402786
reward_mean: -538.1571428571428
reward_std: 6.492287418034385
reward_max: -528.2142857142858
reward_min: -544.5714285714286
queue_len: 0.33384438142502654
wait_time: 2.4019851116625306
delay_time: 77.27792697002747
pressure: 4.668238213399503
total_envstep_count: 442680
total_train_sample_count: 442680
total_episode_count: 3570
total_duration: 87429.12010028509
[2024-12-27 20:34:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6053076842645675
avg_train_sample_per_sec: 5.6053076842645675
avg_episode_per_sec: 0.04520409422794006
collect_time: 110.60944999334961
reward_mean: -546.3142857142857
reward_std: 11.906403696313609
reward_max: -535.5
reward_min: -568.642857142857
queue_len: 0.33890464374335344
wait_time: 2.423794753633463
delay_time: 77.82518249261004
pressure: 4.742183622828785
total_envstep_count: 443300
total_train_sample_count: 443300
total_episode_count: 3575
total_duration: 87539.72955027844
[2024-12-27 20:36:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.58629351612998
avg_train_sample_per_sec: 5.58629351612998
avg_episode_per_sec: 0.04505075416233855
collect_time: 110.98593337600309
reward_mean: -536.0000000000001
reward_std: 9.770112693352837
reward_max: -525.4285714285717
reward_min: -551.2142857142857
queue_len: 0.33250620347394544
wait_time: 2.391775965969514
delay_time: 76.72813856983278
pressure: 4.653473945409429
total_envstep_count: 443920
total_train_sample_count: 443920
total_episode_count: 3580
total_duration: 87650.71548365444
[2024-12-27 20:38:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.556079467657898
avg_train_sample_per_sec: 5.556079467657898
avg_episode_per_sec: 0.04480709248111208
collect_time: 111.58947664608439
reward_mean: -536.3285714285714
reward_std: 3.856243281342306
reward_max: -531.857142857143
reward_min: -541.7857142857141
queue_len: 0.3327100319035803
wait_time: 2.35620347394541
delay_time: 77.21378342492454
pressure: 4.652977667493796
total_envstep_count: 444540
total_train_sample_count: 444540
total_episode_count: 3585
total_duration: 87762.30496030052
[2024-12-27 20:40:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4026952191886055
avg_train_sample_per_sec: 5.4026952191886055
avg_episode_per_sec: 0.04357012273539198
collect_time: 114.75753764490784
reward_mean: -550.7857142857143
reward_std: 12.626906806902497
reward_max: -533.1428571428573
reward_min: -571.285714285714
queue_len: 0.34167848280751506
wait_time: 2.442812832328961
delay_time: 78.44476745640374
pressure: 4.779528535980149
total_envstep_count: 445160
total_train_sample_count: 445160
total_episode_count: 3590
total_duration: 87877.06249794543
[2024-12-27 20:42:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.50466875615279
avg_train_sample_per_sec: 5.50466875615279
avg_episode_per_sec: 0.04439248996897411
collect_time: 112.6316636776738
reward_mean: -537.5857142857143
reward_std: 2.5755522490827194
reward_max: -533.7857142857143
reward_min: -541.0714285714286
queue_len: 0.3334898971995746
wait_time: 2.382541651896491
delay_time: 76.87131775983804
pressure: 4.66712158808933
total_envstep_count: 445780
total_train_sample_count: 445780
total_episode_count: 3595
total_duration: 87989.6941616231
[2024-12-27 20:44:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.571444757890247
avg_train_sample_per_sec: 5.571444757890247
avg_episode_per_sec: 0.04493100611201812
collect_time: 111.28172797943651
reward_mean: -538.3857142857142
reward_std: 6.297488971561533
reward_max: -531.0714285714284
reward_min: -550.0714285714286
queue_len: 0.3339861751152074
wait_time: 2.379182913860334
delay_time: 77.6096460539822
pressure: 4.664019851116625
total_envstep_count: 446400
total_train_sample_count: 446400
total_episode_count: 3600
total_duration: 88100.97588960255
[2024-12-27 20:46:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.484071507546461
avg_train_sample_per_sec: 5.484071507546461
avg_episode_per_sec: 0.044226383125374684
collect_time: 113.05468922986091
reward_mean: -541.4714285714286
reward_std: 12.278619213735668
reward_max: -526.4285714285716
reward_min: -563.7857142857144
queue_len: 0.33590038993264804
wait_time: 2.415978376462247
delay_time: 77.74860300311452
pressure: 4.69863523573201
total_envstep_count: 447020
total_train_sample_count: 447020
total_episode_count: 3605
total_duration: 88214.0305788324
[2024-12-27 20:47:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.52481583413483
avg_train_sample_per_sec: 5.52481583413483
avg_episode_per_sec: 0.04455496640431314
collect_time: 112.2209352516979
reward_mean: -538.7571428571428
reward_std: 14.321569290366716
reward_max: -519.142857142857
reward_min: -561.4999999999999
queue_len: 0.33421658986175107
wait_time: 2.386166253101737
delay_time: 77.69184895504081
pressure: 4.674813895781638
total_envstep_count: 447640
total_train_sample_count: 447640
total_episode_count: 3610
total_duration: 88326.2515140841
[2024-12-27 20:49:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.589691119485338
avg_train_sample_per_sec: 5.589691119485338
avg_episode_per_sec: 0.04507815418939789
collect_time: 110.91847237116842
reward_mean: -537.9428571428573
reward_std: 8.079755502463785
reward_max: -527.7142857142859
reward_min: -550.2142857142862
queue_len: 0.3337114498404822
wait_time: 2.3979351293867426
delay_time: 77.74177536329387
pressure: 4.66650124069479
total_envstep_count: 448260
total_train_sample_count: 448260
total_episode_count: 3615
total_duration: 88437.16998645526
[2024-12-27 20:51:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.419143215573622
avg_train_sample_per_sec: 5.419143215573622
avg_episode_per_sec: 0.043702767867529205
collect_time: 114.40922952879967
reward_mean: -531.7857142857142
reward_std: 11.377923486170204
reward_max: -513.4285714285712
reward_min: -547.2142857142857
queue_len: 0.3298918823112372
wait_time: 2.355299539170507
delay_time: 76.9593127893162
pressure: 4.611042183622829
total_envstep_count: 448880
total_train_sample_count: 448880
total_episode_count: 3620
total_duration: 88551.57921598406
[2024-12-27 20:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.420493845900618
avg_train_sample_per_sec: 5.420493845900618
avg_episode_per_sec: 0.04371366004758563
collect_time: 114.38072205706686
reward_mean: -545.842857142857
reward_std: 10.581790288712194
reward_max: -527.6428571428572
reward_min: -556.9999999999998
queue_len: 0.3386121942573555
wait_time: 2.425398794753634
delay_time: 77.88046965545736
pressure: 4.736104218362283
total_envstep_count: 449500
total_train_sample_count: 449500
total_episode_count: 3625
total_duration: 88665.95993804112
[2024-12-27 20:55:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.295043158347382
avg_train_sample_per_sec: 5.295043158347382
avg_episode_per_sec: 0.04270196095441437
collect_time: 117.09064146580178
reward_mean: -537.0714285714286
reward_std: 13.122266479195527
reward_max: -520.7857142857143
reward_min: -554.5
queue_len: 0.33317086139666785
wait_time: 2.391155618574974
delay_time: 77.27892292523181
pressure: 4.662034739454095
total_envstep_count: 450120
total_train_sample_count: 450120
total_episode_count: 3630
total_duration: 88783.05057950692
[2024-12-27 20:57:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.47683459480309
avg_train_sample_per_sec: 5.47683459480309
avg_episode_per_sec: 0.04416802092583137
collect_time: 113.20407605303826
reward_mean: -539.4142857142856
reward_std: 9.192654565422586
reward_max: -529.7142857142856
reward_min: -553.0714285714283
queue_len: 0.33462424672102087
wait_time: 2.415074441687346
delay_time: 77.44548676161423
pressure: 4.680769230769231
total_envstep_count: 450740
total_train_sample_count: 450740
total_episode_count: 3635
total_duration: 88896.25465555995
[2024-12-27 20:59:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.40753304126216
avg_train_sample_per_sec: 5.40753304126216
avg_episode_per_sec: 0.04360913742953355
collect_time: 114.65487039452046
reward_mean: -536.5142857142857
reward_std: 7.332816926777284
reward_max: -524.6428571428572
reward_min: -547.0714285714283
queue_len: 0.33282523927685215
wait_time: 2.40433356965615
delay_time: 77.027358984919
pressure: 4.652481389578164
total_envstep_count: 451360
total_train_sample_count: 451360
total_episode_count: 3640
total_duration: 89010.90952595447
[2024-12-27 21:01:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.402338349980019
avg_train_sample_per_sec: 5.402338349980019
avg_episode_per_sec: 0.04356724475790338
collect_time: 114.76511833108216
reward_mean: -533.9142857142857
reward_std: 12.406746025399876
reward_max: -513.9285714285713
reward_min: -547.8571428571429
queue_len: 0.33121233605104566
wait_time: 2.3747784473590925
delay_time: 76.73083324278429
pressure: 4.634615384615384
total_envstep_count: 451980
total_train_sample_count: 451980
total_episode_count: 3645
total_duration: 89125.67464428555
[2024-12-27 21:03:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.376173653791163
avg_train_sample_per_sec: 5.376173653791163
avg_episode_per_sec: 0.043356239143477124
collect_time: 115.32365580542384
reward_mean: -541.1
reward_std: 13.128765737719586
reward_max: -525.2142857142856
reward_min: -557.0714285714287
queue_len: 0.3356699751861042
wait_time: 2.422483161999291
delay_time: 77.52992406871205
pressure: 4.6934243176178665
total_envstep_count: 452600
total_train_sample_count: 452600
total_episode_count: 3650
total_duration: 89240.99830009097
[2024-12-27 21:05:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.326243118089925
avg_train_sample_per_sec: 5.326243118089925
avg_episode_per_sec: 0.04295357353298327
collect_time: 116.40475026275965
reward_mean: -536.9428571428571
reward_std: 6.11845652138538
reward_max: -529.0714285714284
reward_min: -545.7857142857144
queue_len: 0.3330911024459412
wait_time: 2.3980857851825594
delay_time: 76.80994876069963
pressure: 4.660545905707195
total_envstep_count: 453220
total_train_sample_count: 453220
total_episode_count: 3655
total_duration: 89357.40305035374
[2024-12-27 21:07:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.420041930089238
avg_train_sample_per_sec: 5.420041930089238
avg_episode_per_sec: 0.043710015565235794
collect_time: 114.39025896793976
reward_mean: -533.3142857142856
reward_std: 10.5671419880647
reward_max: -521.642857142857
reward_min: -552.3571428571429
queue_len: 0.33084012761432113
wait_time: 2.375248138957816
delay_time: 77.12001725965601
pressure: 4.629156327543424
total_envstep_count: 453840
total_train_sample_count: 453840
total_episode_count: 3660
total_duration: 89471.79330932167
[2024-12-27 21:09:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.542076835648153
avg_train_sample_per_sec: 5.542076835648153
avg_episode_per_sec: 0.04469416802942058
collect_time: 111.87141903410479
reward_mean: -531.4285714285714
reward_std: 8.447315719040136
reward_max: -519.2857142857143
reward_min: -545.5714285714286
queue_len: 0.3296703296703297
wait_time: 2.3488922367954626
delay_time: 77.07874183655659
pressure: 4.612406947890818
total_envstep_count: 454460
total_train_sample_count: 454460
total_episode_count: 3665
total_duration: 89583.66472835577
[2024-12-27 21:10:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.625482647154273
avg_train_sample_per_sec: 5.625482647154273
avg_episode_per_sec: 0.04536679554156672
collect_time: 110.21276553286239
reward_mean: -543.7714285714288
reward_std: 7.725045406378694
reward_max: -534.857142857143
reward_min: -557.5714285714288
queue_len: 0.3373271889400923
wait_time: 2.4065579581708616
delay_time: 77.80390970320991
pressure: 4.719106699751861
total_envstep_count: 455080
total_train_sample_count: 455080
total_episode_count: 3670
total_duration: 89693.87749388863
[2024-12-27 21:12:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.483771005182085
avg_train_sample_per_sec: 5.483771005182085
avg_episode_per_sec: 0.04422395971921036
collect_time: 113.06088445599003
reward_mean: -539.2142857142857
reward_std: 11.643076246842837
reward_max: -523.0714285714286
reward_min: -552.5714285714286
queue_len: 0.3345001772421127
wait_time: 2.374565756823821
delay_time: 77.59541458972245
pressure: 4.680645161290323
total_envstep_count: 455700
total_train_sample_count: 455700
total_episode_count: 3675
total_duration: 89806.93837834462
[2024-12-27 21:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5385659879412055
avg_train_sample_per_sec: 5.5385659879412055
avg_episode_per_sec: 0.044665854741461335
collect_time: 111.94233333138752
reward_mean: -532.3857142857141
reward_std: 4.309600104559993
reward_max: -528.2857142857143
reward_min: -540.2142857142854
queue_len: 0.33026409074796165
wait_time: 2.323218716767104
delay_time: 77.18670145706751
pressure: 4.621836228287841
total_envstep_count: 456320
total_train_sample_count: 456320
total_episode_count: 3680
total_duration: 89918.88071167601
[2024-12-27 21:16:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.772266460988291
avg_train_sample_per_sec: 5.772266460988291
avg_episode_per_sec: 0.04655053597571202
collect_time: 107.4101488886997
reward_mean: -540.8571428571429
reward_std: 7.572237153589634
reward_max: -531.2142857142861
reward_min: -548.4285714285714
queue_len: 0.3355193193902872
wait_time: 2.351745834810351
delay_time: 78.3720077424762
pressure: 4.693548387096774
total_envstep_count: 456940
total_train_sample_count: 456940
total_episode_count: 3685
total_duration: 90026.29086056471
[2024-12-27 21:18:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6947056607211675
avg_train_sample_per_sec: 5.6947056607211675
avg_episode_per_sec: 0.04592504565097716
collect_time: 108.87305454194173
reward_mean: -539.4142857142857
reward_std: 11.287468218139628
reward_max: -521.0714285714283
reward_min: -553.0714285714284
queue_len: 0.33462424672102087
wait_time: 2.358161999291031
delay_time: 78.51002256736912
pressure: 4.681265508684864
total_envstep_count: 457560
total_train_sample_count: 457560
total_episode_count: 3690
total_duration: 90135.16391510665
[2024-12-27 21:20:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.341796455134911
avg_train_sample_per_sec: 5.341796455134911
avg_episode_per_sec: 0.043079003670442824
collect_time: 116.0658226511069
reward_mean: -538.0571428571429
reward_std: 13.092013455787944
reward_max: -522.6428571428572
reward_min: -561.214285714286
queue_len: 0.3337823466855726
wait_time: 2.34485111662531
delay_time: 77.72217827801018
pressure: 4.66985111662531
total_envstep_count: 458180
total_train_sample_count: 458180
total_episode_count: 3695
total_duration: 90251.22973775775
[2024-12-27 21:22:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.537247071445136
avg_train_sample_per_sec: 5.537247071445136
avg_episode_per_sec: 0.044655218318105934
collect_time: 111.96899686800315
reward_mean: -538.5571428571428
reward_std: 8.553600506959388
reward_max: -527.0714285714283
reward_min: -547.6428571428573
queue_len: 0.334092520382843
wait_time: 2.3573821339950376
delay_time: 78.17874485036052
pressure: 4.672704714640198
total_envstep_count: 458800
total_train_sample_count: 458800
total_episode_count: 3700
total_duration: 90363.19873462575
[2024-12-27 21:23:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.614154626399686
avg_train_sample_per_sec: 5.614154626399686
avg_episode_per_sec: 0.04527544053548134
collect_time: 110.43514852343873
reward_mean: -544.6857142857143
reward_std: 11.724089973822508
reward_max: -525.2857142857142
reward_min: -556.5
queue_len: 0.3378943637008153
wait_time: 2.380388160226871
delay_time: 78.71547562788412
pressure: 4.727667493796526
total_envstep_count: 459420
total_train_sample_count: 459420
total_episode_count: 3705
total_duration: 90473.63388314919
[2024-12-27 21:25:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.773698311750161
avg_train_sample_per_sec: 5.773698311750161
avg_episode_per_sec: 0.04656208315927549
collect_time: 107.38351166326554
reward_mean: -535.7714285714285
reward_std: 10.47488736484182
reward_max: -521.3571428571429
reward_min: -549.2142857142858
queue_len: 0.33236440978376464
wait_time: 2.358170861396668
delay_time: 77.53820215895226
pressure: 4.649503722084368
total_envstep_count: 460040
total_train_sample_count: 460040
total_episode_count: 3710
total_duration: 90581.01739481246
[2024-12-27 21:27:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.367151120646362
avg_train_sample_per_sec: 5.367151120646362
avg_episode_per_sec: 0.04328347677940615
collect_time: 115.51752243662068
reward_mean: -535.4428571428571
reward_std: 12.923669157394794
reward_max: -523.2857142857142
reward_min: -555.714285714286
queue_len: 0.33216058135412974
wait_time: 2.342662176533144
delay_time: 77.48675473008707
pressure: 4.649255583126551
total_envstep_count: 460660
total_train_sample_count: 460660
total_episode_count: 3715
total_duration: 90696.53491724908
[2024-12-27 21:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.44631054532291
avg_train_sample_per_sec: 5.44631054532291
avg_episode_per_sec: 0.04392185923647508
collect_time: 113.83853249654173
reward_mean: -545.2571428571429
reward_std: 13.76453591588142
reward_max: -528.7142857142859
reward_min: -564.642857142857
queue_len: 0.3382488479262672
wait_time: 2.4091368309110246
delay_time: 78.41639798108383
pressure: 4.733126550868486
total_envstep_count: 461280
total_train_sample_count: 461280
total_episode_count: 3720
total_duration: 90810.37344974562
[2024-12-27 21:31:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.730947648236405
avg_train_sample_per_sec: 5.730947648236405
avg_episode_per_sec: 0.046217319743841974
collect_time: 108.18455132647979
reward_mean: -533.0857142857143
reward_std: 4.98782190409191
reward_max: -526.6428571428575
reward_min: -539.857142857143
queue_len: 0.3306983339241404
wait_time: 2.360678837291741
delay_time: 77.2591330048719
pressure: 4.627915632754343
total_envstep_count: 461900
total_train_sample_count: 461900
total_episode_count: 3725
total_duration: 90918.5580010721
[2024-12-27 21:33:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.62986843644104
avg_train_sample_per_sec: 5.62986843644104
avg_episode_per_sec: 0.04540216481000839
collect_time: 110.12690740459598
reward_mean: -533.9714285714288
reward_std: 9.775082858879436
reward_max: -518.4285714285717
reward_min: -546.8571428571429
queue_len: 0.33124778447359104
wait_time: 2.330521091811414
delay_time: 77.73969375158164
pressure: 4.635359801488834
total_envstep_count: 462520
total_train_sample_count: 462520
total_episode_count: 3730
total_duration: 91028.6849084767
[2024-12-27 21:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.165159612509102
avg_train_sample_per_sec: 5.165159612509102
avg_episode_per_sec: 0.041654513004105664
collect_time: 120.03501276097447
reward_mean: -531.7142857142858
reward_std: 2.341724464873677
reward_max: -528.9999999999998
reward_min: -535.9285714285714
queue_len: 0.3298475717830557
wait_time: 2.300558312655087
delay_time: 78.27708119527134
pressure: 4.6102977667493805
total_envstep_count: 463140
total_train_sample_count: 463140
total_episode_count: 3735
total_duration: 91148.71992123767
[2024-12-27 21:37:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4800827003497385
avg_train_sample_per_sec: 5.4800827003497385
avg_episode_per_sec: 0.04419421532540112
collect_time: 113.13697874676811
reward_mean: -532.4285714285713
reward_std: 9.282416996996082
reward_max: -518.4999999999999
reward_min: -543.6428571428569
queue_len: 0.33029067706487053
wait_time: 2.3321428571428573
delay_time: 77.51216841077624
pressure: 4.622952853598014
total_envstep_count: 463760
total_train_sample_count: 463760
total_episode_count: 3740
total_duration: 91261.85689998444
[2024-12-27 21:39:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.476255776428576
avg_train_sample_per_sec: 5.476255776428576
avg_episode_per_sec: 0.044163353035714316
collect_time: 113.21604127196969
reward_mean: -533.1571428571428
reward_std: 8.499987995189674
reward_max: -520.642857142857
reward_min: -545.6428571428572
queue_len: 0.3307426444523219
wait_time: 2.3266394895427154
delay_time: 77.77375973036571
pressure: 4.628660049627792
total_envstep_count: 464380
total_train_sample_count: 464380
total_episode_count: 3745
total_duration: 91375.07294125641
[2024-12-27 21:40:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.69912164174086
avg_train_sample_per_sec: 5.69912164174086
avg_episode_per_sec: 0.04596065840113597
collect_time: 108.78869393821432
reward_mean: -534.3714285714286
reward_std: 6.98195925955187
reward_max: -524.5
reward_min: -543.4285714285716
queue_len: 0.3314959234314073
wait_time: 2.337256292095002
delay_time: 77.75482808228739
pressure: 4.637841191066998
total_envstep_count: 465000
total_train_sample_count: 465000
total_episode_count: 3750
total_duration: 91483.86163519463
[2024-12-27 21:42:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6456621056539795
avg_train_sample_per_sec: 5.6456621056539795
avg_episode_per_sec: 0.04552953311011274
collect_time: 109.81882875687629
reward_mean: -545.4571428571428
reward_std: 6.154407745175721
reward_max: -534.2142857142856
reward_min: -551.0000000000003
queue_len: 0.3383729174051754
wait_time: 2.4132311237149944
delay_time: 78.64162900708098
pressure: 4.734863523573201
total_envstep_count: 465620
total_train_sample_count: 465620
total_episode_count: 3755
total_duration: 91593.6804639515
