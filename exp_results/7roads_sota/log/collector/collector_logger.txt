[2024-12-27 16:49:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 10
envstep_count: 1240
train_sample_count: 1240
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 3.7159266942383207
avg_train_sample_per_sec: 3.7159266942383207
avg_episode_per_sec: 0.029967150759986457
collect_time: 333.69872498364003
reward_mean: -2068.5428571428574
reward_std: 220.5304810252419
reward_max: -1728.1428571428567
reward_min: -2437.5
queue_len: 1.2832151719248492
wait_time: 6.118366713931231
delay_time: 496.7510334209148
pressure: 14.436042183622828
total_envstep_count: 1240
total_train_sample_count: 1240
total_episode_count: 10
total_duration: 333.69872498364003
[2024-12-27 16:52:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.146361816326577
avg_train_sample_per_sec: 4.146361816326577
avg_episode_per_sec: 0.03343840174456917
collect_time: 149.52867778173834
reward_mean: -1475.8714285714286
reward_std: 119.52493890568705
reward_max: -1315.928571428571
reward_min: -1671.0714285714291
queue_len: 0.9155529953917052
wait_time: 5.283108826657214
delay_time: 291.22757875249897
pressure: 11.25818858560794
total_envstep_count: 1860
total_train_sample_count: 1860
total_episode_count: 15
total_duration: 483.2274027653784
[2024-12-27 16:54:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.5887066355600465
avg_train_sample_per_sec: 4.5887066355600465
avg_episode_per_sec: 0.037005698673871344
collect_time: 135.11432506827268
reward_mean: -1297.7
reward_std: 41.029864683159346
reward_max: -1234.8571428571431
reward_min: -1362.0000000000002
queue_len: 0.8050248138957816
wait_time: 4.918034384969868
delay_time: 241.47149066753246
pressure: 9.982506203473946
total_envstep_count: 2480
total_train_sample_count: 2480
total_episode_count: 20
total_duration: 618.341727833651
[2024-12-27 16:56:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.870477187627826
avg_train_sample_per_sec: 4.870477187627826
avg_episode_per_sec: 0.03927804183570827
collect_time: 127.29758832973243
reward_mean: -1110.042857142857
reward_std: 58.188427210438405
reward_max: -1041.9999999999998
reward_min: -1205.7142857142856
queue_len: 0.6886121942573555
wait_time: 4.615127614321164
delay_time: 167.3401554673561
pressure: 9.177047146401986
total_envstep_count: 3100
total_train_sample_count: 3100
total_episode_count: 25
total_duration: 745.6393161633835
[2024-12-27 16:58:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.246807480439762
avg_train_sample_per_sec: 5.246807480439762
avg_episode_per_sec: 0.04231296355193356
collect_time: 118.16709538350254
reward_mean: -993.8
reward_std: 47.942214366540696
reward_max: -938.1428571428575
reward_min: -1080.5
queue_len: 0.6165012406947892
wait_time: 4.188053881602268
delay_time: 130.0621925684374
pressure: 8.401861042183622
total_envstep_count: 3720
total_train_sample_count: 3720
total_episode_count: 30
total_duration: 863.806411546886
[2024-12-27 17:00:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4097469188865555
avg_train_sample_per_sec: 5.4097469188865555
avg_episode_per_sec: 0.04362699128134319
collect_time: 114.60794918805732
reward_mean: -954.0142857142857
reward_std: 53.586100847903
reward_max: -867.8571428571428
reward_min: -1010.9999999999998
queue_len: 0.5918202764976959
wait_time: 3.8009925558312667
delay_time: 117.28289250008899
pressure: 8.057444168734492
total_envstep_count: 4340
total_train_sample_count: 4340
total_episode_count: 35
total_duration: 978.4143607349433
[2024-12-27 17:02:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.403004607445469
avg_train_sample_per_sec: 5.403004607445469
avg_episode_per_sec: 0.04357261780197959
collect_time: 114.75096636890245
reward_mean: -879.342857142857
reward_std: 58.556032819785926
reward_max: -798.2142857142859
reward_min: -973.3571428571433
queue_len: 0.5454980503367599
wait_time: 3.7436547323644107
delay_time: 103.97515470995329
pressure: 7.463895781637717
total_envstep_count: 4960
total_train_sample_count: 4960
total_episode_count: 40
total_duration: 1093.1653271038458
[2024-12-27 17:04:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.520868617594262
avg_train_sample_per_sec: 5.520868617594262
avg_episode_per_sec: 0.04452313401285695
collect_time: 112.30116906316948
reward_mean: -851.8857142857144
reward_std: 41.46896060763454
reward_max: -807.2857142857143
reward_min: -921.7142857142856
queue_len: 0.528465083303793
wait_time: 3.628332151719248
delay_time: 100.55560232387629
pressure: 7.283374689826303
total_envstep_count: 5580
total_train_sample_count: 5580
total_episode_count: 45
total_duration: 1205.4664961670153
[2024-12-27 17:06:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.522200443332518
avg_train_sample_per_sec: 5.522200443332518
avg_episode_per_sec: 0.04453387454300418
collect_time: 112.27408464475161
reward_mean: -819.8142857142855
reward_std: 93.17408109423516
reward_max: -703.9285714285714
reward_min: -940.0714285714286
queue_len: 0.5085696561503011
wait_time: 3.648138957816377
delay_time: 90.97122313978053
pressure: 7.112282878411911
total_envstep_count: 6200
total_train_sample_count: 6200
total_episode_count: 50
total_duration: 1317.740580811767
[2024-12-27 17:07:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.940349929865187
avg_train_sample_per_sec: 5.940349929865187
avg_episode_per_sec: 0.04790604782149344
collect_time: 104.37095580564066
reward_mean: -783.3142857142857
reward_std: 50.574285633579976
reward_max: -706.3571428571427
reward_min: -839.4999999999999
queue_len: 0.48592697624955694
wait_time: 3.44228996809642
delay_time: 92.22669059951457
pressure: 6.731389578163771
total_envstep_count: 6820
total_train_sample_count: 6820
total_episode_count: 55
total_duration: 1422.1115366174076
[2024-12-27 17:09:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.1296746839891645
avg_train_sample_per_sec: 6.1296746839891645
avg_episode_per_sec: 0.04943286035475133
collect_time: 101.14729279507323
reward_mean: -705.4714285714286
reward_std: 21.868465787941208
reward_max: -678.7142857142863
reward_min: -741.8571428571425
queue_len: 0.4376373626373627
wait_time: 3.249503722084367
delay_time: 82.85798735776598
pressure: 6.091066997518611
total_envstep_count: 7440
total_train_sample_count: 7440
total_episode_count: 60
total_duration: 1523.258829412481
[2024-12-27 17:11:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.220898001620142
avg_train_sample_per_sec: 6.220898001620142
avg_episode_per_sec: 0.05016853227113018
collect_time: 99.66406776618585
reward_mean: -689.6857142857141
reward_std: 25.25068598785263
reward_max: -669.5714285714286
reward_min: -739.428571428571
queue_len: 0.4278447359092519
wait_time: 3.092546969159873
delay_time: 82.00227240467532
pressure: 5.972456575682382
total_envstep_count: 8060
total_train_sample_count: 8060
total_episode_count: 65
total_duration: 1622.9228971786667
[2024-12-27 17:12:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.052244606924679
avg_train_sample_per_sec: 6.052244606924679
avg_episode_per_sec: 0.04880842424939258
collect_time: 102.44133214487508
reward_mean: -672.5714285714287
reward_std: 64.88061249364878
reward_max: -616.5714285714284
reward_min: -789.7142857142857
queue_len: 0.4172279333569657
wait_time: 3.011467564693371
delay_time: 80.72601338496335
pressure: 5.837468982630273
total_envstep_count: 8680
total_train_sample_count: 8680
total_episode_count: 70
total_duration: 1725.3642293235418
[2024-12-27 17:14:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.042325954020241
avg_train_sample_per_sec: 6.042325954020241
avg_episode_per_sec: 0.04872843511306646
collect_time: 102.6094925560057
reward_mean: -664.6857142857142
reward_std: 27.461163671703446
reward_max: -626.0714285714282
reward_min: -710.9999999999999
queue_len: 0.41233605104572846
wait_time: 3.02670152428217
delay_time: 79.85593620423278
pressure: 5.771339950372208
total_envstep_count: 9300
total_train_sample_count: 9300
total_episode_count: 75
total_duration: 1827.9737218795476
[2024-12-27 17:16:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.033951555354653
avg_train_sample_per_sec: 6.033951555354653
avg_episode_per_sec: 0.04866089963995688
collect_time: 102.75190218419954
reward_mean: -629.6714285714286
reward_std: 16.957365505819645
reward_max: -606.4999999999998
reward_min: -650.3571428571428
queue_len: 0.39061503013115917
wait_time: 2.944345976604041
delay_time: 75.78946031032828
pressure: 5.467617866004963
total_envstep_count: 9920
total_train_sample_count: 9920
total_episode_count: 80
total_duration: 1930.725624063747
[2024-12-27 17:18:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.906184128416587
avg_train_sample_per_sec: 5.906184128416587
avg_episode_per_sec: 0.047630517164649895
collect_time: 104.97471574192495
reward_mean: -604.5142857142857
reward_std: 21.90496169681147
reward_max: -564.4285714285713
reward_min: -628.4285714285714
queue_len: 0.3750088621056363
wait_time: 2.8080645161290336
delay_time: 73.85534033859298
pressure: 5.250124069478908
total_envstep_count: 10540
total_train_sample_count: 10540
total_episode_count: 85
total_duration: 2035.700339805672
[2024-12-27 17:20:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.590357496132705
avg_train_sample_per_sec: 5.590357496132705
avg_episode_per_sec: 0.04508352819461858
collect_time: 110.90525076954441
reward_mean: -597.6142857142856
reward_std: 16.954356492702072
reward_max: -575.9285714285714
reward_min: -621.2142857142853
queue_len: 0.3707284650833037
wait_time: 2.724645515774548
delay_time: 74.00153667418564
pressure: 5.190198511166253
total_envstep_count: 11160
total_train_sample_count: 11160
total_episode_count: 90
total_duration: 2146.6055905752164
[2024-12-27 17:21:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.445382546307019
avg_train_sample_per_sec: 5.445382546307019
avg_episode_per_sec: 0.0439143753734437
collect_time: 113.85793279490993
reward_mean: -580.6714285714285
reward_std: 25.767706414765563
reward_max: -548.9999999999997
reward_min: -615.7142857142853
queue_len: 0.3602180077986529
wait_time: 2.6565225097483163
delay_time: 73.27084836977113
pressure: 5.043052109181142
total_envstep_count: 11780
total_train_sample_count: 11780
total_episode_count: 95
total_duration: 2260.4635233701265
[2024-12-27 17:23:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.663132058092793
avg_train_sample_per_sec: 5.663132058092793
avg_episode_per_sec: 0.04567041982332897
collect_time: 109.48005337682363
reward_mean: -553.7142857142857
reward_std: 31.903809509594524
reward_max: -516.3571428571428
reward_min: -600.5000000000001
queue_len: 0.34349521446295644
wait_time: 2.576488833746898
delay_time: 70.57060126691115
pressure: 4.8088089330024815
total_envstep_count: 12400
total_train_sample_count: 12400
total_episode_count: 100
total_duration: 2369.94357674695
[2024-12-27 17:25:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.747090266195268
avg_train_sample_per_sec: 5.747090266195268
avg_episode_per_sec: 0.04634750214673603
collect_time: 107.88067896668989
reward_mean: -551.242857142857
reward_std: 19.07533935290738
reward_max: -524.1428571428571
reward_min: -583.3571428571432
queue_len: 0.34196207018787667
wait_time: 2.5953739808578518
delay_time: 70.32950365826107
pressure: 4.787468982630273
total_envstep_count: 13020
total_train_sample_count: 13020
total_episode_count: 105
total_duration: 2477.82425571364
[2024-12-27 17:27:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.793417866548627
avg_train_sample_per_sec: 5.793417866548627
avg_episode_per_sec: 0.046721111827005064
collect_time: 107.01800116644425
reward_mean: -539.4857142857143
reward_std: 12.623221232542464
reward_max: -525.6428571428575
reward_min: -563.2857142857141
queue_len: 0.3346685572492024
wait_time: 2.55917227933357
delay_time: 68.77010022163594
pressure: 4.6853598014888345
total_envstep_count: 13640
total_train_sample_count: 13640
total_episode_count: 110
total_duration: 2584.8422568800843
[2024-12-27 17:29:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.673068234785342
avg_train_sample_per_sec: 5.673068234785342
avg_episode_per_sec: 0.04575055028052695
collect_time: 109.28830296776073
reward_mean: -550.1999999999999
reward_std: 13.273834934846418
reward_max: -535.9285714285716
reward_min: -569.2857142857142
queue_len: 0.34131513647642675
wait_time: 2.5679369018078697
delay_time: 70.7733532052552
pressure: 4.778411910669975
total_envstep_count: 14260
total_train_sample_count: 14260
total_episode_count: 115
total_duration: 2694.130559847845
[2024-12-27 17:31:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.562033926216727
avg_train_sample_per_sec: 5.562033926216727
avg_episode_per_sec: 0.04485511230819941
collect_time: 111.4700140676275
reward_mean: -521.8857142857142
reward_std: 14.537256850406694
reward_max: -506.3571428571426
reward_min: -548.2857142857143
queue_len: 0.3237504431052818
wait_time: 2.4435129386742296
delay_time: 68.46474150270292
pressure: 4.53225806451613
total_envstep_count: 14880
total_train_sample_count: 14880
total_episode_count: 120
total_duration: 2805.600573915472
[2024-12-27 17:32:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.640743471973156
avg_train_sample_per_sec: 5.640743471973156
avg_episode_per_sec: 0.04548986670946094
collect_time: 109.91458893327786
reward_mean: -533.4571428571428
reward_std: 10.1246919832211
reward_max: -524.3571428571429
reward_min: -552.7857142857142
queue_len: 0.3309287486706841
wait_time: 2.4646224742998935
delay_time: 68.78873764531019
pressure: 4.633002481389578
total_envstep_count: 15500
total_train_sample_count: 15500
total_episode_count: 125
total_duration: 2915.51516284875
[2024-12-27 17:34:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.647572246327069
avg_train_sample_per_sec: 5.647572246327069
avg_episode_per_sec: 0.04554493747037959
collect_time: 109.78168546727676
reward_mean: -560.1142857142856
reward_std: 20.80544473478632
reward_max: -528.4999999999999
reward_min: -588.2142857142858
queue_len: 0.34746543778801847
wait_time: 2.5418468628146043
delay_time: 71.42700261548677
pressure: 4.864516129032258
total_envstep_count: 16120
total_train_sample_count: 16120
total_episode_count: 130
total_duration: 3025.296848316027
[2024-12-27 17:36:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8077847247875996
avg_train_sample_per_sec: 5.8077847247875996
avg_episode_per_sec: 0.046836973586996775
collect_time: 106.75326813575626
reward_mean: -523.0857142857143
reward_std: 19.10344557018609
reward_max: -493.9285714285714
reward_min: -544.0000000000001
queue_len: 0.3244948599787309
wait_time: 2.437247429989365
delay_time: 68.38576931502095
pressure: 4.542928039702234
total_envstep_count: 16740
total_train_sample_count: 16740
total_episode_count: 135
total_duration: 3132.050116451783
[2024-12-27 17:38:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.873091603344003
avg_train_sample_per_sec: 5.873091603344003
avg_episode_per_sec: 0.04736364196245164
collect_time: 105.56620633108912
reward_mean: -523.9142857142857
reward_std: 21.988976830239665
reward_max: -496.21428571428584
reward_min: -552.7857142857144
queue_len: 0.3250088621056363
wait_time: 2.4008684863523566
delay_time: 68.3610033669858
pressure: 4.550124069478908
total_envstep_count: 17360
total_train_sample_count: 17360
total_episode_count: 140
total_duration: 3237.6163227828724
[2024-12-27 17:40:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.808797965953003
avg_train_sample_per_sec: 5.808797965953003
avg_episode_per_sec: 0.04684514488671777
collect_time: 106.73464693280678
reward_mean: -529.4285714285712
reward_std: 22.014049317355074
reward_max: -506.7142857142854
reward_min: -566.6428571428569
queue_len: 0.3284296348812476
wait_time: 2.4867157036511878
delay_time: 68.33395925982421
pressure: 4.5980148883374685
total_envstep_count: 17980
total_train_sample_count: 17980
total_episode_count: 145
total_duration: 3344.350969715679
[2024-12-27 17:41:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.858519636782546
avg_train_sample_per_sec: 5.858519636782546
avg_episode_per_sec: 0.04724612610308505
collect_time: 105.8287824294977
reward_mean: -528.7714285714286
reward_std: 16.802235031114645
reward_max: -509.92857142857133
reward_min: -557.4999999999999
queue_len: 0.328021978021978
wait_time: 2.454182913860334
delay_time: 68.40283151260759
pressure: 4.592307692307692
total_envstep_count: 18600
total_train_sample_count: 18600
total_episode_count: 150
total_duration: 3450.1797521451767
[2024-12-27 17:43:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.671362493608184
avg_train_sample_per_sec: 5.671362493608184
avg_episode_per_sec: 0.045736794303291806
collect_time: 109.3211729454361
reward_mean: -501.8714285714285
reward_std: 10.947686364465044
reward_max: -485.92857142857156
reward_min: -514.4285714285716
queue_len: 0.3113346331088266
wait_time: 2.392724211272599
delay_time: 66.06452696734033
pressure: 4.358684863523573
total_envstep_count: 19220
total_train_sample_count: 19220
total_episode_count: 155
total_duration: 3559.500925090613
[2024-12-27 17:45:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.693726188187089
avg_train_sample_per_sec: 5.693726188187089
avg_episode_per_sec: 0.045917146678928135
collect_time: 108.89178360672295
reward_mean: -512.4857142857143
reward_std: 19.587292840418943
reward_max: -481.64285714285717
reward_min: -538.0714285714287
queue_len: 0.317919177596597
wait_time: 2.407656859269763
delay_time: 66.79382112009083
pressure: 4.45074441687345
total_envstep_count: 19840
total_train_sample_count: 19840
total_episode_count: 160
total_duration: 3668.392708697336
[2024-12-27 17:47:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.772860006753238
avg_train_sample_per_sec: 5.772860006753238
avg_episode_per_sec: 0.046555322635106755
collect_time: 107.39910534374786
reward_mean: -509.07142857142856
reward_std: 9.171272806865884
reward_max: -497.857142857143
reward_min: -522.0714285714284
queue_len: 0.31580113434952145
wait_time: 2.4219159872385676
delay_time: 65.87807081919586
pressure: 4.421215880893301
total_envstep_count: 20460
total_train_sample_count: 20460
total_episode_count: 165
total_duration: 3775.791814041084
[2024-12-27 17:49:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.719186431090212
avg_train_sample_per_sec: 5.719186431090212
avg_episode_per_sec: 0.04612247121846945
collect_time: 108.40702737536279
reward_mean: -511.157142857143
reward_std: 19.12394588264784
reward_max: -493.57142857142884
reward_min: -548.2142857142856
queue_len: 0.31709500177242117
wait_time: 2.4056008507621405
delay_time: 66.95066501209426
pressure: 4.439330024813896
total_envstep_count: 21080
total_train_sample_count: 21080
total_episode_count: 170
total_duration: 3884.1988414164466
[2024-12-27 17:51:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.658507051843908
avg_train_sample_per_sec: 5.658507051843908
avg_episode_per_sec: 0.045633121385837964
collect_time: 109.56953739201649
reward_mean: -507.8857142857143
reward_std: 16.769238114439663
reward_max: -483.64285714285717
reward_min: -530.5000000000001
queue_len: 0.31506557958170867
wait_time: 2.384881247784474
delay_time: 66.60166663906409
pressure: 4.410918114143921
total_envstep_count: 21700
total_train_sample_count: 21700
total_episode_count: 175
total_duration: 3993.7683788084632
[2024-12-27 17:52:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.509489135683775
avg_train_sample_per_sec: 5.509489135683775
avg_episode_per_sec: 0.0444313639974498
collect_time: 112.53311962889508
reward_mean: -504.92857142857156
reward_std: 4.652627083219707
reward_max: -500.07142857142884
reward_min: -512.3571428571428
queue_len: 0.3132311237149948
wait_time: 2.3561414392059548
delay_time: 66.48755600016436
pressure: 4.385235732009926
total_envstep_count: 22320
total_train_sample_count: 22320
total_episode_count: 180
total_duration: 4106.3014984373585
[2024-12-27 17:54:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.817395805630513
avg_train_sample_per_sec: 5.817395805630513
avg_episode_per_sec: 0.04691448230347188
collect_time: 106.57689810274168
reward_mean: -515.342857142857
reward_std: 18.9492016955322
reward_max: -493.92857142857133
reward_min: -547.9285714285714
queue_len: 0.3196915987238568
wait_time: 2.388559021623538
delay_time: 68.05954676875587
pressure: 4.4734491315136475
total_envstep_count: 22940
total_train_sample_count: 22940
total_episode_count: 185
total_duration: 4212.8783965401
[2024-12-27 17:56:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.691028177254895
avg_train_sample_per_sec: 5.691028177254895
avg_episode_per_sec: 0.04589538852624916
collect_time: 108.94340718219058
reward_mean: -492.74285714285725
reward_std: 14.011190862583833
reward_max: -471.7857142857145
reward_min: -511.0714285714284
queue_len: 0.3056717476072316
wait_time: 2.29822757887274
delay_time: 65.24113021678019
pressure: 4.279404466501241
total_envstep_count: 23560
total_train_sample_count: 23560
total_episode_count: 190
total_duration: 4321.8218037222905
[2024-12-27 17:58:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.685007276608873
avg_train_sample_per_sec: 5.685007276608873
avg_episode_per_sec: 0.04584683287587801
collect_time: 109.05878740929812
reward_mean: -492.38571428571424
reward_std: 16.102262485217985
reward_max: -463.3571428571427
reward_min: -512.5
queue_len: 0.30545019496632403
wait_time: 2.341120170152428
delay_time: 65.80918064686291
pressure: 4.2763027295285365
total_envstep_count: 24180
total_train_sample_count: 24180
total_episode_count: 195
total_duration: 4430.8805911315885
[2024-12-27 18:00:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.591450351478844
avg_train_sample_per_sec: 5.591450351478844
avg_episode_per_sec: 0.045092341544184227
collect_time: 110.88357421183584
reward_mean: -483.9428571428572
reward_std: 11.355157059095816
reward_max: -470.35714285714295
reward_min: -499.4999999999997
queue_len: 0.3002126905352712
wait_time: 2.2838532435306633
delay_time: 64.99783038657748
pressure: 4.202977667493796
total_envstep_count: 24800
total_train_sample_count: 24800
total_episode_count: 200
total_duration: 4541.764165343425
[2024-12-27 18:02:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.764115968032849
avg_train_sample_per_sec: 5.764115968032849
avg_episode_per_sec: 0.0464848061938133
collect_time: 107.56202745372431
reward_mean: -501.05714285714294
reward_std: 14.880435038626258
reward_max: -481.0000000000001
reward_min: -513.4285714285713
queue_len: 0.3108294930875576
wait_time: 2.3340304856433884
delay_time: 66.24907448080874
pressure: 4.351612903225806
total_envstep_count: 25420
total_train_sample_count: 25420
total_episode_count: 205
total_duration: 4649.326192797149
[2024-12-27 18:03:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.560962161039761
avg_train_sample_per_sec: 5.560962161039761
avg_episode_per_sec: 0.04484646904064324
collect_time: 111.4914977022745
reward_mean: -508.84285714285727
reward_std: 37.59782885611722
reward_max: -475.99999999999994
reward_min: -580.0714285714287
queue_len: 0.3156593406593407
wait_time: 2.36889400921659
delay_time: 67.28418869581222
pressure: 4.417493796526054
total_envstep_count: 26040
total_train_sample_count: 26040
total_episode_count: 210
total_duration: 4760.817690499423
[2024-12-27 18:05:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.838710054779677
avg_train_sample_per_sec: 5.838710054779677
avg_episode_per_sec: 0.04708637140951352
collect_time: 106.18783844086528
reward_mean: -493.7285714285714
reward_std: 6.137938229917662
reward_max: -484.3571428571431
reward_min: -500.57142857142856
queue_len: 0.3062832328961361
wait_time: 2.304049982275789
delay_time: 65.50412294312835
pressure: 4.2879652605459055
total_envstep_count: 26660
total_train_sample_count: 26660
total_episode_count: 215
total_duration: 4867.005528940289
[2024-12-27 18:07:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.686418444874455
avg_train_sample_per_sec: 5.686418444874455
avg_episode_per_sec: 0.045858213265116576
collect_time: 109.03172286922482
reward_mean: -477.15714285714284
reward_std: 11.408857997903468
reward_max: -457.14285714285705
reward_min: -491.9285714285712
queue_len: 0.296003190358029
wait_time: 2.228154909606522
delay_time: 64.75898085217003
pressure: 4.144044665012407
total_envstep_count: 27280
total_train_sample_count: 27280
total_episode_count: 220
total_duration: 4976.037251809514
[2024-12-27 18:09:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.591344717114852
avg_train_sample_per_sec: 5.591344717114852
avg_episode_per_sec: 0.04509148965415204
collect_time: 110.8856690774597
reward_mean: -487.54285714285714
reward_std: 15.071909267892783
reward_max: -464.0714285714285
reward_min: -511.0
queue_len: 0.30244594115561857
wait_time: 2.306939028713222
delay_time: 65.22192039791636
pressure: 4.23424317617866
total_envstep_count: 27900
total_train_sample_count: 27900
total_episode_count: 225
total_duration: 5086.922920886974
[2024-12-27 18:11:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.765607839564936
avg_train_sample_per_sec: 5.765607839564936
avg_episode_per_sec: 0.04649683741584626
collect_time: 107.5341953966096
reward_mean: -487.0
reward_std: 9.13381249053462
reward_max: -475.142857142857
reward_min: -503.35714285714295
queue_len: 0.30210918114143925
wait_time: 2.3487238567883733
delay_time: 64.48284528508336
pressure: 4.229528535980149
total_envstep_count: 28520
total_train_sample_count: 28520
total_episode_count: 230
total_duration: 5194.457116283584
[2024-12-27 18:13:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.589379652930581
avg_train_sample_per_sec: 5.589379652930581
avg_episode_per_sec: 0.0450756423623434
collect_time: 110.92465327076616
reward_mean: -483.47142857142853
reward_std: 9.662318984760537
reward_max: -470.2142857142857
reward_min: -497.7142857142855
queue_len: 0.2999202410492733
wait_time: 2.283321517192485
delay_time: 64.63719077433174
pressure: 4.198883374689826
total_envstep_count: 29140
total_train_sample_count: 29140
total_episode_count: 235
total_duration: 5305.381769554349
[2024-12-27 18:14:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.800666188274018
avg_train_sample_per_sec: 5.800666188274018
avg_episode_per_sec: 0.04677956603446789
collect_time: 106.88427499126274
reward_mean: -476.0142857142858
reward_std: 9.619644017343289
reward_max: -464.35714285714283
reward_min: -489.7142857142856
queue_len: 0.2952942219071251
wait_time: 2.306442750797589
delay_time: 63.66480146829876
pressure: 4.134119106699751
total_envstep_count: 29760
total_train_sample_count: 29760
total_episode_count: 240
total_duration: 5412.266044545612
[2024-12-27 18:16:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.665733729142271
avg_train_sample_per_sec: 5.665733729142271
avg_episode_per_sec: 0.04569140104146993
collect_time: 109.42978079096228
reward_mean: -473.85714285714283
reward_std: 18.275052695420847
reward_max: -451.9285714285713
reward_min: -502.42857142857133
queue_len: 0.29395604395604397
wait_time: 2.2742378589152783
delay_time: 64.30511326363536
pressure: 4.115384615384616
total_envstep_count: 30380
total_train_sample_count: 30380
total_episode_count: 245
total_duration: 5521.695825336575
[2024-12-27 18:18:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.825651275841226
avg_train_sample_per_sec: 5.825651275841226
avg_episode_per_sec: 0.046981058676138915
collect_time: 106.42586908198892
reward_mean: -479.21428571428567
reward_std: 15.343681808111434
reward_max: -457.85714285714295
reward_min: -499.14285714285705
queue_len: 0.29727933356965613
wait_time: 2.319523218716767
delay_time: 64.66178268793824
pressure: 4.161910669975187
total_envstep_count: 31000
total_train_sample_count: 31000
total_episode_count: 250
total_duration: 5628.1216944185635
[2024-12-27 18:20:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.652421990605607
avg_train_sample_per_sec: 5.652421990605607
avg_episode_per_sec: 0.04558404831133554
collect_time: 109.68749343740566
reward_mean: -484.9285714285714
reward_std: 7.543073589968022
reward_max: -476.4999999999999
reward_min: -497.2857142857141
queue_len: 0.3008241758241758
wait_time: 2.2786246012052467
delay_time: 65.19740961230492
pressure: 4.211538461538462
total_envstep_count: 31620
total_train_sample_count: 31620
total_episode_count: 255
total_duration: 5737.809187855969
[2024-12-27 18:22:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.439431226918308
avg_train_sample_per_sec: 5.439431226918308
avg_episode_per_sec: 0.043866380862244425
collect_time: 113.98250554796681
reward_mean: -474.05714285714276
reward_std: 11.13840570425825
reward_max: -461.6428571428569
reward_min: -491.4999999999998
queue_len: 0.2940801134349521
wait_time: 2.2579315845444876
delay_time: 64.01500929237118
pressure: 4.11712158808933
total_envstep_count: 32240
total_train_sample_count: 32240
total_episode_count: 260
total_duration: 5851.791693403936
[2024-12-27 18:24:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.665422034167107
avg_train_sample_per_sec: 5.665422034167107
avg_episode_per_sec: 0.04568888737231538
collect_time: 109.43580129792542
reward_mean: -473.64285714285705
reward_std: 5.159694659530954
reward_max: -464.7857142857143
reward_min: -480.2142857142858
queue_len: 0.29382311237149944
wait_time: 2.2503722084367253
delay_time: 63.669636600541764
pressure: 4.113523573200993
total_envstep_count: 32860
total_train_sample_count: 32860
total_episode_count: 265
total_duration: 5961.227494701861
[2024-12-27 18:25:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.896918972059065
avg_train_sample_per_sec: 5.896918972059065
avg_episode_per_sec: 0.04755579816176665
collect_time: 105.13965054254606
reward_mean: -486.7
reward_std: 55.58147907645613
reward_max: -449.7142857142858
reward_min: -596.9285714285714
queue_len: 0.30192307692307696
wait_time: 2.2755051400212696
delay_time: 68.15531032114968
pressure: 4.25
total_envstep_count: 33480
total_train_sample_count: 33480
total_episode_count: 270
total_duration: 6066.367145244408
[2024-12-27 18:27:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.758393789669414
avg_train_sample_per_sec: 5.758393789669414
avg_episode_per_sec: 0.04643865959410818
collect_time: 107.66891300700604
reward_mean: -474.85714285714295
reward_std: 16.594565129485506
reward_max: -456.3571428571431
reward_min: -501.0714285714288
queue_len: 0.2945763913505849
wait_time: 2.3099432825239283
delay_time: 63.283217383750674
pressure: 4.124069478908188
total_envstep_count: 34100
total_train_sample_count: 34100
total_episode_count: 275
total_duration: 6174.036058251414
[2024-12-27 18:29:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.727273205260776
avg_train_sample_per_sec: 5.727273205260776
avg_episode_per_sec: 0.0461876871391998
collect_time: 108.25395921928435
reward_mean: -473.7857142857144
reward_std: 2.626396615835809
reward_max: -471.71428571428595
reward_min: -478.4285714285717
queue_len: 0.29391173342786253
wait_time: 2.266430343849698
delay_time: 64.29807525839301
pressure: 4.114764267990074
total_envstep_count: 34720
total_train_sample_count: 34720
total_episode_count: 280
total_duration: 6282.290017470698
[2024-12-27 18:31:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.635937150754776
avg_train_sample_per_sec: 5.635937150754776
avg_episode_per_sec: 0.045451106054474
collect_time: 110.00832397802172
reward_mean: -471.47142857142865
reward_std: 16.000293364657495
reward_max: -451.7857142857144
reward_min: -497.2142857142859
queue_len: 0.292476072314782
wait_time: 2.2592874867068415
delay_time: 64.02186569050643
pressure: 4.0946650124069475
total_envstep_count: 35340
total_train_sample_count: 35340
total_episode_count: 285
total_duration: 6392.29834144872
[2024-12-27 18:33:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.833128416149674
avg_train_sample_per_sec: 5.833128416149674
avg_episode_per_sec: 0.04704135819475544
collect_time: 106.28944809160382
reward_mean: -465.15714285714284
reward_std: 6.404144066500305
reward_max: -455.28571428571394
reward_min: -474.57142857142856
queue_len: 0.28855902162353775
wait_time: 2.2285714285714286
delay_time: 63.51872358361819
pressure: 4.039826302729528
total_envstep_count: 35960
total_train_sample_count: 35960
total_episode_count: 290
total_duration: 6498.587789540324
[2024-12-27 18:34:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.72184863523785
avg_train_sample_per_sec: 5.72184863523785
avg_episode_per_sec: 0.046143940606756854
collect_time: 108.3565888446868
reward_mean: -475.35714285714283
reward_std: 15.180277215075224
reward_max: -450.3571428571428
reward_min: -490.0714285714286
queue_len: 0.2948865650478554
wait_time: 2.288541297412265
delay_time: 64.24556087548032
pressure: 4.128411910669975
total_envstep_count: 36580
total_train_sample_count: 36580
total_episode_count: 295
total_duration: 6606.94437838501
[2024-12-27 18:36:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.932621233820289
avg_train_sample_per_sec: 5.932621233820289
avg_episode_per_sec: 0.04784371962758297
collect_time: 104.50692460620031
reward_mean: -462.11428571428576
reward_std: 5.705636311077498
reward_max: -455.6428571428571
reward_min: -471.0714285714286
queue_len: 0.28667139312300605
wait_time: 2.233569656150302
delay_time: 62.86112255676299
pressure: 4.013399503722084
total_envstep_count: 37200
total_train_sample_count: 37200
total_episode_count: 300
total_duration: 6711.4513029912105
[2024-12-27 18:38:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.622366049741419
avg_train_sample_per_sec: 5.622366049741419
avg_episode_per_sec: 0.04534166169146306
collect_time: 110.27385881936924
reward_mean: -480.4
reward_std: 12.289584108138941
reward_max: -459.4285714285713
reward_min: -497.71428571428555
queue_len: 0.298014888337469
wait_time: 2.2888248847926267
delay_time: 65.19471392881296
pressure: 4.172208436724565
total_envstep_count: 37820
total_train_sample_count: 37820
total_episode_count: 305
total_duration: 6821.725161810579
[2024-12-27 18:40:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.543084948145809
avg_train_sample_per_sec: 5.543084948145809
avg_episode_per_sec: 0.044702297968917816
collect_time: 111.8510731478855
reward_mean: -481.1
reward_std: 3.104506270516044
reward_max: -478.2857142857144
reward_min: -485.0
queue_len: 0.29844913151364766
wait_time: 2.2846331088266574
delay_time: 64.94742164267765
pressure: 4.178287841191067
total_envstep_count: 38440
total_train_sample_count: 38440
total_episode_count: 310
total_duration: 6933.576234958465
[2024-12-27 18:42:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.682071489241431
avg_train_sample_per_sec: 5.682071489241431
avg_episode_per_sec: 0.045823157171301865
collect_time: 109.11513541741294
reward_mean: -470.8857142857143
reward_std: 6.227752239707664
reward_max: -461.6428571428571
reward_min: -477.7142857142858
queue_len: 0.2921127259836937
wait_time: 2.246729883020206
delay_time: 63.99011445764573
pressure: 4.089578163771713
total_envstep_count: 39060
total_train_sample_count: 39060
total_episode_count: 315
total_duration: 7042.691370375877
[2024-12-27 18:44:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.573306766376845
avg_train_sample_per_sec: 5.573306766376845
avg_episode_per_sec: 0.04494602230949069
collect_time: 111.2445494190976
reward_mean: -474.9428571428572
reward_std: 7.2104515978473
reward_max: -463.3571428571427
reward_min: -485.8571428571429
queue_len: 0.29462956398440265
wait_time: 2.2546791917759657
delay_time: 64.31908989962707
pressure: 4.124813895781638
total_envstep_count: 39680
total_train_sample_count: 39680
total_episode_count: 320
total_duration: 7153.935919794975
[2024-12-27 18:45:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.824511339221754
avg_train_sample_per_sec: 5.824511339221754
avg_episode_per_sec: 0.04697186563888511
collect_time: 106.44669808177277
reward_mean: -455.55714285714294
reward_std: 4.8729574475583455
reward_max: -449.21428571428567
reward_min: -462.3571428571429
queue_len: 0.28260368663594476
wait_time: 2.165233959588798
delay_time: 62.90636265510382
pressure: 3.9564516129032263
total_envstep_count: 40300
total_train_sample_count: 40300
total_episode_count: 325
total_duration: 7260.382617876748
[2024-12-27 18:47:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.648468479938642
avg_train_sample_per_sec: 5.648468479938642
avg_episode_per_sec: 0.0455521651607955
collect_time: 109.76426657987386
reward_mean: -468.8857142857143
reward_std: 20.707121913949802
reward_max: -442.85714285714306
reward_min: -501.92857142857133
queue_len: 0.29087203119461186
wait_time: 2.20586671393123
delay_time: 64.0317568887601
pressure: 4.072208436724566
total_envstep_count: 40920
total_train_sample_count: 40920
total_episode_count: 330
total_duration: 7370.146884456622
[2024-12-27 18:49:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.712339546654779
avg_train_sample_per_sec: 5.712339546654779
avg_episode_per_sec: 0.046067254408506286
collect_time: 108.53696544755994
reward_mean: -475.42857142857144
reward_std: 6.911540186897824
reward_max: -463.21428571428555
reward_min: -482.35714285714295
queue_len: 0.29493087557603687
wait_time: 2.2581265508684862
delay_time: 64.13608755245352
pressure: 4.129032258064516
total_envstep_count: 41540
total_train_sample_count: 41540
total_episode_count: 335
total_duration: 7478.683849904181
[2024-12-27 18:50:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.573033073333695
avg_train_sample_per_sec: 7.573033073333695
avg_episode_per_sec: 0.06107284736559432
collect_time: 81.86944306148028
reward_mean: -461.75714285714275
reward_std: 5.460544938044884
reward_max: -456.92857142857144
reward_min: -472.35714285714266
queue_len: 0.2864498404820985
wait_time: 2.202915632754342
delay_time: 63.08642412179571
pressure: 4.01029776674938
total_envstep_count: 42160
total_train_sample_count: 42160
total_episode_count: 340
total_duration: 7560.553292965662
[2024-12-27 18:52:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.225595687896403
avg_train_sample_per_sec: 6.225595687896403
avg_episode_per_sec: 0.05020641683787422
collect_time: 99.58886363362521
reward_mean: -456.32857142857137
reward_std: 8.356666653099222
reward_max: -445.7857142857142
reward_min: -471.4285714285714
queue_len: 0.2830822403403048
wait_time: 2.202277561148529
delay_time: 62.790527768410925
pressure: 3.9631513647642675
total_envstep_count: 42780
total_train_sample_count: 42780
total_episode_count: 345
total_duration: 7660.142156599287
[2024-12-27 18:54:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.935406404363922
avg_train_sample_per_sec: 6.935406404363922
avg_episode_per_sec: 0.055930696809386476
collect_time: 89.39634735894947
reward_mean: -469.82857142857154
reward_std: 19.764305075110613
reward_max: -441.4999999999999
reward_min: -500.64285714285717
queue_len: 0.29145693016660756
wait_time: 2.2310350939383197
delay_time: 63.82426378946648
pressure: 4.080397022332507
total_envstep_count: 43400
total_train_sample_count: 43400
total_episode_count: 350
total_duration: 7749.538503958236
[2024-12-27 18:55:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.5760676373659885
avg_train_sample_per_sec: 7.5760676373659885
avg_episode_per_sec: 0.06109731965617733
collect_time: 81.83665057873726
reward_mean: -472.0714285714286
reward_std: 15.1674328878741
reward_max: -444.78571428571433
reward_min: -486.78571428571445
queue_len: 0.2928482807515066
wait_time: 2.2940358029067704
delay_time: 63.96902906887376
pressure: 4.099875930521091
total_envstep_count: 44020
total_train_sample_count: 44020
total_episode_count: 355
total_duration: 7831.375154536973
[2024-12-27 18:57:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.44751225524825
avg_train_sample_per_sec: 5.44751225524825
avg_episode_per_sec: 0.0439315504455504
collect_time: 113.81341995195675
reward_mean: -622.1857142857143
reward_std: 294.3602769618572
reward_max: -457.5
reward_min: -1210.071428571429
queue_len: 0.3859712867777384
wait_time: 2.3744859978730952
delay_time: 93.62128760238208
pressure: 5.474813895781638
total_envstep_count: 44640
total_train_sample_count: 44640
total_episode_count: 360
total_duration: 7945.18857448893
[2024-12-27 18:59:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.53331750064593
avg_train_sample_per_sec: 5.53331750064593
avg_episode_per_sec: 0.04462352823101556
collect_time: 112.04851337875054
reward_mean: -607.4142857142857
reward_std: 268.0177362391816
reward_max: -466.35714285714283
reward_min: -1143.357142857143
queue_len: 0.37680786954980505
wait_time: 2.298794753633463
delay_time: 91.09091931868427
pressure: 5.366749379652605
total_envstep_count: 45260
total_train_sample_count: 45260
total_episode_count: 365
total_duration: 8057.23708786768
[2024-12-27 19:01:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.656184048933111
avg_train_sample_per_sec: 5.656184048933111
avg_episode_per_sec: 0.04561438749139606
collect_time: 109.61453775835786
reward_mean: -589.2857142857141
reward_std: 267.0607169364529
reward_max: -442.0714285714286
reward_min: -1123.1428571428569
queue_len: 0.3655618574973413
wait_time: 2.2774104927330736
delay_time: 87.79439978197335
pressure: 5.194665012406948
total_envstep_count: 45880
total_train_sample_count: 45880
total_episode_count: 370
total_duration: 8166.851625626038
[2024-12-27 19:02:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.555516777975432
avg_train_sample_per_sec: 5.555516777975432
avg_episode_per_sec: 0.044802554661092196
collect_time: 111.60077896946669
reward_mean: -455.0857142857141
reward_std: 9.3658519993361
reward_max: -443.1428571428571
reward_min: -468.8571428571426
queue_len: 0.2823112371499467
wait_time: 2.1788816022686994
delay_time: 62.255390376823655
pressure: 3.9523573200992557
total_envstep_count: 46500
total_train_sample_count: 46500
total_episode_count: 375
total_duration: 8278.452404595504
[2024-12-27 19:04:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.755772102924116
avg_train_sample_per_sec: 5.755772102924116
avg_episode_per_sec: 0.046417516959065444
collect_time: 107.71795493518937
reward_mean: -473.37142857142845
reward_std: 15.021712177201891
reward_max: -454.14285714285717
reward_min: -488.3571428571428
queue_len: 0.29365473236440975
wait_time: 2.249344204182914
delay_time: 64.27393814023279
pressure: 4.111166253101738
total_envstep_count: 47120
total_train_sample_count: 47120
total_episode_count: 380
total_duration: 8386.170359530694
[2024-12-27 19:06:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.63610112197789
avg_train_sample_per_sec: 5.63610112197789
avg_episode_per_sec: 0.0454524284030475
collect_time: 110.00512350325289
reward_mean: -477.2285714285714
reward_std: 9.523054731994911
reward_max: -465.92857142857144
reward_min: -494.8571428571428
queue_len: 0.29604750088621057
wait_time: 2.233667139312301
delay_time: 64.66229987938881
pressure: 4.144665012406948
total_envstep_count: 47740
total_train_sample_count: 47740
total_episode_count: 385
total_duration: 8496.175483033947
[2024-12-27 19:08:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.619437077376589
avg_train_sample_per_sec: 5.619437077376589
avg_episode_per_sec: 0.04531804094658539
collect_time: 110.33133594396335
reward_mean: -471.62857142857155
reward_std: 21.22332178889781
reward_max: -454.21428571428567
reward_min: -512.6428571428573
queue_len: 0.2925735554767813
wait_time: 2.2280928748670674
delay_time: 64.3874517311661
pressure: 4.096029776674937
total_envstep_count: 48360
total_train_sample_count: 48360
total_episode_count: 390
total_duration: 8606.50681897791
[2024-12-27 19:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.573923081993771
avg_train_sample_per_sec: 5.573923081993771
avg_episode_per_sec: 0.04495099259672396
collect_time: 111.23224897072465
reward_mean: -455.3285714285715
reward_std: 11.701787758060435
reward_max: -439.7857142857144
reward_min: -472.0714285714286
queue_len: 0.28246189294576396
wait_time: 2.1756292095001775
delay_time: 63.19288821825188
pressure: 3.954466501240695
total_envstep_count: 48980
total_train_sample_count: 48980
total_episode_count: 395
total_duration: 8717.739067948634
[2024-12-27 19:12:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.744119009403213
avg_train_sample_per_sec: 5.744119009403213
avg_episode_per_sec: 0.04632354039841301
collect_time: 107.9364823369868
reward_mean: -487.04285714285714
reward_std: 17.365906077068196
reward_max: -475.0
reward_min: -520.9285714285717
queue_len: 0.30213576745834814
wait_time: 2.2876905352711807
delay_time: 65.53842306996819
pressure: 4.229900744416874
total_envstep_count: 49600
total_train_sample_count: 49600
total_episode_count: 400
total_duration: 8825.675550285621
[2024-12-27 19:14:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.4320545962969335
avg_train_sample_per_sec: 5.4320545962969335
avg_episode_per_sec: 0.04380689190562043
collect_time: 114.13729170223326
reward_mean: -609.5571428571428
reward_std: 296.1120699316117
reward_max: -448.0714285714285
reward_min: -1201.0714285714287
queue_len: 0.37813718539525
wait_time: 2.455184331797235
delay_time: 95.18313571977515
pressure: 5.2064516129032254
total_envstep_count: 50220
total_train_sample_count: 50220
total_episode_count: 405
total_duration: 8939.812841987854
[2024-12-27 19:15:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.739577044982849
avg_train_sample_per_sec: 5.739577044982849
avg_episode_per_sec: 0.046286911653087494
collect_time: 108.02189693436769
reward_mean: -464.6000000000001
reward_std: 15.452402230523056
reward_max: -443.0000000000003
reward_min: -490.0
queue_len: 0.28821339950372216
wait_time: 2.2167405175469685
delay_time: 63.26454710226999
pressure: 4.03498759305211
total_envstep_count: 50840
total_train_sample_count: 50840
total_episode_count: 410
total_duration: 9047.834738922222
[2024-12-27 19:17:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5118879946360995
avg_train_sample_per_sec: 5.5118879946360995
avg_episode_per_sec: 0.04445070963416209
collect_time: 112.48414347377047
reward_mean: -450.07142857142856
reward_std: 9.775020225460564
reward_max: -433.92857142857133
reward_min: -462.71428571428567
queue_len: 0.2792006380716058
wait_time: 2.1473679546260187
delay_time: 62.683969681242544
pressure: 3.9088089330024816
total_envstep_count: 51460
total_train_sample_count: 51460
total_episode_count: 415
total_duration: 9160.318882395992
[2024-12-27 19:19:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.776593120843059
avg_train_sample_per_sec: 5.776593120843059
avg_episode_per_sec: 0.046585428393895637
collect_time: 107.32969884323698
reward_mean: -459.4142857142857
reward_std: 6.169444125391476
reward_max: -452.42857142857133
reward_min: -469.28571428571445
queue_len: 0.28499645515774547
wait_time: 2.171056362991847
delay_time: 62.89749621079991
pressure: 3.989950372208437
total_envstep_count: 52080
total_train_sample_count: 52080
total_episode_count: 420
total_duration: 9267.64858123923
[2024-12-27 19:21:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6521272126726325
avg_train_sample_per_sec: 5.6521272126726325
avg_episode_per_sec: 0.045581671069940585
collect_time: 109.69321401859077
reward_mean: -472.9571428571429
reward_std: 11.103557069328522
reward_max: -458.42857142857156
reward_min: -484.57142857142867
queue_len: 0.29339773130095714
wait_time: 2.219000354484226
delay_time: 64.61165235014879
pressure: 4.1075682382134
total_envstep_count: 52700
total_train_sample_count: 52700
total_episode_count: 425
total_duration: 9377.34179525782
[2024-12-27 19:23:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.832744350703842
avg_train_sample_per_sec: 5.832744350703842
avg_episode_per_sec: 0.047038260892772916
collect_time: 106.29644687327743
reward_mean: -467.47142857142853
reward_std: 14.34477790212254
reward_max: -445.8571428571429
reward_min: -483.07142857142856
queue_len: 0.2899946827366182
wait_time: 2.202534562211981
delay_time: 63.975051565945044
pressure: 4.059925558312655
total_envstep_count: 53320
total_train_sample_count: 53320
total_episode_count: 430
total_duration: 9483.638242131097
[2024-12-27 19:25:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.557361417465652
avg_train_sample_per_sec: 5.557361417465652
avg_episode_per_sec: 0.04481743078601332
collect_time: 111.56373563386873
reward_mean: -463.74285714285713
reward_std: 20.80544473478626
reward_max: -450.42857142857144
reward_min: -505.14285714285717
queue_len: 0.28768167316554416
wait_time: 2.1773484579936193
delay_time: 63.82248973982087
pressure: 4.027543424317618
total_envstep_count: 53940
total_train_sample_count: 53940
total_episode_count: 435
total_duration: 9595.201977764966
[2024-12-27 19:26:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.484249865979807
avg_train_sample_per_sec: 5.484249865979807
avg_episode_per_sec: 0.04422782149983716
collect_time: 113.05101247228308
reward_mean: -459.62857142857166
reward_std: 18.439277067594304
reward_max: -443.50000000000034
reward_min: -494.857142857143
queue_len: 0.28512938674229005
wait_time: 2.173759305210918
delay_time: 63.652988582819624
pressure: 3.991811414392059
total_envstep_count: 54560
total_train_sample_count: 54560
total_episode_count: 440
total_duration: 9708.252990237248
[2024-12-27 19:28:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5763731534635035
avg_train_sample_per_sec: 5.5763731534635035
avg_episode_per_sec: 0.0449707512376089
collect_time: 111.18337724851071
reward_mean: -473.4
reward_std: 21.48006194647691
reward_max: -452.5000000000001
reward_min: -512.8571428571427
queue_len: 0.29367245657568236
wait_time: 2.1977844735909255
delay_time: 65.01063967279677
pressure: 4.111414392059553
total_envstep_count: 55180
total_train_sample_count: 55180
total_episode_count: 445
total_duration: 9819.43636748576
[2024-12-27 19:30:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.769746209232478
avg_train_sample_per_sec: 5.769746209232478
avg_episode_per_sec: 0.04653021136477805
collect_time: 107.45706613713875
reward_mean: -454.97142857142865
reward_std: 10.813313789123187
reward_max: -445.57142857142856
reward_min: -475.35714285714306
queue_len: 0.28224034030485645
wait_time: 2.1897908543069833
delay_time: 63.0859910688407
pressure: 3.95136476426799
total_envstep_count: 55800
total_train_sample_count: 55800
total_episode_count: 450
total_duration: 9926.893433622898
[2024-12-27 19:32:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.524509768877298
avg_train_sample_per_sec: 5.524509768877298
avg_episode_per_sec: 0.04455249813610724
collect_time: 112.22715244216097
reward_mean: -465.75714285714275
reward_std: 14.28539999654287
reward_max: -448.57142857142827
reward_min: -481.42857142857144
queue_len: 0.2889312300602623
wait_time: 2.177144629563985
delay_time: 64.2897158565917
pressure: 4.045037220843673
total_envstep_count: 56420
total_train_sample_count: 56420
total_episode_count: 455
total_duration: 10039.120586065059
[2024-12-27 19:34:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.656728269003904
avg_train_sample_per_sec: 5.656728269003904
avg_episode_per_sec: 0.04561877636293471
collect_time: 109.60399201023954
reward_mean: -458.4142857142857
reward_std: 9.616249003533479
reward_max: -440.42857142857156
reward_min: -469.21428571428584
queue_len: 0.28437610776320454
wait_time: 2.1656061680255223
delay_time: 63.43449613055843
pressure: 3.9812655086848636
total_envstep_count: 57040
total_train_sample_count: 57040
total_episode_count: 460
total_duration: 10148.724578075298
[2024-12-27 19:36:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.665716116568154
avg_train_sample_per_sec: 5.665716116568154
avg_episode_per_sec: 0.04569125900458189
collect_time: 109.43012096687035
reward_mean: -458.68571428571414
reward_std: 11.015999496094778
reward_max: -439.42857142857133
reward_min: -469.7857142857144
queue_len: 0.2845444877702942
wait_time: 2.1970400567174755
delay_time: 62.90931768770061
pressure: 3.9836228287841187
total_envstep_count: 57660
total_train_sample_count: 57660
total_episode_count: 465
total_duration: 10258.154699042168
[2024-12-27 19:38:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.945736577681759
avg_train_sample_per_sec: 4.945736577681759
avg_episode_per_sec: 0.039884972400659344
collect_time: 125.36049792822081
reward_mean: -992.1714285714286
reward_std: 1073.167905914873
reward_max: -450.57142857142867
reward_min: -3138.5
queue_len: 0.615490960652251
wait_time: 2.716811414392059
delay_time: 192.85162611829355
pressure: 7.18287841191067
total_envstep_count: 58280
total_train_sample_count: 58280
total_episode_count: 470
total_duration: 10383.51519697039
[2024-12-27 19:40:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.642139790454912
avg_train_sample_per_sec: 5.642139790454912
avg_episode_per_sec: 0.04550112734237832
collect_time: 109.88738723717636
reward_mean: -453.94285714285724
reward_std: 13.691007029046045
reward_max: -429.0
reward_min: -469.1428571428572
queue_len: 0.2816022686990429
wait_time: 2.159978730946473
delay_time: 62.64874032188243
pressure: 3.9424317617866
total_envstep_count: 58900
total_train_sample_count: 58900
total_episode_count: 475
total_duration: 10493.402584207566
[2024-12-27 19:41:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.576620629812232
avg_train_sample_per_sec: 5.576620629812232
avg_episode_per_sec: 0.04497274701461477
collect_time: 111.17844321084395
reward_mean: -448.38571428571424
reward_std: 14.47887976273274
reward_max: -423.0714285714286
reward_min: -463.64285714285694
queue_len: 0.2781549096065225
wait_time: 2.1586848635235727
delay_time: 62.441361141580884
pressure: 3.8941687344913154
total_envstep_count: 59520
total_train_sample_count: 59520
total_episode_count: 480
total_duration: 10604.58102741841
[2024-12-27 19:43:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.571324102742565
avg_train_sample_per_sec: 5.571324102742565
avg_episode_per_sec: 0.04493003308663359
collect_time: 111.28413794752956
reward_mean: -454.0
reward_std: 11.222517451943897
reward_max: -431.9285714285712
reward_min: -461.7142857142857
queue_len: 0.2816377171215881
wait_time: 2.1903668911733427
delay_time: 62.62756119531599
pressure: 3.9429280397022333
total_envstep_count: 60140
total_train_sample_count: 60140
total_episode_count: 485
total_duration: 10715.86516536594
[2024-12-27 19:46:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.531125165216547
avg_train_sample_per_sec: 4.531125165216547
avg_episode_per_sec: 0.0365413319775528
collect_time: 136.83135587590186
reward_mean: -1256.1857142857143
reward_std: 1411.2814647167525
reward_max: -438.78571428571433
reward_min: -4063.5000000000005
queue_len: 0.7792715349166961
wait_time: 3.0066554413328603
delay_time: 258.8838028836476
pressure: 8.915508684863525
total_envstep_count: 60760
total_train_sample_count: 60760
total_episode_count: 490
total_duration: 10852.696521241842
[2024-12-27 19:48:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.881109346632319
avg_train_sample_per_sec: 4.881109346632319
avg_episode_per_sec: 0.03936378505348644
collect_time: 127.02030542048067
reward_mean: -1000.5857142857142
reward_std: 1071.3443484992229
reward_max: -440.4999999999998
reward_min: -3142.999999999999
queue_len: 0.6207107408720309
wait_time: 2.7958702587734847
delay_time: 192.0602722100005
pressure: 7.318362282878411
total_envstep_count: 61380
total_train_sample_count: 61380
total_episode_count: 495
total_duration: 10979.716826662323
[2024-12-27 19:50:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.261250274759362
avg_train_sample_per_sec: 5.261250274759362
avg_episode_per_sec: 0.04242943769967228
collect_time: 117.842711831145
reward_mean: -638.5428571428572
reward_std: 225.2538504506795
reward_max: -445.3571428571429
reward_min: -957.4999999999997
queue_len: 0.3961183977313009
wait_time: 2.5104041120170155
delay_time: 93.00384662013593
pressure: 5.527543424317618
total_envstep_count: 62000
total_train_sample_count: 62000
total_episode_count: 500
total_duration: 11097.559538493468
[2024-12-27 19:52:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.860688587682836
avg_train_sample_per_sec: 5.860688587682836
avg_episode_per_sec: 0.04726361764260352
collect_time: 105.78961682131141
reward_mean: -457.8285714285715
reward_std: 9.056128830121366
reward_max: -445.85714285714295
reward_min: -466.1428571428572
queue_len: 0.2840127614321163
wait_time: 2.186175115207373
delay_time: 62.77056515264307
pressure: 3.97605459057072
total_envstep_count: 62620
total_train_sample_count: 62620
total_episode_count: 505
total_duration: 11203.34915531478
[2024-12-27 19:53:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.544425795512999
avg_train_sample_per_sec: 5.544425795512999
avg_episode_per_sec: 0.04471311125413709
collect_time: 111.82402341857555
reward_mean: -468.3714285714286
reward_std: 18.631627707218936
reward_max: -450.0000000000001
reward_min: -499.07142857142856
queue_len: 0.2905529953917051
wait_time: 2.2435838355193196
delay_time: 63.727769962474326
pressure: 4.0677419354838715
total_envstep_count: 63240
total_train_sample_count: 63240
total_episode_count: 510
total_duration: 11315.173178733356
[2024-12-27 19:55:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.660552485890049
avg_train_sample_per_sec: 5.660552485890049
avg_episode_per_sec: 0.04564961682169394
collect_time: 109.52994456733016
reward_mean: -457.92857142857144
reward_std: 13.244791043875239
reward_max: -431.85714285714295
reward_min: -467.4285714285713
queue_len: 0.2840747961715704
wait_time: 2.204103154909606
delay_time: 62.56032205230197
pressure: 3.977047146401985
total_envstep_count: 63860
total_train_sample_count: 63860
total_episode_count: 515
total_duration: 11424.703123300686
[2024-12-27 19:57:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.758795037961478
avg_train_sample_per_sec: 5.758795037961478
avg_episode_per_sec: 0.04644189546743127
collect_time: 107.6614110960737
reward_mean: -469.7857142857141
reward_std: 5.773443778302865
reward_max: -463.7142857142858
reward_min: -478.07142857142844
queue_len: 0.2914303438496986
wait_time: 2.218619283941865
delay_time: 63.945432455139645
pressure: 4.080024813895782
total_envstep_count: 64480
total_train_sample_count: 64480
total_episode_count: 520
total_duration: 11532.36453439676
[2024-12-27 19:59:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6805958931135025
avg_train_sample_per_sec: 5.6805958931135025
avg_episode_per_sec: 0.045811257202528245
collect_time: 109.14347925217076
reward_mean: -458.6714285714285
reward_std: 7.354659775146893
reward_max: -450.07142857142856
reward_min: -471.21428571428584
queue_len: 0.28453562566465795
wait_time: 2.16565934065934
delay_time: 63.18516860387725
pressure: 3.9834987593052107
total_envstep_count: 65100
total_train_sample_count: 65100
total_episode_count: 525
total_duration: 11641.50801364893
[2024-12-27 20:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8932283343073
avg_train_sample_per_sec: 5.8932283343073
avg_episode_per_sec: 0.04752603495409113
collect_time: 105.20549431127309
reward_mean: -457.84285714285704
reward_std: 6.151389423271378
reward_max: -449.7142857142855
reward_min: -466.5714285714285
queue_len: 0.2840216235377525
wait_time: 2.1535891527827014
delay_time: 63.00228189126303
pressure: 3.976178660049628
total_envstep_count: 65720
total_train_sample_count: 65720
total_episode_count: 530
total_duration: 11746.713507960203
[2024-12-27 20:02:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.846122790356409
avg_train_sample_per_sec: 5.846122790356409
avg_episode_per_sec: 0.04714615153513233
collect_time: 106.05319495217131
reward_mean: -449.6142857142856
reward_std: 4.17049891793415
reward_max: -445.71428571428567
reward_min: -457.6428571428571
queue_len: 0.2789170506912442
wait_time: 2.1403048564338887
delay_time: 62.538389615849155
pressure: 3.9048387096774193
total_envstep_count: 66340
total_train_sample_count: 66340
total_episode_count: 535
total_duration: 11852.766702912375
[2024-12-27 20:04:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.693771314107021
avg_train_sample_per_sec: 5.693771314107021
avg_episode_per_sec: 0.04591751059763727
collect_time: 108.89092058612778
reward_mean: -453.54285714285714
reward_std: 5.311251053669167
reward_max: -445.857142857143
reward_min: -459.92857142857144
queue_len: 0.2813541297412266
wait_time: 2.1686370081531368
delay_time: 62.35418681308171
pressure: 3.9389578163771715
total_envstep_count: 66960
total_train_sample_count: 66960
total_episode_count: 540
total_duration: 11961.657623498502
[2024-12-27 20:06:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.771800005987419
avg_train_sample_per_sec: 5.771800005987419
avg_episode_per_sec: 0.04654677424183403
collect_time: 107.41882936983929
reward_mean: -461.1
reward_std: 5.251549819834505
reward_max: -453.85714285714283
reward_min: -467.71428571428567
queue_len: 0.28604218362282874
wait_time: 2.2072492024104933
delay_time: 63.305928387641885
pressure: 4.0045905707196034
total_envstep_count: 67580
total_train_sample_count: 67580
total_episode_count: 545
total_duration: 12069.076452868341
[2024-12-27 20:08:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.442706627241224
avg_train_sample_per_sec: 5.442706627241224
avg_episode_per_sec: 0.04389279538097761
collect_time: 113.91391130597518
reward_mean: -459.72857142857146
reward_std: 8.188393976743457
reward_max: -454.9285714285713
reward_min: -476.0714285714287
queue_len: 0.2851914214817441
wait_time: 2.1755405884438135
delay_time: 63.91607305630437
pressure: 3.9926799007444167
total_envstep_count: 68200
total_train_sample_count: 68200
total_episode_count: 550
total_duration: 12182.990364174317
[2024-12-27 20:10:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.55517292881288
avg_train_sample_per_sec: 5.55517292881288
avg_episode_per_sec: 0.04479978168397484
collect_time: 111.60768673541396
reward_mean: -458.34285714285716
reward_std: 7.5977171652048865
reward_max: -448.7142857142857
reward_min: -466.2142857142859
queue_len: 0.28433179723502305
wait_time: 2.1585076214108474
delay_time: 63.359731283031714
pressure: 3.9806451612903224
total_envstep_count: 68820
total_train_sample_count: 68820
total_episode_count: 555
total_duration: 12294.59805090973
[2024-12-27 20:12:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7124082390767486
avg_train_sample_per_sec: 5.7124082390767486
avg_episode_per_sec: 0.046067808379651194
collect_time: 108.53566027700529
reward_mean: -453.94285714285724
reward_std: 6.652818951391996
reward_max: -441.0
reward_min: -458.99999999999994
queue_len: 0.281602268699043
wait_time: 2.139551577454804
delay_time: 63.15937719236082
pressure: 3.9424317617866
total_envstep_count: 69440
total_train_sample_count: 69440
total_episode_count: 560
total_duration: 12403.133711186736
[2024-12-27 20:13:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.893162003601235
avg_train_sample_per_sec: 5.893162003601235
avg_episode_per_sec: 0.04752550002904222
collect_time: 105.206678455662
reward_mean: -450.12857142857155
reward_std: 8.997437276859554
reward_max: -435.42857142857156
reward_min: -461.21428571428595
queue_len: 0.2792360864941511
wait_time: 2.124769585253456
delay_time: 62.54003852755496
pressure: 3.9093052109181143
total_envstep_count: 70060
total_train_sample_count: 70060
total_episode_count: 565
total_duration: 12508.340389642399
[2024-12-27 20:15:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8536815648244955
avg_train_sample_per_sec: 5.8536815648244955
avg_episode_per_sec: 0.04720710939374593
collect_time: 105.9162499931082
reward_mean: -449.3
reward_std: 21.454051517851095
reward_max: -428.57142857142856
reward_min: -488.7857142857142
queue_len: 0.27872208436724566
wait_time: 2.1316731655441337
delay_time: 62.0763718719006
pressure: 3.9021091811414395
total_envstep_count: 70680
total_train_sample_count: 70680
total_episode_count: 570
total_duration: 12614.256639635507
[2024-12-27 20:17:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.762164836135494
avg_train_sample_per_sec: 5.762164836135494
avg_episode_per_sec: 0.04646907125915721
collect_time: 107.59844913006947
reward_mean: -455.02857142857135
reward_std: 11.0703317429046
reward_max: -437.7142857142855
reward_min: -466.7142857142857
queue_len: 0.28227578872740156
wait_time: 2.1483250620347394
delay_time: 62.919606882982976
pressure: 3.951861042183623
total_envstep_count: 71300
total_train_sample_count: 71300
total_episode_count: 575
total_duration: 12721.855088765577
[2024-12-27 20:19:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.49423770627408
avg_train_sample_per_sec: 5.49423770627408
avg_episode_per_sec: 0.04430836859898452
collect_time: 112.84549980282037
reward_mean: -537.6142857142858
reward_std: 157.7396239997796
reward_max: -443.64285714285734
reward_min: -852.0000000000001
queue_len: 0.3335076214108472
wait_time: 2.294337114498405
delay_time: 71.95396512267894
pressure: 4.577419354838709
total_envstep_count: 71920
total_train_sample_count: 71920
total_episode_count: 580
total_duration: 12834.700588568398
[2024-12-27 20:21:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.808420876442698
avg_train_sample_per_sec: 5.808420876442698
avg_episode_per_sec: 0.046842103842279825
collect_time: 106.74157627153768
reward_mean: -449.7428571428571
reward_std: 4.638041458571571
reward_max: -442.71428571428567
reward_min: -455.99999999999994
queue_len: 0.27899680964197093
wait_time: 2.141802552286423
delay_time: 62.17352957990736
pressure: 3.9059553349875933
total_envstep_count: 72540
total_train_sample_count: 72540
total_episode_count: 585
total_duration: 12941.442164839935
[2024-12-27 20:22:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.933312543954502
avg_train_sample_per_sec: 5.933312543954502
avg_episode_per_sec: 0.0478492947093105
collect_time: 104.49474815408516
reward_mean: -455.4428571428572
reward_std: 10.972730577505816
reward_max: -437.85714285714283
reward_min: -470.5714285714286
queue_len: 0.2825327897908543
wait_time: 2.1528092874867073
delay_time: 62.92785029024124
pressure: 3.9554590570719603
total_envstep_count: 73160
total_train_sample_count: 73160
total_episode_count: 590
total_duration: 13045.93691299402
[2024-12-27 20:24:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.74282673332954
avg_train_sample_per_sec: 5.74282673332954
avg_episode_per_sec: 0.04631311881717371
collect_time: 107.9607706779167
reward_mean: -461.6714285714285
reward_std: 11.997414687492968
reward_max: -446.85714285714283
reward_min: -482.142857142857
queue_len: 0.2863966678482807
wait_time: 2.1885767458348098
delay_time: 63.49347430852534
pressure: 4.009553349875931
total_envstep_count: 73780
total_train_sample_count: 73780
total_episode_count: 595
total_duration: 13153.897683671938
[2024-12-27 20:26:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.913638717558919
avg_train_sample_per_sec: 5.913638717558919
avg_episode_per_sec: 0.04769063481902354
collect_time: 104.84238716834037
reward_mean: -452.38571428571424
reward_std: 4.104900008725147
reward_max: -445.5714285714286
reward_min: -457.21428571428544
queue_len: 0.28063629918468624
wait_time: 2.1842786246012054
delay_time: 62.69000016688223
pressure: 3.928908188585608
total_envstep_count: 74400
total_train_sample_count: 74400
total_episode_count: 600
total_duration: 13258.740070840278
[2024-12-27 20:28:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.948966993527319
avg_train_sample_per_sec: 5.948966993527319
avg_episode_per_sec: 0.0479755402703816
collect_time: 104.21977473981305
reward_mean: -446.04285714285714
reward_std: 16.528367698460404
reward_max: -419.1428571428572
reward_min: -471.1428571428571
queue_len: 0.27670152428216943
wait_time: 2.1560085076214106
delay_time: 62.12898065537795
pressure: 3.8738213399503723
total_envstep_count: 75020
total_train_sample_count: 75020
total_episode_count: 605
total_duration: 13362.959845580091
[2024-12-27 20:29:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.1183968030028995
avg_train_sample_per_sec: 6.1183968030028995
avg_episode_per_sec: 0.04934190970163629
collect_time: 101.33373495744914
reward_mean: -450.47142857142865
reward_std: 13.444413148142928
reward_max: -435.14285714285717
reward_min: -474.49999999999994
queue_len: 0.2794487770294222
wait_time: 2.1456664303438493
delay_time: 62.491315554326114
pressure: 3.9122828784119106
total_envstep_count: 75640
total_train_sample_count: 75640
total_episode_count: 610
total_duration: 13464.29358053754
[2024-12-27 20:31:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.887428498722848
avg_train_sample_per_sec: 5.887428498722848
avg_episode_per_sec: 0.04747926208647458
collect_time: 105.30913456265257
reward_mean: -454.47142857142853
reward_std: 15.932933419397093
reward_max: -440.2857142857143
reward_min: -483.857142857143
queue_len: 0.2819301666075859
wait_time: 2.154165189649061
delay_time: 62.77769050728822
pressure: 3.9470223325062035
total_envstep_count: 76260
total_train_sample_count: 76260
total_episode_count: 615
total_duration: 13569.602715100193
[2024-12-27 20:33:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9485690463342555
avg_train_sample_per_sec: 5.9485690463342555
avg_episode_per_sec: 0.04797233101882464
collect_time: 104.2267468311675
reward_mean: -451.5857142857141
reward_std: 8.932330637199133
reward_max: -436.9285714285713
reward_min: -461.85714285714306
queue_len: 0.2801400212690535
wait_time: 2.1771357674583482
delay_time: 62.806696551356005
pressure: 3.9219602977667494
total_envstep_count: 76880
total_train_sample_count: 76880
total_episode_count: 620
total_duration: 13673.82946193136
[2024-12-27 20:35:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.583307642900753
avg_train_sample_per_sec: 5.583307642900753
avg_episode_per_sec: 0.0450266745395222
collect_time: 111.04528706891836
reward_mean: -449.7714285714286
reward_std: 7.594493171411289
reward_max: -439.50000000000006
reward_min: -460.14285714285734
queue_len: 0.2790145338532436
wait_time: 2.1699751861042182
delay_time: 62.683757714077544
pressure: 3.9062034739454092
total_envstep_count: 77500
total_train_sample_count: 77500
total_episode_count: 625
total_duration: 13784.874749000279
[2024-12-27 20:37:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.713112676786398
avg_train_sample_per_sec: 5.713112676786398
avg_episode_per_sec: 0.046073489328922565
collect_time: 108.52227762270346
reward_mean: -455.27142857142854
reward_std: 3.7967225393511836
reward_max: -451.78571428571416
reward_min: -462.5714285714288
queue_len: 0.2824264445232187
wait_time: 2.182789790854307
delay_time: 62.91225134604066
pressure: 3.9539702233250624
total_envstep_count: 78120
total_train_sample_count: 78120
total_episode_count: 630
total_duration: 13893.397026622983
[2024-12-27 20:38:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.832779239465294
avg_train_sample_per_sec: 5.832779239465294
avg_episode_per_sec: 0.047038542253752376
collect_time: 106.29581106121839
reward_mean: -449.8142857142857
reward_std: 9.169670503505369
reward_max: -439.4285714285712
reward_min: -461.92857142857133
queue_len: 0.27904112017015237
wait_time: 2.1623360510457283
delay_time: 62.31162064098048
pressure: 3.906575682382134
total_envstep_count: 78740
total_train_sample_count: 78740
total_episode_count: 635
total_duration: 13999.6928376842
[2024-12-27 20:40:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.594965725582586
avg_train_sample_per_sec: 5.594965725582586
avg_episode_per_sec: 0.04512069133534344
collect_time: 110.81390492976458
reward_mean: -461.21428571428567
reward_std: 10.37432073016089
reward_max: -450.64285714285705
reward_min: -479.42857142857156
queue_len: 0.28611308046791917
wait_time: 2.18110599078341
delay_time: 63.42291414590377
pressure: 4.005583126550869
total_envstep_count: 79360
total_train_sample_count: 79360
total_episode_count: 640
total_duration: 14110.506742613965
[2024-12-27 20:42:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5782904168655945
avg_train_sample_per_sec: 5.5782904168655945
avg_episode_per_sec: 0.044986213039238665
collect_time: 111.14516342237593
reward_mean: -460.15714285714284
reward_std: 24.526345684856132
reward_max: -427.92857142857144
reward_min: -502.35714285714283
queue_len: 0.285457284650833
wait_time: 2.1565225097483163
delay_time: 63.435559220012635
pressure: 3.9964019851116626
total_envstep_count: 79980
total_train_sample_count: 79980
total_episode_count: 645
total_duration: 14221.65190603634
[2024-12-27 20:44:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.693437633820309
avg_train_sample_per_sec: 5.693437633820309
avg_episode_per_sec: 0.04591481962758314
collect_time: 108.89730245169623
reward_mean: -449.35714285714283
reward_std: 15.596375821821795
reward_max: -431.28571428571433
reward_min: -474.07142857142844
queue_len: 0.2787575327897909
wait_time: 2.1509305210918113
delay_time: 62.43763552820121
pressure: 3.9026054590570722
total_envstep_count: 80600
total_train_sample_count: 80600
total_episode_count: 650
total_duration: 14330.549208488037
[2024-12-27 20:46:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.78801913912527
avg_train_sample_per_sec: 5.78801913912527
avg_episode_per_sec: 0.04667757370262315
collect_time: 107.11782133009656
reward_mean: -444.0571428571428
reward_std: 12.133307168993275
reward_max: -423.3571428571427
reward_min: -458.3571428571427
queue_len: 0.2754696915987238
wait_time: 2.0956841545551224
delay_time: 62.133798563137496
pressure: 3.8565756823821338
total_envstep_count: 81220
total_train_sample_count: 81220
total_episode_count: 655
total_duration: 14437.667029818134
[2024-12-27 20:48:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.84238033373062
avg_train_sample_per_sec: 5.84238033373062
avg_episode_per_sec: 0.047115970433311456
collect_time: 106.12112950272486
reward_mean: -450.4
reward_std: 6.455119784215645
reward_max: -443.5714285714285
reward_min: -462.6428571428572
queue_len: 0.2794044665012406
wait_time: 2.137584190003545
delay_time: 62.94399908150514
pressure: 3.9116625310173694
total_envstep_count: 81840
total_train_sample_count: 81840
total_episode_count: 660
total_duration: 14543.788159320859
[2024-12-27 20:49:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.721470225934352
avg_train_sample_per_sec: 5.721470225934352
avg_episode_per_sec: 0.04614088891882542
collect_time: 108.36375538400186
reward_mean: -460.6285714285714
reward_std: 15.102939300354919
reward_max: -438.3571428571427
reward_min: -480.92857142857133
queue_len: 0.2857497341368309
wait_time: 2.1626373626373634
delay_time: 63.47115138413476
pressure: 4.000496277915633
total_envstep_count: 82460
total_train_sample_count: 82460
total_episode_count: 665
total_duration: 14652.15191470486
[2024-12-27 20:51:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.647299476172694
avg_train_sample_per_sec: 5.647299476172694
avg_episode_per_sec: 0.04554273771107011
collect_time: 109.78698803134634
reward_mean: -541.6142857142859
reward_std: 187.29730595053027
reward_max: -442.0
reward_min: -916.1428571428573
queue_len: 0.3359890109890111
wait_time: 2.2767192484934418
delay_time: 78.09524883150581
pressure: 4.785856079404466
total_envstep_count: 83080
total_train_sample_count: 83080
total_episode_count: 670
total_duration: 14761.938902736207
[2024-12-27 20:53:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.767709285418673
avg_train_sample_per_sec: 5.767709285418673
avg_episode_per_sec: 0.046513784559828006
collect_time: 107.49501566721125
reward_mean: -440.35714285714295
reward_std: 12.094441293589416
reward_max: -427.9285714285714
reward_min: -457.9999999999999
queue_len: 0.2731744062389224
wait_time: 2.097571783055655
delay_time: 62.252600386381445
pressure: 3.824441687344913
total_envstep_count: 83700
total_train_sample_count: 83700
total_episode_count: 675
total_duration: 14869.433918403418
[2024-12-27 20:55:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.86293701924338
avg_train_sample_per_sec: 5.86293701924338
avg_episode_per_sec: 0.04728175015518855
collect_time: 105.7490465896241
reward_mean: -441.65714285714273
reward_std: 9.09287678148484
reward_max: -429.8571428571426
reward_min: -456.49999999999983
queue_len: 0.2739808578518256
wait_time: 2.0890198511166256
delay_time: 62.29586964422849
pressure: 3.8357320099255587
total_envstep_count: 84320
total_train_sample_count: 84320
total_episode_count: 680
total_duration: 14975.182964993042
[2024-12-27 20:57:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.540823450451204
avg_train_sample_per_sec: 5.540823450451204
avg_episode_per_sec: 0.044684060084283904
collect_time: 111.89672537743677
reward_mean: -458.8142857142856
reward_std: 15.013979879989648
reward_max: -443.28571428571405
reward_min: -484.57142857142844
queue_len: 0.2846242467210208
wait_time: 2.170852534562212
delay_time: 63.300566065577904
pressure: 3.984739454094292
total_envstep_count: 84940
total_train_sample_count: 84940
total_episode_count: 685
total_duration: 15087.07969037048
[2024-12-27 20:59:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.701148514650908
avg_train_sample_per_sec: 5.701148514650908
avg_episode_per_sec: 0.045977004150410554
collect_time: 108.75001737048481
reward_mean: -450.02857142857147
reward_std: 6.3034813834118335
reward_max: -439.50000000000006
reward_min: -456.7857142857142
queue_len: 0.2791740517546969
wait_time: 2.162185395249911
delay_time: 62.417122455724595
pressure: 3.9084367245657567
total_envstep_count: 85560
total_train_sample_count: 85560
total_episode_count: 690
total_duration: 15195.829707740964
[2024-12-27 21:00:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.567785659598259
avg_train_sample_per_sec: 5.567785659598259
avg_episode_per_sec: 0.044901497254824674
collect_time: 111.35486132286489
reward_mean: -463.5142857142857
reward_std: 18.920585916629822
reward_max: -441.0714285714285
reward_min: -491.9285714285714
queue_len: 0.2875398794753633
wait_time: 2.159464728819567
delay_time: 63.913047802105254
pressure: 4.025558312655087
total_envstep_count: 86180
total_train_sample_count: 86180
total_episode_count: 695
total_duration: 15307.18456906383
[2024-12-27 21:02:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.338274496498656
avg_train_sample_per_sec: 5.338274496498656
avg_episode_per_sec: 0.04305060077821496
collect_time: 116.1423977741599
reward_mean: -452.54285714285726
reward_std: 4.3693272260341045
reward_max: -445.99999999999994
reward_min: -459.28571428571405
queue_len: 0.2807337823466856
wait_time: 2.1615207373271885
delay_time: 62.70133588659316
pressure: 3.930272952853598
total_envstep_count: 86800
total_train_sample_count: 86800
total_episode_count: 700
total_duration: 15423.326966837989
[2024-12-27 21:04:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.538148819831737
avg_train_sample_per_sec: 5.538148819831737
avg_episode_per_sec: 0.044662490482514014
collect_time: 111.95076553013921
reward_mean: -453.95714285714286
reward_std: 12.066279544284395
reward_max: -433.9285714285714
reward_min: -466.4285714285713
queue_len: 0.2816111308046792
wait_time: 2.1868309110244595
delay_time: 62.536174510602095
pressure: 3.9425558312655093
total_envstep_count: 87420
total_train_sample_count: 87420
total_episode_count: 705
total_duration: 15535.277732368128
[2024-12-27 21:06:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.553028167624154
avg_train_sample_per_sec: 5.553028167624154
avg_episode_per_sec: 0.044782485222775434
collect_time: 111.65079327614235
reward_mean: -457.44285714285724
reward_std: 8.62653713010853
reward_max: -448.7142857142859
reward_min: -471.71428571428555
queue_len: 0.28377348457993623
wait_time: 2.1527383906416167
delay_time: 62.9594497032583
pressure: 3.9728287841191063
total_envstep_count: 88040
total_train_sample_count: 88040
total_episode_count: 710
total_duration: 15646.928525644269
[2024-12-27 21:08:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.626204008620041
avg_train_sample_per_sec: 5.626204008620041
avg_episode_per_sec: 0.04537261297274227
collect_time: 110.1986346478164
reward_mean: -448.85714285714295
reward_std: 8.745144425360197
reward_max: -441.9285714285715
reward_min: -466.07142857142867
queue_len: 0.2784473590925204
wait_time: 2.125531726338178
delay_time: 62.583353481860954
pressure: 3.898263027295285
total_envstep_count: 88660
total_train_sample_count: 88660
total_episode_count: 715
total_duration: 15757.127160292086
[2024-12-27 21:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.630352730785465
avg_train_sample_per_sec: 5.630352730785465
avg_episode_per_sec: 0.0454060704095602
collect_time: 110.11743484737352
reward_mean: -461.4428571428572
reward_std: 9.41236702754544
reward_max: -446.7857142857143
reward_min: -476.42857142857144
queue_len: 0.28625487415809997
wait_time: 2.193371144984048
delay_time: 63.39571956432776
pressure: 4.007444168734492
total_envstep_count: 89280
total_train_sample_count: 89280
total_episode_count: 720
total_duration: 15867.24459513946
[2024-12-27 21:12:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.664693300571257
avg_train_sample_per_sec: 5.664693300571257
avg_episode_per_sec: 0.045683010488477886
collect_time: 109.44987964970247
reward_mean: -455.57142857142856
reward_std: 7.7771250131001075
reward_max: -444.00000000000006
reward_min: -465.5714285714285
queue_len: 0.282612548741581
wait_time: 2.14798830202056
delay_time: 62.83858325952383
pressure: 3.956575682382134
total_envstep_count: 89900
total_train_sample_count: 89900
total_episode_count: 725
total_duration: 15976.694474789163
[2024-12-27 21:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.911815128483339
avg_train_sample_per_sec: 5.911815128483339
avg_episode_per_sec: 0.0476759284555108
collect_time: 104.87472739342229
reward_mean: -461.1000000000001
reward_std: 9.981472632751428
reward_max: -454.64285714285734
reward_min: -480.64285714285705
queue_len: 0.28604218362282885
wait_time: 2.161104218362283
delay_time: 63.48984381693545
pressure: 4.0045905707196034
total_envstep_count: 90520
total_train_sample_count: 90520
total_episode_count: 730
total_duration: 16081.569202182585
[2024-12-27 21:15:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.562794943375161
avg_train_sample_per_sec: 5.562794943375161
avg_episode_per_sec: 0.044861249543348074
collect_time: 111.4547644324675
reward_mean: -454.77142857142854
reward_std: 8.336470157919143
reward_max: -441.92857142857144
reward_min: -463.2857142857144
queue_len: 0.2821162708259482
wait_time: 2.1349610067351996
delay_time: 62.799867913952355
pressure: 3.9496277915632754
total_envstep_count: 91140
total_train_sample_count: 91140
total_episode_count: 735
total_duration: 16193.023966615052
[2024-12-27 21:17:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.745048466592984
avg_train_sample_per_sec: 5.745048466592984
avg_episode_per_sec: 0.04633103602091116
collect_time: 107.91901993608103
reward_mean: -443.35714285714283
reward_std: 7.172936665561923
reward_max: -431.21428571428584
reward_min: -453.71428571428567
queue_len: 0.2750354484225452
wait_time: 2.127047146401985
delay_time: 62.204144376329054
pressure: 3.850496277915633
total_envstep_count: 91760
total_train_sample_count: 91760
total_episode_count: 740
total_duration: 16300.942986551134
[2024-12-27 21:19:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.732930387478487
avg_train_sample_per_sec: 5.732930387478487
avg_episode_per_sec: 0.04623330957643941
collect_time: 108.14713560000061
reward_mean: -457.4857142857143
reward_std: 14.069173133239257
reward_max: -439.07142857142844
reward_min: -478.6428571428571
queue_len: 0.283800070896845
wait_time: 2.150638071605814
delay_time: 63.23670052604321
pressure: 3.9732009925558307
total_envstep_count: 92380
total_train_sample_count: 92380
total_episode_count: 745
total_duration: 16409.090122151134
[2024-12-27 21:21:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.691673479375353
avg_train_sample_per_sec: 5.691673479375353
avg_episode_per_sec: 0.04590059257560769
collect_time: 108.93105555802956
reward_mean: -450.61428571428576
reward_std: 7.208639940787646
reward_max: -440.4285714285716
reward_min: -460.9285714285715
queue_len: 0.2795373980857852
wait_time: 2.1280042538107056
delay_time: 62.87294056741134
pressure: 3.913399503722084
total_envstep_count: 93000
total_train_sample_count: 93000
total_episode_count: 750
total_duration: 16518.021177709164
[2024-12-27 21:23:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.583480595723217
avg_train_sample_per_sec: 5.583480595723217
avg_episode_per_sec: 0.04502806932034853
collect_time: 111.04184735143556
reward_mean: -457.64285714285717
reward_std: 6.507922957786923
reward_max: -449.64285714285717
reward_min: -466.2857142857144
queue_len: 0.2838975540588444
wait_time: 2.1815934065934064
delay_time: 62.71880832206283
pressure: 3.9745657568238215
total_envstep_count: 93620
total_train_sample_count: 93620
total_episode_count: 755
total_duration: 16629.0630250606
[2024-12-27 21:25:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.151158133762986
avg_train_sample_per_sec: 5.151158133762986
avg_episode_per_sec: 0.041541597852927305
collect_time: 120.36128262812274
reward_mean: -768.5285714285715
reward_std: 630.3532304208815
reward_max: -438.5714285714288
reward_min: -2029.0714285714287
queue_len: 0.4767546969159874
wait_time: 2.5951435661113083
delay_time: 131.6984589928341
pressure: 5.78424317617866
total_envstep_count: 94240
total_train_sample_count: 94240
total_episode_count: 760
total_duration: 16749.424307688725
[2024-12-27 21:26:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.611015310682988
avg_train_sample_per_sec: 5.611015310682988
avg_episode_per_sec: 0.0452501234732499
collect_time: 110.49693605710941
reward_mean: -449.19999999999993
reward_std: 12.653256417190866
reward_max: -430.2857142857143
reward_min: -465.2857142857141
queue_len: 0.2786600496277915
wait_time: 2.1123626373626374
delay_time: 62.38261869855599
pressure: 3.901240694789082
total_envstep_count: 94860
total_train_sample_count: 94860
total_episode_count: 765
total_duration: 16859.921243745834
[2024-12-27 21:28:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.663149313215134
avg_train_sample_per_sec: 5.663149313215134
avg_episode_per_sec: 0.045670558977541395
collect_time: 109.4797198006436
reward_mean: -445.5571428571428
reward_std: 15.708531413969741
reward_max: -424.0
reward_min: -473.00000000000006
queue_len: 0.2764002126905353
wait_time: 2.101710386387805
delay_time: 62.3805745986656
pressure: 3.869602977667494
total_envstep_count: 95480
total_train_sample_count: 95480
total_episode_count: 770
total_duration: 16969.40096354648
[2024-12-27 21:30:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.456003208678095
avg_train_sample_per_sec: 5.456003208678095
avg_episode_per_sec: 0.04400002587643625
collect_time: 113.63629680676387
reward_mean: -454.4142857142857
reward_std: 14.344336861632915
reward_max: -432.4285714285715
reward_min: -473.85714285714306
queue_len: 0.28189471818504075
wait_time: 2.1608472172988304
delay_time: 62.84200909006203
pressure: 3.9465260545905707
total_envstep_count: 96100
total_train_sample_count: 96100
total_episode_count: 775
total_duration: 17083.03726035324
[2024-12-27 21:32:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.775738705477082
avg_train_sample_per_sec: 5.775738705477082
avg_episode_per_sec: 0.046578537947395825
collect_time: 107.3455763177201
reward_mean: -451.02857142857135
reward_std: 19.880387217515846
reward_max: -429.50000000000006
reward_min: -483.2857142857144
queue_len: 0.27979439914923787
wait_time: 2.127277561148529
delay_time: 62.66384146074256
pressure: 3.91712158808933
total_envstep_count: 96720
total_train_sample_count: 96720
total_episode_count: 780
total_duration: 17190.38283667096
[2024-12-27 21:34:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.495950304445917
avg_train_sample_per_sec: 5.495950304445917
avg_episode_per_sec: 0.04432217987456385
collect_time: 112.81033591196314
reward_mean: -449.8142857142858
reward_std: 5.397013535469493
reward_max: -441.92857142857144
reward_min: -455.85714285714283
queue_len: 0.2790411201701525
wait_time: 2.1296437433534208
delay_time: 62.68970449340037
pressure: 3.906575682382134
total_envstep_count: 97340
total_train_sample_count: 97340
total_episode_count: 785
total_duration: 17303.193172582924
[2024-12-27 21:36:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.583262582043684
avg_train_sample_per_sec: 5.583262582043684
avg_episode_per_sec: 0.04502631114551358
collect_time: 111.04618328250947
reward_mean: -465.17142857142863
reward_std: 14.588827147890257
reward_max: -442.9285714285716
reward_min: -487.7857142857144
queue_len: 0.28856788372917413
wait_time: 2.22595710740872
delay_time: 63.51339535305463
pressure: 4.039950372208437
total_envstep_count: 97960
total_train_sample_count: 97960
total_episode_count: 790
total_duration: 17414.239355865433
[2024-12-27 21:38:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.489169406089518
avg_train_sample_per_sec: 5.489169406089518
avg_episode_per_sec: 0.044267495210399334
collect_time: 112.94969313794375
reward_mean: -451.7571428571429
reward_std: 9.335318059140063
reward_max: -440.71428571428567
reward_min: -462.3571428571429
queue_len: 0.2802463665366891
wait_time: 2.1200194966323997
delay_time: 62.75259508026873
pressure: 3.9234491315136473
total_envstep_count: 98580
total_train_sample_count: 98580
total_episode_count: 795
total_duration: 17527.189049003377
[2024-12-27 21:40:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.127256005542688
avg_train_sample_per_sec: 5.127256005542688
avg_episode_per_sec: 0.04134883875437652
collect_time: 120.92238018342852
reward_mean: -870.1
reward_std: 832.641511659595
reward_max: -445.3571428571429
reward_min: -2535.3571428571427
queue_len: 0.5397642679900745
wait_time: 2.6374867068415453
delay_time: 158.85358834737218
pressure: 6.550744416873448
total_envstep_count: 99200
total_train_sample_count: 99200
total_episode_count: 800
total_duration: 17648.111429186803
[2024-12-27 21:41:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.057508327894194
avg_train_sample_per_sec: 6.057508327894194
avg_episode_per_sec: 0.04885087361204995
collect_time: 102.35231491881979
reward_mean: -456.94285714285724
reward_std: 9.70034714295716
reward_max: -439.92857142857156
reward_min: -468.4285714285716
queue_len: 0.28346331088266574
wait_time: 2.122775611485289
delay_time: 63.4067750291073
pressure: 3.9681141439205954
total_envstep_count: 99820
total_train_sample_count: 99820
total_episode_count: 805
total_duration: 17750.463744105622
[2024-12-27 21:43:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6505626614487445
avg_train_sample_per_sec: 5.6505626614487445
avg_episode_per_sec: 0.045569053721360844
collect_time: 109.72358633061128
reward_mean: -457.5
reward_std: 10.337074152816006
reward_max: -445.50000000000006
reward_min: -476.2857142857144
queue_len: 0.2838089330024814
wait_time: 2.172970577809288
delay_time: 63.0371923841888
pressure: 3.97332506203474
total_envstep_count: 100440
total_train_sample_count: 100440
total_episode_count: 810
total_duration: 17860.187330436234
[2024-12-27 21:45:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.851957306708417
avg_train_sample_per_sec: 7.851957306708417
avg_episode_per_sec: 0.06332223634442272
collect_time: 78.9612036568634
reward_mean: -502.7142857142858
reward_std: 101.0682735499492
reward_max: -443.0714285714283
reward_min: -704.357142857143
queue_len: 0.3118574973413683
wait_time: 2.227126905352711
delay_time: 70.2408369695635
pressure: 4.493300248138958
total_envstep_count: 101060
total_train_sample_count: 101060
total_episode_count: 815
total_duration: 17939.1485340931
[2024-12-27 21:46:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.614519166877742
avg_train_sample_per_sec: 5.614519166877742
avg_episode_per_sec: 0.04527838037804631
collect_time: 110.42797817088665
reward_mean: -455.74285714285713
reward_std: 11.81667794056438
reward_max: -445.2142857142857
reward_min: -477.57142857142867
queue_len: 0.28271889400921657
wait_time: 2.1555565402339596
delay_time: 63.237889263843364
pressure: 3.957940446650124
total_envstep_count: 101680
total_train_sample_count: 101680
total_episode_count: 820
total_duration: 18049.576512263986
[2024-12-27 21:48:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.736287356437821
avg_train_sample_per_sec: 6.736287356437821
avg_episode_per_sec: 0.05432489803578888
collect_time: 92.03882898603939
reward_mean: -448.58571428571423
reward_std: 4.389551601850188
reward_max: -440.3571428571429
reward_min: -452.4285714285713
queue_len: 0.27827897908543064
wait_time: 2.1146401985111662
delay_time: 62.30700305984435
pressure: 3.89590570719603
total_envstep_count: 102300
total_train_sample_count: 102300
total_episode_count: 825
total_duration: 18141.615341250024
[2024-12-27 21:50:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.99499386113955
avg_train_sample_per_sec: 5.99499386113955
avg_episode_per_sec: 0.04834672468660928
collect_time: 103.4196221649088
reward_mean: -452.21428571428567
reward_std: 17.79021744484008
reward_max: -430.49999999999983
reward_min: -481.8571428571428
queue_len: 0.2805299539170507
wait_time: 2.1425203828429638
delay_time: 62.52932772688323
pressure: 3.927419354838709
total_envstep_count: 102920
total_train_sample_count: 102920
total_episode_count: 830
total_duration: 18245.03496341493
[2024-12-27 21:51:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.849672028511521
avg_train_sample_per_sec: 5.849672028511521
avg_episode_per_sec: 0.047174774423480004
collect_time: 105.98884808893503
reward_mean: -445.1857142857143
reward_std: 7.916219464633698
reward_max: -435.49999999999994
reward_min: -457.8571428571429
queue_len: 0.27616979794399155
wait_time: 2.0872031194611833
delay_time: 62.369651246809745
pressure: 3.8663771712158814
total_envstep_count: 103540
total_train_sample_count: 103540
total_episode_count: 835
total_duration: 18351.023811503866
[2024-12-27 21:53:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.756589005046876
avg_train_sample_per_sec: 5.756589005046876
avg_episode_per_sec: 0.04642410487941029
collect_time: 107.70266896880045
reward_mean: -449.7285714285714
reward_std: 6.168617084460135
reward_max: -439.9285714285714
reward_min: -457.7142857142855
queue_len: 0.2789879475363346
wait_time: 2.1298918823112376
delay_time: 62.41873459572514
pressure: 3.9058312655086853
total_envstep_count: 104160
total_train_sample_count: 104160
total_episode_count: 840
total_duration: 18458.726480472666
[2024-12-27 21:55:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.719521009333719
avg_train_sample_per_sec: 5.719521009333719
avg_episode_per_sec: 0.046125169430110635
collect_time: 108.40068582460287
reward_mean: -450.5714285714286
reward_std: 9.332956746532876
reward_max: -439.42857142857156
reward_min: -466.21428571428584
queue_len: 0.2795108117688763
wait_time: 2.1396667848280755
delay_time: 61.987882963568744
pressure: 3.9131513647642677
total_envstep_count: 104780
total_train_sample_count: 104780
total_episode_count: 845
total_duration: 18567.12716629727
[2024-12-27 21:57:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.541250212242233
avg_train_sample_per_sec: 5.541250212242233
avg_episode_per_sec: 0.04468750171163091
collect_time: 111.88810760254783
reward_mean: -452.24285714285713
reward_std: 8.634955065290862
reward_max: -438.8571428571429
reward_min: -460.57142857142856
queue_len: 0.28054767812832326
wait_time: 2.151355902162354
delay_time: 62.847924129190076
pressure: 3.9276674937965255
total_envstep_count: 105400
total_train_sample_count: 105400
total_episode_count: 850
total_duration: 18679.015273899815
[2024-12-27 21:59:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.805440755723808
avg_train_sample_per_sec: 5.805440755723808
avg_episode_per_sec: 0.046818070610675874
collect_time: 106.79637017890813
reward_mean: -439.9285714285714
reward_std: 8.672734662758465
reward_max: -429.21428571428584
reward_min: -454.57142857142856
queue_len: 0.27290854306983336
wait_time: 2.121995746189295
delay_time: 61.76008584040024
pressure: 3.8207196029776673
total_envstep_count: 106020
total_train_sample_count: 106020
total_episode_count: 855
total_duration: 18785.811644078723
[2024-12-27 22:01:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.798558618098378
avg_train_sample_per_sec: 5.798558618098378
avg_episode_per_sec: 0.04676256950079337
collect_time: 106.92312363021819
reward_mean: -441.2285714285714
reward_std: 6.774411639487571
reward_max: -431.28571428571416
reward_min: -449.7857142857142
queue_len: 0.2737149946827365
wait_time: 2.0980680609712863
delay_time: 61.76737066137431
pressure: 3.8320099255583124
total_envstep_count: 106640
total_train_sample_count: 106640
total_episode_count: 860
total_duration: 18892.734767708942
[2024-12-27 22:02:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.822045056625301
avg_train_sample_per_sec: 5.822045056625301
avg_episode_per_sec: 0.046951976263107265
collect_time: 106.4917900788933
reward_mean: -446.32857142857137
reward_std: 7.220096669599899
reward_max: -439.4285714285712
reward_min: -459.07142857142856
queue_len: 0.2768787663948954
wait_time: 2.1229085430698333
delay_time: 62.52679544947095
pressure: 3.8755583126550865
total_envstep_count: 107260
total_train_sample_count: 107260
total_episode_count: 865
total_duration: 18999.226557787835
[2024-12-27 22:04:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.612788359638029
avg_train_sample_per_sec: 5.612788359638029
avg_episode_per_sec: 0.04526442225514539
collect_time: 110.46203068308532
reward_mean: -446.5428571428571
reward_std: 6.312863446801214
reward_max: -439.21428571428567
reward_min: -455.2857142857142
queue_len: 0.27701169797943986
wait_time: 2.120285359801489
delay_time: 62.25434726411579
pressure: 3.878163771712159
total_envstep_count: 107880
total_train_sample_count: 107880
total_episode_count: 870
total_duration: 19109.68858847092
[2024-12-27 22:06:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.614015949485401
avg_train_sample_per_sec: 5.614015949485401
avg_episode_per_sec: 0.045274322173269356
collect_time: 110.43787648249045
reward_mean: -451.1714285714285
reward_std: 4.930041188717374
reward_max: -445.142857142857
reward_min: -460.0714285714286
queue_len: 0.2798830202056008
wait_time: 2.124025168380007
delay_time: 62.767461632746574
pressure: 3.9183622828784124
total_envstep_count: 108500
total_train_sample_count: 108500
total_episode_count: 875
total_duration: 19220.12646495341
[2024-12-27 22:08:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.639863492525472
avg_train_sample_per_sec: 5.639863492525472
avg_episode_per_sec: 0.04548277010101187
collect_time: 109.9317387418486
reward_mean: -448.4999999999999
reward_std: 6.09499627496499
reward_max: -436.64285714285705
reward_min: -453.0714285714285
queue_len: 0.2782258064516129
wait_time: 2.129014533853243
delay_time: 62.089854274327095
pressure: 3.895161290322581
total_envstep_count: 109120
total_train_sample_count: 109120
total_episode_count: 880
total_duration: 19330.05820369526
[2024-12-27 22:10:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.722827252742176
avg_train_sample_per_sec: 5.722827252742176
avg_episode_per_sec: 0.04615183268340465
collect_time: 108.33805960208181
reward_mean: -447.45714285714286
reward_std: 7.325187188525573
reward_max: -439.00000000000017
reward_min: -460.5714285714287
queue_len: 0.277578872740163
wait_time: 2.1481123714994683
delay_time: 62.19940933419679
pressure: 3.886104218362283
total_envstep_count: 109740
total_train_sample_count: 109740
total_episode_count: 885
total_duration: 19438.39626329734
[2024-12-27 22:12:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.456394979670265
avg_train_sample_per_sec: 5.456394979670265
avg_episode_per_sec: 0.04400318531992149
collect_time: 113.62813768248631
reward_mean: -731.9
reward_std: 558.5097876108736
reward_max: -434.35714285714283
reward_min: -1848.7142857142862
queue_len: 0.4540322580645161
wait_time: 2.4575771003190354
delay_time: 114.39667901077826
pressure: 6.136352357320098
total_envstep_count: 110360
total_train_sample_count: 110360
total_episode_count: 890
total_duration: 19552.024400979826
[2024-12-27 22:13:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.726637336221976
avg_train_sample_per_sec: 5.726637336221976
avg_episode_per_sec: 0.04618255916308045
collect_time: 108.26597942188381
reward_mean: -463.52857142857135
reward_std: 5.568973818196172
reward_max: -459.5714285714284
reward_min: -474.4999999999998
queue_len: 0.2875487415809996
wait_time: 2.235085076214109
delay_time: 63.00417821486614
pressure: 4.025682382133995
total_envstep_count: 110980
total_train_sample_count: 110980
total_episode_count: 895
total_duration: 19660.29038040171
[2024-12-27 22:15:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.69354590863397
avg_train_sample_per_sec: 5.69354590863397
avg_episode_per_sec: 0.045915692811564275
collect_time: 108.89523153924198
reward_mean: -440.6714285714285
reward_std: 11.284683497229816
reward_max: -423.42857142857144
reward_min: -452.21428571428544
queue_len: 0.27336937256292093
wait_time: 2.1105724920241054
delay_time: 61.50276467471125
pressure: 3.827171215880893
total_envstep_count: 111600
total_train_sample_count: 111600
total_episode_count: 900
total_duration: 19769.185611940953
[2024-12-27 22:17:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.722209503395016
avg_train_sample_per_sec: 5.722209503395016
avg_episode_per_sec: 0.04614685083383077
collect_time: 108.34975539293885
reward_mean: -442.6285714285715
reward_std: 8.773033822400313
reward_max: -435.42857142857156
reward_min: -459.21428571428584
queue_len: 0.27458348103509395
wait_time: 2.1051931939028714
delay_time: 61.61552944984801
pressure: 3.8441687344913156
total_envstep_count: 112220
total_train_sample_count: 112220
total_episode_count: 905
total_duration: 19877.53536733389
[2024-12-27 22:19:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2913855740350995
avg_train_sample_per_sec: 5.2913855740350995
avg_episode_per_sec: 0.04267246430673467
collect_time: 117.171578469418
reward_mean: -731.2
reward_std: 556.8673428663425
reward_max: -429.78571428571433
reward_min: -1844.3571428571433
queue_len: 0.4535980148883375
wait_time: 2.459828075150655
delay_time: 113.7087712329942
pressure: 6.180397022332507
total_envstep_count: 112840
total_train_sample_count: 112840
total_episode_count: 910
total_duration: 19994.706945803307
[2024-12-27 22:21:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.654024320892559
avg_train_sample_per_sec: 5.654024320892559
avg_episode_per_sec: 0.045596970329778705
collect_time: 109.65640839375186
reward_mean: -530.7285714285715
reward_std: 160.56675387196304
reward_max: -434.85714285714295
reward_min: -851.2857142857141
queue_len: 0.329236086494151
wait_time: 2.289409783764623
delay_time: 71.601256142961
pressure: 4.544044665012407
total_envstep_count: 113460
total_train_sample_count: 113460
total_episode_count: 915
total_duration: 20104.36335419706
[2024-12-27 22:23:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.609077407902941
avg_train_sample_per_sec: 5.609077407902941
avg_episode_per_sec: 0.04523449522502372
collect_time: 110.53511208928005
reward_mean: -437.71428571428567
reward_std: 6.028503723384139
reward_max: -426.4285714285715
reward_min: -443.14285714285705
queue_len: 0.271534916696207
wait_time: 2.089932647997164
delay_time: 61.68602861283468
pressure: 3.801488833746898
total_envstep_count: 114080
total_train_sample_count: 114080
total_episode_count: 920
total_duration: 20214.89846628634
[2024-12-27 22:25:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.678502697557486
avg_train_sample_per_sec: 5.678502697557486
avg_episode_per_sec: 0.04579437659320553
collect_time: 109.18371145032347
reward_mean: -441.0
reward_std: 11.436782764396606
reward_max: -424.5000000000001
reward_min: -455.2142857142858
queue_len: 0.2735732009925559
wait_time: 2.118938319744772
delay_time: 61.761620906673656
pressure: 3.8300248138957813
total_envstep_count: 114700
total_train_sample_count: 114700
total_episode_count: 925
total_duration: 20324.082177736665
[2024-12-27 22:26:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.768858492257694
avg_train_sample_per_sec: 5.768858492257694
avg_episode_per_sec: 0.04652305235691689
collect_time: 107.47360172417014
reward_mean: -446.0571428571428
reward_std: 8.037336344225267
reward_max: -438.4285714285715
reward_min: -460.21428571428584
queue_len: 0.2767103863878057
wait_time: 2.1159340659340655
delay_time: 62.497695421932846
pressure: 3.8739454094292802
total_envstep_count: 115320
total_train_sample_count: 115320
total_episode_count: 930
total_duration: 20431.555779460836
[2024-12-27 22:28:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.78397785856415
avg_train_sample_per_sec: 5.78397785856415
avg_episode_per_sec: 0.04664498273035604
collect_time: 107.19266483394054
reward_mean: -451.94285714285724
reward_std: 19.16562611786521
reward_max: -429.00000000000006
reward_min: -475.85714285714283
queue_len: 0.280361573909961
wait_time: 2.1052286423254163
delay_time: 62.58207794924108
pressure: 3.9250620347394545
total_envstep_count: 115940
total_train_sample_count: 115940
total_episode_count: 935
total_duration: 20538.748444294775
[2024-12-27 22:30:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.188487422035199
avg_train_sample_per_sec: 6.188487422035199
avg_episode_per_sec: 0.04990715662931612
collect_time: 100.18603217845784
reward_mean: -449.4142857142857
reward_std: 8.794061075753318
reward_max: -435.0000000000001
reward_min: -460.4285714285713
queue_len: 0.278792981212336
wait_time: 2.117502658631691
delay_time: 62.917497766834785
pressure: 3.9031017369727046
total_envstep_count: 116560
total_train_sample_count: 116560
total_episode_count: 940
total_duration: 20638.934476473234
[2024-12-27 22:32:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8087446275218975
avg_train_sample_per_sec: 5.8087446275218975
avg_episode_per_sec: 0.04684471473807982
collect_time: 106.73562701696903
reward_mean: -445.4571428571429
reward_std: 10.22707491047617
reward_max: -435.42857142857144
reward_min: -464.7857142857145
queue_len: 0.2763381779510813
wait_time: 2.1132842963488123
delay_time: 61.94472090322258
pressure: 3.8687344913151365
total_envstep_count: 117180
total_train_sample_count: 117180
total_episode_count: 945
total_duration: 20745.670103490203
[2024-12-27 22:34:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.224495807587638
avg_train_sample_per_sec: 5.224495807587638
avg_episode_per_sec: 0.042133030706351916
collect_time: 118.67173844786359
reward_mean: -689.3285714285713
reward_std: 476.9940691883035
reward_max: -430.71428571428555
reward_min: -1643.071428571428
queue_len: 0.4276231832683445
wait_time: 2.4074973413683094
delay_time: 104.84526130544411
pressure: 5.872580645161291
total_envstep_count: 117800
total_train_sample_count: 117800
total_episode_count: 950
total_duration: 20864.34184193807
[2024-12-27 22:35:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.1003881101364925
avg_train_sample_per_sec: 6.1003881101364925
avg_episode_per_sec: 0.04919667830755236
collect_time: 101.63287790981677
reward_mean: -450.3999999999999
reward_std: 8.320199173440201
reward_max: -441.7857142857141
reward_min: -465.42857142857144
queue_len: 0.2794044665012406
wait_time: 2.146437433534208
delay_time: 62.17119578366648
pressure: 3.9116625310173694
total_envstep_count: 118420
total_train_sample_count: 118420
total_episode_count: 955
total_duration: 20965.974719847887
[2024-12-27 22:37:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.598575840109958
avg_train_sample_per_sec: 5.598575840109958
avg_episode_per_sec: 0.04514980516217708
collect_time: 110.74244909895211
reward_mean: -444.0571428571428
reward_std: 8.213279441469917
reward_max: -434.14285714285717
reward_min: -453.9285714285713
queue_len: 0.27546969159872386
wait_time: 2.1245391705069125
delay_time: 61.66286332590164
pressure: 3.8565756823821338
total_envstep_count: 119040
total_train_sample_count: 119040
total_episode_count: 960
total_duration: 21076.717168946838
[2024-12-27 22:39:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.746752597686767
avg_train_sample_per_sec: 5.746752597686767
avg_episode_per_sec: 0.046344779013602955
collect_time: 107.88701783500613
reward_mean: -455.3857142857143
reward_std: 9.5021587235829
reward_max: -436.9285714285715
reward_min: -463.6428571428571
queue_len: 0.28249734136830906
wait_time: 2.1688940092165896
delay_time: 63.03676580873389
pressure: 3.9549627791563275
total_envstep_count: 119660
total_train_sample_count: 119660
total_episode_count: 965
total_duration: 21184.604186781842
[2024-12-27 22:41:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.953671105763969
avg_train_sample_per_sec: 5.953671105763969
avg_episode_per_sec: 0.04801347665938684
collect_time: 104.13742865301295
reward_mean: -451.0571428571428
reward_std: 7.224589530039203
reward_max: -444.92857142857156
reward_min: -464.4285714285717
queue_len: 0.27981212336051053
wait_time: 2.163045019496632
delay_time: 62.327907207674215
pressure: 3.9173697270471464
total_envstep_count: 120280
total_train_sample_count: 120280
total_episode_count: 970
total_duration: 21288.741615434854
[2024-12-27 22:43:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.492312664074191
avg_train_sample_per_sec: 5.492312664074191
avg_episode_per_sec: 0.044292844065114446
collect_time: 112.88505187541247
reward_mean: -450.9142857142859
reward_std: 9.588194271485918
reward_max: -438.1428571428572
reward_min: -463.92857142857144
queue_len: 0.2797235023041475
wait_time: 2.135581354129741
delay_time: 62.517546298820136
pressure: 3.916129032258064
total_envstep_count: 120900
total_train_sample_count: 120900
total_episode_count: 975
total_duration: 21401.626667310265
[2024-12-27 22:44:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.815998453211256
avg_train_sample_per_sec: 5.815998453211256
avg_episode_per_sec: 0.046903213332348835
collect_time: 106.60250427984074
reward_mean: -448.19999999999993
reward_std: 12.236229244438263
reward_max: -429.85714285714295
reward_min: -466.92857142857116
queue_len: 0.2780397022332506
wait_time: 2.1517724211272595
delay_time: 62.08952706782263
pressure: 3.892431761786601
total_envstep_count: 121520
total_train_sample_count: 121520
total_episode_count: 980
total_duration: 21508.229171590105
[2024-12-27 22:46:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.498751307146088
avg_train_sample_per_sec: 5.498751307146088
avg_episode_per_sec: 0.04434476860601684
collect_time: 112.75287158272789
reward_mean: -448.4142857142857
reward_std: 6.266431461789484
reward_max: -437.0714285714287
reward_min: -454.85714285714283
queue_len: 0.27817263381779506
wait_time: 2.169071251329316
delay_time: 61.92059307588769
pressure: 3.8944168734491322
total_envstep_count: 122140
total_train_sample_count: 122140
total_episode_count: 985
total_duration: 21620.982043172833
[2024-12-27 22:48:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.625653120900861
avg_train_sample_per_sec: 5.625653120900861
avg_episode_per_sec: 0.04536817032984565
collect_time: 110.20942576365545
reward_mean: -453.8857142857143
reward_std: 12.498048827308937
reward_max: -441.0714285714285
reward_min: -475.7142857142859
queue_len: 0.2815668202764977
wait_time: 2.17694080113435
delay_time: 62.040155152467136
pressure: 3.941935483870968
total_envstep_count: 122760
total_train_sample_count: 122760
total_episode_count: 990
total_duration: 21731.19146893649
[2024-12-27 22:50:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.586737213088083
avg_train_sample_per_sec: 5.586737213088083
avg_episode_per_sec: 0.04505433236361357
collect_time: 110.9771189071722
reward_mean: -456.042857142857
reward_std: 11.793945177808045
reward_max: -437.49999999999994
reward_min: -473.28571428571405
queue_len: 0.2829049982275788
wait_time: 2.156557958170862
delay_time: 62.506756202169605
pressure: 3.9606699751861045
total_envstep_count: 123380
total_train_sample_count: 123380
total_episode_count: 995
total_duration: 21842.168587843662
[2024-12-27 22:52:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.429126276721081
avg_train_sample_per_sec: 5.429126276721081
avg_episode_per_sec: 0.043783276425170006
collect_time: 114.19885417998582
reward_mean: -446.0857142857143
reward_std: 9.609030616443794
reward_max: -431.71428571428584
reward_min: -459.35714285714283
queue_len: 0.2767281105990783
wait_time: 2.1743264799716413
delay_time: 61.744217549431234
pressure: 3.8741935483870966
total_envstep_count: 124000
total_train_sample_count: 124000
total_episode_count: 1000
total_duration: 21956.36744202365
[2024-12-27 22:54:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.724360473724231
avg_train_sample_per_sec: 5.724360473724231
avg_episode_per_sec: 0.0461641973687438
collect_time: 108.3090421796292
reward_mean: -454.78571428571433
reward_std: 4.769589038044761
reward_max: -450.2142857142857
reward_min: -463.2142857142858
queue_len: 0.2821251329315846
wait_time: 2.1806274370790497
delay_time: 62.138344895348254
pressure: 3.9497518610421833
total_envstep_count: 124620
total_train_sample_count: 124620
total_episode_count: 1005
total_duration: 22064.67648420328
[2024-12-27 22:56:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.827619280497064
avg_train_sample_per_sec: 5.827619280497064
avg_episode_per_sec: 0.046996929681427935
collect_time: 106.38992874412986
reward_mean: -444.1000000000001
reward_std: 12.600421113792068
reward_max: -428.7142857142858
reward_min: -460.9285714285715
queue_len: 0.2754962779156328
wait_time: 2.170400567174761
delay_time: 61.597809988356076
pressure: 3.8569478908188586
total_envstep_count: 125240
total_train_sample_count: 125240
total_episode_count: 1010
total_duration: 22171.06641294741
[2024-12-27 22:57:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.996325644999437
avg_train_sample_per_sec: 5.996325644999437
avg_episode_per_sec: 0.048357464879027715
collect_time: 103.396652667962
reward_mean: -448.2714285714286
reward_std: 7.071702736387915
reward_max: -441.00000000000006
reward_min: -459.7142857142857
queue_len: 0.27808401276143213
wait_time: 2.13254165189649
delay_time: 62.20388386839394
pressure: 3.89317617866005
total_envstep_count: 125860
total_train_sample_count: 125860
total_episode_count: 1015
total_duration: 22274.46306561537
[2024-12-27 22:59:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.468763017081961
avg_train_sample_per_sec: 5.468763017081961
avg_episode_per_sec: 0.044102927557112585
collect_time: 113.37115871786698
reward_mean: -459.4857142857145
reward_std: 14.926445508231563
reward_max: -441.2857142857145
reward_min: -485.6428571428575
queue_len: 0.2850407656859271
wait_time: 2.183011343495214
delay_time: 62.98432097605105
pressure: 3.990570719602977
total_envstep_count: 126480
total_train_sample_count: 126480
total_episode_count: 1020
total_duration: 22387.834224333237
[2024-12-27 23:01:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.205513456226623
avg_train_sample_per_sec: 6.205513456226623
avg_episode_per_sec: 0.05004446335666631
collect_time: 99.9111522960104
reward_mean: -448.5714285714286
reward_std: 8.7008092515956
reward_max: -439.9285714285717
reward_min: -464.14285714285705
queue_len: 0.2782701169797944
wait_time: 2.1680698333924138
delay_time: 62.46402907783236
pressure: 3.895781637717122
total_envstep_count: 127100
total_train_sample_count: 127100
total_episode_count: 1025
total_duration: 22487.74537662925
[2024-12-27 23:03:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.707123584283134
avg_train_sample_per_sec: 5.707123584283134
avg_episode_per_sec: 0.046025190195831726
collect_time: 108.63616160466894
reward_mean: -452.5571428571428
reward_std: 11.113092113652662
reward_max: -438.7857142857144
reward_min: -469.4285714285713
queue_len: 0.28074264445232183
wait_time: 2.1632577100319037
delay_time: 62.08107943872267
pressure: 3.9303970223325058
total_envstep_count: 127720
total_train_sample_count: 127720
total_episode_count: 1030
total_duration: 22596.38153823392
[2024-12-27 23:05:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.542800392589631
avg_train_sample_per_sec: 5.542800392589631
avg_episode_per_sec: 0.04470000316604541
collect_time: 111.85681534354012
reward_mean: -523.8857142857142
reward_std: 145.75254819769856
reward_max: -440.5714285714286
reward_min: -814.9285714285713
queue_len: 0.3249911378943637
wait_time: 2.192192484934421
delay_time: 72.25819718239278
pressure: 4.549875930521091
total_envstep_count: 128340
total_train_sample_count: 128340
total_episode_count: 1035
total_duration: 22708.23835357746
[2024-12-27 23:06:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.777731069586387
avg_train_sample_per_sec: 5.777731069586387
avg_episode_per_sec: 0.046594605399890215
collect_time: 107.3085598018989
reward_mean: -450.6
reward_std: 13.04518051595588
reward_max: -427.5000000000002
reward_min: -463.142857142857
queue_len: 0.2795285359801489
wait_time: 2.136432116270826
delay_time: 62.577495328477525
pressure: 3.913275434243176
total_envstep_count: 128960
total_train_sample_count: 128960
total_episode_count: 1040
total_duration: 22815.54691337936
[2024-12-27 23:08:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.692060834429667
avg_train_sample_per_sec: 5.692060834429667
avg_episode_per_sec: 0.045903716406690866
collect_time: 108.92364260230588
reward_mean: -436.62857142857126
reward_std: 13.408982673064015
reward_max: -424.1428571428571
reward_min: -460.7142857142856
queue_len: 0.2708613966678482
wait_time: 2.074787309464729
delay_time: 61.50717180778781
pressure: 3.792059553349876
total_envstep_count: 129580
total_train_sample_count: 129580
total_episode_count: 1045
total_duration: 22924.470555981665
[2024-12-27 23:10:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.724526916656336
avg_train_sample_per_sec: 5.724526916656336
avg_episode_per_sec: 0.04616553965045432
collect_time: 108.30589305048434
reward_mean: -445.47142857142853
reward_std: 5.651729011225386
reward_max: -435.6428571428571
reward_min: -450.9999999999998
queue_len: 0.27634704005671745
wait_time: 2.1242289968096415
delay_time: 62.435923072122456
pressure: 3.8688585607940444
total_envstep_count: 130200
total_train_sample_count: 130200
total_episode_count: 1050
total_duration: 23032.77644903215
[2024-12-27 23:12:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.91412636597192
avg_train_sample_per_sec: 5.91412636597192
avg_episode_per_sec: 0.04769456746751548
collect_time: 104.83374240484461
reward_mean: -444.9142857142857
reward_std: 11.601583283926262
reward_max: -424.9285714285715
reward_min: -457.357142857143
queue_len: 0.2760014179369018
wait_time: 2.11841545551223
delay_time: 61.77318238517832
pressure: 3.8640198511166255
total_envstep_count: 130820
total_train_sample_count: 130820
total_episode_count: 1055
total_duration: 23137.610191436994
[2024-12-27 23:14:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.458453062039846
avg_train_sample_per_sec: 5.458453062039846
avg_episode_per_sec: 0.044019782758385854
collect_time: 113.585294762671
reward_mean: -437.4857142857144
reward_std: 9.742647672653968
reward_max: -421.857142857143
reward_min: -451.5714285714287
queue_len: 0.2713931230060263
wait_time: 2.088062743707905
delay_time: 61.46054105915325
pressure: 3.799503722084367
total_envstep_count: 131440
total_train_sample_count: 131440
total_episode_count: 1060
total_duration: 23251.195486199664
[2024-12-27 23:16:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.526074418315521
avg_train_sample_per_sec: 5.526074418315521
avg_episode_per_sec: 0.04456511627673807
collect_time: 112.19537651268018
reward_mean: -440.1285714285715
reward_std: 3.505796948612188
reward_max: -435.99999999999994
reward_min: -446.50000000000017
queue_len: 0.27303261254874156
wait_time: 2.06671393123006
delay_time: 61.62352304150143
pressure: 3.822456575682382
total_envstep_count: 132060
total_train_sample_count: 132060
total_episode_count: 1065
total_duration: 23363.390862712346
[2024-12-27 23:17:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8265138584470195
avg_train_sample_per_sec: 5.8265138584470195
avg_episode_per_sec: 0.04698801498747597
collect_time: 106.41011333065855
reward_mean: -445.42857142857156
reward_std: 6.345334136680456
reward_max: -437.8571428571428
reward_min: -455.50000000000006
queue_len: 0.2763204537398086
wait_time: 2.110599078341014
delay_time: 62.46942456271385
pressure: 3.86848635235732
total_envstep_count: 132680
total_train_sample_count: 132680
total_episode_count: 1070
total_duration: 23469.800976043003
[2024-12-27 23:19:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9912372837821595
avg_train_sample_per_sec: 5.9912372837821595
avg_episode_per_sec: 0.04831642970792064
collect_time: 103.48446750361475
reward_mean: -445.47142857142853
reward_std: 6.770222918585933
reward_max: -439.0714285714287
reward_min: -456.57142857142856
queue_len: 0.2763470400567175
wait_time: 2.124344204182914
delay_time: 62.03834657790107
pressure: 3.8688585607940444
total_envstep_count: 133300
total_train_sample_count: 133300
total_episode_count: 1075
total_duration: 23573.285443546618
[2024-12-27 23:21:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.882561995648683
avg_train_sample_per_sec: 5.882561995648683
avg_episode_per_sec: 0.047440016093940995
collect_time: 105.39625429508648
reward_mean: -452.78571428571433
reward_std: 12.53729131309437
reward_max: -432.28571428571405
reward_min: -467.5714285714288
queue_len: 0.2808844381425027
wait_time: 2.1510634526763557
delay_time: 62.76910231230867
pressure: 3.932382133995037
total_envstep_count: 133920
total_train_sample_count: 133920
total_episode_count: 1080
total_duration: 23678.681697841705
[2024-12-27 23:23:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.077958362822785
avg_train_sample_per_sec: 6.077958362822785
avg_episode_per_sec: 0.049015793248570846
collect_time: 102.00793802609294
reward_mean: -446.6857142857143
reward_std: 5.515210877238359
reward_max: -437.0714285714286
reward_min: -453.1428571428572
queue_len: 0.2771003190358029
wait_time: 2.12636476426799
delay_time: 62.21363419647713
pressure: 3.879404466501241
total_envstep_count: 134540
total_train_sample_count: 134540
total_episode_count: 1085
total_duration: 23780.6896358678
[2024-12-27 23:24:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.003625612799006
avg_train_sample_per_sec: 6.003625612799006
avg_episode_per_sec: 0.04841633558708876
collect_time: 103.27092993244528
reward_mean: -438.9857142857143
reward_std: 7.425328962684555
reward_max: -430.1428571428573
reward_min: -452.357142857143
queue_len: 0.2723236440978376
wait_time: 2.1116979794399158
delay_time: 61.460280161569834
pressure: 3.8125310173697273
total_envstep_count: 135160
total_train_sample_count: 135160
total_episode_count: 1090
total_duration: 23883.960565800244
[2024-12-27 23:26:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.901742857451594
avg_train_sample_per_sec: 5.901742857451594
avg_episode_per_sec: 0.0475947004633193
collect_time: 105.0537129412852
reward_mean: -451.1
reward_std: 7.126638730273657
reward_max: -442.21428571428567
reward_min: -459.8571428571427
queue_len: 0.2798387096774194
wait_time: 2.137220843672456
delay_time: 62.270354990286975
pressure: 3.917741935483871
total_envstep_count: 135780
total_train_sample_count: 135780
total_episode_count: 1095
total_duration: 23989.014278741528
[2024-12-27 23:27:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.612483254209963
avg_train_sample_per_sec: 7.612483254209963
avg_episode_per_sec: 0.06139099398556422
collect_time: 81.44517095090079
reward_mean: -443.35714285714283
reward_std: 9.54334900357739
reward_max: -425.7142857142857
reward_min: -454.64285714285717
queue_len: 0.2750354484225452
wait_time: 2.0949840482098545
delay_time: 61.762898150266366
pressure: 3.850496277915633
total_envstep_count: 136400
total_train_sample_count: 136400
total_episode_count: 1100
total_duration: 24070.45944969243
[2024-12-27 23:29:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 7.055012192401341
avg_train_sample_per_sec: 7.055012192401341
avg_episode_per_sec: 0.056895259616139844
collect_time: 87.88078363178113
reward_mean: -437.3142857142857
reward_std: 7.719257657023221
reward_max: -428.35714285714283
reward_min: -449.35714285714295
queue_len: 0.2712867777383906
wait_time: 2.095506912442396
delay_time: 61.338933604231855
pressure: 3.7980148883374687
total_envstep_count: 137020
total_train_sample_count: 137020
total_episode_count: 1105
total_duration: 24158.340233324212
[2024-12-27 23:31:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.539004092094511
avg_train_sample_per_sec: 6.539004092094511
avg_episode_per_sec: 0.05273390396850412
collect_time: 94.81566172279418
reward_mean: -447.25714285714287
reward_std: 8.500492182629078
reward_max: -439.57142857142856
reward_min: -463.14285714285705
queue_len: 0.2774548032612548
wait_time: 2.0890109890109896
delay_time: 62.67874047855855
pressure: 3.884367245657568
total_envstep_count: 137640
total_train_sample_count: 137640
total_episode_count: 1110
total_duration: 24253.155895047006
[2024-12-27 23:32:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.692105331445573
avg_train_sample_per_sec: 5.692105331445573
avg_episode_per_sec: 0.045904075253593336
collect_time: 108.92279111120105
reward_mean: -448.3142857142857
reward_std: 12.432314707229393
reward_max: -434.5
reward_min: -471.5
queue_len: 0.27811059907834096
wait_time: 2.1284119106699753
delay_time: 62.26918995062689
pressure: 3.893548387096774
total_envstep_count: 138260
total_train_sample_count: 138260
total_episode_count: 1115
total_duration: 24362.078686158206
[2024-12-27 23:34:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.073069225878838
avg_train_sample_per_sec: 6.073069225878838
avg_episode_per_sec: 0.04897636472482934
collect_time: 102.09005972762964
reward_mean: -444.2428571428571
reward_std: 5.843119099960737
reward_max: -434.7857142857143
reward_min: -451.85714285714266
queue_len: 0.2755848989719957
wait_time: 2.096464019851117
delay_time: 62.37965332387406
pressure: 3.8580645161290326
total_envstep_count: 138880
total_train_sample_count: 138880
total_episode_count: 1120
total_duration: 24464.168745885836
[2024-12-27 23:36:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.568714066229353
avg_train_sample_per_sec: 5.568714066229353
avg_episode_per_sec: 0.044908984405075424
collect_time: 111.33629642791301
reward_mean: -445.3142857142857
reward_std: 11.0577888331054
reward_max: -434.49999999999994
reward_min: -465.2142857142856
queue_len: 0.2762495568947182
wait_time: 2.101940801134349
delay_time: 62.05818737890886
pressure: 3.867493796526054
total_envstep_count: 139500
total_train_sample_count: 139500
total_episode_count: 1125
total_duration: 24575.505042313747
[2024-12-27 23:38:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.868539856884904
avg_train_sample_per_sec: 5.868539856884904
avg_episode_per_sec: 0.04732693432971697
collect_time: 105.648085404519
reward_mean: -443.4
reward_std: 7.575551438135506
reward_max: -433.3571428571427
reward_min: -453.14285714285717
queue_len: 0.2750620347394541
wait_time: 2.1095179014533856
delay_time: 62.15909017164525
pressure: 3.8508684863523577
total_envstep_count: 140120
total_train_sample_count: 140120
total_episode_count: 1130
total_duration: 24681.153127718266
[2024-12-27 23:40:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.370764800925789
avg_train_sample_per_sec: 5.370764800925789
avg_episode_per_sec: 0.04331261936230475
collect_time: 115.43979730654507
reward_mean: -539.0142857142857
reward_std: 202.43901273606087
reward_max: -429.2142857142857
reward_min: -943.5714285714286
queue_len: 0.33437610776320453
wait_time: 2.2563009571074084
delay_time: 78.74212923614162
pressure: 4.6094292803970225
total_envstep_count: 140740
total_train_sample_count: 140740
total_episode_count: 1135
total_duration: 24796.592925024812
[2024-12-27 23:42:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.372052848554868
avg_train_sample_per_sec: 5.372052848554868
avg_episode_per_sec: 0.04332300684318442
collect_time: 115.41211851011215
reward_mean: -439.5142857142857
reward_std: 9.673274776308048
reward_max: -427.35714285714295
reward_min: -453.3571428571426
queue_len: 0.2726515420063807
wait_time: 2.08168202764977
delay_time: 61.952563121379434
pressure: 3.81712158808933
total_envstep_count: 141360
total_train_sample_count: 141360
total_episode_count: 1140
total_duration: 24912.005043534926
[2024-12-27 23:43:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.509248448203873
avg_train_sample_per_sec: 5.509248448203873
avg_episode_per_sec: 0.04442942296938607
collect_time: 112.538035964258
reward_mean: -443.7
reward_std: 5.6574675231510945
reward_max: -436.42857142857156
reward_min: -450.2142857142856
queue_len: 0.2752481389578164
wait_time: 2.1220046082949318
delay_time: 61.8477323321208
pressure: 3.853473945409429
total_envstep_count: 141980
total_train_sample_count: 141980
total_episode_count: 1145
total_duration: 25024.543079499184
[2024-12-27 23:45:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.110269365208764
avg_train_sample_per_sec: 6.110269365208764
avg_episode_per_sec: 0.04927636584845778
collect_time: 101.46852175293863
reward_mean: -434.85714285714295
reward_std: 4.1531890869351304
reward_max: -428.2857142857142
reward_min: -439.1428571428573
queue_len: 0.2697624955689472
wait_time: 2.0836139666784828
delay_time: 61.20307338763106
pressure: 3.776674937965261
total_envstep_count: 142600
total_train_sample_count: 142600
total_episode_count: 1150
total_duration: 25126.011601252125
[2024-12-27 23:47:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.743015656028651
avg_train_sample_per_sec: 5.743015656028651
avg_episode_per_sec: 0.046314642387327826
collect_time: 107.95721919183063
reward_mean: -490.4000000000001
reward_std: 81.31343489164338
reward_max: -447.64285714285717
reward_min: -652.9999999999998
queue_len: 0.3042183622828784
wait_time: 2.2237238567883733
delay_time: 68.0938765955989
pressure: 4.41091811414392
total_envstep_count: 143220
total_train_sample_count: 143220
total_episode_count: 1155
total_duration: 25233.968820443955
[2024-12-27 23:49:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.72667184005627
avg_train_sample_per_sec: 5.72667184005627
avg_episode_per_sec: 0.04618283741980864
collect_time: 108.26532710732519
reward_mean: -443.58571428571423
reward_std: 3.7218055745422456
reward_max: -438.64285714285717
reward_min: -449.28571428571405
queue_len: 0.27517724211272593
wait_time: 2.125514002126905
delay_time: 61.60701133619269
pressure: 3.852481389578164
total_envstep_count: 143840
total_train_sample_count: 143840
total_episode_count: 1160
total_duration: 25342.23414755128
[2024-12-27 23:51:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.888456264419626
avg_train_sample_per_sec: 5.888456264419626
avg_episode_per_sec: 0.04748755051951311
collect_time: 105.29075400394572
reward_mean: -452.4428571428572
reward_std: 12.34895682614044
reward_max: -439.28571428571416
reward_min: -473.7857142857145
queue_len: 0.28067174760723146
wait_time: 2.1633197447713575
delay_time: 62.677355435451126
pressure: 3.9294044665012406
total_envstep_count: 144460
total_train_sample_count: 144460
total_episode_count: 1165
total_duration: 25447.524901555225
[2024-12-27 23:52:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.763226764345023
avg_train_sample_per_sec: 5.763226764345023
avg_episode_per_sec: 0.04647763519633083
collect_time: 107.57862311365454
reward_mean: -443.5142857142857
reward_std: 17.103669495289033
reward_max: -419.2142857142857
reward_min: -464.2142857142856
queue_len: 0.27513293158454444
wait_time: 2.1000088621056365
delay_time: 62.11299980652343
pressure: 3.851736972704715
total_envstep_count: 145080
total_train_sample_count: 145080
total_episode_count: 1170
total_duration: 25555.10352466888
[2024-12-27 23:54:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.247310421851146
avg_train_sample_per_sec: 5.247310421851146
avg_episode_per_sec: 0.042317019531057626
collect_time: 118.15576936675235
reward_mean: -447.6999999999998
reward_std: 9.131846048028697
reward_max: -437.49999999999966
reward_min: -462.0714285714282
queue_len: 0.2777295285359801
wait_time: 2.1122297057780925
delay_time: 62.33064934599753
pressure: 3.888213399503722
total_envstep_count: 145700
total_train_sample_count: 145700
total_episode_count: 1175
total_duration: 25673.259294035634
[2024-12-27 23:56:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.31480853628211
avg_train_sample_per_sec: 5.31480853628211
avg_episode_per_sec: 0.0428613591635654
collect_time: 116.65519007270038
reward_mean: -443.97142857142853
reward_std: 11.969740760666223
reward_max: -431.64285714285677
reward_min: -460.7857142857144
queue_len: 0.27541651896490604
wait_time: 2.073821339950372
delay_time: 62.44953216299738
pressure: 3.855831265508685
total_envstep_count: 146320
total_train_sample_count: 146320
total_episode_count: 1180
total_duration: 25789.914484108333
[2024-12-27 23:58:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.964124511291753
avg_train_sample_per_sec: 4.964124511291753
avg_episode_per_sec: 0.04003326218783672
collect_time: 124.89614202659575
reward_mean: -454.9428571428572
reward_std: 12.39835407114466
reward_max: -438.92857142857156
reward_min: -472.2142857142856
queue_len: 0.28222261609358384
wait_time: 2.122332506203474
delay_time: 62.57447276332955
pressure: 3.9511166253101733
total_envstep_count: 146940
total_train_sample_count: 146940
total_episode_count: 1185
total_duration: 25914.810626134928
[2024-12-28 00:00:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.04130264750561
avg_train_sample_per_sec: 5.04130264750561
avg_episode_per_sec: 0.040655666512142016
collect_time: 122.98408632672951
reward_mean: -445.2571428571429
reward_std: 8.988950132790483
reward_max: -435.14285714285745
reward_min: -457.4285714285714
queue_len: 0.2762141084721731
wait_time: 2.1062566465792276
delay_time: 61.91537525779712
pressure: 3.8669975186104217
total_envstep_count: 147560
total_train_sample_count: 147560
total_episode_count: 1190
total_duration: 26037.79471246166
[2024-12-28 00:03:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.835002602480041
avg_train_sample_per_sec: 4.835002602480041
avg_episode_per_sec: 0.038991956471613236
collect_time: 128.2315752388593
reward_mean: -448.1285714285715
reward_std: 9.04325207894071
reward_max: -433.7142857142858
reward_min: -459.2142857142858
queue_len: 0.27799539170506915
wait_time: 2.0993885147110953
delay_time: 62.72524038121685
pressure: 3.891935483870968
total_envstep_count: 148180
total_train_sample_count: 148180
total_episode_count: 1195
total_duration: 26166.02628770052
[2024-12-28 00:05:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.956409684223536
avg_train_sample_per_sec: 4.956409684223536
avg_episode_per_sec: 0.03997104584051239
collect_time: 125.0905472914167
reward_mean: -448.8571428571428
reward_std: 13.17209480806509
reward_max: -434.9999999999998
reward_min: -472.71428571428584
queue_len: 0.2784473590925204
wait_time: 2.109783764622474
delay_time: 62.253612265104
pressure: 3.898263027295285
total_envstep_count: 148800
total_train_sample_count: 148800
total_episode_count: 1200
total_duration: 26291.116834991935
[2024-12-28 00:07:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.197732849663121
avg_train_sample_per_sec: 5.197732849663121
avg_episode_per_sec: 0.041917200400509044
collect_time: 119.2827753816135
reward_mean: -437.21428571428567
reward_std: 4.062772753795044
reward_max: -429.8571428571429
reward_min: -441.6428571428571
queue_len: 0.2712247429989365
wait_time: 2.0906061680255226
delay_time: 61.64684302113227
pressure: 3.797146401985112
total_envstep_count: 149420
total_train_sample_count: 149420
total_episode_count: 1205
total_duration: 26410.399610373548
[2024-12-28 00:09:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.299826454367217
avg_train_sample_per_sec: 5.299826454367217
avg_episode_per_sec: 0.04274053592231627
collect_time: 116.98496268478777
reward_mean: -471.7999999999999
reward_std: 44.59645359744859
reward_max: -437.8571428571428
reward_min: -560.0714285714284
queue_len: 0.29267990074441685
wait_time: 2.1968096419709324
delay_time: 64.7630530291124
pressure: 4.179404466501241
total_envstep_count: 150040
total_train_sample_count: 150040
total_episode_count: 1210
total_duration: 26527.384573058334
[2024-12-28 00:11:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.2226256781712594
avg_train_sample_per_sec: 5.2226256781712594
avg_episode_per_sec: 0.04211794901751016
collect_time: 118.71423268785702
reward_mean: -444.34285714285704
reward_std: 15.789585821298855
reward_max: -425.28571428571445
reward_min: -470.99999999999994
queue_len: 0.2756469337114498
wait_time: 2.0982896136121942
delay_time: 61.56794978335728
pressure: 3.859057071960298
total_envstep_count: 150660
total_train_sample_count: 150660
total_episode_count: 1215
total_duration: 26646.09880574619
[2024-12-28 00:13:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.041868488222957
avg_train_sample_per_sec: 5.041868488222957
avg_episode_per_sec: 0.040660229743733525
collect_time: 122.9702840223275
reward_mean: -444.6285714285714
reward_std: 12.854793436135658
reward_max: -430.7142857142855
reward_min: -468.5714285714286
queue_len: 0.27582417582417573
wait_time: 2.075983693725629
delay_time: 61.87497923667363
pressure: 3.861538461538461
total_envstep_count: 151280
total_train_sample_count: 151280
total_episode_count: 1220
total_duration: 26769.06908976852
[2024-12-28 00:15:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5870654872103955
avg_train_sample_per_sec: 5.5870654872103955
avg_episode_per_sec: 0.0450569797355677
collect_time: 110.97059832559151
reward_mean: -459.57142857142856
reward_std: 13.2111579309897
reward_max: -445.3571428571429
reward_min: -483.0714285714286
queue_len: 0.2850939383197447
wait_time: 2.1739010989010987
delay_time: 62.99131316297687
pressure: 3.9913151364764268
total_envstep_count: 151900
total_train_sample_count: 151900
total_episode_count: 1225
total_duration: 26880.03968809411
[2024-12-28 00:16:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.812219494749854
avg_train_sample_per_sec: 5.812219494749854
avg_episode_per_sec: 0.04687273786088592
collect_time: 106.67181453832612
reward_mean: -444.14285714285705
reward_std: 4.3638122258935645
reward_max: -437.7142857142856
reward_min: -450.42857142857173
queue_len: 0.2755228642325416
wait_time: 2.099645515774548
delay_time: 61.827669558614375
pressure: 3.8573200992555825
total_envstep_count: 152520
total_train_sample_count: 152520
total_episode_count: 1230
total_duration: 26986.71150263244
[2024-12-28 00:18:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 4.970570014188325
avg_train_sample_per_sec: 4.970570014188325
avg_episode_per_sec: 0.04008524204990584
collect_time: 124.73418505930525
reward_mean: -1021.0571428571429
reward_std: 1147.6805423753333
reward_max: -438.5
reward_min: -3316.3571428571436
queue_len: 0.6334101382488481
wait_time: 2.6901542006380708
delay_time: 196.3428765702707
pressure: 7.3952853598014885
total_envstep_count: 153140
total_train_sample_count: 153140
total_episode_count: 1235
total_duration: 27111.445687691743
[2024-12-28 00:20:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.906351356284794
avg_train_sample_per_sec: 5.906351356284794
avg_episode_per_sec: 0.04763186577649027
collect_time: 104.97174356894197
reward_mean: -441.30000000000007
reward_std: 7.016801992651635
reward_max: -432.1428571428574
reward_min: -453.642857142857
queue_len: 0.2737593052109182
wait_time: 2.104829847571783
delay_time: 61.537237709502904
pressure: 3.8326302729528536
total_envstep_count: 153760
total_train_sample_count: 153760
total_episode_count: 1240
total_duration: 27216.417431260685
[2024-12-28 00:22:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.365703828163917
avg_train_sample_per_sec: 5.365703828163917
avg_episode_per_sec: 0.04327180506583804
collect_time: 115.54868100354264
reward_mean: -742.9571428571429
reward_std: 595.7610988800592
reward_max: -429.2142857142857
reward_min: -1934.214285714286
queue_len: 0.4608915278270117
wait_time: 2.5138071605813535
delay_time: 126.79789094274979
pressure: 5.658436724565758
total_envstep_count: 154380
total_train_sample_count: 154380
total_episode_count: 1245
total_duration: 27331.96611226423
[2024-12-28 00:24:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.755624679850685
avg_train_sample_per_sec: 5.755624679850685
avg_episode_per_sec: 0.04641632806331198
collect_time: 107.7207139948681
reward_mean: -448.57142857142856
reward_std: 13.940178314088078
reward_max: -428.7142857142857
reward_min: -469.71428571428584
queue_len: 0.2782701169797944
wait_time: 2.1252215526409075
delay_time: 62.0428460425581
pressure: 3.8957816377171213
total_envstep_count: 155000
total_train_sample_count: 155000
total_episode_count: 1250
total_duration: 27439.686826259098
[2024-12-28 00:26:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.863959645290514
avg_train_sample_per_sec: 5.863959645290514
avg_episode_per_sec: 0.04728999713943963
collect_time: 105.7306048308052
reward_mean: -450.67142857142863
reward_std: 7.416693801066324
reward_max: -437.21428571428567
reward_min: -457.42857142857144
queue_len: 0.27957284650833036
wait_time: 2.1261963842609
delay_time: 62.26415824316357
pressure: 3.9140198511166253
total_envstep_count: 155620
total_train_sample_count: 155620
total_episode_count: 1255
total_duration: 27545.417431089903
[2024-12-28 00:28:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.797508962073251
avg_train_sample_per_sec: 5.797508962073251
avg_episode_per_sec: 0.0467541045328488
collect_time: 106.94248237578944
reward_mean: -442.3
reward_std: 6.112449657569887
reward_max: -431.57142857142856
reward_min: -448.5714285714285
queue_len: 0.27437965260545905
wait_time: 2.1112105636299185
delay_time: 61.828915363369504
pressure: 3.841315136476427
total_envstep_count: 156240
total_train_sample_count: 156240
total_episode_count: 1260
total_duration: 27652.359913465694
[2024-12-28 00:29:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.773136080055554
avg_train_sample_per_sec: 5.773136080055554
avg_episode_per_sec: 0.04655754903270608
collect_time: 107.39396948253363
reward_mean: -439.4285714285714
reward_std: 2.690497260768714
reward_max: -436.07142857142856
reward_min: -443.7857142857143
queue_len: 0.2725983693725629
wait_time: 2.1089330024813897
delay_time: 61.46245438316362
pressure: 3.816377171215881
total_envstep_count: 156860
total_train_sample_count: 156860
total_episode_count: 1265
total_duration: 27759.75388294823
[2024-12-28 00:31:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.164516034221987
avg_train_sample_per_sec: 6.164516034221987
avg_episode_per_sec: 0.04971383898566119
collect_time: 100.57561640818234
reward_mean: -445.17142857142863
reward_std: 10.789129071544615
reward_max: -432.85714285714283
reward_min: -462.5
queue_len: 0.2761609358383552
wait_time: 2.1277472527472527
delay_time: 62.324121987485135
pressure: 3.866253101736972
total_envstep_count: 157480
total_train_sample_count: 157480
total_episode_count: 1270
total_duration: 27860.329499356412
[2024-12-28 00:33:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.463709354424485
avg_train_sample_per_sec: 5.463709354424485
avg_episode_per_sec: 0.04406217221310069
collect_time: 113.47602146844196
reward_mean: -884.0428571428569
reward_std: 866.5504172950845
reward_max: -449.6428571428571
reward_min: -2617.1428571428564
queue_len: 0.5484136830911024
wait_time: 2.6131956752924497
delay_time: 160.9162866697451
pressure: 6.769230769230769
total_envstep_count: 158100
total_train_sample_count: 158100
total_episode_count: 1275
total_duration: 27973.805520824855
[2024-12-28 00:35:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.675820228101664
avg_train_sample_per_sec: 5.675820228101664
avg_episode_per_sec: 0.04577274377501342
collect_time: 109.23531315003706
reward_mean: -448.0857142857143
reward_std: 6.923547515839131
reward_max: -436.6428571428571
reward_min: -455.64285714285717
queue_len: 0.2779688053881602
wait_time: 2.141510102800425
delay_time: 62.11370274181172
pressure: 3.891563275434243
total_envstep_count: 158720
total_train_sample_count: 158720
total_episode_count: 1280
total_duration: 28083.040833974894
[2024-12-28 00:37:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7904642010784615
avg_train_sample_per_sec: 5.7904642010784615
avg_episode_per_sec: 0.04669729194418114
collect_time: 107.07259011885893
reward_mean: -445.8857142857143
reward_std: 3.101217667370164
reward_max: -441.9999999999999
reward_min: -449.85714285714306
queue_len: 0.2766040411201701
wait_time: 2.1280397022332513
delay_time: 62.01122954019449
pressure: 3.8724565756823823
total_envstep_count: 159340
total_train_sample_count: 159340
total_episode_count: 1285
total_duration: 28190.113424093754
[2024-12-28 00:38:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.133071996702455
avg_train_sample_per_sec: 6.133071996702455
avg_episode_per_sec: 0.049460258037923026
collect_time: 101.0912639429886
reward_mean: -442.95714285714274
reward_std: 9.15452380642752
reward_max: -434.00000000000006
reward_min: -457.7142857142856
queue_len: 0.2747873094647288
wait_time: 2.125177242112726
delay_time: 61.733705835131445
pressure: 3.847022332506204
total_envstep_count: 159960
total_train_sample_count: 159960
total_episode_count: 1290
total_duration: 28291.20468803674
[2024-12-28 00:40:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.229482603219117
avg_train_sample_per_sec: 6.229482603219117
avg_episode_per_sec: 0.05023776292918643
collect_time: 99.52672468811645
reward_mean: -444.45714285714286
reward_std: 14.814816080876696
reward_max: -422.0
reward_min: -464.42857142857133
queue_len: 0.27571783055654026
wait_time: 2.1282701169797944
delay_time: 61.480888062012355
pressure: 3.8600496277915632
total_envstep_count: 160580
total_train_sample_count: 160580
total_episode_count: 1295
total_duration: 28390.731412724857
[2024-12-28 00:42:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.812884063484664
avg_train_sample_per_sec: 5.812884063484664
avg_episode_per_sec: 0.046878097286166646
collect_time: 106.65961908559501
reward_mean: -439.54285714285714
reward_std: 8.03533014954857
reward_max: -430.21428571428567
reward_min: -450.99999999999994
queue_len: 0.2726692662176533
wait_time: 2.12959943282524
delay_time: 61.03122612857156
pressure: 3.8172456575682383
total_envstep_count: 161200
total_train_sample_count: 161200
total_episode_count: 1300
total_duration: 28497.391031810454
[2024-12-28 00:43:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.035651421594842
avg_train_sample_per_sec: 6.035651421594842
avg_episode_per_sec: 0.048674608238668086
collect_time: 102.72296338746698
reward_mean: -441.35714285714283
reward_std: 7.2434347473264555
reward_max: -435.49999999999983
reward_min: -455.6428571428572
queue_len: 0.2737947536334633
wait_time: 2.10787841191067
delay_time: 61.79335689499145
pressure: 3.8331265508684864
total_envstep_count: 161820
total_train_sample_count: 161820
total_episode_count: 1305
total_duration: 28600.11399519792
[2024-12-28 00:45:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.804564260517375
avg_train_sample_per_sec: 5.804564260517375
avg_episode_per_sec: 0.04681100210094657
collect_time: 106.81249654125423
reward_mean: -439.9142857142857
reward_std: 6.540517360800939
reward_max: -430.857142857143
reward_min: -448.71428571428567
queue_len: 0.2728996809641971
wait_time: 2.0998670684154557
delay_time: 61.620733835979195
pressure: 3.8205955334987594
total_envstep_count: 162440
total_train_sample_count: 162440
total_episode_count: 1310
total_duration: 28706.926491739174
[2024-12-28 00:47:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.774935069642202
avg_train_sample_per_sec: 5.774935069642202
avg_episode_per_sec: 0.046572057013243566
collect_time: 107.36051445136219
reward_mean: -448.9142857142857
reward_std: 7.229531274500381
reward_max: -437.2142857142857
reward_min: -458.78571428571416
queue_len: 0.2784828075150656
wait_time: 2.1273750443105284
delay_time: 62.28164334353876
pressure: 3.8987593052109184
total_envstep_count: 163060
total_train_sample_count: 163060
total_episode_count: 1315
total_duration: 28814.287006190538
[2024-12-28 00:49:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.986670859986419
avg_train_sample_per_sec: 5.986670859986419
avg_episode_per_sec: 0.048279603709567895
collect_time: 103.56340184725079
reward_mean: -443.1
reward_std: 10.83546708447667
reward_max: -424.142857142857
reward_min: -453.6428571428573
queue_len: 0.2748759305210918
wait_time: 2.096774193548387
delay_time: 61.95054492491884
pressure: 3.8482630272952862
total_envstep_count: 163680
total_train_sample_count: 163680
total_episode_count: 1320
total_duration: 28917.85040803779
[2024-12-28 00:51:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.072194338150302
avg_train_sample_per_sec: 6.072194338150302
avg_episode_per_sec: 0.04896930917863147
collect_time: 102.10476896377841
reward_mean: -440.80000000000007
reward_std: 7.961309501557567
reward_max: -431.6428571428575
reward_min: -452.5714285714286
queue_len: 0.2734491315136477
wait_time: 2.11285891527827
delay_time: 61.33692748051833
pressure: 3.8282878411910675
total_envstep_count: 164300
total_train_sample_count: 164300
total_episode_count: 1325
total_duration: 29019.955177001568
[2024-12-28 00:52:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.735276530748202
avg_train_sample_per_sec: 5.735276530748202
avg_episode_per_sec: 0.046252230086679044
collect_time: 108.10289559292048
reward_mean: -463.24285714285713
reward_std: 14.955484967470811
reward_max: -442.42857142857133
reward_min: -481.50000000000006
queue_len: 0.2873714994682737
wait_time: 2.1624778447359096
delay_time: 63.56823572055761
pressure: 4.023200992555831
total_envstep_count: 164920
total_train_sample_count: 164920
total_episode_count: 1330
total_duration: 29128.05807259449
[2024-12-28 00:54:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6716705518476065
avg_train_sample_per_sec: 5.6716705518476065
avg_episode_per_sec: 0.04573927864393231
collect_time: 109.31523513791338
reward_mean: -449.95714285714286
reward_std: 9.653232513473514
reward_max: -440.7857142857143
reward_min: -467.57142857142844
queue_len: 0.2791297412265154
wait_time: 2.120116979794399
delay_time: 62.511506075405805
pressure: 3.9078163771712155
total_envstep_count: 165540
total_train_sample_count: 165540
total_episode_count: 1335
total_duration: 29237.373307732403
[2024-12-28 00:56:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.962038185657821
avg_train_sample_per_sec: 5.962038185657821
avg_episode_per_sec: 0.04808095311014372
collect_time: 103.99128296284005
reward_mean: -450.74285714285725
reward_std: 13.957998219147115
reward_max: -423.85714285714295
reward_min: -461.7857142857142
queue_len: 0.2796171570365119
wait_time: 2.090526409074796
delay_time: 62.61452045264441
pressure: 3.914640198511166
total_envstep_count: 166160
total_train_sample_count: 166160
total_episode_count: 1340
total_duration: 29341.364590695244
[2024-12-28 00:58:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7810037993017005
avg_train_sample_per_sec: 5.7810037993017005
avg_episode_per_sec: 0.04662099838146533
collect_time: 107.24781050565839
reward_mean: -446.22857142857146
reward_std: 13.179096001948347
reward_max: -430.0000000000002
reward_min: -466.92857142857156
queue_len: 0.2768167316554414
wait_time: 2.1266394895427148
delay_time: 62.20139555068918
pressure: 3.8754342431761786
total_envstep_count: 166780
total_train_sample_count: 166780
total_episode_count: 1345
total_duration: 29448.612401200902
[2024-12-28 00:59:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.93560705878158
avg_train_sample_per_sec: 5.93560705878158
avg_episode_per_sec: 0.04786779886114177
collect_time: 104.4543538445197
reward_mean: -447.0571428571428
reward_std: 14.188986818613193
reward_max: -429.28571428571405
reward_min: -472.1428571428573
queue_len: 0.27733073378234663
wait_time: 2.0901187522155262
delay_time: 62.50789020147371
pressure: 3.8826302729528535
total_envstep_count: 167400
total_train_sample_count: 167400
total_episode_count: 1350
total_duration: 29553.066755045424
[2024-12-28 01:01:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.921485540985511
avg_train_sample_per_sec: 5.921485540985511
avg_episode_per_sec: 0.04775391565310896
collect_time: 104.70345586570724
reward_mean: -449.7714285714286
reward_std: 10.263806033129864
reward_max: -435.28571428571445
reward_min: -460.2857142857142
queue_len: 0.2790145338532436
wait_time: 2.1252835873803617
delay_time: 62.161961389358645
pressure: 3.9062034739454092
total_envstep_count: 168020
total_train_sample_count: 168020
total_episode_count: 1355
total_duration: 29657.77021091113
[2024-12-28 01:03:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.190209950535841
avg_train_sample_per_sec: 6.190209950535841
avg_episode_per_sec: 0.049921047988192274
collect_time: 100.15815375475772
reward_mean: -446.3857142857143
reward_std: 8.36228169233971
reward_max: -435.35714285714283
reward_min: -460.4999999999999
queue_len: 0.2769142148174406
wait_time: 2.1152959943282523
delay_time: 62.2150602979318
pressure: 3.8767990074441685
total_envstep_count: 168640
total_train_sample_count: 168640
total_episode_count: 1360
total_duration: 29757.928364665888
[2024-12-28 01:05:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.828443303717602
avg_train_sample_per_sec: 5.828443303717602
avg_episode_per_sec: 0.04700357502998066
collect_time: 106.37488737422228
reward_mean: -436.5142857142857
reward_std: 12.1341481374017
reward_max: -425.28571428571405
reward_min: -459.5
queue_len: 0.2707904998227578
wait_time: 2.0702853598014888
delay_time: 61.545804436476956
pressure: 3.791066997518611
total_envstep_count: 169260
total_train_sample_count: 169260
total_episode_count: 1365
total_duration: 29864.30325204011
[2024-12-28 01:06:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.756681715938487
avg_train_sample_per_sec: 5.756681715938487
avg_episode_per_sec: 0.04642485254789102
collect_time: 107.70093442606182
reward_mean: -440.57142857142856
reward_std: 4.42442201921126
reward_max: -435.4999999999997
reward_min: -447.7857142857141
queue_len: 0.27330733782346683
wait_time: 2.0996721020914566
delay_time: 61.9142798363829
pressure: 3.8263027295285355
total_envstep_count: 169880
total_train_sample_count: 169880
total_episode_count: 1370
total_duration: 29972.004186466173
[2024-12-28 01:08:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.567739523110355
avg_train_sample_per_sec: 5.567739523110355
avg_episode_per_sec: 0.044901125186373826
collect_time: 111.35578405321017
reward_mean: -437.2
reward_std: 4.677213543405047
reward_max: -432.57142857142867
reward_min: -445.9999999999999
queue_len: 0.27121588089330023
wait_time: 2.0774370790499814
delay_time: 61.32469282430353
pressure: 3.7970223325062036
total_envstep_count: 170500
total_train_sample_count: 170500
total_episode_count: 1375
total_duration: 30083.35997051938
[2024-12-28 01:10:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.944532759589695
avg_train_sample_per_sec: 5.944532759589695
avg_episode_per_sec: 0.04793978031927173
collect_time: 104.29751589808613
reward_mean: -437.1999999999998
reward_std: 12.027383721477962
reward_max: -426.642857142857
reward_min: -457.3571428571428
queue_len: 0.2712158808933001
wait_time: 2.079608294930876
delay_time: 61.760723937721366
pressure: 3.797022332506203
total_envstep_count: 171120
total_train_sample_count: 171120
total_episode_count: 1380
total_duration: 30187.657486417465
[2024-12-28 01:12:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.709445936217316
avg_train_sample_per_sec: 5.709445936217316
avg_episode_per_sec: 0.046043918840462224
collect_time: 108.59197318378833
reward_mean: -448.27142857142843
reward_std: 10.843544115260007
reward_max: -436.85714285714295
reward_min: -463.0714285714285
queue_len: 0.278084012761432
wait_time: 2.1239542715349167
delay_time: 62.70257959880295
pressure: 3.89317617866005
total_envstep_count: 171740
total_train_sample_count: 171740
total_episode_count: 1385
total_duration: 30296.249459601255
[2024-12-28 01:14:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.875381993442524
avg_train_sample_per_sec: 5.875381993442524
avg_episode_per_sec: 0.04738211285034294
collect_time: 105.52505363770015
reward_mean: -445.84285714285716
reward_std: 6.453507193924932
reward_max: -438.8571428571429
reward_min: -454.21428571428584
queue_len: 0.27657745480326124
wait_time: 2.12492910315491
delay_time: 62.02286537654133
pressure: 3.8720843672456575
total_envstep_count: 172360
total_train_sample_count: 172360
total_episode_count: 1390
total_duration: 30401.774513238954
[2024-12-28 01:15:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.842044465878411
avg_train_sample_per_sec: 5.842044465878411
avg_episode_per_sec: 0.04711326182160009
collect_time: 106.12723056478426
reward_mean: -445.2
reward_std: 6.589633169313911
reward_max: -436.42857142857133
reward_min: -455.0
queue_len: 0.27617866004962777
wait_time: 2.0685040765685927
delay_time: 62.41953993176882
pressure: 3.866501240694789
total_envstep_count: 172980
total_train_sample_count: 172980
total_episode_count: 1395
total_duration: 30507.901743803737
[2024-12-28 01:17:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.784137379889303
avg_train_sample_per_sec: 5.784137379889303
avg_episode_per_sec: 0.04664626919265567
collect_time: 107.18970855631122
reward_mean: -441.8285714285713
reward_std: 6.080010741129041
reward_max: -433.2142857142856
reward_min: -451.78571428571416
queue_len: 0.2740872031194611
wait_time: 2.1027472527472533
delay_time: 61.932739354272975
pressure: 3.837220843672456
total_envstep_count: 173600
total_train_sample_count: 173600
total_episode_count: 1400
total_duration: 30615.091452360048
[2024-12-28 01:19:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.898626840098366
avg_train_sample_per_sec: 5.898626840098366
avg_episode_per_sec: 0.04756957129111585
collect_time: 105.10920877131818
reward_mean: -441.52857142857135
reward_std: 16.16771789835586
reward_max: -423.42857142857144
reward_min: -467.9285714285714
queue_len: 0.27390109890109887
wait_time: 2.099787309464729
delay_time: 61.65490903915016
pressure: 3.8346153846153848
total_envstep_count: 174220
total_train_sample_count: 174220
total_episode_count: 1405
total_duration: 30720.200661131366
[2024-12-28 01:21:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.76824018990722
avg_train_sample_per_sec: 5.76824018990722
avg_episode_per_sec: 0.04651806604763887
collect_time: 107.48512190682068
reward_mean: -450.3
reward_std: 10.489100270747606
reward_max: -429.85714285714266
reward_min: -459.2857142857142
queue_len: 0.2793424317617866
wait_time: 2.1321783055654024
delay_time: 62.42796931579447
pressure: 3.9107940446650127
total_envstep_count: 174840
total_train_sample_count: 174840
total_episode_count: 1410
total_duration: 30827.68578303819
[2024-12-28 01:23:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.781722609171502
avg_train_sample_per_sec: 5.781722609171502
avg_episode_per_sec: 0.046626795235254044
collect_time: 107.23447697343674
reward_mean: -453.55714285714294
reward_std: 16.246154961110317
reward_max: -432.64285714285705
reward_min: -480.28571428571445
queue_len: 0.28136299184686286
wait_time: 2.1512229705778094
delay_time: 62.55812696631904
pressure: 3.939081885856079
total_envstep_count: 175460
total_train_sample_count: 175460
total_episode_count: 1415
total_duration: 30934.920260011626
[2024-12-28 01:24:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.793384192864453
avg_train_sample_per_sec: 5.793384192864453
avg_episode_per_sec: 0.04672084026503591
collect_time: 107.01862320189923
reward_mean: -446.04285714285726
reward_std: 2.8630652904086777
reward_max: -441.5714285714286
reward_min: -449.2142857142858
queue_len: 0.2767015242821695
wait_time: 2.077472527472528
delay_time: 62.193753504317854
pressure: 3.8738213399503723
total_envstep_count: 176080
total_train_sample_count: 176080
total_episode_count: 1420
total_duration: 31041.938883213526
[2024-12-28 01:26:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.687165968195826
avg_train_sample_per_sec: 5.687165968195826
avg_episode_per_sec: 0.045864241678998593
collect_time: 109.01739169688526
reward_mean: -448.95714285714286
reward_std: 6.255870712166789
reward_max: -437.21428571428584
reward_min: -455.49999999999994
queue_len: 0.2785093938319745
wait_time: 2.117848280751507
delay_time: 62.33253604191579
pressure: 3.8991315136476423
total_envstep_count: 176700
total_train_sample_count: 176700
total_episode_count: 1425
total_duration: 31150.95627491041
[2024-12-28 01:28:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.768503736261396
avg_train_sample_per_sec: 5.768503736261396
avg_episode_per_sec: 0.046520191421462874
collect_time: 107.48021122056618
reward_mean: -445.5428571428571
reward_std: 10.642195569083066
reward_max: -433.0714285714285
reward_min: -462.8571428571428
queue_len: 0.2763913505848989
wait_time: 2.11003190358029
delay_time: 61.89474108075821
pressure: 3.8694789081885856
total_envstep_count: 177320
total_train_sample_count: 177320
total_episode_count: 1430
total_duration: 31258.436486130977
[2024-12-28 01:30:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.6107875282039625
avg_train_sample_per_sec: 5.6107875282039625
avg_episode_per_sec: 0.04524828651777389
collect_time: 110.50142192756756
reward_mean: -442.9428571428572
reward_std: 10.587381784994045
reward_max: -425.00000000000017
reward_min: -457.2857142857143
queue_len: 0.27477844735909257
wait_time: 2.111095356256647
delay_time: 62.149304441543265
pressure: 3.8468982630272954
total_envstep_count: 177940
total_train_sample_count: 177940
total_episode_count: 1435
total_duration: 31368.937908058546
[2024-12-28 01:32:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.878534089716877
avg_train_sample_per_sec: 5.878534089716877
avg_episode_per_sec: 0.047407532981587716
collect_time: 105.46847063191235
reward_mean: -444.4857142857143
reward_std: 7.315959629885959
reward_max: -431.857142857143
reward_min: -453.57142857142844
queue_len: 0.2757355547678128
wait_time: 2.0948333924140377
delay_time: 62.16942035430734
pressure: 3.8602977667493796
total_envstep_count: 178560
total_train_sample_count: 178560
total_episode_count: 1440
total_duration: 31474.40637869046
[2024-12-28 01:33:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.796257374853599
avg_train_sample_per_sec: 5.796257374853599
avg_episode_per_sec: 0.04674401108752902
collect_time: 106.96557449118792
reward_mean: -442.84285714285704
reward_std: 12.68627733628186
reward_max: -421.3571428571429
reward_min: -460.4285714285711
queue_len: 0.27471641261963836
wait_time: 2.1005140021269058
delay_time: 61.987207194473186
pressure: 3.846029776674938
total_envstep_count: 179180
total_train_sample_count: 179180
total_episode_count: 1445
total_duration: 31581.371953181646
[2024-12-28 01:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.836368011005855
avg_train_sample_per_sec: 5.836368011005855
avg_episode_per_sec: 0.04706748395972463
collect_time: 106.23044997005725
reward_mean: -443.2857142857142
reward_std: 6.838367152041648
reward_max: -433.5000000000001
reward_min: -454.2142857142858
queue_len: 0.27499113789436375
wait_time: 2.1122031194611837
delay_time: 61.64481737195344
pressure: 3.8498759305210917
total_envstep_count: 179800
total_train_sample_count: 179800
total_episode_count: 1450
total_duration: 31687.602403151704
[2024-12-28 01:37:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.799076016763721
avg_train_sample_per_sec: 5.799076016763721
avg_episode_per_sec: 0.04676674207067517
collect_time: 106.91358385503665
reward_mean: -489.17142857142863
reward_std: 96.65191700749912
reward_max: -437.2142857142859
reward_min: -682.357142857143
queue_len: 0.30345622119815674
wait_time: 2.2104572846508326
delay_time: 68.74227287758293
pressure: 4.374565756823822
total_envstep_count: 180420
total_train_sample_count: 180420
total_episode_count: 1455
total_duration: 31794.51598700674
[2024-12-28 01:39:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.946530385326844
avg_train_sample_per_sec: 5.946530385326844
avg_episode_per_sec: 0.047955890204248744
collect_time: 104.26247909703103
reward_mean: -443.0857142857143
reward_std: 8.188518592193244
reward_max: -433.57142857142867
reward_min: -456.85714285714306
queue_len: 0.27486706841545555
wait_time: 2.1025700106345275
delay_time: 61.85879504169841
pressure: 3.848138957816377
total_envstep_count: 181040
total_train_sample_count: 181040
total_episode_count: 1460
total_duration: 31898.77846610377
[2024-12-28 01:41:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.740783498162602
avg_train_sample_per_sec: 5.740783498162602
avg_episode_per_sec: 0.04629664111421454
collect_time: 107.99919561475144
reward_mean: -450.32857142857137
reward_std: 7.055552163121729
reward_max: -442.0714285714286
reward_min: -461.64285714285734
queue_len: 0.27936015597305924
wait_time: 2.132311237149947
delay_time: 62.192999215623594
pressure: 3.911042183622829
total_envstep_count: 181660
total_train_sample_count: 181660
total_episode_count: 1465
total_duration: 32006.777661718523
[2024-12-28 01:42:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8394655796028765
avg_train_sample_per_sec: 5.8394655796028765
avg_episode_per_sec: 0.0470924643516361
collect_time: 106.17409958980599
reward_mean: -447.94285714285706
reward_std: 5.740724550729352
reward_max: -437.64285714285717
reward_min: -454.7857142857142
queue_len: 0.27788018433179723
wait_time: 2.089055299539171
delay_time: 62.40127962347638
pressure: 3.8903225806451616
total_envstep_count: 182280
total_train_sample_count: 182280
total_episode_count: 1470
total_duration: 32112.95176130833
[2024-12-28 01:44:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9332891815370825
avg_train_sample_per_sec: 5.9332891815370825
avg_episode_per_sec: 0.04784910630271841
collect_time: 104.49515960376337
reward_mean: -449.55714285714276
reward_std: 10.655495851284101
reward_max: -433.00000000000006
reward_min: -462.142857142857
queue_len: 0.27888160226869896
wait_time: 2.1373006026231836
delay_time: 61.97048042147786
pressure: 3.904342431761787
total_envstep_count: 182900
total_train_sample_count: 182900
total_episode_count: 1475
total_duration: 32217.446920912094
[2024-12-28 01:46:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.846338553545653
avg_train_sample_per_sec: 5.846338553545653
avg_episode_per_sec: 0.04714789156085204
collect_time: 106.04928098527343
reward_mean: -453.92857142857144
reward_std: 15.402292434728698
reward_max: -440.8571428571428
reward_min: -473.07142857142856
queue_len: 0.2815934065934066
wait_time: 2.1441687344913154
delay_time: 62.48263828046951
pressure: 3.942307692307692
total_envstep_count: 183520
total_train_sample_count: 183520
total_episode_count: 1480
total_duration: 32323.496201897367
[2024-12-28 01:48:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.812856489745862
avg_train_sample_per_sec: 5.812856489745862
avg_episode_per_sec: 0.04687787491730534
collect_time: 106.66012503382935
reward_mean: -446.5571428571428
reward_std: 11.808540665681813
reward_max: -429.85714285714295
reward_min: -464.71428571428584
queue_len: 0.2770205600850762
wait_time: 2.1264533853243526
delay_time: 62.306508099432314
pressure: 3.8782878411910673
total_envstep_count: 184140
total_train_sample_count: 184140
total_episode_count: 1485
total_duration: 32430.156326931196
[2024-12-28 01:49:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.122818970069512
avg_train_sample_per_sec: 6.122818970069512
avg_episode_per_sec: 0.04937757233927026
collect_time: 101.2605473117493
reward_mean: -440.2285714285714
reward_std: 5.673317425655338
reward_max: -435.71428571428567
reward_min: -451.21428571428555
queue_len: 0.2730946472881956
wait_time: 2.0903846153846155
delay_time: 61.370478756536976
pressure: 3.823325062034739
total_envstep_count: 184760
total_train_sample_count: 184760
total_episode_count: 1490
total_duration: 32531.416874242947
[2024-12-28 01:51:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.20670957453867
avg_train_sample_per_sec: 6.20670957453867
avg_episode_per_sec: 0.05005410947208605
collect_time: 99.8918980426248
reward_mean: -440.3857142857143
reward_std: 6.559865603401857
reward_max: -432.8571428571426
reward_min: -451.00000000000017
queue_len: 0.27319213045019497
wait_time: 2.0876639489542717
delay_time: 61.44980313716799
pressure: 3.8246898263027296
total_envstep_count: 185380
total_train_sample_count: 185380
total_episode_count: 1495
total_duration: 32631.30877228557
[2024-12-28 01:53:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.83751288357881
avg_train_sample_per_sec: 5.83751288357881
avg_episode_per_sec: 0.047076716803054926
collect_time: 106.2096156985089
reward_mean: -438.1428571428572
reward_std: 2.3608196432075865
reward_max: -435.1428571428571
reward_min: -441.4999999999999
queue_len: 0.27180077986529605
wait_time: 2.085900389932648
delay_time: 61.45813771280852
pressure: 3.805210918114144
total_envstep_count: 186000
total_train_sample_count: 186000
total_episode_count: 1500
total_duration: 32737.51838798408
[2024-12-28 01:55:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.918478177747413
avg_train_sample_per_sec: 5.918478177747413
avg_episode_per_sec: 0.04772966272376945
collect_time: 104.75665895518661
reward_mean: -445.15714285714273
reward_std: 12.491254083214777
reward_max: -425.57142857142856
reward_min: -461.0714285714285
queue_len: 0.2761520737327189
wait_time: 2.1197624955689474
delay_time: 61.77453290379394
pressure: 3.8661290322580646
total_envstep_count: 186620
total_train_sample_count: 186620
total_episode_count: 1505
total_duration: 32842.27504693927
[2024-12-28 01:56:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.819032763035318
avg_train_sample_per_sec: 5.819032763035318
avg_episode_per_sec: 0.04692768357286546
collect_time: 106.54691685849802
reward_mean: -438.80000000000007
reward_std: 12.425976740650384
reward_max: -428.714285714286
reward_min: -462.7142857142859
queue_len: 0.2722084367245658
wait_time: 2.0971641261963847
delay_time: 61.704260216318936
pressure: 3.81091811414392
total_envstep_count: 187240
total_train_sample_count: 187240
total_episode_count: 1510
total_duration: 32948.82196379777
[2024-12-28 01:58:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.157980700260149
avg_train_sample_per_sec: 6.157980700260149
avg_episode_per_sec: 0.04966113467951733
collect_time: 100.68235517103969
reward_mean: -443.17142857142863
reward_std: 12.38123992340088
reward_max: -425.0714285714285
reward_min: -462.92857142857133
queue_len: 0.2749202410492733
wait_time: 2.145870258773485
delay_time: 61.52706667071341
pressure: 3.8488833746898266
total_envstep_count: 187860
total_train_sample_count: 187860
total_episode_count: 1515
total_duration: 33049.50431896881
[2024-12-28 02:00:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7374074107674655
avg_train_sample_per_sec: 5.7374074107674655
avg_episode_per_sec: 0.04626941460296343
collect_time: 108.06274604735897
reward_mean: -435.17142857142863
reward_std: 8.415316453967078
reward_max: -420.5714285714285
reward_min: -445.7142857142857
queue_len: 0.2699574618929458
wait_time: 2.0486529599432823
delay_time: 61.35000760511947
pressure: 3.7794044665012407
total_envstep_count: 188480
total_train_sample_count: 188480
total_episode_count: 1520
total_duration: 33157.56706501617
[2024-12-28 02:02:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7859701813438935
avg_train_sample_per_sec: 5.7859701813438935
avg_episode_per_sec: 0.046661049849547526
collect_time: 107.15575444877148
reward_mean: -439.0142857142858
reward_std: 7.514530142684032
reward_max: -431.1428571428571
reward_min: -450.5000000000001
queue_len: 0.27234136830911027
wait_time: 2.115863169088975
delay_time: 61.23572463728874
pressure: 3.8127791563275437
total_envstep_count: 189100
total_train_sample_count: 189100
total_episode_count: 1525
total_duration: 33264.72281946494
[2024-12-28 02:03:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.109461745563311
avg_train_sample_per_sec: 6.109461745563311
avg_episode_per_sec: 0.0492698527868009
collect_time: 101.4819350412078
reward_mean: -440.5857142857143
reward_std: 7.719892142632472
reward_max: -435.71428571428567
reward_min: -455.9285714285716
queue_len: 0.2733161999291032
wait_time: 2.103438496986884
delay_time: 61.38113447889199
pressure: 3.8264267990074443
total_envstep_count: 189720
total_train_sample_count: 189720
total_episode_count: 1530
total_duration: 33366.20475450615
[2024-12-28 02:05:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.378866507750243
avg_train_sample_per_sec: 5.378866507750243
avg_episode_per_sec: 0.04337795570766325
collect_time: 115.26592063711956
reward_mean: -835.3571428571429
reward_std: 794.2444054006327
reward_max: -420.5714285714285
reward_min: -2423.7142857142862
queue_len: 0.5182116270825949
wait_time: 2.5430166607585964
delay_time: 154.2096820717319
pressure: 6.391563275434242
total_envstep_count: 190340
total_train_sample_count: 190340
total_episode_count: 1535
total_duration: 33481.47067514327
[2024-12-28 02:07:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.68745492806877
avg_train_sample_per_sec: 5.68745492806877
avg_episode_per_sec: 0.0458665720005546
collect_time: 109.01185290105269
reward_mean: -447.2
reward_std: 14.017438119305854
reward_max: -424.9285714285717
reward_min: -463.142857142857
queue_len: 0.27741935483870966
wait_time: 2.1060528181495917
delay_time: 61.99123257007783
pressure: 3.883870967741936
total_envstep_count: 190960
total_train_sample_count: 190960
total_episode_count: 1540
total_duration: 33590.48252804432
[2024-12-28 02:09:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.042358201285399
avg_train_sample_per_sec: 6.042358201285399
avg_episode_per_sec: 0.04872869517165644
collect_time: 102.60894494273884
reward_mean: -447.52857142857135
reward_std: 6.872690706777076
reward_max: -438.7142857142858
reward_min: -455.5714285714286
queue_len: 0.2776231832683445
wait_time: 2.1185483870967747
delay_time: 61.74997583862837
pressure: 3.886724565756824
total_envstep_count: 191580
total_train_sample_count: 191580
total_episode_count: 1545
total_duration: 33693.09147298706
[2024-12-28 02:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.10966761886542
avg_train_sample_per_sec: 6.10966761886542
avg_episode_per_sec: 0.04927151305536629
collect_time: 101.47851547366753
reward_mean: -448.65714285714284
reward_std: 8.690060003080745
reward_max: -440.35714285714295
reward_min: -463.3571428571429
queue_len: 0.27832328961361225
wait_time: 2.1020382842963476
delay_time: 62.7331259662021
pressure: 3.896526054590571
total_envstep_count: 192200
total_train_sample_count: 192200
total_episode_count: 1550
total_duration: 33794.569988460724
[2024-12-28 02:12:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.792547460075512
avg_train_sample_per_sec: 5.792547460075512
avg_episode_per_sec: 0.046714092419963806
collect_time: 107.03408202924204
reward_mean: -451.9142857142859
reward_std: 8.851772565482015
reward_max: -444.14285714285734
reward_min: -468.7857142857144
queue_len: 0.28034384969868853
wait_time: 2.105716058135413
delay_time: 62.82819892025056
pressure: 3.924813895781637
total_envstep_count: 192820
total_train_sample_count: 192820
total_episode_count: 1555
total_duration: 33901.604070489964
[2024-12-28 02:14:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.740416132057582
avg_train_sample_per_sec: 5.740416132057582
avg_episode_per_sec: 0.04629367848433534
collect_time: 108.00610717707124
reward_mean: -441.5285714285716
reward_std: 5.4624133113188895
reward_max: -434.9285714285715
reward_min: -451.2142857142859
queue_len: 0.273901098901099
wait_time: 2.0971818504076567
delay_time: 61.677483098717005
pressure: 3.8346153846153848
total_envstep_count: 193440
total_train_sample_count: 193440
total_episode_count: 1560
total_duration: 34009.61017766703
[2024-12-28 02:16:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.843395911792298
avg_train_sample_per_sec: 5.843395911792298
avg_episode_per_sec: 0.04712416057897014
collect_time: 106.10268572574478
reward_mean: -439.8714285714285
reward_std: 5.565638016491167
reward_max: -435.9999999999999
reward_min: -450.642857142857
queue_len: 0.2728730946472882
wait_time: 2.083312655086849
delay_time: 61.88005782457277
pressure: 3.8198511166253097
total_envstep_count: 194060
total_train_sample_count: 194060
total_episode_count: 1565
total_duration: 34115.71286339278
[2024-12-28 02:18:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.8203158538884905
avg_train_sample_per_sec: 5.8203158538884905
avg_episode_per_sec: 0.046938031079745896
collect_time: 106.52342854997889
reward_mean: -444.7142857142858
reward_std: 17.20032035771902
reward_max: -417.92857142857144
reward_min: -464.4999999999999
queue_len: 0.2758773484579936
wait_time: 2.123076923076923
delay_time: 61.88782154016285
pressure: 3.8622828784119108
total_envstep_count: 194680
total_train_sample_count: 194680
total_episode_count: 1570
total_duration: 34222.236291942754
[2024-12-28 02:20:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7288696287806955
avg_train_sample_per_sec: 5.7288696287806955
avg_episode_per_sec: 0.046200561522424965
collect_time: 108.22379285526833
reward_mean: -450.04285714285714
reward_std: 15.845594250227908
reward_max: -430.3571428571429
reward_min: -470.78571428571416
queue_len: 0.2791829138603332
wait_time: 2.1488302020560086
delay_time: 62.326293168304815
pressure: 3.9084367245657567
total_envstep_count: 195300
total_train_sample_count: 195300
total_episode_count: 1575
total_duration: 34330.460084798025
[2024-12-28 02:21:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.071115178309414
avg_train_sample_per_sec: 6.071115178309414
avg_episode_per_sec: 0.04896060627668883
collect_time: 102.12291840798967
reward_mean: -439.3857142857144
reward_std: 5.462786909291578
reward_max: -429.35714285714283
reward_min: -445.5714285714288
queue_len: 0.2725717830556541
wait_time: 2.0421924849344206
delay_time: 61.782283277328375
pressure: 3.8160049627791564
total_envstep_count: 195920
total_train_sample_count: 195920
total_episode_count: 1580
total_duration: 34432.58300320602
[2024-12-28 02:23:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.112210876545786
avg_train_sample_per_sec: 6.112210876545786
avg_episode_per_sec: 0.04929202319794989
collect_time: 101.43629081567006
reward_mean: -445.21428571428567
reward_std: 5.272764058473133
reward_max: -437.5714285714288
reward_min: -454.07142857142856
queue_len: 0.2761875221552641
wait_time: 2.07605459057072
delay_time: 62.317645589032246
pressure: 3.866625310173697
total_envstep_count: 196540
total_train_sample_count: 196540
total_episode_count: 1585
total_duration: 34534.01929402169
[2024-12-28 02:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.271135043043001
avg_train_sample_per_sec: 6.271135043043001
avg_episode_per_sec: 0.050573669701959686
collect_time: 98.86567515202984
reward_mean: -443.84285714285716
reward_std: 6.882156757343796
reward_max: -432.42857142857144
reward_min: -453.0000000000001
queue_len: 0.27533676001417934
wait_time: 2.1034828075150656
delay_time: 61.83599813284801
pressure: 3.854714640198511
total_envstep_count: 197160
total_train_sample_count: 197160
total_episode_count: 1590
total_duration: 34632.88496917372
[2024-12-28 02:26:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.847278119897809
avg_train_sample_per_sec: 5.847278119897809
avg_episode_per_sec: 0.0471554687088533
collect_time: 106.03224052062629
reward_mean: -445.24285714285725
reward_std: 9.674878051227392
reward_max: -432.2142857142858
reward_min: -456.7857142857143
queue_len: 0.2762052463665367
wait_time: 2.128119461183977
delay_time: 61.793133349468135
pressure: 3.866873449131514
total_envstep_count: 197780
total_train_sample_count: 197780
total_episode_count: 1595
total_duration: 34738.917209694344
[2024-12-28 02:28:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.346931600948765
avg_train_sample_per_sec: 6.346931600948765
avg_episode_per_sec: 0.05118493226571585
collect_time: 97.6849978826493
reward_mean: -444.5714285714286
reward_std: 4.934261725477365
reward_max: -435.7857142857141
reward_min: -450.9285714285715
queue_len: 0.27578872740163063
wait_time: 2.103509393831974
delay_time: 61.97634116035412
pressure: 3.8610421836228284
total_envstep_count: 198400
total_train_sample_count: 198400
total_episode_count: 1600
total_duration: 34836.602207576994
[2024-12-28 02:30:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.3515054833433044
avg_train_sample_per_sec: 6.3515054833433044
avg_episode_per_sec: 0.05122181841405891
collect_time: 97.6146524042115
reward_mean: -443.45714285714286
reward_std: 9.568080437857187
reward_max: -430.9285714285716
reward_min: -460.5
queue_len: 0.2750974831619993
wait_time: 2.1067086139666786
delay_time: 62.288963754975114
pressure: 3.85136476426799
total_envstep_count: 199020
total_train_sample_count: 199020
total_episode_count: 1605
total_duration: 34934.21685998121
[2024-12-28 02:32:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.829815283362407
avg_train_sample_per_sec: 5.829815283362407
avg_episode_per_sec: 0.047014639381954895
collect_time: 106.34985327398032
reward_mean: -440.6857142857142
reward_std: 6.887521991520168
reward_max: -432.14285714285705
reward_min: -450.3571428571427
queue_len: 0.2733782346685572
wait_time: 2.105264090747962
delay_time: 61.67017333771489
pressure: 3.8272952853598015
total_envstep_count: 199640
total_train_sample_count: 199640
total_episode_count: 1610
total_duration: 35040.56671325519
[2024-12-28 02:33:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.198303136258891
avg_train_sample_per_sec: 6.198303136258891
avg_episode_per_sec: 0.04998631561499106
collect_time: 100.02737626256422
reward_mean: -451.4428571428572
reward_std: 5.875476532996787
reward_max: -445.92857142857144
reward_min: -458.8571428571428
queue_len: 0.2800514002126906
wait_time: 2.1273395958879826
delay_time: 62.736624410395265
pressure: 3.9207196029776674
total_envstep_count: 200260
total_train_sample_count: 200260
total_episode_count: 1615
total_duration: 35140.594089517755
[2024-12-28 02:35:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.90245478965845
avg_train_sample_per_sec: 5.90245478965845
avg_episode_per_sec: 0.04760044185208428
collect_time: 105.04104175203292
reward_mean: -446.64285714285705
reward_std: 10.346349055367739
reward_max: -436.64285714285705
reward_min: -464.1428571428569
queue_len: 0.27707373271889396
wait_time: 2.1292360864941515
delay_time: 61.91224893120896
pressure: 3.879032258064516
total_envstep_count: 200880
total_train_sample_count: 200880
total_episode_count: 1620
total_duration: 35245.63513126979
[2024-12-28 02:37:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.676834969356939
avg_train_sample_per_sec: 5.676834969356939
avg_episode_per_sec: 0.04578092717223338
collect_time: 109.21578720302881
reward_mean: -442.05714285714294
reward_std: 6.437517584679848
reward_max: -435.285714285714
reward_min: -454.1428571428572
queue_len: 0.27422899680964197
wait_time: 2.1163062743707908
delay_time: 62.13658730729878
pressure: 3.8392059553349873
total_envstep_count: 201500
total_train_sample_count: 201500
total_episode_count: 1625
total_duration: 35354.85091847282
[2024-12-28 02:39:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.050625720694363
avg_train_sample_per_sec: 6.050625720694363
avg_episode_per_sec: 0.04879536871527712
collect_time: 102.46874102284573
reward_mean: -445.2
reward_std: 4.721725730868977
reward_max: -439.2142857142856
reward_min: -452.4999999999998
queue_len: 0.27617866004962777
wait_time: 2.1067529244948604
delay_time: 62.360828407499255
pressure: 3.8665012406947894
total_envstep_count: 202120
total_train_sample_count: 202120
total_episode_count: 1630
total_duration: 35457.31965949566
[2024-12-28 02:40:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.950200087401309
avg_train_sample_per_sec: 5.950200087401309
avg_episode_per_sec: 0.04798548457581701
collect_time: 104.19817668195068
reward_mean: -441.2000000000001
reward_std: 14.297095466405418
reward_max: -427.857142857143
reward_min: -464.14285714285717
queue_len: 0.2736972704714641
wait_time: 2.1099344204182913
delay_time: 61.71050257477806
pressure: 3.8317617866004965
total_envstep_count: 202740
total_train_sample_count: 202740
total_episode_count: 1635
total_duration: 35561.51783617761
[2024-12-28 02:42:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.793440033501016
avg_train_sample_per_sec: 5.793440033501016
avg_episode_per_sec: 0.04672129059275013
collect_time: 107.0175916924663
reward_mean: -446.35714285714295
reward_std: 11.276759557711967
reward_max: -431.5000000000001
reward_min: -461.71428571428567
queue_len: 0.27689649060616806
wait_time: 2.0894363700815317
delay_time: 62.23434678365167
pressure: 3.8764267990074446
total_envstep_count: 203360
total_train_sample_count: 203360
total_episode_count: 1640
total_duration: 35668.535427870076
[2024-12-28 02:44:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.233320394027737
avg_train_sample_per_sec: 6.233320394027737
avg_episode_per_sec: 0.05026871285506239
collect_time: 99.46544711451602
reward_mean: -448.9
reward_std: 10.131140113531051
reward_max: -436.14285714285717
reward_min: -462.64285714285694
queue_len: 0.27847394540942927
wait_time: 2.1624955689471816
delay_time: 61.90312131814068
pressure: 3.89863523573201
total_envstep_count: 203980
total_train_sample_count: 203980
total_episode_count: 1645
total_duration: 35768.000874984595
[2024-12-28 02:45:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.237089735732543
avg_train_sample_per_sec: 6.237089735732543
avg_episode_per_sec: 0.05029911077203664
collect_time: 99.40533586489778
reward_mean: -446.47142857142853
reward_std: 8.254819247950085
reward_max: -433.49999999999994
reward_min: -455.78571428571445
queue_len: 0.27696738745125843
wait_time: 2.090047855370436
delay_time: 62.2213040296431
pressure: 3.8775434243176177
total_envstep_count: 204600
total_train_sample_count: 204600
total_episode_count: 1650
total_duration: 35867.40621084949
[2024-12-28 02:47:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.970613627461495
avg_train_sample_per_sec: 5.970613627461495
avg_episode_per_sec: 0.04815010989888303
collect_time: 103.84192290526815
reward_mean: -443.5857142857143
reward_std: 5.937669439043172
reward_max: -432.2857142857143
reward_min: -449.35714285714295
queue_len: 0.275177242112726
wait_time: 2.085093938319745
delay_time: 61.99758721829049
pressure: 3.8524813895781636
total_envstep_count: 205220
total_train_sample_count: 205220
total_episode_count: 1655
total_duration: 35971.24813375476
[2024-12-28 02:49:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9601281259409555
avg_train_sample_per_sec: 5.9601281259409555
avg_episode_per_sec: 0.048065549402749645
collect_time: 104.02460935386644
reward_mean: -444.6000000000001
reward_std: 13.069328480789544
reward_max: -429.50000000000017
reward_min: -463.3571428571432
queue_len: 0.2758064516129033
wait_time: 2.1573023750443103
delay_time: 61.610538925457305
pressure: 3.8612903225806456
total_envstep_count: 205840
total_train_sample_count: 205840
total_episode_count: 1660
total_duration: 36075.272743108624
[2024-12-28 02:51:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.962393775594526
avg_train_sample_per_sec: 5.962393775594526
avg_episode_per_sec: 0.0480838207709236
collect_time: 103.98508104879036
reward_mean: -441.8
reward_std: 9.150599400463046
reward_max: -432.8571428571429
reward_min: -459.35714285714283
queue_len: 0.2740694789081886
wait_time: 2.1270382842963493
delay_time: 61.66563239732854
pressure: 3.8369727047146407
total_envstep_count: 206460
total_train_sample_count: 206460
total_episode_count: 1665
total_duration: 36179.257824157416
[2024-12-28 02:52:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.2535427079844705
avg_train_sample_per_sec: 6.2535427079844705
avg_episode_per_sec: 0.05043179603213283
collect_time: 99.14380199377054
reward_mean: -443.85714285714283
reward_std: 6.483888981663043
reward_max: -436.92857142857144
reward_min: -452.35714285714295
queue_len: 0.2753456221198156
wait_time: 2.1272864232541653
delay_time: 61.85319189284004
pressure: 3.854838709677419
total_envstep_count: 207080
total_train_sample_count: 207080
total_episode_count: 1670
total_duration: 36278.401626151186
[2024-12-28 02:54:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.9149401335582255
avg_train_sample_per_sec: 5.9149401335582255
avg_episode_per_sec: 0.047701130109340524
collect_time: 104.81931955362484
reward_mean: -447.3857142857143
reward_std: 9.638104648969618
reward_max: -432.64285714285705
reward_min: -458.35714285714295
queue_len: 0.2775345622119816
wait_time: 2.1467919177596597
delay_time: 62.329762670689966
pressure: 3.8854838709677417
total_envstep_count: 207700
total_train_sample_count: 207700
total_episode_count: 1675
total_duration: 36383.22094570481
[2024-12-28 02:56:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.720663289540913
avg_train_sample_per_sec: 5.720663289540913
avg_episode_per_sec: 0.04613438136726543
collect_time: 108.3790407894738
reward_mean: -440.1857142857142
reward_std: 6.436915220120533
reward_max: -430.4999999999999
reward_min: -449.8571428571425
queue_len: 0.2730680609712867
wait_time: 2.136325771003191
delay_time: 61.2475649149916
pressure: 3.8229528535980144
total_envstep_count: 208320
total_train_sample_count: 208320
total_episode_count: 1680
total_duration: 36491.59998649428
[2024-12-28 02:58:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.818250749377213
avg_train_sample_per_sec: 5.818250749377213
avg_episode_per_sec: 0.04692137701110655
collect_time: 106.56123751049489
reward_mean: -440.0571428571428
reward_std: 11.0922293079619
reward_max: -426.64285714285717
reward_min: -459.21428571428584
queue_len: 0.27298830202056007
wait_time: 2.138231123714994
delay_time: 61.585871564328
pressure: 3.821836228287841
total_envstep_count: 208940
total_train_sample_count: 208940
total_episode_count: 1685
total_duration: 36598.161224004776
[2024-12-28 03:00:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.591415487902898
avg_train_sample_per_sec: 5.591415487902898
avg_episode_per_sec: 0.04509206038631369
collect_time: 110.88426559274271
reward_mean: -442.4571428571429
reward_std: 10.648426155626787
reward_max: -431.5714285714287
reward_min: -458.07142857142856
queue_len: 0.27447713576745836
wait_time: 2.1282169443459766
delay_time: 61.93798062995023
pressure: 3.8426799007444172
total_envstep_count: 209560
total_train_sample_count: 209560
total_episode_count: 1690
total_duration: 36709.04548959752
[2024-12-28 03:02:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.155435494102573
avg_train_sample_per_sec: 5.155435494102573
avg_episode_per_sec: 0.04157609269437559
collect_time: 120.26142131139707
reward_mean: -877.9857142857143
reward_std: 860.5187500477101
reward_max: -437.1428571428574
reward_min: -2598.9285714285716
queue_len: 0.5446561503013118
wait_time: 2.627144629563984
delay_time: 162.90702636794256
pressure: 6.668734491315137
total_envstep_count: 210180
total_train_sample_count: 210180
total_episode_count: 1695
total_duration: 36829.30691090892
[2024-12-28 03:03:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.999923944094144
avg_train_sample_per_sec: 5.999923944094144
avg_episode_per_sec: 0.04838648342011406
collect_time: 103.33464320164917
reward_mean: -445.5142857142856
reward_std: 13.728073426377035
reward_max: -432.78571428571445
reward_min: -471.2857142857143
queue_len: 0.2763736263736264
wait_time: 2.154244948599787
delay_time: 61.76544133643438
pressure: 3.8692307692307693
total_envstep_count: 210800
total_train_sample_count: 210800
total_episode_count: 1700
total_duration: 36932.64155411057
[2024-12-28 03:05:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.066768485034608
avg_train_sample_per_sec: 6.066768485034608
avg_episode_per_sec: 0.04892555229866619
collect_time: 102.19608701558408
reward_mean: -446.69999999999993
reward_std: 5.820863250377123
reward_max: -436.5000000000001
reward_min: -454.3571428571427
queue_len: 0.2771091811414392
wait_time: 2.173068060971287
delay_time: 62.181629095251864
pressure: 3.8795285359801484
total_envstep_count: 211420
total_train_sample_count: 211420
total_episode_count: 1705
total_duration: 37034.83764112615
[2024-12-28 03:07:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.798025111880923
avg_train_sample_per_sec: 5.798025111880923
avg_episode_per_sec: 0.04675826703129777
collect_time: 106.93296217871456
reward_mean: -438.37142857142845
reward_std: 18.533334556844302
reward_max: -411.64285714285694
reward_min: -463.4285714285714
queue_len: 0.27194257355547674
wait_time: 2.1331176887628494
delay_time: 61.54432539398
pressure: 3.807196029776675
total_envstep_count: 212040
total_train_sample_count: 212040
total_episode_count: 1710
total_duration: 37141.77060330486
[2024-12-28 03:09:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.77131634027271
avg_train_sample_per_sec: 5.77131634027271
avg_episode_per_sec: 0.046542873711876695
collect_time: 107.42783161504943
reward_mean: -445.9000000000001
reward_std: 9.20576571768909
reward_max: -437.00000000000017
reward_min: -463.42857142857156
queue_len: 0.27661290322580656
wait_time: 2.1680786954980507
delay_time: 61.484725538679484
pressure: 3.8725806451612903
total_envstep_count: 212660
total_train_sample_count: 212660
total_episode_count: 1715
total_duration: 37249.19843491991
[2024-12-28 03:10:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.365200649875222
avg_train_sample_per_sec: 6.365200649875222
avg_episode_per_sec: 0.05133226330544533
collect_time: 97.40462777275592
reward_mean: -447.50000000000017
reward_std: 7.397186448031474
reward_max: -435.7142857142857
reward_min: -456.71428571428595
queue_len: 0.27760545905707207
wait_time: 2.154528535980149
delay_time: 62.211704459352575
pressure: 3.8864764267990077
total_envstep_count: 213280
total_train_sample_count: 213280
total_episode_count: 1720
total_duration: 37346.603062692666
[2024-12-28 03:12:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.845337324615812
avg_train_sample_per_sec: 5.845337324615812
avg_episode_per_sec: 0.047139817133998486
collect_time: 106.0674458237104
reward_mean: -443.07142857142856
reward_std: 17.87364951370511
reward_max: -410.0000000000002
reward_min: -459.7857142857141
queue_len: 0.2748582063098192
wait_time: 2.132266926621766
delay_time: 61.753436177821655
pressure: 3.848014888337469
total_envstep_count: 213900
total_train_sample_count: 213900
total_episode_count: 1725
total_duration: 37452.67050851638
[2024-12-28 03:14:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.599701998122623
avg_train_sample_per_sec: 5.599701998122623
avg_episode_per_sec: 0.04515888708163406
collect_time: 110.72017764657181
reward_mean: -482.0571428571428
reward_std: 79.15086859915054
reward_max: -430.7857142857142
reward_min: -639.4285714285713
queue_len: 0.2990428925912797
wait_time: 2.2048032612548742
delay_time: 66.97362580592582
pressure: 4.328163771712159
total_envstep_count: 214520
total_train_sample_count: 214520
total_episode_count: 1730
total_duration: 37563.39068616295
[2024-12-28 03:16:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.630390345891045
avg_train_sample_per_sec: 5.630390345891045
avg_episode_per_sec: 0.04540637375718585
collect_time: 110.11669918275996
reward_mean: -761.9428571428571
reward_std: 636.943862903
reward_max: -430.85714285714283
reward_min: -2035.7142857142853
queue_len: 0.47266926621765337
wait_time: 2.5165012406947893
delay_time: 132.3407668784834
pressure: 5.735732009925559
total_envstep_count: 215140
total_train_sample_count: 215140
total_episode_count: 1735
total_duration: 37673.507385345714
[2024-12-28 03:18:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.765604261100143
avg_train_sample_per_sec: 5.765604261100143
avg_episode_per_sec: 0.04649680855725922
collect_time: 107.53426213850081
reward_mean: -779.8571428571429
reward_std: 663.5512744901868
reward_max: -429.1428571428573
reward_min: -2106.6428571428573
queue_len: 0.4837823466855725
wait_time: 2.494877702942219
delay_time: 136.51169993498735
pressure: 6.266377171215881
total_envstep_count: 215760
total_train_sample_count: 215760
total_episode_count: 1740
total_duration: 37781.04164748421
[2024-12-28 03:19:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.551728212061633
avg_train_sample_per_sec: 5.551728212061633
avg_episode_per_sec: 0.04477200171017446
collect_time: 111.67693667946384
reward_mean: -749.2857142857143
reward_std: 605.0303028336176
reward_max: -436.0000000000001
reward_min: -1959.2857142857147
queue_len: 0.46481744062389224
wait_time: 2.5331797235023044
delay_time: 128.22823800047
pressure: 5.631141439205956
total_envstep_count: 216380
total_train_sample_count: 216380
total_episode_count: 1745
total_duration: 37892.718584163675
[2024-12-28 03:21:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.7174328113968595
avg_train_sample_per_sec: 5.7174328113968595
avg_episode_per_sec: 0.04610832912416822
collect_time: 108.44027738535404
reward_mean: -464.9285714285713
reward_std: 46.94025729693048
reward_max: -435.4285714285713
reward_min: -558.5714285714283
queue_len: 0.2884172279333569
wait_time: 2.1806451612903226
delay_time: 64.64600852217671
pressure: 4.1864764267990076
total_envstep_count: 217000
total_train_sample_count: 217000
total_episode_count: 1750
total_duration: 38001.158861549025
[2024-12-28 03:23:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.184209356916953
avg_train_sample_per_sec: 6.184209356916953
avg_episode_per_sec: 0.04987265610416897
collect_time: 100.25533810664714
reward_mean: -438.7428571428571
reward_std: 9.51696658926703
reward_max: -423.14285714285717
reward_min: -451.0714285714287
queue_len: 0.2721729883020205
wait_time: 2.1206664303438494
delay_time: 61.33775372291395
pressure: 3.810421836228288
total_envstep_count: 217620
total_train_sample_count: 217620
total_episode_count: 1755
total_duration: 38101.41419965567
[2024-12-28 03:25:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.184089481825315
avg_train_sample_per_sec: 6.184089481825315
avg_episode_per_sec: 0.04987168936955899
collect_time: 100.2572814999111
reward_mean: -445.04285714285714
reward_std: 9.439128289049883
reward_max: -434.5714285714287
reward_min: -458.42857142857144
queue_len: 0.2760811768876285
wait_time: 2.1082328961361227
delay_time: 61.92099763967483
pressure: 3.865136476426799
total_envstep_count: 218240
total_train_sample_count: 218240
total_episode_count: 1760
total_duration: 38201.67148115558
[2024-12-28 03:26:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.5488995326542
avg_train_sample_per_sec: 5.5488995326542
avg_episode_per_sec: 0.04474918977946936
collect_time: 111.73386657145619
reward_mean: -481.6
reward_std: 74.67505935582469
reward_max: -432.4999999999997
reward_min: -629.2857142857146
queue_len: 0.2987593052109181
wait_time: 2.2241580999645514
delay_time: 66.46771389048038
pressure: 4.353473945409429
total_envstep_count: 218860
total_train_sample_count: 218860
total_episode_count: 1765
total_duration: 38313.405347727035
[2024-12-28 03:28:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.012965659159614
avg_train_sample_per_sec: 6.012965659159614
avg_episode_per_sec: 0.04849165854160979
collect_time: 103.11051736268399
reward_mean: -450.8714285714285
reward_std: 7.119590678442869
reward_max: -438.0000000000001
reward_min: -457.1428571428573
queue_len: 0.27969691598723856
wait_time: 2.1731478199220136
delay_time: 62.25964150286653
pressure: 3.9156327543424316
total_envstep_count: 219480
total_train_sample_count: 219480
total_episode_count: 1770
total_duration: 38416.51586508972
[2024-12-28 03:30:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.642906804595982
avg_train_sample_per_sec: 5.642906804595982
avg_episode_per_sec: 0.04550731294029018
collect_time: 109.87245075446367
reward_mean: -441.14285714285717
reward_std: 7.783813660542044
reward_max: -433.35714285714295
reward_min: -454.1428571428572
queue_len: 0.2736618220489188
wait_time: 2.1376285005317266
delay_time: 61.4746850967702
pressure: 3.8312655086848637
total_envstep_count: 220100
total_train_sample_count: 220100
total_episode_count: 1775
total_duration: 38526.38831584418
[2024-12-28 03:32:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.408423064355571
avg_train_sample_per_sec: 6.408423064355571
avg_episode_per_sec: 0.05168083116415783
collect_time: 96.74767002330347
reward_mean: -440.9
reward_std: 9.789686367993205
reward_max: -431.64285714285717
reward_min: -457.71428571428567
queue_len: 0.27351116625310173
wait_time: 2.1031903580290683
delay_time: 61.66413707547573
pressure: 3.829156327543424
total_envstep_count: 220720
total_train_sample_count: 220720
total_episode_count: 1780
total_duration: 38623.135985867484
[2024-12-28 03:33:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.920968316820286
avg_train_sample_per_sec: 5.920968316820286
avg_episode_per_sec: 0.047749744490486176
collect_time: 104.71260220033675
reward_mean: -435.2142857142858
reward_std: 8.822165961083307
reward_max: -422.9285714285715
reward_min: -449.4285714285713
queue_len: 0.2699840482098547
wait_time: 2.093273661822048
delay_time: 61.04546192854754
pressure: 3.7797766749379647
total_envstep_count: 221340
total_train_sample_count: 221340
total_episode_count: 1785
total_duration: 38727.84858806782
[2024-12-28 03:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.910445774032858
avg_train_sample_per_sec: 5.910445774032858
avg_episode_per_sec: 0.047664885274458536
collect_time: 104.89902516726028
reward_mean: -446.8857142857143
reward_std: 8.893772184707068
reward_max: -437.92857142857144
reward_min: -462.92857142857156
queue_len: 0.2772243885147111
wait_time: 2.168450903934775
delay_time: 61.92624784268918
pressure: 3.8811414392059556
total_envstep_count: 221960
total_train_sample_count: 221960
total_episode_count: 1790
total_duration: 38832.74761323508
[2024-12-28 03:37:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.808069522363908
avg_train_sample_per_sec: 5.808069522363908
avg_episode_per_sec: 0.04683927034164442
collect_time: 106.74803350970521
reward_mean: -439.4857142857142
reward_std: 10.54933985747791
reward_max: -418.92857142857133
reward_min: -448.14285714285717
queue_len: 0.2726338177951081
wait_time: 2.1374601205246373
delay_time: 61.7027560388874
pressure: 3.8168734491315135
total_envstep_count: 222580
total_train_sample_count: 222580
total_episode_count: 1795
total_duration: 38939.495646744785
[2024-12-28 03:39:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.713372044399923
avg_train_sample_per_sec: 5.713372044399923
avg_episode_per_sec: 0.04607558100322519
collect_time: 108.51735108125953
reward_mean: -435.9285714285714
reward_std: 9.280548013375752
reward_max: -422.85714285714266
reward_min: -449.7142857142857
queue_len: 0.27042715349166957
wait_time: 2.125248138957816
delay_time: 61.32540985085118
pressure: 3.7859801488833753
total_envstep_count: 223200
total_train_sample_count: 223200
total_episode_count: 1800
total_duration: 39048.012997826045
[2024-12-28 03:41:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.555738570903632
avg_train_sample_per_sec: 5.555738570903632
avg_episode_per_sec: 0.04480434331373896
collect_time: 111.59632370879504
reward_mean: -447.3571428571428
reward_std: 14.135351543746816
reward_max: -423.2857142857143
reward_min: -463.3571428571428
queue_len: 0.277516838000709
wait_time: 2.172695852534562
delay_time: 61.462120654207794
pressure: 3.885111662531018
total_envstep_count: 223820
total_train_sample_count: 223820
total_episode_count: 1805
total_duration: 39159.60932153484
[2024-12-28 03:42:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.858051098025176
avg_train_sample_per_sec: 5.858051098025176
avg_episode_per_sec: 0.047242347564719164
collect_time: 105.83724682924154
reward_mean: -438.71428571428567
reward_std: 4.424652644039724
reward_max: -430.57142857142856
reward_min: -443.3571428571426
queue_len: 0.2721552640907479
wait_time: 2.1053527118043243
delay_time: 61.65697394155082
pressure: 3.8101736972704714
total_envstep_count: 224440
total_train_sample_count: 224440
total_episode_count: 1810
total_duration: 39265.44656836408
[2024-12-28 03:44:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.265903498904509
avg_train_sample_per_sec: 6.265903498904509
avg_episode_per_sec: 0.05053147982987507
collect_time: 98.94822033381091
reward_mean: -451.9571428571429
reward_std: 10.555451246650263
reward_max: -435.49999999999983
reward_min: -467.21428571428595
queue_len: 0.2803704360155973
wait_time: 2.171180432470755
delay_time: 62.62838407698423
pressure: 3.925186104218362
total_envstep_count: 225060
total_train_sample_count: 225060
total_episode_count: 1815
total_duration: 39364.39478869789
[2024-12-28 03:46:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.963366991411936
avg_train_sample_per_sec: 5.963366991411936
avg_episode_per_sec: 0.048091669285580126
collect_time: 103.9681107825302
reward_mean: -450.5142857142858
reward_std: 14.51103731928333
reward_max: -434.0714285714286
reward_min: -473.28571428571445
queue_len: 0.2794753633463311
wait_time: 2.149415101028005
delay_time: 62.45796412908459
pressure: 3.9126550868486354
total_envstep_count: 225680
total_train_sample_count: 225680
total_episode_count: 1820
total_duration: 39468.362899480424
[2024-12-28 03:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.092078379089166
avg_train_sample_per_sec: 6.092078379089166
avg_episode_per_sec: 0.049129664347493274
collect_time: 101.77150742645188
reward_mean: -444.7000000000001
reward_std: 8.637412688947084
reward_max: -434.0000000000001
reward_min: -458.2857142857144
queue_len: 0.2758684863523574
wait_time: 2.140118752215526
delay_time: 61.85749709845127
pressure: 3.8621588089330023
total_envstep_count: 226300
total_train_sample_count: 226300
total_episode_count: 1825
total_duration: 39570.13440690687
[2024-12-28 03:49:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.081376926800833
avg_train_sample_per_sec: 6.081376926800833
avg_episode_per_sec: 0.04904336231290994
collect_time: 101.95059564021416
reward_mean: -445.9571428571429
reward_std: 6.210031384455199
reward_max: -436.5000000000001
reward_min: -452.7142857142858
queue_len: 0.2766483516483517
wait_time: 2.1738656504785534
delay_time: 61.72552113789626
pressure: 3.8730769230769226
total_envstep_count: 226920
total_train_sample_count: 226920
total_episode_count: 1830
total_duration: 39672.085002547086
[2024-12-28 03:51:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.802701024813751
avg_train_sample_per_sec: 5.802701024813751
avg_episode_per_sec: 0.04679597600656251
collect_time: 106.84679382045194
reward_mean: -443.51428571428585
reward_std: 8.797889357275263
reward_max: -430.357142857143
reward_min: -456.14285714285734
queue_len: 0.27513293158454455
wait_time: 2.1394629563984404
delay_time: 62.20461452093487
pressure: 3.851861042183623
total_envstep_count: 227540
total_train_sample_count: 227540
total_episode_count: 1835
total_duration: 39778.931796367535
[2024-12-28 03:53:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.92444342191622
avg_train_sample_per_sec: 5.92444342191622
avg_episode_per_sec: 0.04777776953158242
collect_time: 104.6511808529459
reward_mean: -442.5857142857143
reward_std: 3.5840918355580134
reward_max: -437.64285714285734
reward_min: -447.92857142857133
queue_len: 0.27455689471818506
wait_time: 2.14966323998582
delay_time: 61.62107304153672
pressure: 3.8437965260545908
total_envstep_count: 228160
total_train_sample_count: 228160
total_episode_count: 1840
total_duration: 39883.58297722048
[2024-12-28 03:55:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.941300628178732
avg_train_sample_per_sec: 5.941300628178732
avg_episode_per_sec: 0.04791371474337687
collect_time: 104.3542548679374
reward_mean: -441.8285714285715
reward_std: 17.49592372350696
reward_max: -418.0714285714287
reward_min: -467.8571428571428
queue_len: 0.27408720311946116
wait_time: 2.107107408720312
delay_time: 62.139073600933656
pressure: 3.837220843672457
total_envstep_count: 228780
total_train_sample_count: 228780
total_episode_count: 1845
total_duration: 39987.93723208842
[2024-12-28 03:56:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.581880134884315
avg_train_sample_per_sec: 5.581880134884315
avg_episode_per_sec: 0.04501516237809932
collect_time: 111.07368575066141
reward_mean: -445.58571428571423
reward_std: 10.677785446468555
reward_max: -436.35714285714283
reward_min: -466.3571428571428
queue_len: 0.2764179369018079
wait_time: 2.12234136830911
delay_time: 62.254160445514756
pressure: 3.86985111662531
total_envstep_count: 229400
total_train_sample_count: 229400
total_episode_count: 1850
total_duration: 40099.010917839085
[2024-12-28 03:58:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.219970408259496
avg_train_sample_per_sec: 6.219970408259496
avg_episode_per_sec: 0.05016105167951207
collect_time: 99.6789308156036
reward_mean: -435.65714285714296
reward_std: 4.465377009473611
reward_max: -429.7857142857143
reward_min: -440.2142857142859
queue_len: 0.27025877348457994
wait_time: 2.104688053881602
delay_time: 61.38342989141269
pressure: 3.7836228287841194
total_envstep_count: 230020
total_train_sample_count: 230020
total_episode_count: 1855
total_duration: 40198.689848654685
[2024-12-28 04:00:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 5.898693743736883
avg_train_sample_per_sec: 5.898693743736883
avg_episode_per_sec: 0.04757011083658777
collect_time: 105.10801661101728
reward_mean: -436.1285714285715
reward_std: 8.732112912598375
reward_max: -421.2857142857142
reward_min: -444.42857142857144
queue_len: 0.2705512229705779
wait_time: 2.1088355193193906
delay_time: 61.35934784203799
pressure: 3.787717121588089
total_envstep_count: 230640
total_train_sample_count: 230640
total_episode_count: 1860
total_duration: 40303.797865265704
[2024-12-28 04:02:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.108785814499918
avg_train_sample_per_sec: 6.108785814499918
avg_episode_per_sec: 0.04926440172983805
collect_time: 101.4931639162004
reward_mean: -434.5428571428571
reward_std: 9.68931664994276
reward_max: -422.92857142857116
reward_min: -450.21428571428567
queue_len: 0.26956752924494853
wait_time: 2.0928571428571425
delay_time: 61.18767457409892
pressure: 3.77394540942928
total_envstep_count: 231260
total_train_sample_count: 231260
total_episode_count: 1865
total_duration: 40405.291029181906
[2024-12-28 04:03:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.099934292419316
avg_train_sample_per_sec: 6.099934292419316
avg_episode_per_sec: 0.04919301848725254
collect_time: 101.64043910612351
reward_mean: -433.14285714285717
reward_std: 10.857424808369114
reward_max: -415.2857142857142
reward_min: -447.71428571428595
queue_len: 0.26869904289259133
wait_time: 2.0988567883729177
delay_time: 60.956083933338995
pressure: 3.761786600496278
total_envstep_count: 231880
total_train_sample_count: 231880
total_episode_count: 1870
total_duration: 40506.93146828803
[2024-12-28 04:05:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.062643168129249
avg_train_sample_per_sec: 6.062643168129249
avg_episode_per_sec: 0.048892283613945556
collect_time: 102.2656261973791
reward_mean: -433.72857142857146
reward_std: 7.468764889832355
reward_max: -423.4285714285715
reward_min: -444.21428571428584
queue_len: 0.2690623892236796
wait_time: 2.0804324707550514
delay_time: 61.0339752471265
pressure: 3.7668734491315137
total_envstep_count: 232500
total_train_sample_count: 232500
total_episode_count: 1875
total_duration: 40609.19709448541
[2024-12-28 04:07:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.010555683402938
avg_train_sample_per_sec: 6.010555683402938
avg_episode_per_sec: 0.0484722232532495
collect_time: 103.15186027009413
reward_mean: -444.5000000000001
reward_std: 11.203862307804512
reward_max: -428.5000000000004
reward_min: -454.642857142857
queue_len: 0.2757444168734492
wait_time: 2.1193725629209497
delay_time: 62.04414678507146
pressure: 3.860421836228288
total_envstep_count: 233120
total_train_sample_count: 233120
total_episode_count: 1880
total_duration: 40712.34895475551
[2024-12-28 04:08:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 5
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 6.250781204718507
avg_train_sample_per_sec: 6.250781204718507
avg_episode_per_sec: 0.05040952584450409
collect_time: 99.18760226833449
reward_mean: -438.3714285714285
reward_std: 6.538957040971689
reward_max: -431.0000000000001
reward_min: -449.2142857142857
queue_len: 0.27194257355547674
wait_time: 2.1258153137185394
delay_time: 61.283331858137764
pressure: 3.807196029776675
total_envstep_count: 233740
total_train_sample_count: 233740
total_episode_count: 1885
total_duration: 40811.53655702384
