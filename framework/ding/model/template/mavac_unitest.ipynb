{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```mermaid\n",
    "Input: agent_state, cls_state, global_state, edges\n",
    "       |\n",
    "       v\n",
    "+------------------+     +-------------------+\n",
    "| AgentEncoder     |     | ClsEncoder        |\n",
    "| (fc_block)       |     | (GCN -> Mean Pool)|\n",
    "+------------------+     +-------------------+\n",
    "       |                       |\n",
    "       v                       v\n",
    "agent_emb                  cls_emb\n",
    "       |                       |\n",
    "       v                       v\n",
    "+------------------+     +-------------------+\n",
    "| SelfAttention   |     | GraphWeight (GCN)  |\n",
    "| (Self-Attention)|     | (GCN -> Attention) |\n",
    "+------------------+     +-------------------+\n",
    "       |                       |\n",
    "       v                       v\n",
    "integrate_obs_emb          integrate_cls_emb\n",
    "       |                       |\n",
    "       v                       v\n",
    "+----------------------------------+\n",
    "| Add (integrate_obs_emb + integrate_cls_emb) |\n",
    "+----------------------------------+\n",
    "       |\n",
    "       v\n",
    "critic_head (MLP -> RegressionHead)\n",
    "       |\n",
    "       v\n",
    "Output: value\n",
    "```\n",
    "\n",
    "### 总结\n",
    "\n",
    "- **GCN** 是一个包含两层图卷积的网络，用于处理图结构数据。\n",
    "- **ClsEncoder** 使用 GCN 对邻域状态进行编码，并通过均值池化得到最终的编码结果。\n",
    "- **GraphWeight** 使用两个 GCN 分别生成查询和键，然后通过注意力机制计算节点之间的关系权重。\n",
    "- **整体结构** 包含了多个模块的协同工作，最终通过 Critic Head 计算 Q 值输出。\n",
    "\n",
    "如果你有具体的绘图工具或需求，可以进一步细化这些结构图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉注意力CrosAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch import nn\n",
    "import unittest\n",
    "\n",
    "class CrosAttention(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=4):\n",
    "        super(CrosAttention, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        # 输入和输出的维度，点乘\n",
    "        self.query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.value = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, agent_state, integrate_cluster_emb):\n",
    "        T, B, A, N = agent_state.shape\n",
    "\n",
    "        # Cross-attention\n",
    "        query = self.query(integrate_cluster_emb)       # integrate_cluster_emb作为query\n",
    "        key = self.key(agent_state)                     # agent_state作为key\n",
    "        value = self.value(agent_state)                 # agent_state作为value\n",
    "        # 矩阵点积\n",
    "        attention_map = torch.matmul(query, key.transpose(-1, -2))  # T, B, 1, A\n",
    "        attention_map /= math.sqrt(self._hidden_dim)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)\n",
    "        # 输出注意力权重，attention_map点乘value向量\n",
    "        cross_attention_output = torch.matmul(attention_map, value)  # T, B, 1, hidden_dim\n",
    "        \n",
    "        return cross_attention_output  # T, B, 1, hidden_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数学习机制\n",
    "### 线性层 (nn.Linear):\n",
    "- self.query = nn.Linear(input_dim, hidden_dim): 这是一个线性层，将输入维度 input_dim 映射到隐藏维度 hidden_dim。它包含两个可学习的参数：权重矩阵和偏置向量。\n",
    "- self.key = nn.Linear(input_dim, hidden_dim): 同样是一个线性层，将输入维度 input_dim 映射到隐藏维度 hidden_dim。它也包含权重矩阵和偏置向量。\n",
    "- self.value = nn.Linear(input_dim, hidden_dim): 同样是一个线性层，将输入维度 input_dim 映射到隐藏维度 hidden_dim。它也包含权重矩阵和偏置向量。\n",
    "### 前向传播 (forward 方法):\n",
    "- query = self.query(integrate_cluster_emb): 使用 query 线性层将 integrate_cluster_emb 映射到隐藏维度 hidden_dim。\n",
    "- key = self.key(agent_state): 使用 key 线性层将 agent_state 映射到隐藏维度 hidden_dim。\n",
    "- value = self.value(agent_state): 使用 value 线性层将 agent_state 映射到隐藏维度 hidden_dim。\n",
    "- attention_map = torch.matmul(query, key.transpose(-1, -2)): 计算查询和键之间的注意力分数。\n",
    "- attention_map /= math.sqrt(self._hidden_dim): 对注意力分数进行缩放。\n",
    "- attention_map = F.softmax(attention_map, dim=-1): 对注意力分数进行 softmax 归一化。\n",
    "- cross_attention_output = torch.matmul(attention_map, value): 使用注意力权重对值进行加权求和。\n",
    "### 参数学习过程\n",
    "在训练过程中，优化器（如 Adam 或 SGD）会更新这些线性层的权重和偏置，以最小化损失函数。具体来说，优化器会根据反向传播计算出的梯度来调整这些参数，从而使得模型能够更好地学习到数据中的模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建 CrosAttention 实例\n",
    "cros_attention = CrosAttention(input_dim=4, hidden_dim=4)\n",
    "\n",
    "# 查看参数\n",
    "for name, param in cros_attention.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Shape: {param.shape}, Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 前向传播过程：\n",
    "    - 获取输入 `agent_state` 的形状 `(T, B, A, N)`，其中：\n",
    "      - `T`: 时间步数。\n",
    "      - `B`: 批次大小。\n",
    "      - `A`: 智能体数量。\n",
    "      - `N`: 每个智能体的特征维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCrosAttention(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim = 4\n",
    "        self.hidden_dim = 4\n",
    "        self.model = CrosAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "\n",
    "    def test_forward_output_shape(self):\n",
    "        T, B, A, N = 2, 3, 5, self.input_dim\n",
    "        agent_state = torch.randn(T, B, A, N)\n",
    "\n",
    "        integrate_cluster_emb = torch.randn(T, B, 1, N)\n",
    "        print(\"agent_state shape is \", agent_state.shape)\n",
    "        # print(\"agent_state is \\n\", agent_state)\n",
    "        print(\"integrate_cluster_emb shape is \", integrate_cluster_emb.shape)\n",
    "        # print(\"integrate_cluster_emb is \\n\", integrate_cluster_emb)\n",
    "        output = self.model(agent_state, integrate_cluster_emb)\n",
    "        print(\"output shape is \", output.shape)\n",
    "        # print(\"output is \\n\", output)\n",
    "        self.assertEqual(output.shape, (T, B, 1, self.hidden_dim))\n",
    "\n",
    "    def test_forward_attention_behavior(self):\n",
    "        T, B, A, N = 2, 3, 5, self.input_dim\n",
    "        agent_state = torch.randn(T, B, A, N)\n",
    "        integrate_cluster_emb = torch.randn(T, B, 1, N)\n",
    "        \n",
    "        output = self.model(agent_state, integrate_cluster_emb)\n",
    "\n",
    "        print(\"model output is \\n\", output)\n",
    "        # 验证输出是否在预期范围内\n",
    "        self.assertTrue(torch.all(output >= 0))\n",
    "        self.assertTrue(torch.all(output <= 1))\n",
    "        \n",
    "        # 验证输出的平均值是否接近0.5（假设均匀分布）\n",
    "        self.assertTrue(torch.allclose(output.mean(dim=-1), torch.tensor(0.5), atol=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention_test = TestCrosAttention()\n",
    "cross_attention_test.setUp()\n",
    "# cross_attention_test.test_forward_attention_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自注意力 SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=4):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.value = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, agent_state):\n",
    "        T, B, A, N = agent_state.shape\n",
    "        # print(\"agent_state shape is \", agent_state.shape)\n",
    "        query = self.query(agent_state)\n",
    "        key = self.key(agent_state)\n",
    "        value = self.value(agent_state)\n",
    "        \n",
    "        attention_map = torch.matmul(query, key.transpose(-1, -2))  # T, B, A, A\n",
    "        attention_map /= math.sqrt(self._hidden_dim)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)\n",
    "        self_attention_output = torch.matmul(attention_map, value)  # T, B, A, hidden_dim\n",
    "        \n",
    "        return self_attention_output  # T, B, A, hidden_dim\n",
    "\n",
    "\n",
    "class TestSelfAttention(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim = 4\n",
    "        self.hidden_dim = 4\n",
    "        self.model = SelfAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "\n",
    "    def test_forward_output_shape(self):\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        print(\"output shape is \", output.shape)\n",
    "        self.assertEqual(output.shape, (T, B, A, self.hidden_dim))\n",
    "\n",
    "    def test_forward_output_range(self):\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        print(\"output is \", output)\n",
    "        self.assertTrue(output.max() <= 1.0)\n",
    "        self.assertTrue(output.min() >= -1.0)\n",
    "\n",
    "    def test_forward_different_hidden_dim(self):\n",
    "        self.hidden_dim = 8\n",
    "        self.model = SelfAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        self.assertEqual(output.shape, (T, B, A, self.hidden_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention_test = TestSelfAttention()\n",
    "self_attention_test.setUp()\n",
    "self_attention_test.test_forward_output_shape()\n",
    "self_attention_test.test_forward_output_range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单元测试设计\n",
    "被测方法行为：\n",
    "\n",
    "- AgentEncoder 类是一个继承自 nn.Module 的 PyTorch 模块，它包含一个编码器，该编码器是一个全连接块（fc_block），用于将输入的 agent_state 转换为隐藏表示。\n",
    "- ClsEncoder 类也是一个继承自 nn.Module 的 PyTorch 模块，它包含一个编码器，该编码器是一个图卷积网络（GCN），用于将 neigborhood_state 和 edges 转换为隐藏表示。然后，它通过在倒数第二个维度上取平均值来聚合这些表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClsEncoder簇编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 创建图\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(5))\n",
    "G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)])\n",
    "\n",
    "# 定义图的布局\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# 创建图形对象\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 定义动画函数\n",
    "def update(num, G, pos, ax):\n",
    "    ax.clear()\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, edge_color='gray', width=2, ax=ax)\n",
    "    ax.set_title(f'Frame {num}')\n",
    "\n",
    "# 创建动画\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(10), fargs=(G, pos, ax), repeat=False)\n",
    "\n",
    "# 将动画转换为 HTML\n",
    "html_animation = ani.to_jshtml()\n",
    "\n",
    "# 在 Jupyter Notebook 中显示动画\n",
    "\n",
    "# HTML(html_animation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import unittest\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class ClsEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim: int = 4, output_dim: int = 4):\n",
    "        super(ClsEncoder, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.encoder = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, neigborhood_state, edges):\n",
    "        neighborhood_emb = self.encoder(neigborhood_state, edges)\n",
    "        neighborhood_emb = torch.mean(neighborhood_emb, dim=-2, keepdim=False)\n",
    "        return neighborhood_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import unittest\n",
    "\n",
    "class TestClsEncoder(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # 初始化测试参数\n",
    "        self.input_dim = 3\n",
    "        self.hidden_dim = 4\n",
    "        self.output_dim = 2\n",
    "        self.num_nodes = 5\n",
    "        \n",
    "        # 创建模型实例\n",
    "        self.model = ClsEncoder(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.output_dim\n",
    "        )\n",
    "        \n",
    "        # 创建测试用图数据\n",
    "        self.neighborhood_state = torch.randn(self.num_nodes, self.input_dim)\n",
    "        self.edge_index = torch.tensor([[0,1,2,3,4], [1,2,3,4,0]], dtype=torch.long)\n",
    "\n",
    "    def test_output_shape(self):\n",
    "        \"\"\"测试输出维度是否正确\"\"\"\n",
    "        output = self.model(self.neighborhood_state, self.edge_index)\n",
    "        print(\"output shape:\", output.shape)\n",
    "        self.assertEqual(output.shape, (self.output_dim,))\n",
    "\n",
    "    def test_mean_aggregation(self):\n",
    "        \"\"\"测试均值聚合是否正确\"\"\"\n",
    "        # 冻结网络参数\n",
    "        with torch.no_grad():\n",
    "            # 将第一层GCN参数置零，bias置1\n",
    "            self.model.encoder.conv1.lin.weight.zero_()\n",
    "            self.model.encoder.conv1.bias.fill_(1.0)\n",
    "            \n",
    "            # 将第二层GCN参数置零，bias置2\n",
    "            self.model.encoder.conv2.lin.weight.zero_()\n",
    "            self.model.encoder.conv2.bias.fill_(2.0)\n",
    "\n",
    "        # 创建全零输入特征\n",
    "        test_input = torch.zeros(self.num_nodes, self.input_dim)\n",
    "        \n",
    "        # 前向传播\n",
    "        output = self.model(test_input, self.edge_index)\n",
    "        print(\"output shape:\", output.shape)\n",
    "        # 验证输出值全为2.0（ReLU后的bias传播）\n",
    "        expected = torch.full((self.output_dim,), 2.0)\n",
    "        self.assertTrue(torch.allclose(output, expected, atol=1e-6))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     unittest.main()\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_encoder_test = TestClsEncoder()\n",
    "cls_encoder_test.setUp()\n",
    "cls_encoder_test.test_mean_aggregation()\n",
    "# cls_encoder_test.test_output_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc_block \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " fc_block 函数用于创建一个包含线性层、可选的归一化层、可选的激活函数和可选的丢弃层的全连接块。\n",
    " 该函数接受以下参数：\n",
    "\n",
    "- in_channels: 输入张量的通道数。\n",
    "- out_channels: 输出张量的通道数。\n",
    "- activation: 一个可选的激活函数。\n",
    "- norm_type: 归一化类型，可以是 None 或指定的归一化类型。\n",
    "- use_dropout: 一个布尔值，指示是否使用丢弃层。\n",
    "- dropout_probability: 丢弃概率，默认为 0.5。\n",
    "函数根据提供的参数构建一个 nn.Sequential 对象，其中包含线性层、可选的归一化层、可选的激活函数和可选的丢弃层。\n",
    "\n",
    "分支和所需的测试用例:\n",
    "\n",
    "- 线性层: 总是存在，因此不需要特定的测试用例。\n",
    "- 归一化层: 如果 norm_type 不是 None，则包含一个归一化层。需要测试 norm_type 为 None 和非 None 的情况。\n",
    "- 激活函数: 如果 activation 不是 None，则包含一个激活函数。需要测试 activation 为 None 和非 None 的情况。\n",
    "- 丢弃层: 如果 use_dropout 为 True，则包含一个丢弃层。需要测试 use_dropout 为 True 和 False 的情况。\n",
    "- 模拟需求: 不需要模拟，因为该函数不依赖于外部系统或需要模拟的复杂对象。它仅使用 PyTorch 的标准组件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\Eddie\\Documents\\marl_sigctrl\\framework\")\n",
    "sys.path.append(r\"C:\\Users\\Eddie\\Documents\\marl_sigctrl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ding.torch_utils.network.nn_module import fc_block\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationNoNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20)\n",
    "    assert len(block) == 1\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert block[0].in_features == 10\n",
    "    assert block[0].out_features == 20\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationNoNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU())\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.ReLU)\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationWithNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, norm_type='LN')\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationWithNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), norm_type='LN')\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.ReLU)\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationNoNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, use_dropout=True)\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.Dropout)\n",
    "    assert block[1].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationNoNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), use_dropout=True)\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.ReLU)\n",
    "    assert isinstance(block[2], nn.Dropout)\n",
    "    assert block[2].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationWithNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, norm_type='LN', use_dropout=True)\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.Dropout)\n",
    "    assert block[2].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationWithNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), norm_type='LN', use_dropout=True)\n",
    "    assert len(block) == 4\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.ReLU)\n",
    "    assert isinstance(block[3], nn.Dropout)\n",
    "    assert block[3].p == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fc_block_WithActivationNoNormWithDropout()\n",
    "test_fc_block_WithActivationWithNormWithDropout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AgentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ding.torch_utils.network.nn_module import fc_block\n",
    "class AgentEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 hidden_dim: int = 4\n",
    "        ):\n",
    "        super(AgentEncoder, self).__init__()\n",
    "        # 如果没有额外的参数，就是一个线性层\n",
    "        self.encoder = fc_block(input_dim, hidden_dim)\n",
    "        return \n",
    "\n",
    "    def forward(self, agent_state):\n",
    "        return self.encoder(agent_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_AgentEncoder_DefaultHiddenDim():\n",
    "    input_dim = 10\n",
    "    encoder = AgentEncoder(input_dim)\n",
    "    assert isinstance(encoder.encoder, nn.Sequential)\n",
    "    assert len(encoder.encoder) == 1\n",
    "    assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "    assert encoder.encoder[0].in_features == input_dim\n",
    "    assert encoder.encoder[0].out_features == 4  # 默认 hidden_dim 为 4\n",
    "\n",
    "    # 测试 forward 方法\n",
    "    input_tensor = torch.randn(1, input_dim)\n",
    "    output_tensor = encoder(input_tensor)\n",
    "    assert output_tensor.shape == (1, 4)\n",
    "\n",
    "\n",
    "def test_AgentEncoder_CustomHiddenDim():\n",
    "    input_dim = 10\n",
    "    hidden_dim = 8\n",
    "    encoder = AgentEncoder(input_dim, hidden_dim)\n",
    "    assert isinstance(encoder.encoder, nn.Sequential)\n",
    "    assert len(encoder.encoder) == 1\n",
    "    assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "    assert encoder.encoder[0].in_features == input_dim\n",
    "    assert encoder.encoder[0].out_features == hidden_dim\n",
    "\n",
    "    # 测试 forward 方法\n",
    "    input_tensor = torch.randn(1, input_dim)\n",
    "    output_tensor = encoder(input_tensor)\n",
    "    assert output_tensor.shape == (1, hidden_dim)\n",
    "\n",
    "\n",
    "def test_AgentEncoder_DifferentInputDimensions():\n",
    "    input_dims = [5, 10, 20]\n",
    "    hidden_dim = 8\n",
    "    for input_dim in input_dims:\n",
    "        encoder = AgentEncoder(input_dim, hidden_dim)\n",
    "        assert isinstance(encoder.encoder, nn.Sequential)\n",
    "        assert len(encoder.encoder) == 1\n",
    "        assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "        assert encoder.encoder[0].in_features == input_dim\n",
    "        assert encoder.encoder[0].out_features == hidden_dim\n",
    "\n",
    "        # 测试 forward 方法\n",
    "        input_tensor = torch.randn(1, input_dim)\n",
    "        output_tensor = encoder(input_tensor)\n",
    "        assert output_tensor.shape == (1, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AgentEncoder_DefaultHiddenDim()\n",
    "test_AgentEncoder_CustomHiddenDim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Module\n",
    "nn.Module 是所有神经网络模块的基类。它提供了构建和管理神经网络的基本功能。通过继承 nn.Module，您可以定义自己的神经网络层和模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要作用\n",
    "- 模块化设计:\n",
    "允许将神经网络分解为可重用的模块或层。\n",
    "每个模块可以包含子模块，形成复杂的网络结构。\n",
    "- 参数管理:\n",
    "自动管理模型的参数（权重和偏置）。\n",
    "提供 parameters() 方法来获取所有参数，方便优化器进行更新。\n",
    "- 前向传播:\n",
    "需要实现 forward 方法来定义前向传播逻辑。\n",
    "调用模型实例时，会自动调用 forward 方法。\n",
    "- 设备管理:\n",
    "提供 to(device) 方法将模型移动到指定的设备（如 CPU 或 GPU）。\n",
    "提供 cuda() 和 cpu() 方法方便地将模型移动到 GPU 或 CPU。\n",
    "- 保存和加载:\n",
    "提供 state_dict() 方法获取模型的状态字典。\n",
    "提供 load_state_dict(state_dict) 方法加载状态字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = SimpleNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Sequential\n",
    "nn.Sequential 是一个容器，用于按顺序排列多个模块。它简化了模型的定义，特别适用于简单的线性网络结构。\n",
    "\n",
    "主要作用\n",
    "- 简化模型定义:\n",
    "可以按顺序添加多个模块，而不需要显式地定义 forward 方法。适用于简单的线性网络结构。\n",
    "- 模块管理:\n",
    "自动管理添加的模块。提供 parameters() 方法来获取所有参数。\n",
    "- 前向传播:\n",
    "自动按顺序执行添加的模块。不需要手动实现 forward 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAVAC test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据提供的代码片段，`MAVACSota` 类是用于多智能体强化学习（MARL）的模型，继承自 `nn.Module`。以下是对其各个参数的详细解释：\n",
    "\n",
    "### 初始化参数 (`__init__` 方法)\n",
    "\n",
    "```python\n",
    "def __init__(\n",
    "    self,\n",
    "    agent_obs_shape: Union[int, SequenceType],\n",
    "    global_obs_shape: Union[int, SequenceType],\n",
    "    action_shape: Union[int, SequenceType],\n",
    "    agent_num: int,\n",
    "    actor_head_hidden_size: int = 256,\n",
    "    actor_head_layer_num: int = 2,\n",
    "    critic_head_hidden_size: int = 512,\n",
    "    critic_head_layer_num: int = 1,\n",
    "    action_space: str = 'discrete',\n",
    "    activation: Optional[nn.Module] = nn.ReLU(),\n",
    "    norm_type: Optional[str] = None,\n",
    "    sigma_type: Optional[str] = 'independent',\n",
    "    bound_type: Optional[str] = None,\n",
    ") -> None:\n",
    "```\n",
    "\n",
    "#### 参数详解\n",
    "\n",
    "1. **agent_obs_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：单个智能体的观测空间形状。可以是一个整数（表示一维观测）或一个序列（表示多维观测）。\n",
    "   - 作用：用于定义智能体观测的输入维度。\n",
    "\n",
    "2. **global_obs_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：全局观测空间形状。可以是一个整数（表示一维观测）或一个序列（表示多维观测）。\n",
    "   - 作用：用于定义全局观测的输入维度。\n",
    "\n",
    "3. **action_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：动作空间形状。可以是一个整数（表示离散动作）或一个序列（表示连续动作）。\n",
    "   - 作用：用于定义动作输出的维度。\n",
    "\n",
    "4. **agent_num**:\n",
    "   - 类型：`int`\n",
    "   - 描述：智能体的数量。\n",
    "   - 作用：用于确定参与任务的智能体数量。\n",
    "\n",
    "5. **actor_head_hidden_size**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`256`\n",
    "   - 描述：Actor 网络头部隐藏层的大小。\n",
    "   - 作用：控制 Actor 网络中全连接层的神经元数量。\n",
    "\n",
    "6. **actor_head_layer_num**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`2`\n",
    "   - 描述：Actor 网络头部层数。\n",
    "   - 作用：确定 Actor 网络中全连接层的数量。\n",
    "\n",
    "7. **critic_head_hidden_size**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`512`\n",
    "   - 描述：Critic 网络头部隐藏层的大小。\n",
    "   - 作用：控制 Critic 网络中全连接层的神经元数量。\n",
    "\n",
    "8. **critic_head_layer_num**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`1`\n",
    "   - 描述：Critic 网络头部层数。\n",
    "   - 作用：确定 Critic 网络中全连接层的数量。\n",
    "\n",
    "9. **action_space**:\n",
    "   - 类型：`str`\n",
    "   - 默认值：`'discrete'`\n",
    "   - 描述：动作空间类型，可以是 `'discrete'` 或 `'continuous'`。\n",
    "   - 作用：确定动作空间是离散还是连续，影响后续网络结构的选择。\n",
    "\n",
    "10. **activation**:\n",
    "    - 类型：`Optional[nn.Module]`\n",
    "    - 默认值：`nn.ReLU()`\n",
    "    - 描述：激活函数，默认使用 ReLU 激活函数。\n",
    "    - 作用：应用于网络中的非线性变换。\n",
    "\n",
    "11. **norm_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`None`\n",
    "    - 描述：归一化类型，见 `ding.torch_utils.fc_block` 的更多细节。\n",
    "    - 作用：用于在网络中添加归一化层，如 BatchNorm、LayerNorm 等。\n",
    "\n",
    "12. **sigma_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`'independent'`\n",
    "    - 描述：在连续动作空间中，用于确定标准差的生成方式。\n",
    "    - 作用：影响连续动作分布的标准差计算方式。\n",
    "\n",
    "13. **bound_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`None`\n",
    "    - 描述：在连续动作空间中，用于确定动作的边界处理方式。\n",
    "    - 作用：确保生成的动作在合理的范围内。\n",
    "\n",
    "### 总结\n",
    "\n",
    "这些参数共同决定了 `MAVACSota` 模型的结构和行为，包括观测空间、动作空间、网络结构、激活函数等。通过调整这些参数，可以灵活地适应不同的多智能体强化学习任务和环境需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@MODEL_REGISTRY.register('mavac_sota')` 的作用是将 `MAVACSota` 模型类注册到 `MODEL_REGISTRY` 这个全局注册表中，以便后续可以通过名称动态调用和实例化该模型。具体作用如下：\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **核心功能**\n",
    "- **注册模型**  \n",
    "  通过装饰器语法，将 `MAVACSota` 类与字符串标识符 `'mavac_sota'` 绑定，并存入 `MODEL_REGISTRY`（一个 `Registry` 类的实例）。  \n",
    "  等价于手动调用：\n",
    "  ```python\n",
    "  MODEL_REGISTRY.register(module_name='mavac_sota', module=MAVACSota)\n",
    "  ```\n",
    "\n",
    "- **实现解耦**  \n",
    "  其他代码无需直接导入 `MAVACSota` 类，只需通过 `MODEL_REGISTRY.get('mavac_sota')` 即可获取模型类，实现模块间的解耦。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Registry 类的作用**\n",
    "- **统一管理模块**  \n",
    "  `Registry` 继承自 `dict`，本质是一个字典，存储 `name -> module` 的映射。例如：\n",
    "  ```python\n",
    "  MODEL_REGISTRY = Registry()\n",
    "  # 注册后，MODEL_REGISTRY 的内容变为：\n",
    "  {'mavac_sota': MAVACSota}\n",
    "  ```\n",
    "\n",
    "- **动态构建对象**  \n",
    "  通过 `build()` 方法，可以根据注册名动态实例化模型：\n",
    "  ```python\n",
    "  model = MODEL_REGISTRY.build('mavac_sota', agent_obs_shape=..., global_obs_shape=..., ...)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **实际应用场景**\n",
    "- **配置化驱动**  \n",
    "  在配置文件（如 YAML）中只需指定模型名 `mavac_sota`，代码即可自动加载对应模型：\n",
    "  ```yaml\n",
    "  model:\n",
    "    type: mavac_sota\n",
    "    args:\n",
    "      agent_obs_shape: 64\n",
    "      global_obs_shape: 128\n",
    "      ...\n",
    "  ```\n",
    "\n",
    "- **灵活扩展**  \n",
    "  新增模型时，只需用 `@MODEL_REGISTRY.register('new_model')` 装饰新类，无需修改其他代码即可集成。\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **技术实现细节**\n",
    "- **装饰器模式**  \n",
    "  当 `@MODEL_REGISTRY.register('mavac_sota')` 装饰类时，会调用 `Registry.register()` 方法，将类对象存入字典。\n",
    "\n",
    "- **模块元信息追踪**  \n",
    "  若启用 `_DI_ENGINE_REG_TRACE_IS_ON`，会记录模型注册的代码位置（文件名和行号），便于调试：\n",
    "  ```python\n",
    "  # 查询注册信息\n",
    "  print(MODEL_REGISTRY.query_details())\n",
    "  # 输出: OrderedDict([('mavac_sota', ('path/to/file.py', 123))])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **与代码的关联**\n",
    "在 `MAVACSota` 的定义中：\n",
    "```python\n",
    "@MODEL_REGISTRY.register('mavac_sota')\n",
    "class MAVACSota(nn.Module):\n",
    "    ...\n",
    "```\n",
    "- **`MODEL_REGISTRY`** 是一个全局注册表实例。\n",
    "- **`register`** 方法将类名 `'mavac_sota'` 和类对象 `MAVACSota` 绑定。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "通过 `@MODEL_REGISTRY.register('mavac_sota')`，模型 `MAVACSota` 被注册到一个中央仓库中，后续可以通过字符串 `'mavac_sota'` 动态获取并实例化该模型。这种设计模式广泛应用于深度学习框架（如 Detectron2、MMDetection），以实现高度模块化和可配置化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import unittest\n",
    "from ding.model.template import MAVACSota\n",
    "from ding.torch_utils import to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMAVACSota(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.agent_obs_shape = 174\n",
    "        self.global_obs_shape = 442\n",
    "        self.action_shape = 4\n",
    "        self.agent_num = 3\n",
    "        self.action_space = 'discrete'\n",
    "\n",
    "    def test_compute_actor_discrete(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, action_space='discrete'\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'action_mask': torch.ones(4, self.action_shape)\n",
    "        }\n",
    "        actor_outputs = model(inputs, 'compute_actor')\n",
    "        print(\"actor_outputs shape \", actor_outputs['logit'].shape)\n",
    "        self.assertEqual(actor_outputs['logit'].shape, torch.Size([4, self.action_shape]))\n",
    "\n",
    "    def test_compute_critic_sota(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num,\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape)\n",
    "        }\n",
    "        critic_outputs = model(inputs, 'compute_critic')\n",
    "        self.assertEqual(critic_outputs['value'].shape, torch.Size([4]))\n",
    "\n",
    "    def test_compute_critic_non_sota(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num,\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape)\n",
    "        }\n",
    "        critic_outputs = model(inputs, 'compute_critic')\n",
    "        self.assertEqual(critic_outputs['value'].shape, torch.Size([4]))\n",
    "\n",
    "    def test_compute_actor_critic(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, action_space='discrete'\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape),\n",
    "            'action_mask': torch.ones(4, self.action_shape)\n",
    "        }\n",
    "        outputs = model(inputs, 'compute_actor_critic')\n",
    "        self.assertEqual(outputs['logit'].shape, torch.Size([4, self.action_shape]))\n",
    "        self.assertEqual(outputs['value'].shape, torch.Size([4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mavac_sota_test \u001b[38;5;241m=\u001b[39m TestMAVACSota()\n\u001b[0;32m      2\u001b[0m mavac_sota_test\u001b[38;5;241m.\u001b[39msetUp()\n\u001b[1;32m----> 3\u001b[0m mavac_sota_test\u001b[38;5;241m.\u001b[39mtest_compute_critic_sota()\n",
      "Cell \u001b[1;32mIn[57], line 30\u001b[0m, in \u001b[0;36mTestMAVACSota.test_compute_critic_sota\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m MAVACSota(\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_obs_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_obs_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_num,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_obs_shape),\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls_state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_obs_shape),\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_obs_shape)\n\u001b[0;32m     29\u001b[0m }\n\u001b[1;32m---> 30\u001b[0m critic_outputs \u001b[38;5;241m=\u001b[39m model(inputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_critic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massertEqual(critic_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, torch\u001b[38;5;241m.\u001b[39mSize([\u001b[38;5;241m4\u001b[39m]))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\marl_sigctrl\\framework\\ding\\model\\template\\mavac_sota.py:365\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, inputs, mode)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m    364\u001b[0m     assert mode in self.mode, \"not support forward mode: {}/{}\".format(mode, self.mode)\n\u001b[1;32m--> 365\u001b[0m     return getattr(self, mode)(inputs)\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m def compute_actor(self, x: torch.Tensor) -> Dict:\n",
      "File \u001b[1;32m~\\Documents\\marl_sigctrl\\framework\\ding\\model\\template\\mavac_sota.py:441\u001b[0m, in \u001b[0;36mcompute_critic\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    439\u001b[0m     global_state = global_state.unsqueeze(0)\n\u001b[0;32m    440\u001b[0m \n\u001b[1;32m--> 441\u001b[0m T, B, A = agent_state.shape[:3]\n\u001b[0;32m    442\u001b[0m edges = torch.tensor(list(itertools.combinations(range(A), 2))).t().contiguous().to(agent_state.device)\n\u001b[0;32m    443\u001b[0m \n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "mavac_sota_test = TestMAVACSota()\n",
    "mavac_sota_test.setUp()\n",
    "mavac_sota_test.test_compute_critic_sota()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.optim.Adam 是 PyTorch 中实现 Adam（Adaptive Moment Estimation）优化算法的优化器类。\n",
    "Adam 是一种常用的自适应学习率优化算法，结合了 AdaGrad 和 RMSProp 算法的优点，能够自适应地调整每个参数的学习率。\n",
    "- 优点\n",
    "自适应学习率：能够根据每个参数的梯度情况自动调整学习率，对于不同的参数可以有不同的更新步长。\n",
    "处理稀疏梯度：在处理稀疏数据时表现良好，因为它能够自适应地调整学习率，使得对于稀疏特征的更新不会过于激进。\n",
    "收敛速度快：通常比传统的随机梯度下降（SGD）算法收敛速度更快，能够更快地找到最优解。\n",
    "## 原理\n",
    "Adam 算法通过计算梯度的一阶矩估计（均值）和二阶矩估计（方差）来为不同的参数动态调整学习率。具体步骤如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import unittest\n",
    "\n",
    "# 定义一个简单的线性回归模型\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # 输入维度为 1，输出维度为 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class TestAdamOptimizer(unittest.TestCase):\n",
    "    def test_adam_optimizer(self):\n",
    "        # 生成一些简单的训练数据\n",
    "        x = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "        y = torch.tensor([[2.0], [4.0], [6.0], [8.0]], dtype=torch.float32)\n",
    "\n",
    "        # 初始化模型\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # 定义损失函数和优化器\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        # 训练模型\n",
    "        num_epochs = 3000\n",
    "        for epoch in range(num_epochs):\n",
    "            # 前向传播\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        # 测试模型\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.tensor([[5.0]], dtype=torch.float32)\n",
    "            predicted = model(test_input)\n",
    "            print(f'Predicted value for input 5: {predicted.item():.4f}')\n",
    "\n",
    "        # 断言损失值足够小\n",
    "        self.assertTrue(loss.item() < 0.01)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/3000], Loss: 16.0117\n",
      "Epoch [200/3000], Loss: 3.7753\n",
      "Epoch [300/3000], Loss: 1.1573\n",
      "Epoch [400/3000], Loss: 0.7688\n",
      "Epoch [500/3000], Loss: 0.6736\n",
      "Epoch [600/3000], Loss: 0.5996\n",
      "Epoch [700/3000], Loss: 0.5274\n",
      "Epoch [800/3000], Loss: 0.4577\n",
      "Epoch [900/3000], Loss: 0.3920\n",
      "Epoch [1000/3000], Loss: 0.3311\n",
      "Epoch [1100/3000], Loss: 0.2759\n",
      "Epoch [1200/3000], Loss: 0.2266\n",
      "Epoch [1300/3000], Loss: 0.1834\n",
      "Epoch [1400/3000], Loss: 0.1463\n",
      "Epoch [1500/3000], Loss: 0.1148\n",
      "Epoch [1600/3000], Loss: 0.0887\n",
      "Epoch [1700/3000], Loss: 0.0674\n",
      "Epoch [1800/3000], Loss: 0.0503\n",
      "Epoch [1900/3000], Loss: 0.0369\n",
      "Epoch [2000/3000], Loss: 0.0265\n",
      "Epoch [2100/3000], Loss: 0.0187\n",
      "Epoch [2200/3000], Loss: 0.0129\n",
      "Epoch [2300/3000], Loss: 0.0087\n",
      "Epoch [2400/3000], Loss: 0.0058\n",
      "Epoch [2500/3000], Loss: 0.0037\n",
      "Epoch [2600/3000], Loss: 0.0023\n",
      "Epoch [2700/3000], Loss: 0.0014\n",
      "Epoch [2800/3000], Loss: 0.0009\n",
      "Epoch [2900/3000], Loss: 0.0005\n",
      "Epoch [3000/3000], Loss: 0.0003\n",
      "Predicted value for input 5: 9.9696\n"
     ]
    }
   ],
   "source": [
    "adam_test = TestAdamOptimizer()\n",
    "adam_test.test_adam_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
