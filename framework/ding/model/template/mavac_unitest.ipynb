{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉注意力CrosAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch import nn\n",
    "import unittest\n",
    "\n",
    "\n",
    "class CrosAttention(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=4):\n",
    "        super(CrosAttention, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        # 输入和输出的维度，点乘\n",
    "        self.query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.value = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, agent_state, integrate_cluster_emb):\n",
    "        T, B, A, N = agent_state.shape\n",
    "\n",
    "        # Cross-attention\n",
    "        query = self.query(integrate_cluster_emb)       # integrate_cluster_emb作为query\n",
    "        key = self.key(agent_state)                     # agent_state作为key\n",
    "        value = self.value(agent_state)                 # agent_state作为value\n",
    "        # 矩阵点积\n",
    "        attention_map = torch.matmul(query, key.transpose(-1, -2))  # T, B, 1, A\n",
    "        attention_map /= math.sqrt(self._hidden_dim)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)\n",
    "        # 输出注意力权重，attention_map点乘value向量\n",
    "        cross_attention_output = torch.matmul(attention_map, value)  # T, B, 1, hidden_dim\n",
    "        \n",
    "        return cross_attention_output  # T, B, 1, hidden_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 前向传播过程：\n",
    "    - 获取输入 `agent_state` 的形状 `(T, B, A, N)`，其中：\n",
    "      - `T`: 时间步数。\n",
    "      - `B`: 批次大小。\n",
    "      - `A`: 智能体数量。\n",
    "      - `N`: 每个智能体的特征维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCrosAttention(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim = 4\n",
    "        self.hidden_dim = 4\n",
    "        self.model = CrosAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "\n",
    "    def test_forward_output_shape(self):\n",
    "        T, B, A, N = 2, 3, 5, self.input_dim\n",
    "        agent_state = torch.randn(T, B, A, N)\n",
    "\n",
    "        integrate_cluster_emb = torch.randn(T, B, 1, N)\n",
    "        print(\"agent_state shape is \", agent_state.shape)\n",
    "        # print(\"agent_state is \\n\", agent_state)\n",
    "        print(\"integrate_cluster_emb shape is \", integrate_cluster_emb.shape)\n",
    "        # print(\"integrate_cluster_emb is \\n\", integrate_cluster_emb)\n",
    "        output = self.model(agent_state, integrate_cluster_emb)\n",
    "        print(\"output shape is \", output.shape)\n",
    "        # print(\"output is \\n\", output)\n",
    "        self.assertEqual(output.shape, (T, B, 1, self.hidden_dim))\n",
    "\n",
    "    def test_forward_attention_behavior(self):\n",
    "        T, B, A, N = 2, 3, 5, self.input_dim\n",
    "        agent_state = torch.randn(T, B, A, N)\n",
    "        integrate_cluster_emb = torch.randn(T, B, 1, N)\n",
    "        \n",
    "        output = self.model(agent_state, integrate_cluster_emb)\n",
    "        # print(\"model output is \\n\", output)\n",
    "        # 验证输出是否在预期范围内\n",
    "        self.assertTrue(torch.all(output >= 0))\n",
    "        self.assertTrue(torch.all(output <= 1))\n",
    "        \n",
    "        # 验证输出的平均值是否接近0.5（假设均匀分布）\n",
    "        self.assertTrue(torch.allclose(output.mean(dim=-1), torch.tensor(0.5), atol=0.1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_state shape is  torch.Size([2, 3, 5, 4])\n",
      "integrate_cluster_emb shape is  torch.Size([2, 3, 1, 4])\n",
      "output shape is  torch.Size([2, 3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "cross_attention_test = TestCrosAttention()\n",
    "cross_attention_test.setUp()\n",
    "cross_attention_test.test_forward_output_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自注意力 SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=4):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.query = nn.Linear(input_dim, hidden_dim)\n",
    "        self.key = nn.Linear(input_dim, hidden_dim)\n",
    "        self.value = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, agent_state):\n",
    "        T, B, A, N = agent_state.shape\n",
    "        # print(\"agent_state shape is \", agent_state.shape)\n",
    "        query = self.query(agent_state)\n",
    "        key = self.key(agent_state)\n",
    "        value = self.value(agent_state)\n",
    "        \n",
    "        attention_map = torch.matmul(query, key.transpose(-1, -2))  # T, B, A, A\n",
    "        attention_map /= math.sqrt(self._hidden_dim)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)\n",
    "        self_attention_output = torch.matmul(attention_map, value)  # T, B, A, hidden_dim\n",
    "        \n",
    "        return self_attention_output  # T, B, A, hidden_dim\n",
    "\n",
    "\n",
    "class TestSelfAttention(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim = 4\n",
    "        self.hidden_dim = 4\n",
    "        self.model = SelfAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "\n",
    "    def test_forward_output_shape(self):\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        print(\"output shape is \", output.shape)\n",
    "        self.assertEqual(output.shape, (T, B, A, self.hidden_dim))\n",
    "\n",
    "    def test_forward_output_range(self):\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        print(\"output is \", output)\n",
    "        self.assertTrue(output.max() <= 1.0)\n",
    "        self.assertTrue(output.min() >= -1.0)\n",
    "\n",
    "    def test_forward_different_hidden_dim(self):\n",
    "        self.hidden_dim = 8\n",
    "        self.model = SelfAttention(input_dim=self.input_dim, hidden_dim=self.hidden_dim)\n",
    "        T, B, A = 3, 2, 5\n",
    "        agent_state = torch.randn(T, B, A, self.input_dim)\n",
    "        output = self.model(agent_state)\n",
    "        self.assertEqual(output.shape, (T, B, A, self.hidden_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is  torch.Size([3, 2, 5, 4])\n",
      "output is  tensor([[[[-0.6337,  0.0669, -0.5709,  0.4067],\n",
      "          [-0.6151,  0.0695, -0.4854,  0.2948],\n",
      "          [-0.6092,  0.0715, -0.4665,  0.2431],\n",
      "          [-0.6426,  0.0631, -0.6317,  0.4658],\n",
      "          [-0.6024,  0.0993, -0.3851,  0.1173]],\n",
      "\n",
      "         [[-0.3108, -0.3637, -0.3411,  0.2565],\n",
      "          [-0.3097, -0.1632,  0.0613, -0.0279],\n",
      "          [-0.3191, -0.3118, -0.2719,  0.1924],\n",
      "          [-0.3209, -0.3024, -0.2551,  0.1853],\n",
      "          [-0.2941, -0.2943, -0.1379,  0.1374]]],\n",
      "\n",
      "\n",
      "        [[[-0.2145, -0.3067, -0.0605,  0.0673],\n",
      "          [-0.2085, -0.3530, -0.1383,  0.1411],\n",
      "          [-0.2196, -0.3855, -0.2553,  0.2333],\n",
      "          [-0.1449, -0.6192, -0.4998,  0.5319],\n",
      "          [-0.2395, -0.3477, -0.2335,  0.1749]],\n",
      "\n",
      "         [[-0.3340,  0.2531,  0.7462, -0.5279],\n",
      "          [-0.3930,  0.2894,  0.6195, -0.4225],\n",
      "          [-0.4450,  0.3227,  0.5093, -0.3328],\n",
      "          [-0.3636,  0.2720,  0.6838, -0.4771],\n",
      "          [-0.4753,  0.3323,  0.4283, -0.2549]]],\n",
      "\n",
      "\n",
      "        [[[-0.2293, -0.0579,  0.3246, -0.0154],\n",
      "          [-0.2308, -0.0523,  0.3293, -0.0220],\n",
      "          [-0.2411, -0.0332,  0.3416, -0.0519],\n",
      "          [-0.2367, -0.0399,  0.3384, -0.0378],\n",
      "          [-0.2381, -0.0381,  0.3400, -0.0383]],\n",
      "\n",
      "         [[-0.4792, -0.1617, -0.5376,  0.3533],\n",
      "          [-0.5327, -0.1273, -0.6526,  0.4230],\n",
      "          [-0.5349, -0.1226, -0.6505,  0.4171],\n",
      "          [-0.6621, -0.0510, -0.9412,  0.6105],\n",
      "          [-0.4400, -0.1714, -0.4182,  0.2599]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "self_attention_test = TestSelfAttention()\n",
    "self_attention_test.setUp()\n",
    "self_attention_test.test_forward_output_shape()\n",
    "self_attention_test.test_forward_output_range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单元测试设计\n",
    "被测方法行为：\n",
    "\n",
    "- AgentEncoder 类是一个继承自 nn.Module 的 PyTorch 模块，它包含一个编码器，该编码器是一个全连接块（fc_block），用于将输入的 agent_state 转换为隐藏表示。\n",
    "- ClsEncoder 类也是一个继承自 nn.Module 的 PyTorch 模块，它包含一个编码器，该编码器是一个图卷积网络（GCN），用于将 neigborhood_state 和 edges 转换为隐藏表示。然后，它通过在倒数第二个维度上取平均值来聚合这些表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClsEncoder簇编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 创建图\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(5))\n",
    "G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)])\n",
    "\n",
    "# 定义图的布局\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# 创建图形对象\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 定义动画函数\n",
    "def update(num, G, pos, ax):\n",
    "    ax.clear()\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, edge_color='gray', width=2, ax=ax)\n",
    "    ax.set_title(f'Frame {num}')\n",
    "\n",
    "# 创建动画\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(10), fargs=(G, pos, ax), repeat=False)\n",
    "\n",
    "# 将动画转换为 HTML\n",
    "html_animation = ani.to_jshtml()\n",
    "\n",
    "# 在 Jupyter Notebook 中显示动画\n",
    "\n",
    "# HTML(html_animation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import unittest\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class ClsEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim: int = 4, output_dim: int = 4):\n",
    "        super(ClsEncoder, self).__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.encoder = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, neigborhood_state, edges):\n",
    "        neighborhood_emb = self.encoder(neigborhood_state, edges)\n",
    "        neighborhood_emb = torch.mean(neighborhood_emb, dim=-2, keepdim=False)\n",
    "        return neighborhood_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F....\n",
      "======================================================================\n",
      "FAIL: test_forward_attention_behavior (__main__.TestCrosAttention.test_forward_attention_behavior)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Eddie\\AppData\\Local\\Temp\\ipykernel_8172\\3160695866.py\", line 29, in test_forward_attention_behavior\n",
      "    self.assertTrue(torch.all(output >= 0))\n",
      "AssertionError: tensor(False) is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.058s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2])\n",
      "output shape: torch.Size([2])\n",
      "agent_state shape is  torch.Size([2, 3, 5, 4])\n",
      "integrate_cluster_emb shape is  torch.Size([2, 3, 1, 4])\n",
      "output shape is  torch.Size([2, 3, 1, 4])\n",
      "output is  tensor([[[[ 0.1765, -0.0592,  0.0385, -0.5855],\n",
      "          [ 0.2210, -0.1246,  0.0779, -0.4847],\n",
      "          [ 0.2076, -0.0896,  0.0671, -0.5318],\n",
      "          [ 0.2557, -0.1394,  0.1146, -0.4411],\n",
      "          [ 0.2125, -0.1767,  0.0234, -0.4908]],\n",
      "\n",
      "         [[-0.1136,  0.1202,  0.0123, -0.6450],\n",
      "          [-0.1891,  0.0893, -0.0655, -0.6650],\n",
      "          [-0.1585,  0.0966, -0.0383, -0.6565],\n",
      "          [-0.1428,  0.0880, -0.0349, -0.6514],\n",
      "          [-0.0733,  0.1746,  0.0863, -0.6359]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4210, -0.1777,  0.0815, -0.5438],\n",
      "          [ 0.6317, -0.3610,  0.0523, -0.5015],\n",
      "          [-0.1029,  0.1648,  0.0538, -0.6467],\n",
      "          [ 0.1264,  0.0736,  0.1138, -0.6078],\n",
      "          [ 0.0287,  0.0894,  0.0699, -0.6213]],\n",
      "\n",
      "         [[ 0.0789, -0.1828, -0.1155, -0.5854],\n",
      "          [ 0.3612, -0.2194,  0.0538, -0.4977],\n",
      "          [ 0.5690, -0.3300,  0.0822, -0.4606],\n",
      "          [ 0.6809, -0.4247,  0.0600, -0.4487],\n",
      "          [ 0.1978, -0.1767, -0.0209, -0.5432]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8744, -0.5141,  0.3392, -0.1036],\n",
      "          [ 0.8434, -0.4664,  0.3328, -0.1485],\n",
      "          [ 0.8273, -0.4519,  0.3117, -0.1837],\n",
      "          [ 0.8698, -0.4758,  0.3425, -0.1420],\n",
      "          [ 0.7752, -0.4393,  0.2826, -0.2029]],\n",
      "\n",
      "         [[ 0.2683, -0.0472,  0.2088, -0.4316],\n",
      "          [ 0.2708, -0.0170,  0.2331, -0.4379],\n",
      "          [ 0.2691, -0.0266,  0.2264, -0.4337],\n",
      "          [ 0.2604, -0.0295,  0.2203, -0.4326],\n",
      "          [ 0.2641, -0.0212,  0.2303, -0.4317]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "output shape is  torch.Size([3, 2, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import unittest\n",
    "\n",
    "class TestClsEncoder(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # 初始化测试参数\n",
    "        self.input_dim = 3\n",
    "        self.hidden_dim = 4\n",
    "        self.output_dim = 2\n",
    "        self.num_nodes = 5\n",
    "        \n",
    "        # 创建模型实例\n",
    "        self.model = ClsEncoder(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.output_dim\n",
    "        )\n",
    "        \n",
    "        # 创建测试用图数据\n",
    "        self.neighborhood_state = torch.randn(self.num_nodes, self.input_dim)\n",
    "        self.edge_index = torch.tensor([[0,1,2,3,4], [1,2,3,4,0]], dtype=torch.long)\n",
    "\n",
    "    def test_output_shape(self):\n",
    "        \"\"\"测试输出维度是否正确\"\"\"\n",
    "        output = self.model(self.neighborhood_state, self.edge_index)\n",
    "        print(\"output shape:\", output.shape)\n",
    "        self.assertEqual(output.shape, (self.output_dim,))\n",
    "\n",
    "    def test_mean_aggregation(self):\n",
    "        \"\"\"测试均值聚合是否正确\"\"\"\n",
    "        # 冻结网络参数\n",
    "        with torch.no_grad():\n",
    "            # 将第一层GCN参数置零，bias置1\n",
    "            self.model.encoder.conv1.lin.weight.zero_()\n",
    "            self.model.encoder.conv1.bias.fill_(1.0)\n",
    "            \n",
    "            # 将第二层GCN参数置零，bias置2\n",
    "            self.model.encoder.conv2.lin.weight.zero_()\n",
    "            self.model.encoder.conv2.bias.fill_(2.0)\n",
    "\n",
    "        # 创建全零输入特征\n",
    "        test_input = torch.zeros(self.num_nodes, self.input_dim)\n",
    "        \n",
    "        # 前向传播\n",
    "        output = self.model(test_input, self.edge_index)\n",
    "        print(\"output shape:\", output.shape)\n",
    "        # 验证输出值全为2.0（ReLU后的bias传播）\n",
    "        expected = torch.full((self.output_dim,), 2.0)\n",
    "        self.assertTrue(torch.allclose(output, expected, atol=1e-6))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     unittest.main()\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "cls_encoder_test = TestClsEncoder()\n",
    "cls_encoder_test.setUp()\n",
    "cls_encoder_test.test_mean_aggregation()\n",
    "# cls_encoder_test.test_output_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc_block \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " fc_block 函数用于创建一个包含线性层、可选的归一化层、可选的激活函数和可选的丢弃层的全连接块。\n",
    " 该函数接受以下参数：\n",
    "\n",
    "- in_channels: 输入张量的通道数。\n",
    "- out_channels: 输出张量的通道数。\n",
    "- activation: 一个可选的激活函数。\n",
    "- norm_type: 归一化类型，可以是 None 或指定的归一化类型。\n",
    "- use_dropout: 一个布尔值，指示是否使用丢弃层。\n",
    "- dropout_probability: 丢弃概率，默认为 0.5。\n",
    "函数根据提供的参数构建一个 nn.Sequential 对象，其中包含线性层、可选的归一化层、可选的激活函数和可选的丢弃层。\n",
    "\n",
    "分支和所需的测试用例:\n",
    "\n",
    "- 线性层: 总是存在，因此不需要特定的测试用例。\n",
    "- 归一化层: 如果 norm_type 不是 None，则包含一个归一化层。需要测试 norm_type 为 None 和非 None 的情况。\n",
    "- 激活函数: 如果 activation 不是 None，则包含一个激活函数。需要测试 activation 为 None 和非 None 的情况。\n",
    "- 丢弃层: 如果 use_dropout 为 True，则包含一个丢弃层。需要测试 use_dropout 为 True 和 False 的情况。\n",
    "- 模拟需求: 不需要模拟，因为该函数不依赖于外部系统或需要模拟的复杂对象。它仅使用 PyTorch 的标准组件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\Eddie\\Documents\\marl_sigctrl\\framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\treevalue\\tree\\integration\\torch.py:23: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  register_for_torch(TreeValue)\n",
      "d:\\Anaconda\\Lib\\site-packages\\treevalue\\tree\\integration\\torch.py:24: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  register_for_torch(FastTreeValue)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ding.torch_utils.network.nn_module import fc_block\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationNoNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20)\n",
    "    assert len(block) == 1\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert block[0].in_features == 10\n",
    "    assert block[0].out_features == 20\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationNoNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU())\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.ReLU)\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationWithNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, norm_type='LN')\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationWithNormNoDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), norm_type='LN')\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.ReLU)\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationNoNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, use_dropout=True)\n",
    "    assert len(block) == 2\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.Dropout)\n",
    "    assert block[1].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationNoNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), use_dropout=True)\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.ReLU)\n",
    "    assert isinstance(block[2], nn.Dropout)\n",
    "    assert block[2].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_NoActivationWithNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, norm_type='LN', use_dropout=True)\n",
    "    assert len(block) == 3\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.Dropout)\n",
    "    assert block[2].p == 0.5\n",
    "\n",
    "\n",
    "def test_fc_block_WithActivationWithNormWithDropout():\n",
    "    block = fc_block(in_channels=10, out_channels=20, activation=nn.ReLU(), norm_type='LN', use_dropout=True)\n",
    "    assert len(block) == 4\n",
    "    assert isinstance(block[0], nn.Linear)\n",
    "    assert isinstance(block[1], nn.LayerNorm)\n",
    "    assert isinstance(block[2], nn.ReLU)\n",
    "    assert isinstance(block[3], nn.Dropout)\n",
    "    assert block[3].p == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fc_block_WithActivationNoNormWithDropout()\n",
    "test_fc_block_WithActivationWithNormWithDropout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AgentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ding.torch_utils.network.nn_module import fc_block\n",
    "class AgentEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 hidden_dim: int = 4\n",
    "        ):\n",
    "        super(AgentEncoder, self).__init__()\n",
    "        # 如果没有额外的参数，就是一个线性层\n",
    "        self.encoder = fc_block(input_dim, hidden_dim)\n",
    "        return \n",
    "\n",
    "    def forward(self, agent_state):\n",
    "        return self.encoder(agent_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_AgentEncoder_DefaultHiddenDim():\n",
    "    input_dim = 10\n",
    "    encoder = AgentEncoder(input_dim)\n",
    "    assert isinstance(encoder.encoder, nn.Sequential)\n",
    "    assert len(encoder.encoder) == 1\n",
    "    assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "    assert encoder.encoder[0].in_features == input_dim\n",
    "    assert encoder.encoder[0].out_features == 4  # 默认 hidden_dim 为 4\n",
    "\n",
    "    # 测试 forward 方法\n",
    "    input_tensor = torch.randn(1, input_dim)\n",
    "    output_tensor = encoder(input_tensor)\n",
    "    assert output_tensor.shape == (1, 4)\n",
    "\n",
    "\n",
    "def test_AgentEncoder_CustomHiddenDim():\n",
    "    input_dim = 10\n",
    "    hidden_dim = 8\n",
    "    encoder = AgentEncoder(input_dim, hidden_dim)\n",
    "    assert isinstance(encoder.encoder, nn.Sequential)\n",
    "    assert len(encoder.encoder) == 1\n",
    "    assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "    assert encoder.encoder[0].in_features == input_dim\n",
    "    assert encoder.encoder[0].out_features == hidden_dim\n",
    "\n",
    "    # 测试 forward 方法\n",
    "    input_tensor = torch.randn(1, input_dim)\n",
    "    output_tensor = encoder(input_tensor)\n",
    "    assert output_tensor.shape == (1, hidden_dim)\n",
    "\n",
    "\n",
    "def test_AgentEncoder_DifferentInputDimensions():\n",
    "    input_dims = [5, 10, 20]\n",
    "    hidden_dim = 8\n",
    "    for input_dim in input_dims:\n",
    "        encoder = AgentEncoder(input_dim, hidden_dim)\n",
    "        assert isinstance(encoder.encoder, nn.Sequential)\n",
    "        assert len(encoder.encoder) == 1\n",
    "        assert isinstance(encoder.encoder[0], nn.Linear)\n",
    "        assert encoder.encoder[0].in_features == input_dim\n",
    "        assert encoder.encoder[0].out_features == hidden_dim\n",
    "\n",
    "        # 测试 forward 方法\n",
    "        input_tensor = torch.randn(1, input_dim)\n",
    "        output_tensor = encoder(input_tensor)\n",
    "        assert output_tensor.shape == (1, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AgentEncoder_DefaultHiddenDim()\n",
    "test_AgentEncoder_CustomHiddenDim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAVAC test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据提供的代码片段，`MAVACSota` 类是用于多智能体强化学习（MARL）的模型，继承自 `nn.Module`。以下是对其各个参数的详细解释：\n",
    "\n",
    "### 初始化参数 (`__init__` 方法)\n",
    "\n",
    "```python\n",
    "def __init__(\n",
    "    self,\n",
    "    agent_obs_shape: Union[int, SequenceType],\n",
    "    global_obs_shape: Union[int, SequenceType],\n",
    "    action_shape: Union[int, SequenceType],\n",
    "    agent_num: int,\n",
    "    actor_head_hidden_size: int = 256,\n",
    "    actor_head_layer_num: int = 2,\n",
    "    critic_head_hidden_size: int = 512,\n",
    "    critic_head_layer_num: int = 1,\n",
    "    action_space: str = 'discrete',\n",
    "    activation: Optional[nn.Module] = nn.ReLU(),\n",
    "    norm_type: Optional[str] = None,\n",
    "    sigma_type: Optional[str] = 'independent',\n",
    "    bound_type: Optional[str] = None,\n",
    ") -> None:\n",
    "```\n",
    "\n",
    "#### 参数详解\n",
    "\n",
    "1. **agent_obs_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：单个智能体的观测空间形状。可以是一个整数（表示一维观测）或一个序列（表示多维观测）。\n",
    "   - 作用：用于定义智能体观测的输入维度。\n",
    "\n",
    "2. **global_obs_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：全局观测空间形状。可以是一个整数（表示一维观测）或一个序列（表示多维观测）。\n",
    "   - 作用：用于定义全局观测的输入维度。\n",
    "\n",
    "3. **action_shape**:\n",
    "   - 类型：`Union[int, SequenceType]`\n",
    "   - 描述：动作空间形状。可以是一个整数（表示离散动作）或一个序列（表示连续动作）。\n",
    "   - 作用：用于定义动作输出的维度。\n",
    "\n",
    "4. **agent_num**:\n",
    "   - 类型：`int`\n",
    "   - 描述：智能体的数量。\n",
    "   - 作用：用于确定参与任务的智能体数量。\n",
    "\n",
    "5. **actor_head_hidden_size**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`256`\n",
    "   - 描述：Actor 网络头部隐藏层的大小。\n",
    "   - 作用：控制 Actor 网络中全连接层的神经元数量。\n",
    "\n",
    "6. **actor_head_layer_num**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`2`\n",
    "   - 描述：Actor 网络头部层数。\n",
    "   - 作用：确定 Actor 网络中全连接层的数量。\n",
    "\n",
    "7. **critic_head_hidden_size**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`512`\n",
    "   - 描述：Critic 网络头部隐藏层的大小。\n",
    "   - 作用：控制 Critic 网络中全连接层的神经元数量。\n",
    "\n",
    "8. **critic_head_layer_num**:\n",
    "   - 类型：`int`\n",
    "   - 默认值：`1`\n",
    "   - 描述：Critic 网络头部层数。\n",
    "   - 作用：确定 Critic 网络中全连接层的数量。\n",
    "\n",
    "9. **action_space**:\n",
    "   - 类型：`str`\n",
    "   - 默认值：`'discrete'`\n",
    "   - 描述：动作空间类型，可以是 `'discrete'` 或 `'continuous'`。\n",
    "   - 作用：确定动作空间是离散还是连续，影响后续网络结构的选择。\n",
    "\n",
    "10. **activation**:\n",
    "    - 类型：`Optional[nn.Module]`\n",
    "    - 默认值：`nn.ReLU()`\n",
    "    - 描述：激活函数，默认使用 ReLU 激活函数。\n",
    "    - 作用：应用于网络中的非线性变换。\n",
    "\n",
    "11. **norm_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`None`\n",
    "    - 描述：归一化类型，见 `ding.torch_utils.fc_block` 的更多细节。\n",
    "    - 作用：用于在网络中添加归一化层，如 BatchNorm、LayerNorm 等。\n",
    "\n",
    "12. **sigma_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`'independent'`\n",
    "    - 描述：在连续动作空间中，用于确定标准差的生成方式。\n",
    "    - 作用：影响连续动作分布的标准差计算方式。\n",
    "\n",
    "13. **bound_type**:\n",
    "    - 类型：`Optional[str]`\n",
    "    - 默认值：`None`\n",
    "    - 描述：在连续动作空间中，用于确定动作的边界处理方式。\n",
    "    - 作用：确保生成的动作在合理的范围内。\n",
    "\n",
    "### 总结\n",
    "\n",
    "这些参数共同决定了 `MAVACSota` 模型的结构和行为，包括观测空间、动作空间、网络结构、激活函数等。通过调整这些参数，可以灵活地适应不同的多智能体强化学习任务和环境需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@MODEL_REGISTRY.register('mavac_sota')` 的作用是将 `MAVACSota` 模型类注册到 `MODEL_REGISTRY` 这个全局注册表中，以便后续可以通过名称动态调用和实例化该模型。具体作用如下：\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **核心功能**\n",
    "- **注册模型**  \n",
    "  通过装饰器语法，将 `MAVACSota` 类与字符串标识符 `'mavac_sota'` 绑定，并存入 `MODEL_REGISTRY`（一个 `Registry` 类的实例）。  \n",
    "  等价于手动调用：\n",
    "  ```python\n",
    "  MODEL_REGISTRY.register(module_name='mavac_sota', module=MAVACSota)\n",
    "  ```\n",
    "\n",
    "- **实现解耦**  \n",
    "  其他代码无需直接导入 `MAVACSota` 类，只需通过 `MODEL_REGISTRY.get('mavac_sota')` 即可获取模型类，实现模块间的解耦。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Registry 类的作用**\n",
    "- **统一管理模块**  \n",
    "  `Registry` 继承自 `dict`，本质是一个字典，存储 `name -> module` 的映射。例如：\n",
    "  ```python\n",
    "  MODEL_REGISTRY = Registry()\n",
    "  # 注册后，MODEL_REGISTRY 的内容变为：\n",
    "  {'mavac_sota': MAVACSota}\n",
    "  ```\n",
    "\n",
    "- **动态构建对象**  \n",
    "  通过 `build()` 方法，可以根据注册名动态实例化模型：\n",
    "  ```python\n",
    "  model = MODEL_REGISTRY.build('mavac_sota', agent_obs_shape=..., global_obs_shape=..., ...)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **实际应用场景**\n",
    "- **配置化驱动**  \n",
    "  在配置文件（如 YAML）中只需指定模型名 `mavac_sota`，代码即可自动加载对应模型：\n",
    "  ```yaml\n",
    "  model:\n",
    "    type: mavac_sota\n",
    "    args:\n",
    "      agent_obs_shape: 64\n",
    "      global_obs_shape: 128\n",
    "      ...\n",
    "  ```\n",
    "\n",
    "- **灵活扩展**  \n",
    "  新增模型时，只需用 `@MODEL_REGISTRY.register('new_model')` 装饰新类，无需修改其他代码即可集成。\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **技术实现细节**\n",
    "- **装饰器模式**  \n",
    "  当 `@MODEL_REGISTRY.register('mavac_sota')` 装饰类时，会调用 `Registry.register()` 方法，将类对象存入字典。\n",
    "\n",
    "- **模块元信息追踪**  \n",
    "  若启用 `_DI_ENGINE_REG_TRACE_IS_ON`，会记录模型注册的代码位置（文件名和行号），便于调试：\n",
    "  ```python\n",
    "  # 查询注册信息\n",
    "  print(MODEL_REGISTRY.query_details())\n",
    "  # 输出: OrderedDict([('mavac_sota', ('path/to/file.py', 123))])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **与代码的关联**\n",
    "在 `MAVACSota` 的定义中：\n",
    "```python\n",
    "@MODEL_REGISTRY.register('mavac_sota')\n",
    "class MAVACSota(nn.Module):\n",
    "    ...\n",
    "```\n",
    "- **`MODEL_REGISTRY`** 是一个全局注册表实例。\n",
    "- **`register`** 方法将类名 `'mavac_sota'` 和类对象 `MAVACSota` 绑定。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "通过 `@MODEL_REGISTRY.register('mavac_sota')`，模型 `MAVACSota` 被注册到一个中央仓库中，后续可以通过字符串 `'mavac_sota'` 动态获取并实例化该模型。这种设计模式广泛应用于深度学习框架（如 Detectron2、MMDetection），以实现高度模块化和可配置化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import unittest\n",
    "from ding.model.template import MAVACSota\n",
    "from ding.torch_utils import to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMAVACSota(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.agent_obs_shape = 3\n",
    "        self.global_obs_shape = 9\n",
    "        self.action_shape = 2\n",
    "        self.agent_num = 4\n",
    "        self.action_space = 'discrete'\n",
    "\n",
    "    def test_compute_actor_discrete(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, action_space='discrete'\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'action_mask': torch.ones(4, self.action_shape)\n",
    "        }\n",
    "        actor_outputs = model(inputs, 'compute_actor')\n",
    "        print(\"actor_outputs shape \", actor_outputs['logit'].shape)\n",
    "        self.assertEqual(actor_outputs['logit'].shape, torch.Size([4, self.action_shape]))\n",
    "\n",
    "    def test_compute_actor_continuous(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, action_space='continuous'\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'action_mask': torch.ones(4, self.action_shape)\n",
    "        }\n",
    "        actor_outputs = model(inputs, 'compute_actor')\n",
    "        self.assertEqual(actor_outputs['logit'].shape, torch.Size([4, self.action_shape]))\n",
    "\n",
    "    def test_compute_critic_sota(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, sota=True\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape)\n",
    "        }\n",
    "        critic_outputs = model(inputs, 'compute_critic')\n",
    "        self.assertEqual(critic_outputs['value'].shape, torch.Size([4]))\n",
    "\n",
    "    def test_compute_critic_non_sota(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, sota=False\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape)\n",
    "        }\n",
    "        critic_outputs = model(inputs, 'compute_critic')\n",
    "        self.assertEqual(critic_outputs['value'].shape, torch.Size([4]))\n",
    "\n",
    "    def test_compute_actor_critic(self):\n",
    "        model = MAVACSota(\n",
    "            self.agent_obs_shape, self.global_obs_shape, self.action_shape, self.agent_num, action_space='discrete'\n",
    "        )\n",
    "        inputs = {\n",
    "            'agent_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'cls_state': torch.randn(4, self.agent_obs_shape),\n",
    "            'global_state': torch.randn(4, self.global_obs_shape),\n",
    "            'action_mask': torch.ones(4, self.action_shape)\n",
    "        }\n",
    "        outputs = model(inputs, 'compute_actor_critic')\n",
    "        self.assertEqual(outputs['logit'].shape, torch.Size([4, self.action_shape]))\n",
    "        self.assertEqual(outputs['value'].shape, torch.Size([4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavac_sota_test = TestMAVACSota()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mavac_sota_test\u001b[38;5;241m.\u001b[39msetUp()\n\u001b[1;32m----> 2\u001b[0m mavac_sota_test\u001b[38;5;241m.\u001b[39mtest_compute_actor_continuous()\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mTestMAVACSota.test_compute_actor_continuous\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_obs_shape),\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_shape)\n\u001b[0;32m     28\u001b[0m }\n\u001b[0;32m     29\u001b[0m actor_outputs \u001b[38;5;241m=\u001b[39m model(inputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_actor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massertEqual(actor_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, torch\u001b[38;5;241m.\u001b[39mSize([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_shape]))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "mavac_sota_test.setUp()\n",
    "mavac_sota_test.test_compute_actor_continuous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
