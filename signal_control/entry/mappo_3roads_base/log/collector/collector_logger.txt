[2024-12-27 11:56:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 12
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 14.454333242714641
avg_train_sample_per_sec: 14.454333242714641
avg_episode_per_sec: 0.12460632105788484
collect_time: 96.3033006521836
reward_mean: -318.5188492063492
reward_std: 36.040009810306145
reward_max: -272.93767507002786
reward_min: -393.95308123249293
queue_len: 0.21121939602543052
wait_time: 1.9549970960975018
delay_time: 16.116806741714793
pressure: 2.6080349248452697
total_envstep_count: 1392
total_train_sample_count: 1392
total_episode_count: 12
total_duration: 96.3033006521836
[2024-12-27 11:57:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.127550675490193
avg_train_sample_per_sec: 15.127550675490193
avg_episode_per_sec: 0.13040991961629478
collect_time: 46.00877002036199
reward_mean: -257.77649393090564
reward_std: 26.68549246074609
reward_max: -214.2801120448179
reward_min: -299.6365546218486
queue_len: 0.1709393195828287
wait_time: 1.6599309595633125
delay_time: 11.992341448122014
pressure: 2.0865384615384612
total_envstep_count: 2088
total_train_sample_count: 2088
total_episode_count: 18
total_duration: 142.3120706725456
[2024-12-27 11:58:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.087649671201316
avg_train_sample_per_sec: 15.087649671201316
avg_episode_per_sec: 0.13006594544139066
collect_time: 46.13044544164464
reward_mean: -256.1178804855275
reward_std: 16.25303342239402
reward_max: -238.4908963585434
reward_min: -285.2408963585434
queue_len: 0.16983944329279013
wait_time: 1.627232181555204
delay_time: 12.228265216290616
pressure: 2.036472148541114
total_envstep_count: 2784
total_train_sample_count: 2784
total_episode_count: 24
total_duration: 188.44251611419023
[2024-12-27 11:58:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.579003711705269
avg_train_sample_per_sec: 15.579003711705269
avg_episode_per_sec: 0.13430175613539025
collect_time: 44.67551410088317
reward_mean: -222.97619047619045
reward_std: 8.89810115371741
reward_max: -211.4243697478992
reward_min: -238.05952380952374
queue_len: 0.14786219527598835
wait_time: 1.506631841507602
delay_time: 9.420725862372844
pressure: 1.8007294429708223
total_envstep_count: 3480
total_train_sample_count: 3480
total_episode_count: 30
total_duration: 233.1180302150734
[2024-12-27 11:59:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.551159197196853
avg_train_sample_per_sec: 15.551159197196853
avg_episode_per_sec: 0.13406171721721424
collect_time: 44.75550607992337
reward_mean: -205.51844070961718
reward_std: 5.876225170000795
reward_max: -196.99579831932775
reward_min: -214.25070028011206
queue_len: 0.13628543813635094
wait_time: 1.3851925274972945
delay_time: 8.763614812914355
pressure: 1.653846153846154
total_envstep_count: 4176
total_train_sample_count: 4176
total_episode_count: 36
total_duration: 277.87353629499677
[2024-12-27 12:00:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.790190395682622
avg_train_sample_per_sec: 15.790190395682622
avg_episode_per_sec: 0.13612233099726398
collect_time: 44.07799922351167
reward_mean: -184.44105975723622
reward_std: 7.140097797066299
reward_max: -171.33193277310923
reward_min: -191.73459383753502
queue_len: 0.12230839506448025
wait_time: 1.2515741597257823
delay_time: 7.485323129268427
pressure: 1.4974580017683465
total_envstep_count: 4872
total_train_sample_count: 4872
total_episode_count: 42
total_duration: 321.9515355185084
[2024-12-27 12:01:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.024614651233332
avg_train_sample_per_sec: 16.024614651233332
avg_episode_per_sec: 0.1381432297520115
collect_time: 43.433181711263956
reward_mean: -178.30333800186744
reward_std: 5.817371932954799
reward_max: -169.7240896358543
reward_min: -185.3025210084034
queue_len: 0.11823828779964683
wait_time: 1.2124354825926833
delay_time: 7.27263957275542
pressure: 1.4413129973474803
total_envstep_count: 5568
total_train_sample_count: 5568
total_episode_count: 48
total_duration: 365.3847172297724
[2024-12-27 12:01:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.393403893142345
avg_train_sample_per_sec: 16.393403893142345
avg_episode_per_sec: 0.1413224473546754
collect_time: 42.456100303314635
reward_mean: -165.94677871148463
reward_std: 6.164438398905797
reward_max: -156.72198879551826
reward_min: -176.84663865546221
queue_len: 0.11004428296517547
wait_time: 1.1119543418605284
delay_time: 6.658183593510294
pressure: 1.3618479221927497
total_envstep_count: 6264
total_train_sample_count: 6264
total_episode_count: 54
total_duration: 407.84081753308703
[2024-12-27 12:02:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.92954443704939
avg_train_sample_per_sec: 15.92954443704939
avg_episode_per_sec: 0.13732365894008094
collect_time: 43.69239828235284
reward_mean: -164.84173669467785
reward_std: 7.199351294457741
reward_max: -156.05672268907563
reward_min: -174.60014005602244
queue_len: 0.10931149648188186
wait_time: 1.1000177701496159
delay_time: 6.804369785590961
pressure: 1.3470380194518123
total_envstep_count: 6960
total_train_sample_count: 6960
total_episode_count: 60
total_duration: 451.53321581543986
[2024-12-27 12:03:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.23233461818632
avg_train_sample_per_sec: 16.23233461818632
avg_episode_per_sec: 0.13993391912229589
collect_time: 42.87738124990463
reward_mean: -154.46837068160596
reward_std: 3.2038496371879512
reward_max: -147.3718487394958
reward_min: -156.84033613445382
queue_len: 0.10243260655278912
wait_time: 1.0248874969970305
delay_time: 6.021403906397908
pressure: 1.260057471264368
total_envstep_count: 7656
total_train_sample_count: 7656
total_episode_count: 66
total_duration: 494.4105970653445
[2024-12-27 12:04:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61836325567987
avg_train_sample_per_sec: 16.61836325567987
avg_episode_per_sec: 0.1432617522041368
collect_time: 41.88138081300631
reward_mean: -152.75431839402427
reward_std: 7.427868292152522
reward_max: -140.51190476190476
reward_min: -162.50980392156856
queue_len: 0.10129596710479062
wait_time: 0.9999196628253424
delay_time: 6.214049653504674
pressure: 1.230106100795756
total_envstep_count: 8352
total_train_sample_count: 8352
total_episode_count: 72
total_duration: 536.2919778783508
[2024-12-27 12:04:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.637731629461527
avg_train_sample_per_sec: 16.637731629461527
avg_episode_per_sec: 0.14342872094363385
collect_time: 41.83262571488694
reward_mean: -150.0215919701214
reward_std: 6.054451128644422
reward_max: -141.140756302521
reward_min: -155.96358543417367
queue_len: 0.09948381430379401
wait_time: 0.9848261032971988
delay_time: 6.072724402349178
pressure: 1.2104332449160038
total_envstep_count: 9048
total_train_sample_count: 9048
total_episode_count: 78
total_duration: 578.1246035932378
[2024-12-27 12:05:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.316081310411743
avg_train_sample_per_sec: 16.316081310411743
avg_episode_per_sec: 0.14065587336561847
collect_time: 42.65730151490868
reward_mean: -147.9512138188609
reward_std: 3.3704998952006036
reward_max: -143.33683473389362
reward_min: -153.39775910364148
queue_len: 0.09811088449526584
wait_time: 0.9712761320266391
delay_time: 5.933704530464688
pressure: 1.1920866489832007
total_envstep_count: 9744
total_train_sample_count: 9744
total_episode_count: 84
total_duration: 620.7819051081465
[2024-12-27 12:06:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.145215911929576
avg_train_sample_per_sec: 16.145215911929576
avg_episode_per_sec: 0.13918289579249635
collect_time: 43.10874526526034
reward_mean: -143.4234360410831
reward_std: 2.1626358791360363
reward_max: -139.9747899159664
reward_min: -146.82142857142864
queue_len: 0.09510837933758826
wait_time: 0.934584565479596
delay_time: 5.862211338383368
pressure: 1.1568302387267906
total_envstep_count: 10440
total_train_sample_count: 10440
total_episode_count: 90
total_duration: 663.8906503734069
[2024-12-27 12:06:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.695230728357362
avg_train_sample_per_sec: 16.695230728357362
avg_episode_per_sec: 0.1439244028306669
collect_time: 41.688552337154746
reward_mean: -142.53186274509804
reward_std: 3.2553650586246703
reward_max: -138.24019607843135
reward_min: -147.31442577030816
queue_len: 0.09451715036147085
wait_time: 0.9337294157273875
delay_time: 5.734002001478402
pressure: 1.1486516357206014
total_envstep_count: 11136
total_train_sample_count: 11136
total_episode_count: 96
total_duration: 705.5792027105616
[2024-12-27 12:07:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.18150897831996
avg_train_sample_per_sec: 16.18150897831996
avg_episode_per_sec: 0.1394957670544824
collect_time: 43.012057832956316
reward_mean: -142.2733426704015
reward_std: 3.7932883846857317
reward_max: -137.7563025210084
reward_min: -148.05882352941168
queue_len: 0.09434571795119462
wait_time: 0.9353355400515645
delay_time: 5.634710111466604
pressure: 1.1541777188328912
total_envstep_count: 11832
total_train_sample_count: 11832
total_episode_count: 102
total_duration: 748.5912605435179
[2024-12-27 12:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.299354975021682
avg_train_sample_per_sec: 16.299354975021682
avg_episode_per_sec: 0.14051168081915244
collect_time: 42.70107627366856
reward_mean: -136.4389589169001
reward_std: 4.132961827448078
reward_max: -130.45448179271705
reward_min: -142.78151260504205
queue_len: 0.09047676320749344
wait_time: 0.8890183726010298
delay_time: 5.498660043952281
pressure: 1.0978116710875332
total_envstep_count: 12528
total_train_sample_count: 12528
total_episode_count: 108
total_duration: 791.2923368171865
[2024-12-27 12:09:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.836176993603548
avg_train_sample_per_sec: 16.836176993603548
avg_episode_per_sec: 0.1451394568414099
collect_time: 41.33955115014688
reward_mean: -139.73190943043883
reward_std: 6.110876307912505
reward_max: -131.8067226890756
reward_min: -148.59313725490193
queue_len: 0.09266041739419022
wait_time: 0.9046379161744271
delay_time: 5.549079473015936
pressure: 1.12842617152962
total_envstep_count: 13224
total_train_sample_count: 13224
total_episode_count: 114
total_duration: 832.6318879673335
[2024-12-27 12:09:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5062584103909
avg_train_sample_per_sec: 16.5062584103909
avg_episode_per_sec: 0.14229533112405945
collect_time: 42.165824785698206
reward_mean: -133.32084500466854
reward_std: 1.9937506251518022
reward_max: -130.04971988795515
reward_min: -136.60784313725492
queue_len: 0.08840904841158391
wait_time: 0.8634060609212738
delay_time: 5.24479648577176
pressure: 1.0740495137046862
total_envstep_count: 13920
total_train_sample_count: 13920
total_episode_count: 120
total_duration: 874.7977127530316
[2024-12-27 12:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7079102992172
avg_train_sample_per_sec: 16.7079102992172
avg_episode_per_sec: 0.14403370947601032
collect_time: 41.656915050148974
reward_mean: -135.41129785247432
reward_std: 3.3840878200079865
reward_max: -128.593837535014
reward_min: -138.733893557423
queue_len: 0.08979529035309969
wait_time: 0.877606391805175
delay_time: 5.4076629897144635
pressure: 1.1036693191865605
total_envstep_count: 14616
total_train_sample_count: 14616
total_episode_count: 126
total_duration: 916.4546278031806
[2024-12-27 12:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.72015026884531
avg_train_sample_per_sec: 16.72015026884531
avg_episode_per_sec: 0.144139226455563
collect_time: 41.6264201462865
reward_mean: -136.59873949579836
reward_std: 2.7795265642817015
reward_max: -133.7296918767507
reward_min: -140.24159663865544
queue_len: 0.09058271849854
wait_time: 0.8869958571403803
delay_time: 5.468120272917557
pressure: 1.1037798408488064
total_envstep_count: 15312
total_train_sample_count: 15312
total_episode_count: 132
total_duration: 958.0810479494671
[2024-12-27 12:11:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.629638311533288
avg_train_sample_per_sec: 16.629638311533288
avg_episode_per_sec: 0.14335895096149387
collect_time: 41.85298483114317
reward_mean: -134.94234360410834
reward_std: 3.0333256268006106
reward_max: -130.0770308123249
reward_min: -139.67927170868353
queue_len: 0.08948431273481984
wait_time: 0.880236699012054
delay_time: 5.3471466542153125
pressure: 1.1054376657824934
total_envstep_count: 16008
total_train_sample_count: 16008
total_episode_count: 138
total_duration: 999.9340327806103
[2024-12-27 12:12:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.732267332923836
avg_train_sample_per_sec: 16.732267332923836
avg_episode_per_sec: 0.14424368390451583
collect_time: 41.596275397207584
reward_mean: -136.32738095238096
reward_std: 4.980637044567346
reward_max: -128.43767507002804
reward_min: -143.03781512605045
queue_len: 0.09040277251484148
wait_time: 0.8847713378012566
delay_time: 5.480273844943079
pressure: 1.1085322723253759
total_envstep_count: 16704
total_train_sample_count: 16704
total_episode_count: 144
total_duration: 1041.530308177818
[2024-12-27 12:13:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.528842780528716
avg_train_sample_per_sec: 16.528842780528716
avg_episode_per_sec: 0.14249002397007515
collect_time: 42.10821103700623
reward_mean: -133.10830999066295
reward_std: 3.188066663030159
reward_max: -128.18067226890753
reward_min: -138.1470588235294
queue_len: 0.0882681100733839
wait_time: 0.8681659224255572
delay_time: 5.378829875239447
pressure: 1.0706233421750664
total_envstep_count: 17400
total_train_sample_count: 17400
total_episode_count: 150
total_duration: 1083.638519214824
[2024-12-27 12:13:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.671783791836173
avg_train_sample_per_sec: 16.671783791836173
avg_episode_per_sec: 0.14372227406755322
collect_time: 41.74718246651068
reward_mean: -131.08333333333334
reward_std: 6.142482869043162
reward_max: -121.49159663865544
reward_min: -138.57563025210086
queue_len: 0.08692528735632184
wait_time: 0.8491671093724847
delay_time: 5.244597023799852
pressure: 1.0571396993810787
total_envstep_count: 18096
total_train_sample_count: 18096
total_episode_count: 156
total_duration: 1125.3857016813347
[2024-12-27 12:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.564483335124798
avg_train_sample_per_sec: 16.564483335124798
avg_episode_per_sec: 0.14279727013038618
collect_time: 42.01760996216163
reward_mean: -133.1281512605042
reward_std: 3.010008964030874
reward_max: -128.1155462184874
reward_min: -137.27521008403363
queue_len: 0.08828126741412747
wait_time: 0.8678447285191706
delay_time: 5.360995320956417
pressure: 1.081896551724138
total_envstep_count: 18792
total_train_sample_count: 18792
total_episode_count: 162
total_duration: 1167.4033116434964
[2024-12-27 12:15:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.32778224210304
avg_train_sample_per_sec: 16.32778224210304
avg_episode_per_sec: 0.14075674346640552
collect_time: 42.62673213544488
reward_mean: -133.32236227824464
reward_std: 5.366940392773567
reward_max: -123.65336134453784
reward_min: -139.70588235294113
queue_len: 0.08841005456117018
wait_time: 0.8699874401573183
delay_time: 5.355026863171015
pressure: 1.0816755083996463
total_envstep_count: 19488
total_train_sample_count: 19488
total_episode_count: 168
total_duration: 1210.0300437789413
[2024-12-27 12:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.560200920652388
avg_train_sample_per_sec: 16.560200920652388
avg_episode_per_sec: 0.14276035276424473
collect_time: 42.02847558039055
reward_mean: -133.7546685340803
reward_std: 2.4467415548911315
reward_max: -131.03711484593836
reward_min: -136.33193277310926
queue_len: 0.0886967297971355
wait_time: 0.8740352573390099
delay_time: 5.3927232429963565
pressure: 1.0812334217506632
total_envstep_count: 20184
total_train_sample_count: 20184
total_episode_count: 174
total_duration: 1252.0585193593317
[2024-12-27 12:16:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.638691791020616
avg_train_sample_per_sec: 16.638691791020616
avg_episode_per_sec: 0.1434369981984536
collect_time: 41.83021169823036
reward_mean: -131.73155929038282
reward_std: 3.503786504227398
reward_max: -125.69607843137257
reward_min: -136.73529411764707
queue_len: 0.08735514541802573
wait_time: 0.8508127057188922
delay_time: 5.353885505236036
pressure: 1.0617816091954022
total_envstep_count: 20880
total_train_sample_count: 20880
total_episode_count: 180
total_duration: 1293.8887310575622
[2024-12-27 12:17:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.706871350936265
avg_train_sample_per_sec: 16.706871350936265
avg_episode_per_sec: 0.14402475302531262
collect_time: 41.65950556391851
reward_mean: -132.36239495798318
reward_std: 3.1865084601832936
reward_max: -128.06442577030808
reward_min: -137.44327731092437
queue_len: 0.08777347145754855
wait_time: 0.8586441871178181
delay_time: 5.433783924693581
pressure: 1.066976127320955
total_envstep_count: 21576
total_train_sample_count: 21576
total_episode_count: 186
total_duration: 1335.5482366214806
[2024-12-27 12:18:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.605748388055616
avg_train_sample_per_sec: 16.605748388055616
avg_episode_per_sec: 0.14315300334530703
collect_time: 41.913196787964544
reward_mean: -130.87686741363208
reward_std: 2.3372463042898346
reward_max: -127.51750700280112
reward_min: -134.6358543417367
queue_len: 0.08678837361646691
wait_time: 0.8494355191236531
delay_time: 5.191759549559837
pressure: 1.0624447391688772
total_envstep_count: 22272
total_train_sample_count: 22272
total_episode_count: 192
total_duration: 1377.4614334094451
[2024-12-27 12:18:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.419015482325523
avg_train_sample_per_sec: 16.419015482325523
avg_episode_per_sec: 0.14154323691659934
collect_time: 42.389874152272945
reward_mean: -133.5813492063492
reward_std: 5.256321699789518
reward_max: -125.68067226890756
reward_min: -141.3452380952381
queue_len: 0.0885817965559345
wait_time: 0.8676141654716706
delay_time: 5.381070853012443
pressure: 1.0919540229885059
total_envstep_count: 22968
total_train_sample_count: 22968
total_episode_count: 198
total_duration: 1419.8513075617182
[2024-12-27 12:19:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.854597140577944
avg_train_sample_per_sec: 16.854597140577944
avg_episode_per_sec: 0.14529825121187884
collect_time: 41.294371748842295
reward_mean: -131.39169000933708
reward_std: 6.1026459731623826
reward_max: -121.9712885154062
reward_min: -140.41666666666666
queue_len: 0.08712976791070098
wait_time: 0.8478390693147286
delay_time: 5.330863015359157
pressure: 1.0543766578249336
total_envstep_count: 23664
total_train_sample_count: 23664
total_episode_count: 204
total_duration: 1461.1456793105604
[2024-12-27 12:20:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83118505687247
avg_train_sample_per_sec: 16.83118505687247
avg_episode_per_sec: 0.145096422904073
collect_time: 41.35181198758259
reward_mean: -130.63352007469655
reward_std: 3.6944016436471347
reward_max: -125.55462184873949
reward_min: -137.9047619047619
queue_len: 0.08662700270205342
wait_time: 0.8411710064220208
delay_time: 5.303906778898653
pressure: 1.04763483642794
total_envstep_count: 24360
total_train_sample_count: 24360
total_episode_count: 210
total_duration: 1502.497491298143
[2024-12-27 12:21:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.771843134235418
avg_train_sample_per_sec: 16.771843134235418
avg_episode_per_sec: 0.14458485460547774
collect_time: 41.498122444234795
reward_mean: -133.79691876750698
reward_std: 4.9228353888577105
reward_max: -126.61624649859942
reward_min: -141.08123249299717
queue_len: 0.08872474719330703
wait_time: 0.8698101256417686
delay_time: 5.41427888185157
pressure: 1.0810123784261716
total_envstep_count: 25056
total_train_sample_count: 25056
total_episode_count: 216
total_duration: 1543.9956137423776
[2024-12-27 12:21:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.666764480534482
avg_train_sample_per_sec: 16.666764480534482
avg_episode_per_sec: 0.14367900414253862
collect_time: 41.759754919011144
reward_mean: -132.15978057889822
reward_std: 2.807975692289723
reward_max: -128.20868347338936
reward_min: -136.30532212885151
queue_len: 0.08763911178972032
wait_time: 0.8586678703311562
delay_time: 5.347961110102609
pressure: 1.0468611847922193
total_envstep_count: 25752
total_train_sample_count: 25752
total_episode_count: 222
total_duration: 1585.7553686613887
[2024-12-27 12:22:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.879211265574007
avg_train_sample_per_sec: 16.879211265574007
avg_episode_per_sec: 0.14551044194460352
collect_time: 41.23415419413149
reward_mean: -132.85655929038282
reward_std: 7.079437537058429
reward_max: -122.20448179271709
reward_min: -143.1162464985994
queue_len: 0.0881011666381849
wait_time: 0.8550423263912109
delay_time: 5.430393477445442
pressure: 1.0654288240495138
total_envstep_count: 26448
total_train_sample_count: 26448
total_episode_count: 228
total_duration: 1626.9895228555201
[2024-12-27 12:23:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.732307422593287
avg_train_sample_per_sec: 16.732307422593287
avg_episode_per_sec: 0.14424402950511456
collect_time: 41.59617573486641
reward_mean: -133.96125116713355
reward_std: 3.698674152420067
reward_max: -129.35714285714286
reward_min: -140.34103641456585
queue_len: 0.08883372093311243
wait_time: 0.8720239643160537
delay_time: 5.4014384099996535
pressure: 1.0821175950486295
total_envstep_count: 27144
total_train_sample_count: 27144
total_episode_count: 234
total_duration: 1668.5856985903865
[2024-12-27 12:23:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61596331443222
avg_train_sample_per_sec: 16.61596331443222
avg_episode_per_sec: 0.1432410630554502
collect_time: 41.88742998700962
reward_mean: -135.41036414565826
reward_std: 5.469807879464293
reward_max: -125.29621848739491
reward_min: -143.21778711484595
queue_len: 0.0897946711841235
wait_time: 0.8843540953074421
delay_time: 5.487195066928166
pressure: 1.095711759504863
total_envstep_count: 27840
total_train_sample_count: 27840
total_episode_count: 240
total_duration: 1710.4731285773962
[2024-12-27 12:24:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.80319715121175
avg_train_sample_per_sec: 16.80319715121175
avg_episode_per_sec: 0.14485514785527373
collect_time: 41.420688797298816
reward_mean: -131.64320728291315
reward_std: 3.8152000613492856
reward_max: -126.59313725490192
reward_min: -138.40616246498598
queue_len: 0.08729655655365594
wait_time: 0.8476564918628814
delay_time: 5.3017092459462125
pressure: 1.0689655172413792
total_envstep_count: 28536
total_train_sample_count: 28536
total_episode_count: 246
total_duration: 1751.8938173746951
[2024-12-27 12:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.630348510863186
avg_train_sample_per_sec: 16.630348510863186
avg_episode_per_sec: 0.14336507336951024
collect_time: 41.851197498679156
reward_mean: -133.31792717086833
reward_std: 4.280721500244004
reward_max: -126.73389355742295
reward_min: -140.12394957983196
queue_len: 0.0884071135085334
wait_time: 0.8644690966572308
delay_time: 5.354587686306629
pressure: 1.0748231653404068
total_envstep_count: 29232
total_train_sample_count: 29232
total_episode_count: 252
total_duration: 1793.7450148733742
[2024-12-27 12:25:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.699471279375427
avg_train_sample_per_sec: 16.699471279375427
avg_episode_per_sec: 0.14396095930496056
collect_time: 41.67796622756496
reward_mean: -133.01633986928104
reward_std: 1.9743157903841042
reward_max: -129.67366946778714
reward_min: -135.42086834733894
queue_len: 0.08820712192923146
wait_time: 0.8680178636441314
delay_time: 5.442700263778211
pressure: 1.0695181255526083
total_envstep_count: 29928
total_train_sample_count: 29928
total_episode_count: 258
total_duration: 1835.422981100939
[2024-12-27 12:26:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54792385711463
avg_train_sample_per_sec: 16.54792385711463
avg_episode_per_sec: 0.14265451600960888
collect_time: 42.05965690981598
reward_mean: -134.18312324929968
reward_std: 4.814066224584753
reward_max: -124.84033613445376
reward_min: -141.12464985994396
queue_len: 0.0889808509610741
wait_time: 0.8697472799906877
delay_time: 5.450472299157972
pressure: 1.0673076923076923
total_envstep_count: 30624
total_train_sample_count: 30624
total_episode_count: 264
total_duration: 1877.482638010755
[2024-12-27 12:27:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56915501458628
avg_train_sample_per_sec: 16.56915501458628
avg_episode_per_sec: 0.14283754322919207
collect_time: 42.005763081297275
reward_mean: -128.79388422035478
reward_std: 4.022678969291838
reward_max: -122.51330532212884
reward_min: -134.67226890756302
queue_len: 0.08540708502676048
wait_time: 0.8321744038021929
delay_time: 5.153223738093251
pressure: 1.036030061892131
total_envstep_count: 31320
total_train_sample_count: 31320
total_episode_count: 270
total_duration: 1919.4884010920523
[2024-12-27 12:28:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.400970429636644
avg_train_sample_per_sec: 16.400970429636644
avg_episode_per_sec: 0.1413876761175573
collect_time: 42.43651331401245
reward_mean: -132.68662464985997
reward_std: 4.119563049274224
reward_max: -127.51400560224089
reward_min: -138.76540616246496
queue_len: 0.08798847788452252
wait_time: 0.8619712916112512
delay_time: 5.531655290712351
pressure: 1.0594606542882403
total_envstep_count: 32016
total_train_sample_count: 32016
total_episode_count: 276
total_duration: 1961.9249144060648
[2024-12-27 12:28:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.733042055602297
avg_train_sample_per_sec: 16.733042055602297
avg_episode_per_sec: 0.14425036254829568
collect_time: 41.594349532336
reward_mean: -128.98144257703083
reward_std: 1.7020285553690906
reward_max: -126.62535014005604
reward_min: -131.6841736694678
queue_len: 0.08553146059484802
wait_time: 0.8341752483486763
delay_time: 5.29106505420744
pressure: 1.0350353669319186
total_envstep_count: 32712
total_train_sample_count: 32712
total_episode_count: 282
total_duration: 2003.5192639384009
[2024-12-27 12:29:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53345751958193
avg_train_sample_per_sec: 16.53345751958193
avg_episode_per_sec: 0.1425298062032925
collect_time: 42.0964579958953
reward_mean: -130.95436507936506
reward_std: 3.011915790541053
reward_max: -125.26680672268907
reward_min: -134.15196078431376
queue_len: 0.08683976464148879
wait_time: 0.8440129146265049
delay_time: 5.373382828468821
pressure: 1.051945181255526
total_envstep_count: 33408
total_train_sample_count: 33408
total_episode_count: 288
total_duration: 2045.615721934296
[2024-12-27 12:30:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.92420729511423
avg_train_sample_per_sec: 16.92420729511423
avg_episode_per_sec: 0.14589833875098474
collect_time: 41.12452582644299
reward_mean: -131.60749299719888
reward_std: 2.3316626256348347
reward_max: -129.1323529411765
reward_min: -134.5770308123249
queue_len: 0.08727287334031757
wait_time: 0.8555201700485678
delay_time: 5.352212659445148
pressure: 1.0623342175066313
total_envstep_count: 34104
total_train_sample_count: 34104
total_episode_count: 294
total_duration: 2086.740247760739
[2024-12-27 12:30:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.515816080910938
avg_train_sample_per_sec: 16.515816080910938
avg_episode_per_sec: 0.14237772483543912
collect_time: 42.141423505220565
reward_mean: -127.23097572362276
reward_std: 2.424277690826771
reward_max: -123.60644257703083
reward_min: -129.57072829131653
queue_len: 0.08437067355677903
wait_time: 0.8206093334769804
delay_time: 5.243674962507106
pressure: 1.0321618037135278
total_envstep_count: 34800
total_train_sample_count: 34800
total_episode_count: 300
total_duration: 2128.8816712659595
[2024-12-27 12:31:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.79314982586867
avg_train_sample_per_sec: 16.79314982586867
avg_episode_per_sec: 0.14476853298162648
collect_time: 41.44547075545415
reward_mean: -129.56769374416436
reward_std: 3.440763689718736
reward_max: -123.1043417366947
reward_min: -133.47689075630257
queue_len: 0.08592022131575887
wait_time: 0.8382447364445337
delay_time: 5.176336340557502
pressure: 1.04210875331565
total_envstep_count: 35496
total_train_sample_count: 35496
total_episode_count: 306
total_duration: 2170.3271420214137
[2024-12-27 12:32:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.404834065425064
avg_train_sample_per_sec: 16.404834065425064
avg_episode_per_sec: 0.14142098332262987
collect_time: 42.42651874589175
reward_mean: -129.1706349206349
reward_std: 3.5637992160049636
reward_max: -125.03571428571428
reward_min: -136.5882352941177
queue_len: 0.08565691970864385
wait_time: 0.8347407818122828
delay_time: 5.251487213622142
pressure: 1.04210875331565
total_envstep_count: 36192
total_train_sample_count: 36192
total_episode_count: 312
total_duration: 2212.7536607673055
[2024-12-27 12:33:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.750328118181073
avg_train_sample_per_sec: 16.750328118181073
avg_episode_per_sec: 0.14439938032914718
collect_time: 41.55142484907806
reward_mean: -128.55287114845933
reward_std: 2.5497675777836806
reward_max: -125.18907563025208
reward_min: -131.9327731092437
queue_len: 0.08524726203478737
wait_time: 0.8295507526618074
delay_time: 5.249385346313727
pressure: 1.0377984084880636
total_envstep_count: 36888
total_train_sample_count: 36888
total_episode_count: 318
total_duration: 2254.3050856163836
[2024-12-27 12:33:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.40116592597919
avg_train_sample_per_sec: 16.40116592597919
avg_episode_per_sec: 0.14138936143085507
collect_time: 42.43600748514756
reward_mean: -127.84115312791785
reward_std: 2.3482641876180788
reward_max: -125.38025210084038
reward_min: -131.76260504201682
queue_len: 0.08477530048270414
wait_time: 0.8276222734894133
delay_time: 5.227622292721883
pressure: 1.0263041556145005
total_envstep_count: 37584
total_train_sample_count: 37584
total_episode_count: 324
total_duration: 2296.741093101531
[2024-12-27 12:34:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.946856756970647
avg_train_sample_per_sec: 16.946856756970647
avg_episode_per_sec: 0.14609359273250558
collect_time: 41.069562927279634
reward_mean: -128.86811391223156
reward_std: 3.9091588415912364
reward_max: -123.08683473389351
reward_min: -133.89915966386556
queue_len: 0.08545630896036573
wait_time: 0.8343940471856294
delay_time: 5.153382534307386
pressure: 1.0444297082228116
total_envstep_count: 38280
total_train_sample_count: 38280
total_episode_count: 330
total_duration: 2337.8106560288106
[2024-12-27 12:35:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.796088357603885
avg_train_sample_per_sec: 16.796088357603885
avg_episode_per_sec: 0.14479386515175763
collect_time: 41.438219731971614
reward_mean: -127.97152194211014
reward_std: 5.2576857431256
reward_max: -121.59313725490193
reward_min: -137.05112044817926
queue_len: 0.08486175195100143
wait_time: 0.8247850864483723
delay_time: 5.2139113189911255
pressure: 1.0351458885941645
total_envstep_count: 38976
total_train_sample_count: 38976
total_episode_count: 336
total_duration: 2379.248875760782
[2024-12-27 12:35:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.758883655852536
avg_train_sample_per_sec: 16.758883655852536
avg_episode_per_sec: 0.144473134964246
collect_time: 41.530212530411774
reward_mean: -127.71253501400564
reward_std: 3.314273660937007
reward_max: -121.63165266106444
reward_min: -130.4754901960785
queue_len: 0.08469000995623714
wait_time: 0.8262154441794402
delay_time: 5.143229846376664
pressure: 1.033709106984969
total_envstep_count: 39672
total_train_sample_count: 39672
total_episode_count: 342
total_duration: 2420.779088291194
[2024-12-27 12:36:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.449069407745316
avg_train_sample_per_sec: 16.449069407745316
avg_episode_per_sec: 0.14180232248056307
collect_time: 42.3124240494892
reward_mean: -129.4264705882353
reward_std: 1.7379031818237076
reward_max: -127.29551820728294
reward_min: -132.77170868347338
queue_len: 0.0858265720081136
wait_time: 0.8386274602679268
delay_time: 5.218340546254361
pressure: 1.0509504862953138
total_envstep_count: 40368
total_train_sample_count: 40368
total_episode_count: 348
total_duration: 2463.091512340683
[2024-12-27 12:37:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.508516016814383
avg_train_sample_per_sec: 16.508516016814383
avg_episode_per_sec: 0.14231479324839985
collect_time: 42.1600584383905
reward_mean: -129.54913632119514
reward_std: 4.643326655641396
reward_max: -121.91736694677869
reward_min: -134.55252100840332
queue_len: 0.08590791533235752
wait_time: 0.8378320603219184
delay_time: 5.342193334571682
pressure: 1.031498673740053
total_envstep_count: 41064
total_train_sample_count: 41064
total_episode_count: 354
total_duration: 2505.2515707790735
[2024-12-27 12:38:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.6603470721414
avg_train_sample_per_sec: 16.6603470721414
avg_episode_per_sec: 0.1436236816563914
collect_time: 41.77584038233012
reward_mean: -128.5922035480859
reward_std: 3.9200324761301597
reward_max: -122.46358543417368
reward_min: -134.406862745098
queue_len: 0.08527334452790843
wait_time: 0.8392112592163302
delay_time: 5.15701268208165
pressure: 1.041887709991158
total_envstep_count: 41760
total_train_sample_count: 41760
total_episode_count: 360
total_duration: 2547.0274111614035
[2024-12-27 12:38:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.58926424782356
avg_train_sample_per_sec: 16.58926424782356
avg_episode_per_sec: 0.14301089868813416
collect_time: 41.95484438626096
reward_mean: -127.61729691876752
reward_std: 2.482834380857669
reward_max: -124.17507002801122
reward_min: -131.08893557422968
queue_len: 0.08462685472066811
wait_time: 0.827939442797455
delay_time: 5.108081800976934
pressure: 1.0250884173297965
total_envstep_count: 42456
total_train_sample_count: 42456
total_episode_count: 366
total_duration: 2588.9822555476644
[2024-12-27 12:39:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81834389017492
avg_train_sample_per_sec: 16.81834389017492
avg_episode_per_sec: 0.1449857231911631
collect_time: 41.383384983975446
reward_mean: -126.70308123249299
reward_std: 2.2677698269031183
reward_max: -124.30392156862746
reward_min: -131.4131652661065
queue_len: 0.08402061089687864
wait_time: 0.8196932729767415
delay_time: 5.012212640314584
pressure: 1.0277409372236959
total_envstep_count: 43152
total_train_sample_count: 43152
total_episode_count: 372
total_duration: 2630.3656405316397
[2024-12-27 12:40:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93338636208251
avg_train_sample_per_sec: 16.93338636208251
avg_episode_per_sec: 0.1459774686386423
collect_time: 41.102233488187196
reward_mean: -128.60399159663865
reward_std: 3.788388524111434
reward_max: -124.32212885154058
reward_min: -134.52661064425774
queue_len: 0.08528116153623254
wait_time: 0.8318879607545937
delay_time: 5.221258985316199
pressure: 1.0295092838196285
total_envstep_count: 43848
total_train_sample_count: 43848
total_episode_count: 378
total_duration: 2671.467874019827
[2024-12-27 12:40:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.710997338854128
avg_train_sample_per_sec: 16.710997338854128
avg_episode_per_sec: 0.1440603218866735
collect_time: 41.64921972560883
reward_mean: -126.79633520074697
reward_std: 5.146002839150979
reward_max: -119.33053221288517
reward_min: -133.9159663865546
queue_len: 0.08408245039837331
wait_time: 0.8158647190087353
delay_time: 5.146285082210551
pressure: 1.0170203359858532
total_envstep_count: 44544
total_train_sample_count: 44544
total_episode_count: 384
total_duration: 2713.117093745436
[2024-12-27 12:41:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.988263094930726
avg_train_sample_per_sec: 16.988263094930726
avg_episode_per_sec: 0.1464505439218166
collect_time: 40.969462040394546
reward_mean: -128.35037348272644
reward_std: 2.5456676559217013
reward_max: -124.52591036414567
reward_min: -131.99929971988797
queue_len: 0.08511297976308119
wait_time: 0.8333047741643077
delay_time: 5.145050265664929
pressure: 1.0406719717064543
total_envstep_count: 45240
total_train_sample_count: 45240
total_episode_count: 390
total_duration: 2754.0865557858306
[2024-12-27 12:42:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.355612270776923
avg_train_sample_per_sec: 16.355612270776923
avg_episode_per_sec: 0.14099665750669763
collect_time: 42.55420026332885
reward_mean: -130.77357609710552
reward_std: 3.0448821528382477
reward_max: -127.17857142857142
reward_min: -135.03641456582636
queue_len: 0.08671987804847846
wait_time: 0.8456204320808784
delay_time: 5.374034545445923
pressure: 1.0665340406719717
total_envstep_count: 45936
total_train_sample_count: 45936
total_episode_count: 396
total_duration: 2796.6407560491593
[2024-12-27 12:42:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.515611187808187
avg_train_sample_per_sec: 16.515611187808187
avg_episode_per_sec: 0.1423759585155878
collect_time: 42.141946312818675
reward_mean: -128.00116713352008
reward_std: 2.1735122023871614
reward_max: -125.56022408963582
reward_min: -131.84593837535016
queue_len: 0.08488141056599474
wait_time: 0.827476846176136
delay_time: 5.1971719796502205
pressure: 1.032714412024757
total_envstep_count: 46632
total_train_sample_count: 46632
total_episode_count: 402
total_duration: 2838.782702361978
[2024-12-27 12:43:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.462152541781382
avg_train_sample_per_sec: 16.462152541781382
avg_episode_per_sec: 0.141915108118805
collect_time: 42.278796666082
reward_mean: -127.76038748832866
reward_std: 1.780202787671923
reward_max: -124.92717086834733
reward_min: -130.57563025210084
queue_len: 0.08472174236626571
wait_time: 0.8259993542067577
delay_time: 5.175276255295441
pressure: 1.0423297966401417
total_envstep_count: 47328
total_train_sample_count: 47328
total_episode_count: 408
total_duration: 2881.06149902806
[2024-12-27 12:44:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.609746900204975
avg_train_sample_per_sec: 16.609746900204975
avg_episode_per_sec: 0.1431874732776291
collect_time: 41.903106903538124
reward_mean: -125.71265172735764
reward_std: 6.099020526962594
reward_max: -119.69327731092443
reward_min: -137.73249299719885
queue_len: 0.08336382740540958
wait_time: 0.8100905039292462
delay_time: 5.133520316996287
pressure: 1.0163572060123784
total_envstep_count: 48024
total_train_sample_count: 48024
total_episode_count: 414
total_duration: 2922.9646059315983
[2024-12-27 12:45:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.13361770071233
avg_train_sample_per_sec: 16.13361770071233
avg_episode_per_sec: 0.1390829112130373
collect_time: 43.13973548346012
reward_mean: -129.7706582633053
reward_std: 3.586542978524447
reward_max: -124.640056022409
reward_min: -133.99159663865547
queue_len: 0.08605481317195313
wait_time: 0.8393237157816266
delay_time: 5.291400577997749
pressure: 1.0460875331564987
total_envstep_count: 48720
total_train_sample_count: 48720
total_episode_count: 420
total_duration: 2966.1043414150586
[2024-12-27 12:45:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.394643118389922
avg_train_sample_per_sec: 16.394643118389922
avg_episode_per_sec: 0.1413331303309476
collect_time: 42.452891165364534
reward_mean: -128.1308356676004
reward_std: 3.8509694300312467
reward_max: -122.36764705882356
reward_min: -132.69397759103643
queue_len: 0.08496739765755994
wait_time: 0.8277226562596747
delay_time: 5.2639234965282125
pressure: 1.0438770999115825
total_envstep_count: 49416
total_train_sample_count: 49416
total_episode_count: 426
total_duration: 3008.5572325804233
[2024-12-27 12:46:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.679604085589254
avg_train_sample_per_sec: 16.679604085589254
avg_episode_per_sec: 0.14378969039301082
collect_time: 41.72760914639011
reward_mean: -125.81150793650791
reward_std: 4.201344979911373
reward_max: -120.69327731092433
reward_min: -132.91386554621846
queue_len: 0.08342938192076123
wait_time: 0.8091828022101857
delay_time: 5.1586711239953695
pressure: 1.0135941644562334
total_envstep_count: 50112
total_train_sample_count: 50112
total_episode_count: 432
total_duration: 3050.2848417268133
[2024-12-27 12:47:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.560852339821214
avg_train_sample_per_sec: 16.560852339821214
avg_episode_per_sec: 0.1427659684467346
collect_time: 42.02682239527255
reward_mean: -129.85574229691875
reward_std: 6.424458904373462
reward_max: -121.88375350140055
reward_min: -142.39565826330528
queue_len: 0.08611123494490634
wait_time: 0.8375288997119626
delay_time: 5.221776737567398
pressure: 1.0560344827586206
total_envstep_count: 50808
total_train_sample_count: 50808
total_episode_count: 438
total_duration: 3092.311664122086
[2024-12-27 12:47:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.631130442561492
avg_train_sample_per_sec: 16.631130442561492
avg_episode_per_sec: 0.14337181416001285
collect_time: 41.84922981656342
reward_mean: -126.08123249299719
reward_std: 4.330138211904879
reward_max: -120.87675070028008
reward_min: -134.0504201680673
queue_len: 0.08360824435875146
wait_time: 0.8058279125089469
delay_time: 5.083635032459566
pressure: 1.015473032714412
total_envstep_count: 51504
total_train_sample_count: 51504
total_episode_count: 444
total_duration: 3134.160893938649
[2024-12-27 12:48:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.754614071713515
avg_train_sample_per_sec: 16.754614071713515
avg_episode_per_sec: 0.14443632820442684
collect_time: 41.540795688934615
reward_mean: -127.91725023342671
reward_std: 3.6453458055519667
reward_max: -121.60574229691873
reward_min: -133.49299719887958
queue_len: 0.08482576275426175
wait_time: 0.8203998995707922
delay_time: 5.21657984338658
pressure: 1.0278514588859415
total_envstep_count: 52200
total_train_sample_count: 52200
total_episode_count: 450
total_duration: 3175.7016896275836
[2024-12-27 12:49:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.558413090387344
avg_train_sample_per_sec: 16.558413090387344
avg_episode_per_sec: 0.14274494043437366
collect_time: 42.033013441611075
reward_mean: -129.36309523809524
reward_std: 5.917551858585212
reward_max: -122.20868347338937
reward_min: -138.5280112044818
queue_len: 0.08578454591385626
wait_time: 0.8337730980986556
delay_time: 5.325945790766405
pressure: 1.0310565870910697
total_envstep_count: 52896
total_train_sample_count: 52896
total_episode_count: 456
total_duration: 3217.734703069195
[2024-12-27 12:50:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.570974938895937
avg_train_sample_per_sec: 16.570974938895937
avg_episode_per_sec: 0.14285323223186153
collect_time: 42.00114975530655
reward_mean: -128.48739495798318
reward_std: 4.596613211027557
reward_max: -123.94677871148461
reward_min: -135.18977591036418
queue_len: 0.08520384281033368
wait_time: 0.8295182462905587
delay_time: 5.2367832461552215
pressure: 1.0429929266136162
total_envstep_count: 53592
total_train_sample_count: 53592
total_episode_count: 462
total_duration: 3259.7358528245013
[2024-12-27 12:50:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.707071738400526
avg_train_sample_per_sec: 16.707071738400526
avg_episode_per_sec: 0.14402648050345282
collect_time: 41.65900589271262
reward_mean: -125.11181139122313
reward_std: 2.3566755644412853
reward_max: -121.829131652661
reward_min: -129.37184873949582
queue_len: 0.0829653921692461
wait_time: 0.8058012108468496
delay_time: 5.087057936800484
pressure: 1.0171308576480989
total_envstep_count: 54288
total_train_sample_count: 54288
total_episode_count: 468
total_duration: 3301.394858717214
[2024-12-27 12:51:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.38689515682117
avg_train_sample_per_sec: 16.38689515682117
avg_episode_per_sec: 0.1412663375588032
collect_time: 42.47296350768954
reward_mean: -129.86309523809524
reward_std: 4.089546254878136
reward_max: -122.92086834733891
reward_min: -134.37605042016804
queue_len: 0.08611611090059364
wait_time: 0.8433916559550433
delay_time: 5.307382297683814
pressure: 1.0553713527851458
total_envstep_count: 54984
total_train_sample_count: 54984
total_episode_count: 474
total_duration: 3343.8678222249036
[2024-12-27 12:52:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.753179884619094
avg_train_sample_per_sec: 16.753179884619094
avg_episode_per_sec: 0.14442396452257839
collect_time: 41.54435186593978
reward_mean: -126.67226890756304
reward_std: 5.304315503937977
reward_max: -119.27871148459386
reward_min: -133.08403361344537
queue_len: 0.08400017832066514
wait_time: 0.8162696555191483
delay_time: 5.133930412421917
pressure: 1.0222148541114058
total_envstep_count: 55680
total_train_sample_count: 55680
total_episode_count: 480
total_duration: 3385.4121740908436
[2024-12-27 12:52:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.790210152806242
avg_train_sample_per_sec: 16.790210152806242
avg_episode_per_sec: 0.14474319097246763
collect_time: 41.45272713478655
reward_mean: -128.29948646125118
reward_std: 3.741452741118766
reward_max: -122.05112044817926
reward_min: -133.8172268907563
queue_len: 0.08507923505388008
wait_time: 0.8202198761909715
delay_time: 5.2596187466762485
pressure: 1.0286251105216622
total_envstep_count: 56376
total_train_sample_count: 56376
total_episode_count: 486
total_duration: 3426.86490122563
[2024-12-27 12:53:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.791118987835937
avg_train_sample_per_sec: 16.791118987835937
avg_episode_per_sec: 0.14475102575720636
collect_time: 41.45048346713559
reward_mean: -125.30135387488328
reward_std: 2.183893848838328
reward_max: -120.7177871148459
reward_min: -127.296918767507
queue_len: 0.083091083471408
wait_time: 0.8081972399923717
delay_time: 5.076300224095276
pressure: 1.0098364279398762
total_envstep_count: 57072
total_train_sample_count: 57072
total_episode_count: 492
total_duration: 3468.3153846927657
[2024-12-27 12:54:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.046299930188553
avg_train_sample_per_sec: 17.046299930188553
avg_episode_per_sec: 0.1469508614671427
collect_time: 40.82997500046342
reward_mean: -125.52252567693745
reward_std: 3.5726625542691153
reward_max: -120.53851540616246
reward_min: -132.12324929971987
queue_len: 0.08323774912263755
wait_time: 0.8092721947311197
delay_time: 4.9834683514322995
pressure: 1.0321618037135278
total_envstep_count: 57768
total_train_sample_count: 57768
total_episode_count: 498
total_duration: 3509.1453596932292
[2024-12-27 12:54:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.623273802706457
avg_train_sample_per_sec: 16.623273802706457
avg_episode_per_sec: 0.14330408450609017
collect_time: 41.869008972629885
reward_mean: -124.9158496732026
reward_std: 1.8307347942954848
reward_max: -121.40686274509804
reward_min: -127.13445378151259
queue_len: 0.08283544408037309
wait_time: 0.8033027092357723
delay_time: 5.176452169093047
pressure: 1.0064102564102564
total_envstep_count: 58464
total_train_sample_count: 58464
total_episode_count: 504
total_duration: 3551.014368665859
[2024-12-27 12:55:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55704222760683
avg_train_sample_per_sec: 16.55704222760683
avg_episode_per_sec: 0.142733122651783
collect_time: 42.03649362200126
reward_mean: -125.91386554621847
reward_std: 3.2224069679731677
reward_max: -122.89705882352939
reward_min: -131.52310924369746
queue_len: 0.08349725831977352
wait_time: 0.8109287039307324
delay_time: 5.071119200595638
pressure: 1.0286251105216622
total_envstep_count: 59160
total_train_sample_count: 59160
total_episode_count: 510
total_duration: 3593.05086228786
[2024-12-27 12:56:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.045918636065316
avg_train_sample_per_sec: 17.045918636065316
avg_episode_per_sec: 0.14694757444883894
collect_time: 40.830888311728835
reward_mean: -125.3988095238095
reward_std: 2.862665634500686
reward_max: -121.33193277310922
reward_min: -128.53571428571428
queue_len: 0.08315570923329542
wait_time: 0.8030344542768479
delay_time: 5.099401844719907
pressure: 1.0179045092838195
total_envstep_count: 59856
total_train_sample_count: 59856
total_episode_count: 516
total_duration: 3633.881750599589
[2024-12-27 12:57:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.662966113908627
avg_train_sample_per_sec: 16.662966113908627
avg_episode_per_sec: 0.1436462596026606
collect_time: 41.76927416416257
reward_mean: -129.41748366013073
reward_std: 4.017400794010027
reward_max: -123.55462184873952
reward_min: -137.03571428571425
queue_len: 0.08582061250671798
wait_time: 0.8333890585411883
delay_time: 5.1988196830550635
pressure: 1.0579133510167993
total_envstep_count: 60552
total_train_sample_count: 60552
total_episode_count: 522
total_duration: 3675.6510247637516
[2024-12-27 12:57:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.915237979784315
avg_train_sample_per_sec: 16.915237979784315
avg_episode_per_sec: 0.14582101706710618
collect_time: 41.146332131525504
reward_mean: -125.8500233426704
reward_std: 1.4135287436669768
reward_max: -124.33963585434167
reward_min: -128.37745098039213
queue_len: 0.0834549226410281
wait_time: 0.810567573625383
delay_time: 5.140490357320288
pressure: 1.0300618921308575
total_envstep_count: 61248
total_train_sample_count: 61248
total_episode_count: 528
total_duration: 3716.797356895277
[2024-12-27 12:58:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.794543100843562
avg_train_sample_per_sec: 16.794543100843562
avg_episode_per_sec: 0.1447805439727893
collect_time: 41.44203243999184
reward_mean: -128.32761437908496
reward_std: 3.8781595517517133
reward_max: -122.67647058823532
reward_min: -133.34103641456576
queue_len: 0.08509788751928711
wait_time: 0.8251495447869687
delay_time: 5.291152618095395
pressure: 1.0487400530503979
total_envstep_count: 61944
total_train_sample_count: 61944
total_episode_count: 534
total_duration: 3758.2393893352687
[2024-12-27 12:59:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.757523393317552
avg_train_sample_per_sec: 16.757523393317552
avg_episode_per_sec: 0.14446140856308234
collect_time: 41.53358367248624
reward_mean: -127.26610644257704
reward_std: 3.1086016288879823
reward_max: -123.23529411764706
reward_min: -131.47478991596634
queue_len: 0.0843939697895073
wait_time: 0.82338940217997
delay_time: 5.2402886002759
pressure: 1.032603890362511
total_envstep_count: 62640
total_train_sample_count: 62640
total_episode_count: 540
total_duration: 3799.772973007755
[2024-12-27 12:59:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81109803436445
avg_train_sample_per_sec: 16.81109803436445
avg_episode_per_sec: 0.1449232589169349
collect_time: 41.40122189385071
reward_mean: -127.23249299719886
reward_std: 4.168100738704732
reward_max: -121.48039215686278
reward_min: -132.19887955182077
queue_len: 0.08437167970636529
wait_time: 0.819361398405516
delay_time: 5.23579665850952
pressure: 1.0267462422634839
total_envstep_count: 63336
total_train_sample_count: 63336
total_episode_count: 546
total_duration: 3841.1741949016055
[2024-12-27 13:00:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.687905584699077
avg_train_sample_per_sec: 16.687905584699077
avg_episode_per_sec: 0.14386125504050928
collect_time: 41.70685149598122
reward_mean: -129.80450513538747
reward_std: 4.743745780510705
reward_max: -122.25070028011203
reward_min: -136.44957983193277
queue_len: 0.08607725804733916
wait_time: 0.8390357248115867
delay_time: 5.244414847591398
pressure: 1.0377984084880636
total_envstep_count: 64032
total_train_sample_count: 64032
total_episode_count: 552
total_duration: 3882.8810463975865
[2024-12-27 13:01:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.528361944879183
avg_train_sample_per_sec: 16.528361944879183
avg_episode_per_sec: 0.1424858788351654
collect_time: 42.10943603008613
reward_mean: -129.8842203548086
reward_std: 4.589596795389238
reward_max: -123.0483193277311
reward_min: -137.20378151260505
queue_len: 0.08613011959867944
wait_time: 0.8349059451366755
delay_time: 5.299173441224686
pressure: 1.053603006189213
total_envstep_count: 64728
total_train_sample_count: 64728
total_episode_count: 558
total_duration: 3924.9904824276728
[2024-12-27 13:02:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.876607565388397
avg_train_sample_per_sec: 16.876607565388397
avg_episode_per_sec: 0.14548799625334827
collect_time: 41.240515743661675
reward_mean: -127.84407096171803
reward_std: 1.9847387424006102
reward_max: -124.84523809523812
reward_min: -129.96148459383753
queue_len: 0.08477723538575466
wait_time: 0.8262273631822316
delay_time: 5.237436829262705
pressure: 1.0366931918656057
total_envstep_count: 65424
total_train_sample_count: 65424
total_episode_count: 564
total_duration: 3966.2309981713342
[2024-12-27 13:02:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.74145785189887
avg_train_sample_per_sec: 16.74145785189887
avg_episode_per_sec: 0.14432291251636956
collect_time: 41.57344038715586
reward_mean: -124.31781045751633
reward_std: 2.9664173147861037
reward_max: -119.85434173669469
reward_min: -128.19467787114843
queue_len: 0.08243886635113816
wait_time: 0.8010798152152107
delay_time: 5.110166672492438
pressure: 1.0045313881520779
total_envstep_count: 66120
total_train_sample_count: 66120
total_episode_count: 570
total_duration: 4007.80443855849
[2024-12-27 13:03:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.882720626879564
avg_train_sample_per_sec: 16.882720626879564
avg_episode_per_sec: 0.14554069505930659
collect_time: 41.22558297220617
reward_mean: -124.34512138188607
reward_std: 4.3308840639943575
reward_max: -118.08473389355741
reward_min: -131.80462184873946
queue_len: 0.08245697704369104
wait_time: 0.7955378658979065
delay_time: 5.037056078488184
pressure: 0.9996684350132625
total_envstep_count: 66816
total_train_sample_count: 66816
total_episode_count: 576
total_duration: 4049.030021530696
[2024-12-27 13:04:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.44747828643097
avg_train_sample_per_sec: 16.44747828643097
avg_episode_per_sec: 0.14178860591750836
collect_time: 42.31651733349264
reward_mean: -124.20203081232494
reward_std: 4.621687119624163
reward_max: -116.2044817927171
reward_min: -130.96848739495798
queue_len: 0.08236208939809345
wait_time: 0.7899450673284346
delay_time: 5.194031704220758
pressure: 0.9965738284703801
total_envstep_count: 67512
total_train_sample_count: 67512
total_episode_count: 582
total_duration: 4091.346538864189
[2024-12-27 13:04:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.096938563704715
avg_train_sample_per_sec: 17.096938563704715
avg_episode_per_sec: 0.14738740141124754
collect_time: 40.70904258131607
reward_mean: -125.66690009337067
reward_std: 2.455518563281996
reward_max: -122.00140056022411
reward_min: -129.46778711484595
queue_len: 0.08333348812557738
wait_time: 0.8040162240846825
delay_time: 5.153961978570504
pressure: 1.0089522546419099
total_envstep_count: 68208
total_train_sample_count: 68208
total_episode_count: 588
total_duration: 4132.055581445505
[2024-12-27 13:05:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.77144707606354
avg_train_sample_per_sec: 16.77144707606354
avg_episode_per_sec: 0.1445814403108926
collect_time: 41.49910242350772
reward_mean: -128.36297852474323
reward_std: 1.3981916051016943
reward_max: -125.89565826330531
reward_min: -130.25700280112042
queue_len: 0.08512133854425945
wait_time: 0.8265663581966827
delay_time: 5.242889478289595
pressure: 1.0288461538461537
total_envstep_count: 68904
total_train_sample_count: 68904
total_episode_count: 594
total_duration: 4173.5546838690125
[2024-12-27 13:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.913991374549042
avg_train_sample_per_sec: 16.913991374549042
avg_episode_per_sec: 0.14581027047025036
collect_time: 41.14936472341418
reward_mean: -127.43790849673202
reward_std: 2.856681134616269
reward_max: -122.99579831932772
reward_min: -131.8529411764706
queue_len: 0.08450789688112204
wait_time: 0.8275245995834232
delay_time: 5.2100529989540805
pressure: 1.0177939876215738
total_envstep_count: 69600
total_train_sample_count: 69600
total_episode_count: 600
total_duration: 4214.704048592426
[2024-12-27 13:06:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81538039361818
avg_train_sample_per_sec: 16.81538039361818
avg_episode_per_sec: 0.14496017580705328
collect_time: 41.390678278330704
reward_mean: -126.48646125116714
reward_std: 2.667291863911309
reward_max: -122.68347338935573
reward_min: -131.35784313725495
queue_len: 0.0838769636944079
wait_time: 0.8183714246087472
delay_time: 5.086729415140584
pressure: 1.021662245800177
total_envstep_count: 70296
total_train_sample_count: 70296
total_episode_count: 606
total_duration: 4256.094726870757
[2024-12-27 13:07:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.515129834093734
avg_train_sample_per_sec: 16.515129834093734
avg_episode_per_sec: 0.14237180891460116
collect_time: 42.14317459153011
reward_mean: -128.26167133520073
reward_std: 2.671351579728829
reward_max: -123.0840336134454
reward_min: -131.9460784313725
queue_len: 0.08505415871034532
wait_time: 0.8345054202052173
delay_time: 5.225980543387444
pressure: 1.0334880636604775
total_envstep_count: 70992
total_train_sample_count: 70992
total_episode_count: 612
total_duration: 4298.237901462287
[2024-12-27 13:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.656312550537596
avg_train_sample_per_sec: 16.656312550537596
avg_episode_per_sec: 0.14358890129773788
collect_time: 41.78595940057189
reward_mean: -126.84442110177405
reward_std: 4.2793039389398615
reward_max: -120.70028011204482
reward_min: -132.62114845938373
queue_len: 0.08411433760064592
wait_time: 0.8206068568010757
delay_time: 5.144907278232862
pressure: 1.0271883289124668
total_envstep_count: 71688
total_train_sample_count: 71688
total_episode_count: 618
total_duration: 4340.023860862859
[2024-12-27 13:09:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.59763293995316
avg_train_sample_per_sec: 16.59763293995316
avg_episode_per_sec: 0.14308304258580312
collect_time: 41.93369033512101
reward_mean: -126.36076097105507
reward_std: 2.375478735167998
reward_max: -122.73039215686272
reward_min: -129.30042016806718
queue_len: 0.08379360807099144
wait_time: 0.813708772633722
delay_time: 5.193671449380107
pressure: 1.016688770999116
total_envstep_count: 72384
total_train_sample_count: 72384
total_episode_count: 624
total_duration: 4381.95755119798
[2024-12-27 13:09:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85261411009428
avg_train_sample_per_sec: 16.85261411009428
avg_episode_per_sec: 0.1452811561215024
collect_time: 41.29923081684485
reward_mean: -126.18265639589168
reward_std: 2.612992853212427
reward_max: -121.59103641456582
reward_min: -128.58263305322134
queue_len: 0.0836755015887876
wait_time: 0.8050520937818098
delay_time: 5.098165824334211
pressure: 1.0132625994694962
total_envstep_count: 73080
total_train_sample_count: 73080
total_episode_count: 630
total_duration: 4423.256782014825
[2024-12-27 13:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.611824876693785
avg_train_sample_per_sec: 16.611824876693785
avg_episode_per_sec: 0.14320538686804984
collect_time: 41.89786523553356
reward_mean: -122.97408963585433
reward_std: 2.6566944682783467
reward_max: -120.20868347338939
reward_min: -128.281512605042
queue_len: 0.08154780479831189
wait_time: 0.7930682330403426
delay_time: 5.003254297448119
pressure: 1.00342617152962
total_envstep_count: 73776
total_train_sample_count: 73776
total_episode_count: 636
total_duration: 4465.154647250359
[2024-12-27 13:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.782170832256778
avg_train_sample_per_sec: 16.782170832256778
avg_episode_per_sec: 0.1446738864849722
collect_time: 41.472584623094654
reward_mean: -124.53279645191411
reward_std: 4.2247808314804205
reward_max: -120.81582633053215
reward_min: -132.7535014005602
queue_len: 0.08258143000790058
wait_time: 0.7978611426887289
delay_time: 5.063548577548233
pressure: 1.0041998231653404
total_envstep_count: 74472
total_train_sample_count: 74472
total_episode_count: 642
total_duration: 4506.627231873454
[2024-12-27 13:11:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.852128077712685
avg_train_sample_per_sec: 16.852128077712685
avg_episode_per_sec: 0.1452769661871783
collect_time: 41.30042192834242
reward_mean: -122.96463585434172
reward_std: 2.4108342677837915
reward_max: -119.26750700280108
reward_min: -126.31162464985995
queue_len: 0.0815415357124282
wait_time: 0.7876356444434537
delay_time: 4.932124947729709
pressure: 1.0061892130857648
total_envstep_count: 75168
total_train_sample_count: 75168
total_episode_count: 648
total_duration: 4547.927653801796
[2024-12-27 13:12:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.387987874086836
avg_train_sample_per_sec: 16.387987874086836
avg_episode_per_sec: 0.14127575753523133
collect_time: 42.47013149799406
reward_mean: -126.45039682539682
reward_std: 3.048214260219486
reward_max: -122.01540616246501
reward_min: -131.32352941176467
queue_len: 0.08385304829270347
wait_time: 0.8217463599055891
delay_time: 5.096894035139738
pressure: 1.030282935455349
total_envstep_count: 75864
total_train_sample_count: 75864
total_episode_count: 654
total_duration: 4590.39778529979
[2024-12-27 13:13:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.44004050075715
avg_train_sample_per_sec: 17.44004050075715
avg_episode_per_sec: 0.15034517673066508
collect_time: 39.90816420235856
reward_mean: -124.05182072829132
reward_std: 1.3200576690652661
reward_max: -121.98249299719886
reward_min: -125.8662464985994
queue_len: 0.08226248058905261
wait_time: 0.7982383713874586
delay_time: 5.028292427994825
pressure: 0.9924845269672855
total_envstep_count: 76560
total_train_sample_count: 76560
total_episode_count: 660
total_duration: 4630.305949502148
[2024-12-27 13:13:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.749040882724895
avg_train_sample_per_sec: 16.749040882724895
avg_episode_per_sec: 0.14438828347176633
collect_time: 41.55461825386434
reward_mean: -124.20156395891689
reward_std: 4.058507799392619
reward_max: -115.96008403361344
reward_min: -128.41596638655466
queue_len: 0.08236177981360537
wait_time: 0.8051128497375962
delay_time: 4.970957394123082
pressure: 1.0139257294429707
total_envstep_count: 77256
total_train_sample_count: 77256
total_episode_count: 666
total_duration: 4671.860567756013
[2024-12-27 13:14:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.956620848166175
avg_train_sample_per_sec: 16.956620848166175
avg_episode_per_sec: 0.146177765932467
collect_time: 41.04591393722595
reward_mean: -125.51960784313725
reward_std: 1.2743598633340518
reward_max: -123.6155462184874
reward_min: -127.19257703081232
queue_len: 0.08323581421958705
wait_time: 0.801540631725723
delay_time: 4.974847790063159
pressure: 1.0268567639257293
total_envstep_count: 77952
total_train_sample_count: 77952
total_episode_count: 672
total_duration: 4712.906481693239
[2024-12-27 13:15:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.950429636932423
avg_train_sample_per_sec: 16.950429636932423
avg_episode_per_sec: 0.14612439342183123
collect_time: 41.06090611907094
reward_mean: -123.77824463118579
reward_std: 5.012902566903495
reward_max: -116.38585434173672
reward_min: -130.0343137254902
queue_len: 0.08208106407903566
wait_time: 0.7934874878333297
delay_time: 5.085673072718187
pressure: 0.9985632183908048
total_envstep_count: 78648
total_train_sample_count: 78648
total_episode_count: 678
total_duration: 4753.967387812309
[2024-12-27 13:16:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89440575238559
avg_train_sample_per_sec: 16.89440575238559
avg_episode_per_sec: 0.1456414288998758
collect_time: 41.19706902989
reward_mean: -126.34932306255837
reward_std: 4.07824498397393
reward_max: -119.07282913165264
reward_min: -132.07142857142856
queue_len: 0.0837860232510334
wait_time: 0.8124743044874889
delay_time: 5.094214700354617
pressure: 1.024867374005305
total_envstep_count: 79344
total_train_sample_count: 79344
total_episode_count: 684
total_duration: 4795.1644568422
[2024-12-27 13:16:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61500285319304
avg_train_sample_per_sec: 16.61500285319304
avg_episode_per_sec: 0.1432327832171814
collect_time: 41.88985136805101
reward_mean: -125.57061157796454
reward_std: 3.636857493457844
reward_max: -120.58823529411767
reward_min: -131.09033613445374
queue_len: 0.08326963632491015
wait_time: 0.8120969983926374
delay_time: 5.006209790145227
pressure: 1.0213306808134395
total_envstep_count: 80040
total_train_sample_count: 80040
total_episode_count: 690
total_duration: 4837.05430821025
[2024-12-27 13:17:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.798355578568305
avg_train_sample_per_sec: 16.798355578568305
avg_episode_per_sec: 0.1448134101600716
collect_time: 41.43262694641203
reward_mean: -125.3611111111111
reward_std: 3.7855427237063193
reward_max: -120.67016806722688
reward_min: -131.57142857142856
queue_len: 0.08313071028588269
wait_time: 0.8089044857553986
delay_time: 5.009986946350197
pressure: 1.0167992926613618
total_envstep_count: 80736
total_train_sample_count: 80736
total_episode_count: 696
total_duration: 4878.486935156662
[2024-12-27 13:18:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.72175514490584
avg_train_sample_per_sec: 16.72175514490584
avg_episode_per_sec: 0.14415306159401586
collect_time: 41.622425036646426
reward_mean: -126.77077497665736
reward_std: 3.2218866580898022
reward_max: -122.59873949579831
reward_min: -131.11554621848742
queue_len: 0.08406550064765077
wait_time: 0.822676893480646
delay_time: 5.088814797620274
pressure: 1.0328249336870028
total_envstep_count: 81432
total_train_sample_count: 81432
total_episode_count: 702
total_duration: 4920.109360193309
[2024-12-27 13:18:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.68331371294688
avg_train_sample_per_sec: 16.68331371294688
avg_episode_per_sec: 0.14382166993919723
collect_time: 41.71833078100532
reward_mean: -123.72805788982264
reward_std: 3.9550506579140117
reward_max: -119.43137254901961
reward_min: -132.02941176470588
queue_len: 0.08204778374656672
wait_time: 0.793763018027724
delay_time: 4.952799818690057
pressure: 1.0087312113174183
total_envstep_count: 82128
total_train_sample_count: 82128
total_episode_count: 708
total_duration: 4961.8276909743145
[2024-12-27 13:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.893881490120862
avg_train_sample_per_sec: 15.893881490120862
avg_episode_per_sec: 0.1370162197424212
collect_time: 43.79043598837778
reward_mean: -123.86332866479928
reward_std: 2.2810548198325735
reward_max: -121.40686274509801
reward_min: -127.49019607843144
queue_len: 0.0821374858519889
wait_time: 0.7995361495615044
delay_time: 5.00684862255462
pressure: 1.0117152961980547
total_envstep_count: 82824
total_train_sample_count: 82824
total_episode_count: 714
total_duration: 5005.618126962692
[2024-12-27 13:20:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.968430040047984
avg_train_sample_per_sec: 15.968430040047984
avg_episode_per_sec: 0.13765887965558607
collect_time: 43.58600051817671
reward_mean: -125.07749766573295
reward_std: 3.074366067118718
reward_max: -120.53711484593838
reward_min: -128.6190476190476
queue_len: 0.08294263770937199
wait_time: 0.8042818475754582
delay_time: 5.0520525296646435
pressure: 1.0183465959328029
total_envstep_count: 83520
total_train_sample_count: 83520
total_episode_count: 720
total_duration: 5049.204127480869
[2024-12-27 13:21:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.919233139225776
avg_train_sample_per_sec: 15.919233139225776
avg_episode_per_sec: 0.1372347684416015
collect_time: 43.72069897544384
reward_mean: -124.11542950513541
reward_std: 3.0185667553296547
reward_max: -118.74859943977593
reward_min: -128.94887955182074
queue_len: 0.08230466147555397
wait_time: 0.7970278186429302
delay_time: 5.07530686491605
pressure: 1.008731211317418
total_envstep_count: 84216
total_train_sample_count: 84216
total_episode_count: 726
total_duration: 5092.924826456313
[2024-12-27 13:21:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.858909175411567
avg_train_sample_per_sec: 15.858909175411567
avg_episode_per_sec: 0.13671473427078937
collect_time: 43.88700334315002
reward_mean: -123.42471988795518
reward_std: 2.8448569846766363
reward_max: -120.74509803921572
reward_min: -129.47759103641457
queue_len: 0.08184663122543447
wait_time: 0.7969079320499199
delay_time: 5.119695127101015
pressure: 0.991710875331565
total_envstep_count: 84912
total_train_sample_count: 84912
total_episode_count: 732
total_duration: 5136.811829799463
[2024-12-27 13:22:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.029554272466108
avg_train_sample_per_sec: 16.029554272466108
avg_episode_per_sec: 0.13818581269367333
collect_time: 43.419797467201946
reward_mean: -123.64612511671335
reward_std: 3.283921621537214
reward_max: -119.52030812324936
reward_min: -127.92787114845946
queue_len: 0.08199345166890808
wait_time: 0.7920901782463649
delay_time: 5.023579110516121
pressure: 1.0018788682581787
total_envstep_count: 85608
total_train_sample_count: 85608
total_episode_count: 738
total_duration: 5180.231627266665
[2024-12-27 13:23:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.01511040346447
avg_train_sample_per_sec: 16.01511040346447
avg_episode_per_sec: 0.13806129658159025
collect_time: 43.45895735126733
reward_mean: -126.27042483660131
reward_std: 3.9300894577531835
reward_max: -120.69397759103636
reward_min: -130.66666666666669
queue_len: 0.08373370347254729
wait_time: 0.8133060032147252
delay_time: 5.114045868264073
pressure: 1.0245358090185677
total_envstep_count: 86304
total_train_sample_count: 86304
total_episode_count: 744
total_duration: 5223.6905846179325
[2024-12-27 13:24:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.851694205562687
avg_train_sample_per_sec: 15.851694205562687
avg_episode_per_sec: 0.13665253625485077
collect_time: 43.90697870993242
reward_mean: -124.91619981325864
reward_std: 1.1484889649883685
reward_max: -122.46428571428572
reward_min: -126.00140056022407
queue_len: 0.08283567626873915
wait_time: 0.8043008096253531
delay_time: 4.989109133180354
pressure: 1.0261936339522546
total_envstep_count: 87000
total_train_sample_count: 87000
total_episode_count: 750
total_duration: 5267.597563327865
[2024-12-27 13:24:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.963195044383436
avg_train_sample_per_sec: 15.963195044383436
avg_episode_per_sec: 0.13761375038261583
collect_time: 43.600294180762006
reward_mean: -124.44456115779644
reward_std: 3.1881247235946852
reward_max: -121.48459383753506
reward_min: -131.16596638655457
queue_len: 0.08252291853965282
wait_time: 0.799968639091357
delay_time: 5.082097688312038
pressure: 0.9996684350132625
total_envstep_count: 87696
total_train_sample_count: 87696
total_episode_count: 756
total_duration: 5311.197857508627
[2024-12-27 13:25:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.832606365410927
avg_train_sample_per_sec: 15.832606365410927
avg_episode_per_sec: 0.1364879859087149
collect_time: 43.959913101896646
reward_mean: -126.1050420168067
reward_std: 2.953004566573685
reward_max: -120.57282913165267
reward_min: -129.76540616246498
queue_len: 0.0836240331676437
wait_time: 0.8134507339629042
delay_time: 5.111064999190222
pressure: 1.0331564986737403
total_envstep_count: 88392
total_train_sample_count: 88392
total_episode_count: 762
total_duration: 5355.157770610524
[2024-12-27 13:26:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.09737024411501
avg_train_sample_per_sec: 16.09737024411501
avg_episode_per_sec: 0.13877043313892248
collect_time: 43.23687592726201
reward_mean: -125.55613912231559
reward_std: 3.806837992577886
reward_max: -119.43487394957987
reward_min: -131.01260504201682
queue_len: 0.08326003920577958
wait_time: 0.805560354115121
delay_time: 5.105479891678348
pressure: 1.012709991158267
total_envstep_count: 89088
total_train_sample_count: 89088
total_episode_count: 768
total_duration: 5398.394646537786
[2024-12-27 13:26:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.10351772914775
avg_train_sample_per_sec: 16.10351772914775
avg_episode_per_sec: 0.13882342869954956
collect_time: 43.220370338104665
reward_mean: -124.02205882352943
reward_std: 3.7444358866536
reward_max: -118.49299719887955
reward_min: -129.26610644257698
queue_len: 0.08224274457793727
wait_time: 0.797957655652889
delay_time: 5.063290009305494
pressure: 0.9972369584438551
total_envstep_count: 89784
total_train_sample_count: 89784
total_episode_count: 774
total_duration: 5441.61501687589
[2024-12-27 13:27:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.106258253169877
avg_train_sample_per_sec: 16.106258253169877
avg_episode_per_sec: 0.13884705390663685
collect_time: 43.21301627353579
reward_mean: -124.72245564892624
reward_std: 2.8817386750157454
reward_max: -121.08963585434172
reward_min: -129.87044817927168
queue_len: 0.08270719870618451
wait_time: 0.8034944968261398
delay_time: 4.991030022431665
pressure: 1.0225464190981433
total_envstep_count: 90480
total_train_sample_count: 90480
total_episode_count: 780
total_duration: 5484.828033149426
[2024-12-27 13:28:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.772372864693196
avg_train_sample_per_sec: 15.772372864693196
avg_episode_per_sec: 0.13596873159218273
collect_time: 44.12779268983751
reward_mean: -126.2599206349206
reward_std: 2.0246972962556242
reward_max: -123.46148459383751
reward_min: -130.2429971988795
queue_len: 0.08372673782156537
wait_time: 0.8119989375060371
delay_time: 5.0998758591108
pressure: 1.013925729442971
total_envstep_count: 91176
total_train_sample_count: 91176
total_episode_count: 786
total_duration: 5528.9558258392635
[2024-12-27 13:29:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.205876713075128
avg_train_sample_per_sec: 16.205876713075128
avg_episode_per_sec: 0.13970583373340628
collect_time: 42.94738336732239
reward_mean: -125.24486461251166
reward_std: 3.6355727905956288
reward_max: -120.89145658263304
reward_min: -129.97268907563029
queue_len: 0.08305362374834992
wait_time: 0.8021361174885516
delay_time: 5.077704241101605
pressure: 1.0096153846153848
total_envstep_count: 91872
total_train_sample_count: 91872
total_episode_count: 792
total_duration: 5571.903209206586
[2024-12-27 13:29:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.128931060960085
avg_train_sample_per_sec: 16.128931060960085
avg_episode_per_sec: 0.13904250914620764
collect_time: 43.15227074686065
reward_mean: -123.22105508870214
reward_std: 1.7631173872394026
reward_max: -120.59103641456582
reward_min: -125.6953781512605
queue_len: 0.08171157499250806
wait_time: 0.7850974386217794
delay_time: 5.029602341485414
pressure: 0.9927055702917773
total_envstep_count: 92568
total_train_sample_count: 92568
total_episode_count: 798
total_duration: 5615.055479953447
[2024-12-27 13:30:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.720800871308485
avg_train_sample_per_sec: 15.720800871308485
avg_episode_per_sec: 0.13552414544231453
collect_time: 44.27255365025624
reward_mean: -125.7110177404295
reward_std: 4.965387209828223
reward_max: -120.70938375350143
reward_min: -136.031512605042
queue_len: 0.08336274385970126
wait_time: 0.8102075268657419
delay_time: 5.053965214366168
pressure: 1.007294429708223
total_envstep_count: 93264
total_train_sample_count: 93264
total_episode_count: 804
total_duration: 5659.328033603703
[2024-12-27 13:31:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.234191957049642
avg_train_sample_per_sec: 16.234191957049642
avg_episode_per_sec: 0.13994993066422107
collect_time: 42.87247568843513
reward_mean: -124.0138888888889
reward_std: 3.8491785350188206
reward_max: -118.8172268907563
reward_min: -128.36554621848734
queue_len: 0.08223732684939582
wait_time: 0.8002175450197763
delay_time: 5.003393655366222
pressure: 1.0012157382847036
total_envstep_count: 93960
total_train_sample_count: 93960
total_episode_count: 810
total_duration: 5702.200509292138
[2024-12-27 13:32:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.786229366902118
avg_train_sample_per_sec: 15.786229366902118
avg_episode_per_sec: 0.13608818419743207
collect_time: 44.08905913018434
reward_mean: -123.20296451914099
reward_std: 3.274486626321699
reward_max: -118.87254901960786
reward_min: -126.87815126050421
queue_len: 0.08169957859359482
wait_time: 0.78805907862703
delay_time: 5.003446159199785
pressure: 0.9942528735632182
total_envstep_count: 94656
total_train_sample_count: 94656
total_episode_count: 816
total_duration: 5746.289568422322
[2024-12-27 13:32:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.058770640962223
avg_train_sample_per_sec: 16.058770640962223
avg_episode_per_sec: 0.1384376779393295
collect_time: 43.3408020801209
reward_mean: -123.96428571428571
reward_std: 4.021443869779008
reward_max: -119.42857142857146
reward_min: -130.39425770308122
queue_len: 0.08220443349753694
wait_time: 0.7954068342633253
delay_time: 5.029142853219172
pressure: 1.0068523430592395
total_envstep_count: 95352
total_train_sample_count: 95352
total_episode_count: 822
total_duration: 5789.630370502443
[2024-12-27 13:33:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.04609295191639
avg_train_sample_per_sec: 16.04609295191639
avg_episode_per_sec: 0.1383283875165206
collect_time: 43.375044759221375
reward_mean: -126.75875350140053
reward_std: 3.0996716315234254
reward_max: -121.82072829131647
reward_min: -131.03991596638653
queue_len: 0.0840575288470826
wait_time: 0.8175291226127941
delay_time: 5.090488490774106
pressure: 1.0297303271441203
total_envstep_count: 96048
total_train_sample_count: 96048
total_episode_count: 828
total_duration: 5833.005415261664
[2024-12-27 13:34:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.101300739522937
avg_train_sample_per_sec: 16.101300739522937
avg_episode_per_sec: 0.13880431672002533
collect_time: 43.22632135499269
reward_mean: -125.54049953314659
reward_std: 3.9445247177284366
reward_max: -117.53641456582632
reward_min: -129.5021008403361
queue_len: 0.08324966812542879
wait_time: 0.8110220436538894
delay_time: 5.04070924437402
pressure: 1.01657824933687
total_envstep_count: 96744
total_train_sample_count: 96744
total_episode_count: 834
total_duration: 5876.231736616656
[2024-12-27 13:35:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.242482615273982
avg_train_sample_per_sec: 16.242482615273982
avg_episode_per_sec: 0.1400214018558102
collect_time: 42.8505922700204
reward_mean: -123.03127917833801
reward_std: 3.5248238392103306
reward_max: -116.34243697478995
reward_min: -127.45448179271709
queue_len: 0.08158572889810212
wait_time: 0.7896385786852318
delay_time: 4.923732544402307
pressure: 1.0012157382847038
total_envstep_count: 97440
total_train_sample_count: 97440
total_episode_count: 840
total_duration: 5919.082328886677
[2024-12-27 13:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.20120531916217
avg_train_sample_per_sec: 16.20120531916217
avg_episode_per_sec: 0.1396655630962256
collect_time: 42.95976665247231
reward_mean: -124.3374183006536
reward_std: 3.045762718962258
reward_max: -119.83753501400562
reward_min: -128.39635854341736
queue_len: 0.08245186889963767
wait_time: 0.7984193235207434
delay_time: 5.00567089876217
pressure: 1.0148099027409374
total_envstep_count: 98136
total_train_sample_count: 98136
total_episode_count: 846
total_duration: 5962.042095539149
[2024-12-27 13:36:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.00055358556626
avg_train_sample_per_sec: 16.00055358556626
avg_episode_per_sec: 0.13793580677212292
collect_time: 43.49849499131368
reward_mean: -123.42448646125116
reward_std: 2.067212713382895
reward_max: -120.24439775910363
reward_min: -126.67857142857144
queue_len: 0.08184647643319043
wait_time: 0.7911149097127798
delay_time: 4.955857041787195
pressure: 0.9930371352785147
total_envstep_count: 98832
total_train_sample_count: 98832
total_episode_count: 852
total_duration: 6005.540590530462
[2024-12-27 13:37:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.933812539996161
avg_train_sample_per_sec: 15.933812539996161
avg_episode_per_sec: 0.13736045293100138
collect_time: 43.68069463933631
reward_mean: -125.84243697478992
reward_std: 2.9338915939993035
reward_max: -121.28151260504204
reward_min: -130.80182072829135
queue_len: 0.08344989189309678
wait_time: 0.8095090268645037
delay_time: 5.141895759716655
pressure: 1.0123784261715296
total_envstep_count: 99528
total_train_sample_count: 99528
total_episode_count: 858
total_duration: 6049.221285169799
[2024-12-27 13:37:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.981485820486498
avg_train_sample_per_sec: 15.981485820486498
avg_episode_per_sec: 0.13777142948695256
collect_time: 43.55039373797178
reward_mean: -122.28408029878615
reward_std: 3.1573626380659134
reward_max: -119.56792717086834
reward_min: -128.45588235294116
queue_len: 0.08109023892492452
wait_time: 0.7828977634378241
delay_time: 4.978725716165766
pressure: 0.9859637488947833
total_envstep_count: 100224
total_train_sample_count: 100224
total_episode_count: 864
total_duration: 6092.77167890777
[2024-12-27 13:38:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.91643926329656
avg_train_sample_per_sec: 15.91643926329656
avg_episode_per_sec: 0.13721068330428068
collect_time: 43.72837344373762
reward_mean: -121.69444444444446
reward_std: 2.6314787240561426
reward_max: -116.33823529411768
reward_min: -125.05742296918768
queue_len: 0.08069923371647512
wait_time: 0.7863832977930342
delay_time: 4.973104423972994
pressure: 0.9940318302387269
total_envstep_count: 100920
total_train_sample_count: 100920
total_episode_count: 870
total_duration: 6136.500052351508
[2024-12-27 13:39:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.99774211688676
avg_train_sample_per_sec: 15.99774211688676
avg_episode_per_sec: 0.13791156997316173
collect_time: 43.506139486104246
reward_mean: -125.98716153127918
reward_std: 3.6024746709413833
reward_max: -120.15756302521008
reward_min: -131.7843137254902
queue_len: 0.08354586308440264
wait_time: 0.8129608165105123
delay_time: 5.0589639054703985
pressure: 1.0154730327144121
total_envstep_count: 101616
total_train_sample_count: 101616
total_episode_count: 876
total_duration: 6180.006191837612
[2024-12-27 13:40:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.107825287657654
avg_train_sample_per_sec: 16.107825287657654
avg_episode_per_sec: 0.13886056282463494
collect_time: 43.208812336280936
reward_mean: -123.63060224089635
reward_std: 6.002972630937455
reward_max: -114.24509803921568
reward_min: -131.48249299719888
queue_len: 0.08198315798467928
wait_time: 0.7947139067828721
delay_time: 4.984993978837717
pressure: 0.998342175066313
total_envstep_count: 102312
total_train_sample_count: 102312
total_episode_count: 882
total_duration: 6223.215004173893
[2024-12-27 13:40:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.93038740485208
avg_train_sample_per_sec: 15.93038740485208
avg_episode_per_sec: 0.13733092590389723
collect_time: 43.69008626795932
reward_mean: -124.4013772175537
reward_std: 3.5591568982228936
reward_max: -119.84873949579831
reward_min: -130.3382352941177
queue_len: 0.0824942819745051
wait_time: 0.8055033131731913
delay_time: 5.010029307849758
pressure: 1.0142572944297081
total_envstep_count: 103008
total_train_sample_count: 103008
total_episode_count: 888
total_duration: 6266.905090441853
[2024-12-27 13:41:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.925674285336152
avg_train_sample_per_sec: 15.925674285336152
avg_episode_per_sec: 0.13729029556324268
collect_time: 43.70301611912623
reward_mean: -123.65044351073762
reward_std: 3.9838017575219884
reward_max: -119.44957983193272
reward_min: -129.77170868347335
queue_len: 0.08199631532542283
wait_time: 0.7945354313254921
delay_time: 4.9650575667112395
pressure: 0.9959106984969054
total_envstep_count: 103704
total_train_sample_count: 103704
total_episode_count: 894
total_duration: 6310.608106560979
[2024-12-27 13:42:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.837398276905507
avg_train_sample_per_sec: 15.837398276905507
avg_episode_per_sec: 0.13652929549056472
collect_time: 43.94661217902973
reward_mean: -126.15219421101777
reward_std: 6.705952052323715
reward_max: -117.80882352941174
reward_min: -133.28571428571433
queue_len: 0.08365530120094017
wait_time: 0.8107112208278537
delay_time: 5.1016922862322645
pressure: 1.0339301503094607
total_envstep_count: 104400
total_train_sample_count: 104400
total_episode_count: 900
total_duration: 6354.554718740009
[2024-12-27 13:43:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.758884785899363
avg_train_sample_per_sec: 15.758884785899363
avg_episode_per_sec: 0.13585245505085658
collect_time: 44.1655618056655
reward_mean: -122.83356676003734
reward_std: 1.7356744384100289
reward_max: -120.77380952380956
reward_min: -125.78291316526614
queue_len: 0.08145461986739878
wait_time: 0.7863276499813011
delay_time: 4.967693913984959
pressure: 0.9911582670203359
total_envstep_count: 105096
total_train_sample_count: 105096
total_episode_count: 906
total_duration: 6398.7202805456745
[2024-12-27 13:43:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.90915819277686
avg_train_sample_per_sec: 15.90915819277686
avg_episode_per_sec: 0.13714791545497293
collect_time: 43.748386405259374
reward_mean: -125.3376517273576
reward_std: 2.9054627873349426
reward_max: -121.40546218487395
reward_min: -130.63235294117644
queue_len: 0.0831151536653565
wait_time: 0.8144376119147925
delay_time: 4.965116819834432
pressure: 1.0306145004420866
total_envstep_count: 105792
total_train_sample_count: 105792
total_episode_count: 912
total_duration: 6442.468666950934
[2024-12-27 13:44:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.92075642676052
avg_train_sample_per_sec: 15.92075642676052
avg_episode_per_sec: 0.13724790023069414
collect_time: 43.716515807636085
reward_mean: -125.86496265172737
reward_std: 2.9283963091191545
reward_max: -122.86554621848737
reward_min: -129.9271708683473
queue_len: 0.08346482934464679
wait_time: 0.8107035586117736
delay_time: 5.1050851946408144
pressure: 1.0253094606542883
total_envstep_count: 106488
total_train_sample_count: 106488
total_episode_count: 918
total_duration: 6486.18518275857
[2024-12-27 13:45:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.844035977126957
avg_train_sample_per_sec: 15.844035977126957
avg_episode_per_sec: 0.1365865170441979
collect_time: 43.928201185908165
reward_mean: -122.98027544351073
reward_std: 4.548163445198709
reward_max: -117.28991596638653
reward_min: -129.9348739495798
queue_len: 0.08155190679277899
wait_time: 0.7898628726468483
delay_time: 4.9524849729070946
pressure: 0.9969053934571175
total_envstep_count: 107184
total_train_sample_count: 107184
total_episode_count: 924
total_duration: 6530.113383944477
[2024-12-27 13:46:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.01094493376886
avg_train_sample_per_sec: 16.01094493376886
avg_episode_per_sec: 0.1380253873600764
collect_time: 43.47026380261034
reward_mean: -124.29901960784314
reward_std: 3.378851008451692
reward_max: -118.89145658263304
reward_min: -130.234593837535
queue_len: 0.08242640557549279
wait_time: 0.7981373694482214
delay_time: 5.007321358356726
pressure: 1.0071839080459768
total_envstep_count: 107880
total_train_sample_count: 107880
total_episode_count: 930
total_duration: 6573.5836477470875
[2024-12-27 13:46:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.96245021984421
avg_train_sample_per_sec: 15.96245021984421
avg_episode_per_sec: 0.13760732948141563
collect_time: 43.60232861586288
reward_mean: -124.55112044817928
reward_std: 2.2728826013889365
reward_max: -121.65756302521011
reward_min: -127.87675070028013
queue_len: 0.08259358119905787
wait_time: 0.808679959605416
delay_time: 5.007344798072472
pressure: 1.0129310344827587
total_envstep_count: 108576
total_train_sample_count: 108576
total_episode_count: 936
total_duration: 6617.18597636295
[2024-12-27 13:47:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.00282773902974
avg_train_sample_per_sec: 16.00282773902974
avg_episode_per_sec: 0.13795541154335983
collect_time: 43.49231344298647
reward_mean: -123.50863678804853
reward_std: 2.8408680186080453
reward_max: -119.87044817927166
reward_min: -126.86764705882355
queue_len: 0.08190227903716746
wait_time: 0.7981150793650792
delay_time: 4.975119945556212
pressure: 1.0096153846153848
total_envstep_count: 109272
total_train_sample_count: 109272
total_episode_count: 942
total_duration: 6660.678289805936
[2024-12-27 13:48:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.717249370615537
avg_train_sample_per_sec: 15.717249370615537
avg_episode_per_sec: 0.1354935290570305
collect_time: 44.282557563871144
reward_mean: -127.19794584500465
reward_std: 4.759112256987087
reward_max: -121.39355742296915
reward_min: -134.30742296918766
queue_len: 0.08434877045424712
wait_time: 0.8206623498205649
delay_time: 5.1306517864110335
pressure: 1.0354774535809017
total_envstep_count: 109968
total_train_sample_count: 109968
total_episode_count: 948
total_duration: 6704.960847369807
[2024-12-27 13:49:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.87299983679326
avg_train_sample_per_sec: 15.87299983679326
avg_episode_per_sec: 0.13683620548959707
collect_time: 43.84804429889097
reward_mean: -123.74754901960786
reward_std: 2.886043007050484
reward_max: -118.06302521008408
reward_min: -127.03291316526607
queue_len: 0.0820607088989442
wait_time: 0.7962588107745309
delay_time: 4.9811197875074
pressure: 1.0113837312113174
total_envstep_count: 110664
total_train_sample_count: 110664
total_episode_count: 954
total_duration: 6748.808891668698
[2024-12-27 13:49:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.889664215565222
avg_train_sample_per_sec: 15.889664215565222
avg_episode_per_sec: 0.1369798639272864
collect_time: 43.80205840462074
reward_mean: -125.83228291316527
reward_std: 5.224548783369987
reward_max: -118.77100840336138
reward_min: -133.578431372549
queue_len: 0.08344315843048095
wait_time: 0.8110379872550258
delay_time: 5.011310885838221
pressure: 1.0208885941644563
total_envstep_count: 111360
total_train_sample_count: 111360
total_episode_count: 960
total_duration: 6792.610950073319
[2024-12-27 13:50:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.07515405039836
avg_train_sample_per_sec: 16.07515405039836
avg_episode_per_sec: 0.1385789142275721
collect_time: 43.29663017958775
reward_mean: -121.29995331465916
reward_std: 1.6340597722858303
reward_max: -119.20168067226886
reward_min: -124.08683473389348
queue_len: 0.08043763482404453
wait_time: 0.7775436545086647
delay_time: 4.93036346455717
pressure: 0.9780061892130858
total_envstep_count: 112056
total_train_sample_count: 112056
total_episode_count: 966
total_duration: 6835.907580252907
[2024-12-27 13:51:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.201894910370246
avg_train_sample_per_sec: 16.201894910370246
avg_episode_per_sec: 0.13967150784801938
collect_time: 42.957938182558856
reward_mean: -123.42331932773111
reward_std: 4.119066881071028
reward_max: -115.0679271708683
reward_min: -127.358543417367
queue_len: 0.08184570247197023
wait_time: 0.7943767692753494
delay_time: 5.035318538959073
pressure: 1.0009946949602122
total_envstep_count: 112752
total_train_sample_count: 112752
total_episode_count: 972
total_duration: 6878.865518435466
[2024-12-27 13:52:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.791364705019333
avg_train_sample_per_sec: 15.791364705019333
avg_episode_per_sec: 0.13613245435361493
collect_time: 44.074721406362954
reward_mean: -125.06337535014006
reward_std: 2.009086504576411
reward_max: -122.24579831932772
reward_min: -127.81512605042015
queue_len: 0.08293327277860746
wait_time: 0.8105101457028433
delay_time: 5.141232322283938
pressure: 1.0156940760389037
total_envstep_count: 113448
total_train_sample_count: 113448
total_episode_count: 978
total_duration: 6922.940239841829
[2024-12-27 13:52:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.06782954435483
avg_train_sample_per_sec: 16.06782954435483
avg_episode_per_sec: 0.13851577193409337
collect_time: 43.31636691058428
reward_mean: -123.74416433239962
reward_std: 5.000623113484003
reward_max: -115.68767507002799
reward_min: -128.9187675070028
queue_len: 0.08205846441140559
wait_time: 0.7938646391359372
delay_time: 4.991644535253902
pressure: 1.000110521662246
total_envstep_count: 114144
total_train_sample_count: 114144
total_episode_count: 984
total_duration: 6966.256606752413
[2024-12-27 13:53:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.806689496282246
avg_train_sample_per_sec: 15.806689496282246
avg_episode_per_sec: 0.1362645646231228
collect_time: 44.03199039012566
reward_mean: -123.89799253034545
reward_std: 3.3451027291175492
reward_max: -119.66946778711484
reward_min: -130.27380952380955
queue_len: 0.08216047250022909
wait_time: 0.7992723835776574
delay_time: 5.025240691432566
pressure: 1.003315649867374
total_envstep_count: 114840
total_train_sample_count: 114840
total_episode_count: 990
total_duration: 7010.2885971425385
[2024-12-27 13:54:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.770587039982193
avg_train_sample_per_sec: 15.770587039982193
avg_episode_per_sec: 0.13595333655157063
collect_time: 44.132789618767795
reward_mean: -123.86309523809524
reward_std: 4.746938686353402
reward_max: -119.71358543417368
reward_min: -133.74299719887955
queue_len: 0.08213733105974486
wait_time: 0.8004645934412667
delay_time: 4.974056937609782
pressure: 0.9969053934571176
total_envstep_count: 115536
total_train_sample_count: 115536
total_episode_count: 996
total_duration: 7054.421386761306
[2024-12-27 13:55:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.9225321284202
avg_train_sample_per_sec: 15.9225321284202
avg_episode_per_sec: 0.1372632080036224
collect_time: 43.71164048447461
reward_mean: -124.90721288515402
reward_std: 5.52571287159683
reward_max: -117.06512605042015
reward_min: -135.18907563025203
queue_len: 0.08282971676734353
wait_time: 0.8062639622604126
delay_time: 5.044590703765166
pressure: 1.0090627763041555
total_envstep_count: 116232
total_train_sample_count: 116232
total_episode_count: 1002
total_duration: 7098.133027245781
[2024-12-27 13:55:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.702241695764329
avg_train_sample_per_sec: 15.702241695764329
avg_episode_per_sec: 0.1353641525496925
collect_time: 44.324881344027816
reward_mean: -126.18499066293185
reward_std: 2.0842552400288032
reward_max: -122.83543417366951
reward_min: -129.71778711484598
queue_len: 0.08367704951122801
wait_time: 0.8107714350107859
delay_time: 5.130178740275539
pressure: 1.0098364279398762
total_envstep_count: 116928
total_train_sample_count: 116928
total_episode_count: 1008
total_duration: 7142.4579085898085
[2024-12-27 13:56:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.9505049670652
avg_train_sample_per_sec: 15.9505049670652
avg_episode_per_sec: 0.13750435316435516
collect_time: 43.6349821800068
reward_mean: -123.29773576097107
reward_std: 4.158545259667582
reward_max: -117.67366946778714
reward_min: -130.05742296918768
queue_len: 0.08176242424467578
wait_time: 0.7913263559181406
delay_time: 4.947364601056264
pressure: 0.9997789566755083
total_envstep_count: 117624
total_train_sample_count: 117624
total_episode_count: 1014
total_duration: 7186.092890769815
[2024-12-27 13:57:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.774902379637243
avg_train_sample_per_sec: 15.774902379637243
avg_episode_per_sec: 0.1359905377554935
collect_time: 44.12071677213162
reward_mean: -122.77182539682542
reward_std: 1.028844589321768
reward_max: -121.51610644257707
reward_min: -123.86904761904762
queue_len: 0.08141367731884976
wait_time: 0.7897693781314471
delay_time: 4.984612050385555
pressure: 0.9909372236958444
total_envstep_count: 118320
total_train_sample_count: 118320
total_episode_count: 1020
total_duration: 7230.213607541947
[2024-12-27 13:57:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.0389638807878
avg_train_sample_per_sec: 16.0389638807878
avg_episode_per_sec: 0.13826693000679138
collect_time: 43.394324295081205
reward_mean: -127.08870214752567
reward_std: 3.4738684043488224
reward_max: -122.04341736694674
reward_min: -132.68347338935573
queue_len: 0.08427632768403559
wait_time: 0.8163373771259166
delay_time: 5.1230123261840825
pressure: 1.0257515473032714
total_envstep_count: 119016
total_train_sample_count: 119016
total_episode_count: 1026
total_duration: 7273.6079318370275
[2024-12-27 13:58:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.845654300846967
avg_train_sample_per_sec: 15.845654300846967
avg_episode_per_sec: 0.13660046811074972
collect_time: 43.923714779187
reward_mean: -123.31851073762836
reward_std: 4.633232211528121
reward_max: -116.25770308123253
reward_min: -130.43487394957984
queue_len: 0.08177620075439547
wait_time: 0.7889639940856977
delay_time: 4.982404608596581
pressure: 1.0081786030061892
total_envstep_count: 119712
total_train_sample_count: 119712
total_episode_count: 1032
total_duration: 7317.531646616215
[2024-12-27 13:59:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.801548805800271
avg_train_sample_per_sec: 15.801548805800271
avg_episode_per_sec: 0.1362202483258644
collect_time: 44.04631524123252
reward_mean: -124.78688141923435
reward_std: 4.1048948913686925
reward_max: -119.81302521008408
reward_min: -130.4425770308123
queue_len: 0.08274992136554003
wait_time: 0.8075216492432516
delay_time: 4.99171808194568
pressure: 0.9985632183908048
total_envstep_count: 120408
total_train_sample_count: 120408
total_episode_count: 1038
total_duration: 7361.577961857447
[2024-12-27 14:00:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.228928501600443
avg_train_sample_per_sec: 16.228928501600443
avg_episode_per_sec: 0.13990455604827967
collect_time: 42.886380325809114
reward_mean: -124.11227824463117
reward_std: 2.6185963509561523
reward_max: -121.95098039215688
reward_min: -129.4341736694678
queue_len: 0.0823025717802594
wait_time: 0.7957760137653646
delay_time: 5.0774822810457465
pressure: 1.003205128205128
total_envstep_count: 121104
total_train_sample_count: 121104
total_episode_count: 1044
total_duration: 7404.464342183256
[2024-12-27 14:00:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.842331871085083
avg_train_sample_per_sec: 15.842331871085083
avg_episode_per_sec: 0.1365718264748714
collect_time: 43.932926393892615
reward_mean: -122.7281746031746
reward_std: 2.039660624088449
reward_max: -120.57913165266103
reward_min: -126.74859943977589
queue_len: 0.08138473116921392
wait_time: 0.7869127646637787
delay_time: 4.988169912851924
pressure: 0.9835322723253758
total_envstep_count: 121800
total_train_sample_count: 121800
total_episode_count: 1050
total_duration: 7448.397268577149
[2024-12-27 14:01:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.963614577309974
avg_train_sample_per_sec: 15.963614577309974
avg_episode_per_sec: 0.13761736704577562
collect_time: 43.599148340079935
reward_mean: -120.85702614379083
reward_std: 1.2580777569482764
reward_max: -119.04831932773112
reward_min: -123.08543417366946
queue_len: 0.08014391654097534
wait_time: 0.7744133683535305
delay_time: 4.938570342767451
pressure: 0.9750221043324491
total_envstep_count: 122496
total_train_sample_count: 122496
total_episode_count: 1056
total_duration: 7491.996416917229
[2024-12-27 14:02:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.75932545056315
avg_train_sample_per_sec: 15.75932545056315
avg_episode_per_sec: 0.13585625388416508
collect_time: 44.16432684148476
reward_mean: -124.71988795518207
reward_std: 3.2879350688942246
reward_max: -119.84453781512605
reward_min: -129.94887955182074
queue_len: 0.08270549599150005
wait_time: 0.8051446595437467
delay_time: 5.0027376355756745
pressure: 0.9995579133510168
total_envstep_count: 123192
total_train_sample_count: 123192
total_episode_count: 1062
total_duration: 7536.160743758714
[2024-12-27 14:03:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.845811707165339
avg_train_sample_per_sec: 15.845811707165339
avg_episode_per_sec: 0.13660182506177015
collect_time: 43.92327845756711
reward_mean: -121.03851540616245
reward_std: 5.334851034603875
reward_max: -110.77871148459384
reward_min: -127.0833333333333
queue_len: 0.08026426751071782
wait_time: 0.7746867314565082
delay_time: 4.983288131338046
pressure: 0.9790008841732979
total_envstep_count: 123888
total_train_sample_count: 123888
total_episode_count: 1068
total_duration: 7580.084022216281
[2024-12-27 14:03:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.896033559915747
avg_train_sample_per_sec: 15.896033559915747
avg_episode_per_sec: 0.1370347720682392
collect_time: 43.784507460720846
reward_mean: -124.49253034547154
reward_std: 4.113252891328005
reward_max: -119.25420168067225
reward_min: -132.37605042016807
queue_len: 0.0825547283458034
wait_time: 0.7987727142138906
delay_time: 5.093612725663642
pressure: 0.9985632183908045
total_envstep_count: 124584
total_train_sample_count: 124584
total_episode_count: 1074
total_duration: 7623.868529677002
[2024-12-27 14:04:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.059379791891494
avg_train_sample_per_sec: 16.059379791891494
avg_episode_per_sec: 0.13844292924044393
collect_time: 43.33915811315551
reward_mean: -120.50070028011203
reward_std: 1.6398875219327327
reward_max: -118.40056022408965
reward_min: -122.98599439775909
queue_len: 0.07990762618044565
wait_time: 0.7700964448555725
delay_time: 4.865934438431705
pressure: 0.9757957559681696
total_envstep_count: 125280
total_train_sample_count: 125280
total_episode_count: 1080
total_duration: 7667.207687790157
[2024-12-27 14:05:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.969388731500876
avg_train_sample_per_sec: 15.969388731500876
avg_episode_per_sec: 0.13766714423707652
collect_time: 43.5833839166984
reward_mean: -122.20506535947713
reward_std: 4.502840389267757
reward_max: -117.26400560224091
reward_min: -129.359243697479
queue_len: 0.0810378417503164
wait_time: 0.7802837094165694
delay_time: 5.0017720134417
pressure: 0.9787798408488063
total_envstep_count: 125976
total_train_sample_count: 125976
total_episode_count: 1086
total_duration: 7710.791071706855
[2024-12-27 14:06:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.927173017547792
avg_train_sample_per_sec: 15.927173017547792
avg_episode_per_sec: 0.13730321566851544
collect_time: 43.69890370583535
reward_mean: -122.69747899159661
reward_std: 3.0589353242243043
reward_max: -117.30742296918768
reward_min: -125.56862745098037
queue_len: 0.08136437598912244
wait_time: 0.7872064829468481
delay_time: 5.015046329500321
pressure: 0.9919319186560566
total_envstep_count: 126672
total_train_sample_count: 126672
total_episode_count: 1092
total_duration: 7754.489975412691
[2024-12-27 14:06:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.077576615338824
avg_train_sample_per_sec: 16.077576615338824
avg_episode_per_sec: 0.13859979840809333
collect_time: 43.290106254942714
reward_mean: -123.76785714285717
reward_std: 4.240631022981482
reward_max: -118.92997198879551
reward_min: -131.95028011204485
queue_len: 0.08207417582417584
wait_time: 0.7902750843927313
delay_time: 5.0575707919396615
pressure: 0.996131741821397
total_envstep_count: 127368
total_train_sample_count: 127368
total_episode_count: 1098
total_duration: 7797.780081667634
[2024-12-27 14:07:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.04791119669126
avg_train_sample_per_sec: 16.04791119669126
avg_episode_per_sec: 0.1383440620404419
collect_time: 43.37013032222539
reward_mean: -125.86472922502337
reward_std: 2.208191824423622
reward_max: -122.15266106442573
reward_min: -129.1176470588236
queue_len: 0.08346467455240277
wait_time: 0.8107300280855049
delay_time: 5.115131036407443
pressure: 1.0143678160919538
total_envstep_count: 128064
total_train_sample_count: 128064
total_episode_count: 1104
total_duration: 7841.150211989859
[2024-12-27 14:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.914296250229532
avg_train_sample_per_sec: 15.914296250229532
avg_episode_per_sec: 0.13719220905370286
collect_time: 43.734261889837676
reward_mean: -124.59278711484596
reward_std: 5.397541643419503
reward_max: -116.7044817927171
reward_min: -134.1351540616247
queue_len: 0.08262121161461933
wait_time: 0.8009752530543607
delay_time: 5.031643916960174
pressure: 1.0153625110521662
total_envstep_count: 128760
total_train_sample_count: 128760
total_episode_count: 1110
total_duration: 7884.884473879696
[2024-12-27 14:09:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.841220371388516
avg_train_sample_per_sec: 15.841220371388516
avg_episode_per_sec: 0.1365622445809355
collect_time: 43.93600894897431
reward_mean: -121.06150793650795
reward_std: 2.3457915354864363
reward_max: -116.31442577030813
reward_min: -123.3830532212885
queue_len: 0.08027951454675593
wait_time: 0.7739511587128219
delay_time: 4.83325649209102
pressure: 0.9798850574712642
total_envstep_count: 129456
total_train_sample_count: 129456
total_episode_count: 1116
total_duration: 7928.820482828671
[2024-12-27 14:09:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.159898465874846
avg_train_sample_per_sec: 16.159898465874846
avg_episode_per_sec: 0.13930946953340387
collect_time: 43.069577539101246
reward_mean: -120.76423902894491
reward_std: 2.999391216164935
reward_max: -117.60574229691879
reward_min: -126.69537815126051
queue_len: 0.08008238662396877
wait_time: 0.7663291886162069
delay_time: 4.902814523313443
pressure: 0.9797745358090185
total_envstep_count: 130152
total_train_sample_count: 130152
total_episode_count: 1122
total_duration: 7971.890060367772
[2024-12-27 14:10:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.07573155409029
avg_train_sample_per_sec: 16.07573155409029
avg_episode_per_sec: 0.1385838927076749
collect_time: 43.29507479383796
reward_mean: -121.92180205415498
reward_std: 3.8086138229988635
reward_max: -116.55602240896357
reward_min: -127.34453781512602
queue_len: 0.08085000136217174
wait_time: 0.7786401253693342
delay_time: 4.975615781359116
pressure: 0.9857427055702916
total_envstep_count: 130848
total_train_sample_count: 130848
total_episode_count: 1128
total_duration: 8015.18513516161
[2024-12-27 14:11:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.933454313631383
avg_train_sample_per_sec: 15.933454313631383
avg_episode_per_sec: 0.13735736477268434
collect_time: 43.681676697347314
reward_mean: -122.66118113912232
reward_std: 4.480735414075596
reward_max: -115.86764705882354
reward_min: -128.203081232493
queue_len: 0.08134030579517396
wait_time: 0.7807399595558824
delay_time: 4.947853233662587
pressure: 0.997347480106101
total_envstep_count: 131544
total_train_sample_count: 131544
total_episode_count: 1134
total_duration: 8058.866811858957
[2024-12-27 14:12:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.974390658723571
avg_train_sample_per_sec: 15.974390658723571
avg_episode_per_sec: 0.13771026429934113
collect_time: 43.569737016536294
reward_mean: -122.36636321195145
reward_std: 4.3710573879276495
reward_max: -115.73669467787113
reward_min: -130.28081232492997
queue_len: 0.08114480319094923
wait_time: 0.7817463413305198
delay_time: 5.01831438426395
pressure: 0.9798850574712644
total_envstep_count: 132240
total_train_sample_count: 132240
total_episode_count: 1140
total_duration: 8102.436548875493
[2024-12-27 14:12:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.83923241238192
avg_train_sample_per_sec: 15.83923241238192
avg_episode_per_sec: 0.13654510700329242
collect_time: 43.94152329351008
reward_mean: -123.69584500466853
reward_std: 1.4027824146471763
reward_max: -121.24649859943979
reward_min: -125.40756302521007
queue_len: 0.08202642241688896
wait_time: 0.7940038747594529
delay_time: 5.01820309089003
pressure: 1.0080680813439435
total_envstep_count: 132936
total_train_sample_count: 132936
total_episode_count: 1146
total_duration: 8146.378072169003
[2024-12-27 14:13:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.042522115890907
avg_train_sample_per_sec: 16.042522115890907
avg_episode_per_sec: 0.1382976044473354
collect_time: 43.38469942395017
reward_mean: -122.94316059757237
reward_std: 2.6050423122504505
reward_max: -118.05952380952382
reward_min: -125.36834733893559
queue_len: 0.08152729482597637
wait_time: 0.7883863094309342
delay_time: 5.016632525747027
pressure: 0.9900530503978779
total_envstep_count: 133632
total_train_sample_count: 133632
total_episode_count: 1152
total_duration: 8189.762771592953
[2024-12-27 14:14:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.942968538401441
avg_train_sample_per_sec: 15.942968538401441
avg_episode_per_sec: 0.13743938395173658
collect_time: 43.655608949083835
reward_mean: -123.19094304388425
reward_std: 3.6392065892934253
reward_max: -117.91596638655462
reward_min: -128.05882352941182
queue_len: 0.08169160679302667
wait_time: 0.7875529079890136
delay_time: 5.032212761592317
pressure: 0.9981211317418213
total_envstep_count: 134328
total_train_sample_count: 134328
total_episode_count: 1158
total_duration: 8233.418380542036
[2024-12-27 14:14:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.771986296473184
avg_train_sample_per_sec: 15.771986296473184
avg_episode_per_sec: 0.13596539910752745
collect_time: 44.1288742531836
reward_mean: -123.37161531279177
reward_std: 4.4795401060749
reward_max: -117.26400560224093
reward_min: -130.04061624649856
queue_len: 0.08181141598991497
wait_time: 0.7886229093759519
delay_time: 5.064353302663409
pressure: 1.0013262599469497
total_envstep_count: 135024
total_train_sample_count: 135024
total_episode_count: 1164
total_duration: 8277.54725479522
[2024-12-27 14:15:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.828641206367875
avg_train_sample_per_sec: 15.828641206367875
avg_episode_per_sec: 0.13645380350317135
collect_time: 43.97092529458553
reward_mean: -122.92542016806725
reward_std: 1.313878636437178
reward_max: -121.26120448179277
reward_min: -125.28641456582635
queue_len: 0.08151553061542921
wait_time: 0.7888315693209202
delay_time: 4.9630740683620935
pressure: 0.9982316534040673
total_envstep_count: 135720
total_train_sample_count: 135720
total_episode_count: 1170
total_duration: 8321.518180089804
[2024-12-27 14:16:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.878896735189665
avg_train_sample_per_sec: 15.878896735189665
avg_episode_per_sec: 0.13688704082060058
collect_time: 43.83176058180258
reward_mean: -123.50058356676003
reward_std: 5.0583656287770555
reward_max: -116.32843137254899
reward_min: -131.5035014005602
queue_len: 0.08189693870474803
wait_time: 0.7888350521464114
delay_time: 5.001174557987963
pressure: 1.0013262599469497
total_envstep_count: 136416
total_train_sample_count: 136416
total_episode_count: 1176
total_duration: 8365.349940671607
[2024-12-27 14:17:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.046843053631438
avg_train_sample_per_sec: 16.046843053631438
avg_episode_per_sec: 0.13833485391061587
collect_time: 43.373017214279635
reward_mean: -122.01388888888891
reward_std: 3.0741769820976645
reward_max: -115.53921568627452
reward_min: -124.9817927170868
queue_len: 0.08091106690244622
wait_time: 0.7850242218903477
delay_time: 4.939561589898456
pressure: 0.9880636604774535
total_envstep_count: 137112
total_train_sample_count: 137112
total_episode_count: 1182
total_duration: 8408.722957885888
[2024-12-27 14:17:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.038610224271594
avg_train_sample_per_sec: 16.038610224271594
avg_episode_per_sec: 0.13826388124372063
collect_time: 43.395281153894956
reward_mean: -126.55695611577964
reward_std: 3.572462128385895
reward_max: -122.01750700280115
reward_min: -133.78851540616247
queue_len: 0.08392371095210854
wait_time: 0.8176180507569959
delay_time: 5.251599083661386
pressure: 1.023209549071618
total_envstep_count: 137808
total_train_sample_count: 137808
total_episode_count: 1188
total_duration: 8452.118239039783
[2024-12-27 14:18:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.26028363165488
avg_train_sample_per_sec: 16.26028363165488
avg_episode_per_sec: 0.14017485889357656
collect_time: 42.80368139735611
reward_mean: -120.8251633986928
reward_std: 4.69165942656703
reward_max: -116.07773109243692
reward_min: -129.8501400560224
queue_len: 0.08012278739966366
wait_time: 0.779199312350935
delay_time: 4.8854493394385035
pressure: 0.9757957559681697
total_envstep_count: 138504
total_train_sample_count: 138504
total_episode_count: 1194
total_duration: 8494.921920437138
[2024-12-27 14:19:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.76485868716724
avg_train_sample_per_sec: 15.76485868716724
avg_episode_per_sec: 0.1359039541997176
collect_time: 44.14882580371946
reward_mean: -122.29913632119514
reward_std: 3.1559371982785382
reward_max: -116.63585434173665
reward_min: -125.78711484593839
queue_len: 0.08110022302466521
wait_time: 0.785985404329725
delay_time: 4.970314691336446
pressure: 0.9885057471264368
total_envstep_count: 139200
total_train_sample_count: 139200
total_episode_count: 1200
total_duration: 8539.070746240857
[2024-12-27 14:20:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.05635056036203
avg_train_sample_per_sec: 16.05635056036203
avg_episode_per_sec: 0.13841681517553475
collect_time: 43.34733458786085
reward_mean: -118.24906629318394
reward_std: 4.081081224776543
reward_max: -111.34453781512603
reward_min: -123.96498599439775
queue_len: 0.07841450019441905
wait_time: 0.7552777963528472
delay_time: 4.727781584242732
pressure: 0.9679487179487181
total_envstep_count: 139896
total_train_sample_count: 139896
total_episode_count: 1206
total_duration: 8582.418080828718
[2024-12-27 14:20:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.127695285872147
avg_train_sample_per_sec: 16.127695285872147
avg_episode_per_sec: 0.1390318559126909
collect_time: 43.155577264018355
reward_mean: -122.88165266106444
reward_std: 2.6678094954319076
reward_max: -118.81232492997201
reward_min: -126.46988795518213
queue_len: 0.08148650706967137
wait_time: 0.7919838359747082
delay_time: 4.94821290263672
pressure: 0.997236958443855
total_envstep_count: 140592
total_train_sample_count: 140592
total_episode_count: 1212
total_duration: 8625.573658092737
[2024-12-27 14:21:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.977331345090104
avg_train_sample_per_sec: 15.977331345090104
avg_episode_per_sec: 0.1377356150438802
collect_time: 43.56171784682199
reward_mean: -123.04154995331464
reward_std: 4.021318583588679
reward_max: -116.53291316526611
reward_min: -129.83753501400562
queue_len: 0.08159253975683994
wait_time: 0.7918289663345442
delay_time: 4.978825349325659
pressure: 1.0046419098143236
total_envstep_count: 141288
total_train_sample_count: 141288
total_episode_count: 1218
total_duration: 8669.135375939559
[2024-12-27 14:22:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.955053832965929
avg_train_sample_per_sec: 15.955053832965929
avg_episode_per_sec: 0.13754356752556834
collect_time: 43.62254162765295
reward_mean: -121.43078898225956
reward_std: 3.2529860579037666
reward_max: -118.2450980392157
reward_min: -127.37955182072828
queue_len: 0.08052439587682995
wait_time: 0.7793868431545915
delay_time: 4.9243521976589975
pressure: 0.9809902740937225
total_envstep_count: 141984
total_train_sample_count: 141984
total_episode_count: 1224
total_duration: 8712.757917567213
[2024-12-27 14:23:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.084335947525588
avg_train_sample_per_sec: 16.084335947525588
avg_episode_per_sec: 0.13865806851315163
collect_time: 43.27191388383507
reward_mean: -120.78104575163398
reward_std: 5.164385074408512
reward_max: -115.6911764705882
reward_min: -130.8732492997199
queue_len: 0.08009353166553977
wait_time: 0.7691669948262239
delay_time: 4.931261524354094
pressure: 0.9771220159151195
total_envstep_count: 142680
total_train_sample_count: 142680
total_episode_count: 1230
total_duration: 8756.029831451047
[2024-12-27 14:23:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.957701556087944
avg_train_sample_per_sec: 15.957701556087944
avg_episode_per_sec: 0.13756639272489607
collect_time: 43.61530371737479
reward_mean: -123.99288048552752
reward_std: 4.329436384550775
reward_max: -118.70028011204481
reward_min: -129.828431372549
queue_len: 0.08222339554743206
wait_time: 0.7942294844551437
delay_time: 5.003594529270918
pressure: 1.0145888594164456
total_envstep_count: 143376
total_train_sample_count: 143376
total_episode_count: 1236
total_duration: 8799.645135168423
[2024-12-27 14:24:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.972678972603674
avg_train_sample_per_sec: 15.972678972603674
avg_episode_per_sec: 0.13769550838451444
collect_time: 43.574406096421185
reward_mean: -123.63433706816058
reward_std: 2.7134144826325994
reward_max: -119.33613445378151
reward_min: -128.58193277310926
queue_len: 0.08198563466058394
wait_time: 0.8027370983760437
delay_time: 4.962390084218833
pressure: 1.0101679929266136
total_envstep_count: 144072
total_train_sample_count: 144072
total_episode_count: 1242
total_duration: 8843.219541264843
[2024-12-27 14:25:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.239709465237215
avg_train_sample_per_sec: 16.239709465237215
avg_episode_per_sec: 0.139997495389976
collect_time: 42.857909588214014
reward_mean: -121.7700746965453
reward_std: 4.92471037689347
reward_max: -118.18067226890759
reward_min: -130.96078431372547
queue_len: 0.08074938640354462
wait_time: 0.7871591165201713
delay_time: 4.859287988370438
pressure: 1.0030946065428825
total_envstep_count: 144768
total_train_sample_count: 144768
total_episode_count: 1248
total_duration: 8886.077450853058
[2024-12-27 14:26:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.73258058874623
avg_train_sample_per_sec: 15.73258058874623
avg_episode_per_sec: 0.13562569473057096
collect_time: 44.23940472282469
reward_mean: -126.22478991596638
reward_std: 4.560003615795292
reward_max: -119.76680672268907
reward_min: -134.2675070028011
queue_len: 0.08370344158883714
wait_time: 0.8103123212149582
delay_time: 5.146199887028577
pressure: 1.0206675508399647
total_envstep_count: 145464
total_train_sample_count: 145464
total_episode_count: 1254
total_duration: 8930.316855575882
[2024-12-27 14:26:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.110354424491113
avg_train_sample_per_sec: 16.110354424491113
avg_episode_per_sec: 0.13888236572837168
collect_time: 43.2020290591456
reward_mean: -125.11963118580765
reward_std: 5.0711656842548845
reward_max: -117.0336134453782
reward_min: -131.59523809523805
queue_len: 0.08297057770942153
wait_time: 0.7997237577612832
delay_time: 5.0437699496038055
pressure: 1.0072944297082227
total_envstep_count: 146160
total_train_sample_count: 146160
total_episode_count: 1260
total_duration: 8973.518884635028
[2024-12-27 14:27:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.718882502090487
avg_train_sample_per_sec: 16.718882502090487
avg_episode_per_sec: 0.14412829743181454
collect_time: 41.62957661272958
reward_mean: -126.70856676003736
reward_std: 4.46393858917863
reward_max: -119.47198879551824
reward_min: -133.2163865546218
queue_len: 0.08402424851461364
wait_time: 0.8183231294286063
delay_time: 5.06312155918151
pressure: 1.0352564102564104
total_envstep_count: 146856
total_train_sample_count: 146856
total_episode_count: 1266
total_duration: 9015.148461247758
[2024-12-27 14:28:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.57837392733102
avg_train_sample_per_sec: 16.57837392733102
avg_episode_per_sec: 0.1429170166149226
collect_time: 41.98240448977798
reward_mean: -122.8608776844071
reward_std: 5.308077390095456
reward_max: -118.09873949579827
reward_min: -132.83823529411765
queue_len: 0.08147273055995165
wait_time: 0.7844127925263829
delay_time: 4.980375452462088
pressure: 1.0039787798408488
total_envstep_count: 147552
total_train_sample_count: 147552
total_episode_count: 1272
total_duration: 9057.130865737536
[2024-12-27 14:28:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51773410222095
avg_train_sample_per_sec: 16.51773410222095
avg_episode_per_sec: 0.14239425950190474
collect_time: 42.136530088979754
reward_mean: -126.51937441643325
reward_std: 4.34580510393566
reward_max: -119.79271708683474
reward_min: -134.16736694677874
queue_len: 0.0838987894008178
wait_time: 0.8207687694883435
delay_time: 5.019164054353852
pressure: 1.0422192749778956
total_envstep_count: 148248
total_train_sample_count: 148248
total_episode_count: 1278
total_duration: 9099.267395826515
[2024-12-27 14:29:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.3628913196077
avg_train_sample_per_sec: 16.3628913196077
avg_episode_per_sec: 0.1410594079276526
collect_time: 42.535269984100005
reward_mean: -123.5716619981326
reward_std: 6.794198879964419
reward_max: -115.46918767507006
reward_min: -133.96148459383755
queue_len: 0.08194407294305874
wait_time: 0.794875896866262
delay_time: 4.941103137610701
pressure: 1.0061892130857648
total_envstep_count: 148944
total_train_sample_count: 148944
total_episode_count: 1284
total_duration: 9141.802665810616
[2024-12-27 14:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.57114219936733
avg_train_sample_per_sec: 16.57114219936733
avg_episode_per_sec: 0.14285467413247696
collect_time: 42.00072581759468
reward_mean: -124.50431839402427
reward_std: 2.3756403028547273
reward_max: -120.08823529411764
reward_min: -127.0441176470588
queue_len: 0.08256254535412749
wait_time: 0.8022730312284065
delay_time: 5.095237851276973
pressure: 1.000552608311229
total_envstep_count: 149640
total_train_sample_count: 149640
total_episode_count: 1290
total_duration: 9183.80339162821
[2024-12-27 14:31:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.784183852004748
avg_train_sample_per_sec: 16.784183852004748
avg_episode_per_sec: 0.1446912401034892
collect_time: 41.46761058726534
reward_mean: -122.11449579831934
reward_std: 2.6597290358486885
reward_max: -118.6372549019608
reward_min: -126.60714285714288
queue_len: 0.0809777823596282
wait_time: 0.7806957663702084
delay_time: 4.890532471362835
pressure: 0.9801061007957559
total_envstep_count: 150336
total_train_sample_count: 150336
total_episode_count: 1296
total_duration: 9225.271002215475
[2024-12-27 14:31:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.515516755751854
avg_train_sample_per_sec: 16.515516755751854
avg_episode_per_sec: 0.14237514444613666
collect_time: 42.14218727110699
reward_mean: -123.73167600373483
reward_std: 4.839844525694303
reward_max: -116.1547619047619
reward_min: -131.52100840336126
queue_len: 0.08205018302634935
wait_time: 0.7944026969762263
delay_time: 5.018190961659857
pressure: 1.0088417329796642
total_envstep_count: 151032
total_train_sample_count: 151032
total_episode_count: 1302
total_duration: 9267.413189486582
[2024-12-27 14:32:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.231147303524768
avg_train_sample_per_sec: 16.231147303524768
avg_episode_per_sec: 0.13992368365107558
collect_time: 42.880517746817326
reward_mean: -123.00198412698411
reward_std: 3.914956419012138
reward_max: -116.20798319327733
reward_min: -128.125350140056
queue_len: 0.08156630247147488
wait_time: 0.7951806053986581
delay_time: 4.902048984281829
pressure: 1.0011052166224579
total_envstep_count: 151728
total_train_sample_count: 151728
total_episode_count: 1308
total_duration: 9310.293707233399
[2024-12-27 14:33:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.363345729756617
avg_train_sample_per_sec: 16.363345729756617
avg_episode_per_sec: 0.14106332525652257
collect_time: 42.53408877955377
reward_mean: -125.05240429505137
reward_std: 3.6126789790978098
reward_max: -119.5105042016807
reward_min: -130.44047619047623
queue_len: 0.08292599754313751
wait_time: 0.8073910819854023
delay_time: 5.014311680697463
pressure: 1.0179045092838197
total_envstep_count: 152424
total_train_sample_count: 152424
total_episode_count: 1314
total_duration: 9352.827796012953
[2024-12-27 14:33:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52928342856613
avg_train_sample_per_sec: 16.52928342856613
avg_episode_per_sec: 0.14249382266005287
collect_time: 42.107088489823056
reward_mean: -123.31279178338002
reward_std: 3.642815515904085
reward_max: -118.29131652661067
reward_min: -129.77661064425766
queue_len: 0.08177240834441647
wait_time: 0.795629115925769
delay_time: 5.007884494806773
pressure: 1.0076259946949602
total_envstep_count: 153120
total_train_sample_count: 153120
total_episode_count: 1320
total_duration: 9394.934884502776
[2024-12-27 14:34:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.523788613366705
avg_train_sample_per_sec: 16.523788613366705
avg_episode_per_sec: 0.14244645356350608
collect_time: 42.121090767100455
reward_mean: -120.01435574229691
reward_std: 2.190966673050118
reward_max: -117.28291316526614
reward_min: -124.15966386554621
queue_len: 0.0795851165399847
wait_time: 0.7693796793695373
delay_time: 4.809055668531621
pressure: 0.9677276746242263
total_envstep_count: 153816
total_train_sample_count: 153816
total_episode_count: 1326
total_duration: 9437.055975269877
[2024-12-27 14:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61647042984488
avg_train_sample_per_sec: 16.61647042984488
avg_episode_per_sec: 0.1432454347400421
collect_time: 41.886151631210005
reward_mean: -124.21860410831
reward_std: 4.464670520693578
reward_max: -118.18557422969187
reward_min: -132.64495798319328
queue_len: 0.08237307964742042
wait_time: 0.7946533056193301
delay_time: 4.983655827485769
pressure: 1.0004420866489832
total_envstep_count: 154512
total_train_sample_count: 154512
total_episode_count: 1332
total_duration: 9478.942126901087
[2024-12-27 14:36:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.393634923637492
avg_train_sample_per_sec: 16.393634923637492
avg_episode_per_sec: 0.14132443899687494
collect_time: 42.45550198244676
reward_mean: -119.58356676003734
reward_std: 4.056127890239307
reward_max: -114.33893557422975
reward_min: -125.24999999999999
queue_len: 0.07929944745360568
wait_time: 0.7677985539927731
delay_time: 4.895274834190654
pressure: 0.9757957559681697
total_envstep_count: 155208
total_train_sample_count: 155208
total_episode_count: 1338
total_duration: 9521.397628883535
[2024-12-27 14:36:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.65833747749822
avg_train_sample_per_sec: 16.65833747749822
avg_episode_per_sec: 0.14360635756463982
collect_time: 41.78088005121425
reward_mean: -124.09628851540616
reward_std: 4.206305514718608
reward_max: -118.61904761904759
reward_min: -131.43277310924367
queue_len: 0.08229196851154254
wait_time: 0.7921846789113524
delay_time: 4.9966736000552645
pressure: 1.0091732979664014
total_envstep_count: 155904
total_train_sample_count: 155904
total_episode_count: 1344
total_duration: 9563.178508934749
[2024-12-27 14:37:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.472173454252875
avg_train_sample_per_sec: 16.472173454252875
avg_episode_per_sec: 0.14200149529528341
collect_time: 42.253076191369445
reward_mean: -123.08041549953316
reward_std: 2.6540523373508322
reward_max: -118.31862745098042
reward_min: -126.74579831932782
queue_len: 0.08161831266547293
wait_time: 0.7903229151961405
delay_time: 4.8981750964072885
pressure: 1.0023209549071617
total_envstep_count: 156600
total_train_sample_count: 156600
total_episode_count: 1350
total_duration: 9605.431585126118
[2024-12-27 14:38:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.581306766676096
avg_train_sample_per_sec: 16.581306766676096
avg_episode_per_sec: 0.14294229971272496
collect_time: 41.974978799546136
reward_mean: -124.08251633986926
reward_std: 2.874128495395369
reward_max: -121.07002801120447
reward_min: -129.45938375350138
queue_len: 0.08228283576914407
wait_time: 0.7952922106066121
delay_time: 4.9867005549654415
pressure: 1.017241379310345
total_envstep_count: 157296
total_train_sample_count: 157296
total_episode_count: 1356
total_duration: 9647.406563925664
[2024-12-27 14:38:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.447063108046194
avg_train_sample_per_sec: 16.447063108046194
avg_episode_per_sec: 0.1417850267935017
collect_time: 42.31758554264344
reward_mean: -122.69957983193275
reward_std: 2.147825013137376
reward_max: -120.9782913165266
reward_min: -127.30882352941174
queue_len: 0.08136576911931881
wait_time: 0.7856447839967111
delay_time: 4.935713135111122
pressure: 0.9976790450928382
total_envstep_count: 157992
total_train_sample_count: 157992
total_episode_count: 1362
total_duration: 9689.724149468308
[2024-12-27 14:39:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55290809035899
avg_train_sample_per_sec: 16.55290809035899
avg_episode_per_sec: 0.1426974835375775
collect_time: 42.046992359329025
reward_mean: -120.7139355742297
reward_std: 3.6858574698944504
reward_max: -117.58473389355747
reward_min: -127.32072829131651
queue_len: 0.0800490288953778
wait_time: 0.768762832277031
delay_time: 4.879699007637678
pressure: 0.9795534924845269
total_envstep_count: 158688
total_train_sample_count: 158688
total_episode_count: 1368
total_duration: 9731.771141827636
[2024-12-27 14:40:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.524637621889763
avg_train_sample_per_sec: 16.524637621889763
avg_episode_per_sec: 0.14245377260249797
collect_time: 42.11892665519192
reward_mean: -125.28513071895424
reward_std: 3.4011723472720945
reward_max: -120.46778711484596
reward_min: -129.19887955182065
queue_len: 0.08308032541044712
wait_time: 0.8060553023154444
delay_time: 5.061845085443831
pressure: 1.0170203359858532
total_envstep_count: 159384
total_train_sample_count: 159384
total_episode_count: 1374
total_duration: 9773.890068482828
[2024-12-27 14:41:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.599535827939814
avg_train_sample_per_sec: 16.599535827939814
avg_episode_per_sec: 0.1430994467925846
collect_time: 41.92888326603174
reward_mean: -125.6280345471522
reward_std: 3.0940047126434767
reward_max: -121.54131652661064
reward_min: -129.1449579831933
queue_len: 0.08330771521694443
wait_time: 0.8059453224260528
delay_time: 5.030575635832679
pressure: 1.0090627763041555
total_envstep_count: 160080
total_train_sample_count: 160080
total_episode_count: 1380
total_duration: 9815.818951748859
[2024-12-27 14:41:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.522320619661336
avg_train_sample_per_sec: 16.522320619661336
avg_episode_per_sec: 0.14243379844535634
collect_time: 42.1248331890963
reward_mean: -125.04108309990663
reward_std: 3.6756548529612076
reward_max: -120.2366946778711
reward_min: -130.64145658263305
queue_len: 0.08291849011930147
wait_time: 0.8038441725054302
delay_time: 5.038017762713478
pressure: 1.0125994694960214
total_envstep_count: 160776
total_train_sample_count: 160776
total_episode_count: 1386
total_duration: 9857.943784937956
[2024-12-27 14:42:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.442321380213073
avg_train_sample_per_sec: 16.442321380213073
avg_episode_per_sec: 0.14174414982942304
collect_time: 42.329789322666834
reward_mean: -124.38422035480859
reward_std: 5.009080711002301
reward_max: -117.64075630252103
reward_min: -130.1652661064426
queue_len: 0.08248290474456803
wait_time: 0.8013932695093949
delay_time: 5.0514077994473565
pressure: 1.0125994694960212
total_envstep_count: 161472
total_train_sample_count: 161472
total_episode_count: 1392
total_duration: 9900.273574260622
[2024-12-27 14:43:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52335498029455
avg_train_sample_per_sec: 16.52335498029455
avg_episode_per_sec: 0.1424427153473668
collect_time: 42.12219617807866
reward_mean: -125.76062091503267
reward_std: 3.5533413677493217
reward_max: -119.3921568627451
reward_min: -129.40476190476193
queue_len: 0.08339563721156014
wait_time: 0.8096086356735444
delay_time: 5.118522518468399
pressure: 1.030503978779841
total_envstep_count: 162168
total_train_sample_count: 162168
total_episode_count: 1398
total_duration: 9942.395770438701
[2024-12-27 14:43:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.525763183716023
avg_train_sample_per_sec: 16.525763183716023
avg_episode_per_sec: 0.14246347572168985
collect_time: 42.116057955242695
reward_mean: -127.35889355742295
reward_std: 3.371371714159934
reward_max: -122.71218487394961
reward_min: -132.54901960784312
queue_len: 0.08445549970651389
wait_time: 0.8215964436172346
delay_time: 5.166372876754389
pressure: 1.027077807250221
total_envstep_count: 162864
total_train_sample_count: 162864
total_episode_count: 1404
total_duration: 9984.511828393945
[2024-12-27 14:44:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.522628911957643
avg_train_sample_per_sec: 16.522628911957643
avg_episode_per_sec: 0.1424364561375659
collect_time: 42.12404719059542
reward_mean: -124.16981792717087
reward_std: 3.375848501967573
reward_max: -119.33963585434175
reward_min: -129.33193277310923
queue_len: 0.0823407280684157
wait_time: 0.7876460929199265
delay_time: 5.099551551261066
pressure: 1.0029840848806366
total_envstep_count: 163560
total_train_sample_count: 163560
total_episode_count: 1410
total_duration: 10026.63587558454
[2024-12-27 14:45:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.599842974320776
avg_train_sample_per_sec: 16.599842974320776
avg_episode_per_sec: 0.1431020946062136
collect_time: 41.92810745720193
reward_mean: -125.26237161531282
reward_std: 3.6447620355297254
reward_max: -121.10574229691883
reward_min: -130.61484593837537
queue_len: 0.08306523316665305
wait_time: 0.8002085670696218
delay_time: 5.146017448770803
pressure: 1.0070733863837311
total_envstep_count: 164256
total_train_sample_count: 164256
total_episode_count: 1416
total_duration: 10068.563983041742
[2024-12-27 14:46:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.499119199439292
avg_train_sample_per_sec: 16.499119199439292
avg_episode_per_sec: 0.14223378620206287
collect_time: 42.18407004560903
reward_mean: -122.24929971988796
reward_std: 4.320294349334045
reward_max: -115.9936974789916
reward_min: -126.30952380952378
queue_len: 0.08106717488056231
wait_time: 0.7790937440404986
delay_time: 4.927098846681532
pressure: 0.9965738284703803
total_envstep_count: 164952
total_train_sample_count: 164952
total_episode_count: 1422
total_duration: 10110.74805308735
[2024-12-27 14:46:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.46493623950346
avg_train_sample_per_sec: 16.46493623950346
avg_episode_per_sec: 0.14193910551296085
collect_time: 42.27164866451919
reward_mean: -124.23190943043885
reward_std: 2.5248749856202704
reward_max: -119.90336134453781
reward_min: -127.24229691876751
queue_len: 0.0823819028053308
wait_time: 0.7931193918769983
delay_time: 5.054695642828243
pressure: 1.0041998231653404
total_envstep_count: 165648
total_train_sample_count: 165648
total_episode_count: 1428
total_duration: 10153.01970175187
[2024-12-27 14:47:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.349947884190765
avg_train_sample_per_sec: 16.349947884190765
avg_episode_per_sec: 0.14094782658785143
collect_time: 42.568943028435115
reward_mean: -121.08520074696547
reward_std: 2.979131453666917
reward_max: -116.93697478991601
reward_min: -126.65406162464987
queue_len: 0.08029522595952616
wait_time: 0.7750137300720464
delay_time: 4.9600667808295915
pressure: 0.9838638373121132
total_envstep_count: 166344
total_train_sample_count: 166344
total_episode_count: 1434
total_duration: 10195.588644780304
[2024-12-27 14:48:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.24598929701371
avg_train_sample_per_sec: 16.24598929701371
avg_episode_per_sec: 0.14005163187080788
collect_time: 42.84134300937503
reward_mean: -122.93382352941177
reward_std: 3.111884549612115
reward_max: -118.06232492997198
reward_min: -127.72058823529409
queue_len: 0.08152110313621469
wait_time: 0.7814005354573307
delay_time: 4.944699221099991
pressure: 1.0065207780725023
total_envstep_count: 167040
total_train_sample_count: 167040
total_episode_count: 1440
total_duration: 10238.42998778968
[2024-12-27 14:48:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.606232258837878
avg_train_sample_per_sec: 16.606232258837878
avg_episode_per_sec: 0.14315717464515412
collect_time: 41.9119755253084
reward_mean: -121.48996265172735
reward_std: 2.7025301340784877
reward_max: -117.76820728291321
reward_min: -124.59803921568627
queue_len: 0.08056363571069454
wait_time: 0.7789396483615553
delay_time: 4.9121103918873255
pressure: 0.9877320954907162
total_envstep_count: 167736
total_train_sample_count: 167736
total_episode_count: 1446
total_duration: 10280.341963314988
[2024-12-27 14:49:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.939442994404743
avg_train_sample_per_sec: 16.939442994404743
avg_episode_per_sec: 0.14602968098624777
collect_time: 41.08753754358366
reward_mean: -122.57574696545284
reward_std: 4.2748609126852415
reward_max: -114.73179271708682
reward_min: -128.42296918767508
queue_len: 0.08128365183385466
wait_time: 0.782882052025054
delay_time: 4.9512317518896225
pressure: 0.9977895667550839
total_envstep_count: 168432
total_train_sample_count: 168432
total_episode_count: 1452
total_duration: 10321.429500858572
[2024-12-27 14:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.479299854362083
avg_train_sample_per_sec: 16.479299854362083
avg_episode_per_sec: 0.1420629297789835
collect_time: 42.23480403603241
reward_mean: -118.9940476190476
reward_std: 3.081617802016236
reward_max: -115.83823529411758
reward_min: -124.66456582633057
queue_len: 0.07890851964127825
wait_time: 0.764222853155409
delay_time: 4.797322591412651
pressure: 0.9607648099027409
total_envstep_count: 169128
total_train_sample_count: 169128
total_episode_count: 1458
total_duration: 10363.664304894604
[2024-12-27 14:51:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56745265197247
avg_train_sample_per_sec: 16.56745265197247
avg_episode_per_sec: 0.14282286768941785
collect_time: 42.010079317603264
reward_mean: -122.71428571428572
reward_std: 3.580156578433055
reward_max: -116.78151260504205
reward_min: -127.2310924369748
queue_len: 0.08137552103069344
wait_time: 0.7924785519866658
delay_time: 4.989238960141339
pressure: 0.988395225464191
total_envstep_count: 169824
total_train_sample_count: 169824
total_episode_count: 1464
total_duration: 10405.674384212207
[2024-12-27 14:51:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.16953812367276
avg_train_sample_per_sec: 16.16953812367276
avg_episode_per_sec: 0.1393925700316617
collect_time: 43.04390111063421
reward_mean: -123.61309523809523
reward_std: 3.778336511367882
reward_max: -118.1897759103641
reward_min: -129.60364145658264
queue_len: 0.08197154856637615
wait_time: 0.7896851711506884
delay_time: 4.986695488745901
pressure: 1.014367816091954
total_envstep_count: 170520
total_train_sample_count: 170520
total_episode_count: 1470
total_duration: 10448.71828532284
[2024-12-27 14:52:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.047503939275728
avg_train_sample_per_sec: 16.047503939275728
avg_episode_per_sec: 0.1383405512006528
collect_time: 43.3712309798263
reward_mean: -121.87908496732025
reward_std: 1.2012552779214527
reward_max: -119.48669467787114
reward_min: -123.24019607843138
queue_len: 0.08082167438151212
wait_time: 0.7827918081467775
delay_time: 4.8851021841315525
pressure: 0.992263483642794
total_envstep_count: 171216
total_train_sample_count: 171216
total_episode_count: 1476
total_duration: 10492.089516302667
[2024-12-27 14:53:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.530171075097194
avg_train_sample_per_sec: 16.530171075097194
avg_episode_per_sec: 0.14250147478532063
collect_time: 42.104827399428935
reward_mean: -122.05975723622782
reward_std: 3.2863380575470664
reward_max: -116.99509803921566
reward_min: -127.32072829131654
queue_len: 0.08094148357840043
wait_time: 0.7789337662562814
delay_time: 4.883668370077557
pressure: 0.9935897435897436
total_envstep_count: 171912
total_train_sample_count: 171912
total_episode_count: 1482
total_duration: 10534.194343702096
[2024-12-27 14:53:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51938804945778
avg_train_sample_per_sec: 16.51938804945778
avg_episode_per_sec: 0.1424085176677395
collect_time: 42.132311312999576
reward_mean: -122.96381886087771
reward_std: 5.545453544653151
reward_max: -116.84453781512606
reward_min: -131.32773109243703
queue_len: 0.08154099393957408
wait_time: 0.7828016374542742
delay_time: 5.004308744308367
pressure: 0.992263483642794
total_envstep_count: 172608
total_train_sample_count: 172608
total_episode_count: 1488
total_duration: 10576.326655015097
[2024-12-27 14:54:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.451004489943482
avg_train_sample_per_sec: 16.451004489943482
avg_episode_per_sec: 0.1418190042236507
collect_time: 42.30744696626067
reward_mean: -121.61998132586369
reward_std: 3.448559675257541
reward_max: -117.47899159663865
reward_min: -126.18207282913168
queue_len: 0.08064985499062578
wait_time: 0.7821651317467747
delay_time: 4.880716014861406
pressure: 0.9832007073386384
total_envstep_count: 173304
total_train_sample_count: 173304
total_episode_count: 1494
total_duration: 10618.634101981357
[2024-12-27 14:55:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.879860306477635
avg_train_sample_per_sec: 16.879860306477635
avg_episode_per_sec: 0.14551603712480718
collect_time: 41.232568715803325
reward_mean: -122.89075630252103
reward_std: 3.6121706027714997
reward_max: -117.49789915966387
reward_min: -128.53011204481797
queue_len: 0.08149254396718902
wait_time: 0.7805760345694422
delay_time: 4.98830907963238
pressure: 0.9881741821396993
total_envstep_count: 174000
total_train_sample_count: 174000
total_episode_count: 1500
total_duration: 10659.86667069716
[2024-12-27 14:56:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.553611910377242
avg_train_sample_per_sec: 16.553611910377242
avg_episode_per_sec: 0.14270355095152795
collect_time: 42.04520462169871
reward_mean: -122.75746965452849
reward_std: 3.0179250093487227
reward_max: -118.8452380952381
reward_min: -126.41946778711488
queue_len: 0.08140415759584117
wait_time: 0.7883144084335769
delay_time: 4.940240476110585
pressure: 1.0065207780725023
total_envstep_count: 174696
total_train_sample_count: 174696
total_episode_count: 1506
total_duration: 10701.911875318858
[2024-12-27 14:56:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.187073672888705
avg_train_sample_per_sec: 16.187073672888705
avg_episode_per_sec: 0.13954373855938537
collect_time: 42.997271407105025
reward_mean: -124.85749299719889
reward_std: 3.4068529989794367
reward_max: -120.07563025210081
reward_min: -128.92296918767508
queue_len: 0.08279674601936264
wait_time: 0.8010852329437522
delay_time: 5.010966128597317
pressure: 1.0194518125552607
total_envstep_count: 175392
total_train_sample_count: 175392
total_episode_count: 1512
total_duration: 10744.909146725962
[2024-12-27 14:57:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.944368906905726
avg_train_sample_per_sec: 15.944368906905726
avg_episode_per_sec: 0.13745145609401488
collect_time: 43.651774746540944
reward_mean: -119.34570494864614
reward_std: 3.1970879719942
reward_max: -116.06092436974795
reward_min: -125.70798319327734
queue_len: 0.07914171415692715
wait_time: 0.7538367579569406
delay_time: 4.884192735013113
pressure: 0.9829796640141467
total_envstep_count: 176088
total_train_sample_count: 176088
total_episode_count: 1518
total_duration: 10788.560921472503
[2024-12-27 14:58:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.18019854496944
avg_train_sample_per_sec: 16.18019854496944
avg_episode_per_sec: 0.1394844702152538
collect_time: 43.01554137704894
reward_mean: -123.3013538748833
reward_std: 2.7229751904238957
reward_max: -119.43067226890757
reward_min: -127.16806722689078
queue_len: 0.08176482352445842
wait_time: 0.7877262753023402
delay_time: 4.9995309203405
pressure: 1.0051945181255524
total_envstep_count: 176784
total_train_sample_count: 176784
total_episode_count: 1524
total_duration: 10831.57646284955
[2024-12-27 14:58:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.45268067766086
avg_train_sample_per_sec: 16.45268067766086
avg_episode_per_sec: 0.14183345411776604
collect_time: 42.303136712852854
reward_mean: -120.92390289449115
reward_std: 3.021861222937434
reward_max: -116.68137254901961
reward_min: -124.55812324929975
queue_len: 0.08018826451889331
wait_time: 0.7732737104567732
delay_time: 4.946953047779933
pressure: 0.9837533156498672
total_envstep_count: 177480
total_train_sample_count: 177480
total_episode_count: 1530
total_duration: 10873.879599562404
[2024-12-27 14:59:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.441275197028563
avg_train_sample_per_sec: 16.441275197028563
avg_episode_per_sec: 0.14173513100886692
collect_time: 42.33248283112421
reward_mean: -122.7829131652661
reward_std: 3.1930865710393497
reward_max: -118.5658263305322
reward_min: -127.25070028011206
queue_len: 0.0814210299504417
wait_time: 0.7899791216221237
delay_time: 5.046596509698505
pressure: 1.0051945181255524
total_envstep_count: 178176
total_train_sample_count: 178176
total_episode_count: 1536
total_duration: 10916.212082393527
[2024-12-27 15:00:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.66384882507633
avg_train_sample_per_sec: 16.66384882507633
avg_episode_per_sec: 0.14365386918169248
collect_time: 41.76706157779321
reward_mean: -120.99988328664801
reward_std: 5.0785722476773625
reward_max: -114.1435574229692
reward_min: -128.43697478991598
queue_len: 0.08023864939432893
wait_time: 0.773049803475767
delay_time: 4.920278362197852
pressure: 0.9788903625110522
total_envstep_count: 178872
total_train_sample_count: 178872
total_episode_count: 1542
total_duration: 10957.97914397132
[2024-12-27 15:01:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.13014827369443
avg_train_sample_per_sec: 16.13014827369443
avg_episode_per_sec: 0.13905300235943474
collect_time: 43.14901439158246
reward_mean: -122.72327264239027
reward_std: 3.0923016365827314
reward_max: -117.85574229691872
reward_min: -127.61274509803924
queue_len: 0.08138148053208906
wait_time: 0.7844347730250366
delay_time: 5.027182790491522
pressure: 0.9998894783377542
total_envstep_count: 179568
total_train_sample_count: 179568
total_episode_count: 1548
total_duration: 11001.128158362902
[2024-12-27 15:01:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.526878609301956
avg_train_sample_per_sec: 16.526878609301956
avg_episode_per_sec: 0.14247309145949963
collect_time: 42.11321547483653
reward_mean: -122.3524743230626
reward_std: 3.396195373429567
reward_max: -117.05532212885153
reward_min: -126.27170868347338
queue_len: 0.08113559305242876
wait_time: 0.7876128899835796
delay_time: 4.992259084517362
pressure: 1.0057471264367817
total_envstep_count: 180264
total_train_sample_count: 180264
total_episode_count: 1554
total_duration: 11043.241373837738
[2024-12-27 15:02:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.49629994970866
avg_train_sample_per_sec: 16.49629994970866
avg_episode_per_sec: 0.14220948232507466
collect_time: 42.19127938518673
reward_mean: -121.31676003734826
reward_std: 2.839125656509207
reward_max: -116.58263305322126
reward_min: -124.08123249299722
queue_len: 0.08044877986561556
wait_time: 0.7728053091263031
delay_time: 4.925988548802491
pressure: 0.9806587091069848
total_envstep_count: 180960
total_train_sample_count: 180960
total_episode_count: 1560
total_duration: 11085.432653222924
[2024-12-27 15:03:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.585616973265115
avg_train_sample_per_sec: 16.585616973265115
avg_episode_per_sec: 0.14297945666607859
collect_time: 41.96407050288841
reward_mean: -121.04691876750701
reward_std: 3.528885380655684
reward_max: -115.69257703081232
reward_min: -124.8347338935574
queue_len: 0.08026984003150332
wait_time: 0.777519429522472
delay_time: 4.9564401505145605
pressure: 0.9706012378426171
total_envstep_count: 181656
total_train_sample_count: 181656
total_episode_count: 1566
total_duration: 11127.396723725813
[2024-12-27 15:03:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.30080154632879
avg_train_sample_per_sec: 16.30080154632879
avg_episode_per_sec: 0.14052415126145507
collect_time: 42.69728688015043
reward_mean: -125.890406162465
reward_std: 4.487081575879486
reward_max: -120.56792717086837
reward_min: -132.00980392156856
queue_len: 0.08348170169924735
wait_time: 0.8057307029796887
delay_time: 5.125464219149369
pressure: 1.0098364279398762
total_envstep_count: 182352
total_train_sample_count: 182352
total_episode_count: 1572
total_duration: 11170.094010605964
[2024-12-27 15:04:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.446914553143614
avg_train_sample_per_sec: 16.446914553143614
avg_episode_per_sec: 0.14178374614778977
collect_time: 42.31796777146682
reward_mean: -121.0531045751634
reward_std: 2.7475986276643174
reward_max: -116.70028011204481
reward_min: -124.86974789915966
queue_len: 0.08027394202597042
wait_time: 0.7787487121285296
delay_time: 4.925957419810099
pressure: 0.9733642793987621
total_envstep_count: 183048
total_train_sample_count: 183048
total_episode_count: 1578
total_duration: 11212.411978377431
[2024-12-27 15:05:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.4747818362154
avg_train_sample_per_sec: 16.4747818362154
avg_episode_per_sec: 0.14202398134668448
collect_time: 42.24638644197584
reward_mean: -121.72222222222223
reward_std: 1.9887846139722216
reward_max: -119.05042016806723
reward_min: -125.30112044817933
queue_len: 0.08071765399351606
wait_time: 0.7835968052119169
delay_time: 4.994434215634512
pressure: 0.9908267020335986
total_envstep_count: 183744
total_train_sample_count: 183744
total_episode_count: 1584
total_duration: 11254.658364819406
[2024-12-27 15:06:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.558990318895
avg_train_sample_per_sec: 16.558990318895
avg_episode_per_sec: 0.14274991654219826
collect_time: 42.031548216186465
reward_mean: -120.19164332399627
reward_std: 2.5558632155210264
reward_max: -116.99789915966383
reward_min: -124.41246498599438
queue_len: 0.0797026812493344
wait_time: 0.7672734987009835
delay_time: 4.936179784749861
pressure: 0.9804376657824934
total_envstep_count: 184440
total_train_sample_count: 184440
total_episode_count: 1590
total_duration: 11296.689913035592
[2024-12-27 15:06:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.469185792422316
avg_train_sample_per_sec: 16.469185792422316
avg_episode_per_sec: 0.14197573958984758
collect_time: 42.26074128814786
reward_mean: -120.43545751633985
reward_std: 3.2335538985923256
reward_max: -116.32422969187677
reward_min: -126.5910364145658
queue_len: 0.07986436174823598
wait_time: 0.7728196274088769
delay_time: 4.897450642552842
pressure: 0.9762378426171529
total_envstep_count: 185136
total_train_sample_count: 185136
total_episode_count: 1596
total_duration: 11338.95065432374
[2024-12-27 15:07:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.33613961182713
avg_train_sample_per_sec: 16.33613961182713
avg_episode_per_sec: 0.14082878975713042
collect_time: 42.604924819331615
reward_mean: -121.62266573295985
reward_std: 3.6629070064923566
reward_max: -115.73529411764706
reward_min: -127.6022408963586
queue_len: 0.08065163510143226
wait_time: 0.7810101494178573
delay_time: 4.933712625741788
pressure: 0.9870689655172414
total_envstep_count: 185832
total_train_sample_count: 185832
total_episode_count: 1602
total_duration: 11381.555579143072
[2024-12-27 15:08:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.550332351149724
avg_train_sample_per_sec: 16.550332351149724
avg_episode_per_sec: 0.14267527888922177
collect_time: 42.053536160659036
reward_mean: -121.20039682539685
reward_std: 4.036454463952177
reward_max: -114.98179271708688
reward_min: -127.87675070028013
queue_len: 0.08037161593196078
wait_time: 0.7788155823779556
delay_time: 4.863187636990909
pressure: 0.9792219274977896
total_envstep_count: 186528
total_train_sample_count: 186528
total_episode_count: 1608
total_duration: 11423.609115303732
[2024-12-27 15:08:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.379497984652062
avg_train_sample_per_sec: 16.379497984652062
avg_episode_per_sec: 0.14120256883320742
collect_time: 42.492144792970265
reward_mean: -120.6574463118581
reward_std: 5.926257656899239
reward_max: -115.16036414565828
reward_min: -132.08543417366948
queue_len: 0.0800115691723197
wait_time: 0.7684745317225034
delay_time: 4.962876997539159
pressure: 0.9807692307692308
total_envstep_count: 187224
total_train_sample_count: 187224
total_episode_count: 1614
total_duration: 11466.101260096702
[2024-12-27 15:09:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.435196170166265
avg_train_sample_per_sec: 16.435196170166265
avg_episode_per_sec: 0.1416827256048816
collect_time: 42.34814070935175
reward_mean: -120.7089169000934
reward_std: 2.376140943241233
reward_max: -118.26960784313725
reward_min: -125.64915966386557
queue_len: 0.08004570086213089
wait_time: 0.7738719050838726
delay_time: 4.865467927240198
pressure: 0.9719274977895668
total_envstep_count: 187920
total_train_sample_count: 187920
total_episode_count: 1620
total_duration: 11508.449400806054
[2024-12-27 15:10:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.435988400963538
avg_train_sample_per_sec: 16.435988400963538
avg_episode_per_sec: 0.14168955518072016
collect_time: 42.34609948734193
reward_mean: -121.1455415499533
reward_std: 4.563797957144542
reward_max: -113.62955182072831
reward_min: -128.1022408963585
queue_len: 0.08033523975461095
wait_time: 0.7797095849834186
delay_time: 4.8857016303560235
pressure: 0.9840848806366048
total_envstep_count: 188616
total_train_sample_count: 188616
total_episode_count: 1626
total_duration: 11550.795500293396
[2024-12-27 15:11:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.508507995438247
avg_train_sample_per_sec: 16.508507995438247
avg_episode_per_sec: 0.1423147240986056
collect_time: 42.16007892368734
reward_mean: -122.9940476190476
reward_std: 1.7635321870739529
reward_max: -119.82212885154065
reward_min: -125.55672268907564
queue_len: 0.08156103953517746
wait_time: 0.7920730737033982
delay_time: 4.959506583245044
pressure: 0.9930371352785144
total_envstep_count: 189312
total_train_sample_count: 189312
total_episode_count: 1632
total_duration: 11592.955579217083
[2024-12-27 15:11:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.48904904754971
avg_train_sample_per_sec: 16.48904904754971
avg_episode_per_sec: 0.1421469745478423
collect_time: 42.20983259816468
reward_mean: -120.10819327731092
reward_std: 4.457264516792603
reward_max: -113.32492997198877
reward_min: -126.52521008403363
queue_len: 0.07964734302208946
wait_time: 0.7634325613534539
delay_time: 4.895676632574932
pressure: 0.9602122015915119
total_envstep_count: 190008
total_train_sample_count: 190008
total_episode_count: 1638
total_duration: 11635.165411815247
[2024-12-27 15:12:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.429296456217635
avg_train_sample_per_sec: 16.429296456217635
avg_episode_per_sec: 0.14163186600187616
collect_time: 42.3633478070572
reward_mean: -120.5686274509804
reward_std: 3.488141304534677
reward_max: -115.25630252100842
reward_min: -124.73809523809524
queue_len: 0.0799526707234618
wait_time: 0.7670720365953633
delay_time: 4.934542037482852
pressure: 0.9734748010610078
total_envstep_count: 190704
total_train_sample_count: 190704
total_episode_count: 1644
total_duration: 11677.528759622304
[2024-12-27 15:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.590496276512155
avg_train_sample_per_sec: 16.590496276512155
avg_episode_per_sec: 0.1430215196251048
collect_time: 41.95172877289727
reward_mean: -120.43569094304388
reward_std: 2.1931422746610263
reward_max: -116.72058823529412
reward_min: -123.9474789915966
queue_len: 0.07986451654048002
wait_time: 0.7710233408128945
delay_time: 4.868692007546223
pressure: 0.9835322723253758
total_envstep_count: 191400
total_train_sample_count: 191400
total_episode_count: 1650
total_duration: 11719.480488395202
[2024-12-27 15:13:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.49963646536149
avg_train_sample_per_sec: 16.49963646536149
avg_episode_per_sec: 0.14223824539104732
collect_time: 42.18274756908418
reward_mean: -120.89460784313728
reward_std: 4.573993056224516
reward_max: -114.67997198879554
reward_min: -126.92577030812325
queue_len: 0.08016883809226609
wait_time: 0.7711141264640249
delay_time: 4.9459279216009495
pressure: 0.9772325375773651
total_envstep_count: 192096
total_train_sample_count: 192096
total_episode_count: 1656
total_duration: 11761.663235964286
[2024-12-27 15:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.425414393458084
avg_train_sample_per_sec: 16.425414393458084
avg_episode_per_sec: 0.14159839994360415
collect_time: 42.37336016783863
reward_mean: -123.10901027077495
reward_std: 3.021351345476748
reward_max: -118.45588235294119
reward_min: -127.58963585434171
queue_len: 0.08163727471536801
wait_time: 0.7920339886617777
delay_time: 5.05515512367652
pressure: 0.9973474801061007
total_envstep_count: 192792
total_train_sample_count: 192792
total_episode_count: 1662
total_duration: 11804.036596132124
[2024-12-27 15:15:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.472265140191304
avg_train_sample_per_sec: 16.472265140191304
avg_episode_per_sec: 0.14200228569130435
collect_time: 42.25284100738539
reward_mean: -118.51937441643327
reward_std: 3.806766717551779
reward_max: -113.24369747899162
reward_min: -122.73739495798318
queue_len: 0.0785937496130194
wait_time: 0.7558619822818605
delay_time: 4.851771007020952
pressure: 0.9576702033598585
total_envstep_count: 193488
total_train_sample_count: 193488
total_episode_count: 1668
total_duration: 11846.289437139509
[2024-12-27 15:16:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.388756211405216
avg_train_sample_per_sec: 16.388756211405216
avg_episode_per_sec: 0.14128238113280359
collect_time: 42.468140414197
reward_mean: -120.84757236227823
reward_std: 2.592187226032202
reward_max: -117.02591036414566
reward_min: -123.91176470588236
queue_len: 0.08013764745509168
wait_time: 0.7729207841403581
delay_time: 4.878771790082973
pressure: 0.974027409372237
total_envstep_count: 194184
total_train_sample_count: 194184
total_episode_count: 1674
total_duration: 11888.757577553706
[2024-12-27 15:16:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.360690881508066
avg_train_sample_per_sec: 16.360690881508066
avg_episode_per_sec: 0.14104043863369023
collect_time: 42.540990783382206
reward_mean: -118.92005135387491
reward_std: 2.8541350588626724
reward_max: -114.8228291316527
reward_min: -121.30742296918767
queue_len: 0.07885945049991704
wait_time: 0.7562926917009068
delay_time: 4.907140590387031
pressure: 0.9725906277630415
total_envstep_count: 194880
total_train_sample_count: 194880
total_episode_count: 1680
total_duration: 11931.298568337088
[2024-12-27 15:17:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.49820860896924
avg_train_sample_per_sec: 16.49820860896924
avg_episode_per_sec: 0.1422259362842176
collect_time: 42.18639832336827
reward_mean: -120.57049486461251
reward_std: 4.904180364284561
reward_max: -112.64565826330532
reward_min: -127.05952380952377
queue_len: 0.07995390906141413
wait_time: 0.7719425745541364
delay_time: 4.915101519101873
pressure: 0.9846374889478339
total_envstep_count: 195576
total_train_sample_count: 195576
total_episode_count: 1686
total_duration: 11973.484966660457
[2024-12-27 15:18:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.49279641879995
avg_train_sample_per_sec: 16.49279641879995
avg_episode_per_sec: 0.14217927947241335
collect_time: 42.20024199211224
reward_mean: -121.60235760971055
reward_std: 5.289925042281372
reward_max: -115.53361344537811
reward_min: -131.76120448179273
queue_len: 0.08063816817620063
wait_time: 0.7703624553269582
delay_time: 4.954266688779487
pressure: 0.9712643678160919
total_envstep_count: 196272
total_train_sample_count: 196272
total_episode_count: 1692
total_duration: 12015.685208652569
[2024-12-27 15:18:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.46752548338062
avg_train_sample_per_sec: 16.46752548338062
avg_episode_per_sec: 0.1419614265808674
collect_time: 42.26500215241313
reward_mean: -119.0249766573296
reward_std: 2.240387199489891
reward_max: -116.6778711484594
reward_min: -122.94747899159661
queue_len: 0.0789290296136138
wait_time: 0.7598753581892529
delay_time: 4.951752680822934
pressure: 0.9647435897435899
total_envstep_count: 196968
total_train_sample_count: 196968
total_episode_count: 1698
total_duration: 12057.950210804982
[2024-12-27 15:19:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.45295333927335
avg_train_sample_per_sec: 16.45295333927335
avg_episode_per_sec: 0.1418358046489082
collect_time: 42.302435656864205
reward_mean: -120.19701213818864
reward_std: 2.836589560915251
reward_max: -115.51750700280115
reward_min: -124.66946778711484
queue_len: 0.07970624147094736
wait_time: 0.7690127443550363
delay_time: 4.875641447977728
pressure: 0.9788903625110521
total_envstep_count: 197664
total_train_sample_count: 197664
total_episode_count: 1704
total_duration: 12100.252646461846
[2024-12-27 15:20:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.479268617363246
avg_train_sample_per_sec: 16.479268617363246
avg_episode_per_sec: 0.14206266049451075
collect_time: 42.23488409350068
reward_mean: -119.26295518207284
reward_std: 5.856318183113163
reward_max: -112.2549019607843
reward_min: -128.04131652661061
queue_len: 0.07908684030641434
wait_time: 0.7601948493809548
delay_time: 4.870331151030801
pressure: 0.9640804597701149
total_envstep_count: 198360
total_train_sample_count: 198360
total_episode_count: 1710
total_duration: 12142.487530555347
[2024-12-27 15:21:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.33462106419079
avg_train_sample_per_sec: 16.33462106419079
avg_episode_per_sec: 0.14081569882923095
collect_time: 42.60888558509573
reward_mean: -122.02999533146591
reward_std: 1.6793912123169308
reward_max: -119.06512605042016
reward_min: -123.74019607843138
queue_len: 0.0809217475672851
wait_time: 0.7822133495307937
delay_time: 5.0713485580630815
pressure: 0.9903846153846154
total_envstep_count: 199056
total_train_sample_count: 199056
total_episode_count: 1716
total_duration: 12185.096416140443
[2024-12-27 15:21:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.460894769858335
avg_train_sample_per_sec: 16.460894769858335
avg_episode_per_sec: 0.14190426525739946
collect_time: 42.28202717597409
reward_mean: -121.20319794584502
reward_std: 2.4928227921041795
reward_max: -117.29971988795516
reward_min: -123.90476190476191
queue_len: 0.08037347343888927
wait_time: 0.7705680194270458
delay_time: 5.0373962087909705
pressure: 0.9824270557029178
total_envstep_count: 199752
total_train_sample_count: 199752
total_episode_count: 1722
total_duration: 12227.378443316416
[2024-12-27 15:22:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.450659529451002
avg_train_sample_per_sec: 16.450659529451002
avg_episode_per_sec: 0.14181603042630173
collect_time: 42.30833412812278
reward_mean: -122.85305788982264
reward_std: 3.4461564706349392
reward_max: -115.20658263305329
reward_min: -124.9894957983193
queue_len: 0.08146754501977627
wait_time: 0.7896127283804768
delay_time: 4.960417952572381
pressure: 1.000110521662246
total_envstep_count: 200448
total_train_sample_count: 200448
total_episode_count: 1728
total_duration: 12269.68677744454
[2024-12-27 15:23:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.501909639412485
avg_train_sample_per_sec: 16.501909639412485
avg_episode_per_sec: 0.14225784171907316
collect_time: 42.176936803586784
reward_mean: -122.65172735760973
reward_std: 2.750528463262807
reward_max: -118.55462184873953
reward_min: -125.62815126050418
queue_len: 0.08133403670929028
wait_time: 0.7830460544076163
delay_time: 5.088690822447606
pressure: 0.9980106100795757
total_envstep_count: 201144
total_train_sample_count: 201144
total_episode_count: 1734
total_duration: 12311.863714248128
[2024-12-27 15:24:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.46446428836269
avg_train_sample_per_sec: 16.46446428836269
avg_episode_per_sec: 0.1419350369686439
collect_time: 42.27286037432401
reward_mean: -121.48225957049486
reward_std: 2.6608773604535862
reward_max: -117.3823529411765
reward_min: -125.03641456582633
queue_len: 0.08055852756664116
wait_time: 0.7787282795523162
delay_time: 4.925802725402476
pressure: 0.9818744473916888
total_envstep_count: 201840
total_train_sample_count: 201840
total_episode_count: 1740
total_duration: 12354.136574622451
[2024-12-27 15:24:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.582761486219685
avg_train_sample_per_sec: 16.582761486219685
avg_episode_per_sec: 0.14295484039844555
collect_time: 41.971296552650635
reward_mean: -120.70494864612515
reward_std: 2.2427518675763984
reward_max: -118.09663865546214
reward_min: -125.06372549019608
queue_len: 0.08004306939398217
wait_time: 0.7759279330653571
delay_time: 4.954282615412912
pressure: 0.980106100795756
total_envstep_count: 202536
total_train_sample_count: 202536
total_episode_count: 1746
total_duration: 12396.107871175102
[2024-12-27 15:25:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.361214628658125
avg_train_sample_per_sec: 16.361214628658125
avg_episode_per_sec: 0.14104495369532868
collect_time: 42.539628982123
reward_mean: -122.64729225023343
reward_std: 3.7826802859372153
reward_max: -117.36974789915972
reward_min: -128.73039215686273
queue_len: 0.08133109565665349
wait_time: 0.7884900976305641
delay_time: 4.923727468530617
pressure: 0.9953580901856762
total_envstep_count: 203232
total_train_sample_count: 203232
total_episode_count: 1752
total_duration: 12438.647500157225
[2024-12-27 15:26:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.436063877937883
avg_train_sample_per_sec: 16.436063877937883
avg_episode_per_sec: 0.1416902058442921
collect_time: 42.345905027434235
reward_mean: -119.39460784313725
reward_std: 3.8825134976612588
reward_max: -113.64775910364148
reward_min: -123.01820728291321
queue_len: 0.07917414313205388
wait_time: 0.7593848215678843
delay_time: 4.869953904345443
pressure: 0.969496021220159
total_envstep_count: 203928
total_train_sample_count: 203928
total_episode_count: 1758
total_duration: 12480.99340518466
[2024-12-27 15:26:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.433658215696422
avg_train_sample_per_sec: 16.433658215696422
avg_episode_per_sec: 0.14166946737669328
collect_time: 42.35210388732702
reward_mean: -119.91631652661063
reward_std: 4.303454096390438
reward_max: -113.95518207282919
reward_min: -126.10014005602244
queue_len: 0.07952010379748717
wait_time: 0.7685055675674337
delay_time: 4.935124417171966
pressure: 0.9683908045977012
total_envstep_count: 204624
total_train_sample_count: 204624
total_episode_count: 1764
total_duration: 12523.345509071987
[2024-12-27 15:27:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.521177024005944
avg_train_sample_per_sec: 16.521177024005944
avg_episode_per_sec: 0.1424239398621202
collect_time: 42.12774906949327
reward_mean: -118.34652194211019
reward_std: 2.53593492000534
reward_max: -114.437675070028
reward_min: -121.11764705882354
queue_len: 0.07847912595630648
wait_time: 0.7584667487684728
delay_time: 4.8869680037072
pressure: 0.9564544650751547
total_envstep_count: 205320
total_train_sample_count: 205320
total_episode_count: 1770
total_duration: 12565.473258141481
[2024-12-27 15:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.704062711317373
avg_train_sample_per_sec: 16.704062711317373
avg_episode_per_sec: 0.14400054061480494
collect_time: 41.66651023935899
reward_mean: -120.11227824463118
reward_std: 1.704088579046553
reward_max: -118.16526610644262
reward_min: -122.62815126050421
queue_len: 0.0796500518863602
wait_time: 0.7655662176453251
delay_time: 4.9384556952273195
pressure: 0.9760167992926614
total_envstep_count: 206016
total_train_sample_count: 206016
total_episode_count: 1776
total_duration: 12607.139768380839
[2024-12-27 15:29:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.470979377073757
avg_train_sample_per_sec: 16.470979377073757
avg_episode_per_sec: 0.1419912015264979
collect_time: 42.256139362834396
reward_mean: -120.2386788048553
reward_std: 3.1442286004245728
reward_max: -114.33263305322129
reward_min: -123.7233893557423
queue_len: 0.07973387188650882
wait_time: 0.7674014344906839
delay_time: 4.96212365591294
pressure: 0.9730327144120247
total_envstep_count: 206712
total_train_sample_count: 206712
total_episode_count: 1782
total_duration: 12649.395907743674
[2024-12-27 15:29:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.759474143440613
avg_train_sample_per_sec: 16.759474143440613
avg_episode_per_sec: 0.14447822537448804
collect_time: 41.5287492938675
reward_mean: -118.69117647058825
reward_std: 3.3240268940903586
reward_max: -114.42366946778712
reward_min: -122.61694677871151
queue_len: 0.07870767670463409
wait_time: 0.7571784129213134
delay_time: 4.908542552321688
pressure: 0.9617595048629531
total_envstep_count: 207408
total_train_sample_count: 207408
total_episode_count: 1788
total_duration: 12690.924657037542
[2024-12-27 15:30:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.37912335742977
avg_train_sample_per_sec: 16.37912335742977
avg_episode_per_sec: 0.14119933928818765
collect_time: 42.49311668345705
reward_mean: -120.00268440709617
reward_std: 3.1201370613013872
reward_max: -113.34243697478989
reward_min: -122.98529411764704
queue_len: 0.0795773769277826
wait_time: 0.7671263686730218
delay_time: 4.894630183390712
pressure: 0.9803271441202476
total_envstep_count: 208104
total_train_sample_count: 208104
total_episode_count: 1794
total_duration: 12733.417773721
[2024-12-27 15:31:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.518060580945317
avg_train_sample_per_sec: 16.518060580945317
avg_episode_per_sec: 0.14239707397366652
collect_time: 42.13569726235793
reward_mean: -123.80999066293184
reward_std: 1.86416230438332
reward_max: -121.32843137254898
reward_min: -126.06442577030812
queue_len: 0.08210211582422534
wait_time: 0.7903537188527047
delay_time: 5.083217374466687
pressure: 1.0019893899204244
total_envstep_count: 208800
total_train_sample_count: 208800
total_episode_count: 1800
total_duration: 12775.553470983357
[2024-12-27 15:31:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.756590171927126
avg_train_sample_per_sec: 16.756590171927126
avg_episode_per_sec: 0.1444533635510959
collect_time: 41.53589679396898
reward_mean: -118.36939775910366
reward_std: 2.456187204804329
reward_max: -115.75350140056022
reward_min: -123.2324929971989
queue_len: 0.07849429559622258
wait_time: 0.7540218120846925
delay_time: 4.867411274272556
pressure: 0.963527851458886
total_envstep_count: 209496
total_train_sample_count: 209496
total_episode_count: 1806
total_duration: 12817.089367777326
[2024-12-27 15:32:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.598239052697625
avg_train_sample_per_sec: 16.598239052697625
avg_episode_per_sec: 0.14308826769566918
collect_time: 41.932159055564554
reward_mean: -123.55415499533144
reward_std: 2.147011759540799
reward_max: -121.25700280112044
reward_min: -127.56372549019605
queue_len: 0.0819324635247556
wait_time: 0.7978895470655104
delay_time: 5.013555552186567
pressure: 1.0072944297082227
total_envstep_count: 210192
total_train_sample_count: 210192
total_episode_count: 1812
total_duration: 12859.02152683289
[2024-12-27 15:33:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.466583525591012
avg_train_sample_per_sec: 16.466583525591012
avg_episode_per_sec: 0.14195330625509495
collect_time: 42.267419888183476
reward_mean: -119.22093837535014
reward_std: 2.8550637949141167
reward_max: -115.62114845938376
reward_min: -125.01890756302518
queue_len: 0.07905897770248682
wait_time: 0.7586591555278167
delay_time: 4.908775409822053
pressure: 0.9720380194518125
total_envstep_count: 210888
total_train_sample_count: 210888
total_episode_count: 1818
total_duration: 12901.288946721073
[2024-12-27 15:33:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.345956004946913
avg_train_sample_per_sec: 16.345956004946913
avg_episode_per_sec: 0.14091341383574926
collect_time: 42.579338876806204
reward_mean: -123.77462651727355
reward_std: 2.8119466735468284
reward_max: -119.7240896358543
reward_min: -127.28011204481788
queue_len: 0.08207866479925302
wait_time: 0.7927495158098606
delay_time: 5.102977995175965
pressure: 1.008289124668435
total_envstep_count: 211584
total_train_sample_count: 211584
total_episode_count: 1824
total_duration: 12943.86828559788
[2024-12-27 15:34:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.726201952291007
avg_train_sample_per_sec: 16.726201952291007
avg_episode_per_sec: 0.14419139614043971
collect_time: 41.6113593501523
reward_mean: -122.17950513538746
reward_std: 2.133777696843963
reward_max: -118.4236694677871
reward_min: -125.37535014005601
queue_len: 0.08102089199959382
wait_time: 0.7804506528517686
delay_time: 5.016163791164363
pressure: 0.9875110521662247
total_envstep_count: 212280
total_train_sample_count: 212280
total_episode_count: 1830
total_duration: 12985.479644948033
[2024-12-27 15:35:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.470182424617693
avg_train_sample_per_sec: 16.470182424617693
avg_episode_per_sec: 0.14198433124670426
collect_time: 42.25818403563648
reward_mean: -121.65557889822595
reward_std: 3.3833434681715397
reward_max: -116.32072829131653
reward_min: -127.85714285714285
queue_len: 0.08067346080784214
wait_time: 0.7782895209365797
delay_time: 5.027651773975627
pressure: 0.9804376657824934
total_envstep_count: 212976
total_train_sample_count: 212976
total_episode_count: 1836
total_duration: 13027.737828983669
[2024-12-27 15:36:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.64300309519003
avg_train_sample_per_sec: 16.64300309519003
avg_episode_per_sec: 0.14347416461370713
collect_time: 41.819375747226175
reward_mean: -121.10084033613445
reward_std: 2.287561786532734
reward_max: -116.83123249299722
reward_min: -123.2563025210084
queue_len: 0.08030559703987696
wait_time: 0.7739075073000024
delay_time: 4.9077320858208955
pressure: 0.9860742705570291
total_envstep_count: 213672
total_train_sample_count: 213672
total_episode_count: 1842
total_duration: 13069.557204730894
[2024-12-27 15:36:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.750807407441908
avg_train_sample_per_sec: 16.750807407441908
avg_episode_per_sec: 0.14440351213311992
collect_time: 41.5502359421067
reward_mean: -118.31465919701213
reward_std: 2.474293740907599
reward_max: -113.29131652661063
reward_min: -121.58613445378148
queue_len: 0.07845799681499478
wait_time: 0.7556951936389057
delay_time: 4.884410007134018
pressure: 0.9648541114058357
total_envstep_count: 214368
total_train_sample_count: 214368
total_episode_count: 1848
total_duration: 13111.107440673
[2024-12-27 15:37:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.623223731312954
avg_train_sample_per_sec: 16.623223731312954
avg_episode_per_sec: 0.14330365285614616
collect_time: 41.86913508773594
reward_mean: -121.38083566760037
reward_std: 3.723122255803405
reward_max: -115.82633053221289
reward_min: -127.09453781512606
queue_len: 0.08049127033660501
wait_time: 0.7693909018072304
delay_time: 4.992277980765299
pressure: 0.9855216622458002
total_envstep_count: 215064
total_train_sample_count: 215064
total_episode_count: 1854
total_duration: 13152.976575760737
[2024-12-27 15:38:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61605966798031
avg_train_sample_per_sec: 16.61605966798031
avg_episode_per_sec: 0.14324189368948542
collect_time: 41.887187089320264
reward_mean: -120.83636788048553
reward_std: 4.339777099620273
reward_max: -113.30392156862747
reward_min: -125.43277310924371
queue_len: 0.08013021742737765
wait_time: 0.7727913778243393
delay_time: 4.945602944092798
pressure: 0.9787798408488064
total_envstep_count: 215760
total_train_sample_count: 215760
total_episode_count: 1860
total_duration: 13194.863762850056
[2024-12-27 15:38:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54717973553651
avg_train_sample_per_sec: 16.54717973553651
avg_episode_per_sec: 0.1426481011684182
collect_time: 42.06154831963778
reward_mean: -120.12044817927172
reward_std: 3.438599094954373
reward_max: -114.40826330532218
reward_min: -124.0490196078431
queue_len: 0.07965546961490168
wait_time: 0.7697927424727627
delay_time: 4.886400434268561
pressure: 0.975132625994695
total_envstep_count: 216456
total_train_sample_count: 216456
total_episode_count: 1866
total_duration: 13236.925311169694
[2024-12-27 15:39:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.380523764403755
avg_train_sample_per_sec: 16.380523764403755
avg_episode_per_sec: 0.14121141176210134
collect_time: 42.48948385353013
reward_mean: -122.44222689075632
reward_std: 1.5235850244795366
reward_max: -120.07072829131651
reward_min: -124.41456582633056
queue_len: 0.08119511067026279
wait_time: 0.7814303329643089
delay_time: 5.046726901212783
pressure: 0.9857427055702918
total_envstep_count: 217152
total_train_sample_count: 217152
total_episode_count: 1872
total_duration: 13279.414795023224
[2024-12-27 15:40:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.676648154060416
avg_train_sample_per_sec: 16.676648154060416
avg_episode_per_sec: 0.14376420822465874
collect_time: 41.735005354210735
reward_mean: -119.95063025210084
reward_std: 2.4692514842751314
reward_max: -115.79621848739494
reward_min: -123.93067226890753
queue_len: 0.07954285825736129
wait_time: 0.7668353592542233
delay_time: 4.886502756979269
pressure: 0.9744694960212201
total_envstep_count: 217848
total_train_sample_count: 217848
total_episode_count: 1878
total_duration: 13321.149800377434
[2024-12-27 15:41:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.669570248084558
avg_train_sample_per_sec: 16.669570248084558
avg_episode_per_sec: 0.1437031917938324
collect_time: 41.75272605362906
reward_mean: -120.98330999066296
reward_std: 2.5679984460792813
reward_max: -116.58473389355741
reward_min: -124.12815126050417
queue_len: 0.08022765914500195
wait_time: 0.7749653574957834
delay_time: 4.938770208578835
pressure: 0.9940318302387269
total_envstep_count: 218544
total_train_sample_count: 218544
total_episode_count: 1884
total_duration: 13362.902526431064
[2024-12-27 15:41:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5208841424956
avg_train_sample_per_sec: 16.5208841424956
avg_episode_per_sec: 0.1424214150215138
collect_time: 42.12849590838328
reward_mean: -118.03571428571429
reward_std: 3.3142138152401035
reward_max: -113.30672268907563
reward_min: -122.53431372549016
queue_len: 0.07827302008336491
wait_time: 0.7525053124698156
delay_time: 4.849506214101581
pressure: 0.9603227232537578
total_envstep_count: 219240
total_train_sample_count: 219240
total_episode_count: 1890
total_duration: 13405.031022339448
[2024-12-27 15:42:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.32970744396855
avg_train_sample_per_sec: 16.32970744396855
avg_episode_per_sec: 0.14077334003421166
collect_time: 42.621706628128884
reward_mean: -120.5856676003735
reward_std: 4.17130658073226
reward_max: -113.35014005602238
reward_min: -125.72829131652661
queue_len: 0.07996397055727684
wait_time: 0.763744854705808
delay_time: 5.046872496696818
pressure: 0.973364279398762
total_envstep_count: 219936
total_train_sample_count: 219936
total_episode_count: 1896
total_duration: 13447.652728967578
[2024-12-27 15:43:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73071998261728
avg_train_sample_per_sec: 16.73071998261728
avg_episode_per_sec: 0.14423034467773518
collect_time: 41.60012245277688
reward_mean: -118.94584500466853
reward_std: 5.515435261692291
reward_max: -110.63025210084037
reward_min: -126.05322128851539
queue_len: 0.07887655504288364
wait_time: 0.7645361526573495
delay_time: 4.8519829617795756
pressure: 0.9734748010610078
total_envstep_count: 220632
total_train_sample_count: 220632
total_episode_count: 1902
total_duration: 13489.252851420355
[2024-12-27 15:43:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.572422365383193
avg_train_sample_per_sec: 16.572422365383193
avg_episode_per_sec: 0.14286571004640683
collect_time: 41.997481397397806
reward_mean: -118.17927170868346
reward_std: 3.2411997536634103
reward_max: -113.7801120448179
reward_min: -123.67997198879554
queue_len: 0.07836821731345057
wait_time: 0.7547034397313303
delay_time: 4.956056812420289
pressure: 0.962422634836428
total_envstep_count: 221328
total_train_sample_count: 221328
total_episode_count: 1908
total_duration: 13531.250332817754
[2024-12-27 15:44:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.522020515656866
avg_train_sample_per_sec: 16.522020515656866
avg_episode_per_sec: 0.14243121134186953
collect_time: 42.125598339527855
reward_mean: -120.08333333333333
reward_std: 3.4319248921863665
reward_max: -115.26820728291317
reward_min: -126.67927170868346
queue_len: 0.07963085764809903
wait_time: 0.7650771515502752
delay_time: 4.8579808096313455
pressure: 0.9715959328028294
total_envstep_count: 222024
total_train_sample_count: 222024
total_episode_count: 1914
total_duration: 13573.375931157281
[2024-12-27 15:45:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73986243705386
avg_train_sample_per_sec: 16.73986243705386
avg_episode_per_sec: 0.14430915894011948
collect_time: 41.57740259916335
reward_mean: -122.31944444444444
reward_std: 3.6377845320662803
reward_max: -116.11274509803923
reward_min: -126.30812324929971
queue_len: 0.08111368994989683
wait_time: 0.7815324958453761
delay_time: 4.981230399250376
pressure: 0.9897214854111406
total_envstep_count: 222720
total_train_sample_count: 222720
total_episode_count: 1920
total_duration: 13614.953333756444
[2024-12-27 15:46:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.497179679819688
avg_train_sample_per_sec: 16.497179679819688
avg_episode_per_sec: 0.14221706620534214
collect_time: 42.189029489167034
reward_mean: -120.09348739495799
reward_std: 2.640558205822471
reward_max: -116.44607843137258
reward_min: -123.69187675070026
queue_len: 0.07963759111071483
wait_time: 0.7679356999209941
delay_time: 4.8905273940909035
pressure: 0.9700486295313882
total_envstep_count: 223416
total_train_sample_count: 223416
total_episode_count: 1926
total_duration: 13657.142363245612
[2024-12-27 15:46:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.78221216048071
avg_train_sample_per_sec: 16.78221216048071
avg_episode_per_sec: 0.14467424276276475
collect_time: 41.47248249184712
reward_mean: -119.10317460317462
reward_std: 3.1792564039442337
reward_max: -115.48809523809526
reward_min: -123.53361344537817
queue_len: 0.07898088501536778
wait_time: 0.7578361251662469
delay_time: 4.940865046559917
pressure: 0.9670645446507516
total_envstep_count: 224112
total_train_sample_count: 224112
total_episode_count: 1932
total_duration: 13698.614845737458
[2024-12-27 15:47:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.782081212041746
avg_train_sample_per_sec: 16.782081212041746
avg_episode_per_sec: 0.1446731138969116
collect_time: 41.47280609633774
reward_mean: -119.9910130718954
reward_std: 4.563294674855939
reward_max: -112.63515406162463
reward_min: -125.96848739495798
queue_len: 0.07956963731558052
wait_time: 0.7668221245173577
delay_time: 4.866415858760006
pressure: 0.9771220159151194
total_envstep_count: 224808
total_train_sample_count: 224808
total_episode_count: 1938
total_duration: 13740.087651833795
[2024-12-27 15:48:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.68342164911757
avg_train_sample_per_sec: 16.68342164911757
avg_episode_per_sec: 0.14382260042342732
collect_time: 41.718060877326884
reward_mean: -120.82329598506067
reward_std: 3.9605916714796074
reward_max: -115.98599439775909
reward_min: -127.50910364145655
queue_len: 0.08012154906171132
wait_time: 0.7706187912830914
delay_time: 4.909856317136187
pressure: 0.9817639257294432
total_envstep_count: 225504
total_train_sample_count: 225504
total_episode_count: 1944
total_duration: 13781.805712711122
[2024-12-27 15:48:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51718869088112
avg_train_sample_per_sec: 16.51718869088112
avg_episode_per_sec: 0.14238955768000966
collect_time: 42.13792147232965
reward_mean: -121.21288515406162
reward_std: 4.309756395471872
reward_max: -115.01890756302521
reward_min: -128.4264705882353
queue_len: 0.080379897317017
wait_time: 0.779558972129966
delay_time: 4.896625796037541
pressure: 0.9920424403183024
total_envstep_count: 226200
total_train_sample_count: 226200
total_episode_count: 1950
total_duration: 13823.943634183452
[2024-12-27 15:49:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.664482836452454
avg_train_sample_per_sec: 16.664482836452454
avg_episode_per_sec: 0.1436593347970039
collect_time: 41.76547252204827
reward_mean: -119.25758636788048
reward_std: 2.664299639621232
reward_max: -115.7114845938375
reward_min: -124.01820728291314
queue_len: 0.07908328008480138
wait_time: 0.7625720712688259
delay_time: 4.823825475230495
pressure: 0.9668435013262601
total_envstep_count: 226896
total_train_sample_count: 226896
total_episode_count: 1956
total_duration: 13865.7091067055
[2024-12-27 15:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.504013793696117
avg_train_sample_per_sec: 16.504013793696117
avg_episode_per_sec: 0.14227598098013894
collect_time: 42.17155951880291
reward_mean: -117.97257236227826
reward_std: 5.303231497520427
reward_max: -111.12114845938383
reward_min: -125.66946778711484
queue_len: 0.07823114878135162
wait_time: 0.7520920171782243
delay_time: 4.8211253377340695
pressure: 0.9536914235190098
total_envstep_count: 227592
total_train_sample_count: 227592
total_episode_count: 1962
total_duration: 13907.880666224304
[2024-12-27 15:51:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.643645203071667
avg_train_sample_per_sec: 16.643645203071667
avg_episode_per_sec: 0.1434797000264799
collect_time: 41.81776236563549
reward_mean: -119.68779178338002
reward_std: 3.577293188773412
reward_max: -114.6981792717087
reward_min: -124.72759103641457
queue_len: 0.0793685621905703
wait_time: 0.7676783578152745
delay_time: 4.866780377982976
pressure: 0.975685234305924
total_envstep_count: 228288
total_train_sample_count: 228288
total_episode_count: 1968
total_duration: 13949.69842858994
[2024-12-27 15:51:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.525522228062176
avg_train_sample_per_sec: 16.525522228062176
avg_episode_per_sec: 0.1424613985177774
collect_time: 42.11667204187439
reward_mean: -120.12301587301589
reward_std: 1.6340274604816742
reward_max: -118.31442577030813
reward_min: -123.01960784313728
queue_len: 0.07965717232958612
wait_time: 0.7643066731555574
delay_time: 4.783425842485142
pressure: 0.9720380194518126
total_envstep_count: 228984
total_train_sample_count: 228984
total_episode_count: 1974
total_duration: 13991.815100631815
[2024-12-27 15:52:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.693435434730095
avg_train_sample_per_sec: 16.693435434730095
avg_episode_per_sec: 0.14390892616146633
collect_time: 41.69303572780453
reward_mean: -119.71591970121382
reward_std: 3.2398105928605556
reward_max: -115.59733893557419
reward_min: -123.99019607843135
queue_len: 0.07938721465597733
wait_time: 0.7682209046306411
delay_time: 4.841801290023933
pressure: 0.9722590627763043
total_envstep_count: 229680
total_train_sample_count: 229680
total_episode_count: 1980
total_duration: 14033.50813635962
[2024-12-27 15:53:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.18821044927083
avg_train_sample_per_sec: 16.18821044927083
avg_episode_per_sec: 0.13955353835578302
collect_time: 42.994252031814305
reward_mean: -119.28688141923432
reward_std: 3.5064178494015716
reward_max: -115.61974789915965
reward_min: -125.23179271708679
queue_len: 0.0791027065114286
wait_time: 0.7669115170382916
delay_time: 4.786033836699926
pressure: 0.9721485411140584
total_envstep_count: 230376
total_train_sample_count: 230376
total_episode_count: 1986
total_duration: 14076.502388391435
[2024-12-27 15:53:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.681425822222913
avg_train_sample_per_sec: 16.681425822222913
avg_episode_per_sec: 0.14380539501916303
collect_time: 41.723052178956564
reward_mean: -117.08858543417368
reward_std: 1.615397866324248
reward_max: -115.21218487394961
reward_min: -119.81722689075629
queue_len: 0.07764495055316557
wait_time: 0.7467624428197449
delay_time: 4.770857388290085
pressure: 0.9469496021220158
total_envstep_count: 231072
total_train_sample_count: 231072
total_episode_count: 1992
total_duration: 14118.225440570392
[2024-12-27 15:54:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.648921125457154
avg_train_sample_per_sec: 16.648921125457154
avg_episode_per_sec: 0.14352518211600995
collect_time: 41.804510619957
reward_mean: -121.66188141923436
reward_std: 5.297647133060974
reward_max: -116.41946778711484
reward_min: -132.64005602240903
queue_len: 0.08067764019843128
wait_time: 0.779473372019011
delay_time: 4.951891777452783
pressure: 0.9784482758620691
total_envstep_count: 231768
total_train_sample_count: 231768
total_episode_count: 1998
total_duration: 14160.029951190349
[2024-12-27 15:55:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76283547153832
avg_train_sample_per_sec: 16.76283547153832
avg_episode_per_sec: 0.1445072023408476
collect_time: 41.520421839237216
reward_mean: -120.72292250233427
reward_std: 2.8996121512167994
reward_max: -114.48179271708685
reward_min: -123.64075630252103
queue_len: 0.0800549883967734
wait_time: 0.7753896430367018
delay_time: 4.889459222843329
pressure: 0.9799955791335103
total_envstep_count: 232464
total_train_sample_count: 232464
total_episode_count: 2004
total_duration: 14201.550373029586
[2024-12-27 15:55:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.74351674159111
avg_train_sample_per_sec: 16.74351674159111
avg_episode_per_sec: 0.14434066156544062
collect_time: 41.56832825156301
reward_mean: -118.35352474323064
reward_std: 4.983226579157912
reward_max: -110.05462184873952
reward_min: -124.57983193277309
queue_len: 0.07848376972362774
wait_time: 0.7533531095904323
delay_time: 4.774481210155266
pressure: 0.9649646330680813
total_envstep_count: 233160
total_train_sample_count: 233160
total_episode_count: 2010
total_duration: 14243.11870128115
[2024-12-27 15:56:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.565908100783844
avg_train_sample_per_sec: 16.565908100783844
avg_episode_per_sec: 0.14280955259296416
collect_time: 42.013996200248606
reward_mean: -117.7454481792717
reward_std: 3.779385657112615
reward_max: -112.08823529411767
reward_min: -122.72128851540617
queue_len: 0.07808053592789901
wait_time: 0.7545741108114333
delay_time: 4.795433066747742
pressure: 0.957338638373121
total_envstep_count: 233856
total_train_sample_count: 233856
total_episode_count: 2016
total_duration: 14285.132697481398
[2024-12-27 15:57:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81355590083515
avg_train_sample_per_sec: 16.81355590083515
avg_episode_per_sec: 0.1449444474209927
collect_time: 41.395169713351876
reward_mean: -116.90044351073762
reward_std: 2.455697755090139
reward_max: -113.7934173669468
reward_min: -121.60504201680672
queue_len: 0.07752018800446793
wait_time: 0.7549991703135719
delay_time: 4.651893925397576
pressure: 0.9588859416445623
total_envstep_count: 234552
total_train_sample_count: 234552
total_episode_count: 2022
total_duration: 14326.52786719475
[2024-12-27 15:58:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.551434149293353
avg_train_sample_per_sec: 16.551434149293353
avg_episode_per_sec: 0.14268477714908065
collect_time: 42.05073673508316
reward_mean: -117.97140522875817
reward_std: 3.0920306824713206
reward_max: -112.56512605042016
reward_min: -121.71428571428572
queue_len: 0.07823037482013143
wait_time: 0.7571548845002192
delay_time: 4.757548720016668
pressure: 0.9646330680813439
total_envstep_count: 235248
total_train_sample_count: 235248
total_episode_count: 2028
total_duration: 14368.578603929835
[2024-12-27 15:58:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.67432304009058
avg_train_sample_per_sec: 16.67432304009058
avg_episode_per_sec: 0.14374416413871188
collect_time: 41.74082499940694
reward_mean: -116.25035014005603
reward_std: 2.753878192385588
reward_max: -113.4950980392157
reward_min: -120.84803921568628
queue_len: 0.0770890916048117
wait_time: 0.7442111570534492
delay_time: 4.655304062005862
pressure: 0.9399867374005305
total_envstep_count: 235944
total_train_sample_count: 235944
total_episode_count: 2034
total_duration: 14410.319428929242
[2024-12-27 15:59:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.644167214026105
avg_train_sample_per_sec: 16.644167214026105
avg_episode_per_sec: 0.1434842001209147
collect_time: 41.81645083530992
reward_mean: -120.42180205415497
reward_std: 2.1302864648823534
reward_max: -117.29551820728287
reward_min: -123.32492997198878
queue_len: 0.07985530640195954
wait_time: 0.7714573782651876
delay_time: 4.8326330250335365
pressure: 0.9738063660477455
total_envstep_count: 236640
total_train_sample_count: 236640
total_episode_count: 2040
total_duration: 14452.135879764552
[2024-12-27 16:00:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.973647148554466
avg_train_sample_per_sec: 16.973647148554466
avg_episode_per_sec: 0.14632454438409023
collect_time: 41.00474069647864
reward_mean: -118.68020541549951
reward_std: 4.747637092510622
reward_max: -112.94467787114844
reward_min: -127.83683473389354
queue_len: 0.07870040146916414
wait_time: 0.7564646658840372
delay_time: 4.8852166826900065
pressure: 0.9583333333333331
total_envstep_count: 237336
total_train_sample_count: 237336
total_episode_count: 2046
total_duration: 14493.14062046103
[2024-12-27 16:00:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93079769699548
avg_train_sample_per_sec: 16.93079769699548
avg_episode_per_sec: 0.14595515256030586
collect_time: 41.10851788888313
reward_mean: -120.93837535014002
reward_std: 3.309572929526866
reward_max: -117.45938375350137
reward_min: -126.93277310924366
queue_len: 0.0801978616380239
wait_time: 0.7730025918413341
delay_time: 4.879745466912916
pressure: 0.9721485411140584
total_envstep_count: 238032
total_train_sample_count: 238032
total_episode_count: 2052
total_duration: 14534.249138349913
[2024-12-27 16:01:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.210893148116938
avg_train_sample_per_sec: 17.210893148116938
avg_episode_per_sec: 0.14836976851824946
collect_time: 40.43950502802059
reward_mean: -118.60982726423906
reward_std: 3.4470260110604873
reward_max: -112.26120448179272
reward_min: -122.17016806722692
queue_len: 0.07865373160758557
wait_time: 0.7586475461095138
delay_time: 4.790700738914276
pressure: 0.9660698496905393
total_envstep_count: 238728
total_train_sample_count: 238728
total_episode_count: 2058
total_duration: 14574.688643377933
[2024-12-27 16:02:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.009984994245098
avg_train_sample_per_sec: 17.009984994245098
avg_episode_per_sec: 0.14663780167452672
collect_time: 40.91714367975481
reward_mean: -119.18067226890757
reward_std: 4.155762985245072
reward_max: -113.29551820728295
reward_min: -124.99929971988794
queue_len: 0.07903227604038962
wait_time: 0.7626676554795216
delay_time: 4.835459592366759
pressure: 0.9658488063660479
total_envstep_count: 239424
total_train_sample_count: 239424
total_episode_count: 2064
total_duration: 14615.605787057688
[2024-12-27 16:02:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.78204281335369
avg_train_sample_per_sec: 16.78204281335369
avg_episode_per_sec: 0.14467278287373872
collect_time: 41.472900989513846
reward_mean: -121.06699346405229
reward_std: 2.4636982191111256
reward_max: -116.97408963585434
reward_min: -124.31442577030812
queue_len: 0.0802831521644909
wait_time: 0.77763769079692
delay_time: 4.996656195551228
pressure: 0.9816534040671971
total_envstep_count: 240120
total_train_sample_count: 240120
total_episode_count: 2070
total_duration: 14657.078688047202
[2024-12-27 16:03:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.074558313440185
avg_train_sample_per_sec: 17.074558313440185
avg_episode_per_sec: 0.14719446821931195
collect_time: 40.76240141756087
reward_mean: -120.41398225957046
reward_std: 4.346640148773573
reward_max: -112.28151260504201
reward_min: -125.0238095238095
queue_len: 0.07985012086178414
wait_time: 0.766949441138082
delay_time: 4.933813647870496
pressure: 0.9798850574712644
total_envstep_count: 240816
total_train_sample_count: 240816
total_episode_count: 2076
total_duration: 14697.841089464764
[2024-12-27 16:04:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.233800739549846
avg_train_sample_per_sec: 17.233800739549846
avg_episode_per_sec: 0.14856724775474003
collect_time: 40.38575184420868
reward_mean: -118.9810924369748
reward_std: 4.0208060300812365
reward_max: -113.77661064425774
reward_min: -126.44957983193281
queue_len: 0.07889992867173395
wait_time: 0.7652916162043953
delay_time: 4.831845786957813
pressure: 0.9710433244916005
total_envstep_count: 241512
total_train_sample_count: 241512
total_episode_count: 2082
total_duration: 14738.226841308973
[2024-12-27 16:05:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.093643609588486
avg_train_sample_per_sec: 17.093643609588486
avg_episode_per_sec: 0.1473589966343835
collect_time: 40.71688961676881
reward_mean: -116.41083099906626
reward_std: 3.6549821901956747
reward_max: -110.30112044817923
reward_min: -121.10854341736695
queue_len: 0.07719551127259038
wait_time: 0.7473932986103371
delay_time: 4.670652239741899
pressure: 0.9522546419098142
total_envstep_count: 242208
total_train_sample_count: 242208
total_episode_count: 2088
total_duration: 14778.943730925743
[2024-12-27 16:05:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.996163228403695
avg_train_sample_per_sec: 16.996163228403695
avg_episode_per_sec: 0.14651864852072152
collect_time: 40.950418670777225
reward_mean: -121.18113912231559
reward_std: 3.6773077092983697
reward_max: -114.52871148459386
reward_min: -126.56372549019606
queue_len: 0.08035884557182732
wait_time: 0.7767546784407838
delay_time: 4.881734640241739
pressure: 0.9838638373121132
total_envstep_count: 242904
total_train_sample_count: 242904
total_episode_count: 2094
total_duration: 14819.89414959652
[2024-12-27 16:06:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.985927130512785
avg_train_sample_per_sec: 16.985927130512785
avg_episode_per_sec: 0.14643040629752402
collect_time: 40.97509630485437
reward_mean: -117.49474789915968
reward_std: 2.4899166448837624
reward_max: -113.38235294117648
reward_min: -121.14845938375352
queue_len: 0.0779142890577982
wait_time: 0.7513805920246082
delay_time: 4.78989673095139
pressure: 0.9543545534924845
total_envstep_count: 243600
total_train_sample_count: 243600
total_episode_count: 2100
total_duration: 14860.869245901373
[2024-12-27 16:07:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.965150279477832
avg_train_sample_per_sec: 16.965150279477832
avg_episode_per_sec: 0.1462512955127399
collect_time: 41.025277615249166
reward_mean: -116.74194677871151
reward_std: 3.2451325631639354
reward_max: -111.41666666666671
reward_min: -120.97058823529412
queue_len: 0.0774150840707636
wait_time: 0.7453546847563074
delay_time: 4.857480283124264
pressure: 0.9454022988505746
total_envstep_count: 244296
total_train_sample_count: 244296
total_episode_count: 2106
total_duration: 14901.894523516621
[2024-12-27 16:07:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18385227618705
avg_train_sample_per_sec: 17.18385227618705
avg_episode_per_sec: 0.14813665755333663
collect_time: 40.503141485014936
reward_mean: -122.58309990662933
reward_std: 0.23171536542336443
reward_max: -122.20028011204487
reward_min: -122.79761904761904
queue_len: 0.081288527789542
wait_time: 0.7858019755205352
delay_time: 4.950650235962967
pressure: 0.9981211317418214
total_envstep_count: 244992
total_train_sample_count: 244992
total_episode_count: 2112
total_duration: 14942.397665001636
[2024-12-27 16:08:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25062362600638
avg_train_sample_per_sec: 17.25062362600638
avg_episode_per_sec: 0.14871227263798603
collect_time: 40.34636747570894
reward_mean: -115.76774042950514
reward_std: 0.7888083444140946
reward_max: -114.67927170868346
reward_min: -117.12114845938376
queue_len: 0.0767690586402554
wait_time: 0.7404678936119099
delay_time: 4.685493148600936
pressure: 0.9542440318302386
total_envstep_count: 245688
total_train_sample_count: 245688
total_episode_count: 2118
total_duration: 14982.744032477345
[2024-12-27 16:09:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.167872127048707
avg_train_sample_per_sec: 17.167872127048707
avg_episode_per_sec: 0.1479988976469716
collect_time: 40.54084250216558
reward_mean: -118.01167133520075
reward_std: 2.481134294867807
reward_max: -114.40896358543415
reward_min: -120.32843137254902
queue_len: 0.0782570764822286
wait_time: 0.7552174273776706
delay_time: 4.873464725743699
pressure: 0.9521441202475684
total_envstep_count: 246384
total_train_sample_count: 246384
total_episode_count: 2124
total_duration: 15023.28487497951
[2024-12-27 16:09:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.032433042657722
avg_train_sample_per_sec: 17.032433042657722
avg_episode_per_sec: 0.14683131933325624
collect_time: 40.86321656200663
reward_mean: -119.89810924369749
reward_std: 3.8997351546805956
reward_max: -114.35644257703086
reward_min: -124.56512605042015
queue_len: 0.07950803000245192
wait_time: 0.7695724731094913
delay_time: 4.937361314899395
pressure: 0.9761273209549072
total_envstep_count: 247080
total_train_sample_count: 247080
total_episode_count: 2130
total_duration: 15064.148091541518
[2024-12-27 16:10:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75871939177134
avg_train_sample_per_sec: 16.75871939177134
avg_episode_per_sec: 0.1444717188945805
collect_time: 41.530619597446176
reward_mean: -119.08111577964517
reward_std: 3.3153566194824515
reward_max: -113.56372549019606
reward_min: -123.99649859943979
queue_len: 0.07896625714830584
wait_time: 0.7647746101092957
delay_time: 4.893408910246071
pressure: 0.9751326259946951
total_envstep_count: 247776
total_train_sample_count: 247776
total_episode_count: 2136
total_duration: 15105.678711138964
[2024-12-27 16:11:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.000177102168173
avg_train_sample_per_sec: 17.000177102168173
avg_episode_per_sec: 0.14655325088076013
collect_time: 40.94074995908327
reward_mean: -119.75665266106442
reward_std: 3.172533775267904
reward_max: -116.37675070028014
reward_min: -125.16526610644259
queue_len: 0.0794142259025626
wait_time: 0.7637748070050301
delay_time: 4.904668161117313
pressure: 0.9729221927497789
total_envstep_count: 248472
total_train_sample_count: 248472
total_episode_count: 2142
total_duration: 15146.619461098047
[2024-12-27 16:11:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.0080790712819
avg_train_sample_per_sec: 17.0080790712819
avg_episode_per_sec: 0.1466213713041543
collect_time: 40.921728849155826
reward_mean: -117.66491596638657
reward_std: 3.7193387499750634
reward_max: -111.63725490196079
reward_min: -122.74859943977592
queue_len: 0.07802713260370461
wait_time: 0.7516014031607338
delay_time: 4.858104719238056
pressure: 0.9559018567639258
total_envstep_count: 249168
total_train_sample_count: 249168
total_episode_count: 2148
total_duration: 15187.541189947204
[2024-12-27 16:12:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.902286389493103
avg_train_sample_per_sec: 16.902286389493103
avg_episode_per_sec: 0.14570936542666468
collect_time: 41.177861027881505
reward_mean: -122.76797385620911
reward_std: 4.75548715313808
reward_max: -114.79691876750695
reward_min: -128.11834733893554
queue_len: 0.08141112324682304
wait_time: 0.7861886465461515
delay_time: 5.023894740655776
pressure: 1.0036472148541113
total_envstep_count: 249864
total_train_sample_count: 249864
total_episode_count: 2154
total_duration: 15228.719050975085
[2024-12-27 16:13:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.152662198792797
avg_train_sample_per_sec: 17.152662198792797
avg_episode_per_sec: 0.14786777757579997
collect_time: 40.57679163348675
reward_mean: -115.0185574229692
reward_std: 3.0634986110471956
reward_max: -111.32773109243699
reward_min: -120.68207282913167
queue_len: 0.07627225293300344
wait_time: 0.727165899516305
delay_time: 4.753547589996793
pressure: 0.9431918656056587
total_envstep_count: 250560
total_train_sample_count: 250560
total_episode_count: 2160
total_duration: 15269.295842608572
[2024-12-27 16:14:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97939776304354
avg_train_sample_per_sec: 16.97939776304354
avg_episode_per_sec: 0.1463741186469271
collect_time: 40.99085313348844
reward_mean: -117.20296451914096
reward_std: 4.015920153096278
reward_max: -112.02450980392157
reward_min: -122.45868347338939
queue_len: 0.07772079875274601
wait_time: 0.7540929391208295
delay_time: 4.742812824268243
pressure: 0.9573386383731212
total_envstep_count: 251256
total_train_sample_count: 251256
total_episode_count: 2166
total_duration: 15310.28669574206
[2024-12-27 16:14:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.831491131971955
avg_train_sample_per_sec: 16.831491131971955
avg_episode_per_sec: 0.14509906148251686
collect_time: 41.35106001855806
reward_mean: -116.84955648926235
reward_std: 2.873371626154216
reward_max: -113.1225490196078
reward_min: -120.10574229691872
queue_len: 0.07748644329526681
wait_time: 0.7469711801608354
delay_time: 4.7397257603470875
pressure: 0.9553492484526968
total_envstep_count: 251952
total_train_sample_count: 251952
total_episode_count: 2172
total_duration: 15351.637755760617
[2024-12-27 16:15:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.786887243620868
avg_train_sample_per_sec: 16.786887243620868
avg_episode_per_sec: 0.14471454520362817
collect_time: 41.46093256595172
reward_mean: -120.61192810457517
reward_std: 1.9784943425837942
reward_max: -118.54831932773111
reward_min: -123.59523809523813
queue_len: 0.07998138468473155
wait_time: 0.7667402394202597
delay_time: 4.97228661204846
pressure: 0.9803271441202477
total_envstep_count: 252648
total_train_sample_count: 252648
total_episode_count: 2178
total_duration: 15393.098688326569
[2024-12-27 16:16:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.329984797655335
avg_train_sample_per_sec: 17.329984797655335
avg_episode_per_sec: 0.14939642066944253
collect_time: 40.16160476344824
reward_mean: -117.89414098972924
reward_std: 3.643491818318596
reward_max: -114.66596638655462
reward_min: -124.59593837535019
queue_len: 0.0781791385873536
wait_time: 0.7555505402868485
delay_time: 4.8002738556233
pressure: 0.9593280282935456
total_envstep_count: 253344
total_train_sample_count: 253344
total_episode_count: 2184
total_duration: 15433.260293090018
[2024-12-27 16:16:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.969926308495204
avg_train_sample_per_sec: 16.969926308495204
avg_episode_per_sec: 0.1462924681766828
collect_time: 41.01373142979295
reward_mean: -120.7279411764706
reward_std: 1.7520253971976902
reward_max: -118.46778711484595
reward_min: -123.063025210084
queue_len: 0.08005831643002029
wait_time: 0.7715568322819846
delay_time: 4.949001223121716
pressure: 0.9849690539345711
total_envstep_count: 254040
total_train_sample_count: 254040
total_episode_count: 2190
total_duration: 15474.274024519811
[2024-12-27 16:17:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.034365362040734
avg_train_sample_per_sec: 17.034365362040734
avg_episode_per_sec: 0.14684797725897186
collect_time: 40.858581180309876
reward_mean: -120.06162464985994
reward_std: 3.1672779461139386
reward_max: -115.46288515406165
reward_min: -125.58403361344538
queue_len: 0.07961646196940314
wait_time: 0.7758863713478318
delay_time: 4.872534235015032
pressure: 0.9844164456233422
total_envstep_count: 254736
total_train_sample_count: 254736
total_episode_count: 2196
total_duration: 15515.13260570012
[2024-12-27 16:18:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.223678374692394
avg_train_sample_per_sec: 17.223678374692394
avg_episode_per_sec: 0.14847998598872753
collect_time: 40.40948657185026
reward_mean: -120.19572829131653
reward_std: 3.362483169416844
reward_max: -116.11764705882354
reward_min: -127.1603641456583
queue_len: 0.07970539011360513
wait_time: 0.7673673801969949
delay_time: 4.875689875624674
pressure: 0.9837533156498673
total_envstep_count: 255432
total_train_sample_count: 255432
total_episode_count: 2202
total_duration: 15555.542092271971
[2024-12-27 16:18:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.936209362249453
avg_train_sample_per_sec: 16.936209362249453
avg_episode_per_sec: 0.14600180484697803
collect_time: 41.09538239125534
reward_mean: -118.88993930905694
reward_std: 2.3761467133252627
reward_max: -115.94117647058822
reward_min: -123.07913165266105
queue_len: 0.07883948230043564
wait_time: 0.7614571801311151
delay_time: 4.870468104929473
pressure: 0.9587754199823166
total_envstep_count: 256128
total_train_sample_count: 256128
total_episode_count: 2208
total_duration: 15596.637474663226
[2024-12-27 16:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05435786457186
avg_train_sample_per_sec: 17.05435786457186
avg_episode_per_sec: 0.14702032641872292
collect_time: 40.81068343510292
reward_mean: -120.62885154061622
reward_std: 3.9330342508551945
reward_max: -115.03851540616247
reward_min: -125.56302521008404
queue_len: 0.07999260712242455
wait_time: 0.777804402043753
delay_time: 4.829469303770984
pressure: 0.9735853227232538
total_envstep_count: 256824
total_train_sample_count: 256824
total_episode_count: 2214
total_duration: 15637.44815809833
[2024-12-27 16:20:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.9591786411686
avg_train_sample_per_sec: 16.9591786411686
avg_episode_per_sec: 0.1461998158721431
collect_time: 41.03972336905822
reward_mean: -118.75583566760038
reward_std: 5.304330044493718
reward_max: -110.42226890756305
reward_min: -126.22338935574227
queue_len: 0.07875055415623368
wait_time: 0.7613340429009798
delay_time: 4.739043065014431
pressure: 0.9730327144120249
total_envstep_count: 257520
total_train_sample_count: 257520
total_episode_count: 2220
total_duration: 15678.487881467388
[2024-12-27 16:20:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05309522979418
avg_train_sample_per_sec: 17.05309522979418
avg_episode_per_sec: 0.14700944163615673
collect_time: 40.813705114599315
reward_mean: -117.78034547152193
reward_std: 4.025567105200595
reward_max: -113.31302521008402
reward_min: -124.22058823529407
queue_len: 0.07810367736838324
wait_time: 0.7579819394601341
delay_time: 4.788098747749799
pressure: 0.961759504862953
total_envstep_count: 258216
total_train_sample_count: 258216
total_episode_count: 2226
total_duration: 15719.301586581987
[2024-12-27 16:21:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.721328496103293
avg_train_sample_per_sec: 16.721328496103293
avg_episode_per_sec: 0.14414938358709736
collect_time: 41.623487043041735
reward_mean: -116.51505602240896
reward_std: 2.4780840583879034
reward_max: -112.49579831932772
reward_min: -119.41666666666667
queue_len: 0.07726462600955501
wait_time: 0.74216681588639
delay_time: 4.723451041812145
pressure: 0.9536914235190097
total_envstep_count: 258912
total_train_sample_count: 258912
total_episode_count: 2232
total_duration: 15760.925073625029
[2024-12-27 16:22:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.217880753195306
avg_train_sample_per_sec: 17.217880753195306
avg_episode_per_sec: 0.14843000649306298
collect_time: 40.42309329333901
reward_mean: -119.95996732026141
reward_std: 4.2115504491646565
reward_max: -114.9922969187675
reward_min: -127.69467787114841
queue_len: 0.07954904994712296
wait_time: 0.7701449722240797
delay_time: 4.886030104371648
pressure: 0.9732537577365163
total_envstep_count: 259608
total_train_sample_count: 259608
total_episode_count: 2238
total_duration: 15801.348166918367
[2024-12-27 16:23:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.867827362087965
avg_train_sample_per_sec: 16.867827362087965
avg_episode_per_sec: 0.1454123048455859
collect_time: 41.26198265250958
reward_mean: -114.60515873015873
reward_std: 1.5060340952681925
reward_max: -112.59733893557421
reward_min: -117.03781512605043
queue_len: 0.07599811586880552
wait_time: 0.7326476346506771
delay_time: 4.730722488590669
pressure: 0.9249557913351018
total_envstep_count: 260304
total_train_sample_count: 260304
total_episode_count: 2244
total_duration: 15842.610149570877
[2024-12-27 16:23:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.36473658662315
avg_train_sample_per_sec: 16.36473658662315
avg_episode_per_sec: 0.1410753154019237
collect_time: 42.53047376081347
reward_mean: -118.0518207282913
reward_std: 4.053196385019793
reward_max: -111.07773109243698
reward_min: -124.12605042016801
queue_len: 0.07828370074820377
wait_time: 0.7567227819509766
delay_time: 4.782804109105122
pressure: 0.9643015030946066
total_envstep_count: 261000
total_train_sample_count: 261000
total_episode_count: 2250
total_duration: 15885.14062333169
[2024-12-27 16:24:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.534648595745796
avg_train_sample_per_sec: 16.534648595745796
avg_episode_per_sec: 0.14254007410125688
collect_time: 42.093425570536404
reward_mean: -116.95634920634922
reward_std: 3.345175173192311
reward_max: -111.8466386554622
reward_min: -122.67226890756307
queue_len: 0.07755726074691595
wait_time: 0.7440980813191768
delay_time: 4.784739874165127
pressure: 0.9450707338638372
total_envstep_count: 261696
total_train_sample_count: 261696
total_episode_count: 2256
total_duration: 15927.234048902226
[2024-12-27 16:25:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.42579170331678
avg_train_sample_per_sec: 16.42579170331678
avg_episode_per_sec: 0.14160165261479982
collect_time: 42.372386827446505
reward_mean: -120.4624183006536
reward_std: 4.9322910493826075
reward_max: -110.68137254901958
reward_min: -126.88445378151262
queue_len: 0.07988224025242281
wait_time: 0.772471809236515
delay_time: 4.916422104779479
pressure: 0.9781167108753316
total_envstep_count: 262392
total_train_sample_count: 262392
total_episode_count: 2262
total_duration: 15969.606435729673
[2024-12-27 16:25:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.549511182498478
avg_train_sample_per_sec: 16.549511182498478
avg_episode_per_sec: 0.14266819984912482
collect_time: 42.05562281114607
reward_mean: -117.94059290382819
reward_std: 5.2954171342327045
reward_max: -110.27591036414563
reward_min: -125.88865546218487
queue_len: 0.07820994224391789
wait_time: 0.7579413064960733
delay_time: 4.811129628195434
pressure: 0.9593280282935456
total_envstep_count: 263088
total_train_sample_count: 263088
total_episode_count: 2268
total_duration: 16011.662058540818
[2024-12-27 16:26:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51215875126621
avg_train_sample_per_sec: 16.51215875126621
avg_episode_per_sec: 0.14234619613160523
collect_time: 42.15075754081085
reward_mean: -117.50198412698411
reward_std: 4.3617166706824895
reward_max: -111.22689075630252
reward_min: -124.83543417366947
queue_len: 0.07791908761736348
wait_time: 0.7548206174600698
delay_time: 4.770891154417565
pressure: 0.9498231653404067
total_envstep_count: 263784
total_train_sample_count: 263784
total_episode_count: 2274
total_duration: 16053.812816081629
[2024-12-27 16:27:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.738939519703234
avg_train_sample_per_sec: 16.738939519703234
avg_episode_per_sec: 0.14430120275606237
collect_time: 41.579695008799426
reward_mean: -119.99579831932772
reward_std: 5.697180013377331
reward_max: -112.74299719887956
reward_min: -127.93557422969187
queue_len: 0.07957281055658336
wait_time: 0.7685197310577635
delay_time: 4.87892464836699
pressure: 0.9746905393457116
total_envstep_count: 264480
total_train_sample_count: 264480
total_episode_count: 2280
total_duration: 16095.392511090427
[2024-12-27 16:28:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.677865927353965
avg_train_sample_per_sec: 15.677865927353965
avg_episode_per_sec: 0.1351540166151204
collect_time: 44.393797167614096
reward_mean: -118.19642857142857
reward_std: 2.751002944147749
reward_max: -113.62745098039214
reward_min: -121.46498599439774
queue_len: 0.07837959454338764
wait_time: 0.7583838575217885
delay_time: 4.770356840653881
pressure: 0.957338638373121
total_envstep_count: 265176
total_train_sample_count: 265176
total_episode_count: 2286
total_duration: 16139.78630825804
[2024-12-27 16:28:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.566606818148994
avg_train_sample_per_sec: 16.566606818148994
avg_episode_per_sec: 0.14281557601852582
collect_time: 42.012224207405005
reward_mean: -113.31279178338
reward_std: 2.4108984066390806
reward_max: -108.65756302521011
reward_min: -116.24859943977586
queue_len: 0.07514110860966844
wait_time: 0.7191687130201329
delay_time: 4.5967673627389285
pressure: 0.9226348364279399
total_envstep_count: 265872
total_train_sample_count: 265872
total_episode_count: 2292
total_duration: 16181.798532465446
[2024-12-27 16:29:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.204062828619396
avg_train_sample_per_sec: 16.204062828619396
avg_episode_per_sec: 0.13969019679844305
collect_time: 42.95219090182336
reward_mean: -120.08916900093372
reward_std: 2.9957620792217097
reward_max: -116.45378151260502
reward_min: -125.1652661064426
queue_len: 0.07963472745420007
wait_time: 0.7690757447983615
delay_time: 4.927714691577962
pressure: 0.9840848806366047
total_envstep_count: 266568
total_train_sample_count: 266568
total_episode_count: 2298
total_duration: 16224.75072336727
[2024-12-27 16:30:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54793958227995
avg_train_sample_per_sec: 16.54793958227995
avg_episode_per_sec: 0.14265465157137888
collect_time: 42.05961694139242
reward_mean: -117.19852941176474
reward_std: 4.55849630344885
reward_max: -111.52521008403362
reward_min: -124.27380952380958
queue_len: 0.07771785770010924
wait_time: 0.749626176730639
delay_time: 4.767245931637309
pressure: 0.954686118479222
total_envstep_count: 267264
total_train_sample_count: 267264
total_episode_count: 2304
total_duration: 16266.810340308662
[2024-12-27 16:30:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.29198393923371
avg_train_sample_per_sec: 17.29198393923371
avg_episode_per_sec: 0.14906882706235955
collect_time: 40.24986389334127
reward_mean: -115.78688141923435
reward_std: 4.368934396213205
reward_max: -109.39145658263303
reward_min: -120.88095238095235
queue_len: 0.07678175160426681
wait_time: 0.737972255657347
delay_time: 4.759911620865148
pressure: 0.9421971706454465
total_envstep_count: 267960
total_train_sample_count: 267960
total_episode_count: 2310
total_duration: 16307.060204202004
[2024-12-27 16:31:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.134035097277824
avg_train_sample_per_sec: 17.134035097277824
avg_episode_per_sec: 0.147707199114464
collect_time: 40.62090430237167
reward_mean: -116.0060690943044
reward_std: 2.158038564245418
reward_max: -113.07072829131656
reward_min: -118.24439775910362
queue_len: 0.07692710152142201
wait_time: 0.7413595743337124
delay_time: 4.717722545350404
pressure: 0.9515915119363396
total_envstep_count: 268656
total_train_sample_count: 268656
total_episode_count: 2316
total_duration: 16347.681108504376
[2024-12-27 16:32:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.957850758269647
avg_train_sample_per_sec: 16.957850758269647
avg_episode_per_sec: 0.1461883686057728
collect_time: 41.042936980713165
reward_mean: -116.20214752567693
reward_std: 4.3355341200683775
reward_max: -110.19327731092437
reward_min: -123.86554621848744
queue_len: 0.07705712700641706
wait_time: 0.7418571540021843
delay_time: 4.79587072848278
pressure: 0.9456233421750664
total_envstep_count: 269352
total_train_sample_count: 269352
total_episode_count: 2322
total_duration: 16388.724045485087
[2024-12-27 16:32:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.12395693510164
avg_train_sample_per_sec: 17.12395693510164
avg_episode_per_sec: 0.1476203184060486
collect_time: 40.64481139714271
reward_mean: -117.67775443510739
reward_std: 2.711429564882918
reward_max: -113.24439775910362
reward_min: -122.05042016806728
queue_len: 0.07803564617712691
wait_time: 0.7478712970599379
delay_time: 4.825449594410528
pressure: 0.9652961980548188
total_envstep_count: 270048
total_train_sample_count: 270048
total_episode_count: 2328
total_duration: 16429.36885688223
[2024-12-27 16:33:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.725160785711907
avg_train_sample_per_sec: 16.725160785711907
avg_episode_per_sec: 0.14418242056648198
collect_time: 41.6139497202672
reward_mean: -119.00887021475258
reward_std: 3.823852276572219
reward_max: -115.00910364145663
reward_min: -125.84733893557426
queue_len: 0.07891834894877492
wait_time: 0.7597255966931424
delay_time: 4.78373382108137
pressure: 0.9667329796640142
total_envstep_count: 270744
total_train_sample_count: 270744
total_episode_count: 2334
total_duration: 16470.982806602497
[2024-12-27 16:34:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.449656408490632
avg_train_sample_per_sec: 16.449656408490632
avg_episode_per_sec: 0.1418073828318158
collect_time: 42.31091414412484
reward_mean: -121.02567693744163
reward_std: 3.962727016929694
reward_max: -114.21428571428571
reward_min: -126.16106442577029
queue_len: 0.08025575393729552
wait_time: 0.7763560110162544
delay_time: 4.9304211509001306
pressure: 0.981211317418214
total_envstep_count: 271440
total_train_sample_count: 271440
total_episode_count: 2340
total_duration: 16513.29372074662
[2024-12-27 16:35:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.754526471897588
avg_train_sample_per_sec: 16.754526471897588
avg_episode_per_sec: 0.14443557303359988
collect_time: 41.541012881945825
reward_mean: -119.2923669467787
reward_std: 5.1869035945977915
reward_max: -114.1736694677871
reward_min: -128.4467787114846
queue_len: 0.07910634412916359
wait_time: 0.7722439550532855
delay_time: 4.864841473992499
pressure: 0.9715959328028294
total_envstep_count: 272136
total_train_sample_count: 272136
total_episode_count: 2346
total_duration: 16554.834733628566
[2024-12-27 16:35:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.017947756541442
avg_train_sample_per_sec: 17.017947756541442
avg_episode_per_sec: 0.14670644617708142
collect_time: 40.8979983930476
reward_mean: -116.76809056956115
reward_std: 3.527580427996568
reward_max: -110.84383753501403
reward_min: -121.79411764705878
queue_len: 0.07743242080209627
wait_time: 0.7453897451995829
delay_time: 4.701549166354229
pressure: 0.9466180371352785
total_envstep_count: 272832
total_train_sample_count: 272832
total_episode_count: 2352
total_duration: 16595.732732021614
[2024-12-27 16:36:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.692056401346335
avg_train_sample_per_sec: 16.692056401346335
avg_episode_per_sec: 0.14389703794264083
collect_time: 41.69648024576903
reward_mean: -120.594070961718
reward_std: 4.088483360774572
reward_max: -117.36554621848734
reward_min: -129.4705882352941
queue_len: 0.07996954307806234
wait_time: 0.7628975993580456
delay_time: 4.964073423692601
pressure: 0.9749115826702033
total_envstep_count: 273528
total_train_sample_count: 273528
total_episode_count: 2358
total_duration: 16637.429212267383
[2024-12-27 16:37:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.931738592214252
avg_train_sample_per_sec: 16.931738592214252
avg_episode_per_sec: 0.14596326372598492
collect_time: 41.10623349217326
reward_mean: -119.3733660130719
reward_std: 3.7312241625054137
reward_max: -114.24299719887954
reward_min: -125.2514005602241
queue_len: 0.07916005703784608
wait_time: 0.7651660022983552
delay_time: 4.8167134302647945
pressure: 0.978558797524315
total_envstep_count: 274224
total_train_sample_count: 274224
total_episode_count: 2364
total_duration: 16678.535445759557
[2024-12-27 16:37:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.841357316239126
avg_train_sample_per_sec: 16.841357316239126
avg_episode_per_sec: 0.14518411479516488
collect_time: 41.32683529782295
reward_mean: -119.890406162465
reward_std: 3.699044558767757
reward_max: -114.19047619047619
reward_min: -126.1386554621849
queue_len: 0.07950292185839854
wait_time: 0.7711453944973216
delay_time: 4.852385689672419
pressure: 0.9688328912466844
total_envstep_count: 274920
total_train_sample_count: 274920
total_episode_count: 2370
total_duration: 16719.86228105738
[2024-12-27 16:38:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71127271468186
avg_train_sample_per_sec: 16.71127271468186
avg_episode_per_sec: 0.14406269581622294
collect_time: 41.64853341113403
reward_mean: -118.33380018674136
reward_std: 4.377526797047734
reward_max: -112.83193277310919
reward_min: -124.90756302521008
queue_len: 0.07847068977900619
wait_time: 0.7579161527564166
delay_time: 4.864230331734865
pressure: 0.9615384615384616
total_envstep_count: 275616
total_train_sample_count: 275616
total_episode_count: 2376
total_duration: 16761.510814468515
[2024-12-27 16:39:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.99709064956536
avg_train_sample_per_sec: 16.99709064956536
avg_episode_per_sec: 0.14652664353073588
collect_time: 40.9481842716299
reward_mean: -119.57703081232494
reward_std: 2.836200504124191
reward_max: -115.00070028011203
reward_min: -123.843837535014
queue_len: 0.0792951132707725
wait_time: 0.7645175001919425
delay_time: 4.804095340323676
pressure: 0.9623121131741822
total_envstep_count: 276312
total_train_sample_count: 276312
total_episode_count: 2382
total_duration: 16802.458998740145
[2024-12-27 16:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.23204639846803
avg_train_sample_per_sec: 16.23204639846803
avg_episode_per_sec: 0.13993143446955197
collect_time: 42.878142589937895
reward_mean: -118.26155462184875
reward_std: 2.908854364804689
reward_max: -113.62605042016803
reward_min: -120.95728291316532
queue_len: 0.0784227815794753
wait_time: 0.7552369312004199
delay_time: 4.836114233271172
pressure: 0.9538019451812555
total_envstep_count: 277008
total_train_sample_count: 277008
total_episode_count: 2388
total_duration: 16845.337141330085
[2024-12-27 16:40:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.11105791580646
avg_train_sample_per_sec: 16.11105791580646
avg_episode_per_sec: 0.13888843030867637
collect_time: 43.20014263726026
reward_mean: -115.59138655462186
reward_std: 3.369194089786157
reward_max: -112.28501400560228
reward_min: -121.58963585434172
queue_len: 0.07665211309988186
wait_time: 0.7327659733212472
delay_time: 4.74017134482417
pressure: 0.9266136162687887
total_envstep_count: 277704
total_train_sample_count: 277704
total_episode_count: 2394
total_duration: 16888.537283967344
[2024-12-27 16:41:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.45735436249496
avg_train_sample_per_sec: 16.45735436249496
avg_episode_per_sec: 0.1418737445042669
collect_time: 42.29112314590067
reward_mean: -117.49369747899158
reward_std: 3.776879337272823
reward_max: -112.72689075630251
reward_min: -123.84103641456579
queue_len: 0.07791359249269998
wait_time: 0.7487793083634866
delay_time: 4.710081487531586
pressure: 0.9575596816976127
total_envstep_count: 278400
total_train_sample_count: 278400
total_episode_count: 2400
total_duration: 16930.828407113244
[2024-12-27 16:42:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.814306021552262
avg_train_sample_per_sec: 16.814306021552262
avg_episode_per_sec: 0.1449509139788988
collect_time: 41.393322989832605
reward_mean: -115.37978524743228
reward_std: 1.762400754763096
reward_max: -112.9887955182073
reward_min: -117.9747899159664
queue_len: 0.07651179393065803
wait_time: 0.7304786857271645
delay_time: 4.686840073115975
pressure: 0.9362290008841732
total_envstep_count: 279096
total_train_sample_count: 279096
total_episode_count: 2406
total_duration: 16972.221730103076
[2024-12-27 16:42:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.777730485097713
avg_train_sample_per_sec: 16.777730485097713
avg_episode_per_sec: 0.14463560763015268
collect_time: 41.483560641184454
reward_mean: -118.60014005602243
reward_std: 3.692418635466116
reward_max: -114.84733893557424
reward_min: -126.12254901960785
queue_len: 0.07864730772945784
wait_time: 0.7571489249988237
delay_time: 4.811702919901642
pressure: 0.96684350132626
total_envstep_count: 279792
total_train_sample_count: 279792
total_episode_count: 2412
total_duration: 17013.70529074426
[2024-12-27 16:43:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.751419827385526
avg_train_sample_per_sec: 16.751419827385526
avg_episode_per_sec: 0.14440879161539247
collect_time: 41.54871689515933
reward_mean: -117.17705415499533
reward_std: 2.94636900517673
reward_max: -113.05672268907564
reward_min: -120.42717086834735
queue_len: 0.07770361681365738
wait_time: 0.7443156418181772
delay_time: 4.73232481418714
pressure: 0.9472811671087533
total_envstep_count: 280488
total_train_sample_count: 280488
total_episode_count: 2418
total_duration: 17055.254007639418
[2024-12-27 16:44:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.007497810972524
avg_train_sample_per_sec: 17.007497810972524
avg_episode_per_sec: 0.14661636043941828
collect_time: 40.92312741918862
reward_mean: -118.00875350140056
reward_std: 4.690458882958898
reward_max: -112.55462184873947
reward_min: -122.86694677871145
queue_len: 0.07825514157917808
wait_time: 0.7553210607850568
delay_time: 4.803189017516439
pressure: 0.9605437665782494
total_envstep_count: 281184
total_train_sample_count: 281184
total_episode_count: 2424
total_duration: 17096.177135058606
[2024-12-27 16:44:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.855165656224862
avg_train_sample_per_sec: 16.855165656224862
avg_episode_per_sec: 0.14530315220883502
collect_time: 41.29297891195492
reward_mean: -115.36426237161531
reward_std: 3.905303140422566
reward_max: -112.11344537815127
reward_min: -123.87044817927173
queue_len: 0.07650150024642925
wait_time: 0.7315833605767681
delay_time: 4.682909003066206
pressure: 0.9355658709106986
total_envstep_count: 281880
total_train_sample_count: 281880
total_episode_count: 2430
total_duration: 17137.47011397056
[2024-12-27 16:45:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.60320343924224
avg_train_sample_per_sec: 16.60320343924224
avg_episode_per_sec: 0.14313106413139862
collect_time: 41.91962126748265
reward_mean: -118.86006069094304
reward_std: 4.913846574925763
reward_max: -111.6113445378151
reward_min: -127.85924369747897
queue_len: 0.07881966889319829
wait_time: 0.7621668251739245
delay_time: 4.838952654503966
pressure: 0.9614279398762156
total_envstep_count: 282576
total_train_sample_count: 282576
total_episode_count: 2436
total_duration: 17179.389735238045
[2024-12-27 16:46:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.636025496753682
avg_train_sample_per_sec: 16.636025496753682
avg_episode_per_sec: 0.14341401290304898
collect_time: 41.83691592296585
reward_mean: -119.93417366946777
reward_std: 3.9641415569645577
reward_max: -114.97128851540613
reward_min: -125.53571428571425
queue_len: 0.07953194540415635
wait_time: 0.7633764491649887
delay_time: 4.938962311371135
pressure: 0.9622015915119363
total_envstep_count: 283272
total_train_sample_count: 283272
total_episode_count: 2442
total_duration: 17221.22665116101
[2024-12-27 16:47:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.843211700316616
avg_train_sample_per_sec: 16.843211700316616
avg_episode_per_sec: 0.14520010086479843
collect_time: 41.32228534460068
reward_mean: -116.67542016806725
reward_std: 2.8957486900436726
reward_max: -113.31302521008406
reward_min: -120.2843137254902
queue_len: 0.07737096828121169
wait_time: 0.7381806060178272
delay_time: 4.7471474468167285
pressure: 0.9457338638373122
total_envstep_count: 283968
total_train_sample_count: 283968
total_episode_count: 2448
total_duration: 17262.548936505613
[2024-12-27 16:47:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.559065386834085
avg_train_sample_per_sec: 16.559065386834085
avg_episode_per_sec: 0.14275056367960418
collect_time: 42.03135767272115
reward_mean: -116.75233426704015
reward_std: 2.583777421790849
reward_max: -112.41176470588236
reward_min: -120.64565826330526
queue_len: 0.07742197232562344
wait_time: 0.7440264125101853
delay_time: 4.778432382250878
pressure: 0.9413129973474801
total_envstep_count: 284664
total_train_sample_count: 284664
total_episode_count: 2454
total_duration: 17304.580294178333
[2024-12-27 16:48:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.748050106140898
avg_train_sample_per_sec: 16.748050106140898
avg_episode_per_sec: 0.1443797422943181
collect_time: 41.557076530646526
reward_mean: -115.91643323996266
reward_std: 3.1178216433377735
reward_max: -113.61624649859941
reward_min: -122.72549019607845
queue_len: 0.07686766129970998
wait_time: 0.739329319260861
delay_time: 4.742465032458589
pressure: 0.9377763041556145
total_envstep_count: 285360
total_train_sample_count: 285360
total_episode_count: 2460
total_duration: 17346.13737070898
[2024-12-27 16:49:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.717838837049623
avg_train_sample_per_sec: 16.717838837049623
avg_episode_per_sec: 0.1441193003193933
collect_time: 41.63217547339573
reward_mean: -116.83660130718953
reward_std: 3.613244509492557
reward_max: -110.68907563025209
reward_min: -120.47619047619044
queue_len: 0.0774778523257225
wait_time: 0.7464337414895225
delay_time: 4.775500042028877
pressure: 0.9459549071618035
total_envstep_count: 286056
total_train_sample_count: 286056
total_episode_count: 2466
total_duration: 17387.769546182375
[2024-12-27 16:49:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.705458610834967
avg_train_sample_per_sec: 16.705458610834967
avg_episode_per_sec: 0.1440125742313359
collect_time: 41.66302860722318
reward_mean: -118.15814659197014
reward_std: 2.4965944700604537
reward_max: -113.57913165266109
reward_min: -121.06372549019609
queue_len: 0.07835420861536482
wait_time: 0.7547147395651453
delay_time: 4.7620479130764135
pressure: 0.958554376657825
total_envstep_count: 286752
total_train_sample_count: 286752
total_episode_count: 2472
total_duration: 17429.4325747896
[2024-12-27 16:50:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.65164229551638
avg_train_sample_per_sec: 16.65164229551638
avg_episode_per_sec: 0.14354864047858945
collect_time: 41.797679030578564
reward_mean: -116.37383286647993
reward_std: 2.692895444155046
reward_max: -112.20378151260506
reward_min: -119.56582633053222
queue_len: 0.07717097670190977
wait_time: 0.7376118993132176
delay_time: 4.766300882607143
pressure: 0.9367816091954023
total_envstep_count: 287448
total_train_sample_count: 287448
total_episode_count: 2478
total_duration: 17471.23025382018
[2024-12-27 16:51:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.684428335641755
avg_train_sample_per_sec: 16.684428335641755
avg_episode_per_sec: 0.14383127875553237
collect_time: 41.715543739259246
reward_mean: -121.2080999066293
reward_std: 4.696064288893081
reward_max: -114.78711484593838
reward_min: -127.13655462184877
queue_len: 0.08037672407601414
wait_time: 0.7733183680191793
delay_time: 4.976679970615891
pressure: 0.9723695844385499
total_envstep_count: 288144
total_train_sample_count: 288144
total_episode_count: 2484
total_duration: 17512.945797559438
[2024-12-27 16:52:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.6594170335347
avg_train_sample_per_sec: 16.6594170335347
avg_episode_per_sec: 0.1436156640821957
collect_time: 41.77817258545011
reward_mean: -116.91900093370684
reward_std: 3.0852467184554873
reward_max: -112.52731092436976
reward_min: -121.96148459383757
queue_len: 0.07753249398786927
wait_time: 0.7499414111356302
delay_time: 4.733410741730332
pressure: 0.9521441202475686
total_envstep_count: 288840
total_train_sample_count: 288840
total_episode_count: 2490
total_duration: 17554.72397014489
[2024-12-27 16:52:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.622109235381604
avg_train_sample_per_sec: 16.622109235381604
avg_episode_per_sec: 0.14329404513260002
collect_time: 41.87194237169995
reward_mean: -120.5815826330532
reward_std: 2.504879112336604
reward_max: -116.21428571428571
reward_min: -124.86764705882355
queue_len: 0.07996126169300612
wait_time: 0.770679702031122
delay_time: 4.9064512378080405
pressure: 0.9732537577365165
total_envstep_count: 289536
total_train_sample_count: 289536
total_episode_count: 2496
total_duration: 17596.59591251659
[2024-12-27 16:53:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.74016826121567
avg_train_sample_per_sec: 16.74016826121567
avg_episode_per_sec: 0.1443117953553075
collect_time: 41.576643026493485
reward_mean: -119.42471988795519
reward_std: 7.216438107082057
reward_max: -111.82212885154065
reward_min: -134.50980392156865
queue_len: 0.07919411133153527
wait_time: 0.7636716379743763
delay_time: 4.848560607301083
pressure: 0.9717064544650752
total_envstep_count: 290232
total_train_sample_count: 290232
total_episode_count: 2502
total_duration: 17638.172555543082
[2024-12-27 16:54:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.670686797405065
avg_train_sample_per_sec: 16.670686797405065
avg_episode_per_sec: 0.14371281721900916
collect_time: 41.749929589483884
reward_mean: -114.57598039215686
reward_std: 3.772208544731865
reward_max: -110.98179271708683
reward_min: -122.32633053221286
queue_len: 0.07597876683830031
wait_time: 0.7313798861719755
delay_time: 4.698842609186209
pressure: 0.9284924845269673
total_envstep_count: 290928
total_train_sample_count: 290928
total_episode_count: 2508
total_duration: 17679.922485132567
[2024-12-27 16:54:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.689127866830155
avg_train_sample_per_sec: 16.689127866830155
avg_episode_per_sec: 0.14387179195543237
collect_time: 41.703796960134056
reward_mean: -117.74183006535947
reward_std: 4.5749117792238945
reward_max: -109.48039215686273
reward_min: -122.18417366946778
queue_len: 0.07807813664811636
wait_time: 0.7491831613281917
delay_time: 4.893949325822748
pressure: 0.9469496021220158
total_envstep_count: 291624
total_train_sample_count: 291624
total_episode_count: 2514
total_duration: 17721.6262820927
[2024-12-27 16:55:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.179506403025023
avg_train_sample_per_sec: 16.179506403025023
avg_episode_per_sec: 0.13947850347435364
collect_time: 43.01738153580949
reward_mean: -118.30718954248368
reward_std: 4.814829092123476
reward_max: -112.31792717086839
reward_min: -126.45518207282916
queue_len: 0.07845304346318546
wait_time: 0.7546578534154599
delay_time: 4.800258635016077
pressure: 0.9654067197170644
total_envstep_count: 292320
total_train_sample_count: 292320
total_episode_count: 2520
total_duration: 17764.64366362851
[2024-12-27 16:56:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.343906049424437
avg_train_sample_per_sec: 16.343906049424437
avg_episode_per_sec: 0.14089574180538306
collect_time: 42.58467944537103
reward_mean: -117.00758636788049
reward_std: 4.987198963812058
reward_max: -109.11904761904762
reward_min: -122.92507002801118
queue_len: 0.07759123764448307
wait_time: 0.7419374137807201
delay_time: 4.758980116751405
pressure: 0.9514809902740936
total_envstep_count: 293016
total_train_sample_count: 293016
total_episode_count: 2526
total_duration: 17807.228343073883
[2024-12-27 16:57:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.649963069288987
avg_train_sample_per_sec: 16.649963069288987
avg_episode_per_sec: 0.1435341643904223
collect_time: 41.80189452094212
reward_mean: -118.38211951447245
reward_std: 3.517611508067917
reward_max: -112.45938375350137
reward_min: -122.74929971988797
queue_len: 0.07850273177352285
wait_time: 0.7534309700891851
delay_time: 4.777462014664917
pressure: 0.9570070733863837
total_envstep_count: 293712
total_train_sample_count: 293712
total_episode_count: 2532
total_duration: 17849.030237594823
[2024-12-27 16:57:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83441439071682
avg_train_sample_per_sec: 16.83441439071682
avg_episode_per_sec: 0.1451242619889381
collect_time: 41.34387949864194
reward_mean: -115.46195144724554
reward_std: 4.243387188603923
reward_max: -110.97058823529409
reward_min: -123.50630252100838
queue_len: 0.07656628080056072
wait_time: 0.7397839440816115
delay_time: 4.652304231355025
pressure: 0.9368921308576481
total_envstep_count: 294408
total_train_sample_count: 294408
total_episode_count: 2538
total_duration: 17890.374117093466
[2024-12-27 16:58:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75959472855167
avg_train_sample_per_sec: 16.75959472855167
avg_episode_per_sec: 0.1444792649013075
collect_time: 41.52845049494505
reward_mean: -118.0280112044818
reward_std: 5.717964076136639
reward_max: -112.23949579831935
reward_min: -128.97198879551817
queue_len: 0.07826791193931154
wait_time: 0.7539379920845438
delay_time: 4.7476220456367555
pressure: 0.9691644562334217
total_envstep_count: 295104
total_train_sample_count: 295104
total_episode_count: 2544
total_duration: 17931.90256758841
[2024-12-27 16:59:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.574133897384172
avg_train_sample_per_sec: 16.574133897384172
avg_episode_per_sec: 0.1428804646326222
collect_time: 41.993144517183296
reward_mean: -117.36683006535947
reward_std: 2.577092955621065
reward_max: -112.53011204481795
reward_min: -120.6204481792717
queue_len: 0.07782946290806331
wait_time: 0.7538558747990796
delay_time: 4.76208008634694
pressure: 0.9577807250221043
total_envstep_count: 295800
total_train_sample_count: 295800
total_episode_count: 2550
total_duration: 17973.895712105594
[2024-12-27 16:59:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.550867876059613
avg_train_sample_per_sec: 16.550867876059613
avg_episode_per_sec: 0.1426798954832725
collect_time: 42.052175463665286
reward_mean: -117.26925770308124
reward_std: 2.644739495859134
reward_max: -114.8389355742297
reward_min: -122.32352941176471
queue_len: 0.07776475975005388
wait_time: 0.7524981146304676
delay_time: 4.727842423768618
pressure: 0.9626436781609194
total_envstep_count: 296496
total_train_sample_count: 296496
total_episode_count: 2556
total_duration: 18015.94788756926
[2024-12-27 17:00:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73330632120735
avg_train_sample_per_sec: 16.73330632120735
avg_episode_per_sec: 0.14425264070006338
collect_time: 41.59369264147803
reward_mean: -117.73599439775911
reward_std: 3.4382477475129236
reward_max: -112.40896358543417
reward_min: -122.1932773109244
queue_len: 0.07807426684201534
wait_time: 0.7513437514705262
delay_time: 4.790622296914926
pressure: 0.9533598585322722
total_envstep_count: 297192
total_train_sample_count: 297192
total_episode_count: 2562
total_duration: 18057.541580210738
[2024-12-27 17:01:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54024688396205
avg_train_sample_per_sec: 16.54024688396205
avg_episode_per_sec: 0.14258833520656938
collect_time: 42.079178435653446
reward_mean: -120.16176470588236
reward_std: 2.3115979905521904
reward_max: -115.20308123249302
reward_min: -122.55252100840337
queue_len: 0.07968286784209705
wait_time: 0.7736195937260847
delay_time: 4.803758454039304
pressure: 0.9676171529619806
total_envstep_count: 297888
total_train_sample_count: 297888
total_episode_count: 2568
total_duration: 18099.620758646393
[2024-12-27 17:01:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.770422813404434
avg_train_sample_per_sec: 16.770422813404434
avg_episode_per_sec: 0.14457261046038303
collect_time: 41.50163700367138
reward_mean: -115.42577030812323
reward_std: 4.564369508324056
reward_max: -110.23389355742297
reward_min: -122.88025210084032
queue_len: 0.07654228800273426
wait_time: 0.7369347606416573
delay_time: 4.615586951742532
pressure: 0.9410919540229884
total_envstep_count: 298584
total_train_sample_count: 298584
total_episode_count: 2574
total_duration: 18141.122395650065
[2024-12-27 17:02:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.721583636768813
avg_train_sample_per_sec: 16.721583636768813
avg_episode_per_sec: 0.1441515830755932
collect_time: 41.62285194505006
reward_mean: -118.27089169000931
reward_std: 3.6744794175901
reward_max: -111.1001400560224
reward_min: -122.63725490196077
queue_len: 0.07842897326923694
wait_time: 0.758778964724705
delay_time: 4.779319942595183
pressure: 0.958001768346596
total_envstep_count: 299280
total_train_sample_count: 299280
total_episode_count: 2580
total_duration: 18182.745247595114
[2024-12-27 17:03:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.609721750100963
avg_train_sample_per_sec: 16.609721750100963
avg_episode_per_sec: 0.1431872564663876
collect_time: 41.903170352373266
reward_mean: -119.75210084033613
reward_std: 3.4556806824666735
reward_max: -115.35294117647061
reward_min: -124.2542016806722
queue_len: 0.0794112074538038
wait_time: 0.7713782020323601
delay_time: 4.846137356708726
pressure: 0.9848585322723253
total_envstep_count: 299976
total_train_sample_count: 299976
total_episode_count: 2586
total_duration: 18224.648417947486
[2024-12-27 17:04:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7460483269344
avg_train_sample_per_sec: 16.7460483269344
avg_episode_per_sec: 0.1443624855770207
collect_time: 41.56204415584728
reward_mean: -117.70856676003736
reward_std: 1.812794537398253
reward_max: -114.91666666666664
reward_min: -120.03711484593839
queue_len: 0.07805607875334042
wait_time: 0.7581864200145133
delay_time: 4.753521256958041
pressure: 0.9564544650751547
total_envstep_count: 300672
total_train_sample_count: 300672
total_episode_count: 2592
total_duration: 18266.210462103332
[2024-12-27 17:04:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.888911736841738
avg_train_sample_per_sec: 16.888911736841738
avg_episode_per_sec: 0.14559406669691152
collect_time: 41.21047056464477
reward_mean: -115.00711951447245
reward_std: 3.8728688477691002
reward_max: -109.9439775910364
reward_min: -121.07843137254899
queue_len: 0.0762646681130454
wait_time: 0.7406232276288057
delay_time: 4.628668803156605
pressure: 0.9428603006189213
total_envstep_count: 301368
total_train_sample_count: 301368
total_episode_count: 2598
total_duration: 18307.420932667977
[2024-12-27 17:05:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.63712326838386
avg_train_sample_per_sec: 16.63712326838386
avg_episode_per_sec: 0.143423476451585
collect_time: 41.834155386865135
reward_mean: -117.87733426704017
reward_std: 2.550440210403516
reward_max: -115.19677871148457
reward_min: -121.48389355742297
queue_len: 0.07816799354578259
wait_time: 0.757072457630267
delay_time: 4.823854013782713
pressure: 0.9588859416445622
total_envstep_count: 302064
total_train_sample_count: 302064
total_episode_count: 2604
total_duration: 18349.255088054844
[2024-12-27 17:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.746104517137198
avg_train_sample_per_sec: 16.746104517137198
avg_episode_per_sec: 0.14436296997532067
collect_time: 41.56190469776093
reward_mean: -115.54225023342669
reward_std: 1.5911351281224082
reward_max: -113.99159663865552
reward_min: -118.60294117647052
queue_len: 0.07661952933251108
wait_time: 0.7368881681762006
delay_time: 4.643950513578069
pressure: 0.938549955791335
total_envstep_count: 302760
total_train_sample_count: 302760
total_episode_count: 2610
total_duration: 18390.816992752607
[2024-12-27 17:06:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.6721426222119
avg_train_sample_per_sec: 16.6721426222119
avg_episode_per_sec: 0.1437253674328612
collect_time: 41.746283952293915
reward_mean: -116.63095238095237
reward_std: 3.179488726412649
reward_max: -111.27801120448187
reward_min: -120.8319327731092
queue_len: 0.07734148035872175
wait_time: 0.7440118620392454
delay_time: 4.752295223404539
pressure: 0.9416445623342176
total_envstep_count: 303456
total_train_sample_count: 303456
total_episode_count: 2616
total_duration: 18432.5632767049
[2024-12-27 17:07:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.589105491366535
avg_train_sample_per_sec: 16.589105491366535
avg_episode_per_sec: 0.14300953009798736
collect_time: 41.95524589087815
reward_mean: -116.28804855275445
reward_std: 3.807528082024063
reward_max: -110.65336134453784
reward_min: -121.17296918767506
queue_len: 0.07711409055222444
wait_time: 0.7409242985434669
delay_time: 4.8251891564907945
pressure: 0.9467285587975242
total_envstep_count: 304152
total_train_sample_count: 304152
total_episode_count: 2622
total_duration: 18474.518522595776
[2024-12-27 17:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71623633753044
avg_train_sample_per_sec: 16.71623633753044
avg_episode_per_sec: 0.14410548566836587
collect_time: 41.63616653572768
reward_mean: -116.65371148459384
reward_std: 0.9722461320524884
reward_max: -114.55672268907564
reward_min: -117.38865546218491
queue_len: 0.07735657260251581
wait_time: 0.7412916979347001
delay_time: 4.799368604760972
pressure: 0.9428603006189213
total_envstep_count: 304848
total_train_sample_count: 304848
total_episode_count: 2628
total_duration: 18516.154689131505
[2024-12-27 17:09:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76180125777553
avg_train_sample_per_sec: 16.76180125777553
avg_episode_per_sec: 0.14449828670496148
collect_time: 41.52298367558419
reward_mean: -115.06255835667599
reward_std: 2.657350923418045
reward_max: -111.6211484593838
reward_min: -118.5322128851541
queue_len: 0.07630143127100529
wait_time: 0.7289087827880932
delay_time: 4.702701779511601
pressure: 0.9250663129973474
total_envstep_count: 305544
total_train_sample_count: 305544
total_episode_count: 2634
total_duration: 18557.677672807087
[2024-12-27 17:09:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.975341827822405
avg_train_sample_per_sec: 16.975341827822405
avg_episode_per_sec: 0.14633915368812417
collect_time: 41.00064711859077
reward_mean: -117.34687208216617
reward_std: 1.809194491925542
reward_max: -114.01400560224089
reward_min: -119.33473389355746
queue_len: 0.07781622817119775
wait_time: 0.7532774161830957
delay_time: 4.781586267391062
pressure: 0.9512599469496021
total_envstep_count: 306240
total_train_sample_count: 306240
total_episode_count: 2640
total_duration: 18598.67831992568
[2024-12-27 17:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.588956642020815
avg_train_sample_per_sec: 16.588956642020815
avg_episode_per_sec: 0.14300824691397254
collect_time: 41.95562234679609
reward_mean: -116.56816059757237
reward_std: 2.7590934709849853
reward_max: -112.82282913165267
reward_min: -121.04201680672264
queue_len: 0.07729984124507451
wait_time: 0.7411156991532245
delay_time: 4.739490042849219
pressure: 0.9509283819628647
total_envstep_count: 306936
total_train_sample_count: 306936
total_episode_count: 2646
total_duration: 18640.633942272474
[2024-12-27 17:11:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.720926476817734
avg_train_sample_per_sec: 16.720926476817734
avg_episode_per_sec: 0.14414591790360115
collect_time: 41.62448779168726
reward_mean: -117.77112511671338
reward_std: 4.3730733648974995
reward_max: -111.95448179271712
reward_min: -123.96778711484592
queue_len: 0.07809756307474361
wait_time: 0.7471238827095825
delay_time: 4.807215855102939
pressure: 0.9581122900088417
total_envstep_count: 307632
total_train_sample_count: 307632
total_episode_count: 2652
total_duration: 18682.25843006416
[2024-12-27 17:11:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.695994099748436
avg_train_sample_per_sec: 16.695994099748436
avg_episode_per_sec: 0.143930983618521
collect_time: 41.68664626028389
reward_mean: -117.69969654528477
reward_std: 3.388557256972078
reward_max: -113.29971988795509
reward_min: -122.83053221288515
queue_len: 0.07805019664806682
wait_time: 0.7517812717483103
delay_time: 4.751499430415254
pressure: 0.9571175950486294
total_envstep_count: 308328
total_train_sample_count: 308328
total_episode_count: 2658
total_duration: 18723.945076324446
[2024-12-27 17:12:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81969453804321
avg_train_sample_per_sec: 16.81969453804321
avg_episode_per_sec: 0.14499736670726904
collect_time: 41.380061833214015
reward_mean: -115.55987394957982
reward_std: 3.6065505126034525
reward_max: -108.75280112044818
reward_min: -119.53081232492998
queue_len: 0.07663121614693623
wait_time: 0.7370364591459926
delay_time: 4.7701724473827625
pressure: 0.9419761273209549
total_envstep_count: 309024
total_train_sample_count: 309024
total_episode_count: 2664
total_duration: 18765.32513815766
[2024-12-27 17:13:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.788988734011692
avg_train_sample_per_sec: 16.788988734011692
avg_episode_per_sec: 0.1447326615001008
collect_time: 41.45574286973104
reward_mean: -118.12243230625585
reward_std: 2.626096993569798
reward_max: -115.25350140056018
reward_min: -121.92366946778712
queue_len: 0.07833052540202642
wait_time: 0.7593606739778139
delay_time: 4.798737576013226
pressure: 0.9619805481874447
total_envstep_count: 309720
total_train_sample_count: 309720
total_episode_count: 2670
total_duration: 18806.78088102739
[2024-12-27 17:13:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.743112462344932
avg_train_sample_per_sec: 16.743112462344932
avg_episode_per_sec: 0.14433717639952526
collect_time: 41.56933196054772
reward_mean: -118.57154528478056
reward_std: 3.6567890870261524
reward_max: -114.46638655462186
reward_min: -124.99579831932776
queue_len: 0.07862834567956271
wait_time: 0.7570937415638226
delay_time: 4.823164096196199
pressure: 0.9561229000884173
total_envstep_count: 310416
total_train_sample_count: 310416
total_episode_count: 2676
total_duration: 18848.350212987938
[2024-12-27 17:14:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81851265091689
avg_train_sample_per_sec: 16.81851265091689
avg_episode_per_sec: 0.1449871780251456
collect_time: 41.382969733774665
reward_mean: -116.99801587301585
reward_std: 3.142688892641233
reward_max: -112.96288515406162
reward_min: -122.81722689075623
queue_len: 0.07758489116247735
wait_time: 0.7489671487516315
delay_time: 4.811666265964106
pressure: 0.9508178603006189
total_envstep_count: 311112
total_train_sample_count: 311112
total_episode_count: 2682
total_duration: 18889.733182721713
[2024-12-27 17:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53572116557079
avg_train_sample_per_sec: 16.53572116557079
avg_episode_per_sec: 0.14254932039285165
collect_time: 42.090695230707524
reward_mean: -118.52882819794583
reward_std: 1.8388608786859377
reward_max: -116.46078431372555
reward_min: -121.71008403361346
queue_len: 0.07860001869890308
wait_time: 0.7558683287638663
delay_time: 4.838382955586855
pressure: 0.9617595048629531
total_envstep_count: 311808
total_train_sample_count: 311808
total_episode_count: 2688
total_duration: 18931.82387795242
[2024-12-27 17:16:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.855172505329655
avg_train_sample_per_sec: 16.855172505329655
avg_episode_per_sec: 0.14530321125284185
collect_time: 41.2929621325396
reward_mean: -118.22280578898227
reward_std: 5.181137041340715
reward_max: -113.0189075630252
reward_min: -125.36904761904759
queue_len: 0.07839708606696436
wait_time: 0.7548151223354064
delay_time: 4.849621012606242
pressure: 0.9480548187444738
total_envstep_count: 312504
total_train_sample_count: 312504
total_episode_count: 2694
total_duration: 18973.11684008496
[2024-12-27 17:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.866947102952494
avg_train_sample_per_sec: 16.866947102952494
avg_episode_per_sec: 0.14540471640476288
collect_time: 41.26413604974002
reward_mean: -116.14437441643322
reward_std: 2.668901839332455
reward_max: -112.77801120448177
reward_min: -120.25560224089638
queue_len: 0.07701881592601674
wait_time: 0.7394721151059894
delay_time: 4.709116005635781
pressure: 0.943081343943413
total_envstep_count: 313200
total_train_sample_count: 313200
total_episode_count: 2700
total_duration: 19014.3809761347
[2024-12-27 17:17:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.473470739316507
avg_train_sample_per_sec: 16.473470739316507
avg_episode_per_sec: 0.14201267878721127
collect_time: 42.24974876356125
reward_mean: -119.24778244631186
reward_std: 3.658645718542179
reward_max: -112.51470588235298
reward_min: -123.296918767507
queue_len: 0.07907677881055164
wait_time: 0.7575381500964666
delay_time: 4.906186745187875
pressure: 0.9633068081343943
total_envstep_count: 313896
total_train_sample_count: 313896
total_episode_count: 2706
total_duration: 19056.630724898263
[2024-12-27 17:18:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.60035992785694
avg_train_sample_per_sec: 16.60035992785694
avg_episode_per_sec: 0.14310655110221498
collect_time: 41.92680176964402
reward_mean: -115.14600840336136
reward_std: 3.447729591398853
reward_max: -109.11974789915969
reward_min: -120.82983193277312
queue_len: 0.07635676949825024
wait_time: 0.7350805043502814
delay_time: 4.6526789924280925
pressure: 0.9312555260831124
total_envstep_count: 314592
total_train_sample_count: 314592
total_episode_count: 2712
total_duration: 19098.557526667908
[2024-12-27 17:18:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.823057244033052
avg_train_sample_per_sec: 16.823057244033052
avg_episode_per_sec: 0.14502635555200907
collect_time: 41.37179050774872
reward_mean: -115.16164799253033
reward_std: 2.913263163864318
reward_max: -111.59383753501402
reward_min: -120.01890756302524
queue_len: 0.07636714057860103
wait_time: 0.7315503898287873
delay_time: 4.715671345978957
pressure: 0.9329133510167993
total_envstep_count: 315288
total_train_sample_count: 315288
total_episode_count: 2718
total_duration: 19139.929317175658
[2024-12-27 17:19:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75418207624619
avg_train_sample_per_sec: 16.75418207624619
avg_episode_per_sec: 0.1444326041055706
collect_time: 41.54186679078638
reward_mean: -118.04061624649863
reward_std: 2.7064154243099807
reward_max: -113.91106442577035
reward_min: -122.50420168067228
queue_len: 0.0782762707204898
wait_time: 0.7456326916266064
delay_time: 4.851734233967757
pressure: 0.9564544650751547
total_envstep_count: 315984
total_train_sample_count: 315984
total_episode_count: 2724
total_duration: 19181.471183966445
[2024-12-27 17:20:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.67564047903065
avg_train_sample_per_sec: 16.67564047903065
avg_episode_per_sec: 0.1437555213709539
collect_time: 41.73752731567994
reward_mean: -117.97665732959852
reward_std: 3.6864169325215954
reward_max: -112.28711484593842
reward_min: -122.2801120448179
queue_len: 0.07823385764562236
wait_time: 0.7526888960712489
delay_time: 4.799351006993044
pressure: 0.9505968169761273
total_envstep_count: 316680
total_train_sample_count: 316680
total_episode_count: 2730
total_duration: 19223.208711282125
[2024-12-27 17:21:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.81396820560913
avg_train_sample_per_sec: 16.81396820560913
avg_episode_per_sec: 0.1449480017724925
collect_time: 41.39415463910624
reward_mean: -115.84453781512606
reward_std: 2.3637804859776796
reward_max: -113.02310924369746
reward_min: -118.98319327731099
queue_len: 0.07681998528854513
wait_time: 0.734014759750054
delay_time: 4.743607735015608
pressure: 0.9363395225464192
total_envstep_count: 317376
total_train_sample_count: 317376
total_episode_count: 2736
total_duration: 19264.60286592123
[2024-12-27 17:21:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.600592419644475
avg_train_sample_per_sec: 16.600592419644475
avg_episode_per_sec: 0.1431085553417627
collect_time: 41.92621458354592
reward_mean: -115.6781045751634
reward_std: 3.859980665612349
reward_max: -107.78151260504202
reward_min: -118.89005602240894
queue_len: 0.07670961841854337
wait_time: 0.7338873657332075
delay_time: 4.74753339028643
pressure: 0.9358974358974358
total_envstep_count: 318072
total_train_sample_count: 318072
total_episode_count: 2742
total_duration: 19306.529080504777
[2024-12-27 17:22:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.714939869662086
avg_train_sample_per_sec: 16.714939869662086
avg_episode_per_sec: 0.14409430922122488
collect_time: 41.63939597911761
reward_mean: -118.31255835667599
reward_std: 3.9871417567180525
reward_max: -112.29201680672271
reward_min: -125.05602240896354
queue_len: 0.07845660368479841
wait_time: 0.75491751740484
delay_time: 4.842779350852977
pressure: 0.9553492484526966
total_envstep_count: 318768
total_train_sample_count: 318768
total_episode_count: 2748
total_duration: 19348.168476483894
[2024-12-27 17:23:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.57898536144224
avg_train_sample_per_sec: 16.57898536144224
avg_episode_per_sec: 0.14292228759863998
collect_time: 41.98085617583618
reward_mean: -115.41806722689076
reward_std: 4.577554581737361
reward_max: -106.38165266106446
reward_min: -120.19817927170872
queue_len: 0.07653717985868087
wait_time: 0.736733608120525
delay_time: 4.8015392303437645
pressure: 0.9301503094606544
total_envstep_count: 319464
total_train_sample_count: 319464
total_episode_count: 2754
total_duration: 19390.14933265973
[2024-12-27 17:23:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.493465854849035
avg_train_sample_per_sec: 16.493465854849035
avg_episode_per_sec: 0.1421850504728365
collect_time: 42.198529170591385
reward_mean: -115.7873482726424
reward_std: 2.8340178285958677
reward_max: -111.10294117647067
reward_min: -120.11624649859944
queue_len: 0.0767820611887549
wait_time: 0.733836980857772
delay_time: 4.7604879420233965
pressure: 0.9412024756852343
total_envstep_count: 320160
total_train_sample_count: 320160
total_episode_count: 2760
total_duration: 19432.34786183032
[2024-12-27 17:24:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8019371677125
avg_train_sample_per_sec: 16.8019371677125
avg_episode_per_sec: 0.14484428592855603
collect_time: 41.42379495011271
reward_mean: -118.48762838468723
reward_std: 2.9985940611081126
reward_max: -115.49299719887958
reward_min: -124.23249299719886
queue_len: 0.07857269786782972
wait_time: 0.7591632364705386
delay_time: 4.829421404349119
pressure: 0.9559018567639258
total_envstep_count: 320856
total_train_sample_count: 320856
total_episode_count: 2766
total_duration: 19473.77165678043
[2024-12-27 17:25:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.712684663274057
avg_train_sample_per_sec: 16.712684663274057
avg_episode_per_sec: 0.1440748677868453
collect_time: 41.64501479103788
reward_mean: -116.39624183006536
reward_std: 2.1485521824325877
reward_max: -113.35714285714286
reward_min: -119.72899159663865
queue_len: 0.07718583675733777
wait_time: 0.7372954265702744
delay_time: 4.8310911907264815
pressure: 0.935344827586207
total_envstep_count: 321552
total_train_sample_count: 321552
total_episode_count: 2772
total_duration: 19515.416671571467
[2024-12-27 17:25:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.63279624473419
avg_train_sample_per_sec: 16.63279624473419
avg_episode_per_sec: 0.1433861745235706
collect_time: 41.84503854668141
reward_mean: -118.27602707749766
reward_std: 3.802226385334747
reward_max: -111.55182072829129
reward_min: -123.7927170868347
queue_len: 0.07843237869860586
wait_time: 0.7503600467596411
delay_time: 4.8482978346202845
pressure: 0.9535809018567639
total_envstep_count: 322248
total_train_sample_count: 322248
total_episode_count: 2778
total_duration: 19557.26171011815
[2024-12-27 17:26:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.43411436308488
avg_train_sample_per_sec: 16.43411436308488
avg_episode_per_sec: 0.1416733996817662
collect_time: 42.35092835689336
reward_mean: -118.24789915966387
reward_std: 2.897688251170552
reward_max: -113.3214285714286
reward_min: -122.83193277310924
queue_len: 0.07841372623319885
wait_time: 0.755084925216771
delay_time: 4.884322935253651
pressure: 0.9646330680813439
total_envstep_count: 322944
total_train_sample_count: 322944
total_episode_count: 2784
total_duration: 19599.612638475042
[2024-12-27 17:27:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.46902316215625
avg_train_sample_per_sec: 16.46902316215625
avg_episode_per_sec: 0.14197433760479528
collect_time: 42.26115860953555
reward_mean: -117.5249766573296
reward_std: 3.442332334013688
reward_max: -114.14635854341736
reward_min: -124.21638655462182
queue_len: 0.07793433465340159
wait_time: 0.7497560474233902
delay_time: 4.775333971405762
pressure: 0.949049513704686
total_envstep_count: 323640
total_train_sample_count: 323640
total_episode_count: 2790
total_duration: 19641.87379708458
[2024-12-27 17:28:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.881973906764184
avg_train_sample_per_sec: 16.881973906764184
avg_episode_per_sec: 0.14553425781693263
collect_time: 41.22740645400063
reward_mean: -115.8096405228758
reward_std: 1.224878026150574
reward_max: -113.73599439775907
reward_min: -117.48039215686273
queue_len: 0.07679684384806089
wait_time: 0.7397517472948508
delay_time: 4.678693640398999
pressure: 0.9352343059239611
total_envstep_count: 324336
total_train_sample_count: 324336
total_episode_count: 2796
total_duration: 19683.10120353858
[2024-12-27 17:28:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.87240959186845
avg_train_sample_per_sec: 16.87240959186845
avg_episode_per_sec: 0.14545180682645217
collect_time: 41.25077667243407
reward_mean: -116.87149859943976
reward_std: 2.951279742290129
reward_max: -113.05462184873953
reward_min: -122.08193277310923
queue_len: 0.07750099376620674
wait_time: 0.7458528061976338
delay_time: 4.701272933908339
pressure: 0.9550176834659593
total_envstep_count: 325032
total_train_sample_count: 325032
total_episode_count: 2802
total_duration: 19724.351980211013
[2024-12-27 17:29:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.60070730073382
avg_train_sample_per_sec: 16.60070730073382
avg_episode_per_sec: 0.14310954569598122
collect_time: 41.925924443546684
reward_mean: -117.85084033613447
reward_std: 2.8088155564614086
reward_max: -114.7717086834734
reward_min: -123.73599439775909
queue_len: 0.07815042462608386
wait_time: 0.7544543016145452
delay_time: 4.806708487144772
pressure: 0.9618700265251988
total_envstep_count: 325728
total_train_sample_count: 325728
total_episode_count: 2808
total_duration: 19766.27790465456
[2024-12-27 17:30:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.505087641959634
avg_train_sample_per_sec: 16.505087641959634
avg_episode_per_sec: 0.14228523829275547
collect_time: 42.168815767485654
reward_mean: -115.53839869281046
reward_std: 3.1920834740457877
reward_max: -111.75350140056021
reward_min: -121.02380952380949
queue_len: 0.07661697526048439
wait_time: 0.7345727857898244
delay_time: 4.690483493353482
pressure: 0.9413129973474801
total_envstep_count: 326424
total_train_sample_count: 326424
total_episode_count: 2814
total_duration: 19808.446720422045
[2024-12-27 17:30:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.750178468151034
avg_train_sample_per_sec: 16.750178468151034
avg_episode_per_sec: 0.14439809024268135
collect_time: 41.55179607927054
reward_mean: -117.54878618113912
reward_std: 3.3674152421258534
reward_max: -114.70378151260508
reward_min: -124.54481792717087
queue_len: 0.07795012346229385
wait_time: 0.7502283959560835
delay_time: 4.779793349264776
pressure: 0.9465075154730327
total_envstep_count: 327120
total_train_sample_count: 327120
total_episode_count: 2820
total_duration: 19849.998516501317
[2024-12-27 17:31:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.711052371731874
avg_train_sample_per_sec: 16.711052371731874
avg_episode_per_sec: 0.1440607963080334
collect_time: 41.649082566298546
reward_mean: -117.41059757236225
reward_std: 7.153400027987337
reward_max: -110.03221288515408
reward_min: -130.4614845938375
queue_len: 0.07785848645382111
wait_time: 0.7550651892056557
delay_time: 4.773050003075307
pressure: 0.9542440318302386
total_envstep_count: 327816
total_train_sample_count: 327816
total_episode_count: 2826
total_duration: 19891.647599067615
[2024-12-27 17:32:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.494877209389884
avg_train_sample_per_sec: 16.494877209389884
avg_episode_per_sec: 0.1421972173223266
collect_time: 42.19491852923856
reward_mean: -116.68825863678806
reward_std: 3.2765971349316754
reward_max: -113.42156862745098
reward_min: -122.39635854341739
queue_len: 0.07737948185463399
wait_time: 0.7455022791610014
delay_time: 4.730031632354543
pressure: 0.9466180371352785
total_envstep_count: 328512
total_train_sample_count: 328512
total_episode_count: 2832
total_duration: 19933.842517596855
[2024-12-27 17:33:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.615292685227946
avg_train_sample_per_sec: 16.615292685227946
avg_episode_per_sec: 0.14323528176920644
collect_time: 41.88912065441907
reward_mean: -115.99159663865544
reward_std: 5.019750427443583
reward_max: -109.08543417366946
reward_min: -124.29481792717088
queue_len: 0.0769175044022914
wait_time: 0.7397873495109805
delay_time: 4.717737557675414
pressure: 0.9487179487179488
total_envstep_count: 329208
total_train_sample_count: 329208
total_episode_count: 2838
total_duration: 19975.731638251273
[2024-12-27 17:33:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5721978978439
avg_train_sample_per_sec: 16.5721978978439
avg_episode_per_sec: 0.14286377498141295
collect_time: 41.99805024598167
reward_mean: -115.09161998132585
reward_std: 3.429766183398871
reward_max: -109.65616246498595
reward_min: -120.24719887955177
queue_len: 0.0763207029053885
wait_time: 0.7302238976934717
delay_time: 4.7212963657886275
pressure: 0.9355658709106985
total_envstep_count: 329904
total_train_sample_count: 329904
total_episode_count: 2844
total_duration: 20017.729688497253
[2024-12-27 17:34:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.59630663142003
avg_train_sample_per_sec: 16.59630663142003
avg_episode_per_sec: 0.143071608891552
collect_time: 41.93704150309786
reward_mean: -113.98447712418302
reward_std: 3.6106640286704565
reward_max: -109.09873949579831
reward_min: -119.02941176470588
queue_len: 0.07558652329189855
wait_time: 0.727458224669178
delay_time: 4.635885610251733
pressure: 0.9239610963748893
total_envstep_count: 330600
total_train_sample_count: 330600
total_episode_count: 2850
total_duration: 20059.66673000035
[2024-12-27 17:35:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.804590874642678
avg_train_sample_per_sec: 16.804590874642678
avg_episode_per_sec: 0.14486716271243688
collect_time: 41.41725348697603
reward_mean: -118.91444911297852
reward_std: 3.811576776642831
reward_max: -111.93207282913164
reward_min: -122.71778711484596
queue_len: 0.07885573548606002
wait_time: 0.760484775254045
delay_time: 4.794756422720347
pressure: 0.9599911582670203
total_envstep_count: 331296
total_train_sample_count: 331296
total_episode_count: 2856
total_duration: 20101.083983487326
[2024-12-27 17:35:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.72206182890661
avg_train_sample_per_sec: 16.72206182890661
avg_episode_per_sec: 0.14415570542160872
collect_time: 41.621661677919334
reward_mean: -117.4403594771242
reward_std: 5.243289081957411
reward_max: -107.78571428571428
reward_min: -122.94957983193282
queue_len: 0.07787822246493648
wait_time: 0.7518420277040967
delay_time: 4.749917544927321
pressure: 0.9541335101679929
total_envstep_count: 331992
total_train_sample_count: 331992
total_episode_count: 2862
total_duration: 20142.705645165246
[2024-12-27 17:36:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.236007984403397
avg_train_sample_per_sec: 16.236007984403397
avg_episode_per_sec: 0.13996558607244305
collect_time: 42.867680323179826
reward_mean: -114.92892156862744
reward_std: 2.639516322783497
reward_max: -112.29691876750697
reward_min: -120.00700280112042
queue_len: 0.07621281271129139
wait_time: 0.7338932478384811
delay_time: 4.716804430838949
pressure: 0.9361184792219275
total_envstep_count: 332688
total_train_sample_count: 332688
total_episode_count: 2868
total_duration: 20185.573325488425
[2024-12-27 17:37:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.29153468714216
avg_train_sample_per_sec: 16.29153468714216
avg_episode_per_sec: 0.14044426454432898
collect_time: 42.72157371087373
reward_mean: -116.95179738562092
reward_std: 2.1668050440208533
reward_max: -113.35924369747899
reward_min: -119.33053221288513
queue_len: 0.0775542422981571
wait_time: 0.7432296968301025
delay_time: 4.770909088329865
pressure: 0.9427497789566753
total_envstep_count: 333384
total_train_sample_count: 333384
total_episode_count: 2874
total_duration: 20228.2948991993
[2024-12-27 17:38:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.405212697670176
avg_train_sample_per_sec: 16.405212697670176
avg_episode_per_sec: 0.14142424739370843
collect_time: 42.42553954200447
reward_mean: -117.01062091503267
reward_std: 4.251757441192516
reward_max: -110.93627450980391
reward_min: -124.61344537815125
queue_len: 0.07759324994365562
wait_time: 0.7455581591611002
delay_time: 4.772306228945062
pressure: 0.9482758620689654
total_envstep_count: 334080
total_train_sample_count: 334080
total_episode_count: 2880
total_duration: 20270.720438741304
[2024-12-27 17:38:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.361177577959378
avg_train_sample_per_sec: 16.361177577959378
avg_episode_per_sec: 0.14104463429275327
collect_time: 42.53972531522437
reward_mean: -118.90534547152195
reward_std: 3.132323623539359
reward_max: -115.22899159663864
reward_min: -124.39495798319327
queue_len: 0.0788496985885424
wait_time: 0.7608503945344717
delay_time: 4.967114383742852
pressure: 0.9665119363395225
total_envstep_count: 334776
total_train_sample_count: 334776
total_episode_count: 2886
total_duration: 20313.26016405653
[2024-12-27 17:39:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.31898988390124
avg_train_sample_per_sec: 16.31898988390124
avg_episode_per_sec: 0.14068094727501065
collect_time: 42.64969859970361
reward_mean: -118.82516339869284
reward_std: 4.514909753485197
reward_max: -113.23039215686276
reward_min: -124.55742296918771
queue_len: 0.07879652745271408
wait_time: 0.7560148396228518
delay_time: 4.844781005312359
pressure: 0.9672855879752431
total_envstep_count: 335472
total_train_sample_count: 335472
total_episode_count: 2892
total_duration: 20355.909862656234
[2024-12-27 17:40:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.41202652757668
avg_train_sample_per_sec: 16.41202652757668
avg_episode_per_sec: 0.1414829873066955
collect_time: 42.40792560446635
reward_mean: -117.86974789915966
reward_std: 3.063574652816183
reward_max: -113.71288515406158
reward_min: -121.96498599439775
queue_len: 0.07816296279785123
wait_time: 0.7486687867012413
delay_time: 4.857295428487833
pressure: 0.9556808134394341
total_envstep_count: 336168
total_train_sample_count: 336168
total_episode_count: 2898
total_duration: 20398.3177882607
[2024-12-27 17:40:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.604787571529044
avg_train_sample_per_sec: 16.604787571529044
avg_episode_per_sec: 0.1431447204442159
collect_time: 41.915622045859706
reward_mean: -113.5685107376284
reward_std: 4.657353343868248
reward_max: -107.53011204481798
reward_min: -121.32282913165267
queue_len: 0.07531068351301617
wait_time: 0.7240361551340252
delay_time: 4.61961507901414
pressure: 0.9293766578249336
total_envstep_count: 336864
total_train_sample_count: 336864
total_episode_count: 2904
total_duration: 20440.233410306562
[2024-12-27 17:41:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.58474182667673
avg_train_sample_per_sec: 16.58474182667673
avg_episode_per_sec: 0.14297191229893733
collect_time: 41.96628487037867
reward_mean: -115.41409897292249
reward_std: 3.8341574164226073
reward_max: -110.2303921568627
reward_min: -121.28291316526608
queue_len: 0.07653454839053214
wait_time: 0.7342443166479677
delay_time: 4.661822539684642
pressure: 0.9410919540229884
total_envstep_count: 337560
total_train_sample_count: 337560
total_episode_count: 2910
total_duration: 20482.19969517694
[2024-12-27 17:42:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.603148634062645
avg_train_sample_per_sec: 16.603148634062645
avg_episode_per_sec: 0.14313059167295383
collect_time: 41.91975963957235
reward_mean: -114.41433239962653
reward_std: 3.013206689640256
reward_max: -110.31022408963587
reward_min: -120.0595238095238
queue_len: 0.07587157320930142
wait_time: 0.7243565750791919
delay_time: 4.660756208261911
pressure: 0.9297082228116711
total_envstep_count: 338256
total_train_sample_count: 338256
total_episode_count: 2916
total_duration: 20524.11945481651
[2024-12-27 17:43:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.705087037374085
avg_train_sample_per_sec: 16.705087037374085
avg_episode_per_sec: 0.14400937101184555
collect_time: 41.663955323480074
reward_mean: -117.6889589169001
reward_std: 3.501592628174357
reward_max: -114.53081232492997
reward_min: -125.15826330532214
queue_len: 0.07804307620484092
wait_time: 0.7544323211158911
delay_time: 4.713082163812094
pressure: 0.9592175066312997
total_envstep_count: 338952
total_train_sample_count: 338952
total_episode_count: 2922
total_duration: 20565.783410139993
[2024-12-27 17:43:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.432139622019964
avg_train_sample_per_sec: 16.432139622019964
avg_episode_per_sec: 0.14165637605189624
collect_time: 42.35601790209487
reward_mean: -116.79843604108311
reward_std: 2.1939380808702493
reward_max: -113.15826330532221
reward_min: -120.32913165266105
queue_len: 0.07745254379382169
wait_time: 0.7490717109124817
delay_time: 4.676156510831782
pressure: 0.9596595932802829
total_envstep_count: 339648
total_train_sample_count: 339648
total_episode_count: 2928
total_duration: 20608.139428042086
[2024-12-27 17:44:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5475268687152
avg_train_sample_per_sec: 16.5475268687152
avg_episode_per_sec: 0.14265109369582066
collect_time: 42.060665954612205
reward_mean: -115.4985994397759
reward_std: 4.054744103628662
reward_max: -111.45378151260503
reward_min: -123.97408963585433
queue_len: 0.07659058318287527
wait_time: 0.7392141538312939
delay_time: 4.724980176338621
pressure: 0.9421971706454465
total_envstep_count: 340344
total_train_sample_count: 340344
total_episode_count: 2934
total_duration: 20650.2000939967
[2024-12-27 17:45:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.59218360066575
avg_train_sample_per_sec: 16.59218360066575
avg_episode_per_sec: 0.1430360655229806
collect_time: 41.94746253724396
reward_mean: -117.3563258636788
reward_std: 5.849819978525064
reward_max: -108.20518207282909
reward_min: -125.29901960784315
queue_len: 0.07782249725708144
wait_time: 0.7512522692542976
delay_time: 4.783092044622982
pressure: 0.9504862953138815
total_envstep_count: 341040
total_train_sample_count: 341040
total_episode_count: 2940
total_duration: 20692.147556533942
[2024-12-27 17:45:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.604770700954127
avg_train_sample_per_sec: 16.604770700954127
avg_episode_per_sec: 0.14314457500822522
collect_time: 41.91566463245452
reward_mean: -117.01762371615312
reward_std: 2.301089668349072
reward_max: -114.2142857142857
reward_min: -121.35644257703082
queue_len: 0.07759789371097686
wait_time: 0.7440404212082713
delay_time: 4.763245869137598
pressure: 0.9512599469496023
total_envstep_count: 341736
total_train_sample_count: 341736
total_episode_count: 2946
total_duration: 20734.063221166398
[2024-12-27 17:46:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.367560341790618
avg_train_sample_per_sec: 16.367560341790618
avg_episode_per_sec: 0.1410996581188846
collect_time: 42.52313634200767
reward_mean: -113.54376750700281
reward_std: 2.762352129321682
reward_max: -110.55042016806725
reward_min: -117.5567226890756
queue_len: 0.07529427553514777
wait_time: 0.7195505080900616
delay_time: 4.62518862750277
pressure: 0.9236295313881522
total_envstep_count: 342432
total_train_sample_count: 342432
total_episode_count: 2952
total_duration: 20776.586357508404
[2024-12-27 17:47:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.577786873518967
avg_train_sample_per_sec: 16.577786873518967
avg_episode_per_sec: 0.14291195580619798
collect_time: 41.98389117378369
reward_mean: -117.67565359477125
reward_std: 2.7706344770624014
reward_max: -114.79971988795518
reward_min: -121.79761904761905
queue_len: 0.07803425304693053
wait_time: 0.7565494920337718
delay_time: 4.835387677567868
pressure: 0.9421971706454465
total_envstep_count: 343128
total_train_sample_count: 343128
total_episode_count: 2958
total_duration: 20818.570248682187
[2024-12-27 17:48:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.536271085550503
avg_train_sample_per_sec: 16.536271085550503
avg_episode_per_sec: 0.14255406108233193
collect_time: 42.08929548864067
reward_mean: -118.76190476190476
reward_std: 4.174220666984736
reward_max: -110.95938375350137
reward_min: -122.45658263305322
queue_len: 0.07875457875457874
wait_time: 0.7597521435629954
delay_time: 4.875843597359104
pressure: 0.9631962864721486
total_envstep_count: 343824
total_train_sample_count: 343824
total_episode_count: 2964
total_duration: 20860.659544170827
[2024-12-27 17:48:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.835442844879765
avg_train_sample_per_sec: 16.835442844879765
avg_episode_per_sec: 0.14513312797310143
collect_time: 41.34135385762528
reward_mean: -116.11951447245563
reward_std: 1.5484481064889102
reward_max: -113.28781512605036
reward_min: -118.29761904761904
queue_len: 0.0770023305520263
wait_time: 0.7408626138342163
delay_time: 4.687550848798918
pressure: 0.9398762157382848
total_envstep_count: 344520
total_train_sample_count: 344520
total_episode_count: 2970
total_duration: 20902.00089802845
[2024-12-27 17:49:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.80277353816102
avg_train_sample_per_sec: 16.80277353816102
avg_episode_per_sec: 0.14485149601862948
collect_time: 41.42173305016011
reward_mean: -118.12511671335199
reward_std: 1.898030180829527
reward_max: -115.12114845938376
reward_min: -120.86204481792717
queue_len: 0.07833230551283288
wait_time: 0.7564806094851733
delay_time: 4.807144854145954
pressure: 0.9549071618037136
total_envstep_count: 345216
total_train_sample_count: 345216
total_episode_count: 2976
total_duration: 20943.42263107861
[2024-12-27 17:50:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.504538582412952
avg_train_sample_per_sec: 16.504538582412952
avg_episode_per_sec: 0.1422805050208013
collect_time: 42.17021860530228
reward_mean: -117.95459850606908
reward_std: 4.820008789270071
reward_max: -109.96218487394958
reward_min: -125.50490196078424
queue_len: 0.0782192297785604
wait_time: 0.7499386248752374
delay_time: 4.873530275479075
pressure: 0.9587754199823166
total_envstep_count: 345912
total_train_sample_count: 345912
total_episode_count: 2982
total_duration: 20985.59284968391
[2024-12-27 17:50:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.820123405050673
avg_train_sample_per_sec: 16.820123405050673
avg_episode_per_sec: 0.1450010638366437
collect_time: 41.379006755147124
reward_mean: -116.24206349206348
reward_std: 3.746839445097912
reward_max: -110.20938375350144
reward_min: -122.07142857142853
queue_len: 0.07708359648014819
wait_time: 0.7399875732786483
delay_time: 4.70005210379781
pressure: 0.9387709991158267
total_envstep_count: 346608
total_train_sample_count: 346608
total_episode_count: 2988
total_duration: 21026.971856439057
[2024-12-27 17:51:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.565191117271958
avg_train_sample_per_sec: 16.565191117271958
avg_episode_per_sec: 0.14280337170062032
collect_time: 42.015814672630285
reward_mean: -116.74673202614379
reward_std: 3.8452841270543483
reward_max: -112.5980392156863
reward_min: -121.48319327731089
queue_len: 0.07741825731176644
wait_time: 0.7435429963320429
delay_time: 4.766495786469812
pressure: 0.9497126436781609
total_envstep_count: 347304
total_train_sample_count: 347304
total_episode_count: 2994
total_duration: 21068.98767111169
[2024-12-27 17:52:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.63511214805801
avg_train_sample_per_sec: 16.63511214805801
avg_episode_per_sec: 0.14340613920739664
collect_time: 41.839212973460555
reward_mean: -115.55917366946778
reward_std: 3.9227355821332863
reward_max: -109.80672268907561
reward_min: -121.2478991596639
queue_len: 0.0766307517702041
wait_time: 0.7333911791949316
delay_time: 4.748549720796928
pressure: 0.9374447391688769
total_envstep_count: 348000
total_train_sample_count: 348000
total_episode_count: 3000
total_duration: 21110.82688408515
[2024-12-27 17:52:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.655923897823435
avg_train_sample_per_sec: 16.655923897823435
avg_episode_per_sec: 0.1435855508433055
collect_time: 41.78693444264307
reward_mean: -115.12698412698411
reward_std: 3.2814269908873572
reward_max: -109.37955182072824
reward_min: -119.15406162464984
queue_len: 0.07634415393036081
wait_time: 0.7332469128234848
delay_time: 4.6626851610822735
pressure: 0.9352343059239611
total_envstep_count: 348696
total_train_sample_count: 348696
total_episode_count: 3006
total_duration: 21152.613818527792
[2024-12-27 17:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.668091241982882
avg_train_sample_per_sec: 16.668091241982882
avg_episode_per_sec: 0.14369044174123174
collect_time: 41.75643088915572
reward_mean: -118.7989028944911
reward_std: 2.3841912877047053
reward_max: -115.16876750700284
reward_min: -121.53851540616247
queue_len: 0.07877911332525936
wait_time: 0.7607856913764621
delay_time: 4.942778954766525
pressure: 0.9635278514588861
total_envstep_count: 349392
total_train_sample_count: 349392
total_episode_count: 3012
total_duration: 21194.37024941695
[2024-12-27 17:54:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.521547571231714
avg_train_sample_per_sec: 16.521547571231714
avg_episode_per_sec: 0.14242713423475617
collect_time: 42.12680422334745
reward_mean: -118.70529878618113
reward_std: 5.212402151274379
reward_max: -113.04551820728294
reward_min: -124.94887955182075
queue_len: 0.07871704163539862
wait_time: 0.7638172974760197
delay_time: 4.853302157458168
pressure: 0.9599911582670203
total_envstep_count: 350088
total_train_sample_count: 350088
total_episode_count: 3018
total_duration: 21236.497053640294
[2024-12-27 17:55:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.496504857021968
avg_train_sample_per_sec: 16.496504857021968
avg_episode_per_sec: 0.14221124876743074
collect_time: 42.1907553164959
reward_mean: -119.77987861811391
reward_std: 3.2451319062279924
reward_max: -115.40756302521012
reward_min: -124.40546218487395
queue_len: 0.07942962773084479
wait_time: 0.7665155584780332
delay_time: 4.9002977992541314
pressure: 0.9656277630415562
total_envstep_count: 350784
total_train_sample_count: 350784
total_episode_count: 3024
total_duration: 21278.68780895679
[2024-12-27 17:55:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54095802375943
avg_train_sample_per_sec: 16.54095802375943
avg_episode_per_sec: 0.14259446572206405
collect_time: 42.07736933980883
reward_mean: -117.52742763772176
reward_std: 4.208512758039001
reward_max: -109.88655462184876
reward_min: -122.77941176470586
queue_len: 0.07793595997196402
wait_time: 0.748497896063819
delay_time: 4.813278396695216
pressure: 0.9504862953138815
total_envstep_count: 351480
total_train_sample_count: 351480
total_episode_count: 3030
total_duration: 21320.7651782966
[2024-12-27 17:56:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.69056130559747
avg_train_sample_per_sec: 16.69056130559747
avg_episode_per_sec: 0.14388414918618508
collect_time: 41.700215304717425
reward_mean: -116.44806255835665
reward_std: 4.157947597609988
reward_max: -111.43137254901958
reward_min: -124.01680672268907
queue_len: 0.07722020063551503
wait_time: 0.7406718323934348
delay_time: 4.727681726846083
pressure: 0.9377763041556145
total_envstep_count: 352176
total_train_sample_count: 352176
total_episode_count: 3036
total_duration: 21362.465393601316
[2024-12-27 17:57:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.499891583956476
avg_train_sample_per_sec: 16.499891583956476
avg_episode_per_sec: 0.14224044468927996
collect_time: 42.18209534641728
reward_mean: -113.48389355742297
reward_std: 2.467367851759177
reward_max: -110.93837535014002
reward_min: -117.27591036414563
queue_len: 0.07525457132455105
wait_time: 0.7171384579472816
delay_time: 4.662454477854144
pressure: 0.9204244031830239
total_envstep_count: 352872
total_train_sample_count: 352872
total_episode_count: 3042
total_duration: 21404.647488947732
[2024-12-27 17:57:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.618364514019284
avg_train_sample_per_sec: 16.618364514019284
avg_episode_per_sec: 0.14326176305189037
collect_time: 41.88137764175609
reward_mean: -115.70436507936506
reward_std: 3.3531314376436585
reward_max: -111.87745098039217
reward_min: -121.51680672268907
queue_len: 0.07672703254599807
wait_time: 0.7337413966470762
delay_time: 4.6897538706424085
pressure: 0.937555260831123
total_envstep_count: 353568
total_train_sample_count: 353568
total_episode_count: 3048
total_duration: 21446.528866589488
[2024-12-27 17:58:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.756927425290048
avg_train_sample_per_sec: 16.756927425290048
avg_episode_per_sec: 0.14445627090767282
collect_time: 41.5350608339794
reward_mean: -112.87885154061627
reward_std: 1.9451950900647423
reward_max: -109.03851540616247
reward_min: -115.27240896358545
queue_len: 0.07485334982799487
wait_time: 0.7200463076477274
delay_time: 4.5378174295974745
pressure: 0.9194297082228117
total_envstep_count: 354264
total_train_sample_count: 354264
total_episode_count: 3054
total_duration: 21488.063927423467
[2024-12-27 17:59:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.705504821215772
avg_train_sample_per_sec: 16.705504821215772
avg_episode_per_sec: 0.1440129725966877
collect_time: 41.662913359917695
reward_mean: -114.49603174603176
reward_std: 1.4004894161995103
reward_max: -112.70028011204484
reward_min: -116.57633053221289
queue_len: 0.07592575049471602
wait_time: 0.7296058896591351
delay_time: 4.682016602519697
pressure: 0.9283819628647215
total_envstep_count: 354960
total_train_sample_count: 354960
total_episode_count: 3060
total_duration: 21529.726840783384
[2024-12-27 18:00:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.58727562128222
avg_train_sample_per_sec: 16.58727562128222
avg_episode_per_sec: 0.1429937553558812
collect_time: 41.9598742970787
reward_mean: -115.91538281979457
reward_std: 2.124603636363199
reward_max: -113.56792717086834
reward_min: -119.24999999999997
queue_len: 0.0768669647346118
wait_time: 0.7368733081207726
delay_time: 4.6823126997037505
pressure: 0.9322502210433244
total_envstep_count: 355656
total_train_sample_count: 355656
total_episode_count: 3066
total_duration: 21571.68671508046
[2024-12-27 18:00:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.492584454518376
avg_train_sample_per_sec: 16.492584454518376
avg_episode_per_sec: 0.14217745219412392
collect_time: 42.20078435368091
reward_mean: -115.9595004668534
reward_std: 5.671174396953977
reward_max: -109.15476190476191
reward_min: -125.80252100840335
queue_len: 0.07689622046873568
wait_time: 0.7341026043485476
delay_time: 4.727270514735285
pressure: 0.9431918656056587
total_envstep_count: 356352
total_train_sample_count: 356352
total_episode_count: 3072
total_duration: 21613.887499434142
[2024-12-27 18:01:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.64341904814078
avg_train_sample_per_sec: 16.64341904814078
avg_episode_per_sec: 0.14347775041500674
collect_time: 41.81833059582487
reward_mean: -116.04493464052287
reward_std: 2.647091627085495
reward_max: -113.07773109243702
reward_min: -119.79271708683473
queue_len: 0.07695287443005495
wait_time: 0.7419711584899212
delay_time: 4.635841563041488
pressure: 0.9496021220159151
total_envstep_count: 357048
total_train_sample_count: 357048
total_episode_count: 3078
total_duration: 21655.70583002997
[2024-12-27 18:02:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.478683990218272
avg_train_sample_per_sec: 16.478683990218272
avg_episode_per_sec: 0.14205762060532995
collect_time: 42.236382493477315
reward_mean: -116.50490196078432
reward_std: 2.279906998628485
reward_max: -113.00210084033613
reward_min: -120.26820728291317
queue_len: 0.0772578925469392
wait_time: 0.7445754605998013
delay_time: 4.735389019596447
pressure: 0.9447391688771
total_envstep_count: 357744
total_train_sample_count: 357744
total_episode_count: 3084
total_duration: 21697.942212523445
[2024-12-27 18:02:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.533102063650364
avg_train_sample_per_sec: 16.533102063650364
avg_episode_per_sec: 0.1425267419280204
collect_time: 42.097363055069
reward_mean: -117.32878151260508
reward_std: 2.9019542712845383
reward_max: -113.4845938375351
reward_min: -122.18277310924374
queue_len: 0.07780423177228453
wait_time: 0.7433676167195437
delay_time: 4.700759267219023
pressure: 0.9565649867374005
total_envstep_count: 358440
total_train_sample_count: 358440
total_episode_count: 3090
total_duration: 21740.039575578514
[2024-12-27 18:03:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.66027102440439
avg_train_sample_per_sec: 16.66027102440439
avg_episode_per_sec: 0.14362302607245164
collect_time: 41.776031072992836
reward_mean: -117.25583566760038
reward_std: 2.938366078330716
reward_max: -112.80742296918767
reward_min: -120.73389355742299
queue_len: 0.07775585919602147
wait_time: 0.7459774913502093
delay_time: 4.740723957906806
pressure: 0.9418656056587092
total_envstep_count: 359136
total_train_sample_count: 359136
total_episode_count: 3096
total_duration: 21781.815606651508
[2024-12-27 18:04:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.4699221822071
avg_train_sample_per_sec: 16.4699221822071
avg_episode_per_sec: 0.14198208777764743
collect_time: 42.258851760204884
reward_mean: -120.37383286647992
reward_std: 7.804508050209917
reward_max: -109.66106442577032
reward_min: -131.48179271708685
queue_len: 0.07982349659580897
wait_time: 0.7726706398739869
delay_time: 4.865914038509874
pressure: 0.9874005305039789
total_envstep_count: 359832
total_train_sample_count: 359832
total_episode_count: 3102
total_duration: 21824.074458411713
[2024-12-27 18:05:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.650449211664178
avg_train_sample_per_sec: 16.650449211664178
avg_episode_per_sec: 0.14353835527296704
collect_time: 41.80067403301224
reward_mean: -113.85014005602238
reward_std: 1.6236057448520167
reward_max: -111.88725490196076
reward_min: -115.7829131652661
queue_len: 0.07549744035545251
wait_time: 0.729304973536718
delay_time: 4.6070997701024625
pressure: 0.9276083112290009
total_envstep_count: 360528
total_train_sample_count: 360528
total_episode_count: 3108
total_duration: 21865.875132444726
[2024-12-27 18:05:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55976784596059
avg_train_sample_per_sec: 16.55976784596059
avg_episode_per_sec: 0.14275661936172923
collect_time: 42.029574718330046
reward_mean: -117.53781512605042
reward_std: 4.548224770064843
reward_max: -109.90546218487395
reward_min: -123.33543417366947
queue_len: 0.07794284822682389
wait_time: 0.7490561542919555
delay_time: 4.797276921833615
pressure: 0.9499336870026526
total_envstep_count: 361224
total_train_sample_count: 361224
total_episode_count: 3114
total_duration: 21907.904707163056
[2024-12-27 18:06:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.679732524691868
avg_train_sample_per_sec: 16.679732524691868
avg_episode_per_sec: 0.14379079762665403
collect_time: 41.727287830885494
reward_mean: -117.18732492997202
reward_std: 3.3697914299026985
reward_max: -113.65406162464988
reward_min: -124.24019607843137
queue_len: 0.07771042767239524
wait_time: 0.7485366715209515
delay_time: 4.77445768696309
pressure: 0.9521441202475686
total_envstep_count: 361920
total_train_sample_count: 361920
total_episode_count: 3120
total_duration: 21949.631994993942
[2024-12-27 18:07:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.25759098939423
avg_train_sample_per_sec: 16.25759098939423
avg_episode_per_sec: 0.1401516464602951
collect_time: 42.81077070114761
reward_mean: -117.22525676937441
reward_std: 3.843991236061495
reward_max: -110.15056022408962
reward_min: -123.02310924369745
queue_len: 0.077735581412052
wait_time: 0.7482089763403151
delay_time: 4.775771490057204
pressure: 0.9582228116710875
total_envstep_count: 362616
total_train_sample_count: 362616
total_episode_count: 3126
total_duration: 21992.44276569509
[2024-12-27 18:07:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.64108366255603
avg_train_sample_per_sec: 16.64108366255603
avg_episode_per_sec: 0.14345761778065547
collect_time: 41.824199319787326
reward_mean: -114.10982726423902
reward_std: 2.625590262100948
reward_max: -110.39285714285715
reward_min: -118.2261904761905
queue_len: 0.07566964672694895
wait_time: 0.7225078139124791
delay_time: 4.654997403477337
pressure: 0.933134394341291
total_envstep_count: 363312
total_train_sample_count: 363312
total_episode_count: 3132
total_duration: 22034.26696501488
[2024-12-27 18:08:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.725339242749495
avg_train_sample_per_sec: 16.725339242749495
avg_episode_per_sec: 0.1441839589892198
collect_time: 41.61350570522621
reward_mean: -116.09978991596637
reward_std: 4.465136619993122
reward_max: -107.31302521008402
reward_min: -120.96428571428568
queue_len: 0.07698925060740476
wait_time: 0.73288059697796
delay_time: 4.734171896253785
pressure: 0.9439655172413791
total_envstep_count: 364008
total_train_sample_count: 364008
total_episode_count: 3138
total_duration: 22075.880470720105
[2024-12-27 18:09:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.43553471751932
avg_train_sample_per_sec: 16.43553471751932
avg_episode_per_sec: 0.14168564411654586
collect_time: 42.347268401198086
reward_mean: -115.62896825396825
reward_std: 2.2639822239508356
reward_max: -112.07843137254902
reward_min: -119.26400560224089
queue_len: 0.07667703465117258
wait_time: 0.7343402104431518
delay_time: 4.6889622700564635
pressure: 0.9414235190097259
total_envstep_count: 364704
total_train_sample_count: 364704
total_episode_count: 3144
total_duration: 22118.227739121303
[2024-12-27 18:10:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.479196906686738
avg_train_sample_per_sec: 16.479196906686738
avg_episode_per_sec: 0.1420620422990236
collect_time: 42.23506788231805
reward_mean: -118.0654761904762
reward_std: 3.779032730063668
reward_max: -112.42927170868352
reward_min: -122.84033613445379
queue_len: 0.07829275609448023
wait_time: 0.7518749984520774
delay_time: 4.705538991109459
pressure: 0.9643015030946066
total_envstep_count: 365400
total_train_sample_count: 365400
total_episode_count: 3150
total_duration: 22160.46280700362
[2024-12-27 18:10:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.564176619085504
avg_train_sample_per_sec: 16.564176619085504
avg_episode_per_sec: 0.14279462602659918
collect_time: 42.01838799509406
reward_mean: -119.2260737628385
reward_std: 2.6559522439092444
reward_max: -115.33893557422968
reward_min: -123.03851540616246
queue_len: 0.07906238313185576
wait_time: 0.7595822590751599
delay_time: 4.86849547587279
pressure: 0.9609858532272325
total_envstep_count: 366096
total_train_sample_count: 366096
total_episode_count: 3156
total_duration: 22202.481194998712
[2024-12-27 18:11:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.426216825501047
avg_train_sample_per_sec: 16.426216825501047
avg_episode_per_sec: 0.1416053174612159
collect_time: 42.37129019991309
reward_mean: -120.37535014005603
reward_std: 4.27909520789934
reward_max: -114.12605042016804
reward_min: -125.68207282913168
queue_len: 0.07982450274539525
wait_time: 0.7633897612979763
delay_time: 4.949721581717314
pressure: 0.9721485411140582
total_envstep_count: 366792
total_train_sample_count: 366792
total_episode_count: 3162
total_duration: 22244.852485198626
[2024-12-27 18:12:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.50031112368332
avg_train_sample_per_sec: 16.50031112368332
avg_episode_per_sec: 0.1422440614110631
collect_time: 42.18102281726151
reward_mean: -116.36776377217556
reward_std: 2.2407109377312384
reward_max: -113.8326330532213
reward_min: -120.71008403361348
queue_len: 0.07716695210356468
wait_time: 0.7428443415385605
delay_time: 4.781562627042235
pressure: 0.9467285587975244
total_envstep_count: 367488
total_train_sample_count: 367488
total_episode_count: 3168
total_duration: 22287.033508015887
[2024-12-27 18:12:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.40243407215613
avg_train_sample_per_sec: 16.40243407215613
avg_episode_per_sec: 0.14140029372548388
collect_time: 42.4327265659608
reward_mean: -120.35819327731092
reward_std: 4.3979715195999205
reward_max: -113.96428571428568
reward_min: -128.27450980392157
queue_len: 0.07981312551545817
wait_time: 0.7707654569343211
delay_time: 4.954303803285417
pressure: 0.96684350132626
total_envstep_count: 368184
total_train_sample_count: 368184
total_episode_count: 3174
total_duration: 22329.466234581847
[2024-12-27 18:13:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52725845765292
avg_train_sample_per_sec: 16.52725845765292
avg_episode_per_sec: 0.14247636601424932
collect_time: 42.11224758076669
reward_mean: -119.89600840336136
reward_std: 1.933046932777753
reward_max: -117.19607843137258
reward_min: -123.4075630252101
queue_len: 0.07950663687225555
wait_time: 0.7632296287215151
delay_time: 4.850816873988099
pressure: 0.9713748894783376
total_envstep_count: 368880
total_train_sample_count: 368880
total_episode_count: 3180
total_duration: 22371.578482162615
[2024-12-27 18:14:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.463329372554288
avg_train_sample_per_sec: 16.463329372554288
avg_episode_per_sec: 0.14192525321167487
collect_time: 42.27577449554577
reward_mean: -119.4263538748833
reward_std: 2.8723739276461373
reward_max: -116.71918767507003
reward_min: -125.50630252100841
queue_len: 0.07919519487724357
wait_time: 0.7603690680516237
delay_time: 4.84138642247072
pressure: 0.9735853227232538
total_envstep_count: 369576
total_train_sample_count: 369576
total_episode_count: 3186
total_duration: 22413.85425665816
[2024-12-27 18:15:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55553689855228
avg_train_sample_per_sec: 16.55553689855228
avg_episode_per_sec: 0.14272014567717484
collect_time: 42.0403158329986
reward_mean: -117.98050887021475
reward_std: 3.4240260687050217
reward_max: -111.56862745098036
reward_min: -122.52310924369749
queue_len: 0.07823641171764902
wait_time: 0.7505974206658791
delay_time: 4.842173498427559
pressure: 0.9589964633068081
total_envstep_count: 370272
total_train_sample_count: 370272
total_episode_count: 3192
total_duration: 22455.894572491157
[2024-12-27 18:15:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.427997992902295
avg_train_sample_per_sec: 16.427997992902295
avg_episode_per_sec: 0.141620672352606
collect_time: 42.36669619150832
reward_mean: -116.35259103641455
reward_std: 3.5345832578425243
reward_max: -111.39915966386553
reward_min: -120.3928571428571
queue_len: 0.07715689060770196
wait_time: 0.7413819418129762
delay_time: 4.750337616214876
pressure: 0.9451812555260831
total_envstep_count: 370968
total_train_sample_count: 370968
total_episode_count: 3198
total_duration: 22498.261268682665
[2024-12-27 18:16:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.452254217564242
avg_train_sample_per_sec: 16.452254217564242
avg_episode_per_sec: 0.1418297777376228
collect_time: 42.304233255583796
reward_mean: -118.12371615312793
reward_std: 3.1326669442813344
reward_max: -114.65826330532215
reward_min: -124.56582633053225
queue_len: 0.07833137675936865
wait_time: 0.7491631157325885
delay_time: 4.800464526265544
pressure: 0.9608753315649867
total_envstep_count: 371664
total_train_sample_count: 371664
total_episode_count: 3204
total_duration: 22540.56550193825
[2024-12-27 18:17:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.58284168880656
avg_train_sample_per_sec: 16.58284168880656
avg_episode_per_sec: 0.14295553180005655
collect_time: 41.97109355930238
reward_mean: -117.6670168067227
reward_std: 6.504295394359857
reward_max: -110.2542016806723
reward_min: -130.90266106442576
queue_len: 0.078028525733901
wait_time: 0.7426996107903815
delay_time: 4.844344197334916
pressure: 0.9504862953138815
total_envstep_count: 372360
total_train_sample_count: 372360
total_episode_count: 3210
total_duration: 22582.536595497553
[2024-12-27 18:17:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61183154090527
avg_train_sample_per_sec: 16.61183154090527
avg_episode_per_sec: 0.14320544431814888
collect_time: 41.89784842725844
reward_mean: -116.812091503268
reward_std: 2.995659276796184
reward_max: -112.34593837535013
reward_min: -121.51750700280112
queue_len: 0.07746159914009813
wait_time: 0.7407996133908914
delay_time: 4.8176682555210215
pressure: 0.9439655172413793
total_envstep_count: 373056
total_train_sample_count: 373056
total_episode_count: 3216
total_duration: 22624.434443924813
[2024-12-27 18:18:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5913273234451
avg_train_sample_per_sec: 16.5913273234451
avg_episode_per_sec: 0.1430286838228026
collect_time: 41.94962744279578
reward_mean: -116.18172268907563
reward_std: 2.4360527728601946
reward_max: -113.5791316526611
reward_min: -119.11974789915965
queue_len: 0.07704358268506342
wait_time: 0.736582608286462
delay_time: 4.740043287363054
pressure: 0.9394341290893015
total_envstep_count: 373752
total_train_sample_count: 373752
total_episode_count: 3222
total_duration: 22666.384071367607
[2024-12-27 18:19:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.440902260055726
avg_train_sample_per_sec: 16.440902260055726
avg_episode_per_sec: 0.14173191603496316
collect_time: 42.333443079397085
reward_mean: -119.86157796451914
reward_std: 1.6994555960395021
reward_max: -117.2528011204482
reward_min: -122.60434173669469
queue_len: 0.07948380501625939
wait_time: 0.7693733328875316
delay_time: 4.828024760194239
pressure: 0.976790450928382
total_envstep_count: 374448
total_train_sample_count: 374448
total_episode_count: 3228
total_duration: 22708.717514447006
[2024-12-27 18:20:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.47234384242796
avg_train_sample_per_sec: 16.47234384242796
avg_episode_per_sec: 0.1420029641588617
collect_time: 42.25263913003727
reward_mean: -114.93674136321196
reward_std: 1.661829414216598
reward_max: -111.7983193277311
reward_min: -117.38585434173672
queue_len: 0.0762179982514668
wait_time: 0.7299068831776743
delay_time: 4.688057602035807
pressure: 0.928050397877984
total_envstep_count: 375144
total_train_sample_count: 375144
total_episode_count: 3234
total_duration: 22750.970153577044
[2024-12-27 18:20:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55082339848042
avg_train_sample_per_sec: 16.55082339848042
avg_episode_per_sec: 0.1426795120558657
collect_time: 42.05228847187758
reward_mean: -117.60550887021476
reward_std: 3.2044078683070105
reward_max: -114.3627450980392
reward_min: -124.01890756302517
queue_len: 0.07798773797759599
wait_time: 0.7499537945151536
delay_time: 4.760426374921702
pressure: 0.9581122900088418
total_envstep_count: 375840
total_train_sample_count: 375840
total_episode_count: 3240
total_duration: 22793.02244204892
[2024-12-27 18:21:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.565492197530514
avg_train_sample_per_sec: 16.565492197530514
avg_episode_per_sec: 0.14280596722009065
collect_time: 42.01505102901534
reward_mean: -115.55217086834735
reward_std: 2.7040706884024273
reward_max: -110.34243697478996
reward_min: -118.85364145658262
queue_len: 0.07662610800288286
wait_time: 0.7401492537775498
delay_time: 4.669170465970731
pressure: 0.9398762157382846
total_envstep_count: 376536
total_train_sample_count: 376536
total_episode_count: 3246
total_duration: 22835.037493077936
[2024-12-27 18:22:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.290115842640834
avg_train_sample_per_sec: 16.290115842640834
avg_episode_per_sec: 0.14043203312621408
collect_time: 42.725294695459304
reward_mean: -114.43487394957982
reward_std: 3.712857461503263
reward_max: -110.43837535014008
reward_min: -121.7093837535014
queue_len: 0.07588519492677707
wait_time: 0.7207428727459154
delay_time: 4.732813654254274
pressure: 0.9307029177718834
total_envstep_count: 377232
total_train_sample_count: 377232
total_episode_count: 3252
total_duration: 22877.762787773394
[2024-12-27 18:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.438515415220134
avg_train_sample_per_sec: 16.438515415220134
avg_episode_per_sec: 0.14171133978638048
collect_time: 42.3395898242481
reward_mean: -116.78338001867412
reward_std: 4.272534659905821
reward_max: -112.49929971988794
reward_min: -125.67507002801119
queue_len: 0.07744255969408098
wait_time: 0.744106981873209
delay_time: 4.8584354100033105
pressure: 0.9412024756852344
total_envstep_count: 377928
total_train_sample_count: 377928
total_episode_count: 3258
total_duration: 22920.102377597643
[2024-12-27 18:23:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53097089559938
avg_train_sample_per_sec: 16.53097089559938
avg_episode_per_sec: 0.14250836978964984
collect_time: 42.102790235102184
reward_mean: -116.30240429505137
reward_std: 3.2518064655010273
reward_max: -113.04551820728295
reward_min: -121.15266106442581
queue_len: 0.07712361027523301
wait_time: 0.7345004204157348
delay_time: 4.759093405747559
pressure: 0.9427497789566756
total_envstep_count: 378624
total_train_sample_count: 378624
total_episode_count: 3264
total_duration: 22962.205167832744
[2024-12-27 18:24:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.453984714341185
avg_train_sample_per_sec: 16.453984714341185
avg_episode_per_sec: 0.1418446958132861
collect_time: 42.299784039143475
reward_mean: -117.89133986928103
reward_std: 3.2244259529506913
reward_max: -112.52871148459387
reward_min: -122.70868347338933
queue_len: 0.0781772810804251
wait_time: 0.7481342116864428
delay_time: 4.739467480204067
pressure: 0.948054818744474
total_envstep_count: 379320
total_train_sample_count: 379320
total_episode_count: 3270
total_duration: 23004.504951871888
[2024-12-27 18:25:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.44844401054707
avg_train_sample_per_sec: 16.44844401054707
avg_episode_per_sec: 0.14179693112540578
collect_time: 42.31403283822536
reward_mean: -117.03851540616246
reward_std: 2.9469747157213804
reward_max: -114.32983193277313
reward_min: -121.7535014005602
queue_len: 0.07761174761681862
wait_time: 0.7416183095696282
delay_time: 4.672231689509181
pressure: 0.9587754199823166
total_envstep_count: 380016
total_train_sample_count: 380016
total_episode_count: 3276
total_duration: 23046.818984710113
[2024-12-27 18:25:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.539739117800142
avg_train_sample_per_sec: 16.539739117800142
avg_episode_per_sec: 0.14258395791207018
collect_time: 42.08047025668994
reward_mean: -118.1265172735761
reward_std: 2.1086487190460668
reward_max: -115.9509803921568
reward_min: -121.4453781512605
queue_len: 0.07833323426629714
wait_time: 0.7552349189012476
delay_time: 4.770903574102463
pressure: 0.9631962864721486
total_envstep_count: 380712
total_train_sample_count: 380712
total_episode_count: 3282
total_duration: 23088.899454966802
[2024-12-27 18:26:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.47120986149961
avg_train_sample_per_sec: 16.47120986149961
avg_episode_per_sec: 0.1419931884612035
collect_time: 42.255548065528274
reward_mean: -115.62850140056024
reward_std: 3.699767627852933
reward_max: -109.54621848739495
reward_min: -121.00630252100838
queue_len: 0.0766767250666845
wait_time: 0.7372554901713116
delay_time: 4.749523392782851
pressure: 0.9382183908045977
total_envstep_count: 381408
total_train_sample_count: 381408
total_episode_count: 3288
total_duration: 23131.15500303233
[2024-12-27 18:27:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.484180934128396
avg_train_sample_per_sec: 16.484180934128396
avg_episode_per_sec: 0.142105008052831
collect_time: 42.22229801900686
reward_mean: -114.98914565826328
reward_std: 2.6583935054706047
reward_max: -111.15056022408965
reward_min: -118.72198879551821
queue_len: 0.07625274911025416
wait_time: 0.7349367797516885
delay_time: 4.7376972019194055
pressure: 0.9299292661361628
total_envstep_count: 382104
total_train_sample_count: 382104
total_episode_count: 3294
total_duration: 23173.377301051336
[2024-12-27 18:27:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.4795862013671
avg_train_sample_per_sec: 16.4795862013671
avg_episode_per_sec: 0.14206539828764742
collect_time: 42.23407016993314
reward_mean: -117.24883286647992
reward_std: 4.4209459521935575
reward_max: -111.93487394957982
reward_min: -125.11344537815127
queue_len: 0.07775121542870021
wait_time: 0.7442495455299714
delay_time: 4.815267411086901
pressure: 0.951923076923077
total_envstep_count: 382800
total_train_sample_count: 382800
total_episode_count: 3300
total_duration: 23215.61137122127
[2024-12-27 18:28:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.386463437456886
avg_train_sample_per_sec: 16.386463437456886
avg_episode_per_sec: 0.14126261584014554
collect_time: 42.47408250452951
reward_mean: -118.74194677871151
reward_std: 5.478701099637718
reward_max: -112.9495798319328
reward_min: -129.093137254902
queue_len: 0.0787413440177132
wait_time: 0.7595585758618212
delay_time: 4.813389432119325
pressure: 0.963527851458886
total_envstep_count: 383496
total_train_sample_count: 383496
total_episode_count: 3306
total_duration: 23258.0854537258
[2024-12-27 18:29:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52634638067749
avg_train_sample_per_sec: 16.52634638067749
avg_episode_per_sec: 0.1424685032817025
collect_time: 42.11457172492519
reward_mean: -117.46988795518207
reward_std: 2.1600632804374067
reward_max: -113.96918767507002
reward_min: -120.0644257703081
queue_len: 0.07789780368380773
wait_time: 0.7463405565586093
delay_time: 4.810686701211845
pressure: 0.959106984969054
total_envstep_count: 384192
total_train_sample_count: 384192
total_episode_count: 3312
total_duration: 23300.200025450722
[2024-12-27 18:30:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.428094864271397
avg_train_sample_per_sec: 16.428094864271397
avg_episode_per_sec: 0.1416215074506155
collect_time: 42.366446368269635
reward_mean: -115.59768907563024
reward_std: 3.068552226944639
reward_max: -112.31092436974788
reward_min: -120.4110644257703
queue_len: 0.07665629249047098
wait_time: 0.7327810655650412
delay_time: 4.750591670839364
pressure: 0.9476127320954908
total_envstep_count: 384888
total_train_sample_count: 384888
total_episode_count: 3318
total_duration: 23342.56647181899
[2024-12-27 18:30:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.450031770513977
avg_train_sample_per_sec: 16.450031770513977
avg_episode_per_sec: 0.14181061871132739
collect_time: 42.309948680315145
reward_mean: -118.24451447245565
reward_std: 3.0113048920533867
reward_max: -114.38375350140062
reward_min: -122.19257703081236
queue_len: 0.07841148174566025
wait_time: 0.7516097619419123
delay_time: 4.914842823959215
pressure: 0.9561229000884173
total_envstep_count: 385584
total_train_sample_count: 385584
total_episode_count: 3324
total_duration: 23384.876420499306
[2024-12-27 18:31:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.47335709833895
avg_train_sample_per_sec: 16.47335709833895
avg_episode_per_sec: 0.14201169912361164
collect_time: 42.25004022223129
reward_mean: -118.82259570494864
reward_std: 4.763257031634576
reward_max: -112.2843137254902
reward_min: -126.47198879551816
queue_len: 0.07879482473802961
wait_time: 0.7562597209529258
delay_time: 4.8948196191986595
pressure: 0.9640804597701149
total_envstep_count: 386280
total_train_sample_count: 386280
total_episode_count: 3330
total_duration: 23427.126460721538
[2024-12-27 18:32:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.396135385302276
avg_train_sample_per_sec: 16.396135385302276
avg_episode_per_sec: 0.14134599470088172
collect_time: 42.44902738628909
reward_mean: -117.87161531279179
reward_std: 0.6482353293538845
reward_max: -116.99369747899159
reward_min: -118.59663865546214
queue_len: 0.07816420113580357
wait_time: 0.7499251579500058
delay_time: 4.855774559409535
pressure: 0.9509283819628647
total_envstep_count: 386976
total_train_sample_count: 386976
total_episode_count: 3336
total_duration: 23469.57548810783
[2024-12-27 18:32:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.563284972704142
avg_train_sample_per_sec: 16.563284972704142
avg_episode_per_sec: 0.1427869394198633
collect_time: 42.020649958446626
reward_mean: -117.32726423902896
reward_std: 3.7964203603150684
reward_max: -113.59663865546219
reward_min: -124.34313725490198
queue_len: 0.07780322562269824
wait_time: 0.7449892976642469
delay_time: 4.74968475063335
pressure: 0.9471706454465075
total_envstep_count: 387672
total_train_sample_count: 387672
total_episode_count: 3342
total_duration: 23511.596138066274
[2024-12-27 18:33:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.273207949300893
avg_train_sample_per_sec: 16.273207949300893
avg_episode_per_sec: 0.1402862754250077
collect_time: 42.76968635614962
reward_mean: -117.5294117647059
reward_std: 5.688072559800559
reward_max: -108.44607843137254
reward_min: -124.22689075630251
queue_len: 0.07793727570603838
wait_time: 0.7453946211552703
delay_time: 4.783698401496001
pressure: 0.9521441202475686
total_envstep_count: 388368
total_train_sample_count: 388368
total_episode_count: 3348
total_duration: 23554.365824422424
[2024-12-27 18:34:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.41726645362499
avg_train_sample_per_sec: 16.41726645362499
avg_episode_per_sec: 0.14152815908297403
collect_time: 42.39439019681141
reward_mean: -116.7137021475257
reward_std: 2.79124090542633
reward_max: -111.24649859943979
reward_min: -119.52450980392165
queue_len: 0.07739635420923455
wait_time: 0.7399566922259622
delay_time: 4.7640343098852584
pressure: 0.9315870910698497
total_envstep_count: 389064
total_train_sample_count: 389064
total_episode_count: 3354
total_duration: 23596.760214619237
[2024-12-27 18:35:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51894374436664
avg_train_sample_per_sec: 16.51894374436664
avg_episode_per_sec: 0.14240468745143656
collect_time: 42.133444533180445
reward_mean: -115.8355508870215
reward_std: 2.597286145505802
reward_max: -112.7591036414566
reward_min: -120.46708683473393
queue_len: 0.07681402578714953
wait_time: 0.741054478820706
delay_time: 4.7250397365134065
pressure: 0.9361184792219275
total_envstep_count: 389760
total_train_sample_count: 389760
total_episode_count: 3360
total_duration: 23638.893659152418
[2024-12-27 18:35:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.406630218526125
avg_train_sample_per_sec: 16.406630218526125
avg_episode_per_sec: 0.14143646740108728
collect_time: 42.421874006405474
reward_mean: -114.75992063492065
reward_std: 2.8460576254275605
reward_max: -109.83683473389355
reward_min: -118.02170868347338
queue_len: 0.0761007431266052
wait_time: 0.7220815160723882
delay_time: 4.675630518678115
pressure: 0.9260610079575596
total_envstep_count: 390456
total_train_sample_count: 390456
total_episode_count: 3366
total_duration: 23681.315533158824
[2024-12-27 18:36:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.411316425545163
avg_train_sample_per_sec: 16.411316425545163
avg_episode_per_sec: 0.1414768657374583
collect_time: 42.40976055501774
reward_mean: -118.0454014939309
reward_std: 1.2641769695791232
reward_max: -116.8088235294118
reward_min: -120.35364145658262
queue_len: 0.07827944396149265
wait_time: 0.7520530095327255
delay_time: 4.760388623998703
pressure: 0.9657382847038019
total_envstep_count: 391152
total_train_sample_count: 391152
total_episode_count: 3372
total_duration: 23723.72529371384
[2024-12-27 18:37:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.43574827450487
avg_train_sample_per_sec: 16.43574827450487
avg_episode_per_sec: 0.14168748512504198
collect_time: 42.34671816430987
reward_mean: -118.48471055088703
reward_std: 2.8084990765553957
reward_max: -114.55042016806723
reward_min: -123.67857142857142
queue_len: 0.0785707629647792
wait_time: 0.7520511520257971
delay_time: 4.827943514080445
pressure: 0.9639699381078692
total_envstep_count: 391848
total_train_sample_count: 391848
total_episode_count: 3378
total_duration: 23766.07201187815
[2024-12-27 18:37:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.26205952481073
avg_train_sample_per_sec: 16.26205952481073
avg_episode_per_sec: 0.14019016831733389
collect_time: 42.799007034633306
reward_mean: -117.84523809523809
reward_std: 3.194465620790252
reward_max: -111.03641456582633
reward_min: -120.34593837535009
queue_len: 0.07814670961222685
wait_time: 0.7539522329709957
delay_time: 4.789495414905614
pressure: 0.9660698496905393
total_envstep_count: 392544
total_train_sample_count: 392544
total_episode_count: 3384
total_duration: 23808.871018912785
[2024-12-27 18:38:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.23041217715909
avg_train_sample_per_sec: 16.23041217715909
avg_episode_per_sec: 0.13991734635481973
collect_time: 42.88245994020253
reward_mean: -114.85737628384686
reward_std: 3.063680476304428
reward_max: -111.56862745098036
reward_min: -121.24509803921572
queue_len: 0.07616536888849261
wait_time: 0.7318264617960359
delay_time: 4.737890489188875
pressure: 0.9293766578249337
total_envstep_count: 393240
total_train_sample_count: 393240
total_episode_count: 3390
total_duration: 23851.75347885299
[2024-12-27 18:39:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.35177572049654
avg_train_sample_per_sec: 16.35177572049654
avg_episode_per_sec: 0.14096358379738397
collect_time: 42.564184581346815
reward_mean: -117.43837535014006
reward_std: 3.375689390802885
reward_max: -112.01120448179275
reward_min: -121.28851540616243
queue_len: 0.0778769067308621
wait_time: 0.7411776934469633
delay_time: 4.805038202119967
pressure: 0.9460654288240495
total_envstep_count: 393936
total_train_sample_count: 393936
total_episode_count: 3396
total_duration: 23894.317663434336
[2024-12-27 18:40:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.622520553999603
avg_train_sample_per_sec: 16.622520553999603
avg_episode_per_sec: 0.14329759098275519
collect_time: 41.87090626472608
reward_mean: -114.05999066293184
reward_std: 3.1931664995707427
reward_max: -109.48039215686273
reward_min: -118.58403361344538
queue_len: 0.07563659858284605
wait_time: 0.7241338290400158
delay_time: 4.672312676603117
pressure: 0.9315870910698497
total_envstep_count: 394632
total_train_sample_count: 394632
total_episode_count: 3402
total_duration: 23936.18856969906
[2024-12-27 18:40:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.697965892521317
avg_train_sample_per_sec: 16.697965892521317
avg_episode_per_sec: 0.14394798183208032
collect_time: 41.68172365903109
reward_mean: -115.03921568627449
reward_std: 2.803912153423654
reward_max: -109.72268907563027
reward_min: -118.98319327731095
queue_len: 0.07628595204660114
wait_time: 0.7292765691599362
delay_time: 4.738977019251748
pressure: 0.9271662245800177
total_envstep_count: 395328
total_train_sample_count: 395328
total_episode_count: 3408
total_duration: 23977.870293358093
[2024-12-27 18:41:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.414288655418837
avg_train_sample_per_sec: 16.414288655418837
avg_episode_per_sec: 0.14150248840878307
collect_time: 42.40208117518574
reward_mean: -115.81127450980394
reward_std: 3.4755435256519513
reward_max: -110.55952380952382
reward_min: -121.8403361344538
queue_len: 0.07679792739376919
wait_time: 0.7378927698400316
delay_time: 4.68151784553796
pressure: 0.9298187444739169
total_envstep_count: 396024
total_train_sample_count: 396024
total_episode_count: 3414
total_duration: 24020.27237453328
[2024-12-27 18:42:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.59046686726664
avg_train_sample_per_sec: 16.59046686726664
avg_episode_per_sec: 0.14302126609712623
collect_time: 41.95180313901976
reward_mean: -117.265406162465
reward_std: 2.904108343387716
reward_max: -113.71988795518207
reward_min: -121.50770308123248
queue_len: 0.07776220567802718
wait_time: 0.7453587867507746
delay_time: 4.816389300840581
pressure: 0.9372236958443855
total_envstep_count: 396720
total_train_sample_count: 396720
total_episode_count: 3420
total_duration: 24062.2241776723
[2024-12-27 18:42:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.42856580235064
avg_train_sample_per_sec: 16.42856580235064
avg_episode_per_sec: 0.14162556726164344
collect_time: 42.365231899939474
reward_mean: -115.32469654528477
reward_std: 2.6722948947125276
reward_max: -112.19537815126051
reward_min: -119.42296918767506
queue_len: 0.07647526296106416
wait_time: 0.7410139232527669
delay_time: 4.729540696744197
pressure: 0.9404288240495137
total_envstep_count: 397416
total_train_sample_count: 397416
total_episode_count: 3426
total_duration: 24104.58940957224
[2024-12-27 18:43:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.619761679029775
avg_train_sample_per_sec: 16.619761679029775
avg_episode_per_sec: 0.1432738075778429
collect_time: 41.877856821388
reward_mean: -113.9125816993464
reward_std: 5.4149452131969
reward_max: -104.45728291316527
reward_min: -123.14495798319328
queue_len: 0.07553884728073369
wait_time: 0.7253188410642771
delay_time: 4.611875384258329
pressure: 0.9196507515473034
total_envstep_count: 398112
total_train_sample_count: 398112
total_episode_count: 3432
total_duration: 24146.46726639363
[2024-12-27 18:44:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.36738519730654
avg_train_sample_per_sec: 16.36738519730654
avg_episode_per_sec: 0.14109814825264258
collect_time: 42.52359137454256
reward_mean: -117.7795284780579
reward_std: 3.389233900450461
reward_max: -112.1218487394958
reward_min: -122.26820728291312
queue_len: 0.0781031355955291
wait_time: 0.7556062654947038
delay_time: 4.772044204110834
pressure: 0.9551282051282052
total_envstep_count: 398808
total_train_sample_count: 398808
total_episode_count: 3438
total_duration: 24188.99085776817
[2024-12-27 18:45:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.457489484631516
avg_train_sample_per_sec: 16.457489484631516
avg_episode_per_sec: 0.1418749093502717
collect_time: 42.2907759199813
reward_mean: -115.703548085901
reward_std: 1.7861506335424207
reward_max: -114.07422969187671
reward_min: -119.5973389355742
queue_len: 0.0767264907731439
wait_time: 0.7390285579306878
delay_time: 4.64846098405574
pressure: 0.9423076923076922
total_envstep_count: 399504
total_train_sample_count: 399504
total_episode_count: 3444
total_duration: 24231.28163368815
[2024-12-27 18:45:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.338085857234564
avg_train_sample_per_sec: 16.338085857234564
avg_episode_per_sec: 0.14084556773478074
collect_time: 42.59984958346933
reward_mean: -114.09021942110178
reward_std: 1.3365356976327434
reward_max: -112.19187675070029
reward_min: -115.96848739495799
queue_len: 0.07565664417844946
wait_time: 0.7277404883261882
delay_time: 4.662066679742309
pressure: 0.9284924845269673
total_envstep_count: 400200
total_train_sample_count: 400200
total_episode_count: 3450
total_duration: 24273.88148327162
[2024-12-27 18:46:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.473998511472075
avg_train_sample_per_sec: 16.473998511472075
avg_episode_per_sec: 0.14201722854717308
collect_time: 42.248395222041765
reward_mean: -117.24077964519142
reward_std: 4.987079360086783
reward_max: -110.46218487394958
reward_min: -124.77521008403362
queue_len: 0.07774587509628078
wait_time: 0.7464870674175947
delay_time: 4.861841068813189
pressure: 0.9387709991158268
total_envstep_count: 400896
total_train_sample_count: 400896
total_episode_count: 3456
total_duration: 24316.129878493663
[2024-12-27 18:47:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.42915955561871
avg_train_sample_per_sec: 16.42915955561871
avg_episode_per_sec: 0.14163068582429925
collect_time: 42.36370081158355
reward_mean: -114.06407563025213
reward_std: 2.6857446455607623
reward_max: -111.05462184873952
reward_min: -118.71848739495799
queue_len: 0.07563930744711679
wait_time: 0.7290656647274293
delay_time: 4.6613844710992955
pressure: 0.9129089301503095
total_envstep_count: 401592
total_train_sample_count: 401592
total_episode_count: 3462
total_duration: 24358.493579305246
[2024-12-27 18:47:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.506099730810742
avg_train_sample_per_sec: 16.506099730810742
avg_episode_per_sec: 0.14229396319664434
collect_time: 42.16623014223203
reward_mean: -114.14600840336135
reward_std: 4.581700192261789
reward_max: -108.10924369747903
reward_min: -120.71918767507003
queue_len: 0.07569363952477544
wait_time: 0.7185114651519316
delay_time: 4.729813068531776
pressure: 0.9226348364279398
total_envstep_count: 402288
total_train_sample_count: 402288
total_episode_count: 3468
total_duration: 24400.65980944748
[2024-12-27 18:48:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.391165719793094
avg_train_sample_per_sec: 16.391165719793094
avg_episode_per_sec: 0.14130315275683702
collect_time: 42.46189757934957
reward_mean: -115.69887955182072
reward_std: 3.180054388742377
reward_max: -111.36414565826328
reward_min: -119.17647058823528
queue_len: 0.07672339492826308
wait_time: 0.7300852812389325
delay_time: 4.761344542007521
pressure: 0.9417550839964633
total_envstep_count: 402984
total_train_sample_count: 402984
total_episode_count: 3474
total_duration: 24443.12170702683
[2024-12-27 18:49:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.315848079641725
avg_train_sample_per_sec: 16.315848079641725
avg_episode_per_sec: 0.14065386275553213
collect_time: 42.65791128984839
reward_mean: -117.32633053221292
reward_std: 2.738954901453338
reward_max: -113.70938375350144
reward_min: -120.62955182072832
queue_len: 0.0778026064537221
wait_time: 0.7498905618834626
delay_time: 4.854607798259349
pressure: 0.9447391688771
total_envstep_count: 403680
total_train_sample_count: 403680
total_episode_count: 3480
total_duration: 24485.779618316676
[2024-12-27 18:50:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55980343613229
avg_train_sample_per_sec: 16.55980343613229
avg_episode_per_sec: 0.14275692617355423
collect_time: 42.02948438876867
reward_mean: -114.70576563958919
reward_std: 3.1068434814337063
reward_max: -111.69467787114849
reward_min: -121.22268907563024
queue_len: 0.07606483132598751
wait_time: 0.7310319132073696
delay_time: 4.687690864915722
pressure: 0.9242926613616268
total_envstep_count: 404376
total_train_sample_count: 404376
total_episode_count: 3486
total_duration: 24527.809102705443
[2024-12-27 18:50:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.484946503635577
avg_train_sample_per_sec: 16.484946503635577
avg_episode_per_sec: 0.14211160778996187
collect_time: 42.220337193481626
reward_mean: -116.90149393090569
reward_std: 3.820102717003916
reward_max: -110.02100840336135
reward_min: -122.64075630252098
queue_len: 0.07752088456956611
wait_time: 0.7469205630970336
delay_time: 4.780104109110489
pressure: 0.9472811671087533
total_envstep_count: 405072
total_train_sample_count: 405072
total_episode_count: 3492
total_duration: 24570.029439898924
[2024-12-27 18:51:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.557650225737397
avg_train_sample_per_sec: 16.557650225737397
avg_episode_per_sec: 0.14273836401497758
collect_time: 42.03495003887265
reward_mean: -114.73809523809524
reward_std: 2.906353362386946
reward_max: -112.1589635854342
reward_min: -120.68277310924371
queue_len: 0.0760862700517873
wait_time: 0.7256506382393807
delay_time: 4.715472099024724
pressure: 0.9299292661361628
total_envstep_count: 405768
total_train_sample_count: 405768
total_episode_count: 3498
total_duration: 24612.064389937797
[2024-12-27 18:52:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.446252001627293
avg_train_sample_per_sec: 16.446252001627293
avg_episode_per_sec: 0.14177803449678703
collect_time: 42.319672587476674
reward_mean: -114.81874416433243
reward_std: 2.6535273814642335
reward_max: -109.75210084033614
reward_min: -117.21288515406167
queue_len: 0.07613975077210373
wait_time: 0.736399876042371
delay_time: 4.735965342896247
pressure: 0.9294871794871794
total_envstep_count: 406464
total_train_sample_count: 406464
total_episode_count: 3504
total_duration: 24654.384062525274
[2024-12-27 18:52:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.379817898297446
avg_train_sample_per_sec: 16.379817898297446
avg_episode_per_sec: 0.14120532670946076
collect_time: 42.49131488038971
reward_mean: -114.05882352941177
reward_std: 3.615998169081797
reward_max: -110.85994397759102
reward_min: -121.37535014005603
queue_len: 0.07563582462162584
wait_time: 0.7256076833916589
delay_time: 4.71241376073258
pressure: 0.9196507515473032
total_envstep_count: 407160
total_train_sample_count: 407160
total_episode_count: 3510
total_duration: 24696.875377405664
[2024-12-27 18:53:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.38410110267704
avg_train_sample_per_sec: 16.38410110267704
avg_episode_per_sec: 0.14124225088514689
collect_time: 42.480206612389544
reward_mean: -115.91083099906628
reward_std: 3.7060333949960538
reward_max: -111.6358543417367
reward_min: -121.37605042016803
queue_len: 0.07686394628585297
wait_time: 0.7352753877855297
delay_time: 4.849635909565549
pressure: 0.9277188328912466
total_envstep_count: 407856
total_train_sample_count: 407856
total_episode_count: 3516
total_duration: 24739.355584018052
[2024-12-27 18:54:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.574657548335967
avg_train_sample_per_sec: 16.574657548335967
avg_episode_per_sec: 0.14288497886496523
collect_time: 41.99181780801714
reward_mean: -116.00058356676006
reward_std: 6.420024419804703
reward_max: -106.74369747899163
reward_min: -127.33193277310926
queue_len: 0.07692346390368705
wait_time: 0.739645095438706
delay_time: 4.744118829401277
pressure: 0.9454022988505747
total_envstep_count: 408552
total_train_sample_count: 408552
total_episode_count: 3522
total_duration: 24781.34740182607
[2024-12-27 18:55:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.32499687812172
avg_train_sample_per_sec: 16.32499687812172
avg_episode_per_sec: 0.14073273170794587
collect_time: 42.63400509024039
reward_mean: -117.97152194211016
reward_std: 3.8606052754301996
reward_max: -111.44537815126047
reward_min: -123.92436974789918
queue_len: 0.07823045221625344
wait_time: 0.7585139604029058
delay_time: 4.7464323325745434
pressure: 0.951923076923077
total_envstep_count: 409248
total_train_sample_count: 409248
total_episode_count: 3528
total_duration: 24823.98140691631
[2024-12-27 18:55:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.466533423555884
avg_train_sample_per_sec: 16.466533423555884
avg_episode_per_sec: 0.14195287434099899
collect_time: 42.2675484935008
reward_mean: -114.76528944911301
reward_std: 1.6581715002706416
reward_max: -111.61484593837535
reward_min: -116.74089635854342
queue_len: 0.07610430334821817
wait_time: 0.7288764312090882
delay_time: 4.724523629719818
pressure: 0.926945181255526
total_envstep_count: 409944
total_train_sample_count: 409944
total_episode_count: 3534
total_duration: 24866.248955409814
[2024-12-27 18:56:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.4776725571036
avg_train_sample_per_sec: 16.4776725571036
avg_episode_per_sec: 0.14204890135434137
collect_time: 42.23897504869104
reward_mean: -116.08555088702148
reward_std: 5.192137616224753
reward_max: -107.64285714285718
reward_min: -124.28851540616252
queue_len: 0.07697980828051822
wait_time: 0.7378434685103042
delay_time: 4.775574257179439
pressure: 0.9354553492484529
total_envstep_count: 410640
total_train_sample_count: 410640
total_episode_count: 3540
total_duration: 24908.487930458505
[2024-12-27 18:57:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.418477176073427
avg_train_sample_per_sec: 16.418477176073427
avg_episode_per_sec: 0.14153859634546057
collect_time: 42.39126397265866
reward_mean: -112.29458450046688
reward_std: 2.6540340218499083
reward_max: -109.63865546218486
reward_min: -117.15616246498602
queue_len: 0.07446590484115838
wait_time: 0.7125258812632037
delay_time: 4.636022318668373
pressure: 0.9049513704686118
total_envstep_count: 411336
total_train_sample_count: 411336
total_episode_count: 3546
total_duration: 24950.879194431163
[2024-12-27 18:57:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.25767390175617
avg_train_sample_per_sec: 16.25767390175617
avg_episode_per_sec: 0.14015236122203598
collect_time: 42.810552370890974
reward_mean: -117.73109243697478
reward_std: 4.935482537320569
reward_max: -111.6673669467787
reward_min: -126.94187675070029
queue_len: 0.07807101620489043
wait_time: 0.7537470558515181
delay_time: 4.853654081497191
pressure: 0.9559018567639256
total_envstep_count: 412032
total_train_sample_count: 412032
total_episode_count: 3552
total_duration: 24993.689746802054
[2024-12-27 18:58:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.52159682768638
avg_train_sample_per_sec: 16.52159682768638
avg_episode_per_sec: 0.14242755885936534
collect_time: 42.12667862913013
reward_mean: -118.33169934640523
reward_std: 2.3350623295076756
reward_max: -114.36414565826327
reward_min: -120.61974789915965
queue_len: 0.07846929664880982
wait_time: 0.7551038872666661
delay_time: 4.885415251089035
pressure: 0.9612068965517241
total_envstep_count: 412728
total_train_sample_count: 412728
total_episode_count: 3558
total_duration: 25035.816425431185
[2024-12-27 18:59:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.62810668019993
avg_train_sample_per_sec: 16.62810668019993
avg_episode_per_sec: 0.14334574724310284
collect_time: 41.856839950922875
reward_mean: -116.01062091503269
reward_std: 1.9788829509817163
reward_max: -113.7563025210084
reward_min: -119.37254901960783
queue_len: 0.0769301199701808
wait_time: 0.7382149698960044
delay_time: 4.715376588294846
pressure: 0.9423076923076922
total_envstep_count: 413424
total_train_sample_count: 413424
total_episode_count: 3564
total_duration: 25077.67326538211
[2024-12-27 19:00:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61545028855366
avg_train_sample_per_sec: 16.61545028855366
avg_episode_per_sec: 0.14323664041856604
collect_time: 41.88872332153842
reward_mean: -115.88188608776842
reward_std: 2.490134526365981
reward_max: -112.52801120448176
reward_min: -119.43487394957984
queue_len: 0.0768447520475918
wait_time: 0.7438311420943267
delay_time: 4.7382297208154
pressure: 0.9387709991158267
total_envstep_count: 414120
total_train_sample_count: 414120
total_episode_count: 3570
total_duration: 25119.56198870365
[2024-12-27 19:00:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.670833527775404
avg_train_sample_per_sec: 16.670833527775404
avg_episode_per_sec: 0.14371408213599485
collect_time: 41.74956212239712
reward_mean: -114.27824463118579
reward_std: 4.592097797084344
reward_max: -107.51050420168062
reward_min: -122.11484593837538
queue_len: 0.07578132933102506
wait_time: 0.732839344844923
delay_time: 4.694161872129396
pressure: 0.9250663129973474
total_envstep_count: 414816
total_train_sample_count: 414816
total_episode_count: 3576
total_duration: 25161.311550826045
[2024-12-27 19:01:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.292288222985423
avg_train_sample_per_sec: 16.292288222985423
avg_episode_per_sec: 0.14045076054297778
collect_time: 42.719597792167214
reward_mean: -116.73646125116711
reward_std: 2.0894215690091937
reward_max: -113.61134453781511
reward_min: -118.69397759103641
queue_len: 0.0774114464530286
wait_time: 0.7404617019221482
delay_time: 4.790683448742589
pressure: 0.9513704686118479
total_envstep_count: 415512
total_train_sample_count: 415512
total_episode_count: 3582
total_duration: 25204.03114861821
[2024-12-27 19:02:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.727639639346137
avg_train_sample_per_sec: 16.727639639346137
avg_episode_per_sec: 0.14420378999436326
collect_time: 41.607782987080526
reward_mean: -117.03221288515407
reward_std: 2.455691117973328
reward_max: -114.12815126050424
reward_min: -120.44957983193274
queue_len: 0.07760756822622948
wait_time: 0.7430134520651762
delay_time: 4.79158458821173
pressure: 0.9476127320954907
total_envstep_count: 416208
total_train_sample_count: 416208
total_episode_count: 3588
total_duration: 25245.638931605292
[2024-12-27 19:02:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73581229810427
avg_train_sample_per_sec: 16.73581229810427
avg_episode_per_sec: 0.14427424394917474
collect_time: 41.5874645103924
reward_mean: -114.33333333333333
reward_std: 4.871895293758315
reward_max: -107.42997198879553
reward_min: -122.74019607843135
queue_len: 0.07581786030061892
wait_time: 0.722558663164647
delay_time: 4.750309504267288
pressure: 0.9367816091954023
total_envstep_count: 416904
total_train_sample_count: 416904
total_episode_count: 3594
total_duration: 25287.226396115686
[2024-12-27 19:03:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.867265148544938
avg_train_sample_per_sec: 16.867265148544938
avg_episode_per_sec: 0.14540745817711154
collect_time: 41.2633579818979
reward_mean: -114.90359477124183
reward_std: 2.3616307889198365
reward_max: -111.15476190476191
reward_min: -117.14705882352942
queue_len: 0.07619601775281289
wait_time: 0.7318681783058051
delay_time: 4.640071071134512
pressure: 0.93578691423519
total_envstep_count: 417600
total_train_sample_count: 417600
total_episode_count: 3600
total_duration: 25328.489754097583
[2024-12-27 19:04:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.950354189155572
avg_train_sample_per_sec: 16.950354189155572
avg_episode_per_sec: 0.1461237430099618
collect_time: 41.06108888540418
reward_mean: -114.22385620915036
reward_std: 3.040732196037259
reward_max: -109.93067226890759
reward_min: -119.94607843137256
queue_len: 0.07574526273816336
wait_time: 0.7277972970797513
delay_time: 4.641865070956203
pressure: 0.9291556145004422
total_envstep_count: 418296
total_train_sample_count: 418296
total_episode_count: 3606
total_duration: 25369.550842982986
[2024-12-27 19:05:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.658944222376523
avg_train_sample_per_sec: 16.658944222376523
avg_episode_per_sec: 0.14361158812393554
collect_time: 41.77935832602904
reward_mean: -114.76762371615312
reward_std: 2.0788967352599195
reward_max: -111.359243697479
reward_min: -117.81092436974787
queue_len: 0.07610585127065857
wait_time: 0.729212717359269
delay_time: 4.720034567330188
pressure: 0.9354553492484525
total_envstep_count: 418992
total_train_sample_count: 418992
total_episode_count: 3612
total_duration: 25411.330201309014
[2024-12-27 19:05:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.949949397549602
avg_train_sample_per_sec: 16.949949397549602
avg_episode_per_sec: 0.14612025342715174
collect_time: 41.06206948916428
reward_mean: -115.98611111111109
reward_std: 5.072794481922284
reward_max: -106.95728291316523
reward_min: -122.11834733893552
queue_len: 0.07691386678455643
wait_time: 0.7388869230273896
delay_time: 4.750975148761271
pressure: 0.9441865605658709
total_envstep_count: 419688
total_train_sample_count: 419688
total_episode_count: 3618
total_duration: 25452.39227079818
[2024-12-27 19:06:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75712110546053
avg_train_sample_per_sec: 16.75712110546053
avg_episode_per_sec: 0.14445794056431494
collect_time: 41.534580768363554
reward_mean: -113.74439775910362
reward_std: 3.044959091221037
reward_max: -108.8410364145658
reward_min: -118.65616246498598
queue_len: 0.07542731946890162
wait_time: 0.7166120095252954
delay_time: 4.738594118226839
pressure: 0.9059460654288242
total_envstep_count: 420384
total_train_sample_count: 420384
total_episode_count: 3624
total_duration: 25493.926851566543
[2024-12-27 19:07:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.9311716659597
avg_train_sample_per_sec: 16.9311716659597
avg_episode_per_sec: 0.14595837643068704
collect_time: 41.107609900342304
reward_mean: -119.50373482726422
reward_std: 4.3671943415012
reward_max: -113.35574229691876
reward_min: -127.27521008403357
queue_len: 0.07924650850614338
wait_time: 0.7622801330965633
delay_time: 4.888661308258922
pressure: 0.9659593280282935
total_envstep_count: 421080
total_train_sample_count: 421080
total_episode_count: 3630
total_duration: 25535.034461466887
[2024-12-27 19:07:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.116063727976233
avg_train_sample_per_sec: 17.116063727976233
avg_episode_per_sec: 0.14755227351703648
collect_time: 40.663555070923636
reward_mean: -113.96895424836602
reward_std: 4.270205412477935
reward_max: -107.69117647058825
reward_min: -120.74859943977589
queue_len: 0.07557622960766976
wait_time: 0.7261027863842267
delay_time: 4.665334885258779
pressure: 0.9302608311229
total_envstep_count: 421776
total_train_sample_count: 421776
total_episode_count: 3636
total_duration: 25575.69801653781
[2024-12-27 19:08:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.939793731420014
avg_train_sample_per_sec: 16.939793731420014
avg_episode_per_sec: 0.146032704581207
collect_time: 41.08668682954833
reward_mean: -115.13433706816058
reward_std: 1.8397679536819027
reward_max: -112.80882352941177
reward_min: -118.64285714285714
queue_len: 0.07634902988604814
wait_time: 0.7356898440189518
delay_time: 4.636010078444037
pressure: 0.937444739168877
total_envstep_count: 422472
total_train_sample_count: 422472
total_episode_count: 3642
total_duration: 25616.78470336736
[2024-12-27 19:09:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.94973408090409
avg_train_sample_per_sec: 16.94973408090409
avg_episode_per_sec: 0.1461183972491732
collect_time: 41.06259111074359
reward_mean: -117.14250700280111
reward_std: 3.576024206535626
reward_max: -111.10154061624651
reward_min: -122.4915966386555
queue_len: 0.0776807075615392
wait_time: 0.7527344049909974
delay_time: 4.806076099804531
pressure: 0.9529177718832891
total_envstep_count: 423168
total_train_sample_count: 423168
total_episode_count: 3648
total_duration: 25657.847294478102
[2024-12-27 19:09:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.057185378461078
avg_train_sample_per_sec: 17.057185378461078
avg_episode_per_sec: 0.14704470153845758
collect_time: 40.80391838145069
reward_mean: -115.15476190476191
reward_std: 3.319045144711806
reward_max: -109.20938375350138
reward_min: -119.13305322128848
queue_len: 0.07636257420740179
wait_time: 0.7371334364868849
delay_time: 4.790474336244073
pressure: 0.9332449160035368
total_envstep_count: 423864
total_train_sample_count: 423864
total_episode_count: 3654
total_duration: 25698.651212859553
[2024-12-27 19:10:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.227815594367854
avg_train_sample_per_sec: 17.227815594367854
avg_episode_per_sec: 0.14851565167558495
collect_time: 40.399782328035684
reward_mean: -114.34733893557421
reward_std: 1.3020789913932358
reward_max: -112.53431372549022
reward_min: -116.57422969187675
queue_len: 0.07582714783526141
wait_time: 0.7274839201816888
delay_time: 4.679057846312044
pressure: 0.927497789566755
total_envstep_count: 424560
total_train_sample_count: 424560
total_episode_count: 3660
total_duration: 25739.05099518759
[2024-12-27 19:11:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.240691066870234
avg_train_sample_per_sec: 17.240691066870234
avg_episode_per_sec: 0.14862664712819168
collect_time: 40.36961147905699
reward_mean: -115.00245098039211
reward_std: 4.1688500025089
reward_max: -107.11904761904756
reward_min: -121.00700280112041
queue_len: 0.07626157226816453
wait_time: 0.7306121166415283
delay_time: 4.690640956885139
pressure: 0.935344827586207
total_envstep_count: 425256
total_train_sample_count: 425256
total_episode_count: 3666
total_duration: 25779.42060666665
[2024-12-27 19:11:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.023397035381798
avg_train_sample_per_sec: 17.023397035381798
avg_episode_per_sec: 0.14675342271880862
collect_time: 40.88490672886372
reward_mean: -115.49673202614382
reward_std: 3.9419039263571674
reward_max: -108.92927170868352
reward_min: -119.18557422969191
queue_len: 0.07658934484492294
wait_time: 0.7345220139337787
delay_time: 4.792076262358635
pressure: 0.9316976127320955
total_envstep_count: 425952
total_train_sample_count: 425952
total_episode_count: 3672
total_duration: 25820.305513395513
[2024-12-27 19:12:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.302975148740618
avg_train_sample_per_sec: 17.302975148740618
avg_episode_per_sec: 0.1491635788684536
collect_time: 40.22429634308628
reward_mean: -114.96370214752568
reward_std: 2.4429177583932002
reward_max: -111.11904761904759
reward_min: -118.40126050420169
queue_len: 0.07623587675565363
wait_time: 0.7331909554272639
delay_time: 4.693134251161707
pressure: 0.9339080459770116
total_envstep_count: 426648
total_train_sample_count: 426648
total_episode_count: 3678
total_duration: 25860.5298097386
[2024-12-27 19:13:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.341493541854874
avg_train_sample_per_sec: 17.341493541854874
avg_episode_per_sec: 0.14949563398150756
collect_time: 40.13495137083531
reward_mean: -113.24101307189541
reward_std: 4.826668220570867
reward_max: -106.70938375350133
reward_min: -120.34663865546217
queue_len: 0.07509350999462559
wait_time: 0.7284883670532757
delay_time: 4.580727606675956
pressure: 0.9260610079575597
total_envstep_count: 427344
total_train_sample_count: 427344
total_episode_count: 3684
total_duration: 25900.664761109434
[2024-12-27 19:14:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51282265542844
avg_train_sample_per_sec: 17.51282265542844
avg_episode_per_sec: 0.15097260909852103
collect_time: 39.74230846129543
reward_mean: -113.91141456582632
reward_std: 1.6292218476514742
reward_max: -111.97899159663866
reward_min: -116.73249299719889
queue_len: 0.07553807331951348
wait_time: 0.7234890419474599
delay_time: 4.6921656159863
pressure: 0.9326923076923078
total_envstep_count: 428040
total_train_sample_count: 428040
total_episode_count: 3690
total_duration: 25940.40706957073
[2024-12-27 19:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.22481873576918
avg_train_sample_per_sec: 17.22481873576918
avg_episode_per_sec: 0.14848981668766534
collect_time: 40.406811280671505
reward_mean: -115.59722222222223
reward_std: 4.032156077026356
reward_max: -110.1232492997199
reward_min: -121.93487394957982
queue_len: 0.0766559829059829
wait_time: 0.7288775921509187
delay_time: 4.750188724711127
pressure: 0.9330238726790451
total_envstep_count: 428736
total_train_sample_count: 428736
total_episode_count: 3696
total_duration: 25980.8138808514
[2024-12-27 19:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.235690045513042
avg_train_sample_per_sec: 17.235690045513042
avg_episode_per_sec: 0.14858353487511242
collect_time: 40.38132492300123
reward_mean: -115.32574696545286
reward_std: 2.758533269421751
reward_max: -112.62955182072828
reward_min: -119.1547619047619
queue_len: 0.07647595952616237
wait_time: 0.7317330446767564
delay_time: 4.77746035735063
pressure: 0.9335764809902741
total_envstep_count: 429432
total_train_sample_count: 429432
total_episode_count: 3702
total_duration: 26021.195205774402
[2024-12-27 19:16:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.298314174223652
avg_train_sample_per_sec: 17.298314174223652
avg_episode_per_sec: 0.14912339805365216
collect_time: 40.23513464896567
reward_mean: -115.81746031746029
reward_std: 2.9681881395780527
reward_max: -112.33823529411761
reward_min: -121.22198879551817
queue_len: 0.07680202938823627
wait_time: 0.7400319986526883
delay_time: 4.715160411187645
pressure: 0.9442970822281168
total_envstep_count: 430128
total_train_sample_count: 430128
total_episode_count: 3708
total_duration: 26061.43034042337
[2024-12-27 19:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.967260745597624
avg_train_sample_per_sec: 16.967260745597624
avg_episode_per_sec: 0.1462694891861864
collect_time: 41.02017470207065
reward_mean: -115.7608543417367
reward_std: 2.024412173735119
reward_max: -113.93347338935574
reward_min: -119.44117647058827
queue_len: 0.07676449226905617
wait_time: 0.7431822530073037
delay_time: 4.783701779960812
pressure: 0.9468390804597702
total_envstep_count: 430824
total_train_sample_count: 430824
total_episode_count: 3714
total_duration: 26102.450515125438
[2024-12-27 19:17:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.594101498515663
avg_train_sample_per_sec: 17.594101498515663
avg_episode_per_sec: 0.15167328878030742
collect_time: 39.55871233655885
reward_mean: -114.10574229691879
reward_std: 2.810935128058213
reward_max: -108.38445378151263
reward_min: -117.50700280112048
queue_len: 0.07566693786267824
wait_time: 0.7295547308224792
delay_time: 4.715952845223876
pressure: 0.9273872679045092
total_envstep_count: 431520
total_train_sample_count: 431520
total_episode_count: 3720
total_duration: 26142.009227461996
[2024-12-27 19:18:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.10480319382052
avg_train_sample_per_sec: 17.10480319382052
avg_episode_per_sec: 0.14745519994672862
collect_time: 40.69032494050823
reward_mean: -116.21125116713353
reward_std: 3.1860594336114563
reward_max: -113.46288515406164
reward_min: -122.42016806722691
queue_len: 0.07706316390393471
wait_time: 0.7404579869082912
delay_time: 4.785496832559446
pressure: 0.9463969938107869
total_envstep_count: 432216
total_train_sample_count: 432216
total_episode_count: 3726
total_duration: 26182.699552402504
[2024-12-27 19:18:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.02217581982138
avg_train_sample_per_sec: 17.02217581982138
avg_episode_per_sec: 0.1467428949984602
collect_time: 40.88783991935664
reward_mean: -113.63783846872082
reward_std: 2.504388963893972
reward_max: -111.35084033613445
reward_min: -118.91806722689073
queue_len: 0.07535665680949656
wait_time: 0.7236677495932061
delay_time: 4.656247360250677
pressure: 0.925950486295314
total_envstep_count: 432912
total_train_sample_count: 432912
total_episode_count: 3732
total_duration: 26223.58739232186
[2024-12-27 19:19:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.01427558911992
avg_train_sample_per_sec: 17.01427558911992
avg_episode_per_sec: 0.1466747895613786
collect_time: 40.90682535112277
reward_mean: -113.9660364145658
reward_std: 3.650541366987265
reward_max: -109.34313725490196
reward_min: -119.55882352941175
queue_len: 0.07557429470461924
wait_time: 0.7225891572367232
delay_time: 4.687431694034325
pressure: 0.9312555260831124
total_envstep_count: 433608
total_train_sample_count: 433608
total_episode_count: 3738
total_duration: 26264.494217672982
[2024-12-27 19:20:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.247723688135455
avg_train_sample_per_sec: 17.247723688135455
avg_episode_per_sec: 0.14868727317358152
collect_time: 40.353151093136525
reward_mean: -117.91491596638654
reward_std: 2.780536494762172
reward_max: -114.89775910364145
reward_min: -123.31932773109241
queue_len: 0.07819291509707331
wait_time: 0.751164502051926
delay_time: 4.789838895398228
pressure: 0.9567860300618921
total_envstep_count: 434304
total_train_sample_count: 434304
total_episode_count: 3744
total_duration: 26304.847368766117
[2024-12-27 19:20:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.98183428813717
avg_train_sample_per_sec: 16.98183428813717
avg_episode_per_sec: 0.14639512317359626
collect_time: 40.98497183465027
reward_mean: -116.81162464985994
reward_std: 3.574952651573112
reward_max: -112.16176470588232
reward_min: -122.78151260504202
queue_len: 0.07746128955561003
wait_time: 0.7455855573882957
delay_time: 4.736933390812268
pressure: 0.9434129089301503
total_envstep_count: 435000
total_train_sample_count: 435000
total_episode_count: 3750
total_duration: 26345.832340600766
[2024-12-27 19:21:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.185102804849343
avg_train_sample_per_sec: 17.185102804849343
avg_episode_per_sec: 0.14814743797283916
collect_time: 40.500194145105766
reward_mean: -115.46615312791785
reward_std: 2.758252440738031
reward_max: -110.44607843137256
reward_min: -118.28851540616247
queue_len: 0.07656906706095347
wait_time: 0.7322323270599133
delay_time: 4.721945002113954
pressure: 0.9378868258178604
total_envstep_count: 435696
total_train_sample_count: 435696
total_episode_count: 3756
total_duration: 26386.33253474587
[2024-12-27 19:22:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17892058253971
avg_train_sample_per_sec: 17.17892058253971
avg_episode_per_sec: 0.14809414295292853
collect_time: 40.51476905408129
reward_mean: -114.92448646125116
reward_std: 2.532779456594543
reward_max: -111.68907563025208
reward_min: -119.16246498599439
queue_len: 0.07620987165865462
wait_time: 0.7250038388476523
delay_time: 4.728354008649004
pressure: 0.9278293545534925
total_envstep_count: 436392
total_train_sample_count: 436392
total_episode_count: 3762
total_duration: 26426.84730379995
[2024-12-27 19:22:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.313128543119486
avg_train_sample_per_sec: 17.313128543119486
avg_episode_per_sec: 0.1492511081303404
collect_time: 40.20070654859208
reward_mean: -114.19409430438843
reward_std: 2.8825630917473495
reward_max: -111.22128851540616
reward_min: -119.61624649859944
queue_len: 0.07572552672704802
wait_time: 0.7263771556367905
delay_time: 4.703985832733981
pressure: 0.9260610079575596
total_envstep_count: 437088
total_train_sample_count: 437088
total_episode_count: 3768
total_duration: 26467.048010348542
[2024-12-27 19:23:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.191783884663216
avg_train_sample_per_sec: 17.191783884663216
avg_episode_per_sec: 0.14820503348847602
collect_time: 40.48445493901894
reward_mean: -114.0675770308123
reward_std: 2.6835239103500643
reward_max: -110.58193277310923
reward_min: -117.84173669467783
queue_len: 0.07564162933077741
wait_time: 0.7214621149078554
delay_time: 4.654791256355489
pressure: 0.9189876215738285
total_envstep_count: 437784
total_train_sample_count: 437784
total_episode_count: 3774
total_duration: 26507.53246528756
[2024-12-27 19:24:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18742022731481
avg_train_sample_per_sec: 17.18742022731481
avg_episode_per_sec: 0.14816741575271386
collect_time: 40.494733403556054
reward_mean: -115.62815126050418
reward_std: 3.8841669636943275
reward_max: -110.23669467787111
reward_min: -121.35574229691876
queue_len: 0.07667649287831843
wait_time: 0.7331597647900893
delay_time: 4.674457753072846
pressure: 0.936450044208665
total_envstep_count: 438480
total_train_sample_count: 438480
total_episode_count: 3780
total_duration: 26548.027198691118
[2024-12-27 19:24:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.974112779296934
avg_train_sample_per_sec: 16.974112779296934
avg_episode_per_sec: 0.14632855844221496
collect_time: 41.003615861967205
reward_mean: -114.812558356676
reward_std: 2.9602699260718617
reward_max: -111.1988795518207
reward_min: -120.10294117647062
queue_len: 0.07613564877763661
wait_time: 0.729123866611189
delay_time: 4.645413344664552
pressure: 0.9350132625994695
total_envstep_count: 439176
total_train_sample_count: 439176
total_episode_count: 3786
total_duration: 26589.030814553083
[2024-12-27 19:25:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.956782255512984
avg_train_sample_per_sec: 16.956782255512984
avg_episode_per_sec: 0.14617915737511192
collect_time: 41.045523231491444
reward_mean: -115.33683473389357
reward_std: 3.116536799705335
reward_max: -111.58613445378153
reward_min: -119.85224089635857
queue_len: 0.07648331215775435
wait_time: 0.731096384177013
delay_time: 4.734708443572685
pressure: 0.9366710875331564
total_envstep_count: 439872
total_train_sample_count: 439872
total_episode_count: 3792
total_duration: 26630.076337784576
[2024-12-27 19:26:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.859607091278423
avg_train_sample_per_sec: 16.859607091278423
avg_episode_per_sec: 0.14534144044205538
collect_time: 41.28210083614849
reward_mean: -117.3619281045752
reward_std: 2.881132109841922
reward_max: -114.51750700280108
reward_min: -122.60714285714286
queue_len: 0.07782621227093844
wait_time: 0.752636808481129
delay_time: 4.841552048821774
pressure: 0.9486074270557028
total_envstep_count: 440568
total_train_sample_count: 440568
total_episode_count: 3798
total_duration: 26671.358438620726
[2024-12-27 19:27:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85734282915902
avg_train_sample_per_sec: 16.85734282915902
avg_episode_per_sec: 0.14532192094102606
collect_time: 41.287645808335384
reward_mean: -113.79119981325864
reward_std: 3.6745378721536506
reward_max: -110.79831932773106
reward_min: -121.66666666666669
queue_len: 0.07545835531383199
wait_time: 0.7185538008306772
delay_time: 4.635512399526486
pressure: 0.9224137931034483
total_envstep_count: 441264
total_train_sample_count: 441264
total_episode_count: 3804
total_duration: 26712.64608442906
[2024-12-27 19:27:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.798534247949636
avg_train_sample_per_sec: 16.798534247949636
avg_episode_per_sec: 0.14481495041335893
collect_time: 41.43218626856989
reward_mean: -115.07714752567693
reward_std: 6.0725961906000085
reward_max: -106.50420168067227
reward_min: -125.65826330532217
queue_len: 0.07631110578625792
wait_time: 0.7321528412425978
delay_time: 4.752734480867002
pressure: 0.9377763041556144
total_envstep_count: 441960
total_train_sample_count: 441960
total_episode_count: 3810
total_duration: 26754.078270697628
[2024-12-27 19:28:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.272413268137118
avg_train_sample_per_sec: 16.272413268137118
avg_episode_per_sec: 0.14027942472531996
collect_time: 42.77177506073006
reward_mean: -112.85189075630251
reward_std: 4.553004689625681
reward_max: -109.33123249299722
reward_min: -122.86974789915968
queue_len: 0.07483547132380804
wait_time: 0.714647928136772
delay_time: 4.69560078223181
pressure: 0.9084880636604775
total_envstep_count: 442656
total_train_sample_count: 442656
total_episode_count: 3816
total_duration: 26796.850045758358
[2024-12-27 19:29:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 15.994688502670762
avg_train_sample_per_sec: 15.994688502670762
avg_episode_per_sec: 0.137885245712679
collect_time: 43.51444542879239
reward_mean: -117.84675536881421
reward_std: 3.494750417170492
reward_max: -113.57072829131653
reward_min: -123.86624649859944
queue_len: 0.07814771576181313
wait_time: 0.7568833789041699
delay_time: 4.8281189644581
pressure: 0.9528072502210434
total_envstep_count: 443352
total_train_sample_count: 443352
total_episode_count: 3822
total_duration: 26840.36449118715
[2024-12-27 19:29:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.817621256939276
avg_train_sample_per_sec: 16.817621256939276
avg_episode_per_sec: 0.14497949359430412
collect_time: 41.3851631789375
reward_mean: -114.76423902894493
reward_std: 2.4498555063929595
reward_max: -111.72478991596638
reward_min: -118.04551820728288
queue_len: 0.07610360678311998
wait_time: 0.7305156810734904
delay_time: 4.735691583443949
pressure: 0.924182139699381
total_envstep_count: 444048
total_train_sample_count: 444048
total_episode_count: 3828
total_duration: 26881.749654366085
[2024-12-27 19:30:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.167828953837056
avg_train_sample_per_sec: 17.167828953837056
avg_episode_per_sec: 0.14799852546411255
collect_time: 40.5409444532264
reward_mean: -114.11356209150328
reward_std: 3.7849391704780797
reward_max: -106.3795518207283
reward_min: -118.5749299719888
queue_len: 0.07567212340285363
wait_time: 0.7244865231680647
delay_time: 4.623600009002451
pressure: 0.9340185676392573
total_envstep_count: 444744
total_train_sample_count: 444744
total_episode_count: 3834
total_duration: 26922.290598819312
[2024-12-27 19:31:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.031968207584896
avg_train_sample_per_sec: 17.031968207584896
avg_episode_per_sec: 0.14682731213435254
collect_time: 40.864331797545766
reward_mean: -115.74183006535948
reward_std: 1.8905400966862702
reward_max: -112.98179271708685
reward_min: -118.8977591036414
queue_len: 0.07675187670116675
wait_time: 0.7375693314461063
delay_time: 4.689835695231887
pressure: 0.9404288240495138
total_envstep_count: 445440
total_train_sample_count: 445440
total_episode_count: 3840
total_duration: 26963.15493061686
[2024-12-27 19:32:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.076503105514945
avg_train_sample_per_sec: 17.076503105514945
avg_episode_per_sec: 0.1472112336682323
collect_time: 40.757759109077966
reward_mean: -116.93650793650794
reward_std: 2.3834072334972993
reward_max: -113.0448179271709
reward_min: -119.94467787114843
queue_len: 0.07754410340617238
wait_time: 0.747311723097727
delay_time: 4.72660062320876
pressure: 0.9577807250221043
total_envstep_count: 446136
total_train_sample_count: 446136
total_episode_count: 3846
total_duration: 27003.912689725938
[2024-12-27 19:32:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90894818789892
avg_train_sample_per_sec: 16.90894818789892
avg_episode_per_sec: 0.14576679472326656
collect_time: 41.16163774740881
reward_mean: -112.70681605975723
reward_std: 3.705324959922726
reward_max: -107.2331932773109
reward_min: -117.43977591036409
queue_len: 0.07473926794413609
wait_time: 0.7131540281895251
delay_time: 4.577332541218372
pressure: 0.9145667550839964
total_envstep_count: 446832
total_train_sample_count: 446832
total_episode_count: 3852
total_duration: 27045.074327473347
[2024-12-27 19:33:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.253883222388822
avg_train_sample_per_sec: 17.253883222388822
avg_episode_per_sec: 0.1487403726068002
collect_time: 40.33874525688588
reward_mean: -113.00641923436042
reward_std: 3.4578244381234238
reward_max: -106.68837535014005
reward_min: -117.32703081232498
queue_len: 0.07493794378936368
wait_time: 0.7203415738532373
delay_time: 4.623426363679055
pressure: 0.9154509283819628
total_envstep_count: 447528
total_train_sample_count: 447528
total_episode_count: 3858
total_duration: 27085.413072730233
[2024-12-27 19:34:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.886544148047303
avg_train_sample_per_sec: 16.886544148047303
avg_episode_per_sec: 0.14557365644868364
collect_time: 41.216248505203055
reward_mean: -115.71148459383751
reward_std: 3.8398823855559714
reward_max: -107.31372549019609
reward_min: -119.03361344537814
queue_len: 0.07673175370944132
wait_time: 0.7370096800877733
delay_time: 4.6896784515842596
pressure: 0.9402077807250221
total_envstep_count: 448224
total_train_sample_count: 448224
total_episode_count: 3864
total_duration: 27126.629321235436
[2024-12-27 19:34:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85065412485136
avg_train_sample_per_sec: 16.85065412485136
avg_episode_per_sec: 0.1452642596969945
collect_time: 41.30403454032912
reward_mean: -114.43779178338002
reward_std: 4.38730055157852
reward_max: -106.42717086834735
reward_min: -119.91806722689078
queue_len: 0.07588712982982761
wait_time: 0.7295798845621361
delay_time: 4.732008454630112
pressure: 0.9252873563218391
total_envstep_count: 448920
total_train_sample_count: 448920
total_episode_count: 3870
total_duration: 27167.933355775764
[2024-12-27 19:35:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.462873599463588
avg_train_sample_per_sec: 16.462873599463588
avg_episode_per_sec: 0.1419213241333068
collect_time: 42.27694489634409
reward_mean: -115.8734827264239
reward_std: 4.643283552436569
reward_max: -109.32282913165263
reward_min: -120.04061624649862
queue_len: 0.0768391795268063
wait_time: 0.7385148798688351
delay_time: 4.754178428235266
pressure: 0.9388815207780725
total_envstep_count: 449616
total_train_sample_count: 449616
total_episode_count: 3876
total_duration: 27210.210300672108
[2024-12-27 19:36:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.07003944593519
avg_train_sample_per_sec: 16.07003944593519
avg_episode_per_sec: 0.13853482280978613
collect_time: 43.310410179238765
reward_mean: -112.7359943977591
reward_std: 4.246968679559562
reward_max: -108.10224089635854
reward_min: -120.32422969187677
queue_len: 0.07475861697464131
wait_time: 0.714276581543316
delay_time: 4.584098917484654
pressure: 0.918656056587091
total_envstep_count: 450312
total_train_sample_count: 450312
total_episode_count: 3882
total_duration: 27253.520710851346
[2024-12-27 19:36:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7854364448484
avg_train_sample_per_sec: 16.7854364448484
avg_episode_per_sec: 0.14470203831765863
collect_time: 41.46451611710153
reward_mean: -114.56454248366013
reward_std: 4.263947780276767
reward_max: -108.66316526610642
reward_min: -119.77521008403362
queue_len: 0.07597118201834227
wait_time: 0.7262241435035554
delay_time: 4.6725018394218765
pressure: 0.9253978779840849
total_envstep_count: 451008
total_train_sample_count: 451008
total_episode_count: 3888
total_duration: 27294.98522696845
[2024-12-27 19:37:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.875722113906324
avg_train_sample_per_sec: 16.875722113906324
avg_episode_per_sec: 0.14548036305091658
collect_time: 41.24267959037237
reward_mean: -116.34243697478992
reward_std: 2.1470566156435953
reward_max: -112.84103641456586
reward_min: -119.92717086834735
queue_len: 0.07715015714508615
wait_time: 0.7375669321663237
delay_time: 4.748503553484968
pressure: 0.9420866489832007
total_envstep_count: 451704
total_train_sample_count: 451704
total_episode_count: 3894
total_duration: 27336.227906558823
[2024-12-27 19:38:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.870129353134512
avg_train_sample_per_sec: 16.870129353134512
avg_episode_per_sec: 0.14543214959598716
collect_time: 41.2563523035869
reward_mean: -115.15487861811391
reward_std: 2.2431540045705933
reward_max: -112.22829131652661
reward_min: -117.69887955182071
queue_len: 0.0763626516035238
wait_time: 0.734089447007804
delay_time: 4.751364423030158
pressure: 0.9259504862953137
total_envstep_count: 452400
total_train_sample_count: 452400
total_episode_count: 3900
total_duration: 27377.48425886241
[2024-12-27 19:39:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.026474971665547
avg_train_sample_per_sec: 17.026474971665547
avg_episode_per_sec: 0.14677995665228918
collect_time: 40.87751581923106
reward_mean: -111.8654295051354
reward_std: 2.502579323139612
reward_max: -108.65966386554622
reward_min: -116.09103641456582
queue_len: 0.07418131930048766
wait_time: 0.7080704187068285
delay_time: 4.5935686799593505
pressure: 0.9046198054818744
total_envstep_count: 453096
total_train_sample_count: 453096
total_episode_count: 3906
total_duration: 27418.361774681638
[2024-12-27 19:39:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.129183699721114
avg_train_sample_per_sec: 17.129183699721114
avg_episode_per_sec: 0.14766537672173374
collect_time: 40.632409121243285
reward_mean: -113.30847338935575
reward_std: 2.7186892080629557
reward_max: -109.19117647058823
reward_min: -118.38585434173669
queue_len: 0.07513824495315369
wait_time: 0.7172758360638686
delay_time: 4.647695948892154
pressure: 0.9218611847922192
total_envstep_count: 453792
total_train_sample_count: 453792
total_episode_count: 3912
total_duration: 27458.994183802883
[2024-12-27 19:40:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.846715098698855
avg_train_sample_per_sec: 16.846715098698855
avg_episode_per_sec: 0.14523030257499012
collect_time: 41.31369207126647
reward_mean: -111.05730625583567
reward_std: 3.17329276458993
reward_max: -106.36204481792714
reward_min: -116.43907563025206
queue_len: 0.07364542855161517
wait_time: 0.7006900793031624
delay_time: 4.545080104612416
pressure: 0.8944518125552609
total_envstep_count: 454488
total_train_sample_count: 454488
total_episode_count: 3918
total_duration: 27500.30787587415
[2024-12-27 19:41:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.13960078395477
avg_train_sample_per_sec: 17.13960078395477
avg_episode_per_sec: 0.14775517917202385
collect_time: 40.60771360856667
reward_mean: -112.70028011204482
reward_std: 2.002668079131624
reward_max: -109.67857142857144
reward_min: -115.82563025210082
queue_len: 0.07473493376130293
wait_time: 0.7181145778382088
delay_time: 4.516122574284778
pressure: 0.9119142351900974
total_envstep_count: 455184
total_train_sample_count: 455184
total_episode_count: 3924
total_duration: 27540.915589482716
[2024-12-27 19:41:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.018980705366516
avg_train_sample_per_sec: 17.018980705366516
avg_episode_per_sec: 0.14671535090833204
collect_time: 40.89551613279246
reward_mean: -115.20144724556489
reward_std: 2.5206902961801947
reward_max: -111.00910364145653
reward_min: -118.13235294117652
queue_len: 0.07639353265621013
wait_time: 0.7347728547652483
delay_time: 4.705134788221176
pressure: 0.9316976127320955
total_envstep_count: 455880
total_train_sample_count: 455880
total_episode_count: 3930
total_duration: 27581.81110561551
[2024-12-27 19:42:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08198721894046
avg_train_sample_per_sec: 17.08198721894046
avg_episode_per_sec: 0.14725851050810743
collect_time: 40.74467397026718
reward_mean: -114.91001400560224
reward_std: 3.4913789062217915
reward_max: -108.09453781512607
reward_min: -117.98319327731092
queue_len: 0.07620027453952403
wait_time: 0.7277589859993511
delay_time: 4.68354325025732
pressure: 0.9342396109637489
total_envstep_count: 456576
total_train_sample_count: 456576
total_episode_count: 3936
total_duration: 27622.55577958578
[2024-12-27 19:43:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89264816127885
avg_train_sample_per_sec: 16.89264816127885
avg_episode_per_sec: 0.14562627725240387
collect_time: 41.201355368033056
reward_mean: -116.8655462184874
reward_std: 5.676525748200655
reward_max: -110.46498599439775
reward_min: -128.42647058823533
queue_len: 0.07749704656398368
wait_time: 0.7418759612598357
delay_time: 4.744525520573059
pressure: 0.9563439434129091
total_envstep_count: 457272
total_train_sample_count: 457272
total_episode_count: 3942
total_duration: 27663.757134953812
[2024-12-27 19:43:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.966857648074626
avg_train_sample_per_sec: 16.966857648074626
avg_episode_per_sec: 0.14626601420753987
collect_time: 41.021149256767714
reward_mean: -114.09161998132585
reward_std: 2.045256491182025
reward_max: -110.84173669467783
reward_min: -117.80462184873952
queue_len: 0.07565757293191369
wait_time: 0.719602827868548
delay_time: 4.659941492377962
pressure: 0.9332449160035367
total_envstep_count: 457968
total_train_sample_count: 457968
total_episode_count: 3948
total_duration: 27704.77828421058
[2024-12-27 19:44:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.843458023537888
avg_train_sample_per_sec: 16.843458023537888
avg_episode_per_sec: 0.14520222434084387
collect_time: 41.321681036481635
reward_mean: -114.12126517273573
reward_std: 4.478911513641407
reward_max: -107.91596638655457
reward_min: -118.4887955182073
queue_len: 0.075677231546907
wait_time: 0.7140001999915793
delay_time: 4.729671453952759
pressure: 0.9182139699381078
total_envstep_count: 458664
total_train_sample_count: 458664
total_episode_count: 3954
total_duration: 27746.099965247064
[2024-12-27 19:45:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.978179506763958
avg_train_sample_per_sec: 16.978179506763958
avg_episode_per_sec: 0.14636361643762033
collect_time: 40.99379440079071
reward_mean: -113.79586834733891
reward_std: 3.6212420082944607
reward_max: -108.95448179271706
reward_min: -118.33263305322129
queue_len: 0.0754614511587128
wait_time: 0.7229434766833348
delay_time: 4.646399199492026
pressure: 0.912577365163572
total_envstep_count: 459360
total_train_sample_count: 459360
total_episode_count: 3960
total_duration: 27787.093759647854
[2024-12-27 19:45:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89036961183683
avg_train_sample_per_sec: 16.89036961183683
avg_episode_per_sec: 0.14560663458480028
collect_time: 41.20691352498531
reward_mean: -116.93942577030815
reward_std: 4.130020879043766
reward_max: -110.09873949579836
reward_min: -122.50770308123249
queue_len: 0.07754603830922291
wait_time: 0.737854071779021
delay_time: 4.7766662071014565
pressure: 0.9394341290893014
total_envstep_count: 460056
total_train_sample_count: 460056
total_episode_count: 3966
total_duration: 27828.30067317284
[2024-12-27 19:46:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.884694860965205
avg_train_sample_per_sec: 16.884694860965205
avg_episode_per_sec: 0.14555771431866557
collect_time: 41.22076269255206
reward_mean: -113.57516339869282
reward_std: 2.438666267016357
reward_max: -110.7100840336134
reward_min: -117.54341736694677
queue_len: 0.07531509509197136
wait_time: 0.7198244903620156
delay_time: 4.685516742284027
pressure: 0.9260610079575596
total_envstep_count: 460752
total_train_sample_count: 460752
total_episode_count: 3972
total_duration: 27869.52143586539
[2024-12-27 19:47:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.017611206207647
avg_train_sample_per_sec: 17.017611206207647
avg_episode_per_sec: 0.1467035448811004
collect_time: 40.89880721602775
reward_mean: -115.78734827264238
reward_std: 2.944542410229576
reward_max: -110.51960784313724
reward_min: -118.88305322128849
queue_len: 0.0767820611887549
wait_time: 0.7334619966465808
delay_time: 4.760356851367371
pressure: 0.9308134394341292
total_envstep_count: 461448
total_train_sample_count: 461448
total_episode_count: 3978
total_duration: 27910.42024308142
[2024-12-27 19:48:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.799034719386217
avg_train_sample_per_sec: 16.799034719386217
avg_episode_per_sec: 0.14481926482229499
collect_time: 41.430951934209084
reward_mean: -115.25478524743232
reward_std: 2.699669520087329
reward_max: -112.01890756302521
reward_min: -120.4579831932773
queue_len: 0.07642890268397368
wait_time: 0.7328018077257429
delay_time: 4.7067285992496055
pressure: 0.941865605658709
total_envstep_count: 462144
total_train_sample_count: 462144
total_episode_count: 3984
total_duration: 27951.851195015628
[2024-12-27 19:48:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.031908566400908
avg_train_sample_per_sec: 17.031908566400908
avg_episode_per_sec: 0.14682679798621473
collect_time: 40.86447489349545
reward_mean: -114.44129318394026
reward_std: 3.4467292091282173
reward_max: -109.46008403361347
reward_min: -119.43207282913166
queue_len: 0.07588945171348822
wait_time: 0.7266939379642219
delay_time: 4.661325899044898
pressure: 0.9287135278514588
total_envstep_count: 462840
total_train_sample_count: 462840
total_episode_count: 3990
total_duration: 27992.715669909125
[2024-12-27 19:49:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.245884384884114
avg_train_sample_per_sec: 17.245884384884114
avg_episode_per_sec: 0.14867141711106996
collect_time: 40.35745482615195
reward_mean: -113.49463118580768
reward_std: 2.3976444895721545
reward_max: -108.92436974789916
reward_min: -116.8004201680672
queue_len: 0.07526169176777696
wait_time: 0.7193610423833546
delay_time: 4.641580768549044
pressure: 0.9210875331564986
total_envstep_count: 463536
total_train_sample_count: 463536
total_episode_count: 3996
total_duration: 28033.073124735278
[2024-12-27 19:50:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97911524487729
avg_train_sample_per_sec: 16.97911524487729
avg_episode_per_sec: 0.14637168314549387
collect_time: 40.991535186734055
reward_mean: -115.77159197012138
reward_std: 2.8924563290865426
reward_max: -110.86414565826331
reward_min: -120.1911764705882
queue_len: 0.07677161271228208
wait_time: 0.7404217655231854
delay_time: 4.6917915426565
pressure: 0.9462864721485412
total_envstep_count: 464232
total_train_sample_count: 464232
total_episode_count: 4002
total_duration: 28074.064659922013
[2024-12-27 19:50:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.151616705039388
avg_train_sample_per_sec: 17.151616705039388
avg_episode_per_sec: 0.1478587646986154
collect_time: 40.57926503193751
reward_mean: -113.92553688141923
reward_std: 3.4394902375035694
reward_max: -107.7948179271709
reward_min: -117.97829131652662
queue_len: 0.075547438250278
wait_time: 0.7220113177897153
delay_time: 4.629982370703211
pressure: 0.9236295313881522
total_envstep_count: 464928
total_train_sample_count: 464928
total_episode_count: 4008
total_duration: 28114.64392495395
[2024-12-27 19:51:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.900874276646604
avg_train_sample_per_sec: 16.900874276646604
avg_episode_per_sec: 0.1456971920400569
collect_time: 41.18130154732429
reward_mean: -114.82796451914099
reward_std: 2.0580226830074966
reward_max: -111.87605042016808
reward_min: -116.99159663865545
queue_len: 0.07614586506574335
wait_time: 0.727321156137079
delay_time: 4.688787905138782
pressure: 0.9321396993810788
total_envstep_count: 465624
total_train_sample_count: 465624
total_episode_count: 4014
total_duration: 28155.825226501274
[2024-12-27 19:52:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.933543860052424
avg_train_sample_per_sec: 16.933543860052424
avg_episode_per_sec: 0.14597882637976226
collect_time: 41.101851198550314
reward_mean: -115.02824463118581
reward_std: 3.029143351675191
reward_max: -112.14915966386556
reward_min: -120.9327731092437
queue_len: 0.07627867681113117
wait_time: 0.7327467016868638
delay_time: 4.63031347027203
pressure: 0.9335764809902741
total_envstep_count: 466320
total_train_sample_count: 466320
total_episode_count: 4020
total_duration: 28196.927077699824
[2024-12-27 19:52:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.342888101463966
avg_train_sample_per_sec: 16.342888101463966
avg_episode_per_sec: 0.14088696639193074
collect_time: 42.587331913363194
reward_mean: -112.61636321195145
reward_std: 3.451806107047226
reward_max: -109.73879551820725
reward_min: -119.85224089635862
queue_len: 0.07467928594956992
wait_time: 0.7126903480224982
delay_time: 4.663780549490689
pressure: 0.9084880636604774
total_envstep_count: 467016
total_train_sample_count: 467016
total_episode_count: 4026
total_duration: 28239.514409613188
[2024-12-27 19:53:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.226851910001322
avg_train_sample_per_sec: 16.226851910001322
avg_episode_per_sec: 0.13988665439656311
collect_time: 42.89186860521138
reward_mean: -115.48914565826328
reward_std: 2.528025195496536
reward_max: -112.71078431372553
reward_min: -120.43277310924361
queue_len: 0.07658431409699157
wait_time: 0.7309578451185956
delay_time: 4.695261414768111
pressure: 0.9271662245800177
total_envstep_count: 467712
total_train_sample_count: 467712
total_episode_count: 4032
total_duration: 28282.4062782184
[2024-12-27 19:54:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53710984803717
avg_train_sample_per_sec: 16.53710984803717
avg_episode_per_sec: 0.14256129179342386
collect_time: 42.087160718873136
reward_mean: -113.25548552754435
reward_std: 4.007094800387301
reward_max: -107.72969187675068
reward_min: -120.21778711484595
queue_len: 0.07510310711375622
wait_time: 0.7135404670267754
delay_time: 4.625955835569209
pressure: 0.919871794871795
total_envstep_count: 468408
total_train_sample_count: 468408
total_episode_count: 4038
total_duration: 28324.493438937276
[2024-12-27 19:55:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.755795508331524
avg_train_sample_per_sec: 16.755795508331524
avg_episode_per_sec: 0.14444651300285796
collect_time: 41.53786668343656
reward_mean: -114.08660130718954
reward_std: 2.3352493031350736
reward_max: -109.41666666666667
reward_min: -116.32913165266109
queue_len: 0.0756542448986668
wait_time: 0.7200604711380573
delay_time: 4.627006706386136
pressure: 0.928713527851459
total_envstep_count: 469104
total_train_sample_count: 469104
total_episode_count: 4044
total_duration: 28366.031305620712
[2024-12-27 19:55:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.012127708594132
avg_train_sample_per_sec: 17.012127708594132
avg_episode_per_sec: 0.1466562733499494
collect_time: 40.91199007684365
reward_mean: -115.64577497665736
reward_std: 2.5097715977756856
reward_max: -111.72969187675066
reward_min: -120.16246498599443
queue_len: 0.0766881796927436
wait_time: 0.7341220307751746
delay_time: 4.68494551990592
pressure: 0.9289345711759506
total_envstep_count: 469800
total_train_sample_count: 469800
total_episode_count: 4050
total_duration: 28406.943295697554
[2024-12-27 19:56:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.813497373488396
avg_train_sample_per_sec: 16.813497373488396
avg_episode_per_sec: 0.14494394287489995
collect_time: 41.395313808860266
reward_mean: -113.1686507936508
reward_std: 3.5897282815806753
reward_max: -108.47128851540617
reward_min: -119.9607843137255
queue_len: 0.07504552439897268
wait_time: 0.7144734772777369
delay_time: 4.57605996112986
pressure: 0.9079354553492484
total_envstep_count: 470496
total_train_sample_count: 470496
total_episode_count: 4056
total_duration: 28448.338609506416
[2024-12-27 19:57:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.066453737156177
avg_train_sample_per_sec: 17.066453737156177
avg_episode_per_sec: 0.14712460118238085
collect_time: 40.781758807027714
reward_mean: -115.22875816993466
reward_std: 4.45164708591831
reward_max: -108.98949579831935
reward_min: -120.98529411764707
queue_len: 0.07641164334876303
wait_time: 0.7319527722671739
delay_time: 4.791022431455935
pressure: 0.9323607427055703
total_envstep_count: 471192
total_train_sample_count: 471192
total_episode_count: 4062
total_duration: 28489.120368313444
[2024-12-27 19:57:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.977040035453143
avg_train_sample_per_sec: 16.977040035453143
avg_episode_per_sec: 0.14635379340907884
collect_time: 40.99654583758674
reward_mean: -116.61799719887955
reward_std: 3.7746249077325658
reward_max: -112.5966386554622
reward_min: -123.63165266106448
queue_len: 0.07733288938917743
wait_time: 0.7410277771586088
delay_time: 4.761750800045434
pressure: 0.9484969053934571
total_envstep_count: 471888
total_train_sample_count: 471888
total_episode_count: 4068
total_duration: 28530.116914151033
[2024-12-27 19:58:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.215864538466143
avg_train_sample_per_sec: 17.215864538466143
avg_episode_per_sec: 0.14841262533160468
collect_time: 40.427827394023545
reward_mean: -114.77030812324931
reward_std: 1.4647277182338283
reward_max: -112.37394957983193
reward_min: -116.5735294117647
queue_len: 0.07610763138146505
wait_time: 0.7305015175831605
delay_time: 4.653602741009406
pressure: 0.9315870910698497
total_envstep_count: 472584
total_train_sample_count: 472584
total_episode_count: 4074
total_duration: 28570.544741545054
[2024-12-27 19:59:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.01550229552565
avg_train_sample_per_sec: 17.01550229552565
avg_episode_per_sec: 0.14668536461660042
collect_time: 40.90387623661385
reward_mean: -115.44817927170868
reward_std: 3.139759305557774
reward_max: -112.73529411764704
reward_min: -122.187675070028
queue_len: 0.07655714805816226
wait_time: 0.7307995700490627
delay_time: 4.642684191650633
pressure: 0.9430813439434128
total_envstep_count: 473280
total_train_sample_count: 473280
total_episode_count: 4080
total_duration: 28611.44861778167
[2024-12-27 19:59:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97047338770861
avg_train_sample_per_sec: 16.97047338770861
avg_episode_per_sec: 0.14629718437679834
collect_time: 41.012409265147525
reward_mean: -114.1421568627451
reward_std: 1.7553286624776174
reward_max: -111.48249299719883
reward_min: -116.69957983193281
queue_len: 0.07569108545274873
wait_time: 0.7250075538615093
delay_time: 4.644205254983879
pressure: 0.9268346595932803
total_envstep_count: 473976
total_train_sample_count: 473976
total_episode_count: 4086
total_duration: 28652.461027046815
[2024-12-27 20:00:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55145208386199
avg_train_sample_per_sec: 16.55145208386199
avg_episode_per_sec: 0.1426849317574309
collect_time: 42.0506911703907
reward_mean: -111.5326797385621
reward_std: 1.2092370025064652
reward_max: -109.52801120448181
reward_min: -113.18557422969192
queue_len: 0.07396066295660615
wait_time: 0.7110114713436214
delay_time: 4.591504842524542
pressure: 0.8930150309460655
total_envstep_count: 474672
total_train_sample_count: 474672
total_episode_count: 4092
total_duration: 28694.511718217207
[2024-12-27 20:01:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.619946240540138
avg_train_sample_per_sec: 16.619946240540138
avg_episode_per_sec: 0.143275398625346
collect_time: 41.87739177532866
reward_mean: -112.92296918767506
reward_std: 1.4436658500966773
reward_max: -110.02100840336135
reward_min: -114.29341736694678
queue_len: 0.07488260556211875
wait_time: 0.713691312068594
delay_time: 4.653177378549241
pressure: 0.9072723253757737
total_envstep_count: 475368
total_train_sample_count: 475368
total_episode_count: 4098
total_duration: 28736.389109992535
[2024-12-27 20:02:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.861698848121563
avg_train_sample_per_sec: 16.861698848121563
avg_episode_per_sec: 0.14535947282863415
collect_time: 41.276979637051
reward_mean: -113.9230859010271
reward_std: 3.9169788236646275
reward_max: -109.66666666666667
reward_min: -120.17787114845937
queue_len: 0.07554581293171557
wait_time: 0.7217969305317177
delay_time: 4.704429174470308
pressure: 0.9182139699381079
total_envstep_count: 476064
total_train_sample_count: 476064
total_episode_count: 4104
total_duration: 28777.666089629587
[2024-12-27 20:02:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.927660602405805
avg_train_sample_per_sec: 16.927660602405805
avg_episode_per_sec: 0.14592810864142935
collect_time: 41.11613626640663
reward_mean: -115.58228291316527
reward_std: 6.446660523235716
reward_max: -106.8326330532213
reward_min: -125.72058823529414
queue_len: 0.07664607620236423
wait_time: 0.7358653010275727
delay_time: 4.663018606627811
pressure: 0.9431918656056587
total_envstep_count: 476760
total_train_sample_count: 476760
total_episode_count: 4110
total_duration: 28818.782225895993
[2024-12-27 20:03:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.14338703454137
avg_train_sample_per_sec: 17.14338703454137
avg_episode_per_sec: 0.14778781926328766
collect_time: 40.59874507865125
reward_mean: -114.64087301587303
reward_std: 2.5315910718967443
reward_max: -110.60504201680675
reward_min: -117.62114845938376
queue_len: 0.07602179908214392
wait_time: 0.7254494857182484
delay_time: 4.70932757801977
pressure: 0.9195402298850573
total_envstep_count: 477456
total_train_sample_count: 477456
total_episode_count: 4116
total_duration: 28859.380970974646
[2024-12-27 20:04:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.868902173914726
avg_train_sample_per_sec: 16.868902173914726
avg_episode_per_sec: 0.14542157046478213
collect_time: 41.25935362149776
reward_mean: -114.37511671335203
reward_std: 2.857568876793496
reward_max: -109.9047619047619
reward_min: -118.7366946778712
queue_len: 0.0758455681123024
wait_time: 0.7273032776328922
delay_time: 4.652376779123489
pressure: 0.9311450044208666
total_envstep_count: 478152
total_train_sample_count: 478152
total_episode_count: 4122
total_duration: 28900.640324596145
[2024-12-27 20:04:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.043457302235886
avg_train_sample_per_sec: 17.043457302235886
avg_episode_per_sec: 0.14692635605375765
collect_time: 40.8367849115152
reward_mean: -112.21311858076564
reward_std: 2.3009799213914186
reward_max: -108.86484593837532
reward_min: -115.03571428571426
queue_len: 0.07441188234798783
wait_time: 0.7132102951702345
delay_time: 4.616077251256509
pressure: 0.9034040671971706
total_envstep_count: 478848
total_train_sample_count: 478848
total_episode_count: 4128
total_duration: 28941.47710950766
[2024-12-27 20:05:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.827197642892752
avg_train_sample_per_sec: 16.827197642892752
avg_episode_per_sec: 0.14506204864562716
collect_time: 41.361610814262185
reward_mean: -117.95915032679737
reward_std: 2.570090204569681
reward_max: -114.19537815126048
reward_min: -122.10574229691875
queue_len: 0.0782222482273192
wait_time: 0.7533980767373261
delay_time: 4.857001203019444
pressure: 0.9545755968169761
total_envstep_count: 479544
total_train_sample_count: 479544
total_episode_count: 4134
total_duration: 28982.838720321924
[2024-12-27 20:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.071520357435183
avg_train_sample_per_sec: 17.071520357435183
avg_episode_per_sec: 0.14716827894340676
collect_time: 40.76965527542309
reward_mean: -115.77287581699346
reward_std: 3.2609255724888766
reward_max: -111.9915966386555
reward_min: -121.48039215686273
queue_len: 0.07677246406962432
wait_time: 0.736861002137371
delay_time: 4.639716064388575
pressure: 0.9377763041556144
total_envstep_count: 480240
total_train_sample_count: 480240
total_episode_count: 4140
total_duration: 29023.60837559735
[2024-12-27 20:06:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.727542079619518
avg_train_sample_per_sec: 16.727542079619518
avg_episode_per_sec: 0.1442029489622372
collect_time: 41.608025655364614
reward_mean: -114.41853408029878
reward_std: 2.0909603762194497
reward_max: -112.20728291316523
reward_min: -117.05882352941178
queue_len: 0.07587435946969416
wait_time: 0.7248776057726362
delay_time: 4.676544960639438
pressure: 0.9332449160035367
total_envstep_count: 480936
total_train_sample_count: 480936
total_episode_count: 4146
total_duration: 29065.216401252714
[2024-12-27 20:07:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95809524079789
avg_train_sample_per_sec: 16.95809524079789
avg_episode_per_sec: 0.1461904762137749
collect_time: 41.04234527033195
reward_mean: -113.82166199813258
reward_std: 1.666244418156727
reward_max: -112.2640056022409
reward_min: -117.13515406162465
queue_len: 0.07547855570167943
wait_time: 0.7204909483687376
delay_time: 4.581977262142994
pressure: 0.9207559681697611
total_envstep_count: 481632
total_train_sample_count: 481632
total_episode_count: 4152
total_duration: 29106.258746523046
[2024-12-27 20:08:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.048917859184833
avg_train_sample_per_sec: 17.048917859184833
avg_episode_per_sec: 0.14697342982055892
collect_time: 40.823705395767455
reward_mean: -112.48249299719889
reward_std: 2.3472261192413004
reward_max: -108.12114845938376
reward_min: -115.812324929972
queue_len: 0.074590512597612
wait_time: 0.7119269126748842
delay_time: 4.523767158381832
pressure: 0.9091511936339524
total_envstep_count: 482328
total_train_sample_count: 482328
total_episode_count: 4158
total_duration: 29147.082451918814
[2024-12-27 20:08:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.087124489784223
avg_train_sample_per_sec: 17.087124489784223
avg_episode_per_sec: 0.14730279732572607
collect_time: 40.73242401997559
reward_mean: -112.87873482726422
reward_std: 2.8935324649785343
reward_max: -109.63025210084035
reward_min: -118.34523809523806
queue_len: 0.07485327243187281
wait_time: 0.7121707878553721
delay_time: 4.643042430135148
pressure: 0.9113616268788682
total_envstep_count: 483024
total_train_sample_count: 483024
total_episode_count: 4164
total_duration: 29187.814875938788
[2024-12-27 20:09:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.164666127137835
avg_train_sample_per_sec: 17.164666127137835
avg_episode_per_sec: 0.14797125971670547
collect_time: 40.54841468192637
reward_mean: -113.38422035480863
reward_std: 1.9350474136942302
reward_max: -111.13865546218491
reward_min: -116.95868347338934
queue_len: 0.07518847503634524
wait_time: 0.7204233815542133
delay_time: 4.668766984363258
pressure: 0.9235190097259064
total_envstep_count: 483720
total_train_sample_count: 483720
total_episode_count: 4170
total_duration: 29228.363290620713
[2024-12-27 20:10:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.529980383072637
avg_train_sample_per_sec: 16.529980383072637
avg_episode_per_sec: 0.14249983088855722
collect_time: 42.10531312624738
reward_mean: -113.74498132586366
reward_std: 2.2619547860914437
reward_max: -110.8424369747899
reward_min: -117.99789915966383
queue_len: 0.0754277064495117
wait_time: 0.7258429676026025
delay_time: 4.658705646006086
pressure: 0.9229664014146772
total_envstep_count: 484416
total_train_sample_count: 484416
total_episode_count: 4176
total_duration: 29270.468603746962
[2024-12-27 20:11:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.646315411562522
avg_train_sample_per_sec: 16.646315411562522
avg_episode_per_sec: 0.14350271906519416
collect_time: 41.811054446112365
reward_mean: -113.5219421101774
reward_std: 4.053551606643176
reward_max: -109.77661064425772
reward_min: -121.19537815126048
queue_len: 0.07527980246032984
wait_time: 0.7216511936339524
delay_time: 4.605989568013922
pressure: 0.9185455349248453
total_envstep_count: 485112
total_train_sample_count: 485112
total_episode_count: 4182
total_duration: 29312.279658193074
[2024-12-27 20:11:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.77518000935121
avg_train_sample_per_sec: 16.77518000935121
avg_episode_per_sec: 0.14461362077026907
collect_time: 41.4898677458018
reward_mean: -113.46556956115778
reward_std: 1.8347585910352981
reward_max: -110.71778711484592
reward_min: -116.18277310924368
queue_len: 0.07524242013339376
wait_time: 0.7212404524143876
delay_time: 4.6222288153576185
pressure: 0.9236295313881522
total_envstep_count: 485808
total_train_sample_count: 485808
total_episode_count: 4188
total_duration: 29353.769525938875
[2024-12-27 20:12:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95915665604137
avg_train_sample_per_sec: 16.95915665604137
avg_episode_per_sec: 0.1461996263451842
collect_time: 41.03977657120489
reward_mean: -109.95308123249299
reward_std: 2.5550750325953806
reward_max: -106.28781512605043
reward_min: -113.15336134453779
queue_len: 0.07291318384117573
wait_time: 0.7018227715489379
delay_time: 4.504201141816881
pressure: 0.8972148541114059
total_envstep_count: 486504
total_train_sample_count: 486504
total_episode_count: 4194
total_duration: 29394.80930251008
[2024-12-27 20:13:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05886441197676
avg_train_sample_per_sec: 17.05886441197676
avg_episode_per_sec: 0.1470591759653169
collect_time: 40.79990222041682
reward_mean: -111.80438842203547
reward_std: 2.2870733085680577
reward_max: -109.58333333333336
reward_min: -116.71778711484589
queue_len: 0.07414084112867074
wait_time: 0.711269277826073
delay_time: 4.561235389804419
pressure: 0.9089301503094607
total_envstep_count: 487200
total_train_sample_count: 487200
total_episode_count: 4200
total_duration: 29435.609204730496
[2024-12-27 20:13:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95377906408168
avg_train_sample_per_sec: 16.95377906408168
avg_episode_per_sec: 0.14615326779380758
collect_time: 41.052794033074754
reward_mean: -110.56500933706815
reward_std: 3.370528794100824
reward_max: -104.78501400560225
reward_min: -114.24649859943983
queue_len: 0.07331897170893115
wait_time: 0.7028982680605399
delay_time: 4.452708766604936
pressure: 0.904398762157383
total_envstep_count: 487896
total_train_sample_count: 487896
total_episode_count: 4206
total_duration: 29476.66199876357
[2024-12-27 20:14:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.830849443769768
avg_train_sample_per_sec: 16.830849443769768
avg_episode_per_sec: 0.14509352968767042
collect_time: 41.352636557368555
reward_mean: -113.15838001867415
reward_std: 2.838728897608535
reward_max: -109.47268907563026
reward_min: -116.88515406162465
queue_len: 0.07503871354023485
wait_time: 0.7228121354642653
delay_time: 4.588564543378695
pressure: 0.9217506631299734
total_envstep_count: 488592
total_train_sample_count: 488592
total_episode_count: 4212
total_duration: 29518.01463532094
[2024-12-27 20:15:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.04364762387475
avg_train_sample_per_sec: 17.04364762387475
avg_episode_per_sec: 0.14692799675754095
collect_time: 40.836328898577015
reward_mean: -111.89834267040146
reward_std: 4.140004484549018
reward_max: -105.90056022408959
reward_min: -116.28991596638654
queue_len: 0.07420314500689752
wait_time: 0.7128123243108031
delay_time: 4.655295238665035
pressure: 0.9038461538461539
total_envstep_count: 489288
total_train_sample_count: 489288
total_episode_count: 4218
total_duration: 29558.850964219517
[2024-12-27 20:15:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.484547889580533
avg_train_sample_per_sec: 17.484547889580533
avg_episode_per_sec: 0.15072886111707356
collect_time: 39.806576892660935
reward_mean: -110.93172268907563
reward_std: 4.0170096992938396
reward_max: -104.29761904761904
reward_min: -115.73809523809524
queue_len: 0.0735621503243207
wait_time: 0.7126832275792722
delay_time: 4.567519784560423
pressure: 0.8921308576480991
total_envstep_count: 489984
total_train_sample_count: 489984
total_episode_count: 4224
total_duration: 29598.657541112178
[2024-12-27 20:16:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.231348325741603
avg_train_sample_per_sec: 17.231348325741603
avg_episode_per_sec: 0.14854610625639314
collect_time: 40.391499657647685
reward_mean: -112.62079831932772
reward_std: 2.297875075271171
reward_max: -108.34243697478989
reward_min: -115.9047619047619
queue_len: 0.07468222700220672
wait_time: 0.7208435651006644
delay_time: 4.5014050715661345
pressure: 0.9085985853227232
total_envstep_count: 490680
total_train_sample_count: 490680
total_episode_count: 4230
total_duration: 29639.049040769823
[2024-12-27 20:17:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.389778685484742
avg_train_sample_per_sec: 17.389778685484742
avg_episode_per_sec: 0.14991188521969606
collect_time: 40.02351108590885
reward_mean: -110.78326330532214
reward_std: 2.632809904612352
reward_max: -107.99229691876755
reward_min: -116.32913165266105
queue_len: 0.07346370245711016
wait_time: 0.7017688264518894
delay_time: 4.540356293459851
pressure: 0.8947833775419981
total_envstep_count: 491376
total_train_sample_count: 491376
total_episode_count: 4236
total_duration: 29679.072551855734
[2024-12-27 20:17:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.44466324498508
avg_train_sample_per_sec: 17.44466324498508
avg_episode_per_sec: 0.1503850279740093
collect_time: 39.89758874824272
reward_mean: -111.25023342670403
reward_std: 1.0224373154769333
reward_max: -109.72619047619048
reward_min: -112.64565826330539
queue_len: 0.07377336434131566
wait_time: 0.7060368356007302
delay_time: 4.5322324353037535
pressure: 0.9087091069849689
total_envstep_count: 492072
total_train_sample_count: 492072
total_episode_count: 4242
total_duration: 29718.970140603975
[2024-12-27 20:18:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.06300089325588
avg_train_sample_per_sec: 17.06300089325588
avg_episode_per_sec: 0.14709483528668862
collect_time: 40.790011344082664
reward_mean: -113.84208683473388
reward_std: 3.10457443723098
reward_max: -109.4208683473389
reward_min: -117.42086834733897
queue_len: 0.07549210002303307
wait_time: 0.7221377830530974
delay_time: 4.665655553282323
pressure: 0.9284924845269673
total_envstep_count: 492768
total_train_sample_count: 492768
total_episode_count: 4248
total_duration: 29759.760151948056
[2024-12-27 20:19:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.22793478428479
avg_train_sample_per_sec: 17.22793478428479
avg_episode_per_sec: 0.1485166791748689
collect_time: 40.39950282577611
reward_mean: -113.95249766573296
reward_std: 3.433211778102526
reward_max: -110.26050420168067
reward_min: -118.96008403361346
queue_len: 0.07556531675446482
wait_time: 0.7240777942476727
delay_time: 4.648005014488315
pressure: 0.9311450044208666
total_envstep_count: 493464
total_train_sample_count: 493464
total_episode_count: 4254
total_duration: 29800.159654773834
[2024-12-27 20:20:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.038759489985935
avg_train_sample_per_sec: 17.038759489985935
avg_episode_per_sec: 0.14688585767229254
collect_time: 40.84804415538907
reward_mean: -114.45739962651727
reward_std: 3.7991612622234268
reward_max: -111.33823529411768
reward_min: -121.98599439775911
queue_len: 0.0759001323783271
wait_time: 0.7260251580738396
delay_time: 4.66995186049893
pressure: 0.9355658709106985
total_envstep_count: 494160
total_train_sample_count: 494160
total_episode_count: 4260
total_duration: 29841.00769892922
[2024-12-27 20:20:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.260055150184787
avg_train_sample_per_sec: 17.260055150184787
avg_episode_per_sec: 0.14879357888090333
collect_time: 40.324320747755465
reward_mean: -112.43860877684405
reward_std: 4.611408497824555
reward_max: -106.5749299719888
reward_min: -119.96078431372547
queue_len: 0.07456141165573214
wait_time: 0.7125556013740598
delay_time: 4.582547725883942
pressure: 0.9104774535809018
total_envstep_count: 494856
total_train_sample_count: 494856
total_episode_count: 4266
total_duration: 29881.33201967698
[2024-12-27 20:21:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.410357866727104
avg_train_sample_per_sec: 17.410357866727104
avg_episode_per_sec: 0.150089291954544
collect_time: 39.97620297800564
reward_mean: -112.67845471521946
reward_std: 1.86574806456607
reward_max: -109.40336134453786
reward_min: -115.09313725490203
queue_len: 0.07472046068648504
wait_time: 0.7117209615941867
delay_time: 4.588273998771357
pressure: 0.9133510167992926
total_envstep_count: 495552
total_train_sample_count: 495552
total_episode_count: 4272
total_duration: 29921.308222654985
[2024-12-27 20:22:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.177765084622028
avg_train_sample_per_sec: 17.177765084622028
avg_episode_per_sec: 0.148084181763983
collect_time: 40.517494363866746
reward_mean: -112.96066760037347
reward_std: 1.5582484772569651
reward_max: -111.36134453781507
reward_min: -116.04831932773111
queue_len: 0.07490760450953148
wait_time: 0.7133479828713095
delay_time: 4.652756039547586
pressure: 0.9179929266136163
total_envstep_count: 496248
total_train_sample_count: 496248
total_episode_count: 4278
total_duration: 29961.82571701885
[2024-12-27 20:22:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.225924636979837
avg_train_sample_per_sec: 17.225924636979837
avg_episode_per_sec: 0.14849935031879172
collect_time: 40.404217170778665
reward_mean: -113.2361111111111
reward_std: 3.498185251450187
reward_max: -109.03641456582635
reward_min: -117.92787114845936
queue_len: 0.07509025935750073
wait_time: 0.722351473745997
delay_time: 4.573738553367494
pressure: 0.9236295313881521
total_envstep_count: 496944
total_train_sample_count: 496944
total_episode_count: 4284
total_duration: 30002.22993418963
[2024-12-27 20:23:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.412706520681937
avg_train_sample_per_sec: 17.412706520681937
avg_episode_per_sec: 0.150109538971396
collect_time: 39.97081092323736
reward_mean: -114.20506535947713
reward_std: 2.6409602386683546
reward_max: -109.53851540616252
reward_min: -117.59873949579831
queue_len: 0.075732801962518
wait_time: 0.7210805520262923
delay_time: 4.6863503043445585
pressure: 0.9220822281167109
total_envstep_count: 497640
total_train_sample_count: 497640
total_episode_count: 4290
total_duration: 30042.200745112867
[2024-12-27 20:24:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08990766995732
avg_train_sample_per_sec: 17.08990766995732
avg_episode_per_sec: 0.14732679025825277
collect_time: 40.72579053329304
reward_mean: -112.44000933706816
reward_std: 3.3527799888893997
reward_max: -107.3480392156863
reward_min: -116.62885154061622
queue_len: 0.07456234040919639
wait_time: 0.7095349855238293
delay_time: 4.6894667316823195
pressure: 0.9073828470380194
total_envstep_count: 498336
total_train_sample_count: 498336
total_episode_count: 4296
total_duration: 30082.92653564616
[2024-12-27 20:24:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.13796763150334
avg_train_sample_per_sec: 17.13796763150334
avg_episode_per_sec: 0.14774110027158052
collect_time: 40.61158329652808
reward_mean: -111.57002801120451
reward_std: 3.263176083325845
reward_max: -107.11274509803921
reward_min: -116.02661064425773
queue_len: 0.07398542971565285
wait_time: 0.7126466192135563
delay_time: 4.579422740595249
pressure: 0.9091511936339524
total_envstep_count: 499032
total_train_sample_count: 499032
total_episode_count: 4302
total_duration: 30123.538118942688
[2024-12-27 20:25:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30486577154074
avg_train_sample_per_sec: 17.30486577154074
avg_episode_per_sec: 0.14917987734086846
collect_time: 40.21990168479831
reward_mean: -112.83695144724557
reward_std: 2.4683497328252
reward_max: -111.07843137254902
reward_min: -118.2128851540616
queue_len: 0.07482556462018937
wait_time: 0.7195681544058826
delay_time: 4.6153091424241675
pressure: 0.9178824049513704
total_envstep_count: 499728
total_train_sample_count: 499728
total_episode_count: 4308
total_duration: 30163.758020627487
[2024-12-27 20:26:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.449493906594753
avg_train_sample_per_sec: 17.449493906594753
avg_episode_per_sec: 0.15042667160857545
collect_time: 39.88654362846352
reward_mean: -115.15546218487394
reward_std: 2.441559793298487
reward_max: -111.30252100840335
reward_min: -118.86344537815124
queue_len: 0.07636303858413392
wait_time: 0.7339981969799414
delay_time: 4.718937893237953
pressure: 0.9316976127320956
total_envstep_count: 500424
total_train_sample_count: 500424
total_episode_count: 4314
total_duration: 30203.644564255952
[2024-12-27 20:26:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.400511098302527
avg_train_sample_per_sec: 17.400511098302527
avg_episode_per_sec: 0.15000440601984938
collect_time: 39.998825095884506
reward_mean: -112.8564425770308
reward_std: 4.9843280526009135
reward_max: -108.06442577030813
reward_min: -122.77310924369745
queue_len: 0.07483848977256685
wait_time: 0.7174238948452945
delay_time: 4.592613637233222
pressure: 0.9179929266136164
total_envstep_count: 501120
total_train_sample_count: 501120
total_episode_count: 4320
total_duration: 30243.643389351837
[2024-12-27 20:27:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95588699051661
avg_train_sample_per_sec: 16.95588699051661
avg_episode_per_sec: 0.14617143957341908
collect_time: 41.04769042098896
reward_mean: -113.06944444444444
reward_std: 0.8840228089501977
reward_max: -112.11274509803924
reward_min: -114.74229691876751
queue_len: 0.07497973769525494
wait_time: 0.717637972518804
delay_time: 4.662680775777759
pressure: 0.9238505747126436
total_envstep_count: 501816
total_train_sample_count: 501816
total_episode_count: 4326
total_duration: 30284.691079772827
[2024-12-27 20:28:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.106945806966298
avg_train_sample_per_sec: 17.106945806966298
avg_episode_per_sec: 0.1474736707497095
collect_time: 40.68522855298779
reward_mean: -110.66363211951449
reward_std: 2.562904401476803
reward_max: -108.31442577030815
reward_min: -115.9810924369748
queue_len: 0.07338437143203878
wait_time: 0.6986937237317562
delay_time: 4.608289275016332
pressure: 0.8987621573828471
total_envstep_count: 502512
total_train_sample_count: 502512
total_episode_count: 4332
total_duration: 30325.376308325816
[2024-12-27 20:28:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89329167041296
avg_train_sample_per_sec: 16.89329167041296
avg_episode_per_sec: 0.1456318247449393
collect_time: 41.19978590193762
reward_mean: -111.86834733893558
reward_std: 2.1649087649927576
reward_max: -108.72058823529412
reward_min: -114.3669467787115
queue_len: 0.07418325420353818
wait_time: 0.7106924445286514
delay_time: 4.592643257837984
pressure: 0.9102564102564102
total_envstep_count: 503208
total_train_sample_count: 503208
total_episode_count: 4338
total_duration: 30366.576094227756
[2024-12-27 20:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08325713506383
avg_train_sample_per_sec: 17.08325713506383
avg_episode_per_sec: 0.14726945806089506
collect_time: 40.74164513811842
reward_mean: -113.38422035480859
reward_std: 3.1250055948255095
reward_max: -109.27941176470591
reward_min: -118.14495798319328
queue_len: 0.07518847503634522
wait_time: 0.720990308148016
delay_time: 4.685498529495481
pressure: 0.920866489832007
total_envstep_count: 503904
total_train_sample_count: 503904
total_episode_count: 4344
total_duration: 30407.317739365873
[2024-12-27 20:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.114390454184147
avg_train_sample_per_sec: 17.114390454184147
avg_episode_per_sec: 0.14753784874296677
collect_time: 40.66753074631654
reward_mean: -114.45553221288515
reward_std: 3.2598126405834114
reward_max: -109.27591036414566
reward_min: -117.29761904761901
queue_len: 0.07589889404037477
wait_time: 0.7265871313158332
delay_time: 4.721256489163866
pressure: 0.9276083112290007
total_envstep_count: 504600
total_train_sample_count: 504600
total_episode_count: 4350
total_duration: 30447.98527011219
[2024-12-27 20:31:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18779824784016
avg_train_sample_per_sec: 17.18779824784016
avg_episode_per_sec: 0.1481706745503462
collect_time: 40.49384278102405
reward_mean: -113.93615779645192
reward_std: 4.965236113810079
reward_max: -104.66806722689074
reward_min: -121.33193277310923
queue_len: 0.0755544812973819
wait_time: 0.7289749564724209
delay_time: 4.644767390428846
pressure: 0.9244031830238727
total_envstep_count: 505296
total_train_sample_count: 505296
total_episode_count: 4356
total_duration: 30488.479112893212
[2024-12-27 20:31:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45077443512083
avg_train_sample_per_sec: 17.45077443512083
avg_episode_per_sec: 0.15043771064759337
collect_time: 39.883616775153214
reward_mean: -112.31290849673202
reward_std: 1.845394905993207
reward_max: -110.25420168067228
reward_min: -115.5980392156863
queue_len: 0.07447805603231568
wait_time: 0.7165065186109812
delay_time: 4.691322925413251
pressure: 0.9090406719717065
total_envstep_count: 505992
total_train_sample_count: 505992
total_episode_count: 4362
total_duration: 30528.362729668366
[2024-12-27 20:32:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.316639129071948
avg_train_sample_per_sec: 17.316639129071948
avg_episode_per_sec: 0.14928137180234438
collect_time: 40.192556697189815
reward_mean: -113.05800653594771
reward_std: 1.4993848902322187
reward_max: -110.99859943977589
reward_min: -115.46218487394961
queue_len: 0.0749721528752969
wait_time: 0.7219110124155764
delay_time: 4.653189167846374
pressure: 0.9156719717064544
total_envstep_count: 506688
total_train_sample_count: 506688
total_episode_count: 4368
total_duration: 30568.555286365558
[2024-12-27 20:33:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.210946839955252
avg_train_sample_per_sec: 17.210946839955252
avg_episode_per_sec: 0.14837023137892458
collect_time: 40.43937887160481
reward_mean: -113.14554154995331
reward_std: 2.555651534707401
reward_max: -110.0238095238095
reward_min: -117.98179271708683
queue_len: 0.07503019996681254
wait_time: 0.7134853609878964
delay_time: 4.687814403854235
pressure: 0.9116931918656057
total_envstep_count: 507384
total_train_sample_count: 507384
total_episode_count: 4374
total_duration: 30608.994665237162
[2024-12-27 20:33:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.305795409923583
avg_train_sample_per_sec: 17.305795409923583
avg_episode_per_sec: 0.14918789146485847
collect_time: 40.21774113895371
reward_mean: -110.69047619047619
reward_std: 3.0786669407816722
reward_max: -104.81792717086834
reward_min: -114.12324929971986
queue_len: 0.07340217254010357
wait_time: 0.7000562824599336
delay_time: 4.524991160895916
pressure: 0.9010831122900088
total_envstep_count: 508080
total_train_sample_count: 508080
total_episode_count: 4380
total_duration: 30649.212406376115
[2024-12-27 20:34:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.068640100382538
avg_train_sample_per_sec: 17.068640100382538
avg_episode_per_sec: 0.1471434491412288
collect_time: 40.77653497330472
reward_mean: -114.16526610644257
reward_std: 4.9639925968994465
reward_max: -106.65266106442579
reward_min: -119.1890756302521
queue_len: 0.07570640988490886
wait_time: 0.7294972255038177
delay_time: 4.70141182649761
pressure: 0.9311450044208663
total_envstep_count: 508776
total_train_sample_count: 508776
total_episode_count: 4386
total_duration: 30689.98894134942
[2024-12-27 20:35:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.14615396067995
avg_train_sample_per_sec: 17.14615396067995
avg_episode_per_sec: 0.14781167207482715
collect_time: 40.592193537751214
reward_mean: -112.91468253968254
reward_std: 3.8063080811041172
reward_max: -105.62254901960785
reward_min: -116.93557422969188
queue_len: 0.07487711043745526
wait_time: 0.7104034474090254
delay_time: 4.618433630651743
pressure: 0.9152298850574713
total_envstep_count: 509472
total_train_sample_count: 509472
total_episode_count: 4392
total_duration: 30730.581134887172
[2024-12-27 20:35:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.390889338572787
avg_train_sample_per_sec: 17.390889338572787
avg_episode_per_sec: 0.14992145981528263
collect_time: 40.02095502133294
reward_mean: -113.05030345471522
reward_std: 3.1845664052279146
reward_max: -106.88795518207284
reward_min: -117.42016806722692
queue_len: 0.07496704473124352
wait_time: 0.7181761851513374
delay_time: 4.638977926687202
pressure: 0.9211980548187443
total_envstep_count: 510168
total_train_sample_count: 510168
total_episode_count: 4398
total_duration: 30770.602089908505
[2024-12-27 20:36:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.4603453797128
avg_train_sample_per_sec: 17.4603453797128
avg_episode_per_sec: 0.15052021879062757
collect_time: 39.86175444207899
reward_mean: -113.5109710550887
reward_std: 2.8792825802598023
reward_max: -110.65056022408965
reward_min: -118.28641456582632
queue_len: 0.07527252722485987
wait_time: 0.72814116804989
delay_time: 4.684996897716014
pressure: 0.927497789566755
total_envstep_count: 510864
total_train_sample_count: 510864
total_episode_count: 4404
total_duration: 30810.463844350583
[2024-12-27 20:37:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.290614268093194
avg_train_sample_per_sec: 17.290614268093194
avg_episode_per_sec: 0.14905701955252754
collect_time: 40.25305227497593
reward_mean: -114.2544351073763
reward_std: 5.126886808252772
reward_max: -104.703081232493
reward_min: -119.92086834733894
queue_len: 0.07576554052213282
wait_time: 0.7284981189646506
delay_time: 4.724179310612552
pressure: 0.9325817860300619
total_envstep_count: 511560
total_train_sample_count: 511560
total_episode_count: 4410
total_duration: 30850.71689662556
[2024-12-27 20:37:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16289092935305
avg_train_sample_per_sec: 17.16289092935305
avg_episode_per_sec: 0.1479559562875263
collect_time: 40.55260869890265
reward_mean: -111.6676003734827
reward_std: 4.220835571790143
reward_max: -104.25840336134455
reward_min: -115.08823529411762
queue_len: 0.07405013287366229
wait_time: 0.7094868451359323
delay_time: 4.574296145747379
pressure: 0.9193191865605658
total_envstep_count: 512256
total_train_sample_count: 512256
total_episode_count: 4416
total_duration: 30891.26950532446
[2024-12-27 20:38:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.409815527421465
avg_train_sample_per_sec: 17.409815527421465
avg_episode_per_sec: 0.15008461661570227
collect_time: 39.97744829080813
reward_mean: -109.29703548085901
reward_std: 1.6956042552463089
reward_max: -106.4544817927171
reward_min: -111.96918767507002
queue_len: 0.07247814023929643
wait_time: 0.6931211255501317
delay_time: 4.508559598628088
pressure: 0.8859416445623342
total_envstep_count: 512952
total_train_sample_count: 512952
total_episode_count: 4422
total_duration: 30931.246953615268
[2024-12-27 20:39:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.421918868901788
avg_train_sample_per_sec: 17.421918868901788
avg_episode_per_sec: 0.1501889557663947
collect_time: 39.949675190048296
reward_mean: -111.12990196078431
reward_std: 2.858644481852061
reward_max: -108.10434173669466
reward_min: -117.01400560224091
queue_len: 0.07369356893951214
wait_time: 0.7054774938268853
delay_time: 4.600377838629388
pressure: 0.9122458001768347
total_envstep_count: 513648
total_train_sample_count: 513648
total_episode_count: 4428
total_duration: 30971.196628805315
[2024-12-27 20:39:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.116345452068533
avg_train_sample_per_sec: 17.116345452068533
avg_episode_per_sec: 0.1475547021730046
collect_time: 40.662885774830364
reward_mean: -112.59337068160596
reward_std: 2.951567547219161
reward_max: -107.76050420168066
reward_min: -117.07492997198875
queue_len: 0.07466403891353181
wait_time: 0.7171869853157885
delay_time: 4.567437493207276
pressure: 0.9192086648983201
total_envstep_count: 514344
total_train_sample_count: 514344
total_episode_count: 4434
total_duration: 31011.859514580145
[2024-12-27 20:40:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.2954325994654
avg_train_sample_per_sec: 17.2954325994654
avg_episode_per_sec: 0.1490985568919431
collect_time: 40.2418381845802
reward_mean: -111.44187675070026
reward_std: 2.722476143485538
reward_max: -107.51610644257703
reward_min: -115.03431372549018
queue_len: 0.07390044877367392
wait_time: 0.7067787548264223
delay_time: 4.58664292762662
pressure: 0.9000884173297967
total_envstep_count: 515040
total_train_sample_count: 515040
total_episode_count: 4440
total_duration: 31052.101352764726
[2024-12-27 20:41:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.329402869463262
avg_train_sample_per_sec: 17.329402869463262
avg_episode_per_sec: 0.14939140404709708
collect_time: 40.16295340599679
reward_mean: -113.3500233426704
reward_std: 4.231111085893503
reward_max: -106.38865546218486
reward_min: -118.61974789915963
queue_len: 0.07516579797259311
wait_time: 0.7268250469949251
delay_time: 4.654636519430949
pressure: 0.9345711759504862
total_envstep_count: 515736
total_train_sample_count: 515736
total_episode_count: 4446
total_duration: 31092.264306170724
[2024-12-27 20:41:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30313231145918
avg_train_sample_per_sec: 17.30313231145918
avg_episode_per_sec: 0.1491649337194757
collect_time: 40.223930989596994
reward_mean: -115.62733426704013
reward_std: 2.2448463384298423
reward_max: -112.21918767507
reward_min: -117.78501400560222
queue_len: 0.07667595110546428
wait_time: 0.7356594273429972
delay_time: 4.6953222427562205
pressure: 0.9417550839964633
total_envstep_count: 516432
total_train_sample_count: 516432
total_episode_count: 4452
total_duration: 31132.48823716032
[2024-12-27 20:42:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.441251204545182
avg_train_sample_per_sec: 17.441251204545182
avg_episode_per_sec: 0.15035561383228604
collect_time: 39.90539393289759
reward_mean: -110.83251633986926
reward_std: 2.8754251362657843
reward_max: -107.61204481792717
reward_min: -116.07282913165264
queue_len: 0.07349636362060295
wait_time: 0.7075459051878932
delay_time: 4.498857825884894
pressure: 0.9047303271441202
total_envstep_count: 517128
total_train_sample_count: 517128
total_episode_count: 4458
total_duration: 31172.39363109322
[2024-12-27 20:43:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33036882614863
avg_train_sample_per_sec: 17.33036882614863
avg_episode_per_sec: 0.14939973125990197
collect_time: 40.16071481120773
reward_mean: -110.77626050420167
reward_std: 2.3016513421175224
reward_max: -108.4929971988796
reward_min: -114.89915966386557
queue_len: 0.07345905868978891
wait_time: 0.7043065678968317
delay_time: 4.494753916678428
pressure: 0.8996463306808135
total_envstep_count: 517824
total_train_sample_count: 517824
total_episode_count: 4464
total_duration: 31212.554345904427
[2024-12-27 20:43:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45548400659941
avg_train_sample_per_sec: 17.45548400659941
avg_episode_per_sec: 0.15047831040171902
collect_time: 39.87285598823056
reward_mean: -110.99743230625586
reward_std: 4.265921399749373
reward_max: -107.20518207282913
reward_min: -119.95028011204484
queue_len: 0.07360572434101846
wait_time: 0.7073814384285987
delay_time: 4.527918464175641
pressure: 0.9037356321839081
total_envstep_count: 518520
total_train_sample_count: 518520
total_episode_count: 4470
total_duration: 31252.427201892657
[2024-12-27 20:44:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.877201172909075
avg_train_sample_per_sec: 16.877201172909075
avg_episode_per_sec: 0.145493113559561
collect_time: 41.23906522588618
reward_mean: -113.83695144724554
reward_std: 1.9056820195133928
reward_max: -110.31092436974787
reward_min: -116.11274509803918
queue_len: 0.07548869459366415
wait_time: 0.7186356085316533
delay_time: 4.589602479546392
pressure: 0.9221927497789567
total_envstep_count: 519216
total_train_sample_count: 519216
total_episode_count: 4476
total_duration: 31293.666267118544
[2024-12-27 20:45:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.9653868059927
avg_train_sample_per_sec: 16.9653868059927
avg_episode_per_sec: 0.14625333453441983
collect_time: 41.02470565269701
reward_mean: -111.42892156862747
reward_std: 1.1788174336720696
reward_max: -109.32002801120449
reward_min: -113.09173669467788
queue_len: 0.07389185780412962
wait_time: 0.7039161818573584
delay_time: 4.519000204358112
pressure: 0.9102564102564102
total_envstep_count: 519912
total_train_sample_count: 519912
total_episode_count: 4482
total_duration: 31334.69097277124
[2024-12-27 20:46:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.773121990161577
avg_train_sample_per_sec: 16.773121990161577
avg_episode_per_sec: 0.14459587922553085
collect_time: 41.49495844651013
reward_mean: -112.25828664799252
reward_std: 2.4852272726754183
reward_max: -107.83683473389351
reward_min: -115.6939775910364
queue_len: 0.0744418346472099
wait_time: 0.7135438724561443
delay_time: 4.568459445433086
pressure: 0.9193191865605659
total_envstep_count: 520608
total_train_sample_count: 520608
total_episode_count: 4488
total_duration: 31376.18593121775
[2024-12-27 20:46:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.808955299157354
avg_train_sample_per_sec: 16.808955299157354
avg_episode_per_sec: 0.14490478706170132
collect_time: 41.40649954818376
reward_mean: -112.54936974789916
reward_std: 3.6525046470603804
reward_max: -108.41456582633053
reward_min: -118.63795518207282
queue_len: 0.07463486057552995
wait_time: 0.7152440330685765
delay_time: 4.574652874399276
pressure: 0.9174403183023871
total_envstep_count: 521304
total_train_sample_count: 521304
total_episode_count: 4494
total_duration: 31417.592430765933
[2024-12-27 20:47:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.216408312616256
avg_train_sample_per_sec: 17.216408312616256
avg_episode_per_sec: 0.1484173130397953
collect_time: 40.42655049543454
reward_mean: -112.3250466853408
reward_std: 4.515932091591297
reward_max: -105.42366946778712
reward_min: -117.8074229691877
queue_len: 0.07448610522900583
wait_time: 0.7125004179390589
delay_time: 4.533330696003429
pressure: 0.9217506631299734
total_envstep_count: 522000
total_train_sample_count: 522000
total_episode_count: 4500
total_duration: 31458.018981261368
[2024-12-27 20:48:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.537805310939135
avg_train_sample_per_sec: 17.537805310939135
avg_episode_per_sec: 0.15118797681844082
collect_time: 39.685695425406095
reward_mean: -111.26949112978525
reward_std: 1.903197578811942
reward_max: -108.12675070028016
reward_min: -113.52310924369746
queue_len: 0.07378613470144911
wait_time: 0.70217136368252
delay_time: 4.484400199057124
pressure: 0.9127984084880635
total_envstep_count: 522696
total_train_sample_count: 522696
total_episode_count: 4506
total_duration: 31497.704676686775
[2024-12-27 20:48:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.374872975011325
avg_train_sample_per_sec: 17.374872975011325
avg_episode_per_sec: 0.14978338771561486
collect_time: 40.05784681136907
reward_mean: -111.33356676003734
reward_std: 3.532105047836885
reward_max: -107.46988795518205
reward_min: -117.72478991596641
queue_len: 0.07382862517243856
wait_time: 0.7075469113374794
delay_time: 4.554394003855915
pressure: 0.9087091069849692
total_envstep_count: 523392
total_train_sample_count: 523392
total_episode_count: 4512
total_duration: 31537.762523498146
[2024-12-27 20:49:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.198737974466958
avg_train_sample_per_sec: 17.198737974466958
avg_episode_per_sec: 0.14826498253850826
collect_time: 40.468085567282515
reward_mean: -111.20739962651726
reward_std: 1.7244396179227277
reward_max: -108.9033613445378
reward_min: -113.76820728291312
queue_len: 0.073744959964534
wait_time: 0.7056027981484371
delay_time: 4.5613343587593524
pressure: 0.902740937223696
total_envstep_count: 524088
total_train_sample_count: 524088
total_episode_count: 4518
total_duration: 31578.230609065427
[2024-12-27 20:50:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.374509012365216
avg_train_sample_per_sec: 17.374509012365216
avg_episode_per_sec: 0.14978025010659668
collect_time: 40.05868594644405
reward_mean: -110.65079365079363
reward_std: 2.986730571914189
reward_max: -105.33263305322126
reward_min: -114.28291316526611
queue_len: 0.07337585785861647
wait_time: 0.7015340840138
delay_time: 4.499249795879307
pressure: 0.9014146772767462
total_envstep_count: 524784
total_train_sample_count: 524784
total_episode_count: 4524
total_duration: 31618.289295011873
[2024-12-27 20:50:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27836574195754
avg_train_sample_per_sec: 17.27836574195754
avg_episode_per_sec: 0.1489514288099788
collect_time: 40.281587413668625
reward_mean: -110.07668067226892
reward_std: 4.793305729197695
reward_max: -100.98599439775909
reward_min: -115.75280112044818
queue_len: 0.07299514633439584
wait_time: 0.6985847499919506
delay_time: 4.491303781952442
pressure: 0.8959991158267021
total_envstep_count: 525480
total_train_sample_count: 525480
total_episode_count: 4530
total_duration: 31658.57088242554
[2024-12-27 20:51:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40085301945037
avg_train_sample_per_sec: 17.40085301945037
avg_episode_per_sec: 0.15000735361595147
collect_time: 39.998039131876084
reward_mean: -112.36694677871147
reward_std: 4.077507861768718
reward_max: -108.04271708683474
reward_min: -120.39075630252103
queue_len: 0.07451389043681134
wait_time: 0.7146595375550752
delay_time: 4.5976605460076785
pressure: 0.9161140583554377
total_envstep_count: 526176
total_train_sample_count: 526176
total_episode_count: 4536
total_duration: 31698.568921557417
[2024-12-27 20:52:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.522517031804362
avg_train_sample_per_sec: 17.522517031804362
avg_episode_per_sec: 0.1510561813086583
collect_time: 39.72032092973404
reward_mean: -112.4479458450047
reward_std: 1.507080065692807
reward_max: -109.34313725490195
reward_min: -114.3158263305322
queue_len: 0.07456760334549381
wait_time: 0.7180499520763212
delay_time: 4.5597299411162355
pressure: 0.9202033598585323
total_envstep_count: 526872
total_train_sample_count: 526872
total_episode_count: 4542
total_duration: 31738.28924248715
[2024-12-27 20:52:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30015786766359
avg_train_sample_per_sec: 17.30015786766359
avg_episode_per_sec: 0.14913929196261713
collect_time: 40.2308467543479
reward_mean: -113.07784780578898
reward_std: 2.2031346327180588
reward_max: -110.57072829131653
reward_min: -115.9621848739496
queue_len: 0.07498531021604045
wait_time: 0.7234285955761615
delay_time: 4.655752057387364
pressure: 0.9299292661361628
total_envstep_count: 527568
total_train_sample_count: 527568
total_episode_count: 4548
total_duration: 31778.520089241498
[2024-12-27 20:53:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.022431347219417
avg_train_sample_per_sec: 17.022431347219417
avg_episode_per_sec: 0.14674509782085704
collect_time: 40.88722614314966
reward_mean: -112.24323062558354
reward_std: 3.9240381643925626
reward_max: -106.05672268907564
reward_min: -118.60154061624651
queue_len: 0.0744318505474692
wait_time: 0.7167194353426605
delay_time: 4.5860528249939145
pressure: 0.9195402298850576
total_envstep_count: 528264
total_train_sample_count: 528264
total_episode_count: 4554
total_duration: 31819.407315384648
[2024-12-27 20:54:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.292436683303283
avg_train_sample_per_sec: 17.292436683303283
avg_episode_per_sec: 0.1490727300284766
collect_time: 40.248810086552055
reward_mean: -110.52089169000932
reward_std: 2.786784434215957
reward_max: -105.33193277310924
reward_min: -114.3669467787115
queue_len: 0.07328971597480725
wait_time: 0.7014494126563093
delay_time: 4.480862222102954
pressure: 0.9104774535809019
total_envstep_count: 528960
total_train_sample_count: 528960
total_episode_count: 4560
total_duration: 31859.6561254712
[2024-12-27 20:54:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.21165379725846
avg_train_sample_per_sec: 17.21165379725846
avg_episode_per_sec: 0.14837632583843502
collect_time: 40.43771785084717
reward_mean: -111.5280112044818
reward_std: 1.9924311038354792
reward_max: -109.36274509803918
reward_min: -114.90546218487391
queue_len: 0.07395756711172531
wait_time: 0.7077414851882398
delay_time: 4.564680165408418
pressure: 0.9111405835543768
total_envstep_count: 529656
total_train_sample_count: 529656
total_episode_count: 4566
total_duration: 31900.093843322047
[2024-12-27 20:55:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.171175448111633
avg_train_sample_per_sec: 17.171175448111633
avg_episode_per_sec: 0.1480273745526865
collect_time: 40.53304341937414
reward_mean: -111.73120915032679
reward_std: 3.69459501207187
reward_max: -104.9964985994398
reward_min: -115.88585434173673
queue_len: 0.07409231376016366
wait_time: 0.7076647856313171
delay_time: 4.607905541042924
pressure: 0.9135720601237843
total_envstep_count: 530352
total_train_sample_count: 530352
total_episode_count: 4572
total_duration: 31940.626886741422
[2024-12-27 20:56:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.190599354882185
avg_train_sample_per_sec: 17.190599354882185
avg_episode_per_sec: 0.1481948220248464
collect_time: 40.48724454754591
reward_mean: -112.09535480859012
reward_std: 2.808426466927134
reward_max: -108.18767507002802
reward_min: -116.93697478991598
queue_len: 0.07433378966086877
wait_time: 0.7126295920667117
delay_time: 4.580837784214508
pressure: 0.9195402298850576
total_envstep_count: 531048
total_train_sample_count: 531048
total_episode_count: 4578
total_duration: 31981.114131288967
[2024-12-27 20:56:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.035927804412594
avg_train_sample_per_sec: 17.035927804412594
avg_episode_per_sec: 0.14686144658976374
collect_time: 40.854833854116485
reward_mean: -112.98727824463118
reward_std: 4.328965989343587
reward_max: -106.436974789916
reward_min: -120.8221288515406
queue_len: 0.07492525082535224
wait_time: 0.7181628730183496
delay_time: 4.63659613526708
pressure: 0.9241821396993811
total_envstep_count: 531744
total_train_sample_count: 531744
total_episode_count: 4584
total_duration: 32021.96896514308
[2024-12-27 20:57:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.03551357338542
avg_train_sample_per_sec: 17.03551357338542
avg_episode_per_sec: 0.14685787563263292
collect_time: 40.85582726941445
reward_mean: -112.22117180205417
reward_std: 3.8184457183520233
reward_max: -106.296218487395
reward_min: -117.07633053221292
queue_len: 0.07441722268040728
wait_time: 0.7077481412547334
delay_time: 4.640455176858326
pressure: 0.9095932802829353
total_envstep_count: 532440
total_train_sample_count: 532440
total_episode_count: 4590
total_duration: 32062.824792412495
[2024-12-27 20:58:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.126624228819534
avg_train_sample_per_sec: 17.126624228819534
avg_episode_per_sec: 0.14764331231740976
collect_time: 40.63848139020987
reward_mean: -112.6450746965453
reward_std: 2.7649026271225043
reward_max: -108.8403361344538
reward_min: -116.28011204481794
queue_len: 0.07469832539558706
wait_time: 0.7080222783189315
delay_time: 4.6192877293610195
pressure: 0.9251768346595933
total_envstep_count: 533136
total_train_sample_count: 533136
total_episode_count: 4596
total_duration: 32103.463273802707
[2024-12-27 20:59:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.973788316717318
avg_train_sample_per_sec: 16.973788316717318
avg_episode_per_sec: 0.14632576135101136
collect_time: 41.00439966689795
reward_mean: -114.75338468720821
reward_std: 2.658595081881137
reward_max: -110.42366946778715
reward_min: -117.62254901960787
queue_len: 0.07609640894377202
wait_time: 0.7220884817233703
delay_time: 4.655432008840285
pressure: 0.9325817860300619
total_envstep_count: 533832
total_train_sample_count: 533832
total_episode_count: 4602
total_duration: 32144.467673469604
[2024-12-27 20:59:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.386555761022606
avg_train_sample_per_sec: 17.386555761022606
avg_episode_per_sec: 0.1498841013881259
collect_time: 40.03093019494415
reward_mean: -117.7529178338002
reward_std: 6.022971772725259
reward_max: -111.20168067226892
reward_min: -127.1659663865546
queue_len: 0.07808548927970833
wait_time: 0.7499835920221316
delay_time: 4.774927547986443
pressure: 0.955238726790451
total_envstep_count: 534528
total_train_sample_count: 534528
total_episode_count: 4608
total_duration: 32184.49860366455
[2024-12-27 21:00:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.295397887546155
avg_train_sample_per_sec: 17.295397887546155
avg_episode_per_sec: 0.14909825765125995
collect_time: 40.241918950079004
reward_mean: -111.34605508870216
reward_std: 1.1129224247923577
reward_max: -109.72549019607841
reward_min: -113.28501400560224
queue_len: 0.07383690655749481
wait_time: 0.7049515871777535
delay_time: 4.62068193317718
pressure: 0.90815649867374
total_envstep_count: 535224
total_train_sample_count: 535224
total_episode_count: 4614
total_duration: 32224.74052261463
[2024-12-27 21:01:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40575557827644
avg_train_sample_per_sec: 17.40575557827644
avg_episode_per_sec: 0.15004961705410727
collect_time: 39.986773160750055
reward_mean: -112.18102240896359
reward_std: 1.9198974515283753
reward_max: -108.86484593837535
reward_min: -114.68067226890757
queue_len: 0.07439059841443209
wait_time: 0.705858437539472
delay_time: 4.649765769656649
pressure: 0.9048408488063661
total_envstep_count: 535920
total_train_sample_count: 535920
total_episode_count: 4620
total_duration: 32264.727295775378
[2024-12-27 21:01:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18828497646682
avg_train_sample_per_sec: 17.18828497646682
avg_episode_per_sec: 0.14817487048678296
collect_time: 40.49269609812275
reward_mean: -111.5441176470588
reward_std: 4.769944605218179
reward_max: -104.02591036414566
reward_min: -117.78851540616245
queue_len: 0.0739682477765642
wait_time: 0.6988828798539752
delay_time: 4.615191531090164
pressure: 0.901525198938992
total_envstep_count: 536616
total_train_sample_count: 536616
total_episode_count: 4626
total_duration: 32305.2199918735
[2024-12-27 21:02:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.064657667243093
avg_train_sample_per_sec: 17.064657667243093
avg_episode_per_sec: 0.14710911782106115
collect_time: 40.78605112225749
reward_mean: -112.07166199813258
reward_std: 3.545723243100689
reward_max: -107.28781512605045
reward_min: -118.13025210084037
queue_len: 0.07431807824809854
wait_time: 0.7097929467985248
delay_time: 4.556973560509189
pressure: 0.90815649867374
total_envstep_count: 537312
total_train_sample_count: 537312
total_episode_count: 4632
total_duration: 32346.006042995756
[2024-12-27 21:03:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35435356455304
avg_train_sample_per_sec: 17.35435356455304
avg_episode_per_sec: 0.14960649624614691
collect_time: 40.10521033878253
reward_mean: -111.4550653594771
reward_std: 2.693544937690439
reward_max: -107.21218487394961
reward_min: -115.36904761904763
queue_len: 0.07390919453546228
wait_time: 0.7103224910653917
delay_time: 4.580249751016969
pressure: 0.9099248452696728
total_envstep_count: 538008
total_train_sample_count: 538008
total_episode_count: 4638
total_duration: 32386.111253334537
[2024-12-27 21:03:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.1023607045263
avg_train_sample_per_sec: 17.1023607045263
avg_episode_per_sec: 0.14743414400453708
collect_time: 40.696136166499926
reward_mean: -112.65686274509801
reward_std: 2.5497662074448084
reward_max: -109.4593837535014
reward_min: -116.68557422969187
queue_len: 0.07470614240391116
wait_time: 0.7121492717334502
delay_time: 4.632088315533764
pressure: 0.9231874447391689
total_envstep_count: 538704
total_train_sample_count: 538704
total_episode_count: 4644
total_duration: 32426.80738950104
[2024-12-27 21:04:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30876835470596
avg_train_sample_per_sec: 17.30876835470596
avg_episode_per_sec: 0.14921352029918933
collect_time: 40.21083336127549
reward_mean: -109.95378151260502
reward_std: 4.829305416354021
reward_max: -104.43767507002806
reward_min: -119.95028011204482
queue_len: 0.07291364821790786
wait_time: 0.6930708180708179
delay_time: 4.547935156774279
pressure: 0.8947833775419981
total_envstep_count: 539400
total_train_sample_count: 539400
total_episode_count: 4650
total_duration: 32467.018222862313
[2024-12-27 21:05:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08590714105568
avg_train_sample_per_sec: 17.08590714105568
avg_episode_per_sec: 0.14729230294013518
collect_time: 40.73532615236937
reward_mean: -108.50128384687208
reward_std: 3.9007615738711885
reward_max: -104.21708683473389
reward_min: -114.64635854341739
queue_len: 0.07195045347935815
wait_time: 0.6870229303038634
delay_time: 4.396386960716989
pressure: 0.8848364279398764
total_envstep_count: 540096
total_train_sample_count: 540096
total_episode_count: 4656
total_duration: 32507.75354901468
[2024-12-27 21:05:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.109532885253536
avg_train_sample_per_sec: 17.109532885253536
avg_episode_per_sec: 0.14749597314873736
collect_time: 40.67907666841522
reward_mean: -109.44386087768441
reward_std: 4.259119980079153
reward_max: -105.30532212885154
reward_min: -117.42226890756302
queue_len: 0.07257550456079868
wait_time: 0.6948530185725925
delay_time: 4.463897612102777
pressure: 0.8950044208664898
total_envstep_count: 540792
total_train_sample_count: 540792
total_episode_count: 4662
total_duration: 32548.432625683094
[2024-12-27 21:06:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25863204066987
avg_train_sample_per_sec: 17.25863204066987
avg_episode_per_sec: 0.1487813106954299
collect_time: 40.327645804133255
reward_mean: -110.79061624649863
reward_std: 5.468904492155209
reward_max: -102.54411764705885
reward_min: -117.16176470588242
queue_len: 0.07346857841279748
wait_time: 0.6999453738170778
delay_time: 4.508277838819354
pressure: 0.8999778956675507
total_envstep_count: 541488
total_train_sample_count: 541488
total_episode_count: 4668
total_duration: 32588.760271487226
[2024-12-27 21:07:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16508728147828
avg_train_sample_per_sec: 17.16508728147828
avg_episode_per_sec: 0.14797489035757136
collect_time: 40.54741980549135
reward_mean: -111.96650326797383
reward_std: 4.0706040150313605
reward_max: -105.1974789915966
reward_min: -118.23179271708688
queue_len: 0.07424834434215773
wait_time: 0.7086234913947895
delay_time: 4.531963907943298
pressure: 0.915893015030946
total_envstep_count: 542184
total_train_sample_count: 542184
total_episode_count: 4674
total_duration: 32629.307691292717
[2024-12-27 21:07:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.284680650535375
avg_train_sample_per_sec: 17.284680650535375
avg_episode_per_sec: 0.14900586767702909
collect_time: 40.26687065106072
reward_mean: -110.22595704948644
reward_std: 3.3497332586189548
reward_max: -105.31582633053222
reward_min: -116.30112044817928
queue_len: 0.07309413597446052
wait_time: 0.7028036899994303
delay_time: 4.498338676435501
pressure: 0.8989832007073385
total_envstep_count: 542880
total_train_sample_count: 542880
total_episode_count: 4680
total_duration: 32669.574561943777
[2024-12-27 21:08:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.22968201321352
avg_train_sample_per_sec: 17.22968201321352
avg_episode_per_sec: 0.14853174149322002
collect_time: 40.39540598986299
reward_mean: -113.18942577030812
reward_std: 1.9883331624647251
reward_max: -109.4922969187675
reward_min: -115.7640056022409
queue_len: 0.07505930090869238
wait_time: 0.7211413079820789
delay_time: 4.678224872172226
pressure: 0.9090406719717065
total_envstep_count: 543576
total_train_sample_count: 543576
total_episode_count: 4686
total_duration: 32709.96996793364
[2024-12-27 21:09:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.26137079302165
avg_train_sample_per_sec: 17.26137079302165
avg_episode_per_sec: 0.148804920629497
collect_time: 40.32124727205186
reward_mean: -110.44421101774043
reward_std: 2.751067144029945
reward_max: -107.32563025210084
reward_min: -115.67857142857144
queue_len: 0.07323886672263955
wait_time: 0.6961103959709436
delay_time: 4.525040084574399
pressure: 0.9071618037135277
total_envstep_count: 544272
total_train_sample_count: 544272
total_episode_count: 4692
total_duration: 32750.291215205692
[2024-12-27 21:09:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.245708610182348
avg_train_sample_per_sec: 17.245708610182348
avg_episode_per_sec: 0.14866990181191678
collect_time: 40.357866164401166
reward_mean: -110.68639122315595
reward_std: 3.231986013317061
reward_max: -105.49229691876752
reward_min: -114.86624649859945
queue_len: 0.07339946367583285
wait_time: 0.6979146543674942
delay_time: 4.553798910485506
pressure: 0.9059460654288239
total_envstep_count: 544968
total_train_sample_count: 544968
total_episode_count: 4698
total_duration: 32790.649081370095
[2024-12-27 21:10:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.331668223064735
avg_train_sample_per_sec: 17.331668223064735
avg_episode_per_sec: 0.1494109329574546
collect_time: 40.15770386567712
reward_mean: -112.19899626517274
reward_std: 3.8032782890899304
reward_max: -106.62324929971989
reward_min: -117.78221288515405
queue_len: 0.0744025174172233
wait_time: 0.7091076041380299
delay_time: 4.625866422426226
pressure: 0.9119142351900972
total_envstep_count: 545664
total_train_sample_count: 545664
total_episode_count: 4704
total_duration: 32830.80678523577
[2024-12-27 21:11:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.028089475992573
avg_train_sample_per_sec: 17.028089475992573
avg_episode_per_sec: 0.14679387479303943
collect_time: 40.87364005112088
reward_mean: -110.65697945845004
reward_std: 2.1857326495798857
reward_max: -108.34943977591037
reward_min: -115.27310924369745
queue_len: 0.07337995985308358
wait_time: 0.6951067230605772
delay_time: 4.565457369467719
pressure: 0.9025198938992042
total_envstep_count: 546360
total_train_sample_count: 546360
total_episode_count: 4710
total_duration: 32871.68042528689
[2024-12-27 21:12:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16865988004631
avg_train_sample_per_sec: 17.16865988004631
avg_episode_per_sec: 0.14800568862108887
collect_time: 40.53898235871644
reward_mean: -111.20961718020543
reward_std: 3.041954598371522
reward_max: -106.8557422969188
reward_min: -115.16036414565825
queue_len: 0.0737464304908524
wait_time: 0.7053529634665536
delay_time: 4.578835784204361
pressure: 0.9066091954022989
total_envstep_count: 547056
total_train_sample_count: 547056
total_episode_count: 4716
total_duration: 32912.21940764561
[2024-12-27 21:12:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.217903417080972
avg_train_sample_per_sec: 17.217903417080972
avg_episode_per_sec: 0.1484302018713877
collect_time: 40.42304008451663
reward_mean: -110.97140522875817
reward_std: 2.531427350125916
reward_max: -106.69117647058822
reward_min: -115.07843137254903
queue_len: 0.07358846500580782
wait_time: 0.7022380791397018
delay_time: 4.550330910769107
pressure: 0.897656940760389
total_envstep_count: 547752
total_train_sample_count: 547752
total_episode_count: 4722
total_duration: 32952.642447730126
[2024-12-27 21:13:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.59934912567874
avg_train_sample_per_sec: 17.59934912567874
avg_episode_per_sec: 0.15171852694550636
collect_time: 39.54691704959049
reward_mean: -114.71767040149393
reward_std: 2.5363949550932117
reward_max: -111.17226890756301
reward_min: -118.25000000000004
queue_len: 0.07607272573043365
wait_time: 0.7326930661743035
delay_time: 4.7320878354143305
pressure: 0.9353448275862069
total_envstep_count: 548448
total_train_sample_count: 548448
total_episode_count: 4728
total_duration: 32992.18936477972
[2024-12-27 21:14:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.308463417968785
avg_train_sample_per_sec: 17.308463417968785
avg_episode_per_sec: 0.14921089153421366
collect_time: 40.21154178697616
reward_mean: -115.66619981325863
reward_std: 3.396081732986678
reward_max: -111.88865546218486
reward_min: -122.62114845938372
queue_len: 0.07670172401409724
wait_time: 0.7300065693828369
delay_time: 4.7620498552082475
pressure: 0.9345711759504862
total_envstep_count: 549144
total_train_sample_count: 549144
total_episode_count: 4734
total_duration: 33032.4009065667
[2024-12-27 21:14:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.162289226855812
avg_train_sample_per_sec: 17.162289226855812
avg_episode_per_sec: 0.14795076919703287
collect_time: 40.554030455965545
reward_mean: -112.63211951447249
reward_std: 2.1648464211257346
reward_max: -108.671568627451
reward_min: -115.51890756302521
queue_len: 0.07468973442604274
wait_time: 0.7143274307954836
delay_time: 4.573529095221553
pressure: 0.9084880636604775
total_envstep_count: 549840
total_train_sample_count: 549840
total_episode_count: 4740
total_duration: 33072.95493702267
[2024-12-27 21:15:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.348316131801038
avg_train_sample_per_sec: 17.348316131801038
avg_episode_per_sec: 0.1495544494120779
collect_time: 40.11916745765134
reward_mean: -111.69666199813258
reward_std: 5.168034101331753
reward_max: -105.60574229691875
reward_min: -120.90406162464984
queue_len: 0.07406940450804547
wait_time: 0.7088432963813288
delay_time: 4.563129309256672
pressure: 0.9018567639257294
total_envstep_count: 550536
total_train_sample_count: 550536
total_episode_count: 4746
total_duration: 33113.07410448032
[2024-12-27 21:16:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.082994920168044
avg_train_sample_per_sec: 17.082994920168044
avg_episode_per_sec: 0.14726719758765558
collect_time: 40.74227050072514
reward_mean: -114.21498599439775
reward_std: 3.760023864045093
reward_max: -109.4488795518207
reward_min: -119.38865546218489
queue_len: 0.07573938063288976
wait_time: 0.7273957659987073
delay_time: 4.705704681755417
pressure: 0.9228558797524314
total_envstep_count: 551232
total_train_sample_count: 551232
total_episode_count: 4752
total_duration: 33153.81637498105
[2024-12-27 21:16:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.235178478698646
avg_train_sample_per_sec: 17.235178478698646
avg_episode_per_sec: 0.14857912481636765
collect_time: 40.38252350332214
reward_mean: -109.67320261437906
reward_std: 1.4235835041527418
reward_max: -106.91176470588233
reward_min: -111.16036414565825
queue_len: 0.07272758794056967
wait_time: 0.6922268907563024
delay_time: 4.496700156533421
pressure: 0.886604774535809
total_envstep_count: 551928
total_train_sample_count: 551928
total_episode_count: 4758
total_duration: 33194.19889848437
[2024-12-27 21:17:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.292497769311485
avg_train_sample_per_sec: 17.292497769311485
avg_episode_per_sec: 0.14907325663199555
collect_time: 40.24866790702566
reward_mean: -109.9939309056956
reward_std: 1.6452998729019308
reward_max: -108.44047619047622
reward_min: -113.33963585434174
queue_len: 0.07294027248388303
wait_time: 0.695136443171433
delay_time: 4.608573341410907
pressure: 0.8892572944297082
total_envstep_count: 552624
total_train_sample_count: 552624
total_episode_count: 4764
total_duration: 33234.4475663914
[2024-12-27 21:18:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18725451317823
avg_train_sample_per_sec: 17.18725451317823
avg_episode_per_sec: 0.14816598718257096
collect_time: 40.495123841119934
reward_mean: -110.84768907563023
reward_std: 2.703847342547604
reward_max: -107.6351540616246
reward_min: -114.84383753501402
queue_len: 0.07350642511646567
wait_time: 0.7014980948170604
delay_time: 4.585307316908545
pressure: 0.8984305923961097
total_envstep_count: 553320
total_train_sample_count: 553320
total_episode_count: 4770
total_duration: 33274.94269023252
[2024-12-27 21:18:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.024111576633437
avg_train_sample_per_sec: 17.024111576633437
avg_episode_per_sec: 0.1467595825571848
collect_time: 40.88319069497287
reward_mean: -112.01073762838469
reward_std: 2.9586603976654406
reward_max: -106.66946778711484
reward_min: -115.30672268907566
queue_len: 0.07427767747240364
wait_time: 0.7111709073549842
delay_time: 4.602409031717285
pressure: 0.9090406719717065
total_envstep_count: 554016
total_train_sample_count: 554016
total_episode_count: 4776
total_duration: 33315.82588092749
[2024-12-27 21:19:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.32325578908384
avg_train_sample_per_sec: 17.32325578908384
avg_episode_per_sec: 0.14933841197486072
collect_time: 40.1772050516382
reward_mean: -113.03629785247432
reward_std: 2.9228885837933762
reward_max: -109.64565826330532
reward_min: -117.65896358543415
queue_len: 0.07495775719660101
wait_time: 0.7179981740706891
delay_time: 4.671186302685746
pressure: 0.9168877099911583
total_envstep_count: 554712
total_train_sample_count: 554712
total_episode_count: 4782
total_duration: 33356.00308597913
[2024-12-27 21:20:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.006265013111125
avg_train_sample_per_sec: 17.006265013111125
avg_episode_per_sec: 0.14660573287164763
collect_time: 40.92609396968781
reward_mean: -110.5249766573296
reward_std: 3.3838092650605485
reward_max: -104.96638655462183
reward_min: -115.75770308123246
queue_len: 0.07329242483907798
wait_time: 0.6995895838441477
delay_time: 4.5330197118905575
pressure: 0.8985411140583554
total_envstep_count: 555408
total_train_sample_count: 555408
total_episode_count: 4788
total_duration: 33396.92917994882
[2024-12-27 21:20:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.063035341303895
avg_train_sample_per_sec: 17.063035341303895
avg_episode_per_sec: 0.1470951322526198
collect_time: 40.78992899435759
reward_mean: -112.95459850606909
reward_std: 2.9816566877427055
reward_max: -109.40336134453781
reward_min: -116.34803921568628
queue_len: 0.0749035799111864
wait_time: 0.7240867721978268
delay_time: 4.626691943643643
pressure: 0.9173297966401415
total_envstep_count: 556104
total_train_sample_count: 556104
total_episode_count: 4794
total_duration: 33437.71910894318
[2024-12-27 21:21:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.31676325844136
avg_train_sample_per_sec: 17.31676325844136
avg_episode_per_sec: 0.14928244188311518
collect_time: 40.192268590420476
reward_mean: -110.9673202614379
reward_std: 3.7067839634464868
reward_max: -106.8361344537815
reward_min: -116.7717086834734
queue_len: 0.07358575614153708
wait_time: 0.7066546888428227
delay_time: 4.530870347518613
pressure: 0.9041777188328912
total_envstep_count: 556800
total_train_sample_count: 556800
total_episode_count: 4800
total_duration: 33477.9113775336
[2024-12-27 21:22:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.10875548755941
avg_train_sample_per_sec: 17.10875548755941
avg_episode_per_sec: 0.14748927144447768
collect_time: 40.68092506822572
reward_mean: -111.22945845004669
reward_std: 4.1529243532661555
reward_max: -106.02521008403363
reward_min: -116.70728291316529
queue_len: 0.07375958783159596
wait_time: 0.7069817648544828
delay_time: 4.5746987971348645
pressure: 0.9040671971706454
total_envstep_count: 557496
total_train_sample_count: 557496
total_episode_count: 4806
total_duration: 33518.59230260183
[2024-12-27 21:22:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.489709901614308
avg_train_sample_per_sec: 17.489709901614308
avg_episode_per_sec: 0.150773361220813
collect_time: 39.794828154111286
reward_mean: -109.08776844070964
reward_std: 4.6093146020977285
reward_max: -101.24299719887959
reward_min: -114.99859943977592
queue_len: 0.07233936899251303
wait_time: 0.6899274519710626
delay_time: 4.494308674377067
pressure: 0.8842838196286472
total_envstep_count: 558192
total_train_sample_count: 558192
total_episode_count: 4812
total_duration: 33558.38713075594
[2024-12-27 21:23:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.24407138851556
avg_train_sample_per_sec: 17.24407138851556
avg_episode_per_sec: 0.1486557878320307
collect_time: 40.36169790294022
reward_mean: -109.77205882352943
reward_std: 3.2141865127626463
reward_max: -104.2535014005602
reward_min: -115.0371148459384
queue_len: 0.07279314245592138
wait_time: 0.6969708860555716
delay_time: 4.597653993110597
pressure: 0.875
total_envstep_count: 558888
total_train_sample_count: 558888
total_episode_count: 4818
total_duration: 33598.74882865888
[2024-12-27 21:24:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.351204292793316
avg_train_sample_per_sec: 17.351204292793316
avg_episode_per_sec: 0.14957934735166653
collect_time: 40.11248949959502
reward_mean: -108.63036881419235
reward_std: 2.2516597620882783
reward_max: -105.02941176470591
reward_min: -111.52030812324928
queue_len: 0.07203605359031322
wait_time: 0.6856027888609025
delay_time: 4.4936462889025925
pressure: 0.8793103448275863
total_envstep_count: 559584
total_train_sample_count: 559584
total_episode_count: 4824
total_duration: 33638.86131815847
[2024-12-27 21:25:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.232765930272045
avg_train_sample_per_sec: 17.232765930272045
avg_episode_per_sec: 0.14855832698510382
collect_time: 40.38817696568183
reward_mean: -112.18277310924368
reward_std: 1.5830874986882162
reward_max: -108.82002801120446
reward_min: -113.7471988795518
queue_len: 0.07439175935626238
wait_time: 0.7118227374946442
delay_time: 4.6332664016330405
pressure: 0.9052829354553493
total_envstep_count: 560280
total_train_sample_count: 560280
total_episode_count: 4830
total_duration: 33679.24949512415
[2024-12-27 21:25:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.134481570247416
avg_train_sample_per_sec: 17.134481570247416
avg_episode_per_sec: 0.1477110480193743
collect_time: 40.619845843981956
reward_mean: -114.09010270774978
reward_std: 2.5905446787360202
reward_max: -110.11484593837534
reward_min: -117.67717086834736
queue_len: 0.07565656678232742
wait_time: 0.7235140408948725
delay_time: 4.657333513442205
pressure: 0.9355658709106985
total_envstep_count: 560976
total_train_sample_count: 560976
total_episode_count: 4836
total_duration: 33719.86934096814
[2024-12-27 21:26:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.315979117574592
avg_train_sample_per_sec: 17.315979117574592
avg_episode_per_sec: 0.14927568204805683
collect_time: 40.19408866655454
reward_mean: -110.9938141923436
reward_std: 3.1694926309389437
reward_max: -106.19887955182071
reward_min: -116.42016806722688
queue_len: 0.07360332506123583
wait_time: 0.705453268840693
delay_time: 4.595173880831184
pressure: 0.9024093722369585
total_envstep_count: 561672
total_train_sample_count: 561672
total_episode_count: 4842
total_duration: 33760.06342963469
[2024-12-27 21:27:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45651300523885
avg_train_sample_per_sec: 17.45651300523885
avg_episode_per_sec: 0.15048718107964526
collect_time: 39.870505626818165
reward_mean: -112.56477591036416
reward_std: 4.218675030166829
reward_max: -107.67577030812326
reward_min: -119.7703081232493
queue_len: 0.07464507686363671
wait_time: 0.7138358106284071
delay_time: 4.666065555352617
pressure: 0.9055039787798407
total_envstep_count: 562368
total_train_sample_count: 562368
total_episode_count: 4848
total_duration: 33799.933935261506
[2024-12-27 21:27:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.32262266797141
avg_train_sample_per_sec: 17.32262266797141
avg_episode_per_sec: 0.1493329540342363
collect_time: 40.17867348036543
reward_mean: -109.29154995331466
reward_std: 2.9014666726231253
reward_max: -103.7093837535014
reward_min: -113.56442577030815
queue_len: 0.07247450262156144
wait_time: 0.6945476134750983
delay_time: 4.48547142657137
pressure: 0.8806366047745358
total_envstep_count: 563064
total_train_sample_count: 563064
total_episode_count: 4854
total_duration: 33840.112608741874
[2024-12-27 21:28:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.402714893105635
avg_train_sample_per_sec: 17.402714893105635
avg_episode_per_sec: 0.15002340425091065
collect_time: 39.99375984006562
reward_mean: -108.93895891690009
reward_std: 1.8821873909721711
reward_max: -105.68347338935574
reward_min: -111.35714285714282
queue_len: 0.0722406889369364
wait_time: 0.6869148079214003
delay_time: 4.41362060971986
pressure: 0.8831786030061891
total_envstep_count: 563760
total_train_sample_count: 563760
total_episode_count: 4860
total_duration: 33880.10636858194
[2024-12-27 21:29:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.19516755153741
avg_train_sample_per_sec: 17.19516755153741
avg_episode_per_sec: 0.1482342030304949
collect_time: 40.4764884037301
reward_mean: -110.20063025210084
reward_std: 4.646268280990148
reward_max: -100.60854341736692
reward_min: -115.65336134453781
queue_len: 0.073077341015982
wait_time: 0.7005455807433497
delay_time: 4.526319701639022
pressure: 0.896551724137931
total_envstep_count: 564456
total_train_sample_count: 564456
total_episode_count: 4866
total_duration: 33920.58285698567
[2024-12-27 21:29:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.316330030078802
avg_train_sample_per_sec: 17.316330030078802
avg_episode_per_sec: 0.14927870715585173
collect_time: 40.193274140134456
reward_mean: -111.9780578898226
reward_std: 3.1267295706918317
reward_max: -107.45448179271713
reward_min: -116.3886554621849
queue_len: 0.07425600655823779
wait_time: 0.7148719125139005
delay_time: 4.62002864480614
pressure: 0.907051282051282
total_envstep_count: 565152
total_train_sample_count: 565152
total_episode_count: 4872
total_duration: 33960.7761311258
[2024-12-27 21:30:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.38888158645876
avg_train_sample_per_sec: 17.38888158645876
avg_episode_per_sec: 0.14990415160740309
collect_time: 40.02557591409421
reward_mean: -108.87698412698414
reward_std: 3.397100029436482
reward_max: -101.96568627450982
reward_min: -112.88445378151259
queue_len: 0.07219959159614332
wait_time: 0.6893631568454083
delay_time: 4.508389877626055
pressure: 0.8763262599469496
total_envstep_count: 565848
total_train_sample_count: 565848
total_episode_count: 4878
total_duration: 34000.80170703989
[2024-12-27 21:31:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.50999398154752
avg_train_sample_per_sec: 17.50999398154752
avg_episode_per_sec: 0.15094822397885793
collect_time: 39.748728682229284
reward_mean: -111.33169934640523
reward_std: 2.9329544347932432
reward_max: -107.13865546218487
reward_min: -116.23529411764709
queue_len: 0.07382738683448624
wait_time: 0.710152993558166
delay_time: 4.560468908901146
pressure: 0.9029619805481874
total_envstep_count: 566544
total_train_sample_count: 566544
total_episode_count: 4884
total_duration: 34040.55043572212
[2024-12-27 21:31:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.52203406271139
avg_train_sample_per_sec: 17.52203406271139
avg_episode_per_sec: 0.15105201778199473
collect_time: 39.72141576194949
reward_mean: -113.0668767507003
reward_std: 2.5017407685993756
reward_max: -110.11624649859944
reward_min: -117.48529411764707
queue_len: 0.07497803498057048
wait_time: 0.7222500848261498
delay_time: 4.6416825591790625
pressure: 0.9151193633952254
total_envstep_count: 567240
total_train_sample_count: 567240
total_episode_count: 4890
total_duration: 34080.271851484074
[2024-12-27 21:32:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.999776199426897
avg_train_sample_per_sec: 16.999776199426897
avg_episode_per_sec: 0.14654979482264568
collect_time: 40.941715457610776
reward_mean: -110.64355742296921
reward_std: 2.2109746994976462
reward_max: -107.61974789915968
reward_min: -113.68697478991601
queue_len: 0.07337105929905119
wait_time: 0.7046719549888921
delay_time: 4.579427457532229
pressure: 0.8908045977011493
total_envstep_count: 567936
total_train_sample_count: 567936
total_episode_count: 4896
total_duration: 34121.21356694168
[2024-12-27 21:33:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17402846490793
avg_train_sample_per_sec: 17.17402846490793
avg_episode_per_sec: 0.14805196952506836
collect_time: 40.526309911629184
reward_mean: -110.86192810457516
reward_std: 4.065981786220599
reward_max: -103.23949579831934
reward_min: -115.81092436974791
queue_len: 0.07351586744335224
wait_time: 0.7003380043440895
delay_time: 4.5894863518118925
pressure: 0.899867374005305
total_envstep_count: 568632
total_train_sample_count: 568632
total_episode_count: 4902
total_duration: 34161.73987685331
[2024-12-27 21:33:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.28977091097799
avg_train_sample_per_sec: 17.28977091097799
avg_episode_per_sec: 0.1490497492325689
collect_time: 40.2550157306064
reward_mean: -114.46930438842203
reward_std: 2.9745435498331445
reward_max: -110.06792717086833
reward_min: -119.6764705882353
queue_len: 0.07590802678277322
wait_time: 0.7254804441670567
delay_time: 4.730419529680799
pressure: 0.9229664014146772
total_envstep_count: 569328
total_train_sample_count: 569328
total_episode_count: 4908
total_duration: 34201.99489258391
[2024-12-27 21:34:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.057376964404913
avg_train_sample_per_sec: 17.057376964404913
avg_episode_per_sec: 0.14704635314142167
collect_time: 40.80346007785386
reward_mean: -112.58625116713353
reward_std: 3.2645653180139353
reward_max: -107.2626050420168
reward_min: -116.01120448179267
queue_len: 0.07465931775008854
wait_time: 0.7115580427573329
delay_time: 4.648318636449135
pressure: 0.9025198938992043
total_envstep_count: 570024
total_train_sample_count: 570024
total_episode_count: 4914
total_duration: 34242.79835266177
[2024-12-27 21:35:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.977253774100898
avg_train_sample_per_sec: 16.977253774100898
avg_episode_per_sec: 0.14635563598362844
collect_time: 40.9960297030937
reward_mean: -111.38013538748834
reward_std: 0.8242812956764463
reward_max: -110.07492997198878
reward_min: -112.7773109243697
queue_len: 0.0738595062251249
wait_time: 0.7094448964377972
delay_time: 4.574183271180561
pressure: 0.9080459770114943
total_envstep_count: 570720
total_train_sample_count: 570720
total_episode_count: 4920
total_duration: 34283.79438236486
[2024-12-27 21:35:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.087840439132876
avg_train_sample_per_sec: 17.087840439132876
avg_episode_per_sec: 0.14730896930286963
collect_time: 40.730717405699195
reward_mean: -112.26797385620915
reward_std: 2.248828553630329
reward_max: -109.45588235294119
reward_min: -116.80462184873954
queue_len: 0.07444825852533764
wait_time: 0.709207754719925
delay_time: 4.659693865575741
pressure: 0.9104774535809019
total_envstep_count: 571416
total_train_sample_count: 571416
total_episode_count: 4926
total_duration: 34324.52509977056
[2024-12-27 21:36:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.083959123422673
avg_train_sample_per_sec: 17.083959123422673
avg_episode_per_sec: 0.1472755096846782
collect_time: 40.73997104370034
reward_mean: -111.39647525676935
reward_std: 1.8385961771347334
reward_max: -107.69397759103644
reward_min: -113.03991596638653
queue_len: 0.0738703416822078
wait_time: 0.7071871741623262
delay_time: 4.59101912134289
pressure: 0.8994252873563219
total_envstep_count: 572112
total_train_sample_count: 572112
total_episode_count: 4932
total_duration: 34365.26507081426
[2024-12-27 21:37:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.014038321491718
avg_train_sample_per_sec: 17.014038321491718
avg_episode_per_sec: 0.14667274415079068
collect_time: 40.90739581330493
reward_mean: -110.56465919701213
reward_std: 2.961307674036286
reward_max: -107.44817927170867
reward_min: -115.59803921568626
queue_len: 0.07331873952056507
wait_time: 0.7045390658473822
delay_time: 4.585694121593721
pressure: 0.8938992042440318
total_envstep_count: 572808
total_train_sample_count: 572808
total_episode_count: 4938
total_duration: 34406.17246662757
[2024-12-27 21:38:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.012121636970903
avg_train_sample_per_sec: 17.012121636970903
avg_episode_per_sec: 0.14665622100836986
collect_time: 40.91200467832573
reward_mean: -111.15126050420172
reward_std: 1.7481935835757845
reward_max: -108.9257703081233
reward_min: -113.26050420168067
queue_len: 0.07370773242984197
wait_time: 0.7044937891159998
delay_time: 4.545765168244529
pressure: 0.8958885941644562
total_envstep_count: 573504
total_train_sample_count: 573504
total_episode_count: 4944
total_duration: 34447.0844713059
[2024-12-27 21:38:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.361797639580256
avg_train_sample_per_sec: 17.361797639580256
avg_episode_per_sec: 0.14967066930672634
collect_time: 40.088014757947995
reward_mean: -113.55205415499533
reward_std: 4.3931586125463475
reward_max: -106.90126050420172
reward_min: -118.58053221288523
queue_len: 0.07529977065981124
wait_time: 0.7204064318034907
delay_time: 4.684639885399708
pressure: 0.9241821396993811
total_envstep_count: 574200
total_train_sample_count: 574200
total_episode_count: 4950
total_duration: 34487.17248606384
[2024-12-27 21:39:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.204596996465472
avg_train_sample_per_sec: 17.204596996465472
avg_episode_per_sec: 0.14831549134884028
collect_time: 40.45430416899546
reward_mean: -110.55637254901957
reward_std: 2.658917654322088
reward_max: -107.05182072829136
reward_min: -113.5672268907563
queue_len: 0.0733132443959016
wait_time: 0.7053455334388398
delay_time: 4.607059598736545
pressure: 0.8972148541114059
total_envstep_count: 574896
total_train_sample_count: 574896
total_episode_count: 4956
total_duration: 34527.62679023284
[2024-12-27 21:40:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.28096032065169
avg_train_sample_per_sec: 17.28096032065169
avg_episode_per_sec: 0.148973795867687
collect_time: 40.27553950044327
reward_mean: -111.15546218487395
reward_std: 2.9024958026251952
reward_max: -105.41666666666671
reward_min: -115.18697478991596
queue_len: 0.07371051869023472
wait_time: 0.7038154895026091
delay_time: 4.555205540021107
pressure: 0.9032935455349249
total_envstep_count: 575592
total_train_sample_count: 575592
total_episode_count: 4962
total_duration: 34567.90232973328
[2024-12-27 21:40:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17524317601404
avg_train_sample_per_sec: 17.17524317601404
avg_episode_per_sec: 0.1480624411725348
collect_time: 40.52344370716065
reward_mean: -110.91211484593838
reward_std: 1.950277377555927
reward_max: -107.91736694677871
reward_min: -113.67436974789916
queue_len: 0.0735491477758212
wait_time: 0.704063853658174
delay_time: 4.608568237757593
pressure: 0.8989832007073387
total_envstep_count: 576288
total_train_sample_count: 576288
total_episode_count: 4968
total_duration: 34608.425773440445
[2024-12-27 21:41:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.41366435845165
avg_train_sample_per_sec: 17.41366435845165
avg_episode_per_sec: 0.1501177961935487
collect_time: 39.96861233070679
reward_mean: -111.52999533146591
reward_std: 3.5949955991957134
reward_max: -107.73389355742299
reward_min: -118.27240896358545
queue_len: 0.0739588828457997
wait_time: 0.7082815553277014
delay_time: 4.586226748561921
pressure: 0.90263041556145
total_envstep_count: 576984
total_train_sample_count: 576984
total_episode_count: 4974
total_duration: 34648.39438577115
[2024-12-27 21:42:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.338893765859442
avg_train_sample_per_sec: 17.338893765859442
avg_episode_per_sec: 0.14947322211947794
collect_time: 40.14096916439012
reward_mean: -110.11367880485528
reward_std: 2.3867911076391564
reward_max: -107.71778711484596
reward_min: -114.49929971988801
queue_len: 0.07301968090507646
wait_time: 0.6984839802410797
delay_time: 4.571388363859463
pressure: 0.889920424403183
total_envstep_count: 577680
total_train_sample_count: 577680
total_episode_count: 4980
total_duration: 34688.53535493554
[2024-12-27 21:42:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.24671605818475
avg_train_sample_per_sec: 17.24671605818475
avg_episode_per_sec: 0.1486785867084892
collect_time: 40.355508703913536
reward_mean: -109.19934640522877
reward_std: 2.530295544847332
reward_max: -106.05042016806728
reward_min: -112.13655462184877
queue_len: 0.07241335968516498
wait_time: 0.6896863630509676
delay_time: 4.545905480880133
pressure: 0.8934571175950485
total_envstep_count: 578376
total_train_sample_count: 578376
total_episode_count: 4986
total_duration: 34728.890863639455
[2024-12-27 21:43:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.133014474711615
avg_train_sample_per_sec: 17.133014474711615
avg_episode_per_sec: 0.14769840064406564
collect_time: 40.62332411072776
reward_mean: -111.53839869281046
reward_std: 2.0755950651945945
reward_max: -108.78781512605036
reward_min: -115.04131652661066
queue_len: 0.07396445536658519
wait_time: 0.7061520784264191
delay_time: 4.611292188935278
pressure: 0.9093722369584438
total_envstep_count: 579072
total_train_sample_count: 579072
total_episode_count: 4992
total_duration: 34769.51418775018
[2024-12-27 21:44:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.095101560791875
avg_train_sample_per_sec: 17.095101560791875
avg_episode_per_sec: 0.1473715651792403
collect_time: 40.71341708763502
reward_mean: -110.25746965452849
reward_std: 1.6944190885644124
reward_max: -108.24019607843135
reward_min: -113.34733893557424
queue_len: 0.07311503292740615
wait_time: 0.6955118143632343
delay_time: 4.54771686926176
pressure: 0.8978779840848806
total_envstep_count: 579768
total_train_sample_count: 579768
total_episode_count: 4998
total_duration: 34810.22760483782
[2024-12-27 21:44:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17154191195171
avg_train_sample_per_sec: 17.17154191195171
avg_episode_per_sec: 0.14803053372372163
collect_time: 40.53217838961632
reward_mean: -114.40499533146591
reward_std: 2.4080927147464375
reward_max: -111.02450980392155
reward_min: -117.51400560224093
queue_len: 0.07586538151953974
wait_time: 0.7232763574041464
delay_time: 4.764659404065311
pressure: 0.9245137046861185
total_envstep_count: 580464
total_train_sample_count: 580464
total_episode_count: 5004
total_duration: 34850.75978322743
[2024-12-27 21:45:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.285671205103796
avg_train_sample_per_sec: 17.285671205103796
avg_episode_per_sec: 0.14901440694054996
collect_time: 40.26456315994822
reward_mean: -111.22537348272641
reward_std: 3.9381274388749534
reward_max: -105.48669467787116
reward_min: -115.9908963585434
queue_len: 0.0737568789673252
wait_time: 0.7002263217400135
delay_time: 4.648705947784014
pressure: 0.9026304155614501
total_envstep_count: 581160
total_train_sample_count: 581160
total_episode_count: 5010
total_duration: 34891.024346387385
[2024-12-27 21:46:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.39957215074423
avg_train_sample_per_sec: 17.39957215074423
avg_episode_per_sec: 0.14999631164434682
collect_time: 40.00098358569294
reward_mean: -109.4440943043884
reward_std: 3.6783401368219786
reward_max: -105.00070028011203
reward_min: -116.44537815126051
queue_len: 0.07257565935304272
wait_time: 0.6939597125322278
delay_time: 4.523987555158535
pressure: 0.8945623342175066
total_envstep_count: 581856
total_train_sample_count: 581856
total_episode_count: 5016
total_duration: 34931.025329973076
[2024-12-27 21:46:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.32160201362319
avg_train_sample_per_sec: 17.32160201362319
avg_episode_per_sec: 0.1493241552898551
collect_time: 40.181040959872306
reward_mean: -108.14694211017739
reward_std: 1.6426244666544982
reward_max: -105.76750700280105
reward_min: -110.49439775910365
queue_len: 0.07171547885290279
wait_time: 0.6837317376110481
delay_time: 4.5003749624477605
pressure: 0.8852785145888594
total_envstep_count: 582552
total_train_sample_count: 582552
total_episode_count: 5022
total_duration: 34971.206370932945
[2024-12-27 21:47:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.463039920111434
avg_train_sample_per_sec: 17.463039920111434
avg_episode_per_sec: 0.15054344758716753
collect_time: 39.8556037885733
reward_mean: -110.93300653594774
reward_std: 4.043023115060913
reward_max: -105.2927170868348
reward_min: -116.20798319327731
queue_len: 0.07356300168166295
wait_time: 0.7040195056802562
delay_time: 4.575702842707816
pressure: 0.9035145888594164
total_envstep_count: 583248
total_train_sample_count: 583248
total_episode_count: 5028
total_duration: 35011.06197472152
[2024-12-27 21:48:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.18431567796071
avg_train_sample_per_sec: 17.18431567796071
avg_episode_per_sec: 0.14814065239621302
collect_time: 40.50204925487003
reward_mean: -108.27042483660131
reward_std: 5.362005101655653
reward_max: -101.90476190476193
reward_min: -118.05672268907563
queue_len: 0.07179736395000087
wait_time: 0.6811597870801726
delay_time: 4.490308507878989
pressure: 0.8806366047745359
total_envstep_count: 583944
total_train_sample_count: 583944
total_episode_count: 5034
total_duration: 35051.56402397639
[2024-12-27 21:48:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51140938032274
avg_train_sample_per_sec: 17.51140938032274
avg_episode_per_sec: 0.15096042569243742
collect_time: 39.745515902454024
reward_mean: -112.59897292250234
reward_std: 1.6999969896941438
reward_max: -109.63375350140058
reward_min: -114.83963585434175
queue_len: 0.07466775392738881
wait_time: 0.7164637185555036
delay_time: 4.663543519615502
pressure: 0.9094827586206896
total_envstep_count: 584640
total_train_sample_count: 584640
total_episode_count: 5040
total_duration: 35091.30953987884
[2024-12-27 21:49:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.975713759746483
avg_train_sample_per_sec: 16.975713759746483
avg_episode_per_sec: 0.14634235999781453
collect_time: 40.99974880881793
reward_mean: -110.68674136321196
reward_std: 2.2947365671077904
reward_max: -106.0420168067227
reward_min: -113.20098039215694
queue_len: 0.07339969586419891
wait_time: 0.6991524505469738
delay_time: 4.603988243236956
pressure: 0.899314765694076
total_envstep_count: 585336
total_train_sample_count: 585336
total_episode_count: 5046
total_duration: 35132.30928868766
[2024-12-27 21:50:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.264028204677935
avg_train_sample_per_sec: 17.264028204677935
avg_episode_per_sec: 0.14882782935067185
collect_time: 40.31504071636125
reward_mean: -111.72735760971052
reward_std: 3.7687220069256266
reward_max: -107.70028011204477
reward_min: -118.91736694677869
queue_len: 0.07408975968813696
wait_time: 0.7102351882397521
delay_time: 4.6254849672613245
pressure: 0.9026304155614501
total_envstep_count: 586032
total_train_sample_count: 586032
total_episode_count: 5052
total_duration: 35172.624329404025
[2024-12-27 21:50:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.355508026725907
avg_train_sample_per_sec: 17.355508026725907
avg_episode_per_sec: 0.14961644850625783
collect_time: 40.1025426007826
reward_mean: -110.63818860877684
reward_std: 2.781039883632338
reward_max: -106.89635854341738
reward_min: -114.90266106442576
queue_len: 0.07336749907743821
wait_time: 0.6979706891598373
delay_time: 4.613563070665743
pressure: 0.8953359858532273
total_envstep_count: 586728
total_train_sample_count: 586728
total_episode_count: 5058
total_duration: 35212.72687200481
[2024-12-27 21:51:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.392894395814285
avg_train_sample_per_sec: 17.392894395814285
avg_episode_per_sec: 0.14993874479150243
collect_time: 40.01634139556997
reward_mean: -108.06827731092437
reward_std: 2.8547894201327244
reward_max: -104.21148459383751
reward_min: -111.44117647058825
queue_len: 0.07166331386666074
wait_time: 0.6828523628726467
delay_time: 4.561757091794776
pressure: 0.8734526967285589
total_envstep_count: 587424
total_train_sample_count: 587424
total_episode_count: 5064
total_duration: 35252.743213400376
[2024-12-27 21:52:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.38210399871795
avg_train_sample_per_sec: 17.38210399871795
avg_episode_per_sec: 0.1498457241268789
collect_time: 40.04118258936517
reward_mean: -110.51318860877684
reward_std: 2.902174753251199
reward_max: -105.4978991596639
reward_min: -114.56582633053225
queue_len: 0.07328460783075388
wait_time: 0.6968483679944125
delay_time: 4.622601152152471
pressure: 0.8975464190981434
total_envstep_count: 588120
total_train_sample_count: 588120
total_episode_count: 5070
total_duration: 35292.784395989744
[2024-12-27 21:53:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37397288459507
avg_train_sample_per_sec: 17.37397288459507
avg_episode_per_sec: 0.14977562831547472
collect_time: 40.05992208132893
reward_mean: -110.61869747899159
reward_std: 1.967814558906276
reward_max: -108.83403361344536
reward_min: -114.47338935574228
queue_len: 0.07335457392506074
wait_time: 0.7007536989154638
delay_time: 4.6109744264719135
pressure: 0.8915782493368699
total_envstep_count: 588816
total_train_sample_count: 588816
total_episode_count: 5076
total_duration: 35332.844318071075
[2024-12-27 21:53:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.06546734311355
avg_train_sample_per_sec: 17.06546734311355
avg_episode_per_sec: 0.14711609778546164
collect_time: 40.784116016656164
reward_mean: -109.3453548085901
reward_std: 2.6078373209076884
reward_max: -105.77731092436973
reward_min: -114.37815126050423
queue_len: 0.07251018223381306
wait_time: 0.6952429402353335
delay_time: 4.49538065040889
pressure: 0.8986516357206012
total_envstep_count: 589512
total_train_sample_count: 589512
total_episode_count: 5082
total_duration: 35373.62843408773
[2024-12-27 21:54:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.260052646736852
avg_train_sample_per_sec: 17.260052646736852
avg_episode_per_sec: 0.14879355729945562
collect_time: 40.324326596511526
reward_mean: -107.81220821661998
reward_std: 3.657723341477954
reward_max: -103.12675070028014
reward_min: -114.36414565826328
queue_len: 0.07149350677494692
wait_time: 0.6823226638135361
delay_time: 4.51126260784815
pressure: 0.8744473916887708
total_envstep_count: 590208
total_train_sample_count: 590208
total_episode_count: 5088
total_duration: 35413.952760684246
[2024-12-27 21:55:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51062886919286
avg_train_sample_per_sec: 17.51062886919286
avg_episode_per_sec: 0.1509536971482143
collect_time: 39.747287501735606
reward_mean: -109.7359943977591
reward_std: 2.320065283083296
reward_max: -106.39285714285715
reward_min: -113.51890756302522
queue_len: 0.0727692270542169
wait_time: 0.6957353343636304
delay_time: 4.519839037534881
pressure: 0.8890362511052166
total_envstep_count: 590904
total_train_sample_count: 590904
total_episode_count: 5094
total_duration: 35453.70004818598
[2024-12-27 21:55:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.22709352392978
avg_train_sample_per_sec: 17.22709352392978
avg_episode_per_sec: 0.14850942693042915
collect_time: 40.40147567743807
reward_mean: -112.69187675070027
reward_std: 3.003950124300474
reward_max: -107.67156862745098
reward_min: -116.65336134453781
queue_len: 0.07472936124051742
wait_time: 0.7137163110160069
delay_time: 4.661846784102725
pressure: 0.9063881520778073
total_envstep_count: 591600
total_train_sample_count: 591600
total_episode_count: 5100
total_duration: 35494.10152386342
[2024-12-27 21:56:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33817364462576
avg_train_sample_per_sec: 17.33817364462576
avg_episode_per_sec: 0.14946701417780825
collect_time: 40.142636373683814
reward_mean: -108.05777310924371
reward_std: 2.056624839471532
reward_max: -104.67997198879556
reward_min: -111.47759103641457
queue_len: 0.07165634821567884
wait_time: 0.6878268438232942
delay_time: 4.496521594801703
pressure: 0.8808576480990272
total_envstep_count: 592296
total_train_sample_count: 592296
total_episode_count: 5106
total_duration: 35534.244160237104
[2024-12-27 21:57:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.43106754574182
avg_train_sample_per_sec: 17.43106754574182
avg_episode_per_sec: 0.15026782367018807
collect_time: 39.92870764648168
reward_mean: -107.90044351073762
reward_std: 2.451788396115048
reward_max: -103.85434173669466
reward_min: -111.23739495798317
queue_len: 0.0715520182431947
wait_time: 0.6790252794309589
delay_time: 4.449082707731458
pressure: 0.8726790450928382
total_envstep_count: 592992
total_train_sample_count: 592992
total_episode_count: 5112
total_duration: 35574.172867883586
[2024-12-27 21:57:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17197218161759
avg_train_sample_per_sec: 17.17197218161759
avg_episode_per_sec: 0.14803424294497922
collect_time: 40.53116279474646
reward_mean: -109.24953314659199
reward_std: 2.7163142409268195
reward_max: -105.27030812324935
reward_min: -113.5217086834734
queue_len: 0.07244664001763393
wait_time: 0.6927314360757566
delay_time: 4.525414388970926
pressure: 0.8812997347480106
total_envstep_count: 593688
total_train_sample_count: 593688
total_episode_count: 5118
total_duration: 35614.70403067833
[2024-12-27 21:58:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.17236001349097
avg_train_sample_per_sec: 17.17236001349097
avg_episode_per_sec: 0.14803758632319802
collect_time: 40.5302474123072
reward_mean: -108.55345471521944
reward_std: 2.78559726672751
reward_max: -105.81092436974791
reward_min: -113.98039215686275
queue_len: 0.07198504954590147
wait_time: 0.6864253548457403
delay_time: 4.538327025900609
pressure: 0.8786472148541115
total_envstep_count: 594384
total_train_sample_count: 594384
total_episode_count: 5124
total_duration: 35655.23427809064
[2024-12-27 21:59:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.840085145032447
avg_train_sample_per_sec: 16.840085145032447
avg_episode_per_sec: 0.14517314780200385
collect_time: 41.32995730162972
reward_mean: -110.2699579831933
reward_std: 4.399683593311653
reward_max: -106.93627450980395
reward_min: -119.34663865546216
queue_len: 0.0731233143124624
wait_time: 0.7053727768737911
delay_time: 4.515321549185961
pressure: 0.8822944297082228
total_envstep_count: 595080
total_train_sample_count: 595080
total_episode_count: 5130
total_duration: 35696.56423539227
[2024-12-27 21:59:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73682871367694
avg_train_sample_per_sec: 16.73682871367694
avg_episode_per_sec: 0.1442830061523874
collect_time: 41.584938933577384
reward_mean: -109.25198412698414
reward_std: 3.0152624876886005
reward_max: -106.75280112044818
reward_min: -114.50490196078434
queue_len: 0.07244826533619637
wait_time: 0.6864268253720586
delay_time: 4.507913639960582
pressure: 0.8829575596816975
total_envstep_count: 595776
total_train_sample_count: 595776
total_episode_count: 5136
total_duration: 35738.149174325845
[2024-12-27 22:00:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.563308867545658
avg_train_sample_per_sec: 16.563308867545658
avg_episode_per_sec: 0.14278714540987636
collect_time: 42.02058933790401
reward_mean: -107.95541549953312
reward_std: 2.395100378350051
reward_max: -103.16036414565825
reward_min: -109.92997198879553
queue_len: 0.07158847181666654
wait_time: 0.6790427709545357
delay_time: 4.479598052717261
pressure: 0.8730106100795757
total_envstep_count: 596472
total_train_sample_count: 596472
total_episode_count: 5142
total_duration: 35780.16976366375
[2024-12-27 22:01:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.539228603021666
avg_train_sample_per_sec: 16.539228603021666
avg_episode_per_sec: 0.14257955692260055
collect_time: 42.08176915051788
reward_mean: -109.76283846872082
reward_std: 3.7667765768628483
reward_max: -105.28641456582633
reward_min: -115.44887955182074
queue_len: 0.07278702816228173
wait_time: 0.6963276468854561
delay_time: 4.527263817547014
pressure: 0.889367816091954
total_envstep_count: 597168
total_train_sample_count: 597168
total_episode_count: 5148
total_duration: 35822.25153281426
[2024-12-27 22:02:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.663253301717756
avg_train_sample_per_sec: 16.663253301717756
avg_episode_per_sec: 0.14364873535963582
collect_time: 41.76855427914859
reward_mean: -110.87254901960785
reward_std: 1.233117984627462
reward_max: -109.09243697478996
reward_min: -113.03851540616245
queue_len: 0.07352291049045613
wait_time: 0.7049264334380968
delay_time: 4.527280263424099
pressure: 0.9008620689655172
total_envstep_count: 597864
total_train_sample_count: 597864
total_episode_count: 5154
total_duration: 35864.02008709341
[2024-12-27 22:02:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5331664537093
avg_train_sample_per_sec: 16.5331664537093
avg_episode_per_sec: 0.14252729701473532
collect_time: 42.09719910270721
reward_mean: -108.94946311858075
reward_std: 1.0682889146142414
reward_max: -107.39775910364142
reward_min: -109.99719887955176
queue_len: 0.07224765458791828
wait_time: 0.6869538155668987
delay_time: 4.491912467950503
pressure: 0.8840627763041556
total_envstep_count: 598560
total_train_sample_count: 598560
total_episode_count: 5160
total_duration: 35906.11728619612
[2024-12-27 22:03:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.64243355059668
avg_train_sample_per_sec: 16.64243355059668
avg_episode_per_sec: 0.1434692547465231
collect_time: 41.820806908076634
reward_mean: -111.07843137254902
reward_std: 1.333128333619637
reward_max: -108.64005602240898
reward_min: -112.80322128851543
queue_len: 0.07365943724970093
wait_time: 0.6996303716004527
delay_time: 4.522843873644387
pressure: 0.9051724137931033
total_envstep_count: 599256
total_train_sample_count: 599256
total_episode_count: 5166
total_duration: 35947.938093104196
[2024-12-27 22:04:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.492138280736235
avg_train_sample_per_sec: 16.492138280736235
avg_episode_per_sec: 0.14217360586841582
collect_time: 42.20192604211717
reward_mean: -109.24638188608778
reward_std: 0.5833927961991854
reward_max: -108.44677871148458
reward_min: -110.09383753501407
queue_len: 0.07244455032233937
wait_time: 0.6872079070354934
delay_time: 4.5441744176318615
pressure: 0.8731211317418214
total_envstep_count: 599952
total_train_sample_count: 599952
total_episode_count: 5172
total_duration: 35990.14001914631
[2024-12-27 22:04:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.563477083282216
avg_train_sample_per_sec: 16.563477083282216
avg_episode_per_sec: 0.14278859554553633
collect_time: 42.020162584248936
reward_mean: -107.37500000000001
reward_std: 1.8393639214558821
reward_max: -104.59943977591037
reward_min: -110.60434173669468
queue_len: 0.07120358090185677
wait_time: 0.6789858848048502
delay_time: 4.463799643890903
pressure: 0.8712422634836429
total_envstep_count: 600648
total_train_sample_count: 600648
total_episode_count: 5178
total_duration: 36032.160181730556
[2024-12-27 22:05:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.694876333238767
avg_train_sample_per_sec: 16.694876333238767
avg_episode_per_sec: 0.1439213477003342
collect_time: 41.68943729246406
reward_mean: -109.50513538748832
reward_std: 3.396319791154787
reward_max: -104.19537815126051
reward_min: -113.46778711484588
queue_len: 0.07261613752485964
wait_time: 0.6908100773465885
delay_time: 4.516158825636219
pressure: 0.8899204244031832
total_envstep_count: 601344
total_train_sample_count: 601344
total_episode_count: 5184
total_duration: 36073.84961902302
[2024-12-27 22:06:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.590110091904883
avg_train_sample_per_sec: 16.590110091904883
avg_episode_per_sec: 0.14301819044745587
collect_time: 41.952705325301736
reward_mean: -108.57551353874884
reward_std: 2.468611105252014
reward_max: -105.08543417366947
reward_min: -111.71638655462186
queue_len: 0.07199967741296341
wait_time: 0.6837040297993644
delay_time: 4.53757092371355
pressure: 0.8793103448275862
total_envstep_count: 602040
total_train_sample_count: 602040
total_episode_count: 5190
total_duration: 36115.802324348326
[2024-12-27 22:06:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.445579711149254
avg_train_sample_per_sec: 16.445579711149254
avg_episode_per_sec: 0.1417722388892177
collect_time: 42.321402603287254
reward_mean: -110.05543884220356
reward_std: 1.7183681765834968
reward_max: -106.43907563025208
reward_min: -111.51120448179272
queue_len: 0.07298106024018802
wait_time: 0.7000334506039376
delay_time: 4.575691908914414
pressure: 0.8943412908930152
total_envstep_count: 602736
total_train_sample_count: 602736
total_episode_count: 5196
total_duration: 36158.12372695161
[2024-12-27 22:07:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.555867489839233
avg_train_sample_per_sec: 16.555867489839233
avg_episode_per_sec: 0.14272299560206236
collect_time: 42.03947636251337
reward_mean: -109.87990196078431
reward_std: 1.3449927226810776
reward_max: -108.49719887955185
reward_min: -112.44187675070029
queue_len: 0.07286465647266865
wait_time: 0.6958231789621241
delay_time: 4.56168233622611
pressure: 0.8933465959328029
total_envstep_count: 603432
total_train_sample_count: 603432
total_episode_count: 5202
total_duration: 36200.16320331413
[2024-12-27 22:08:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.673741420232503
avg_train_sample_per_sec: 16.673741420232503
avg_episode_per_sec: 0.14373915017441813
collect_time: 41.74228101891092
reward_mean: -110.87406629318393
reward_std: 2.8581677888961323
reward_max: -106.6610644257703
reward_min: -115.55882352941174
queue_len: 0.07352391664004239
wait_time: 0.7047490415264249
delay_time: 4.558688459788486
pressure: 0.9045092838196287
total_envstep_count: 604128
total_train_sample_count: 604128
total_episode_count: 5208
total_duration: 36241.90548433304
[2024-12-27 22:09:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.133323316923978
avg_train_sample_per_sec: 17.133323316923978
avg_episode_per_sec: 0.14770106307693084
collect_time: 40.62259184197523
reward_mean: -106.75081699346403
reward_std: 3.4112285637000657
reward_max: -104.1785714285714
reward_min: -113.39635854341738
queue_len: 0.07078966644128915
wait_time: 0.6736827799201025
delay_time: 4.444914877289313
pressure: 0.8715738284703803
total_envstep_count: 604824
total_train_sample_count: 604824
total_episode_count: 5214
total_duration: 36282.52807617501
[2024-12-27 22:09:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.048780690553066
avg_train_sample_per_sec: 17.048780690553066
avg_episode_per_sec: 0.14697224733235403
collect_time: 40.82403384927474
reward_mean: -108.90744631185807
reward_std: 3.756520871693827
reward_max: -104.5609243697479
reward_min: -114.61414565826334
queue_len: 0.07221979198399077
wait_time: 0.6890592996703545
delay_time: 4.477267308818263
pressure: 0.8819628647214856
total_envstep_count: 605520
total_train_sample_count: 605520
total_episode_count: 5220
total_duration: 36323.35211002429
[2024-12-27 22:10:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.906931665908157
avg_train_sample_per_sec: 16.906931665908157
avg_episode_per_sec: 0.14574941091300136
collect_time: 41.16654717446119
reward_mean: -107.43312324929973
reward_std: 3.0741811118864315
reward_max: -103.5553221288515
reward_min: -113.16806722689074
queue_len: 0.07124212417062316
wait_time: 0.6804745992119218
delay_time: 4.428449968536022
pressure: 0.8716843501326261
total_envstep_count: 606216
total_train_sample_count: 606216
total_episode_count: 5226
total_duration: 36364.51865719875
[2024-12-27 22:11:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.060674787922924
avg_train_sample_per_sec: 17.060674787922924
avg_episode_per_sec: 0.14707478265450796
collect_time: 40.79557278078422
reward_mean: -109.34348739495796
reward_std: 2.1965447421440363
reward_max: -106.25630252100841
reward_min: -112.3452380952381
queue_len: 0.07250894389586073
wait_time: 0.6899207185084468
delay_time: 4.60137989747621
pressure: 0.8824049513704685
total_envstep_count: 606912
total_train_sample_count: 606912
total_episode_count: 5232
total_duration: 36405.314229979536
[2024-12-27 22:11:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.897665923240865
avg_train_sample_per_sec: 16.897665923240865
avg_episode_per_sec: 0.14566953382104192
collect_time: 41.189120625395326
reward_mean: -106.32166199813257
reward_std: 1.7783314210262435
reward_max: -103.56372549019609
reward_min: -108.93067226890754
queue_len: 0.07050508090061842
wait_time: 0.6735858025792103
delay_time: 4.432663063189769
pressure: 0.8589743589743589
total_envstep_count: 607608
total_train_sample_count: 607608
total_episode_count: 5238
total_duration: 36446.50335060493
[2024-12-27 22:12:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.879702410696954
avg_train_sample_per_sec: 16.879702410696954
avg_episode_per_sec: 0.1455146759542841
collect_time: 41.23295441268757
reward_mean: -110.85924369747902
reward_std: 3.4288402210900335
reward_max: -106.57142857142857
reward_min: -116.42016806722688
queue_len: 0.07351408733254575
wait_time: 0.7021903257324148
delay_time: 4.671653786187886
pressure: 0.8891467727674623
total_envstep_count: 608304
total_train_sample_count: 608304
total_episode_count: 5244
total_duration: 36487.73630501761
[2024-12-27 22:13:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.115491327419893
avg_train_sample_per_sec: 17.115491327419893
avg_episode_per_sec: 0.14754733902948183
collect_time: 40.66491499925406
reward_mean: -107.83648459383754
reward_std: 1.7280925306225603
reward_max: -104.38865546218491
reward_min: -109.31442577030809
queue_len: 0.07150960516832726
wait_time: 0.6817569755576857
delay_time: 4.443778568386974
pressure: 0.8730106100795756
total_envstep_count: 609000
total_train_sample_count: 609000
total_episode_count: 5250
total_duration: 36528.401220016865
[2024-12-27 22:13:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.007824677946275
avg_train_sample_per_sec: 17.007824677946275
avg_episode_per_sec: 0.14661917825815754
collect_time: 40.92234093302302
reward_mean: -110.0846171802054
reward_std: 4.324818102923242
reward_max: -103.81232492997198
reward_min: -114.6071428571428
queue_len: 0.07300040927069325
wait_time: 0.7002890125988502
delay_time: 4.539613504108974
pressure: 0.8932360742705571
total_envstep_count: 609696
total_train_sample_count: 609696
total_episode_count: 5256
total_duration: 36569.32356094989
[2024-12-27 22:14:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.157574717930665
avg_train_sample_per_sec: 17.157574717930665
avg_episode_per_sec: 0.1479101268787126
collect_time: 40.56517377555929
reward_mean: -106.55602240896359
reward_std: 2.96463875597734
reward_max: -103.60504201680669
reward_min: -112.35504201680673
queue_len: 0.07066049231363634
wait_time: 0.6702637288337084
delay_time: 4.478617980828328
pressure: 0.8599690539345713
total_envstep_count: 610392
total_train_sample_count: 610392
total_episode_count: 5262
total_duration: 36609.88873472545
[2024-12-27 22:15:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.241852229495198
avg_train_sample_per_sec: 17.241852229495198
avg_episode_per_sec: 0.14863665715082067
collect_time: 40.36689276395552
reward_mean: -106.02731092436973
reward_std: 0.9772323027722656
reward_max: -104.81652661064425
reward_min: -107.78991596638653
queue_len: 0.07030988788088179
wait_time: 0.6700355650659909
delay_time: 4.4240148901318905
pressure: 0.8567639257294429
total_envstep_count: 611088
total_train_sample_count: 611088
total_episode_count: 5268
total_duration: 36650.2556274894
[2024-12-27 22:16:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.109452238890032
avg_train_sample_per_sec: 17.109452238890032
avg_episode_per_sec: 0.1474952779214658
collect_time: 40.679268411526465
reward_mean: -110.30870681605974
reward_std: 2.1951457701857517
reward_max: -107.10434173669466
reward_min: -114.22759103641457
queue_len: 0.07314900982497331
wait_time: 0.6998218496063323
delay_time: 4.553257913727188
pressure: 0.893788682581786
total_envstep_count: 611784
total_train_sample_count: 611784
total_episode_count: 5274
total_duration: 36690.93489590093
[2024-12-27 22:16:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.189853139640245
avg_train_sample_per_sec: 17.189853139640245
avg_episode_per_sec: 0.1481883891348297
collect_time: 40.489002107586714
reward_mean: -107.64764239028943
reward_std: 3.2917748905224933
reward_max: -103.77030812324928
reward_min: -113.53221288515405
queue_len: 0.0713843782428975
wait_time: 0.683242594119876
delay_time: 4.476297295675389
pressure: 0.8724580017683464
total_envstep_count: 612480
total_train_sample_count: 612480
total_episode_count: 5280
total_duration: 36731.423898008514
[2024-12-27 22:17:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.288891232992437
avg_train_sample_per_sec: 17.288891232992437
avg_episode_per_sec: 0.14904216580165894
collect_time: 40.257063950510684
reward_mean: -106.83345004668534
reward_std: 1.7615050993672672
reward_max: -103.72408963585437
reward_min: -108.60644257703079
queue_len: 0.07084446289567993
wait_time: 0.6759925897856932
delay_time: 4.424696357804544
pressure: 0.8705791335101679
total_envstep_count: 613176
total_train_sample_count: 613176
total_episode_count: 5286
total_duration: 36771.68096195903
[2024-12-27 22:18:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.011119159111793
avg_train_sample_per_sec: 17.011119159111793
avg_episode_per_sec: 0.1466475789578603
collect_time: 40.914415653081605
reward_mean: -110.8313492063492
reward_std: 3.548719461669359
reward_max: -104.08823529411761
reward_min: -115.77240896358545
queue_len: 0.07349558965938276
wait_time: 0.7010741962567519
delay_time: 4.58191349835292
pressure: 0.8948938992042438
total_envstep_count: 613872
total_train_sample_count: 613872
total_episode_count: 5292
total_duration: 36812.59537761211
[2024-12-27 22:18:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.948462316153485
avg_train_sample_per_sec: 16.948462316153485
avg_episode_per_sec: 0.1461074337599438
collect_time: 41.06567233162187
reward_mean: -111.1676003734827
reward_std: 2.681524850182792
reward_max: -107.28641456582632
reward_min: -115.3795518207283
queue_len: 0.0737185678869249
wait_time: 0.7100794672422462
delay_time: 4.569070645167674
pressure: 0.912577365163572
total_envstep_count: 614568
total_train_sample_count: 614568
total_episode_count: 5298
total_duration: 36853.66104994373
[2024-12-27 22:19:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.21930631738107
avg_train_sample_per_sec: 17.21930631738107
avg_episode_per_sec: 0.14844229583949195
collect_time: 40.419746717523786
reward_mean: -107.87815126050423
reward_std: 2.1873609600416946
reward_max: -105.52941176470591
reward_min: -112.22268907563023
queue_len: 0.07153723558388873
wait_time: 0.6880272997793281
delay_time: 4.478801955308548
pressure: 0.8837312113174182
total_envstep_count: 615264
total_train_sample_count: 615264
total_episode_count: 5304
total_duration: 36894.080796661256
[2024-12-27 22:20:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.20129356053175
avg_train_sample_per_sec: 17.20129356053175
avg_episode_per_sec: 0.14828701345285988
collect_time: 40.462073247617106
reward_mean: -110.14507469654528
reward_std: 2.6779017433183996
reward_max: -105.89215686274511
reward_min: -114.98459383753497
queue_len: 0.07304050046190004
wait_time: 0.7001932735959104
delay_time: 4.602172256208249
pressure: 0.8819628647214853
total_envstep_count: 615960
total_train_sample_count: 615960
total_episode_count: 5310
total_duration: 36934.54286990887
[2024-12-27 22:20:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.25499700323924
avg_train_sample_per_sec: 17.25499700323924
avg_episode_per_sec: 0.14874997416585553
collect_time: 40.33614145915769
reward_mean: -106.75723622782448
reward_std: 3.1021996819567867
reward_max: -100.84313725490196
reward_min: -110.7198879551821
queue_len: 0.07079392322800031
wait_time: 0.6789114297354661
delay_time: 4.438625523074179
pressure: 0.8720159151193633
total_envstep_count: 616656
total_train_sample_count: 616656
total_episode_count: 5316
total_duration: 36974.87901136803
[2024-12-27 22:21:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.10575026399391
avg_train_sample_per_sec: 17.10575026399391
avg_episode_per_sec: 0.14746336434477508
collect_time: 40.68807209614292
reward_mean: -109.01972455648924
reward_std: 1.0253756869582693
reward_max: -107.98389355742299
reward_min: -110.36484593837534
queue_len: 0.07229424705337482
wait_time: 0.692484697238754
delay_time: 4.5494120125839315
pressure: 0.8884836427939877
total_envstep_count: 617352
total_train_sample_count: 617352
total_episode_count: 5322
total_duration: 37015.56708346417
[2024-12-27 22:22:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.249041952771687
avg_train_sample_per_sec: 17.249041952771687
avg_episode_per_sec: 0.14869863752389384
collect_time: 40.35006708811223
reward_mean: -108.31781045751632
reward_std: 1.6349882761076229
reward_max: -105.88795518207287
reward_min: -110.07773109243693
queue_len: 0.07182878677554132
wait_time: 0.6860406961192965
delay_time: 4.528529384612624
pressure: 0.8742263483642794
total_envstep_count: 618048
total_train_sample_count: 618048
total_episode_count: 5328
total_duration: 37055.91715055228
[2024-12-27 22:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.20911191482859
avg_train_sample_per_sec: 17.20911191482859
avg_episode_per_sec: 0.14835441305886715
collect_time: 40.44369072876312
reward_mean: -105.92390289449115
reward_std: 2.4032612473777877
reward_max: -103.92086834733897
reward_min: -110.77450980392163
queue_len: 0.07024131491677131
wait_time: 0.6670446693266167
delay_time: 4.427245934673226
pressure: 0.8603006189213085
total_envstep_count: 618744
total_train_sample_count: 618744
total_episode_count: 5334
total_duration: 37096.36084128104
[2024-12-27 22:23:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.1118612319684
avg_train_sample_per_sec: 17.1118612319684
avg_episode_per_sec: 0.14751604510317587
collect_time: 40.67354161917419
reward_mean: -111.05870681605974
reward_std: 4.457926677268162
reward_max: -106.86554621848738
reward_min: -117.95308123249299
queue_len: 0.0736463573050794
wait_time: 0.7033833869533668
delay_time: 4.652810759937079
pressure: 0.9011936339522545
total_envstep_count: 619440
total_train_sample_count: 619440
total_episode_count: 5340
total_duration: 37137.034382900216
[2024-12-27 22:24:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.964071160700023
avg_train_sample_per_sec: 16.964071160700023
avg_episode_per_sec: 0.14624199276465535
collect_time: 41.02788731589355
reward_mean: -109.84173669467789
reward_std: 2.06038986987893
reward_max: -106.56372549019608
reward_min: -112.65406162464987
queue_len: 0.07283934794076782
wait_time: 0.6921430707561539
delay_time: 4.638902135384046
pressure: 0.878868258178603
total_envstep_count: 620136
total_train_sample_count: 620136
total_episode_count: 5346
total_duration: 37178.06227021611
[2024-12-27 22:24:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.043900474969185
avg_train_sample_per_sec: 17.043900474969185
avg_episode_per_sec: 0.14693017650835505
collect_time: 40.83572308006324
reward_mean: -108.69339402427637
reward_std: 3.6154960428514418
reward_max: -103.7331932773109
reward_min: -115.01330532212886
queue_len: 0.07207784749620448
wait_time: 0.6880452556796371
delay_time: 4.4807213583878545
pressure: 0.8842838196286472
total_envstep_count: 620832
total_train_sample_count: 620832
total_episode_count: 5352
total_duration: 37218.897993296174
[2024-12-27 22:25:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.178809741189063
avg_train_sample_per_sec: 17.178809741189063
avg_episode_per_sec: 0.14809318742404365
collect_time: 40.51503046402708
reward_mean: -109.69922969187677
reward_std: 5.117984678748215
reward_max: -103.70868347338934
reward_min: -119.91386554621849
queue_len: 0.07274484727578034
wait_time: 0.6917228872097027
delay_time: 4.555675254730992
pressure: 0.8946728558797524
total_envstep_count: 621528
total_train_sample_count: 621528
total_episode_count: 5358
total_duration: 37259.4130237602
[2024-12-27 22:26:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.01298176745082
avg_train_sample_per_sec: 17.01298176745082
avg_episode_per_sec: 0.1466636359263002
collect_time: 40.909936277695
reward_mean: -110.13095238095237
reward_std: 2.815163822323712
reward_max: -106.99159663865548
reward_min: -115.51330532212884
queue_len: 0.07303113553113554
wait_time: 0.6982322106561458
delay_time: 4.574427691464135
pressure: 0.8922413793103448
total_envstep_count: 622224
total_train_sample_count: 622224
total_episode_count: 5364
total_duration: 37300.3229600379
[2024-12-27 22:27:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.260013552711168
avg_train_sample_per_sec: 17.260013552711168
avg_episode_per_sec: 0.14879322028199282
collect_time: 40.32441793133319
reward_mean: -108.96591970121382
reward_std: 2.0175823391002936
reward_max: -105.46148459383754
reward_min: -111.18557422969188
queue_len: 0.0722585674411232
wait_time: 0.6963253250017957
delay_time: 4.535658137570458
pressure: 0.883841732979664
total_envstep_count: 622920
total_train_sample_count: 622920
total_episode_count: 5370
total_duration: 37340.64737796923
[2024-12-27 22:27:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.26998508490839
avg_train_sample_per_sec: 17.26998508490839
avg_episode_per_sec: 0.14887918176645165
collect_time: 40.30113497945108
reward_mean: -109.72478991596638
reward_std: 4.599715451409953
reward_max: -102.21288515406157
reward_min: -116.25840336134455
queue_len: 0.07276179702650291
wait_time: 0.694023873917383
delay_time: 4.552767568957347
pressure: 0.8916887709991158
total_envstep_count: 623616
total_train_sample_count: 623616
total_episode_count: 5376
total_duration: 37380.948512948686
[2024-12-27 22:28:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.21258853444858
avg_train_sample_per_sec: 17.21258853444858
avg_episode_per_sec: 0.14838438391766018
collect_time: 40.435521862795575
reward_mean: -107.89379084967321
reward_std: 3.5645337151484213
reward_max: -104.80182072829133
reward_min: -115.35924369747895
queue_len: 0.07154760666423952
wait_time: 0.675479376100573
delay_time: 4.515957529754015
pressure: 0.8725685234305924
total_envstep_count: 624312
total_train_sample_count: 624312
total_episode_count: 5382
total_duration: 37421.38403481148
[2024-12-27 22:29:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.117575330189098
avg_train_sample_per_sec: 17.117575330189098
avg_episode_per_sec: 0.1475653045705957
collect_time: 40.659964193206285
reward_mean: -110.04925303454714
reward_std: 3.606032531027052
reward_max: -103.78781512605043
reward_min: -115.08753501400557
queue_len: 0.07297695824572091
wait_time: 0.6978025847828079
delay_time: 4.6203534574832394
pressure: 0.8840627763041556
total_envstep_count: 625008
total_train_sample_count: 625008
total_episode_count: 5388
total_duration: 37462.04399900469
[2024-12-27 22:29:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.393225981171174
avg_train_sample_per_sec: 17.393225981171174
avg_episode_per_sec: 0.14994160328595837
collect_time: 40.01557852197438
reward_mean: -111.08099906629319
reward_std: 3.9617066393917133
reward_max: -105.71218487394957
reward_min: -115.77591036414564
queue_len: 0.0736611399643854
wait_time: 0.7003579725435709
delay_time: 4.620663377423814
pressure: 0.8988726790450929
total_envstep_count: 625704
total_train_sample_count: 625704
total_episode_count: 5394
total_duration: 37502.05957752666
[2024-12-27 22:30:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.508416897096208
avg_train_sample_per_sec: 17.508416897096208
avg_episode_per_sec: 0.15093462842324318
collect_time: 39.7523090802934
reward_mean: -110.38772175536882
reward_std: 3.9196289693119444
reward_max: -102.05252100840335
reward_min: -114.10224089635861
queue_len: 0.07320140699958144
wait_time: 0.6950025478803369
delay_time: 4.5983299525506744
pressure: 0.8983200707338638
total_envstep_count: 626400
total_train_sample_count: 626400
total_episode_count: 5400
total_duration: 37541.811886606956
[2024-12-27 22:31:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.20232396868025
avg_train_sample_per_sec: 17.20232396868025
avg_episode_per_sec: 0.1482958962817263
collect_time: 40.459649595437575
reward_mean: -107.73307656395889
reward_std: 2.3814902457457148
reward_max: -103.78991596638656
reward_min: -111.12605042016806
queue_len: 0.07144103220421677
wait_time: 0.6841416274732705
delay_time: 4.542884523948623
pressure: 0.8710212201591513
total_envstep_count: 627096
total_train_sample_count: 627096
total_episode_count: 5406
total_duration: 37582.271536202396
[2024-12-27 22:31:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.375016779966792
avg_train_sample_per_sec: 17.375016779966792
avg_episode_per_sec: 0.14978462741350682
collect_time: 40.05751527114958
reward_mean: -106.8564425770308
reward_std: 3.772922753333802
reward_max: -99.03781512605045
reward_min: -110.71078431372545
queue_len: 0.07085970993171803
wait_time: 0.6709483749291051
delay_time: 4.448853879214812
pressure: 0.8660477453580903
total_envstep_count: 627792
total_train_sample_count: 627792
total_episode_count: 5412
total_duration: 37622.32905147354
[2024-12-27 22:32:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.1783878344979
avg_train_sample_per_sec: 17.1783878344979
avg_episode_per_sec: 0.1480895502973957
collect_time: 40.516025526113815
reward_mean: -108.28081232492995
reward_std: 3.4961463378534767
reward_max: -103.7156862745098
reward_min: -112.37745098039217
queue_len: 0.07180425220486071
wait_time: 0.685746049082763
delay_time: 4.4736598251918425
pressure: 0.8816312997347481
total_envstep_count: 628488
total_train_sample_count: 628488
total_episode_count: 5418
total_duration: 37662.845076999656
[2024-12-27 22:33:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.41414229296371
avg_train_sample_per_sec: 17.41414229296371
avg_episode_per_sec: 0.15012191631865268
collect_time: 39.967515384390936
reward_mean: -109.5714285714286
reward_std: 1.671148660883513
reward_max: -107.51330532212886
reward_min: -112.2198879551821
queue_len: 0.0726600985221675
wait_time: 0.6930217489294567
delay_time: 4.573982579649634
pressure: 0.8892572944297082
total_envstep_count: 629184
total_train_sample_count: 629184
total_episode_count: 5424
total_duration: 37702.81259238405
[2024-12-27 22:33:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.12731935588856
avg_train_sample_per_sec: 17.12731935588856
avg_episode_per_sec: 0.14764930479214275
collect_time: 40.636832042295495
reward_mean: -110.00922035480859
reward_std: 1.9904415808997031
reward_max: -107.34873949579837
reward_min: -113.45938375350138
queue_len: 0.07295041137586776
wait_time: 0.6924510299256749
delay_time: 4.572093600032389
pressure: 0.889920424403183
total_envstep_count: 629880
total_train_sample_count: 629880
total_episode_count: 5430
total_duration: 37743.44942442635
[2024-12-27 22:34:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.492747193201968
avg_train_sample_per_sec: 17.492747193201968
avg_episode_per_sec: 0.1507995447689825
collect_time: 39.78791851919517
reward_mean: -107.42973856209152
reward_std: 2.7153398041618884
reward_max: -104.87114845938373
reward_min: -113.06162464985994
queue_len: 0.07123987968308455
wait_time: 0.6747015450742632
delay_time: 4.471543344827262
pressure: 0.871131741821397
total_envstep_count: 630576
total_train_sample_count: 630576
total_episode_count: 5436
total_duration: 37783.23734294554
[2024-12-27 22:35:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35857849634637
avg_train_sample_per_sec: 17.35857849634637
avg_episode_per_sec: 0.1496429180719515
collect_time: 40.095449068395425
reward_mean: -107.34500466853409
reward_std: 3.5362439907339183
reward_max: -100.09523809523809
reward_min: -110.66736694677871
queue_len: 0.07118369009849741
wait_time: 0.6773155216993958
delay_time: 4.413122369136601
pressure: 0.8709106984969055
total_envstep_count: 631272
total_train_sample_count: 631272
total_episode_count: 5442
total_duration: 37823.332792013935
[2024-12-27 22:35:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.273557459436837
avg_train_sample_per_sec: 17.273557459436837
avg_episode_per_sec: 0.1489099780985934
collect_time: 40.29280023147539
reward_mean: -109.63807189542484
reward_std: 4.463459259958915
reward_max: -104.39495798319327
reward_min: -116.0588235294118
queue_len: 0.07270429170784141
wait_time: 0.692429823388241
delay_time: 4.5712289129939405
pressure: 0.889367816091954
total_envstep_count: 631968
total_train_sample_count: 631968
total_episode_count: 5448
total_duration: 37863.62559224541
[2024-12-27 22:36:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.684953246004515
avg_train_sample_per_sec: 17.684953246004515
avg_episode_per_sec: 0.15245649350003893
collect_time: 39.35548996473849
reward_mean: -107.45891690009336
reward_std: 1.3302863959536102
reward_max: -104.80462184873944
reward_min: -108.6645658263305
queue_len: 0.07125922871358976
wait_time: 0.6762493901185583
delay_time: 4.514016973299096
pressure: 0.8714633068081344
total_envstep_count: 632664
total_train_sample_count: 632664
total_episode_count: 5454
total_duration: 37902.98108221014
[2024-12-27 22:37:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.297553196195807
avg_train_sample_per_sec: 17.297553196195807
avg_episode_per_sec: 0.1491168378982397
collect_time: 40.2369047289919
reward_mean: -109.31465919701213
reward_std: 3.5250353497219162
reward_max: -104.2990196078431
reward_min: -113.75630252100838
queue_len: 0.07248982705372158
wait_time: 0.6906314470969642
delay_time: 4.491838915858288
pressure: 0.8905835543766578
total_envstep_count: 633360
total_train_sample_count: 633360
total_episode_count: 5460
total_duration: 37943.21798693913
[2024-12-27 22:37:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.35579586566383
avg_train_sample_per_sec: 17.35579586566383
avg_episode_per_sec: 0.14961892987641232
collect_time: 40.10187751614116
reward_mean: -105.62103174603175
reward_std: 2.987380523813488
reward_max: -100.97969187675066
reward_min: -109.30742296918768
queue_len: 0.07004047198012714
wait_time: 0.6678854234001294
delay_time: 4.403844678750711
pressure: 0.8558797524314766
total_envstep_count: 634056
total_train_sample_count: 634056
total_episode_count: 5466
total_duration: 37983.319864455276
[2024-12-27 22:38:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.12974280673209
avg_train_sample_per_sec: 17.12974280673209
avg_episode_per_sec: 0.14767019660975939
collect_time: 40.6310828978978
reward_mean: -107.87114845938375
reward_std: 2.0163206016224398
reward_max: -104.08193277310922
reward_min: -110.13515406162468
queue_len: 0.07153259181656747
wait_time: 0.6835401822090462
delay_time: 4.427238074562201
pressure: 0.8796419098143238
total_envstep_count: 634752
total_train_sample_count: 634752
total_episode_count: 5472
total_duration: 38023.95094735317
[2024-12-27 22:39:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.272307600859587
avg_train_sample_per_sec: 17.272307600859587
avg_episode_per_sec: 0.14889920345568608
collect_time: 40.295715898746636
reward_mean: -108.97584033613445
reward_std: 2.1757619969296744
reward_max: -106.34453781512605
reward_min: -112.44397759103643
queue_len: 0.07226514611149501
wait_time: 0.6893527857650575
delay_time: 4.4342609846968
pressure: 0.886604774535809
total_envstep_count: 635448
total_train_sample_count: 635448
total_episode_count: 5478
total_duration: 38064.24666325192
[2024-12-27 22:39:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.528686139636168
avg_train_sample_per_sec: 17.528686139636168
avg_episode_per_sec: 0.1511093632727256
collect_time: 39.7063416194208
reward_mean: -108.96136788048551
reward_std: 3.350495676604785
reward_max: -104.48459383753502
reward_min: -113.80882352941177
queue_len: 0.0722555489923644
wait_time: 0.6857389286395371
delay_time: 4.5189283684224035
pressure: 0.883178603006189
total_envstep_count: 636144
total_train_sample_count: 636144
total_episode_count: 5484
total_duration: 38103.95300487134
[2024-12-27 22:40:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.413127902796237
avg_train_sample_per_sec: 17.413127902796237
avg_episode_per_sec: 0.15011317157582962
collect_time: 39.96984366537817
reward_mean: -108.17950513538749
reward_std: 2.802268108341891
reward_max: -104.52941176470588
reward_min: -113.29481792717088
queue_len: 0.0717370723709466
wait_time: 0.6790535290154965
delay_time: 4.471632842294285
pressure: 0.8721264367816093
total_envstep_count: 636840
total_train_sample_count: 636840
total_episode_count: 5490
total_duration: 38143.92284853672
[2024-12-27 22:41:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.170233783792654
avg_train_sample_per_sec: 17.170233783792654
avg_episode_per_sec: 0.14801925675683322
collect_time: 40.535266366435216
reward_mean: -107.39285714285712
reward_std: 4.304973474410542
reward_max: -100.85154061624645
reward_min: -113.84313725490199
queue_len: 0.07121542250852596
wait_time: 0.6775809903979275
delay_time: 4.479822915378067
pressure: 0.8753315649867374
total_envstep_count: 637536
total_train_sample_count: 637536
total_episode_count: 5496
total_duration: 38184.45811490316
[2024-12-27 22:42:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27856618184002
avg_train_sample_per_sec: 17.27856618184002
avg_episode_per_sec: 0.14895315674000018
collect_time: 40.28112012740411
reward_mean: -107.50828664799253
reward_std: 2.667670783038926
reward_max: -104.15056022408965
reward_min: -111.22338935574231
queue_len: 0.0712919672732046
wait_time: 0.6790337156082592
delay_time: 4.437496655601124
pressure: 0.8694739168877099
total_envstep_count: 638232
total_train_sample_count: 638232
total_episode_count: 5502
total_duration: 38224.73923503056
[2024-12-27 22:42:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.412798439577394
avg_train_sample_per_sec: 17.412798439577394
avg_episode_per_sec: 0.15011033137566718
collect_time: 39.970599924827006
reward_mean: -107.85550887021475
reward_std: 4.07091554772345
reward_max: -100.77100840336134
reward_min: -112.9320728291317
queue_len: 0.07152222073621668
wait_time: 0.682200455336865
delay_time: 4.4114406464820695
pressure: 0.8765473032714413
total_envstep_count: 638928
total_train_sample_count: 638928
total_episode_count: 5508
total_duration: 38264.709834955385
[2024-12-27 22:43:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.192483547965747
avg_train_sample_per_sec: 17.192483547965747
avg_episode_per_sec: 0.1482110650686702
collect_time: 40.48280738836899
reward_mean: -108.0999066293184
reward_std: 2.013786921924725
reward_max: -103.90126050420169
reward_min: -109.8417366946779
queue_len: 0.07168428821572838
wait_time: 0.6877610571195764
delay_time: 4.460992533674733
pressure: 0.8683687002652519
total_envstep_count: 639624
total_train_sample_count: 639624
total_episode_count: 5514
total_duration: 38305.192642343754
[2024-12-27 22:44:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.29111269093313
avg_train_sample_per_sec: 17.29111269093313
avg_episode_per_sec: 0.14906131630114766
collect_time: 40.25189196557366
reward_mean: -108.2125350140056
reward_std: 3.9663440181054663
reward_max: -101.54761904761907
reward_min: -113.56022408963587
queue_len: 0.07175897547347851
wait_time: 0.6832874064745261
delay_time: 4.501796595219514
pressure: 0.8719053934571175
total_envstep_count: 640320
total_train_sample_count: 640320
total_episode_count: 5520
total_duration: 38345.444534309325
[2024-12-27 22:44:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.462917924735716
avg_train_sample_per_sec: 17.462917924735716
avg_episode_per_sec: 0.1505423959028941
collect_time: 39.85588221852296
reward_mean: -107.03419701213822
reward_std: 2.149687506073731
reward_max: -104.58753501400562
reward_min: -111.21148459383753
queue_len: 0.07097758422555583
wait_time: 0.6813946069143837
delay_time: 4.511121543043892
pressure: 0.8643899204244031
total_envstep_count: 641016
total_train_sample_count: 641016
total_episode_count: 5526
total_duration: 38385.30041652785
[2024-12-27 22:45:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.316062332381673
avg_train_sample_per_sec: 17.316062332381673
avg_episode_per_sec: 0.14927639941708337
collect_time: 40.193895508129145
reward_mean: -109.83239962651726
reward_std: 3.4528186983410185
reward_max: -103.35084033613444
reward_min: -113.05182072829132
queue_len: 0.07283315625100616
wait_time: 0.7006976641231204
delay_time: 4.527781913054298
pressure: 0.8880415561450045
total_envstep_count: 641712
total_train_sample_count: 641712
total_episode_count: 5532
total_duration: 38425.494312035975
[2024-12-27 22:46:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.00335469270504
avg_train_sample_per_sec: 17.00335469270504
avg_episode_per_sec: 0.14658064390262968
collect_time: 40.93309894303418
reward_mean: -110.2700746965453
reward_std: 3.380664831956961
reward_max: -105.22128851540619
reward_min: -113.66106442577035
queue_len: 0.07312339170858441
wait_time: 0.6999851554237964
delay_time: 4.605135195307214
pressure: 0.8905835543766578
total_envstep_count: 642408
total_train_sample_count: 642408
total_episode_count: 5538
total_duration: 38466.427410979006
[2024-12-27 22:46:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.319679268125498
avg_train_sample_per_sec: 17.319679268125498
avg_episode_per_sec: 0.1493075798976336
collect_time: 40.1855016611591
reward_mean: -106.8843370681606
reward_std: 2.6153292950451466
reward_max: -102.8585434173669
reward_min: -110.51470588235296
queue_len: 0.07087820760488102
wait_time: 0.6776380313398569
delay_time: 4.464823824926912
pressure: 0.8667108753315649
total_envstep_count: 643104
total_train_sample_count: 643104
total_episode_count: 5544
total_duration: 38506.612912640165
[2024-12-27 22:47:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.631470337512823
avg_train_sample_per_sec: 17.631470337512823
avg_episode_per_sec: 0.15199543394407605
collect_time: 39.47487002936937
reward_mean: -109.8046218487395
reward_std: 2.960884407259292
reward_max: -105.12955182072834
reward_min: -114.17647058823528
queue_len: 0.07281473597396519
wait_time: 0.6975700868322573
delay_time: 4.545670453705147
pressure: 0.8959991158267021
total_envstep_count: 643800
total_train_sample_count: 643800
total_episode_count: 5550
total_duration: 38546.087782669536
[2024-12-27 22:48:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.10083671230826
avg_train_sample_per_sec: 17.10083671230826
avg_episode_per_sec: 0.14742100614058845
collect_time: 40.6997629244104
reward_mean: -106.65604575163398
reward_std: 3.8327673451510713
reward_max: -101.84453781512605
reward_min: -111.39425770308124
queue_len: 0.07072682079020821
wait_time: 0.6709797203585236
delay_time: 4.442246329901506
pressure: 0.8616268788682583
total_envstep_count: 644496
total_train_sample_count: 644496
total_episode_count: 5556
total_duration: 38586.78754559394
[2024-12-27 22:48:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.42968987296119
avg_train_sample_per_sec: 17.42968987296119
avg_episode_per_sec: 0.15025594718069993
collect_time: 39.931863680472595
reward_mean: -109.765639589169
reward_std: 2.400423033180032
reward_max: -105.281512605042
reward_min: -112.22549019607841
queue_len: 0.0727888856692102
wait_time: 0.6995622630130746
delay_time: 4.519756862784992
pressure: 0.8963306808134394
total_envstep_count: 645192
total_train_sample_count: 645192
total_episode_count: 5562
total_duration: 38626.71940927442
[2024-12-27 22:49:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.381402463861363
avg_train_sample_per_sec: 17.381402463861363
avg_episode_per_sec: 0.14983967641259793
collect_time: 40.04279870091566
reward_mean: -106.54878618113914
reward_std: 3.8656029819194724
reward_max: -100.44817927170867
reward_min: -112.58193277310923
queue_len: 0.07065569375407103
wait_time: 0.6719019725485244
delay_time: 4.457414385825792
pressure: 0.8712422634836429
total_envstep_count: 645888
total_train_sample_count: 645888
total_episode_count: 5568
total_duration: 38666.762207975335
[2024-12-27 22:50:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.356141627974143
avg_train_sample_per_sec: 17.356141627974143
avg_episode_per_sec: 0.149621910585984
collect_time: 40.10107862211764
reward_mean: -108.30368814192344
reward_std: 3.9820091967489475
reward_max: -101.54901960784314
reward_min: -113.1932773109244
queue_len: 0.07181942184477681
wait_time: 0.6872750868694073
delay_time: 4.476379254807439
pressure: 0.8806366047745358
total_envstep_count: 646584
total_train_sample_count: 646584
total_episode_count: 5574
total_duration: 38706.86328659745
[2024-12-27 22:50:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.26708219413182
avg_train_sample_per_sec: 17.26708219413182
avg_episode_per_sec: 0.14885415684596398
collect_time: 40.30791028703935
reward_mean: -108.69514472455649
reward_std: 3.6245762068169634
reward_max: -102.25910364145659
reward_min: -112.95588235294113
queue_len: 0.0720790084380348
wait_time: 0.6903515053236148
delay_time: 4.529598762801146
pressure: 0.8822944297082227
total_envstep_count: 647280
total_train_sample_count: 647280
total_episode_count: 5580
total_duration: 38747.17119688449
[2024-12-27 22:51:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.08680142647531
avg_train_sample_per_sec: 17.08680142647531
avg_episode_per_sec: 0.14730001229720097
collect_time: 40.73319415543602
reward_mean: -108.25186741363211
reward_std: 2.8710023552207566
reward_max: -103.73809523809521
reward_min: -111.56022408963587
queue_len: 0.07178505796659955
wait_time: 0.6883828575638922
delay_time: 4.446121663587344
pressure: 0.8770999115826701
total_envstep_count: 647976
total_train_sample_count: 647976
total_episode_count: 5586
total_duration: 38787.90439103993
[2024-12-27 22:52:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.212611043216075
avg_train_sample_per_sec: 17.212611043216075
avg_episode_per_sec: 0.14838457795875926
collect_time: 40.435468985648825
reward_mean: -108.53513071895422
reward_std: 2.1307254017306887
reward_max: -105.01540616246498
reward_min: -111.26610644257698
queue_len: 0.07197289835474417
wait_time: 0.6855201298025841
delay_time: 4.503082307947923
pressure: 0.877763041556145
total_envstep_count: 648672
total_train_sample_count: 648672
total_episode_count: 5592
total_duration: 38828.339860025575
[2024-12-27 22:52:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.293875237628395
avg_train_sample_per_sec: 17.293875237628395
avg_episode_per_sec: 0.14908513135886547
collect_time: 40.24546207466721
reward_mean: -105.36309523809524
reward_std: 4.040811716407536
reward_max: -99.87394957983194
reward_min: -112.43277310924367
queue_len: 0.06986942655046102
wait_time: 0.6688211425153615
delay_time: 4.378013947547281
pressure: 0.8589743589743589
total_envstep_count: 649368
total_train_sample_count: 649368
total_episode_count: 5598
total_duration: 38868.58532210024
[2024-12-27 22:53:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.225308810367387
avg_train_sample_per_sec: 17.225308810367387
avg_episode_per_sec: 0.14849404146868436
collect_time: 40.405661672730005
reward_mean: -105.68230625583567
reward_std: 3.544682642854755
reward_max: -102.60224089635854
reward_min: -110.7766106442577
queue_len: 0.0700811049441881
wait_time: 0.6695709561454998
delay_time: 4.388958225909808
pressure: 0.8611847922192751
total_envstep_count: 650064
total_train_sample_count: 650064
total_episode_count: 5604
total_duration: 38908.99098377297
[2024-12-27 22:54:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97295401196284
avg_train_sample_per_sec: 16.97295401196284
avg_episode_per_sec: 0.14631856906864518
collect_time: 41.006415236230936
reward_mean: -108.93989262371615
reward_std: 3.1220342610005636
reward_max: -103.62184873949583
reward_min: -113.12324929971989
queue_len: 0.07224130810591256
wait_time: 0.6821520053644802
delay_time: 4.5030248947271465
pressure: 0.8854995579133509
total_envstep_count: 650760
total_train_sample_count: 650760
total_episode_count: 5610
total_duration: 38949.997399009204
[2024-12-27 22:54:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.139699197085793
avg_train_sample_per_sec: 17.139699197085793
avg_episode_per_sec: 0.1477560275610844
collect_time: 40.607480446234355
reward_mean: -107.26949112978525
reward_std: 2.415463601340748
reward_max: -103.77731092436979
reward_min: -110.85504201680669
queue_len: 0.0711336148075499
wait_time: 0.6764489947172502
delay_time: 4.403855775547937
pressure: 0.8747789566755083
total_envstep_count: 651456
total_train_sample_count: 651456
total_episode_count: 5616
total_duration: 38990.60487945544
[2024-12-27 22:55:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27129968749237
avg_train_sample_per_sec: 17.27129968749237
avg_episode_per_sec: 0.14889051454734803
collect_time: 40.29806746414303
reward_mean: -106.35667600373482
reward_std: 1.9788476476891852
reward_max: -102.28361344537814
reward_min: -108.12815126050417
queue_len: 0.07052829973722469
wait_time: 0.6724942850703499
delay_time: 4.397573031774172
pressure: 0.8719053934571175
total_envstep_count: 652152
total_train_sample_count: 652152
total_episode_count: 5622
total_duration: 39030.90294691958
[2024-12-27 22:56:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.142755677727415
avg_train_sample_per_sec: 17.142755677727415
avg_episode_per_sec: 0.1477823765321329
collect_time: 40.60024030467122
reward_mean: -108.52509337068159
reward_std: 3.8028362593066407
reward_max: -102.91316526610649
reward_min: -115.08263305322129
queue_len: 0.0719662422882504
wait_time: 0.686331860330339
delay_time: 4.568744195264229
pressure: 0.8801945181255526
total_envstep_count: 652848
total_train_sample_count: 652848
total_episode_count: 5628
total_duration: 39071.503187224254
[2024-12-27 22:57:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.087739801285288
avg_train_sample_per_sec: 17.087739801285288
avg_episode_per_sec: 0.147308101735218
collect_time: 40.73095728831551
reward_mean: -108.06372549019606
reward_std: 2.3428031364939956
reward_max: -104.18207282913168
reward_min: -111.42436974789914
queue_len: 0.07166029541790189
wait_time: 0.6847301475851172
delay_time: 4.455380441213717
pressure: 0.8815207780725022
total_envstep_count: 653544
total_train_sample_count: 653544
total_episode_count: 5634
total_duration: 39112.23414451257
[2024-12-27 22:57:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30298446648137
avg_train_sample_per_sec: 17.30298446648137
avg_episode_per_sec: 0.1491636591938049
collect_time: 40.224274682108316
reward_mean: -108.54423436041084
reward_std: 2.5911687835780466
reward_max: -105.9586834733894
reward_min: -113.06022408963588
queue_len: 0.07197893525226183
wait_time: 0.6922201572936868
delay_time: 4.557013792552276
pressure: 0.876105216622458
total_envstep_count: 654240
total_train_sample_count: 654240
total_episode_count: 5640
total_duration: 39152.45841919468
[2024-12-27 22:58:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.294426339958047
avg_train_sample_per_sec: 17.294426339958047
avg_episode_per_sec: 0.14908988224101766
collect_time: 40.24417961710133
reward_mean: -107.46942110177402
reward_std: 3.44620810779964
reward_max: -103.05252100840336
reward_min: -113.65336134453781
queue_len: 0.07126619436457164
wait_time: 0.6829110291331387
delay_time: 4.48236349698654
pressure: 0.8719053934571176
total_envstep_count: 654936
total_train_sample_count: 654936
total_episode_count: 5646
total_duration: 39192.70259881178
[2024-12-27 22:59:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.292278749694546
avg_train_sample_per_sec: 17.292278749694546
avg_episode_per_sec: 0.14907136853184952
collect_time: 40.24917768644542
reward_mean: -109.04680205415502
reward_std: 1.2803353268891304
reward_max: -107.18837535014006
reward_min: -110.7836134453782
queue_len: 0.0723122029536837
wait_time: 0.6878995187818718
delay_time: 4.553909831459175
pressure: 0.8845048629531389
total_envstep_count: 655632
total_train_sample_count: 655632
total_episode_count: 5652
total_duration: 39232.95177649823
[2024-12-27 22:59:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.334804532781337
avg_train_sample_per_sec: 17.334804532781337
avg_episode_per_sec: 0.14943797011018395
collect_time: 40.15043830946088
reward_mean: -110.25863678804858
reward_std: 4.058218444923546
reward_max: -102.7577030812325
reward_min: -115.1288515406163
queue_len: 0.07311580688862636
wait_time: 0.6943517238902635
delay_time: 4.607846522850216
pressure: 0.9010831122900088
total_envstep_count: 656328
total_train_sample_count: 656328
total_episode_count: 5658
total_duration: 39273.10221480769
[2024-12-27 23:00:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.207443515809853
avg_train_sample_per_sec: 17.207443515809853
avg_episode_per_sec: 0.14834003030870563
collect_time: 40.44761206744798
reward_mean: -109.42308590102708
reward_std: 4.709344190835273
reward_max: -104.2058823529412
reward_min: -115.24439775910363
queue_len: 0.07256172805107897
wait_time: 0.6896214277045919
delay_time: 4.535943944981487
pressure: 0.8969938107869142
total_envstep_count: 657024
total_train_sample_count: 657024
total_episode_count: 5664
total_duration: 39313.54982687513
[2024-12-27 23:01:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.369739778291454
avg_train_sample_per_sec: 17.369739778291454
avg_episode_per_sec: 0.14973913601975392
collect_time: 40.06968491663039
reward_mean: -107.86239495798317
reward_std: 2.0972536200807745
reward_max: -104.85644257703082
reward_min: -111.6218487394958
queue_len: 0.0715267871074159
wait_time: 0.6832138027624842
delay_time: 4.530232782071317
pressure: 0.8810786914235189
total_envstep_count: 657720
total_train_sample_count: 657720
total_episode_count: 5670
total_duration: 39353.61951179176
[2024-12-27 23:01:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.477292840238167
avg_train_sample_per_sec: 17.477292840238167
avg_episode_per_sec: 0.15066631758826007
collect_time: 39.823101115385064
reward_mean: -107.23809523809524
reward_std: 1.6931863222644603
reward_max: -104.12605042016806
reward_min: -109.64705882352943
queue_len: 0.0711127952507263
wait_time: 0.6770233513387671
delay_time: 4.408440852721618
pressure: 0.8811892130857647
total_envstep_count: 658416
total_train_sample_count: 658416
total_episode_count: 5676
total_duration: 39393.44261290714
[2024-12-27 23:02:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.61298078095983
avg_train_sample_per_sec: 17.61298078095983
avg_episode_per_sec: 0.15183604121517097
collect_time: 39.516309513742115
reward_mean: -110.06932773109246
reward_std: 2.054491645976916
reward_max: -107.46288515406164
reward_min: -113.45868347338936
queue_len: 0.07299027037870852
wait_time: 0.6966452805702299
delay_time: 4.528771384458604
pressure: 0.893788682581786
total_envstep_count: 659112
total_train_sample_count: 659112
total_episode_count: 5682
total_duration: 39432.95892242088
[2024-12-27 23:03:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.45906577250393
avg_train_sample_per_sec: 17.45906577250393
avg_episode_per_sec: 0.1505091876939994
collect_time: 39.864675983758644
reward_mean: -107.35819327731093
reward_std: 1.5970218567087215
reward_max: -105.09943977591038
reward_min: -110.27731092436977
queue_len: 0.07119243586028576
wait_time: 0.6789444778795691
delay_time: 4.4170260770796235
pressure: 0.8804155614500441
total_envstep_count: 659808
total_train_sample_count: 659808
total_episode_count: 5688
total_duration: 39472.82359840464
[2024-12-27 23:03:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.253710566772526
avg_train_sample_per_sec: 17.253710566772526
avg_episode_per_sec: 0.14873888419631487
collect_time: 40.33914892141335
reward_mean: -108.50431839402427
reward_std: 1.351049267532722
reward_max: -106.27240896358546
reward_min: -110.81652661064425
queue_len: 0.07195246577853066
wait_time: 0.6836854547300795
delay_time: 4.460182386560187
pressure: 0.896551724137931
total_envstep_count: 660504
total_train_sample_count: 660504
total_episode_count: 5694
total_duration: 39513.16274732605
[2024-12-27 23:04:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.276850044133166
avg_train_sample_per_sec: 17.276850044133166
avg_episode_per_sec: 0.14893836244942385
collect_time: 40.28512131679618
reward_mean: -108.57457983193278
reward_std: 2.3420998164192524
reward_max: -105.74999999999996
reward_min: -113.19817927170871
queue_len: 0.07199905824398725
wait_time: 0.6863918423249052
delay_time: 4.477694934377149
pressure: 0.8818523430592397
total_envstep_count: 661200
total_train_sample_count: 661200
total_episode_count: 5700
total_duration: 39553.44786864285
[2024-12-27 23:05:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.5435854880951
avg_train_sample_per_sec: 17.5435854880951
avg_episode_per_sec: 0.15123780593185432
collect_time: 39.672619971116994
reward_mean: -109.25373482726427
reward_std: 1.9420458858001985
reward_max: -106.12254901960785
reward_min: -111.86134453781511
queue_len: 0.07244942627802668
wait_time: 0.6924613236099039
delay_time: 4.5303308004554115
pressure: 0.8940097259062775
total_envstep_count: 661896
total_train_sample_count: 661896
total_episode_count: 5706
total_duration: 39593.12048861397
[2024-12-27 23:05:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.240189393808027
avg_train_sample_per_sec: 17.240189393808027
avg_episode_per_sec: 0.14862232236041403
collect_time: 40.370786196233716
reward_mean: -108.52450980392156
reward_std: 3.625534955909176
reward_max: -103.47619047619044
reward_min: -114.1729691876751
queue_len: 0.07196585530764028
wait_time: 0.6836104578878411
delay_time: 4.460417589734942
pressure: 0.8868258178603007
total_envstep_count: 662592
total_train_sample_count: 662592
total_episode_count: 5712
total_duration: 39633.4912748102
[2024-12-27 23:06:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37241206070775
avg_train_sample_per_sec: 17.37241206070775
avg_episode_per_sec: 0.14976217293713578
collect_time: 40.06352126393467
reward_mean: -107.60212418300654
reward_std: 2.1285731156334053
reward_max: -104.8557422969188
reward_min: -111.41176470588236
queue_len: 0.07135419375530938
wait_time: 0.6816454477458534
delay_time: 4.490320548034661
pressure: 0.8827365163572062
total_envstep_count: 663288
total_train_sample_count: 663288
total_episode_count: 5718
total_duration: 39673.55479607413
[2024-12-27 23:07:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.38574323208929
avg_train_sample_per_sec: 17.38574323208929
avg_episode_per_sec: 0.14987709682835593
collect_time: 40.0328010547962
reward_mean: -107.31640989729225
reward_std: 3.7291878543819856
reward_max: -103.14565826330534
reward_min: -113.33333333333334
queue_len: 0.07116472804860229
wait_time: 0.6795046710107563
delay_time: 4.471591656832689
pressure: 0.8756631299734748
total_envstep_count: 663984
total_train_sample_count: 663984
total_episode_count: 5724
total_duration: 39713.58759712893
[2024-12-27 23:07:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.34595719434689
avg_train_sample_per_sec: 17.34595719434689
avg_episode_per_sec: 0.14953411374436973
collect_time: 40.12462340370752
reward_mean: -107.61624649859944
reward_std: 4.249271714746162
reward_max: -104.1078431372549
reward_min: -116.36554621848742
queue_len: 0.07136355868607389
wait_time: 0.6817024886877827
delay_time: 4.437473315994794
pressure: 0.8870468611847923
total_envstep_count: 664680
total_train_sample_count: 664680
total_episode_count: 5730
total_duration: 39753.71222053264
[2024-12-27 23:08:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.719365986785927
avg_train_sample_per_sec: 17.719365986785927
avg_episode_per_sec: 0.15275315505849937
collect_time: 39.27905775630101
reward_mean: -108.66293183940242
reward_std: 2.346202852639984
reward_max: -104.93207282913163
reward_min: -112.71778711484595
queue_len: 0.07205764710835705
wait_time: 0.6896256070951811
delay_time: 4.443987903725097
pressure: 0.8974358974358974
total_envstep_count: 665376
total_train_sample_count: 665376
total_episode_count: 5736
total_duration: 39792.99127828894
[2024-12-27 23:09:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16628855950558
avg_train_sample_per_sec: 17.16628855950558
avg_episode_per_sec: 0.14798524620263434
collect_time: 40.544582341568535
reward_mean: -107.77112511671335
reward_std: 1.8045517567153702
reward_max: -105.09593837535014
reward_min: -110.03501400560224
queue_len: 0.07146626333999559
wait_time: 0.6788720351093577
delay_time: 4.42157065299575
pressure: 0.8853890362511052
total_envstep_count: 666072
total_train_sample_count: 666072
total_episode_count: 5742
total_duration: 39833.53586063051
[2024-12-27 23:09:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.548546313479143
avg_train_sample_per_sec: 17.548546313479143
avg_episode_per_sec: 0.15128057166792364
collect_time: 39.66140485752933
reward_mean: -108.63842203548086
reward_std: 2.739750475382563
reward_max: -104.52030812324925
reward_min: -112.52240896358546
queue_len: 0.07204139392273266
wait_time: 0.6874030226591077
delay_time: 4.4796932828743286
pressure: 0.8838417329796641
total_envstep_count: 666768
total_train_sample_count: 666768
total_episode_count: 5748
total_duration: 39873.19726548804
[2024-12-27 23:10:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.338757717736442
avg_train_sample_per_sec: 17.338757717736442
avg_episode_per_sec: 0.1494720492908314
collect_time: 40.14128412948734
reward_mean: -106.97432306255835
reward_std: 4.715790241955079
reward_max: -101.45308123249299
reward_min: -114.74579831932769
queue_len: 0.07093788001495913
wait_time: 0.6806926240876546
delay_time: 4.430043911424072
pressure: 0.8658267020335986
total_envstep_count: 667464
total_train_sample_count: 667464
total_episode_count: 5754
total_duration: 39913.338549617525
[2024-12-27 23:11:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.415838948740053
avg_train_sample_per_sec: 17.415838948740053
avg_episode_per_sec: 0.15013654266155219
collect_time: 39.96362173815072
reward_mean: -107.17693744164335
reward_std: 3.0774066856928446
reward_max: -103.12044817927173
reward_min: -111.23389355742295
queue_len: 0.07107223968278735
wait_time: 0.6769252904521667
delay_time: 4.484185454048864
pressure: 0.8710212201591512
total_envstep_count: 668160
total_train_sample_count: 668160
total_episode_count: 5760
total_duration: 39953.30217135567
[2024-12-27 23:11:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.252972135760878
avg_train_sample_per_sec: 17.252972135760878
avg_episode_per_sec: 0.1487325184117317
collect_time: 40.34087544588186
reward_mean: -107.50116713352008
reward_std: 3.93369757704987
reward_max: -100.61134453781517
reward_min: -112.89635854341735
queue_len: 0.07128724610976132
wait_time: 0.6751911529421671
delay_time: 4.458416065908735
pressure: 0.8610742705570292
total_envstep_count: 668856
total_train_sample_count: 668856
total_episode_count: 5766
total_duration: 39993.64304680155
[2024-12-27 23:12:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.302821704000113
avg_train_sample_per_sec: 17.302821704000113
avg_episode_per_sec: 0.1491622560689665
collect_time: 40.22465305985883
reward_mean: -108.11076097105507
reward_std: 4.0337563846190365
reward_max: -101.85644257703076
reward_min: -114.80602240896359
queue_len: 0.07169148605507632
wait_time: 0.6873281032129918
delay_time: 4.480364177788869
pressure: 0.8819628647214853
total_envstep_count: 669552
total_train_sample_count: 669552
total_episode_count: 5772
total_duration: 40033.86769986141
[2024-12-27 23:13:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.386065757556043
avg_train_sample_per_sec: 17.386065757556043
avg_episode_per_sec: 0.1498798772203107
collect_time: 40.03205841422267
reward_mean: -108.92775443510737
reward_std: 1.6394804985226896
reward_max: -106.88865546218483
reward_min: -110.92787114845939
queue_len: 0.07223325890922239
wait_time: 0.6896281611672079
delay_time: 4.573282194610538
pressure: 0.883841732979664
total_envstep_count: 670248
total_train_sample_count: 670248
total_episode_count: 5778
total_duration: 40073.899758275635
[2024-12-27 23:14:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.289110165070472
avg_train_sample_per_sec: 17.289110165070472
avg_episode_per_sec: 0.14904405314715924
collect_time: 40.25655417513288
reward_mean: -109.96195144724555
reward_std: 2.4062275011165606
reward_max: -106.7682072829132
reward_min: -113.93067226890757
queue_len: 0.07291906594644931
wait_time: 0.6973535324828429
delay_time: 4.5467210274294985
pressure: 0.8961096374889479
total_envstep_count: 670944
total_train_sample_count: 670944
total_episode_count: 5784
total_duration: 40114.15631245077
[2024-12-27 23:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.681241688027786
avg_train_sample_per_sec: 17.681241688027786
avg_episode_per_sec: 0.15242449731058438
collect_time: 39.36375127269886
reward_mean: -109.20518207282913
reward_std: 1.5970391163230275
reward_max: -106.3872549019608
reward_min: -111.4698879551821
queue_len: 0.072417229491266
wait_time: 0.6880541562336694
delay_time: 4.571994040929802
pressure: 0.8798629531388151
total_envstep_count: 671640
total_train_sample_count: 671640
total_episode_count: 5790
total_duration: 40153.52006372347
[2024-12-27 23:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.222651530496908
avg_train_sample_per_sec: 17.222651530496908
avg_episode_per_sec: 0.14847113388359404
collect_time: 40.411895855151116
reward_mean: -108.68195611577961
reward_std: 3.3577901330722075
reward_max: -104.65826330532212
reward_min: -113.79341736694678
queue_len: 0.07207026267624643
wait_time: 0.686235269970057
delay_time: 4.470072728882323
pressure: 0.8905835543766578
total_envstep_count: 672336
total_train_sample_count: 672336
total_episode_count: 5796
total_duration: 40193.931959578615
[2024-12-27 23:16:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.26613097749663
avg_train_sample_per_sec: 17.26613097749663
avg_episode_per_sec: 0.14884595670255715
collect_time: 40.310130909299474
reward_mean: -110.65861344537814
reward_std: 3.56493846390491
reward_max: -103.86064425770307
reward_min: -114.82492997198878
queue_len: 0.07338104339879187
wait_time: 0.7024219723256236
delay_time: 4.5465561129408245
pressure: 0.8986516357206011
total_envstep_count: 673032
total_train_sample_count: 673032
total_episode_count: 5802
total_duration: 40234.24209048791
[2024-12-27 23:16:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.165374623770372
avg_train_sample_per_sec: 17.165374623770372
avg_episode_per_sec: 0.1479773674462963
collect_time: 40.54674105604365
reward_mean: -106.70191409897295
reward_std: 2.0941071554243402
reward_max: -104.20868347338937
reward_min: -109.6197478991597
queue_len: 0.07075723746616243
wait_time: 0.6742932031344809
delay_time: 4.502961603546787
pressure: 0.8663793103448275
total_envstep_count: 673728
total_train_sample_count: 673728
total_episode_count: 5808
total_duration: 40274.788831543956
[2024-12-27 23:17:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.24576680302694
avg_train_sample_per_sec: 17.24576680302694
avg_episode_per_sec: 0.1486704034743702
collect_time: 40.35772998379171
reward_mean: -107.65114379084964
reward_std: 3.3873563741385775
reward_max: -103.80392156862743
reward_min: -113.96498599439776
queue_len: 0.07138670012655814
wait_time: 0.6778189060770198
delay_time: 4.50667703972957
pressure: 0.8695844385499559
total_envstep_count: 674424
total_train_sample_count: 674424
total_episode_count: 5814
total_duration: 40315.14656152775
[2024-12-27 23:18:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33464918756044
avg_train_sample_per_sec: 17.33464918756044
avg_episode_per_sec: 0.14943663092724518
collect_time: 40.1507981193792
reward_mean: -108.43534080298787
reward_std: 2.9966057006874536
reward_max: -102.44607843137256
reward_min: -112.54481792717087
queue_len: 0.07190672467041635
wait_time: 0.6822109812094598
delay_time: 4.475677297514671
pressure: 0.8847259062776304
total_envstep_count: 675120
total_train_sample_count: 675120
total_episode_count: 5820
total_duration: 40355.29735964713
[2024-12-27 23:18:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.381013695853788
avg_train_sample_per_sec: 17.381013695853788
avg_episode_per_sec: 0.1498363249642568
collect_time: 40.04369435403124
reward_mean: -108.29119981325863
reward_std: 2.149603631373122
reward_max: -105.6974789915966
reward_min: -111.66456582633052
queue_len: 0.07181114045972058
wait_time: 0.6862811658704153
delay_time: 4.516561891526497
pressure: 0.8774314765694076
total_envstep_count: 675816
total_train_sample_count: 675816
total_episode_count: 5826
total_duration: 40395.34105400116
[2024-12-27 23:19:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.284643980416153
avg_train_sample_per_sec: 17.284643980416153
avg_episode_per_sec: 0.14900555155531167
collect_time: 40.266956078967084
reward_mean: -108.01505602240898
reward_std: 3.388356387604582
reward_max: -102.9019607843137
reward_min: -113.75350140056022
queue_len: 0.0716280212350192
wait_time: 0.6864382026019958
delay_time: 4.499785812800411
pressure: 0.8709106984969055
total_envstep_count: 676512
total_train_sample_count: 676512
total_episode_count: 5832
total_duration: 40435.60801008013
[2024-12-27 23:20:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.169218812088225
avg_train_sample_per_sec: 17.169218812088225
avg_episode_per_sec: 0.14801050700076057
collect_time: 40.53766264018789
reward_mean: -110.59080298786178
reward_std: 2.9516227349893023
reward_max: -107.2612044817927
reward_min: -114.39565826330534
queue_len: 0.07333607625189774
wait_time: 0.7047469518311303
delay_time: 4.575667487586419
pressure: 0.9008620689655172
total_envstep_count: 677208
total_train_sample_count: 677208
total_episode_count: 5838
total_duration: 40476.14567272031
[2024-12-27 23:20:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.16117860222513
avg_train_sample_per_sec: 17.16117860222513
avg_episode_per_sec: 0.14794119484676838
collect_time: 40.556655002107846
reward_mean: -109.88258636788048
reward_std: 2.927399502177955
reward_max: -105.46778711484593
reward_min: -113.03711484593843
queue_len: 0.07286643658347512
wait_time: 0.6996049082763078
delay_time: 4.645378605204301
pressure: 0.8879310344827586
total_envstep_count: 677904
total_train_sample_count: 677904
total_episode_count: 5844
total_duration: 40516.70232772242
[2024-12-27 23:21:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.376503386919552
avg_train_sample_per_sec: 17.376503386919552
avg_episode_per_sec: 0.1497974429906858
collect_time: 40.05408824216761
reward_mean: -107.32703081232494
reward_std: 4.1623382369772495
reward_max: -102.13655462184876
reward_min: -113.47549019607843
queue_len: 0.07117177109570619
wait_time: 0.6786632203721453
delay_time: 4.446004065983949
pressure: 0.8745579133510167
total_envstep_count: 678600
total_train_sample_count: 678600
total_episode_count: 5850
total_duration: 40556.75641596459
[2024-12-27 23:22:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40449015395087
avg_train_sample_per_sec: 17.40449015395087
avg_episode_per_sec: 0.1500387082237144
collect_time: 39.989680470013994
reward_mean: -108.5909197012138
reward_std: 2.2506510891695704
reward_max: -105.33963585434171
reward_min: -111.11414565826328
queue_len: 0.07200989370107018
wait_time: 0.6856070456476137
delay_time: 4.4697799550672155
pressure: 0.8786472148541113
total_envstep_count: 679296
total_train_sample_count: 679296
total_episode_count: 5856
total_duration: 40596.7460964346
[2024-12-27 23:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.260223341783284
avg_train_sample_per_sec: 17.260223341783284
avg_episode_per_sec: 0.1487950288084766
collect_time: 40.323927808925504
reward_mean: -109.71055088702148
reward_std: 3.114279078336912
reward_max: -106.19887955182074
reward_min: -113.3809523809524
queue_len: 0.07275235469961637
wait_time: 0.6949529369661217
delay_time: 4.536631616689678
pressure: 0.8921308576480991
total_envstep_count: 679992
total_train_sample_count: 679992
total_episode_count: 5862
total_duration: 40637.07002424353
[2024-12-27 23:23:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.228926416122476
avg_train_sample_per_sec: 17.228926416122476
avg_episode_per_sec: 0.14852522772519378
collect_time: 40.39717758320086
reward_mean: -106.30135387488328
reward_std: 2.057708998979645
reward_max: -103.39915966386559
reward_min: -108.56932773109243
queue_len: 0.0704916139753868
wait_time: 0.6679060107685869
delay_time: 4.433608475492165
pressure: 0.8629531388152079
total_envstep_count: 680688
total_train_sample_count: 680688
total_episode_count: 5868
total_duration: 40677.46720182673
[2024-12-27 23:24:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.600059925078988
avg_train_sample_per_sec: 17.600059925078988
avg_episode_per_sec: 0.151724654526543
collect_time: 39.54531990020349
reward_mean: -107.08216619981327
reward_std: 1.811194454211993
reward_max: -104.40336134453783
reward_min: -110.3480392156863
queue_len: 0.0710093940317064
wait_time: 0.6765198895650214
delay_time: 4.406585223159752
pressure: 0.8780946065428824
total_envstep_count: 681384
total_train_sample_count: 681384
total_episode_count: 5874
total_duration: 40717.01252172693
[2024-12-27 23:24:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.455443459862444
avg_train_sample_per_sec: 17.455443459862444
avg_episode_per_sec: 0.15047796086088314
collect_time: 39.87294860771671
reward_mean: -106.64752567693743
reward_std: 1.5800766531648618
reward_max: -104.98039215686275
reward_min: -109.57633053221285
queue_len: 0.0707211708733007
wait_time: 0.6778597712294466
delay_time: 4.413623857136035
pressure: 0.8639478337754202
total_envstep_count: 682080
total_train_sample_count: 682080
total_episode_count: 5880
total_duration: 40756.885470334644
[2024-12-27 23:25:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.473181593362863
avg_train_sample_per_sec: 17.473181593362863
avg_episode_per_sec: 0.15063087580485227
collect_time: 39.832471051773055
reward_mean: -107.63772175536879
reward_std: 2.7907620587180952
reward_max: -104.0203081232493
reward_min: -111.00840336134453
queue_len: 0.07137779957252573
wait_time: 0.6829341705736228
delay_time: 4.498602687252522
pressure: 0.8721264367816093
total_envstep_count: 682776
total_train_sample_count: 682776
total_episode_count: 5886
total_duration: 40796.717941386414
[2024-12-27 23:26:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.334969496986673
avg_train_sample_per_sec: 17.334969496986673
avg_episode_per_sec: 0.14943939221540234
collect_time: 40.15005622715317
reward_mean: -107.19817927170867
reward_std: 2.543871068917236
reward_max: -103.19467787114844
reward_min: -110.96288515406162
queue_len: 0.07108632577699514
wait_time: 0.6717912960940345
delay_time: 4.543655761035466
pressure: 0.867816091954023
total_envstep_count: 683472
total_train_sample_count: 683472
total_episode_count: 5892
total_duration: 40836.86799761357
[2024-12-27 23:26:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.434721150943137
avg_train_sample_per_sec: 17.434721150943137
avg_episode_per_sec: 0.1502993202667512
collect_time: 39.920340220775465
reward_mean: -107.4129318394024
reward_std: 3.4881738427890636
reward_max: -103.15826330532214
reward_min: -112.53081232493
queue_len: 0.07122873464151354
wait_time: 0.6790323224780628
delay_time: 4.520794995673049
pressure: 0.8704686118479223
total_envstep_count: 684168
total_train_sample_count: 684168
total_episode_count: 5898
total_duration: 40876.78833783435
[2024-12-27 23:27:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.380769579809115
avg_train_sample_per_sec: 17.380769579809115
avg_episode_per_sec: 0.14983422051559583
collect_time: 40.04425677494332
reward_mean: -107.593837535014
reward_std: 1.5779952165258282
reward_max: -105.03361344537812
reward_min: -109.12044817927169
queue_len: 0.0713486986306459
wait_time: 0.6821123785500055
delay_time: 4.388413834600087
pressure: 0.8761052166224581
total_envstep_count: 684864
total_train_sample_count: 684864
total_episode_count: 5904
total_duration: 40916.83259460929
[2024-12-27 23:28:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.599301493217137
avg_train_sample_per_sec: 17.599301493217137
avg_episode_per_sec: 0.15171811632083737
collect_time: 39.54702408321388
reward_mean: -106.79470121381884
reward_std: 1.5974112039453596
reward_max: -104.78641456582632
reward_min: -108.68487394957982
queue_len: 0.070818767383169
wait_time: 0.6742030366523267
delay_time: 4.398593262166886
pressure: 0.8699160035366932
total_envstep_count: 685560
total_train_sample_count: 685560
total_episode_count: 5910
total_duration: 40956.3796186925
[2024-12-27 23:28:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.59281788792301
avg_train_sample_per_sec: 17.59281788792301
avg_episode_per_sec: 0.1516622231717501
collect_time: 39.56159862700477
reward_mean: -106.37931839402428
reward_std: 1.245682365984669
reward_max: -104.54411764705884
reward_min: -108.28361344537817
queue_len: 0.07054331458489674
wait_time: 0.6771652184304314
delay_time: 4.36771705638969
pressure: 0.8682581786030061
total_envstep_count: 686256
total_train_sample_count: 686256
total_episode_count: 5916
total_duration: 40995.94121731951
[2024-12-27 23:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.424130387760304
avg_train_sample_per_sec: 17.424130387760304
avg_episode_per_sec: 0.15020802058414057
collect_time: 39.94460466669314
reward_mean: -107.63060224089635
reward_std: 2.451005460389328
reward_max: -104.54621848739501
reward_min: -110.90126050420167
queue_len: 0.07137307840908247
wait_time: 0.6845733430419029
delay_time: 4.4713129537825065
pressure: 0.8754420866489832
total_envstep_count: 686952
total_train_sample_count: 686952
total_episode_count: 5922
total_duration: 41035.8858219862
[2024-12-27 23:30:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51578818102534
avg_train_sample_per_sec: 17.51578818102534
avg_episode_per_sec: 0.15099817397435636
collect_time: 39.73557985554822
reward_mean: -105.93218954248368
reward_std: 3.3913925840873698
reward_max: -100.35364145658265
reward_min: -111.04761904761908
queue_len: 0.07024681004143479
wait_time: 0.6764438091770749
delay_time: 4.343616064224267
pressure: 0.8620689655172414
total_envstep_count: 687648
total_train_sample_count: 687648
total_episode_count: 5928
total_duration: 41075.62140184175
[2024-12-27 23:30:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.558995987406913
avg_train_sample_per_sec: 17.558995987406913
avg_episode_per_sec: 0.15137065506385272
collect_time: 39.637801643053066
reward_mean: -107.66468253968253
reward_std: 2.839819723487087
reward_max: -104.66456582633056
reward_min: -112.19187675070029
queue_len: 0.07139567807671256
wait_time: 0.6811652822048359
delay_time: 4.428092676032047
pressure: 0.8812997347480106
total_envstep_count: 688344
total_train_sample_count: 688344
total_episode_count: 5934
total_duration: 41115.259203484806
[2024-12-27 23:31:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.755672947019058
avg_train_sample_per_sec: 17.755672947019058
avg_episode_per_sec: 0.1530661460949919
collect_time: 39.19873958462662
reward_mean: -108.37476657329599
reward_std: 4.042286023363392
reward_max: -102.21078431372548
reward_min: -114.19537815126047
queue_len: 0.07186655608308752
wait_time: 0.6843137564486449
delay_time: 4.549660294029725
pressure: 0.8791998231653405
total_envstep_count: 689040
total_train_sample_count: 689040
total_episode_count: 5940
total_duration: 41154.457943069436
[2024-12-27 23:32:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.3417104723245
avg_train_sample_per_sec: 17.3417104723245
avg_episode_per_sec: 0.14949750407176293
collect_time: 40.13444931575469
reward_mean: -109.8343837535014
reward_std: 2.4147584481449975
reward_max: -106.70168067226889
reward_min: -113.97268907563021
queue_len: 0.07283447198508052
wait_time: 0.6937990381829122
delay_time: 4.572303744242729
pressure: 0.8950044208664899
total_envstep_count: 689736
total_train_sample_count: 689736
total_episode_count: 5946
total_duration: 41194.59239238519
[2024-12-27 23:33:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.62592601083138
avg_train_sample_per_sec: 17.62592601083138
avg_episode_per_sec: 0.15194763802440847
collect_time: 39.48728705500625
reward_mean: -105.87289915966387
reward_std: 2.7818688268192355
reward_max: -100.77380952380952
reward_min: -109.49929971988793
queue_len: 0.07020749281144818
wait_time: 0.6699537573650151
delay_time: 4.469986805206343
pressure: 0.8563218390804597
total_envstep_count: 690432
total_train_sample_count: 690432
total_episode_count: 5952
total_duration: 41234.0796794402
[2024-12-27 23:33:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.412772066716872
avg_train_sample_per_sec: 17.412772066716872
avg_episode_per_sec: 0.15011010402342131
collect_time: 39.97066046309471
reward_mean: -106.53361344537815
reward_std: 2.733383576546279
reward_max: -101.40966386554622
reward_min: -110.12254901960792
queue_len: 0.07064563225820834
wait_time: 0.6757326936079471
delay_time: 4.422995546634014
pressure: 0.872236958443855
total_envstep_count: 691128
total_train_sample_count: 691128
total_episode_count: 5958
total_duration: 41274.05033990329
[2024-12-27 23:34:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.51843380378441
avg_train_sample_per_sec: 17.51843380378441
avg_episode_per_sec: 0.15102098106710699
collect_time: 39.729579013487324
reward_mean: -108.85049019607841
reward_std: 3.016441111131041
reward_max: -103.187675070028
reward_min: -112.34873949579833
queue_len: 0.07218202267644457
wait_time: 0.6954783018423992
delay_time: 4.544163589703768
pressure: 0.8826259946949601
total_envstep_count: 691824
total_train_sample_count: 691824
total_episode_count: 5964
total_duration: 41313.77991891678
[2024-12-27 23:35:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.248647838807305
avg_train_sample_per_sec: 17.248647838807305
avg_episode_per_sec: 0.14869523998971815
collect_time: 40.35098904588259
reward_mean: -109.2236227824463
reward_std: 1.7192295424049238
reward_max: -106.14705882352938
reward_min: -111.03921568627456
queue_len: 0.0724294580785453
wait_time: 0.6966089817890021
delay_time: 4.447684785139164
pressure: 0.8953359858532272
total_envstep_count: 692520
total_train_sample_count: 692520
total_episode_count: 5970
total_duration: 41354.13090796266
[2024-12-27 23:35:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.546200134602945
avg_train_sample_per_sec: 17.546200134602945
avg_episode_per_sec: 0.15126034598795643
collect_time: 39.66670815679431
reward_mean: -107.88083566760038
reward_std: 2.2971265084722403
reward_max: -104.50070028011204
reward_min: -110.90266106442579
queue_len: 0.07153901569469522
wait_time: 0.6861930116874336
delay_time: 4.414121338527351
pressure: 0.8877099911582671
total_envstep_count: 693216
total_train_sample_count: 693216
total_episode_count: 5976
total_duration: 41393.79761611945
[2024-12-27 23:36:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.881429051842982
avg_train_sample_per_sec: 17.881429051842982
avg_episode_per_sec: 0.15415025044692224
collect_time: 38.923063586367306
reward_mean: -111.3250466853408
reward_std: 3.591378081126149
reward_max: -106.5
reward_min: -116.8816526610644
queue_len: 0.07382297525553104
wait_time: 0.7092438987089088
delay_time: 4.617037886017822
pressure: 0.8997568523430592
total_envstep_count: 693912
total_train_sample_count: 693912
total_episode_count: 5982
total_duration: 41432.72067970582
[2024-12-27 23:37:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.535215796084323
avg_train_sample_per_sec: 17.535215796084323
avg_episode_per_sec: 0.15116565341452
collect_time: 39.69155601469241
reward_mean: -106.55777310924371
reward_std: 2.1388208856897433
reward_max: -103.88305322128852
reward_min: -110.1022408963585
queue_len: 0.07066165325546665
wait_time: 0.6760080690100972
delay_time: 4.378461473063474
pressure: 0.872347480106101
total_envstep_count: 694608
total_train_sample_count: 694608
total_episode_count: 5988
total_duration: 41472.41223572051
[2024-12-27 23:37:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.28751868313398
avg_train_sample_per_sec: 17.28751868313398
avg_episode_per_sec: 0.14903033347529296
collect_time: 40.26026017713174
reward_mean: -107.09745564892626
reward_std: 4.076147937526128
reward_max: -100.93697478991605
reward_min: -113.55182072829133
queue_len: 0.07101953292369113
wait_time: 0.6763309656311685
delay_time: 4.47326196732554
pressure: 0.867263483642794
total_envstep_count: 695304
total_train_sample_count: 695304
total_episode_count: 5994
total_duration: 41512.67249589764
[2024-12-27 23:38:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.626743188600617
avg_train_sample_per_sec: 17.626743188600617
avg_episode_per_sec: 0.15195468266035014
collect_time: 39.48545641999878
reward_mean: -104.47537348272643
reward_std: 3.877456322109371
reward_max: -98.22829131652661
reward_min: -109.52450980392159
queue_len: 0.0692807516463703
wait_time: 0.6601443406717241
delay_time: 4.2913014545933414
pressure: 0.8545534924845269
total_envstep_count: 696000
total_train_sample_count: 696000
total_episode_count: 6000
total_duration: 41552.15795231764
[2024-12-27 23:39:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.33122738930723
avg_train_sample_per_sec: 17.33122738930723
avg_episode_per_sec: 0.14940713266644162
collect_time: 40.15872530928814
reward_mean: -107.79738562091505
reward_std: 4.074593951780034
reward_max: -103.51960784313727
reward_min: -115.24019607843137
queue_len: 0.0714836774674503
wait_time: 0.684291543761625
delay_time: 4.436452309271961
pressure: 0.8714633068081343
total_envstep_count: 696696
total_train_sample_count: 696696
total_episode_count: 6006
total_duration: 41592.31667762693
[2024-12-27 23:39:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.584042495068534
avg_train_sample_per_sec: 17.584042495068534
avg_episode_per_sec: 0.15158657323334945
collect_time: 39.581342014795176
reward_mean: -105.57924836601309
reward_std: 3.0634575957749943
reward_max: -100.57072829131651
reward_min: -109.75910364145656
queue_len: 0.0700127641684437
wait_time: 0.6670891720967785
delay_time: 4.392441066506855
pressure: 0.8553271441202476
total_envstep_count: 697392
total_train_sample_count: 697392
total_episode_count: 6012
total_duration: 41631.898019641725
[2024-12-27 23:40:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.42576001208056
avg_train_sample_per_sec: 17.42576001208056
avg_episode_per_sec: 0.15022206906965999
collect_time: 39.94086912235059
reward_mean: -106.17040149393091
reward_std: 3.3826143802576345
reward_max: -101.25210084033617
reward_min: -110.51260504201679
queue_len: 0.07040477552647938
wait_time: 0.6727118455693506
delay_time: 4.445088863529871
pressure: 0.8646109637488948
total_envstep_count: 698088
total_train_sample_count: 698088
total_episode_count: 6018
total_duration: 41671.838888764076
[2024-12-27 23:41:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.624116653279835
avg_train_sample_per_sec: 17.624116653279835
avg_episode_per_sec: 0.15193204011448133
collect_time: 39.491340967178346
reward_mean: -106.95354808590103
reward_std: 3.6553100444375017
reward_max: -103.16596638655464
reward_min: -113.30322128851542
queue_len: 0.07092410350523942
wait_time: 0.6764227574318853
delay_time: 4.421402359345273
pressure: 0.8743368700265252
total_envstep_count: 698784
total_train_sample_count: 698784
total_episode_count: 6024
total_duration: 41711.330229731255
[2024-12-27 23:41:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.662071373125368
avg_train_sample_per_sec: 17.662071373125368
avg_episode_per_sec: 0.15225923597521868
collect_time: 39.4064764713291
reward_mean: -106.76003734827265
reward_std: 1.957588793776507
reward_max: -102.88865546218487
reward_min: -108.90966386554624
queue_len: 0.07079578073492881
wait_time: 0.6794524286283922
delay_time: 4.423880400943992
pressure: 0.8625110521662244
total_envstep_count: 699480
total_train_sample_count: 699480
total_episode_count: 6030
total_duration: 41750.73670620258
[2024-12-27 23:42:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.178563671843705
avg_train_sample_per_sec: 17.178563671843705
avg_episode_per_sec: 0.14809106613658365
collect_time: 40.51561080981232
reward_mean: -105.89915966386557
reward_std: 1.7968377576996573
reward_max: -103.48529411764709
reward_min: -108.87184873949577
queue_len: 0.07022490693890288
wait_time: 0.6690014754796701
delay_time: 4.398008141804799
pressure: 0.8633952254641909
total_envstep_count: 700176
total_train_sample_count: 700176
total_episode_count: 6036
total_duration: 41791.25231701239
[2024-12-27 23:43:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.34222314393626
avg_train_sample_per_sec: 17.34222314393626
avg_episode_per_sec: 0.14950192365462292
collect_time: 40.13326285928674
reward_mean: -107.16351540616246
reward_std: 3.1085688094505897
reward_max: -103.23389355742299
reward_min: -113.04831932773106
queue_len: 0.07106333912875494
wait_time: 0.6847016658122135
delay_time: 4.400205047568568
pressure: 0.8757736516357206
total_envstep_count: 700872
total_train_sample_count: 700872
total_episode_count: 6042
total_duration: 41831.385579871676
[2024-12-27 23:43:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.44798230892582
avg_train_sample_per_sec: 17.44798230892582
avg_episode_per_sec: 0.1504136405941881
collect_time: 39.889999180246136
reward_mean: -107.75396825396824
reward_std: 0.9232711643288496
reward_max: -106.34453781512603
reward_min: -108.76260504201683
queue_len: 0.07145488611005851
wait_time: 0.6857626118528755
delay_time: 4.478586333641475
pressure: 0.8815207780725022
total_envstep_count: 701568
total_train_sample_count: 701568
total_episode_count: 6048
total_duration: 41871.27557905192
[2024-12-27 23:44:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.489783191471528
avg_train_sample_per_sec: 17.489783191471528
avg_episode_per_sec: 0.15077399302992697
collect_time: 39.79466139633953
reward_mean: -108.14460784313722
reward_std: 4.1499475617709285
reward_max: -100.39775910364146
reward_min: -113.16666666666656
queue_len: 0.07171393093046234
wait_time: 0.6851983941233434
delay_time: 4.424598062601702
pressure: 0.882736516357206
total_envstep_count: 702264
total_train_sample_count: 702264
total_episode_count: 6054
total_duration: 41911.070240448265
[2024-12-27 23:45:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.081141692072073
avg_train_sample_per_sec: 17.081141692072073
avg_episode_per_sec: 0.14725122148337993
collect_time: 40.74669085632823
reward_mean: -106.61683006535948
reward_std: 3.999467754496701
reward_max: -99.87815126050421
reward_min: -112.15756302521014
queue_len: 0.0707008156932092
wait_time: 0.6709316573667484
delay_time: 4.417781948430085
pressure: 0.8621794871794872
total_envstep_count: 702960
total_train_sample_count: 702960
total_episode_count: 6060
total_duration: 41951.816931304595
[2024-12-27 23:45:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.929765377474435
avg_train_sample_per_sec: 16.929765377474435
avg_episode_per_sec: 0.14594625325408994
collect_time: 41.11102454650961
reward_mean: -106.30135387488328
reward_std: 1.4714033725638467
reward_max: -104.36904761904762
reward_min: -109.16386554621849
queue_len: 0.0704916139753868
wait_time: 0.673770082745742
delay_time: 4.414855761207413
pressure: 0.8638373121131742
total_envstep_count: 703656
total_train_sample_count: 703656
total_episode_count: 6066
total_duration: 41992.927955851104
[2024-12-27 23:46:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.69579060054078
avg_train_sample_per_sec: 16.69579060054078
avg_episode_per_sec: 0.1439292293150067
collect_time: 41.68715436437353
reward_mean: -110.51388888888887
reward_std: 1.690040002255944
reward_max: -108.96148459383755
reward_min: -113.69677871148457
queue_len: 0.073285072207486
wait_time: 0.6946500859406538
delay_time: 4.543030837710005
pressure: 0.8995358090185676
total_envstep_count: 704352
total_train_sample_count: 704352
total_episode_count: 6072
total_duration: 42034.615110215476
[2024-12-27 23:47:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.41663950248489
avg_train_sample_per_sec: 16.41663950248489
avg_episode_per_sec: 0.14152275433176628
collect_time: 42.396009237740195
reward_mean: -105.22747432306255
reward_std: 1.266737068043539
reward_max: -103.10574229691876
reward_min: -106.84033613445376
queue_len: 0.06977949225667278
wait_time: 0.665080355749727
delay_time: 4.356760255392506
pressure: 0.8656056587091069
total_envstep_count: 705048
total_train_sample_count: 705048
total_episode_count: 6078
total_duration: 42077.011119453215
[2024-12-27 23:48:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.501905946053522
avg_train_sample_per_sec: 16.501905946053522
avg_episode_per_sec: 0.14225780987977174
collect_time: 42.17694624337926
reward_mean: -105.17903828197949
reward_std: 2.937027431971042
reward_max: -101.89005602240897
reward_min: -110.26050420168073
queue_len: 0.06974737286603414
wait_time: 0.6617189647742386
delay_time: 4.3566636397163405
pressure: 0.8614058355437666
total_envstep_count: 705744
total_train_sample_count: 705744
total_episode_count: 6084
total_duration: 42119.188065696595
[2024-12-27 23:48:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8806915367734
avg_train_sample_per_sec: 16.8806915367734
avg_episode_per_sec: 0.145523202903219
collect_time: 41.230538362946376
reward_mean: -107.56045751633985
reward_std: 4.5609838400665765
reward_max: -100.71358543417365
reward_min: -114.48809523809518
queue_len: 0.07132656333974792
wait_time: 0.679752880374077
delay_time: 4.534094859470627
pressure: 0.8681476569407605
total_envstep_count: 706440
total_train_sample_count: 706440
total_episode_count: 6090
total_duration: 42160.41860405954
[2024-12-27 23:49:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.82646925843501
avg_train_sample_per_sec: 16.82646925843501
avg_episode_per_sec: 0.14505576946926732
collect_time: 41.36340127630158
reward_mean: -106.85550887021475
reward_std: 3.8108837421896955
reward_max: -102.30742296918768
reward_min: -112.32563025210082
queue_len: 0.07085909076274187
wait_time: 0.6757631102839015
delay_time: 4.458602265712654
pressure: 0.871684350132626
total_envstep_count: 707136
total_train_sample_count: 707136
total_episode_count: 6096
total_duration: 42201.78200533584
[2024-12-27 23:50:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.605611146027748
avg_train_sample_per_sec: 16.605611146027748
avg_episode_per_sec: 0.14315182022437714
collect_time: 41.91354319208487
reward_mean: -107.50245098039214
reward_std: 2.3204150300619126
reward_max: -105.39915966386556
reward_min: -112.29971988795518
queue_len: 0.07128809746710356
wait_time: 0.682244571126417
delay_time: 4.460541688201557
pressure: 0.8732316534040673
total_envstep_count: 707832
total_train_sample_count: 707832
total_episode_count: 6102
total_duration: 42243.695548527925
[2024-12-27 23:50:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.967260810518805
avg_train_sample_per_sec: 16.967260810518805
avg_episode_per_sec: 0.14626948974585177
collect_time: 41.020174545116724
reward_mean: -104.32329598506067
reward_std: 2.181510452507846
reward_max: -101.13445378151259
reward_min: -107.68557422969187
queue_len: 0.06917990449937711
wait_time: 0.6576011041021184
delay_time: 4.343448355619564
pressure: 0.8544429708222813
total_envstep_count: 708528
total_train_sample_count: 708528
total_episode_count: 6108
total_duration: 42284.715723073045
[2024-12-27 23:51:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.622271814130553
avg_train_sample_per_sec: 16.622271814130553
avg_episode_per_sec: 0.14329544667353925
collect_time: 41.87153283153101
reward_mean: -106.48179271708683
reward_std: 2.5359010653237384
reward_max: -103.76260504201683
reward_min: -110.8109243697479
queue_len: 0.07061126838003105
wait_time: 0.6732446404733423
delay_time: 4.385519884526388
pressure: 0.8663793103448275
total_envstep_count: 709224
total_train_sample_count: 709224
total_episode_count: 6114
total_duration: 42326.587255904575
[2024-12-27 23:52:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.320528643667625
avg_train_sample_per_sec: 16.320528643667625
avg_episode_per_sec: 0.14069421244541055
collect_time: 42.64567742847279
reward_mean: -106.57563025210084
reward_std: 3.2643016916620287
reward_max: -102.23879551820725
reward_min: -111.27591036414563
queue_len: 0.07067349486213585
wait_time: 0.6705003287787262
delay_time: 4.452510756000112
pressure: 0.8565428824049514
total_envstep_count: 709920
total_train_sample_count: 709920
total_episode_count: 6120
total_duration: 42369.23293333305
[2024-12-27 23:52:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.59809451951831
avg_train_sample_per_sec: 16.59809451951831
avg_episode_per_sec: 0.14308702171998544
collect_time: 41.93252419315651
reward_mean: -109.14810924369749
reward_std: 1.4094384075310666
reward_max: -107.10994397759103
reward_min: -111.19467787114846
queue_len: 0.0723793827875978
wait_time: 0.6899803909185248
delay_time: 4.547826313558728
pressure: 0.8801945181255526
total_envstep_count: 710616
total_train_sample_count: 710616
total_episode_count: 6126
total_duration: 42411.16545752621
[2024-12-27 23:53:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.63641928197924
avg_train_sample_per_sec: 16.63641928197924
avg_episode_per_sec: 0.14341740760326932
collect_time: 41.83592564019561
reward_mean: -107.10049019607844
reward_std: 3.7147992428404017
reward_max: -102.0672268907563
reward_min: -112.63725490196077
queue_len: 0.07102154522286368
wait_time: 0.680178713837436
delay_time: 4.50998870416227
pressure: 0.8752210433244917
total_envstep_count: 711312
total_train_sample_count: 711312
total_episode_count: 6132
total_duration: 42453.001383166404
[2024-12-27 23:54:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.616059896829313
avg_train_sample_per_sec: 16.616059896829313
avg_episode_per_sec: 0.14324189566232165
collect_time: 41.8871865124181
reward_mean: -106.39542483660132
reward_std: 3.5104774426427365
reward_max: -101.30042016806723
reward_min: -110.53221288515412
queue_len: 0.07055399524973562
wait_time: 0.665937130820498
delay_time: 4.507704665139696
pressure: 0.8580901856763926
total_envstep_count: 712008
total_train_sample_count: 712008
total_episode_count: 6138
total_duration: 42494.88856967882
[2024-12-27 23:55:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55085911316581
avg_train_sample_per_sec: 16.55085911316581
avg_episode_per_sec: 0.14267981994108458
collect_time: 42.052197728294885
reward_mean: -106.28583099906628
reward_std: 2.131561497577421
reward_max: -102.18137254901963
reward_min: -109.42086834733892
queue_len: 0.07048132029115803
wait_time: 0.6742651857383094
delay_time: 4.491356316678229
pressure: 0.8626215738284704
total_envstep_count: 712704
total_train_sample_count: 712704
total_episode_count: 6144
total_duration: 42536.94076740711
[2024-12-27 23:55:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.407677108962655
avg_train_sample_per_sec: 16.407677108962655
avg_episode_per_sec: 0.1414454923186436
collect_time: 42.41916728235782
reward_mean: -108.25910364145658
reward_std: 5.771490008185309
reward_max: -99.2079831932773
reward_min: -115.72058823529412
queue_len: 0.07178985652616483
wait_time: 0.6856818103014857
delay_time: 4.5055875596504675
pressure: 0.873342175066313
total_envstep_count: 713400
total_train_sample_count: 713400
total_episode_count: 6150
total_duration: 42579.35993468947
[2024-12-27 23:56:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.03054305313973
avg_train_sample_per_sec: 17.03054305313973
avg_episode_per_sec: 0.14681502632017007
collect_time: 40.8677514174562
reward_mean: -107.70821661998131
reward_std: 5.004402791844105
reward_max: -100.17647058823529
reward_min: -114.79971988795516
queue_len: 0.07142454683022634
wait_time: 0.6780979190969049
delay_time: 4.462853038586755
pressure: 0.8704686118479222
total_envstep_count: 714096
total_train_sample_count: 714096
total_episode_count: 6156
total_duration: 42620.227686106926
[2024-12-27 23:57:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.39103164233905
avg_train_sample_per_sec: 16.39103164233905
avg_episode_per_sec: 0.14130199691671597
collect_time: 42.46224491460249
reward_mean: -107.74731559290382
reward_std: 2.1358005540619436
reward_max: -106.1554621848739
reward_min: -112.36974789915969
queue_len: 0.07145047453110333
wait_time: 0.6822324973313818
delay_time: 4.498669322117779
pressure: 0.8759946949602121
total_envstep_count: 714792
total_train_sample_count: 714792
total_episode_count: 6162
total_duration: 42662.68993102153
[2024-12-27 23:57:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.720437812715343
avg_train_sample_per_sec: 16.720437812715343
avg_episode_per_sec: 0.14414170528202883
collect_time: 41.62570429051295
reward_mean: -108.18557422969188
reward_std: 3.215316466103069
reward_max: -103.92296918767508
reward_min: -113.11344537815125
queue_len: 0.07174109696929169
wait_time: 0.6825169280798082
delay_time: 4.515188246564616
pressure: 0.8801945181255526
total_envstep_count: 715488
total_train_sample_count: 715488
total_episode_count: 6168
total_duration: 42704.31563531204
[2024-12-27 23:58:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55460600211643
avg_train_sample_per_sec: 16.55460600211643
avg_episode_per_sec: 0.14271212070790026
collect_time: 42.04267983853072
reward_mean: -106.90371148459384
reward_std: 2.911137416324293
reward_max: -102.30602240896363
reward_min: -109.8921568627451
queue_len: 0.0708910553611365
wait_time: 0.6794357110660356
delay_time: 4.465210492900229
pressure: 0.8630636604774536
total_envstep_count: 716184
total_train_sample_count: 716184
total_episode_count: 6174
total_duration: 42746.35831515057
[2024-12-27 23:59:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.39048306570096
avg_train_sample_per_sec: 16.39048306570096
avg_episode_per_sec: 0.14129726780776689
collect_time: 42.46366609270126
reward_mean: -107.69782913165267
reward_std: 2.088497227149126
reward_max: -103.77240896358545
reward_min: -110.29411764705881
queue_len: 0.07141765857536649
wait_time: 0.6775011176000021
delay_time: 4.608136023464447
pressure: 0.8657161803713528
total_envstep_count: 716880
total_train_sample_count: 716880
total_episode_count: 6180
total_duration: 42788.82198124327
[2024-12-28 00:00:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.51746299237678
avg_train_sample_per_sec: 16.51746299237678
avg_episode_per_sec: 0.14239192234807568
collect_time: 42.137221698103474
reward_mean: -108.59955648926235
reward_std: 2.568297126393649
reward_max: -106.5091036414566
reward_min: -114.18697478991602
queue_len: 0.07201562101409971
wait_time: 0.6889507903072811
delay_time: 4.517749203205763
pressure: 0.8824049513704685
total_envstep_count: 717576
total_train_sample_count: 717576
total_episode_count: 6186
total_duration: 42830.959202941376
[2024-12-28 00:00:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.84533606163205
avg_train_sample_per_sec: 16.84533606163205
avg_episode_per_sec: 0.1452184143244142
collect_time: 41.317074201045564
reward_mean: -106.03326330532212
reward_std: 1.522885231495545
reward_max: -102.86414565826333
reward_min: -107.46008403361346
queue_len: 0.07031383508310485
wait_time: 0.6698297687775376
delay_time: 4.362194898576366
pressure: 0.8713527851458887
total_envstep_count: 718272
total_train_sample_count: 718272
total_episode_count: 6192
total_duration: 42872.276277142424
[2024-12-28 00:01:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.658123464762735
avg_train_sample_per_sec: 16.658123464762735
avg_episode_per_sec: 0.14360451262726495
collect_time: 41.78141682478599
reward_mean: -105.64309056956115
reward_std: 2.740646479988842
reward_max: -102.54201680672267
reward_min: -110.42787114845937
queue_len: 0.07005509984718909
wait_time: 0.6735899045736774
delay_time: 4.378958220951621
pressure: 0.8651635720601237
total_envstep_count: 718968
total_train_sample_count: 718968
total_episode_count: 6198
total_duration: 42914.05769396721
[2024-12-28 00:02:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.970035720387916
avg_train_sample_per_sec: 16.970035720387916
avg_episode_per_sec: 0.14629341138265445
collect_time: 41.01346699959039
reward_mean: -109.07866479925302
reward_std: 3.570750806843505
reward_max: -103.80322128851535
reward_min: -114.30952380952384
queue_len: 0.07233333209499539
wait_time: 0.6889435150718112
delay_time: 4.530328034167747
pressure: 0.888262599469496
total_envstep_count: 719664
total_train_sample_count: 719664
total_episode_count: 6204
total_duration: 42955.0711609668
[2024-12-28 00:02:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.817649571458606
avg_train_sample_per_sec: 16.817649571458606
avg_episode_per_sec: 0.14497973768498798
collect_time: 41.38509350207821
reward_mean: -109.64810924369749
reward_std: 4.386097130655288
reward_max: -104.95868347338934
reward_min: -117.46568627450979
queue_len: 0.07271094777433519
wait_time: 0.6921340928059996
delay_time: 4.562183077590032
pressure: 0.8899204244031829
total_envstep_count: 720360
total_train_sample_count: 720360
total_episode_count: 6210
total_duration: 42996.456254468874
[2024-12-28 00:03:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.639118631437288
avg_train_sample_per_sec: 16.639118631437288
avg_episode_per_sec: 0.14344067785721798
collect_time: 41.829138635084036
reward_mean: -105.41386554621847
reward_std: 3.350418287733717
reward_max: -101.1911764705882
reward_min: -109.9670868347339
queue_len: 0.06990309386354011
wait_time: 0.6686756378059623
delay_time: 4.389848298445469
pressure: 0.8558797524314765
total_envstep_count: 721056
total_train_sample_count: 721056
total_episode_count: 6216
total_duration: 43038.28539310396
[2024-12-28 00:04:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.325165099057024
avg_train_sample_per_sec: 16.325165099057024
avg_episode_per_sec: 0.1407341818884226
collect_time: 42.63356577264891
reward_mean: -109.03886554621847
reward_std: 4.0750915051608905
reward_max: -102.06022408963584
reward_min: -114.57002801120449
queue_len: 0.07230694001738626
wait_time: 0.6930638524198364
delay_time: 4.531720238929624
pressure: 0.8911361626878868
total_envstep_count: 721752
total_train_sample_count: 721752
total_episode_count: 6222
total_duration: 43080.91895887661
[2024-12-28 00:05:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.533183357630453
avg_train_sample_per_sec: 16.533183357630453
avg_episode_per_sec: 0.14252744273819357
collect_time: 42.097156061526384
reward_mean: -105.61846405228756
reward_std: 2.60470934420999
reward_max: -101.48459383753497
reward_min: -109.07843137254906
queue_len: 0.07003876926544268
wait_time: 0.6653928812904474
delay_time: 4.46876421959682
pressure: 0.8474801061007957
total_envstep_count: 722448
total_train_sample_count: 722448
total_episode_count: 6228
total_duration: 43123.01611493814
[2024-12-28 00:05:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.615719835109473
avg_train_sample_per_sec: 16.615719835109473
avg_episode_per_sec: 0.1432389640957713
collect_time: 41.88804378666357
reward_mean: -107.04248366013071
reward_std: 3.583643285835754
reward_max: -102.19817927170868
reward_min: -113.8459383753501
queue_len: 0.07098307935021932
wait_time: 0.6817750862502384
delay_time: 4.400403851723315
pressure: 0.8681476569407605
total_envstep_count: 723144
total_train_sample_count: 723144
total_episode_count: 6234
total_duration: 43164.9041587248
[2024-12-28 00:06:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.517219284745813
avg_train_sample_per_sec: 16.517219284745813
avg_episode_per_sec: 0.14238982142022252
collect_time: 42.13784342275933
reward_mean: -109.87640056022411
reward_std: 3.754445195695082
reward_max: -104.28011204481798
reward_min: -114.22338935574231
queue_len: 0.07286233458900802
wait_time: 0.695191781398678
delay_time: 4.602309481490131
pressure: 0.8934571175950486
total_envstep_count: 723840
total_train_sample_count: 723840
total_episode_count: 6240
total_duration: 43207.04200214756
[2024-12-28 00:07:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.462109742748826
avg_train_sample_per_sec: 16.462109742748826
avg_episode_per_sec: 0.1419147391616278
collect_time: 42.278906584653996
reward_mean: -108.17833800186743
reward_std: 2.132756883154439
reward_max: -105.48039215686278
reward_min: -112.12044817927169
queue_len: 0.07173629840972641
wait_time: 0.6861511403854202
delay_time: 4.523594327621694
pressure: 0.8766578249336869
total_envstep_count: 724536
total_train_sample_count: 724536
total_episode_count: 6246
total_duration: 43249.32090873221
[2024-12-28 00:07:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.88670543211782
avg_train_sample_per_sec: 16.88670543211782
avg_episode_per_sec: 0.1455750468286019
collect_time: 41.215854850895695
reward_mean: -106.03944911297852
reward_std: 2.519276614520521
reward_max: -103.71708683473389
reward_min: -110.84943977591041
queue_len: 0.07031793707757196
wait_time: 0.6744426550461032
delay_time: 4.447343604225403
pressure: 0.8611847922192749
total_envstep_count: 725232
total_train_sample_count: 725232
total_episode_count: 6252
total_duration: 43290.536763583106
[2024-12-28 00:08:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.780896249356495
avg_train_sample_per_sec: 16.780896249356495
avg_episode_per_sec: 0.1446628987013491
collect_time: 41.475734648361815
reward_mean: -107.69712885154063
reward_std: 2.5975677500620273
reward_max: -105.1652661064426
reward_min: -111.39425770308122
queue_len: 0.07141719419863436
wait_time: 0.6826136732323347
delay_time: 4.468957571623151
pressure: 0.8743368700265254
total_envstep_count: 725928
total_train_sample_count: 725928
total_episode_count: 6258
total_duration: 43332.01249823147
[2024-12-28 00:09:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.69898748736054
avg_train_sample_per_sec: 16.69898748736054
avg_episode_per_sec: 0.14395678868414258
collect_time: 41.679173694022005
reward_mean: -107.05917366946778
reward_std: 1.770294584356366
reward_max: -105.13445378151253
reward_min: -110.30532212885151
queue_len: 0.07099414699566829
wait_time: 0.6795073024789048
delay_time: 4.47390040082806
pressure: 0.8704686118479222
total_envstep_count: 726624
total_train_sample_count: 726624
total_episode_count: 6264
total_duration: 43373.69167192549
[2024-12-28 00:09:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.071259256377378
avg_train_sample_per_sec: 17.071259256377378
avg_episode_per_sec: 0.1471660280722188
collect_time: 40.77027883809992
reward_mean: -106.77474323062559
reward_std: 2.021725487646713
reward_max: -103.61904761904763
reward_min: -109.203081232493
queue_len: 0.07080553264630345
wait_time: 0.6710713573669963
delay_time: 4.489995690491628
pressure: 0.867263483642794
total_envstep_count: 727320
total_train_sample_count: 727320
total_episode_count: 6270
total_duration: 43414.46195076359
[2024-12-28 00:10:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.929805497579366
avg_train_sample_per_sec: 16.929805497579366
avg_episode_per_sec: 0.1459465991170635
collect_time: 41.110927121963364
reward_mean: -110.57819794584502
reward_std: 3.738489188671222
reward_max: -105.43067226890759
reward_min: -116.06372549019605
queue_len: 0.07332771747071949
wait_time: 0.6967755382435908
delay_time: 4.58246878287991
pressure: 0.9020778072502211
total_envstep_count: 728016
total_train_sample_count: 728016
total_episode_count: 6276
total_duration: 43455.57287788555
[2024-12-28 00:11:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.541315266300867
avg_train_sample_per_sec: 16.541315266300867
avg_episode_per_sec: 0.1425975453991454
collect_time: 42.076460595484825
reward_mean: -109.16713352007473
reward_std: 4.544431563776548
reward_max: -103.5420168067227
reward_min: -118.55322128851543
queue_len: 0.07239199835548721
wait_time: 0.6923314529171528
delay_time: 4.497058062058667
pressure: 0.8871573828470382
total_envstep_count: 728712
total_train_sample_count: 728712
total_episode_count: 6282
total_duration: 43497.64933848103
[2024-12-28 00:12:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.60264623851017
avg_train_sample_per_sec: 16.60264623851017
avg_episode_per_sec: 0.14312626067681183
collect_time: 41.92102813017927
reward_mean: -109.05322128851539
reward_std: 4.3387950111018885
reward_max: -103.9110644257703
reward_min: -116.13655462184872
queue_len: 0.07231645974039484
wait_time: 0.690378439174078
delay_time: 4.556296843386996
pressure: 0.8850574712643677
total_envstep_count: 729408
total_train_sample_count: 729408
total_episode_count: 6288
total_duration: 43539.57036661121
[2024-12-28 00:12:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.702295947418126
avg_train_sample_per_sec: 16.702295947418126
avg_episode_per_sec: 0.14398530989153555
collect_time: 41.67091771042347
reward_mean: -109.23879551820728
reward_std: 3.552568310010721
reward_max: -102.63935574229693
reward_min: -113.17226890756298
queue_len: 0.07243951957440802
wait_time: 0.6872429674787687
delay_time: 4.531447395632996
pressure: 0.8923519009725905
total_envstep_count: 730104
total_train_sample_count: 730104
total_episode_count: 6294
total_duration: 43581.24128432163
[2024-12-28 00:13:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.927367667201473
avg_train_sample_per_sec: 16.927367667201473
avg_episode_per_sec: 0.14592558333794375
collect_time: 41.11684779840707
reward_mean: -105.73179271708683
reward_std: 2.3055645480317875
reward_max: -101.08333333333334
reward_min: -108.27450980392162
queue_len: 0.07011392089992495
wait_time: 0.6697332558133776
delay_time: 4.441305789094428
pressure: 0.860632183908046
total_envstep_count: 730800
total_train_sample_count: 730800
total_episode_count: 6300
total_duration: 43622.35813212004
[2024-12-28 00:14:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8800240535713
avg_train_sample_per_sec: 16.8800240535713
avg_episode_per_sec: 0.14551744873768363
collect_time: 41.23216873335838
reward_mean: -106.37453314659194
reward_std: 1.4658320567164378
reward_max: -104.89005602240894
reward_min: -109.00840336134455
queue_len: 0.07054014134389387
wait_time: 0.6774550669073998
delay_time: 4.375630438707909
pressure: 0.8706896551724138
total_envstep_count: 731496
total_train_sample_count: 731496
total_episode_count: 6306
total_duration: 43663.5903008534
[2024-12-28 00:14:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.899474684643685
avg_train_sample_per_sec: 16.899474684643685
avg_episode_per_sec: 0.14568512659175592
collect_time: 41.18471212791279
reward_mean: -109.05812324929973
reward_std: 2.216813835496682
reward_max: -106.8781512605042
reward_min: -113.23599439775913
queue_len: 0.0723197103775197
wait_time: 0.6921816914210424
delay_time: 4.49011152474587
pressure: 0.8966622458001767
total_envstep_count: 732192
total_train_sample_count: 732192
total_episode_count: 6312
total_duration: 43704.775012981314
[2024-12-28 00:15:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83070015770997
avg_train_sample_per_sec: 16.83070015770997
avg_episode_per_sec: 0.14509224273887905
collect_time: 41.35300334972515
reward_mean: -106.7266573295985
reward_std: 4.114052875896515
reward_max: -100.10574229691878
reward_min: -111.38235294117644
queue_len: 0.07077364544403084
wait_time: 0.6793754194869814
delay_time: 4.3542466353029505
pressure: 0.8729000884173299
total_envstep_count: 732888
total_train_sample_count: 732888
total_episode_count: 6318
total_duration: 43746.12801633104
[2024-12-28 00:16:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.00318408627672
avg_train_sample_per_sec: 17.00318408627672
avg_episode_per_sec: 0.14657917315755792
collect_time: 40.93350965727308
reward_mean: -107.93580765639588
reward_std: 1.9310960508980353
reward_max: -104.94607843137254
reward_min: -110.53571428571425
queue_len: 0.07157546926816703
wait_time: 0.6880791551810823
delay_time: 4.45221740421728
pressure: 0.8811892130857649
total_envstep_count: 733584
total_train_sample_count: 733584
total_episode_count: 6324
total_duration: 43787.06152598831
[2024-12-28 00:16:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.644321600117916
avg_train_sample_per_sec: 16.644321600117916
avg_episode_per_sec: 0.1434855310354993
collect_time: 41.816062962582336
reward_mean: -109.51598972922501
reward_std: 4.278911352336958
reward_max: -103.66036414565824
reward_min: -114.95378151260506
queue_len: 0.07262333536420758
wait_time: 0.70052530295938
delay_time: 4.498631788137626
pressure: 0.8947833775419983
total_envstep_count: 734280
total_train_sample_count: 734280
total_episode_count: 6330
total_duration: 43828.8775889509
[2024-12-28 00:17:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.62095416835511
avg_train_sample_per_sec: 16.62095416835511
avg_episode_per_sec: 0.1432840876582337
collect_time: 41.8748522467576
reward_mean: -111.32329598506071
reward_std: 2.0547988073080714
reward_max: -108.83473389355744
reward_min: -114.32352941176471
queue_len: 0.07382181431370072
wait_time: 0.7088148920045473
delay_time: 4.596782966126914
pressure: 0.9037356321839082
total_envstep_count: 734976
total_train_sample_count: 734976
total_episode_count: 6336
total_duration: 43870.752441197656
[2024-12-28 00:18:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.033682788891138
avg_train_sample_per_sec: 17.033682788891138
avg_episode_per_sec: 0.14684209300768222
collect_time: 40.86021846396662
reward_mean: -107.49964985994399
reward_std: 3.498968196922717
reward_max: -102.03641456582635
reward_min: -111.3844537815126
queue_len: 0.07128623996017507
wait_time: 0.681254597329648
delay_time: 4.457046682991504
pressure: 0.8735632183908045
total_envstep_count: 735672
total_train_sample_count: 735672
total_episode_count: 6342
total_duration: 43911.61265966162
[2024-12-28 00:19:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.799717715656293
avg_train_sample_per_sec: 16.799717715656293
avg_episode_per_sec: 0.14482515272117494
collect_time: 41.42926754961908
reward_mean: -105.6078431372549
reward_std: 1.940347974243342
reward_max: -101.69537815126048
reward_min: -107.49579831932773
queue_len: 0.0700317262183388
wait_time: 0.6694276185275171
delay_time: 4.3598708793098275
pressure: 0.8593059239610964
total_envstep_count: 736368
total_train_sample_count: 736368
total_episode_count: 6348
total_duration: 43953.04192721124
[2024-12-28 00:19:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.711214987521043
avg_train_sample_per_sec: 16.711214987521043
avg_episode_per_sec: 0.14406219816828486
collect_time: 41.64867728167773
reward_mean: -109.09278711484592
reward_std: 3.171376833189875
reward_max: -103.87464985994399
reward_min: -113.78711484593835
queue_len: 0.07234269702575989
wait_time: 0.6953276115928245
delay_time: 4.450506198581042
pressure: 0.8932360742705571
total_envstep_count: 737064
total_train_sample_count: 737064
total_episode_count: 6354
total_duration: 43994.69060449292
[2024-12-28 00:20:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.842940780487954
avg_train_sample_per_sec: 16.842940780487954
avg_episode_per_sec: 0.14519776534903409
collect_time: 41.322950016323475
reward_mean: -107.38620448179272
reward_std: 2.499126581454957
reward_max: -104.24579831932769
reward_min: -110.26680672268905
queue_len: 0.07121101092957076
wait_time: 0.6770845716712858
delay_time: 4.490601260010666
pressure: 0.8660477453580903
total_envstep_count: 737760
total_train_sample_count: 737760
total_episode_count: 6360
total_duration: 44036.01355450924
[2024-12-28 00:21:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.86961166780443
avg_train_sample_per_sec: 16.86961166780443
avg_episode_per_sec: 0.14542768679141752
collect_time: 41.257618355751035
reward_mean: -108.19631185807657
reward_std: 2.9947662914972275
reward_max: -103.47478991596638
reward_min: -112.63865546218487
queue_len: 0.07174821741251762
wait_time: 0.6823501394368533
delay_time: 4.508650503224673
pressure: 0.8824049513704687
total_envstep_count: 738456
total_train_sample_count: 738456
total_episode_count: 6366
total_duration: 44077.271172864996
[2024-12-28 00:21:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.397576300083585
avg_train_sample_per_sec: 16.397576300083585
avg_episode_per_sec: 0.1413584163800309
collect_time: 42.445297235570855
reward_mean: -106.31629318394026
reward_std: 2.954707898318534
reward_max: -101.92016806722691
reward_min: -109.29901960784312
queue_len: 0.07050152067900549
wait_time: 0.6763019420854106
delay_time: 4.390880112033361
pressure: 0.8695844385499557
total_envstep_count: 739152
total_train_sample_count: 739152
total_episode_count: 6372
total_duration: 44119.71647010057
[2024-12-28 00:22:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.693691868682038
avg_train_sample_per_sec: 16.693691868682038
avg_episode_per_sec: 0.14391113679898307
collect_time: 41.692395275710155
reward_mean: -103.87826797385621
reward_std: 1.682675889831064
reward_max: -101.63585434173663
reward_min: -105.98529411764704
queue_len: 0.06888479308611153
wait_time: 0.6567967262059554
delay_time: 4.329777903136537
pressure: 0.849027409372237
total_envstep_count: 739848
total_train_sample_count: 739848
total_episode_count: 6378
total_duration: 44161.40886537628
[2024-12-28 00:23:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.552816121024037
avg_train_sample_per_sec: 16.552816121024037
avg_episode_per_sec: 0.14269669069848306
collect_time: 42.0472259772159
reward_mean: -109.91456582633053
reward_std: 2.332995989145509
reward_max: -106.99439775910362
reward_min: -112.71988795518205
queue_len: 0.07288764312090883
wait_time: 0.7020523284468517
delay_time: 4.523402284082887
pressure: 0.8889257294429708
total_envstep_count: 740544
total_train_sample_count: 740544
total_episode_count: 6384
total_duration: 44203.456091353495
[2024-12-28 00:24:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.810399181003767
avg_train_sample_per_sec: 16.810399181003767
avg_episode_per_sec: 0.14491723431899797
collect_time: 41.402943053636704
reward_mean: -106.83403361344538
reward_std: 3.1254294037091754
reward_max: -102.5728291316527
reward_min: -112.05182072829132
queue_len: 0.07084484987629004
wait_time: 0.6756926798128625
delay_time: 4.438725013613982
pressure: 0.866710875331565
total_envstep_count: 741240
total_train_sample_count: 741240
total_episode_count: 6390
total_duration: 44244.859034407134
[2024-12-28 00:24:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61461859959888
avg_train_sample_per_sec: 16.61461859959888
avg_episode_per_sec: 0.14322947068619724
collect_time: 41.890820173073564
reward_mean: -107.6594304388422
reward_std: 3.1718562273096085
reward_max: -102.8872549019608
reward_min: -112.08053221288515
queue_len: 0.07139219525122162
wait_time: 0.6831893455879255
delay_time: 4.488750553147803
pressure: 0.8723474801061007
total_envstep_count: 741936
total_train_sample_count: 741936
total_episode_count: 6396
total_duration: 44286.74985458021
[2024-12-28 00:25:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.49805413319779
avg_train_sample_per_sec: 16.49805413319779
avg_episode_per_sec: 0.14222460459653266
collect_time: 42.18679332609848
reward_mean: -108.58053221288516
reward_std: 3.43642765847462
reward_max: -103.76540616246498
reward_min: -114.14145658263308
queue_len: 0.07200300544621031
wait_time: 0.6862315549562
delay_time: 4.4611271424624634
pressure: 0.890473032714412
total_envstep_count: 742632
total_train_sample_count: 742632
total_episode_count: 6402
total_duration: 44328.93664790631
[2024-12-28 00:26:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71987185252856
avg_train_sample_per_sec: 16.71987185252856
avg_episode_per_sec: 0.14413682631490135
collect_time: 41.62711330199241
reward_mean: -107.13025210084032
reward_std: 3.3737904699582137
reward_max: -102.28781512605043
reward_min: -112.10294117647061
queue_len: 0.071041281233979
wait_time: 0.6803299458598646
delay_time: 4.3593191569056255
pressure: 0.8768788682581786
total_envstep_count: 743328
total_train_sample_count: 743328
total_episode_count: 6408
total_duration: 44370.5637612083
[2024-12-28 00:26:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.683084140045338
avg_train_sample_per_sec: 16.683084140045338
avg_episode_per_sec: 0.1438196908624598
collect_time: 41.71890485940501
reward_mean: -105.45144724556489
reward_std: 2.8483538584977266
reward_max: -103.09383753501402
reward_min: -110.91666666666661
queue_len: 0.06992801541483083
wait_time: 0.6639888382408667
delay_time: 4.400526333713849
pressure: 0.8604111405835545
total_envstep_count: 744024
total_train_sample_count: 744024
total_episode_count: 6414
total_duration: 44412.28266606771
[2024-12-28 00:27:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.80540054553791
avg_train_sample_per_sec: 16.80540054553791
avg_episode_per_sec: 0.14487414263394752
collect_time: 41.415258036488666
reward_mean: -105.83204948646126
reward_std: 3.1806850507327113
reward_max: -100.81302521008408
reward_min: -109.8375350140056
queue_len: 0.07018040416874088
wait_time: 0.6705613169228788
delay_time: 4.359304444241054
pressure: 0.8596374889478339
total_envstep_count: 744720
total_train_sample_count: 744720
total_episode_count: 6420
total_duration: 44453.6979241042
[2024-12-28 00:28:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.724741974206566
avg_train_sample_per_sec: 16.724741974206566
avg_episode_per_sec: 0.14417881012247039
collect_time: 41.614991793200375
reward_mean: -105.28011204481793
reward_std: 2.009436505259121
reward_max: -102.30042016806725
reward_min: -107.35224089635851
queue_len: 0.0698143979077042
wait_time: 0.6663946966938853
delay_time: 4.3279933082507975
pressure: 0.867263483642794
total_envstep_count: 745416
total_train_sample_count: 745416
total_episode_count: 6426
total_duration: 44495.3129158974
[2024-12-28 00:28:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.074103896079063
avg_train_sample_per_sec: 17.074103896079063
avg_episode_per_sec: 0.1471905508282678
collect_time: 40.76348628520593
reward_mean: -107.07364612511674
reward_std: 2.755733378401085
reward_max: -103.73459383753502
reward_min: -111.49929971988796
queue_len: 0.0710037441147989
wait_time: 0.6786378344441225
delay_time: 4.442300764664454
pressure: 0.8804155614500441
total_envstep_count: 746112
total_train_sample_count: 746112
total_episode_count: 6432
total_duration: 44536.0764021826
[2024-12-28 00:29:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.648918130141915
avg_train_sample_per_sec: 16.648918130141915
avg_episode_per_sec: 0.14352515629432686
collect_time: 41.80451814102754
reward_mean: -104.39764239028945
reward_std: 2.8910171546123147
reward_max: -101.68067226890754
reward_min: -109.64285714285714
queue_len: 0.06922920582910441
wait_time: 0.6645901287128468
delay_time: 4.3251486612395205
pressure: 0.863395225464191
total_envstep_count: 746808
total_train_sample_count: 746808
total_episode_count: 6438
total_duration: 44577.88092032363
[2024-12-28 00:30:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.583607407785724
avg_train_sample_per_sec: 16.583607407785724
avg_episode_per_sec: 0.142962132825739
collect_time: 41.969155617687846
reward_mean: -106.29190009337067
reward_std: 2.0607710232676326
reward_max: -102.63725490196076
reward_min: -109.30672268907564
queue_len: 0.0704853448895031
wait_time: 0.6708457476713056
delay_time: 4.435879300391533
pressure: 0.8557692307692307
total_envstep_count: 747504
total_train_sample_count: 747504
total_episode_count: 6444
total_duration: 44619.85007594132
[2024-12-28 00:31:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.182303612521807
avg_train_sample_per_sec: 16.182303612521807
avg_episode_per_sec: 0.13950261734932592
collect_time: 43.009945720054205
reward_mean: -108.88550420168066
reward_std: 2.505061730949404
reward_max: -105.625350140056
reward_min: -113.44677871148458
queue_len: 0.07220524151305084
wait_time: 0.6863783753996736
delay_time: 4.503866382410659
pressure: 0.8920203359858533
total_envstep_count: 748200
total_train_sample_count: 748200
total_episode_count: 6450
total_duration: 44662.86002166138
[2024-12-28 00:31:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.517029811344116
avg_train_sample_per_sec: 16.517029811344116
avg_episode_per_sec: 0.14238818802882858
collect_time: 42.13832680267841
reward_mean: -103.77030812324931
reward_std: 3.3231058869633143
reward_max: -99.3095238095238
reward_min: -108.68907563025209
queue_len: 0.06881320167324224
wait_time: 0.6499672150027122
delay_time: 4.282463763558579
pressure: 0.84184350132626
total_envstep_count: 748896
total_train_sample_count: 748896
total_episode_count: 6456
total_duration: 44704.998348464054
[2024-12-28 00:32:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83389966185087
avg_train_sample_per_sec: 16.83389966185087
avg_episode_per_sec: 0.14511982467112822
collect_time: 41.34514366729185
reward_mean: -106.49183006535947
reward_std: 4.282979339215382
reward_max: -100.84523809523809
reward_min: -111.70518207282913
queue_len: 0.07061792444652486
wait_time: 0.6721956134354713
delay_time: 4.438230622584183
pressure: 0.8679266136162688
total_envstep_count: 749592
total_train_sample_count: 749592
total_episode_count: 6462
total_duration: 44746.343492131346
[2024-12-28 00:33:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.712172912544826
avg_train_sample_per_sec: 16.712172912544826
avg_episode_per_sec: 0.1440704561426278
collect_time: 41.64629002118297
reward_mean: -106.94292717086836
reward_std: 2.3635880148541344
reward_max: -102.91036414565826
reward_min: -110.53501400560225
queue_len: 0.07091706045813552
wait_time: 0.6751276881221102
delay_time: 4.451721037985414
pressure: 0.8712422634836429
total_envstep_count: 750288
total_train_sample_count: 750288
total_episode_count: 6468
total_duration: 44787.98978215253
[2024-12-28 00:33:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.612863685806495
avg_train_sample_per_sec: 16.612863685806495
avg_episode_per_sec: 0.1432143421190215
collect_time: 41.895245345005776
reward_mean: -108.00676937441642
reward_std: 0.7895674739452422
reward_max: -106.6624649859944
reward_min: -109.12745098039217
queue_len: 0.07162252611035572
wait_time: 0.6836568181649317
delay_time: 4.46893298545069
pressure: 0.8815207780725022
total_envstep_count: 750984
total_train_sample_count: 750984
total_episode_count: 6474
total_duration: 44829.885027497534
[2024-12-28 00:34:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.947024473464296
avg_train_sample_per_sec: 16.947024473464296
avg_episode_per_sec: 0.14609503856434738
collect_time: 41.06915648170562
reward_mean: -105.86904761904763
reward_std: 1.7520538184986048
reward_max: -103.37394957983193
reward_min: -108.53991596638657
queue_len: 0.0702049387394215
wait_time: 0.6655163281050706
delay_time: 4.402776362651303
pressure: 0.8609637488947833
total_envstep_count: 751680
total_train_sample_count: 751680
total_episode_count: 6480
total_duration: 44870.95418397924
[2024-12-28 00:35:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.165564597883517
avg_train_sample_per_sec: 17.165564597883517
avg_episode_per_sec: 0.14797900515416823
collect_time: 40.54629231862351
reward_mean: -105.53127917833801
reward_std: 3.6738310000239336
reward_max: -99.15826330532211
reward_min: -110.79481792717087
queue_len: 0.06998095436229311
wait_time: 0.6703222403019563
delay_time: 4.336690848072909
pressure: 0.8578691423519009
total_envstep_count: 752376
total_train_sample_count: 752376
total_episode_count: 6486
total_duration: 44911.50047629786
[2024-12-28 00:35:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.762798815361425
avg_train_sample_per_sec: 16.762798815361425
avg_episode_per_sec: 0.14450688633932263
collect_time: 41.52051263433322
reward_mean: -108.44969654528478
reward_std: 2.769813298724576
reward_max: -103.14985994397757
reward_min: -111.40826330532214
queue_len: 0.07191624439342491
wait_time: 0.6905887244376089
delay_time: 4.511718359396833
pressure: 0.8821839080459769
total_envstep_count: 753072
total_train_sample_count: 753072
total_episode_count: 6492
total_duration: 44953.02098893219
[2024-12-28 00:36:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.030660424965816
avg_train_sample_per_sec: 17.030660424965816
avg_episode_per_sec: 0.14681603814625704
collect_time: 40.86746976527758
reward_mean: -106.65908029878618
reward_std: 3.765307755059026
reward_max: -101.51120448179269
reward_min: -112.01050420168062
queue_len: 0.07072883308938076
wait_time: 0.6753112717235435
delay_time: 4.422466941820478
pressure: 0.8720159151193633
total_envstep_count: 753768
total_train_sample_count: 753768
total_episode_count: 6498
total_duration: 44993.88845869747
[2024-12-28 00:37:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.666566634214853
avg_train_sample_per_sec: 16.666566634214853
avg_episode_per_sec: 0.1436772985708177
collect_time: 41.760250642815606
reward_mean: -106.28174603174601
reward_std: 3.190045010194548
reward_max: -100.359243697479
reward_min: -108.72829131652657
queue_len: 0.07047861142688729
wait_time: 0.6729778560407363
delay_time: 4.425927578007913
pressure: 0.8657161803713529
total_envstep_count: 754464
total_train_sample_count: 754464
total_episode_count: 6504
total_duration: 45035.64870934028
[2024-12-28 00:38:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.416144298063262
avg_train_sample_per_sec: 16.416144298063262
avg_episode_per_sec: 0.14151848532813158
collect_time: 42.39728814287484
reward_mean: -106.71370214752568
reward_std: 2.5751142378022167
reward_max: -104.0910364145658
reward_min: -111.24229691876756
queue_len: 0.07076505447448651
wait_time: 0.6788782267991195
delay_time: 4.4202132223638815
pressure: 0.865053050397878
total_envstep_count: 755160
total_train_sample_count: 755160
total_episode_count: 6510
total_duration: 45078.04599748316
[2024-12-28 00:38:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.698578742250376
avg_train_sample_per_sec: 16.698578742250376
avg_episode_per_sec: 0.1439532650193998
collect_time: 41.68019391009584
reward_mean: -105.15581232492998
reward_std: 5.585586103092058
reward_max: -99.65616246498602
reward_min: -114.7170868347339
queue_len: 0.06973197103775199
wait_time: 0.6642971069948757
delay_time: 4.296826606853614
pressure: 0.8531167108753316
total_envstep_count: 755856
total_train_sample_count: 755856
total_episode_count: 6516
total_duration: 45119.72619139326
[2024-12-28 00:39:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.913484937807876
avg_train_sample_per_sec: 16.913484937807876
avg_episode_per_sec: 0.14580590463627477
collect_time: 41.150596849747
reward_mean: -107.37301587301586
reward_std: 3.3044291675730206
reward_max: -100.95518207282913
reward_min: -110.68837535014003
queue_len: 0.0712022651677824
wait_time: 0.6831057577761431
delay_time: 4.395577832667702
pressure: 0.8714633068081344
total_envstep_count: 756552
total_train_sample_count: 756552
total_episode_count: 6522
total_duration: 45160.876788243004
[2024-12-28 00:40:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.886513547172907
avg_train_sample_per_sec: 16.886513547172907
avg_episode_per_sec: 0.1455733926480423
collect_time: 41.21632319517621
reward_mean: -106.49568160597572
reward_std: 2.375665314587211
reward_max: -104.05742296918767
reward_min: -110.35434173669466
queue_len: 0.07062047851855152
wait_time: 0.6670257072767215
delay_time: 4.438576411152661
pressure: 0.8709106984969054
total_envstep_count: 757248
total_train_sample_count: 757248
total_episode_count: 6528
total_duration: 45202.09311143818
[2024-12-28 00:40:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.61196948240425
avg_train_sample_per_sec: 16.61196948240425
avg_episode_per_sec: 0.14320663346900214
collect_time: 41.897500518359244
reward_mean: -109.0219421101774
reward_std: 3.124553172779429
reward_max: -105.19607843137256
reward_min: -114.38515406162463
queue_len: 0.07229571757969323
wait_time: 0.6879369785049297
delay_time: 4.500989609516546
pressure: 0.8879310344827585
total_envstep_count: 757944
total_train_sample_count: 757944
total_episode_count: 6534
total_duration: 45243.99061195654
[2024-12-28 00:41:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.892097244886163
avg_train_sample_per_sec: 16.892097244886163
avg_episode_per_sec: 0.14562152797315656
collect_time: 41.20269910302014
reward_mean: -107.16876750700281
reward_std: 3.4952234494495475
reward_max: -102.17016806722688
reward_min: -113.99299719887954
queue_len: 0.07106682195424589
wait_time: 0.6759021911151728
delay_time: 4.457701914730774
pressure: 0.8693633952254641
total_envstep_count: 758640
total_train_sample_count: 758640
total_episode_count: 6540
total_duration: 45285.193311059564
[2024-12-28 00:42:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.72005810071162
avg_train_sample_per_sec: 16.72005810071162
avg_episode_per_sec: 0.14413843190268638
collect_time: 41.62664960897341
reward_mean: -107.79878618113912
reward_std: 2.9713647279083584
reward_max: -103.95308123249299
reward_min: -112.42717086834733
queue_len: 0.07148460622091454
wait_time: 0.6805153869682269
delay_time: 4.460340319357326
pressure: 0.876105216622458
total_envstep_count: 759336
total_train_sample_count: 759336
total_episode_count: 6546
total_duration: 45326.81996066854
[2024-12-28 00:43:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.513038805181193
avg_train_sample_per_sec: 16.513038805181193
avg_episode_per_sec: 0.14235378280328614
collect_time: 42.148511137854314
reward_mean: -105.6551120448179
reward_std: 2.1900884331318546
reward_max: -102.82492997198881
reward_min: -108.00770308123245
queue_len: 0.07006307164775724
wait_time: 0.6662430776908463
delay_time: 4.429710463223825
pressure: 0.8511273209549071
total_envstep_count: 760032
total_train_sample_count: 760032
total_episode_count: 6552
total_duration: 45368.968471806395
[2024-12-28 00:43:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76725781754657
avg_train_sample_per_sec: 16.76725781754657
avg_episode_per_sec: 0.14454532601333253
collect_time: 41.50947087314725
reward_mean: -104.80018674136319
reward_std: 2.3663728339475565
reward_max: -101.64215686274508
reward_min: -108.19467787114843
queue_len: 0.06949614505395438
wait_time: 0.6599325074857529
delay_time: 4.307731671717305
pressure: 0.8464854111405836
total_envstep_count: 760728
total_train_sample_count: 760728
total_episode_count: 6558
total_duration: 45410.47794267954
[2024-12-28 00:44:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.516391447663985
avg_train_sample_per_sec: 16.516391447663985
avg_episode_per_sec: 0.14238268489365502
collect_time: 42.139955462150276
reward_mean: -105.484126984127
reward_std: 1.063328073199997
reward_max: -103.79131652661069
reward_min: -107.17927170868349
queue_len: 0.06994968632899669
wait_time: 0.6684642689967234
delay_time: 4.348486758459922
pressure: 0.8649425287356323
total_envstep_count: 761424
total_train_sample_count: 761424
total_episode_count: 6564
total_duration: 45452.617898141696
[2024-12-28 00:45:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.666448144081727
avg_train_sample_per_sec: 16.666448144081727
avg_episode_per_sec: 0.14367627710415282
collect_time: 41.760547537367785
reward_mean: -109.82411297852472
reward_std: 4.2240149946972645
reward_max: -105.33193277310927
reward_min: -118.11134453781507
queue_len: 0.07282766112634266
wait_time: 0.6949467452763599
delay_time: 4.5731621761093
pressure: 0.8931255526083112
total_envstep_count: 762120
total_train_sample_count: 762120
total_episode_count: 6570
total_duration: 45494.37844567907
[2024-12-28 00:45:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.954533394444994
avg_train_sample_per_sec: 16.954533394444994
avg_episode_per_sec: 0.14615977064176716
collect_time: 41.05096753815935
reward_mean: -106.57621381886088
reward_std: 3.8028992314873853
reward_max: -101.99019607843138
reward_min: -112.65056022408967
queue_len: 0.07067388184274594
wait_time: 0.6702380333211976
delay_time: 4.41948189319177
pressure: 0.8668213969938109
total_envstep_count: 762816
total_train_sample_count: 762816
total_episode_count: 6576
total_duration: 45535.42941321723
[2024-12-28 00:46:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.91525757108128
avg_train_sample_per_sec: 16.91525757108128
avg_episode_per_sec: 0.14582118595759724
collect_time: 41.1462844757326
reward_mean: -104.03396358543417
reward_std: 1.1872739205637808
reward_max: -102.7303921568627
reward_min: -106.13095238095241
queue_len: 0.06898803951288739
wait_time: 0.6544082044842693
delay_time: 4.2955682040975125
pressure: 0.8471485411140584
total_envstep_count: 763512
total_train_sample_count: 763512
total_episode_count: 6582
total_duration: 45576.57569769296
[2024-12-28 00:47:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.121871448373867
avg_train_sample_per_sec: 17.121871448373867
avg_episode_per_sec: 0.1476023400721885
collect_time: 40.64976203673705
reward_mean: -105.32528011204482
reward_std: 3.8022296383700476
reward_max: -100.14005602240897
reward_min: -109.22198879551819
queue_len: 0.06984435020692627
wait_time: 0.666749867497839
delay_time: 4.382109445216702
pressure: 0.8536693191865607
total_envstep_count: 764208
total_train_sample_count: 764208
total_episode_count: 6588
total_duration: 45617.2254597297
[2024-12-28 00:47:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.234984116037257
avg_train_sample_per_sec: 17.234984116037257
avg_episode_per_sec: 0.14857744927618324
collect_time: 40.382978905815634
reward_mean: -102.32469654528478
reward_std: 1.0478400983186775
reward_max: -100.02380952380955
reward_min: -103.0847338935574
queue_len: 0.06785457330589177
wait_time: 0.6441021368759705
delay_time: 4.279067116297422
pressure: 0.8380857648099028
total_envstep_count: 764904
total_train_sample_count: 764904
total_episode_count: 6594
total_duration: 45657.608438635514
[2024-12-28 00:48:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89484811360248
avg_train_sample_per_sec: 16.89484811360248
avg_episode_per_sec: 0.1456452423586421
collect_time: 41.195990358719605
reward_mean: -106.56465919701212
reward_std: 4.946146556380638
reward_max: -102.32072829131651
reward_min: -117.10294117647055
queue_len: 0.07066621962666586
wait_time: 0.6717254319941945
delay_time: 4.374238543989938
pressure: 0.8631741821396993
total_envstep_count: 765600
total_train_sample_count: 765600
total_episode_count: 6600
total_duration: 45698.80442899423
[2024-12-28 00:49:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.884950917548768
avg_train_sample_per_sec: 16.884950917548768
avg_episode_per_sec: 0.1455599217030066
collect_time: 41.22013758871146
reward_mean: -108.24136321195147
reward_std: 3.0195342106945264
reward_max: -105.38935574229693
reward_min: -113.46148459383753
queue_len: 0.07177809231561767
wait_time: 0.6831134199922232
delay_time: 4.427690351822865
pressure: 0.8831786030061891
total_envstep_count: 766296
total_train_sample_count: 766296
total_episode_count: 6606
total_duration: 45740.02456658294
[2024-12-28 00:50:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56926940593861
avg_train_sample_per_sec: 16.56926940593861
avg_episode_per_sec: 0.14283852936153973
collect_time: 42.00547308081948
reward_mean: -106.92810457516339
reward_std: 3.3433951845567065
reward_max: -102.00560224089635
reward_min: -113.01540616246496
queue_len: 0.07090723115063886
wait_time: 0.6769030777651467
delay_time: 4.450273000443228
pressure: 0.8673740053050398
total_envstep_count: 766992
total_train_sample_count: 766992
total_episode_count: 6612
total_duration: 45782.03003966376
[2024-12-28 00:50:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.82832558363591
avg_train_sample_per_sec: 16.82832558363591
avg_episode_per_sec: 0.14507177227272336
collect_time: 41.35883849768154
reward_mean: -108.37044817927169
reward_std: 3.930387264239996
reward_max: -104.3004201680672
reward_min: -115.49789915966392
queue_len: 0.07186369242657274
wait_time: 0.6844095728477068
delay_time: 4.496152425814292
pressure: 0.875
total_envstep_count: 767688
total_train_sample_count: 767688
total_episode_count: 6618
total_duration: 45823.388878161444
[2024-12-28 00:51:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.914530568474518
avg_train_sample_per_sec: 16.914530568474518
avg_episode_per_sec: 0.14581491869374585
collect_time: 41.148052982162696
reward_mean: -106.06080765639592
reward_std: 2.425161746075043
reward_max: -102.3228291316527
reward_min: -110.47198879551824
queue_len: 0.0703321005679018
wait_time: 0.6674278575267419
delay_time: 4.424019979704989
pressure: 0.8633952254641909
total_envstep_count: 768384
total_train_sample_count: 768384
total_episode_count: 6624
total_duration: 45864.53693114361
[2024-12-28 00:52:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.906524177576802
avg_train_sample_per_sec: 16.906524177576802
avg_episode_per_sec: 0.14574589808255864
collect_time: 41.16753938832134
reward_mean: -107.8144257703081
reward_std: 2.252141268665472
reward_max: -105.46638655462183
reward_min: -111.63165266106441
queue_len: 0.07149497730126532
wait_time: 0.6772879686799566
delay_time: 4.520928690473677
pressure: 0.8743368700265252
total_envstep_count: 769080
total_train_sample_count: 769080
total_episode_count: 6630
total_duration: 45905.70447053193
[2024-12-28 00:52:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.07289138776022
avg_train_sample_per_sec: 17.07289138776022
avg_episode_per_sec: 0.14718009817034672
collect_time: 40.76638128788024
reward_mean: -104.44957983193278
reward_std: 2.5810184990934206
reward_max: -101.18977591036413
reward_min: -108.11274509803918
queue_len: 0.0692636471034037
wait_time: 0.6546434112990908
delay_time: 4.3810328984794795
pressure: 0.8512378426171531
total_envstep_count: 769776
total_train_sample_count: 769776
total_episode_count: 6636
total_duration: 45946.47085181981
[2024-12-28 00:53:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56561967450282
avg_train_sample_per_sec: 16.56561967450282
avg_episode_per_sec: 0.14280706615950708
collect_time: 42.01472771171108
reward_mean: -106.79435107376285
reward_std: 2.5567810823802266
reward_max: -103.50770308123253
reward_min: -110.9264705882353
queue_len: 0.07081853519480295
wait_time: 0.6730778518303873
delay_time: 4.47325226930175
pressure: 0.8652740937223696
total_envstep_count: 770472
total_train_sample_count: 770472
total_episode_count: 6642
total_duration: 45988.48557953152
[2024-12-28 00:54:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.6491655149968
avg_train_sample_per_sec: 16.6491655149968
avg_episode_per_sec: 0.1435272889223862
collect_time: 41.80389698048682
reward_mean: -105.8949579831933
reward_std: 1.9497492769287266
reward_max: -102.13375350140055
reward_min: -108.01330532212884
queue_len: 0.07022212067851014
wait_time: 0.6698044602456367
delay_time: 4.392209086253291
pressure: 0.8628426171529621
total_envstep_count: 771168
total_train_sample_count: 771168
total_episode_count: 6648
total_duration: 46030.28947651201
[2024-12-28 00:54:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.96780308348777
avg_train_sample_per_sec: 16.96780308348777
avg_episode_per_sec: 0.1462741645128256
collect_time: 41.01886358389631
reward_mean: -105.89717553688145
reward_std: 1.8139260285486072
reward_max: -102.1638655462185
reward_min: -107.96918767507006
queue_len: 0.07022359120482853
wait_time: 0.6686123277781492
delay_time: 4.408801827673161
pressure: 0.8601900972590627
total_envstep_count: 771864
total_train_sample_count: 771864
total_episode_count: 6654
total_duration: 46071.3083400959
[2024-12-28 00:55:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.769686277767708
avg_train_sample_per_sec: 16.769686277767708
avg_episode_per_sec: 0.14456626101523887
collect_time: 41.50345978282951
reward_mean: -108.40102707749769
reward_std: 4.437177553855325
reward_max: -102.26120448179269
reward_min: -116.3725490196079
queue_len: 0.07188397021054223
wait_time: 0.687685595900606
delay_time: 4.4676040908176216
pressure: 0.8879310344827585
total_envstep_count: 772560
total_train_sample_count: 772560
total_episode_count: 6660
total_duration: 46112.81179987873
[2024-12-28 00:56:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93124397707165
avg_train_sample_per_sec: 16.93124397707165
avg_episode_per_sec: 0.1459589998023418
collect_time: 41.10743433515728
reward_mean: -109.04855275443508
reward_std: 4.27675876782434
reward_max: -102.77030812324921
reward_min: -113.95378151260503
queue_len: 0.07231336389551399
wait_time: 0.6899823258215755
delay_time: 4.477063197463478
pressure: 0.8809681697612732
total_envstep_count: 773256
total_train_sample_count: 773256
total_episode_count: 6666
total_duration: 46153.919234213885
[2024-12-28 00:57:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.760536227967826
avg_train_sample_per_sec: 16.760536227967826
avg_episode_per_sec: 0.14448738127558472
collect_time: 41.526117692977195
reward_mean: -105.9891456582633
reward_std: 2.627349686368045
reward_max: -102.83543417366946
reward_min: -111.10994397759103
queue_len: 0.07028457934898097
wait_time: 0.66800685791558
delay_time: 4.361663275033911
pressure: 0.860079575596817
total_envstep_count: 773952
total_train_sample_count: 773952
total_episode_count: 6672
total_duration: 46195.44535190686
[2024-12-28 00:57:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.805139169220347
avg_train_sample_per_sec: 16.805139169220347
avg_episode_per_sec: 0.14487188938983056
collect_time: 41.41590218275414
reward_mean: -105.70880018674136
reward_std: 3.3823148440001023
reward_max: -101.44047619047616
reward_min: -111.23669467787111
queue_len: 0.07009867386388684
wait_time: 0.6718897439612451
delay_time: 4.370168184721254
pressure: 0.8684792219274978
total_envstep_count: 774648
total_train_sample_count: 774648
total_episode_count: 6678
total_duration: 46236.861254089614
[2024-12-28 00:58:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.5964928904318
avg_train_sample_per_sec: 16.5964928904318
avg_episode_per_sec: 0.14307321457268793
collect_time: 41.936570852342996
reward_mean: -107.16818394024274
reward_std: 2.7421865043029308
reward_max: -103.0343137254902
reward_min: -110.6582633053221
queue_len: 0.07106643497363578
wait_time: 0.6757924434141472
delay_time: 4.508165796858911
pressure: 0.866158267020336
total_envstep_count: 775344
total_train_sample_count: 775344
total_episode_count: 6684
total_duration: 46278.797824941954
[2024-12-28 00:59:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95630000253558
avg_train_sample_per_sec: 16.95630000253558
avg_episode_per_sec: 0.14617500002185846
collect_time: 41.046690604431554
reward_mean: -107.41374883286647
reward_std: 1.8289958730249474
reward_max: -104.72689075630248
reward_min: -109.99229691876748
queue_len: 0.0712292764143677
wait_time: 0.6795638016479802
delay_time: 4.478668683564617
pressure: 0.8669319186560566
total_envstep_count: 776040
total_train_sample_count: 776040
total_episode_count: 6690
total_duration: 46319.844515546385
[2024-12-28 00:59:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71082997047662
avg_train_sample_per_sec: 16.71082997047662
avg_episode_per_sec: 0.14405887905583295
collect_time: 41.649636866010724
reward_mean: -103.77310924369748
reward_std: 2.254933676146058
reward_max: -100.38655462184873
reward_min: -106.13515406162465
queue_len: 0.06881505918017074
wait_time: 0.6521379440370313
delay_time: 4.300099762309695
pressure: 0.8435013262599469
total_envstep_count: 776736
total_train_sample_count: 776736
total_episode_count: 6696
total_duration: 46361.49415241239
[2024-12-28 01:00:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.913091616950112
avg_train_sample_per_sec: 16.913091616950112
avg_episode_per_sec: 0.1458025139392251
collect_time: 41.15155382369457
reward_mean: -106.42763772175535
reward_std: 1.6329279781877988
reward_max: -103.90966386554616
reward_min: -109.26540616246491
queue_len: 0.07057535657941336
wait_time: 0.6694919347049164
delay_time: 4.430747417200593
pressure: 0.8721264367816093
total_envstep_count: 777432
total_train_sample_count: 777432
total_episode_count: 6702
total_duration: 46402.645706236086
[2024-12-28 01:01:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.586880109731045
avg_train_sample_per_sec: 16.586880109731045
avg_episode_per_sec: 0.1429903457735435
collect_time: 41.960874823691334
reward_mean: -106.09523809523812
reward_std: 3.0111813561746525
reward_max: -101.85364145658262
reward_min: -110.07492997198885
queue_len: 0.07035493242389795
wait_time: 0.67219785792301
delay_time: 4.384472142418146
pressure: 0.863395225464191
total_envstep_count: 778128
total_train_sample_count: 778128
total_episode_count: 6708
total_duration: 46444.60658105978
[2024-12-28 01:01:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7187671578667
avg_train_sample_per_sec: 16.7187671578667
avg_episode_per_sec: 0.14412730308505778
collect_time: 41.62986381878704
reward_mean: -107.15312791783379
reward_std: 1.739054668657156
reward_max: -104.52100840336136
reward_min: -109.29901960784315
queue_len: 0.0710564508738951
wait_time: 0.6715109673400749
delay_time: 4.490383586631028
pressure: 0.8745579133510167
total_envstep_count: 778824
total_train_sample_count: 778824
total_episode_count: 6714
total_duration: 46486.23644487857
[2024-12-28 01:02:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.602453738030412
avg_train_sample_per_sec: 16.602453738030412
avg_episode_per_sec: 0.14312460118991735
collect_time: 41.92151419194788
reward_mean: -105.10364145658265
reward_std: 3.429062037712173
reward_max: -100.53711484593839
reward_min: -109.43207282913166
queue_len: 0.06969737497120865
wait_time: 0.6629080787929674
delay_time: 4.374021207780558
pressure: 0.8541114058355439
total_envstep_count: 779520
total_train_sample_count: 779520
total_episode_count: 6720
total_duration: 46528.157959070515
[2024-12-28 01:03:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.564788410050422
avg_train_sample_per_sec: 16.564788410050422
avg_episode_per_sec: 0.14279990008664156
collect_time: 42.01683612075075
reward_mean: -107.50000000000001
reward_std: 3.8629390370764276
reward_max: -101.30462184873952
reward_min: -112.10644257703083
queue_len: 0.07128647214854113
wait_time: 0.674919879534484
delay_time: 4.43532764653435
pressure: 0.871684350132626
total_envstep_count: 780216
total_train_sample_count: 780216
total_episode_count: 6726
total_duration: 46570.17479519127
[2024-12-28 01:04:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.79025855955402
avg_train_sample_per_sec: 16.79025855955402
avg_episode_per_sec: 0.1447436082720174
collect_time: 41.452607625506815
reward_mean: -107.02450980392156
reward_std: 2.7842853395780423
reward_max: -101.87114845938378
reward_min: -110.17717086834732
queue_len: 0.07097116034742809
wait_time: 0.6712876021319226
delay_time: 4.480729839700108
pressure: 0.8695844385499557
total_envstep_count: 780912
total_train_sample_count: 780912
total_episode_count: 6732
total_duration: 46611.627402816775
[2024-12-28 01:04:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7048993729329
avg_train_sample_per_sec: 16.7048993729329
avg_episode_per_sec: 0.14400775321493878
collect_time: 41.66442338034883
reward_mean: -105.97058823529409
reward_std: 2.0333031908698014
reward_max: -103.80812324929974
reward_min: -109.1673669467787
queue_len: 0.07027227336557963
wait_time: 0.6661307759177941
delay_time: 4.39150155972974
pressure: 0.8554376657824934
total_envstep_count: 781608
total_train_sample_count: 781608
total_episode_count: 6738
total_duration: 46653.29182619712
[2024-12-28 01:05:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.29415515005976
avg_train_sample_per_sec: 16.29415515005976
avg_episode_per_sec: 0.14046685474189446
collect_time: 42.71470313067735
reward_mean: -107.83053221288515
reward_std: 4.231248573455751
reward_max: -98.67086834733894
reward_min: -111.55812324929973
queue_len: 0.07150565796610421
wait_time: 0.6814296673576591
delay_time: 4.556810739196751
pressure: 0.8764367816091955
total_envstep_count: 782304
total_train_sample_count: 782304
total_episode_count: 6744
total_duration: 46696.006529327795
[2024-12-28 01:06:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.874053196399714
avg_train_sample_per_sec: 16.874053196399714
avg_episode_per_sec: 0.14546597583103202
collect_time: 41.246758671384306
reward_mean: -104.7840802987862
reward_std: 4.6019658990301595
reward_max: -98.12044817927172
reward_min: -111.73249299719889
queue_len: 0.06948546438911551
wait_time: 0.6608197766286003
delay_time: 4.391036643860851
pressure: 0.8500221043324491
total_envstep_count: 783000
total_train_sample_count: 783000
total_episode_count: 6750
total_duration: 46737.25328799918
[2024-12-28 01:06:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76317778757549
avg_train_sample_per_sec: 16.76317778757549
avg_episode_per_sec: 0.144510153341168
collect_time: 41.51957396263257
reward_mean: -105.26517273576098
reward_std: 2.045029785570651
reward_max: -102.5238095238095
reward_min: -108.06372549019605
queue_len: 0.06980449120408551
wait_time: 0.6604422383453822
delay_time: 4.3830962237110915
pressure: 0.8547745358090185
total_envstep_count: 783696
total_train_sample_count: 783696
total_episode_count: 6756
total_duration: 46778.772861961814
[2024-12-28 01:07:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.531375679120167
avg_train_sample_per_sec: 16.531375679120167
avg_episode_per_sec: 0.14251185930276006
collect_time: 42.101759315716095
reward_mean: -109.5533380018674
reward_std: 3.478356954929378
reward_max: -104.68697478991594
reward_min: -115.27941176470587
queue_len: 0.07264810212325423
wait_time: 0.698058301569965
delay_time: 4.541375638432558
pressure: 0.8934571175950486
total_envstep_count: 784392
total_train_sample_count: 784392
total_episode_count: 6762
total_duration: 46820.87462127753
[2024-12-28 01:08:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.805221643661667
avg_train_sample_per_sec: 16.805221643661667
avg_episode_per_sec: 0.14487260037639368
collect_time: 41.41569892727398
reward_mean: -104.25700280112044
reward_std: 3.284211469066039
reward_max: -100.4159663865546
reward_min: -109.97829131652657
queue_len: 0.06913594350206925
wait_time: 0.651877351294187
delay_time: 4.313434600729482
pressure: 0.8502431476569408
total_envstep_count: 785088
total_train_sample_count: 785088
total_episode_count: 6768
total_duration: 46862.290320204804
[2024-12-28 01:09:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.424669470870292
avg_train_sample_per_sec: 16.424669470870292
avg_episode_per_sec: 0.1415919781971577
collect_time: 42.37528196438775
reward_mean: -105.15534547152191
reward_std: 2.9777719590303495
reward_max: -100.92436974789914
reward_min: -110.78501400560224
queue_len: 0.06973166145326389
wait_time: 0.6645511210673481
delay_time: 4.398148467718811
pressure: 0.8557692307692308
total_envstep_count: 785784
total_train_sample_count: 785784
total_episode_count: 6774
total_duration: 46904.66560216919
[2024-12-28 01:09:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.484781956327975
avg_train_sample_per_sec: 16.484781956327975
avg_episode_per_sec: 0.14211018927868943
collect_time: 42.22075862719119
reward_mean: -106.81827731092437
reward_std: 2.2724567184467155
reward_max: -103.47478991596638
reward_min: -110.97128851540617
queue_len: 0.07083440139981723
wait_time: 0.6732898398086026
delay_time: 4.389161875743506
pressure: 0.8723474801061007
total_envstep_count: 786480
total_train_sample_count: 786480
total_episode_count: 6780
total_duration: 46946.88636079638
[2024-12-28 01:10:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.926242311762365
avg_train_sample_per_sec: 16.926242311762365
avg_episode_per_sec: 0.14591588199795144
collect_time: 41.11958148657345
reward_mean: -105.26925770308124
reward_std: 3.6109330132345034
reward_max: -102.7170868347339
reward_min: -113.0847338935574
queue_len: 0.06980720006835626
wait_time: 0.664631690430372
delay_time: 4.330883294688935
pressure: 0.855106100795756
total_envstep_count: 787176
total_train_sample_count: 787176
total_episode_count: 6786
total_duration: 46988.00594228295
[2024-12-28 01:11:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.540510582282817
avg_train_sample_per_sec: 16.540510582282817
avg_episode_per_sec: 0.14259060846795532
collect_time: 42.078507585220045
reward_mean: -105.34920634920634
reward_std: 3.02392095534731
reward_max: -101.01750700280108
reward_min: -110.7892156862745
queue_len: 0.06986021641194055
wait_time: 0.660303699286965
delay_time: 4.396974090406049
pressure: 0.8574270557029178
total_envstep_count: 787872
total_train_sample_count: 787872
total_episode_count: 6792
total_duration: 47030.08444986817
[2024-12-28 01:11:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.553196372092728
avg_train_sample_per_sec: 16.553196372092728
avg_episode_per_sec: 0.1426999687249373
collect_time: 42.04626009109615
reward_mean: -105.93790849673205
reward_std: 3.8965238069139936
reward_max: -101.33823529411764
reward_min: -110.80882352941175
queue_len: 0.07025060245141382
wait_time: 0.6693431793583923
delay_time: 4.406304174242162
pressure: 0.8621794871794871
total_envstep_count: 788568
total_train_sample_count: 788568
total_episode_count: 6798
total_duration: 47072.13070995927
[2024-12-28 01:12:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.657167589476376
avg_train_sample_per_sec: 16.657167589476376
avg_episode_per_sec: 0.1435962723230722
collect_time: 41.78381446073204
reward_mean: -107.1109943977591
reward_std: 3.839423362257586
reward_max: -103.94887955182077
reward_min: -115.45798319327724
queue_len: 0.07102851087384555
wait_time: 0.6763212911159157
delay_time: 4.443781537889067
pressure: 0.8702475685234305
total_envstep_count: 789264
total_train_sample_count: 789264
total_episode_count: 6804
total_duration: 47113.91452442
[2024-12-28 01:13:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.889128071871262
avg_train_sample_per_sec: 16.889128071871262
avg_episode_per_sec: 0.1455959316540626
collect_time: 41.20994269438833
reward_mean: -103.46673669467786
reward_std: 2.5694097297412206
reward_max: -99.84873949579831
reward_min: -106.93977591036413
queue_len: 0.06861189435986596
wait_time: 0.6523823609903731
delay_time: 4.279166478893523
pressure: 0.8454907161803713
total_envstep_count: 789960
total_train_sample_count: 789960
total_episode_count: 6810
total_duration: 47155.12446711439
[2024-12-28 01:13:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.751394072732523
avg_train_sample_per_sec: 16.751394072732523
avg_episode_per_sec: 0.14440856959252177
collect_time: 41.54878077478521
reward_mean: -105.47303921568626
reward_std: 2.5326029459286263
reward_max: -102.13585434173667
reward_min: -109.78571428571432
queue_len: 0.06994233369740468
wait_time: 0.6670786462241837
delay_time: 4.352426669480095
pressure: 0.851790450928382
total_envstep_count: 790656
total_train_sample_count: 790656
total_episode_count: 6816
total_duration: 47196.67324788917
[2024-12-28 01:14:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.757385286540867
avg_train_sample_per_sec: 16.757385286540867
avg_episode_per_sec: 0.14446021798742126
collect_time: 41.53392597346381
reward_mean: -105.31127450980394
reward_std: 2.063323578117367
reward_max: -102.44677871148461
reward_min: -108.56862745098039
queue_len: 0.06983506267228377
wait_time: 0.6626179207315109
delay_time: 4.424731424563937
pressure: 0.854442970822281
total_envstep_count: 791352
total_train_sample_count: 791352
total_episode_count: 6822
total_duration: 47238.20717386263
[2024-12-28 01:15:22][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.03222310449659
avg_train_sample_per_sec: 17.03222310449659
avg_episode_per_sec: 0.14682950952152232
collect_time: 40.86372023956477
reward_mean: -105.00198412698411
reward_std: 1.7063438456693716
reward_max: -102.78221288515411
reward_min: -107.5
queue_len: 0.06962996294892847
wait_time: 0.6653524805147525
delay_time: 4.3574645182716445
pressure: 0.8573165340406721
total_envstep_count: 792048
total_train_sample_count: 792048
total_episode_count: 6828
total_duration: 47279.070894102195
[2024-12-28 01:16:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54862053461672
avg_train_sample_per_sec: 16.54862053461672
avg_episode_per_sec: 0.14266052185014416
collect_time: 42.05788624762371
reward_mean: -106.24019607843134
reward_std: 2.1986454807706814
reward_max: -101.93767507002802
reward_min: -109.03291316526611
queue_len: 0.07045105840744785
wait_time: 0.6725132471202451
delay_time: 4.429899072127741
pressure: 0.8625110521662246
total_envstep_count: 792744
total_train_sample_count: 792744
total_episode_count: 6834
total_duration: 47321.12878034982
[2024-12-28 01:16:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.527592074018916
avg_train_sample_per_sec: 16.527592074018916
avg_episode_per_sec: 0.14247924201740444
collect_time: 42.11139752741718
reward_mean: -107.29143323996264
reward_std: 2.1053008753246414
reward_max: -104.45378151260505
reward_min: -110.9348739495798
queue_len: 0.07114816527848981
wait_time: 0.6832145767237044
delay_time: 4.43676090578921
pressure: 0.8688107869142351
total_envstep_count: 793440
total_train_sample_count: 793440
total_episode_count: 6840
total_duration: 47363.24017787724
[2024-12-28 01:17:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.444784955805694
avg_train_sample_per_sec: 16.444784955805694
avg_episode_per_sec: 0.14176538755004908
collect_time: 42.32344794233889
reward_mean: -107.03734827264238
reward_std: 4.323109924055834
reward_max: -98.54831932773104
reward_min: -110.89075630252101
queue_len: 0.07097967392085039
wait_time: 0.6749845826924935
delay_time: 4.536878686918883
pressure: 0.8699160035366932
total_envstep_count: 794136
total_train_sample_count: 794136
total_episode_count: 6846
total_duration: 47405.56362581958
[2024-12-28 01:18:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.84389180304949
avg_train_sample_per_sec: 16.84389180304949
avg_episode_per_sec: 0.1452059638193922
collect_time: 41.32061688225717
reward_mean: -105.30812324929973
reward_std: 1.8859621674027038
reward_max: -102.32352941176467
reward_min: -107.79411764705877
queue_len: 0.0698329729769892
wait_time: 0.663148393751842
delay_time: 4.350393959775071
pressure: 0.8510167992926614
total_envstep_count: 794832
total_train_sample_count: 794832
total_episode_count: 6852
total_duration: 47446.88424270184
[2024-12-28 01:18:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.88405588338741
avg_train_sample_per_sec: 16.88405588338741
avg_episode_per_sec: 0.1455522058912708
collect_time: 41.22232269349508
reward_mean: -106.20868347338934
reward_std: 2.2056885632126284
reward_max: -102.52170868347343
reward_min: -109.08333333333333
queue_len: 0.07043016145450222
wait_time: 0.672000652604101
delay_time: 4.386978161963652
pressure: 0.8583112290008841
total_envstep_count: 795528
total_train_sample_count: 795528
total_episode_count: 6858
total_duration: 47488.106565395334
[2024-12-28 01:19:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.624888337342437
avg_train_sample_per_sec: 16.624888337342437
avg_episode_per_sec: 0.14331800290812446
collect_time: 41.86494284215197
reward_mean: -104.97537348272645
reward_std: 3.0438130659978393
reward_max: -101.93627450980392
reward_min: -110.44187675070032
queue_len: 0.06961231663310771
wait_time: 0.6645881938097963
delay_time: 4.297187274276479
pressure: 0.854553492484527
total_envstep_count: 796224
total_train_sample_count: 796224
total_episode_count: 6864
total_duration: 47529.97150823748
[2024-12-28 01:20:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85998663648287
avg_train_sample_per_sec: 16.85998663648287
avg_episode_per_sec: 0.14534471238347302
collect_time: 41.281171510180464
reward_mean: -106.86636321195147
reward_std: 3.0806354839426353
reward_max: -102.14075630252098
reward_min: -112.42436974789916
queue_len: 0.07086628860208982
wait_time: 0.6749276191466861
delay_time: 4.389690337121971
pressure: 0.8721264367816092
total_envstep_count: 796920
total_train_sample_count: 796920
total_episode_count: 6870
total_duration: 47571.25267974766
[2024-12-28 01:21:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.898426114188496
avg_train_sample_per_sec: 16.898426114188496
avg_episode_per_sec: 0.14567608719128014
collect_time: 41.18726769563555
reward_mean: -104.60574229691876
reward_std: 2.1742485205068225
reward_max: -100.046918767507
reward_min: -106.94887955182074
queue_len: 0.06936720311466761
wait_time: 0.6616064308128203
delay_time: 4.339182044263979
pressure: 0.8492484526967284
total_envstep_count: 797616
total_train_sample_count: 797616
total_episode_count: 6876
total_duration: 47612.439947443294
[2024-12-28 01:21:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.898557384303952
avg_train_sample_per_sec: 16.898557384303952
avg_episode_per_sec: 0.1456772188302065
collect_time: 41.186947747768826
reward_mean: -103.64133986928107
reward_std: 1.0395670580638443
reward_max: -102.58473389355746
reward_min: -105.15756302521011
queue_len: 0.06872767895840921
wait_time: 0.6522740064195439
delay_time: 4.305021753707066
pressure: 0.8407382847038019
total_envstep_count: 798312
total_train_sample_count: 798312
total_episode_count: 6882
total_duration: 47653.62689519106
[2024-12-28 01:22:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.740575484217946
avg_train_sample_per_sec: 16.740575484217946
avg_episode_per_sec: 0.14431530589843058
collect_time: 41.57563165353239
reward_mean: -103.28232959850607
reward_std: 1.9829449333616294
reward_max: -100.12184873949579
reward_min: -106.43977591036412
queue_len: 0.06848960848707299
wait_time: 0.6504407244772357
delay_time: 4.273889702726421
pressure: 0.8428381962864723
total_envstep_count: 799008
total_train_sample_count: 799008
total_episode_count: 6888
total_duration: 47695.202526844594
[2024-12-28 01:23:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.74252497129793
avg_train_sample_per_sec: 16.74252497129793
avg_episode_per_sec: 0.14433211182153388
collect_time: 41.57079061809182
reward_mean: -104.04481792717087
reward_std: 2.219094493946641
reward_max: -100.56232492997198
reward_min: -106.64985994397757
queue_len: 0.06899523735223534
wait_time: 0.6594944454351149
delay_time: 4.344965763613076
pressure: 0.8533377541998233
total_envstep_count: 799704
total_train_sample_count: 799704
total_episode_count: 6894
total_duration: 47736.773317462685
[2024-12-28 01:23:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.856099802343074
avg_train_sample_per_sec: 16.856099802343074
avg_episode_per_sec: 0.14531120519261273
collect_time: 41.29069050144404
reward_mean: -106.26108776844073
reward_std: 2.679830429073178
reward_max: -101.58403361344538
reward_min: -109.78151260504202
queue_len: 0.07046491231328961
wait_time: 0.6726629312202334
delay_time: 4.4069916494638015
pressure: 0.8692528735632182
total_envstep_count: 800400
total_train_sample_count: 800400
total_episode_count: 6900
total_duration: 47778.06400796413
[2024-12-28 01:24:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.988710203324622
avg_train_sample_per_sec: 16.988710203324622
avg_episode_per_sec: 0.14645439830452261
collect_time: 40.9683838072531
reward_mean: -102.83998599439774
reward_std: 2.838380159824917
reward_max: -101.12254901960779
reward_min: -109.11064425770307
queue_len: 0.06819627718461388
wait_time: 0.645917540314092
delay_time: 4.3113059435772545
pressure: 0.8373121131741822
total_envstep_count: 801096
total_train_sample_count: 801096
total_episode_count: 6906
total_duration: 47819.03239177138
[2024-12-28 01:25:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.813113397641146
avg_train_sample_per_sec: 16.813113397641146
avg_episode_per_sec: 0.14494063273828575
collect_time: 41.39625919002293
reward_mean: -102.90044351073762
reward_std: 2.7661120098475696
reward_max: -99.62254901960785
reward_min: -107.49019607843137
queue_len: 0.0682363683758207
wait_time: 0.6514585608779319
delay_time: 4.292677864689597
pressure: 0.8334438549955792
total_envstep_count: 801792
total_train_sample_count: 801792
total_episode_count: 6912
total_duration: 47860.4286509614
[2024-12-28 01:25:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.80135569836498
avg_train_sample_per_sec: 16.80135569836498
avg_episode_per_sec: 0.14483927326176707
collect_time: 41.42522856460512
reward_mean: -104.66444911297852
reward_std: 2.604211758169242
reward_max: -101.79761904761905
reward_min: -109.92016806722687
queue_len: 0.06940613336404411
wait_time: 0.6634548823950447
delay_time: 4.339740338238703
pressure: 0.8522325375773651
total_envstep_count: 802488
total_train_sample_count: 802488
total_episode_count: 6918
total_duration: 47901.85387952601
[2024-12-28 01:26:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90329617653014
avg_train_sample_per_sec: 16.90329617653014
avg_episode_per_sec: 0.14571807048732882
collect_time: 41.17540110114031
reward_mean: -102.70564892623717
reward_std: 1.9894384747090863
reward_max: -99.39075630252101
reward_min: -105.16876750700283
queue_len: 0.06810719424816787
wait_time: 0.6479572377138301
delay_time: 4.301233033193814
pressure: 0.8375331564986738
total_envstep_count: 803184
total_train_sample_count: 803184
total_episode_count: 6924
total_duration: 47943.029280627154
[2024-12-28 01:27:20][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.39706702316274
avg_train_sample_per_sec: 16.39706702316274
avg_episode_per_sec: 0.14135402606174777
collect_time: 42.446615545134996
reward_mean: -106.78699813258635
reward_std: 1.896171974612672
reward_max: -104.63375350140058
reward_min: -110.24859943977593
queue_len: 0.07081365923911563
wait_time: 0.6773450096218858
delay_time: 4.419880057944082
pressure: 0.8701370468611849
total_envstep_count: 803880
total_train_sample_count: 803880
total_episode_count: 6930
total_duration: 47985.47589617229
[2024-12-28 01:28:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.803701762419124
avg_train_sample_per_sec: 16.803701762419124
avg_episode_per_sec: 0.144859497951889
collect_time: 41.41944494376704
reward_mean: -105.22035480859007
reward_std: 5.4364187144568294
reward_max: -101.24579831932775
reward_min: -116.75770308123252
queue_len: 0.0697747710932295
wait_time: 0.6610871028340602
delay_time: 4.327258541136643
pressure: 0.8552166224580017
total_envstep_count: 804576
total_train_sample_count: 804576
total_episode_count: 6936
total_duration: 48026.895341116055
[2024-12-28 01:28:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.902403486793464
avg_train_sample_per_sec: 16.902403486793464
avg_episode_per_sec: 0.14571037488615055
collect_time: 41.177575753875075
reward_mean: -102.23237628384685
reward_std: 2.464718415067757
reward_max: -99.23389355742297
reward_min: -105.37535014005601
queue_len: 0.06779335297337326
wait_time: 0.6431164198659127
delay_time: 4.279700361692154
pressure: 0.8254862953138816
total_envstep_count: 805272
total_train_sample_count: 805272
total_episode_count: 6942
total_duration: 48068.07291686993
[2024-12-28 01:29:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.478714031946982
avg_train_sample_per_sec: 16.478714031946982
avg_episode_per_sec: 0.14205787958574984
collect_time: 42.23630549390429
reward_mean: -107.1483426704015
reward_std: 3.092427761839306
reward_max: -102.98389355742297
reward_min: -112.21708683473389
queue_len: 0.07105327763289222
wait_time: 0.676559052002764
delay_time: 4.399039843882855
pressure: 0.8688107869142353
total_envstep_count: 805968
total_train_sample_count: 805968
total_episode_count: 6948
total_duration: 48110.30922236384
[2024-12-28 01:30:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.50294191175508
avg_train_sample_per_sec: 16.50294191175508
avg_episode_per_sec: 0.14226674061857827
collect_time: 42.174298602132126
reward_mean: -103.40989729225022
reward_std: 1.761654973295377
reward_max: -100.11904761904762
reward_min: -105.38655462184877
queue_len: 0.0685742024484418
wait_time: 0.6507957404889454
delay_time: 4.282486060012923
pressure: 0.8342175066312998
total_envstep_count: 806664
total_train_sample_count: 806664
total_episode_count: 6954
total_duration: 48152.48352096597
[2024-12-28 01:30:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.866451661695887
avg_train_sample_per_sec: 16.866451661695887
avg_episode_per_sec: 0.14540044535944732
collect_time: 41.26534815740957
reward_mean: -105.1063258636788
reward_std: 2.2387780099191135
reward_max: -102.0266106442577
reward_min: -108.49649859943976
queue_len: 0.06969915508201512
wait_time: 0.6600910147436517
delay_time: 4.342689760987555
pressure: 0.8612953138815208
total_envstep_count: 807360
total_train_sample_count: 807360
total_episode_count: 6960
total_duration: 48193.74886912338
[2024-12-28 01:31:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.706907017077267
avg_train_sample_per_sec: 16.706907017077267
avg_episode_per_sec: 0.1440250604920454
collect_time: 41.6594166286178
reward_mean: -104.3455882352941
reward_std: 3.07721264364555
reward_max: -99.98039215686276
reward_min: -108.29831932773111
queue_len: 0.0691946871586831
wait_time: 0.6568154560674845
delay_time: 4.303826554245793
pressure: 0.8451591511936339
total_envstep_count: 808056
total_train_sample_count: 808056
total_episode_count: 6966
total_duration: 48235.408285752
[2024-12-28 01:32:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7418275539656
avg_train_sample_per_sec: 16.7418275539656
avg_episode_per_sec: 0.1443260996031517
collect_time: 41.572522340020164
reward_mean: -104.51505602240896
reward_std: 1.0044330256288703
reward_max: -103.14005602240901
reward_min: -106.2471988795518
queue_len: 0.0693070663278574
wait_time: 0.6597928848816274
delay_time: 4.365078742367619
pressure: 0.8542219274977896
total_envstep_count: 808752
total_train_sample_count: 808752
total_episode_count: 6972
total_duration: 48276.98080809202
[2024-12-28 01:32:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.696925545161864
avg_train_sample_per_sec: 16.696925545161864
avg_episode_per_sec: 0.14393901332036088
collect_time: 41.68432075219228
reward_mean: -103.46183473389357
reward_std: 3.0199952771077174
reward_max: -97.97058823529412
reward_min: -106.53081232492994
queue_len: 0.06860864372274107
wait_time: 0.6483716165511297
delay_time: 4.326801395048533
pressure: 0.8450486295313882
total_envstep_count: 809448
total_train_sample_count: 809448
total_episode_count: 6978
total_duration: 48318.66512884421
[2024-12-28 01:33:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.57285139324952
avg_train_sample_per_sec: 16.57285139324952
avg_episode_per_sec: 0.14286940856249586
collect_time: 41.99639419222065
reward_mean: -105.93989262371616
reward_std: 5.156548658962469
reward_max: -99.99159663865548
reward_min: -115.58333333333334
queue_len: 0.07025191818548816
wait_time: 0.664327368878586
delay_time: 4.420283798225908
pressure: 0.860079575596817
total_envstep_count: 810144
total_train_sample_count: 810144
total_episode_count: 6984
total_duration: 48360.661523036426
[2024-12-28 01:34:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.56280713979551
avg_train_sample_per_sec: 16.56280713979551
avg_episode_per_sec: 0.14278282017065094
collect_time: 42.0218622438535
reward_mean: -104.80718954248364
reward_std: 2.856578791817892
reward_max: -101.21568627450979
reward_min: -110.02871148459376
queue_len: 0.06950078882127562
wait_time: 0.656999581441772
delay_time: 4.374034452772042
pressure: 0.8526746242263483
total_envstep_count: 810840
total_train_sample_count: 810840
total_episode_count: 6990
total_duration: 48402.68338528028
[2024-12-28 01:35:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.640230982578043
avg_train_sample_per_sec: 16.640230982578043
avg_episode_per_sec: 0.14345026709119002
collect_time: 41.826342478580784
reward_mean: -105.53863211951447
reward_std: 2.6648073527202953
reward_max: -102.65476190476191
reward_min: -110.03641456582632
queue_len: 0.06998583031798042
wait_time: 0.6643418419534036
delay_time: 4.402308850005892
pressure: 0.8513483642793988
total_envstep_count: 811536
total_train_sample_count: 811536
total_episode_count: 6996
total_duration: 48444.509727758865
[2024-12-28 01:35:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.955872156328333
avg_train_sample_per_sec: 16.955872156328333
avg_episode_per_sec: 0.14617131169248562
collect_time: 41.04772633239254
reward_mean: -106.20880018674136
reward_std: 2.6550835294416983
reward_max: -102.36064425770307
reward_min: -110.421568627451
queue_len: 0.07043023885062424
wait_time: 0.6657999848922772
delay_time: 4.477373940781484
pressure: 0.8620689655172414
total_envstep_count: 812232
total_train_sample_count: 812232
total_episode_count: 7002
total_duration: 48485.55745409126
[2024-12-28 01:36:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.651267814298368
avg_train_sample_per_sec: 16.651267814298368
avg_episode_per_sec: 0.1435454121922273
collect_time: 41.798619045833135
reward_mean: -106.70576563958916
reward_std: 3.108717717828581
reward_max: -102.68697478991595
reward_min: -111.55112044817928
queue_len: 0.0707597915381891
wait_time: 0.6734812404183601
delay_time: 4.460338618649549
pressure: 0.868921308576481
total_envstep_count: 812928
total_train_sample_count: 812928
total_episode_count: 7008
total_duration: 48527.35607313709
[2024-12-28 01:37:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95394368251025
avg_train_sample_per_sec: 16.95394368251025
avg_episode_per_sec: 0.1461546869181918
collect_time: 41.05239542101323
reward_mean: -105.33274976657329
reward_std: 2.3399171378044614
reward_max: -103.28991596638653
reward_min: -110.13935574229693
queue_len: 0.06984930355873561
wait_time: 0.6614277231670741
delay_time: 4.3868855276928045
pressure: 0.8604111405835545
total_envstep_count: 813624
total_train_sample_count: 813624
total_episode_count: 7014
total_duration: 48568.408468558104
[2024-12-28 01:37:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.776845693483207
avg_train_sample_per_sec: 16.776845693483207
avg_episode_per_sec: 0.14462798011623454
collect_time: 41.48574843662978
reward_mean: -104.39612511671338
reward_std: 2.4825197198582547
reward_max: -100.37394957983199
reward_min: -108.5322128851541
queue_len: 0.06922819967951817
wait_time: 0.6560098398333692
delay_time: 4.3636910474194615
pressure: 0.8493589743589743
total_envstep_count: 814320
total_train_sample_count: 814320
total_episode_count: 7020
total_duration: 48609.89421699473
[2024-12-28 01:38:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.485270548963793
avg_train_sample_per_sec: 16.485270548963793
avg_episode_per_sec: 0.14211440128417063
collect_time: 42.21950728274509
reward_mean: -103.16830065359477
reward_std: 2.6575528044427674
reward_max: -98.86554621848744
reward_min: -106.7696078431373
queue_len: 0.06841399247585861
wait_time: 0.6524034901316847
delay_time: 4.283284719485315
pressure: 0.8426171529619806
total_envstep_count: 815016
total_train_sample_count: 815016
total_episode_count: 7026
total_duration: 48652.11372427748
[2024-12-28 01:39:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.938160551619582
avg_train_sample_per_sec: 16.938160551619582
avg_episode_per_sec: 0.14601862544499639
collect_time: 41.09064841361717
reward_mean: -105.19199346405229
reward_std: 2.6850405947783846
reward_max: -103.1694677871148
reward_min: -111.11764705882354
queue_len: 0.06975596383557843
wait_time: 0.6596975328592977
delay_time: 4.382720966685139
pressure: 0.8535587975243147
total_envstep_count: 815712
total_train_sample_count: 815712
total_episode_count: 7032
total_duration: 48693.20437269109
[2024-12-28 01:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.452701012088795
avg_train_sample_per_sec: 16.452701012088795
avg_episode_per_sec: 0.14183362941455857
collect_time: 42.30308442903124
reward_mean: -104.5406162464986
reward_std: 2.8442078839517615
reward_max: -100.79411764705885
reward_min: -107.97128851540617
queue_len: 0.06932401607857998
wait_time: 0.6594794305874427
delay_time: 4.408872351140327
pressure: 0.8494694960212201
total_envstep_count: 816408
total_train_sample_count: 816408
total_episode_count: 7038
total_duration: 48735.507457120126
[2024-12-28 01:40:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.488186088603506
avg_train_sample_per_sec: 16.488186088603506
avg_episode_per_sec: 0.14213953524658193
collect_time: 42.21204177705572
reward_mean: -104.46475256769372
reward_std: 3.4763424933398914
reward_max: -100.13655462184873
reward_min: -110.09733893557426
queue_len: 0.06927370859926639
wait_time: 0.6574015768995486
delay_time: 4.4286745588103305
pressure: 0.8483642793987624
total_envstep_count: 817104
total_train_sample_count: 817104
total_episode_count: 7044
total_duration: 48777.71949889718
[2024-12-28 01:41:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.174553919137047
avg_train_sample_per_sec: 17.174553919137047
avg_episode_per_sec: 0.1480564993029056
collect_time: 40.5250700121224
reward_mean: -103.44736227824465
reward_std: 2.5464941874333027
reward_max: -99.5546218487395
reward_min: -106.65686274509804
queue_len: 0.06859904660361049
wait_time: 0.6489098291836628
delay_time: 4.331897890931992
pressure: 0.8342175066312998
total_envstep_count: 817800
total_train_sample_count: 817800
total_episode_count: 7050
total_duration: 48818.24456890931
[2024-12-28 01:42:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.685215755566524
avg_train_sample_per_sec: 16.685215755566524
avg_episode_per_sec: 0.14383806685833211
collect_time: 41.71357507126034
reward_mean: -104.48225957049486
reward_std: 3.7339413777787174
reward_max: -100.86484593837534
reward_min: -111.26120448179269
queue_len: 0.06928531801756954
wait_time: 0.6560672677559086
delay_time: 4.376743639206719
pressure: 0.8496905393457118
total_envstep_count: 818496
total_train_sample_count: 818496
total_episode_count: 7056
total_duration: 48859.95814398057
[2024-12-28 01:42:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.100232192862748
avg_train_sample_per_sec: 17.100232192862748
avg_episode_per_sec: 0.14741579476605818
collect_time: 40.70120172347687
reward_mean: -104.65651260504201
reward_std: 1.7380585002749693
reward_max: -102.31022408963584
reward_min: -107.28641456582632
queue_len: 0.06940087042774667
wait_time: 0.6590884253789934
delay_time: 4.410116996859235
pressure: 0.8470380194518126
total_envstep_count: 819192
total_train_sample_count: 819192
total_episode_count: 7062
total_duration: 48900.65934570404
[2024-12-28 01:43:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.021687883373712
avg_train_sample_per_sec: 17.021687883373712
avg_episode_per_sec: 0.14673868864977338
collect_time: 40.88901199274324
reward_mean: -104.61858076563959
reward_std: 2.2528093439415544
reward_max: -100.60854341736696
reward_min: -107.10714285714288
queue_len: 0.06937571668808991
wait_time: 0.6572128077579396
delay_time: 4.394140651079809
pressure: 0.849027409372237
total_envstep_count: 819888
total_train_sample_count: 819888
total_episode_count: 7068
total_duration: 48941.54835769679
[2024-12-28 01:44:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.69411811269694
avg_train_sample_per_sec: 16.69411811269694
avg_episode_per_sec: 0.14391481131635292
collect_time: 41.691330761021014
reward_mean: -107.05894024276377
reward_std: 3.8088640519833232
reward_max: -101.7198879551821
reward_min: -113.50630252100844
queue_len: 0.07099399220342427
wait_time: 0.6786927082946352
delay_time: 4.461017622318777
pressure: 0.8734526967285587
total_envstep_count: 820584
total_train_sample_count: 820584
total_episode_count: 7074
total_duration: 48983.23968845781
[2024-12-28 01:44:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.654174994573367
avg_train_sample_per_sec: 16.654174994573367
avg_episode_per_sec: 0.14357047409114973
collect_time: 41.79132260990329
reward_mean: -105.87955182072828
reward_std: 2.689805719050392
reward_max: -102.04061624649859
reward_min: -110.87675070028008
queue_len: 0.07021190439040337
wait_time: 0.6655886160830381
delay_time: 4.435202570659221
pressure: 0.8555481874447391
total_envstep_count: 821280
total_train_sample_count: 821280
total_episode_count: 7080
total_duration: 49025.03101106772
[2024-12-28 01:45:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.80102835784566
avg_train_sample_per_sec: 16.80102835784566
avg_episode_per_sec: 0.14483645136073844
collect_time: 41.42603566733374
reward_mean: -104.70074696545286
reward_std: 3.0318545477004233
reward_max: -101.56932773109244
reward_min: -108.7163865546219
queue_len: 0.0694302035579926
wait_time: 0.6616884707021624
delay_time: 4.391071473478249
pressure: 0.8597480106100795
total_envstep_count: 821976
total_train_sample_count: 821976
total_episode_count: 7086
total_duration: 49066.45704673505
[2024-12-28 01:46:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.53426136819965
avg_train_sample_per_sec: 16.53426136819965
avg_episode_per_sec: 0.14253673593275562
collect_time: 42.094411386203014
reward_mean: -103.24766573295987
reward_std: 2.924334439288494
reward_max: -100.29271708683474
reward_min: -109.48599439775914
queue_len: 0.06846662183883279
wait_time: 0.6521726174996968
delay_time: 4.304221152412693
pressure: 0.842838196286472
total_envstep_count: 822672
total_train_sample_count: 822672
total_episode_count: 7092
total_duration: 49108.551458121256
[2024-12-28 01:47:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.777868946860714
avg_train_sample_per_sec: 16.777868946860714
avg_episode_per_sec: 0.14463680126604064
collect_time: 41.483218292167415
reward_mean: -102.79213352007469
reward_std: 4.129938348406963
reward_max: -99.26820728291315
reward_min: -111.53571428571429
queue_len: 0.06816454477458533
wait_time: 0.6486706751666184
delay_time: 4.247844732217382
pressure: 0.8438328912466844
total_envstep_count: 823368
total_train_sample_count: 823368
total_episode_count: 7098
total_duration: 49150.03467641342
[2024-12-28 01:47:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.73521542664298
avg_train_sample_per_sec: 16.73521542664298
avg_episode_per_sec: 0.14426909850554295
collect_time: 41.58894775217213
reward_mean: -103.17892156862746
reward_std: 1.3219065798489884
reward_max: -100.97268907563026
reward_min: -104.91316526610639
queue_len: 0.06842103552296251
wait_time: 0.6494385220931873
delay_time: 4.264487248780306
pressure: 0.853448275862069
total_envstep_count: 824064
total_train_sample_count: 824064
total_episode_count: 7104
total_duration: 49191.62362416559
[2024-12-28 01:48:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.934133067779584
avg_train_sample_per_sec: 16.934133067779584
avg_episode_per_sec: 0.14598390575672054
collect_time: 41.10042109709606
reward_mean: -105.58998599439774
reward_std: 1.2256430310192903
reward_max: -103.23039215686268
reward_min: -106.93557422969185
queue_len: 0.07001988461166958
wait_time: 0.6713236687247844
delay_time: 4.375116993252473
pressure: 0.8643899204244031
total_envstep_count: 824760
total_train_sample_count: 824760
total_episode_count: 7110
total_duration: 49232.72404526269
[2024-12-28 01:49:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.844018314724906
avg_train_sample_per_sec: 16.844018314724906
avg_episode_per_sec: 0.14520705443728368
collect_time: 41.320306532293564
reward_mean: -103.88550420168066
reward_std: 3.903338159887151
reward_max: -101.3704481792717
reward_min: -112.50420168067227
queue_len: 0.06888959164567683
wait_time: 0.6505892476353937
delay_time: 4.355498684360195
pressure: 0.8504641909814324
total_envstep_count: 825456
total_train_sample_count: 825456
total_episode_count: 7116
total_duration: 49274.04435179498
[2024-12-28 01:49:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.712952441286003
avg_train_sample_per_sec: 16.712952441286003
avg_episode_per_sec: 0.14407717621798277
collect_time: 41.64434754691645
reward_mean: -105.75210084033614
reward_std: 4.73371233748348
reward_max: -99.63305322128855
reward_min: -114.53851540616247
queue_len: 0.0701273878251566
wait_time: 0.6677964952559273
delay_time: 4.394168498992574
pressure: 0.8647214854111405
total_envstep_count: 826152
total_train_sample_count: 826152
total_episode_count: 7122
total_duration: 49315.688699341896
[2024-12-28 01:50:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.818049009142907
avg_train_sample_per_sec: 16.818049009142907
avg_episode_per_sec: 0.1449831811133009
collect_time: 41.38411058391071
reward_mean: -104.76353874883289
reward_std: 4.332231200091106
reward_max: -100.76330532212887
reward_min: -113.29761904761908
queue_len: 0.06947184267163985
wait_time: 0.6579171898644515
delay_time: 4.381242470256082
pressure: 0.8500221043324491
total_envstep_count: 826848
total_train_sample_count: 826848
total_episode_count: 7128
total_duration: 49357.072809925805
[2024-12-28 01:51:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.946462292386354
avg_train_sample_per_sec: 16.946462292386354
avg_episode_per_sec: 0.14609019217574443
collect_time: 41.070518907813366
reward_mean: -104.40219421101773
reward_std: 3.2395231389668377
reward_max: -99.7121848739496
reward_min: -108.68347338935571
queue_len: 0.06923222427786323
wait_time: 0.6578034175650808
delay_time: 4.326567436205123
pressure: 0.8605216622458002
total_envstep_count: 827544
total_train_sample_count: 827544
total_episode_count: 7134
total_duration: 49398.14332883362
[2024-12-28 01:51:58][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.820707600068296
avg_train_sample_per_sec: 16.820707600068296
avg_episode_per_sec: 0.14500610000058875
collect_time: 41.377569633109495
reward_mean: -102.64449112978525
reward_std: 3.4063109129444937
reward_max: -97.87605042016806
reward_min: -109.34733893557421
queue_len: 0.06806663868022896
wait_time: 0.6477705582675156
delay_time: 4.254165336069948
pressure: 0.8442749778956675
total_envstep_count: 828240
total_train_sample_count: 828240
total_episode_count: 7140
total_duration: 49439.520898466726
[2024-12-28 01:52:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.67174978849579
avg_train_sample_per_sec: 16.67174978849579
avg_episode_per_sec: 0.14372198093530855
collect_time: 41.747267613161355
reward_mean: -103.43627450980392
reward_std: 2.176122598408099
reward_max: -100.74649859943978
reward_min: -107.62535014005599
queue_len: 0.06859169397201852
wait_time: 0.6499924461384908
delay_time: 4.329154403747729
pressure: 0.8468169761273211
total_envstep_count: 828936
total_train_sample_count: 828936
total_episode_count: 7146
total_duration: 49481.268166079884
[2024-12-28 01:53:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.413152574037625
avg_train_sample_per_sec: 16.413152574037625
avg_episode_per_sec: 0.14149269460377262
collect_time: 42.40501615155488
reward_mean: -105.84978991596638
reward_std: 3.882375861682758
reward_max: -99.4432773109244
reward_min: -111.10434173669465
queue_len: 0.07019216837928806
wait_time: 0.6672471375818233
delay_time: 4.411135160474504
pressure: 0.8625110521662244
total_envstep_count: 829632
total_train_sample_count: 829632
total_episode_count: 7152
total_duration: 49523.67318223144
[2024-12-28 01:54:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.86866246413505
avg_train_sample_per_sec: 16.86866246413505
avg_episode_per_sec: 0.1454195040011642
collect_time: 41.259939931798726
reward_mean: -103.4309056956116
reward_std: 2.591322682935128
reward_max: -100.91106442577032
reward_min: -108.07843137254906
queue_len: 0.06858813375040557
wait_time: 0.649206798103857
delay_time: 4.3218083232046105
pressure: 0.84394341290893
total_envstep_count: 830328
total_train_sample_count: 830328
total_episode_count: 7158
total_duration: 49564.93312216324
[2024-12-28 01:54:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.68239103021311
avg_train_sample_per_sec: 16.68239103021311
avg_episode_per_sec: 0.14381371577769925
collect_time: 41.720638171080495
reward_mean: -104.65639589169002
reward_std: 2.185590334903379
reward_max: -100.74929971988796
reward_min: -108.14425770308128
queue_len: 0.06940079303162468
wait_time: 0.6546538597755635
delay_time: 4.371167212348975
pressure: 0.8501326259946951
total_envstep_count: 831024
total_train_sample_count: 831024
total_episode_count: 7164
total_duration: 49606.65376033432
[2024-12-28 01:55:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.943740627513193
avg_train_sample_per_sec: 16.943740627513193
avg_episode_per_sec: 0.14606672954752753
collect_time: 41.07711604542844
reward_mean: -105.51167133520075
reward_std: 5.04826663996111
reward_max: -96.7317927170868
reward_min: -111.6820728291317
queue_len: 0.0699679518137936
wait_time: 0.6605332561848789
delay_time: 4.373167137959995
pressure: 0.8622900088417329
total_envstep_count: 831720
total_train_sample_count: 831720
total_episode_count: 7170
total_duration: 49647.73087637975
[2024-12-28 01:56:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.993550329311272
avg_train_sample_per_sec: 16.993550329311272
avg_episode_per_sec: 0.14649612352854546
collect_time: 40.95671513677201
reward_mean: -103.40674603174602
reward_std: 2.4780943377403233
reward_max: -99.51050420168067
reward_min: -106.64355742296914
queue_len: 0.06857211275314724
wait_time: 0.6563743755680876
delay_time: 4.3294564098734805
pressure: 0.8458222811671088
total_envstep_count: 832416
total_train_sample_count: 832416
total_episode_count: 7176
total_duration: 49688.68759151652
[2024-12-28 01:56:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.035129296341964
avg_train_sample_per_sec: 17.035129296341964
avg_episode_per_sec: 0.14685456289949966
collect_time: 40.856748891800635
reward_mean: -102.83951914098974
reward_std: 2.47737311847239
reward_max: -99.53291316526608
reward_min: -106.17997198879549
queue_len: 0.06819596760012582
wait_time: 0.6455991326680982
delay_time: 4.273248181618965
pressure: 0.8390804597701149
total_envstep_count: 833112
total_train_sample_count: 833112
total_episode_count: 7182
total_duration: 49729.54434040832
[2024-12-28 01:57:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.62897741242785
avg_train_sample_per_sec: 16.62897741242785
avg_episode_per_sec: 0.1433532535554125
collect_time: 41.85464822869004
reward_mean: -103.78991596638656
reward_std: 0.8601179845362603
reward_max: -102.34033613445378
reward_min: -105.13725490196079
queue_len: 0.06882620422174175
wait_time: 0.6572750342400443
delay_time: 4.340895747318542
pressure: 0.8485853227232538
total_envstep_count: 833808
total_train_sample_count: 833808
total_episode_count: 7188
total_duration: 49771.39898863701
[2024-12-28 01:58:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.314412958044358
avg_train_sample_per_sec: 16.314412958044358
avg_episode_per_sec: 0.14064149101762377
collect_time: 42.661663756452505
reward_mean: -106.78956582633053
reward_std: 2.944035162860194
reward_max: -102.60224089635854
reward_min: -111.25700280112042
queue_len: 0.0708153619538001
wait_time: 0.6783554933909902
delay_time: 4.390922572424594
pressure: 0.8727895667550839
total_envstep_count: 834504
total_train_sample_count: 834504
total_episode_count: 7194
total_duration: 49814.06065239346
[2024-12-28 01:59:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.709671285506143
avg_train_sample_per_sec: 16.709671285506143
avg_episode_per_sec: 0.14404889039229432
collect_time: 41.652524942468844
reward_mean: -103.1451914098973
reward_std: 2.5742900057687437
reward_max: -100.07072829131653
reward_min: -107.87114845938372
queue_len: 0.06839866804369847
wait_time: 0.6550955594439367
delay_time: 4.265213987938061
pressure: 0.8456012378426173
total_envstep_count: 835200
total_train_sample_count: 835200
total_episode_count: 7200
total_duration: 49855.71317733593
[2024-12-28 01:59:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.966598767253206
avg_train_sample_per_sec: 16.966598767253206
avg_episode_per_sec: 0.14626378247632074
collect_time: 41.02177516824006
reward_mean: -106.33835200746965
reward_std: 2.6463209693165863
reward_max: -103.18347338935573
reward_min: -111.51400560224089
queue_len: 0.07051614854606741
wait_time: 0.6729296382567175
delay_time: 4.443738634364885
pressure: 0.8603006189213086
total_envstep_count: 835896
total_train_sample_count: 835896
total_episode_count: 7206
total_duration: 49896.73495250417
[2024-12-28 02:00:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.98835535417735
avg_train_sample_per_sec: 16.98835535417735
avg_episode_per_sec: 0.14645133926014958
collect_time: 40.969239546125756
reward_mean: -103.54831932773108
reward_std: 1.7788635271041824
reward_max: -99.73039215686278
reward_min: -105.00350140056021
queue_len: 0.06866599424915855
wait_time: 0.6531986578893272
delay_time: 4.272924956693137
pressure: 0.8485853227232538
total_envstep_count: 836592
total_train_sample_count: 836592
total_episode_count: 7212
total_duration: 49937.704192050296
[2024-12-28 02:01:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05137042768607
avg_train_sample_per_sec: 17.05137042768607
avg_episode_per_sec: 0.1469945726524661
collect_time: 40.81783355488628
reward_mean: -103.62686741363211
reward_std: 1.9397850290122425
reward_max: -99.94327731092436
reward_min: -105.65616246498602
queue_len: 0.06871808183927859
wait_time: 0.6558093064812133
delay_time: 4.349984620359211
pressure: 0.8464854111405836
total_envstep_count: 837288
total_train_sample_count: 837288
total_episode_count: 7218
total_duration: 49978.52202560518
[2024-12-28 02:01:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.978693715902917
avg_train_sample_per_sec: 16.978693715902917
avg_episode_per_sec: 0.14636804927502514
collect_time: 40.99255288103223
reward_mean: -106.40721288515404
reward_std: 3.986731123719222
reward_max: -101.90336134453784
reward_min: -113.58193277310926
queue_len: 0.07056181225805971
wait_time: 0.6722061393080662
delay_time: 4.355909508847571
pressure: 0.8745579133510168
total_envstep_count: 837984
total_train_sample_count: 837984
total_episode_count: 7224
total_duration: 50019.51457848622
[2024-12-28 02:02:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.13266003859765
avg_train_sample_per_sec: 17.13266003859765
avg_episode_per_sec: 0.14769534516032456
collect_time: 40.624164515726264
reward_mean: -103.82761437908498
reward_std: 2.7987332386247696
reward_max: -99.27521008403357
reward_min: -106.46218487394957
queue_len: 0.06885120316915448
wait_time: 0.6584650770122374
delay_time: 4.319932436458514
pressure: 0.8521220159151194
total_envstep_count: 838680
total_train_sample_count: 838680
total_episode_count: 7230
total_duration: 50060.138743001946
[2024-12-28 02:03:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97512139165278
avg_train_sample_per_sec: 16.97512139165278
avg_episode_per_sec: 0.1463372533763171
collect_time: 41.00117954633572
reward_mean: -102.45611577964519
reward_std: 2.724023227447861
reward_max: -97.34453781512605
reward_min: -105.08613445378154
queue_len: 0.06794172133928726
wait_time: 0.6507358358905012
delay_time: 4.327121791211809
pressure: 0.8409593280282935
total_envstep_count: 839376
total_train_sample_count: 839376
total_episode_count: 7236
total_duration: 50101.13992254828
[2024-12-28 02:03:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.86050680086619
avg_train_sample_per_sec: 16.86050680086619
avg_episode_per_sec: 0.1453491965591913
collect_time: 41.279897942584014
reward_mean: -104.04260037348274
reward_std: 3.714464838042693
reward_max: -97.86834733893558
reward_min: -108.79131652661067
queue_len: 0.06899376682591694
wait_time: 0.6584978929679741
delay_time: 4.326835427822253
pressure: 0.8551061007957559
total_envstep_count: 840072
total_train_sample_count: 840072
total_episode_count: 7242
total_duration: 50142.41982049087
[2024-12-28 02:04:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.702425566518677
avg_train_sample_per_sec: 16.702425566518677
avg_episode_per_sec: 0.14398642729757483
collect_time: 41.67059432344884
reward_mean: -104.30613912231559
reward_std: 2.082251773671451
reward_max: -101.2429971988795
reward_min: -107.62464985994403
queue_len: 0.06916852726944005
wait_time: 0.6535202387763239
delay_time: 4.37169238793365
pressure: 0.8531167108753316
total_envstep_count: 840768
total_train_sample_count: 840768
total_episode_count: 7248
total_duration: 50184.090414814316
[2024-12-28 02:05:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.851719139310827
avg_train_sample_per_sec: 16.851719139310827
avg_episode_per_sec: 0.1452734408561278
collect_time: 41.3014241601266
reward_mean: -105.0909197012138
reward_std: 2.0030339384908227
reward_max: -103.06022408963582
reward_min: -108.38795518207284
queue_len: 0.06968893879390836
wait_time: 0.6673643927066849
delay_time: 4.401767546186893
pressure: 0.8647214854111406
total_envstep_count: 841464
total_train_sample_count: 841464
total_episode_count: 7254
total_duration: 50225.39183897444
[2024-12-28 02:05:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.06497968510246
avg_train_sample_per_sec: 17.06497968510246
avg_episode_per_sec: 0.14711189383709017
collect_time: 40.78528148542716
reward_mean: -106.31430905695608
reward_std: 1.3103586004316803
reward_max: -103.98599439775909
reward_min: -108.15756302521008
queue_len: 0.0705002049449311
wait_time: 0.6704096979198401
delay_time: 4.450866136518705
pressure: 0.8681476569407605
total_envstep_count: 842160
total_train_sample_count: 842160
total_episode_count: 7260
total_duration: 50266.17712045987
[2024-12-28 02:06:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89949592020004
avg_train_sample_per_sec: 16.89949592020004
avg_episode_per_sec: 0.14568530965689688
collect_time: 41.18466037605703
reward_mean: -105.42075163398692
reward_std: 2.8918023324510753
reward_max: -99.55182072829136
reward_min: -108.41386554621846
queue_len: 0.06990766023473934
wait_time: 0.6619891546362136
delay_time: 4.474173166735132
pressure: 0.8492484526967287
total_envstep_count: 842856
total_train_sample_count: 842856
total_episode_count: 7266
total_duration: 50307.36178083593
[2024-12-28 02:07:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.973177852529588
avg_train_sample_per_sec: 16.973177852529588
avg_episode_per_sec: 0.14632049872870334
collect_time: 41.00587444774062
reward_mean: -104.71171802054154
reward_std: 3.8520997740847056
reward_max: -101.25350140056022
reward_min: -112.6393557422969
queue_len: 0.06943747879346256
wait_time: 0.6604047786223243
delay_time: 4.3553106036299285
pressure: 0.8513483642793988
total_envstep_count: 843552
total_train_sample_count: 843552
total_episode_count: 7272
total_duration: 50348.36765528367
[2024-12-28 02:08:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.133996522325887
avg_train_sample_per_sec: 17.133996522325887
avg_episode_per_sec: 0.14770686657177487
collect_time: 40.620995755024246
reward_mean: -104.59768907563023
reward_std: 2.711544539889455
reward_max: -101.69957983193275
reward_min: -110.01050420168066
queue_len: 0.06936186278224817
wait_time: 0.6644732605685953
delay_time: 4.40969955663265
pressure: 0.8492484526967287
total_envstep_count: 844248
total_train_sample_count: 844248
total_episode_count: 7278
total_duration: 50388.98865103869
[2024-12-28 02:08:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.964700401612614
avg_train_sample_per_sec: 16.964700401612614
avg_episode_per_sec: 0.14624741725528118
collect_time: 41.02636554276197
reward_mean: -103.02474323062559
reward_std: 1.4912443565237856
reward_max: -101.02310924369748
reward_min: -105.23389355742297
queue_len: 0.06831879524577295
wait_time: 0.6523142524029947
delay_time: 4.281514045531785
pressure: 0.84394341290893
total_envstep_count: 844944
total_train_sample_count: 844944
total_episode_count: 7284
total_duration: 50430.015016581456
[2024-12-28 02:09:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.691582596018982
avg_train_sample_per_sec: 16.691582596018982
avg_episode_per_sec: 0.14389295341395672
collect_time: 41.69766383722052
reward_mean: -105.14005602240896
reward_std: 2.5561936680791937
reward_max: -100.92927170868344
reward_min: -108.52661064425769
queue_len: 0.06972152256127916
wait_time: 0.6661295375798417
delay_time: 4.383062777533781
pressure: 0.8583112290008842
total_envstep_count: 845640
total_train_sample_count: 845640
total_episode_count: 7290
total_duration: 50471.71268041868
[2024-12-28 02:10:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.92204133400473
avg_train_sample_per_sec: 16.92204133400473
avg_episode_per_sec: 0.14587966667245458
collect_time: 41.129789619494225
reward_mean: -105.83520074696547
reward_std: 3.385034658105876
reward_max: -101.06652661064429
reward_min: -111.52310924369752
queue_len: 0.07018249386403545
wait_time: 0.6673321185238019
delay_time: 4.446250495091382
pressure: 0.8629531388152079
total_envstep_count: 846336
total_train_sample_count: 846336
total_episode_count: 7296
total_duration: 50512.84247003817
[2024-12-28 02:10:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.785670092235836
avg_train_sample_per_sec: 16.785670092235836
avg_episode_per_sec: 0.14470405251927443
collect_time: 41.46393895361573
reward_mean: -106.61461251167133
reward_std: 4.343926996140875
reward_max: -101.37324929971983
reward_min: -114.25700280112038
queue_len: 0.07069934516689079
wait_time: 0.6758794366552987
delay_time: 4.4502176484854905
pressure: 0.8687002652519894
total_envstep_count: 847032
total_train_sample_count: 847032
total_episode_count: 7302
total_duration: 50554.30640899179
[2024-12-28 02:11:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.955218894656156
avg_train_sample_per_sec: 16.955218894656156
avg_episode_per_sec: 0.14616568012634618
collect_time: 41.04930784581974
reward_mean: -107.43662464985995
reward_std: 2.7888505412224087
reward_max: -103.1680672268907
reward_min: -110.95728291316527
queue_len: 0.07124444605428377
wait_time: 0.6789827889599694
delay_time: 4.451111292772318
pressure: 0.8783156498673739
total_envstep_count: 847728
total_train_sample_count: 847728
total_episode_count: 7308
total_duration: 50595.35571683761
[2024-12-28 02:12:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.680276488688413
avg_train_sample_per_sec: 16.680276488688413
avg_episode_per_sec: 0.14379548697145184
collect_time: 41.725927053546535
reward_mean: -104.37289915966387
reward_std: 1.8113311847224298
reward_max: -101.45238095238096
reward_min: -107.02310924369749
queue_len: 0.06921279785123599
wait_time: 0.6591398164040152
delay_time: 4.3681222758912375
pressure: 0.8521220159151195
total_envstep_count: 848424
total_train_sample_count: 848424
total_episode_count: 7314
total_duration: 50637.08164389115
[2024-12-28 02:12:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.049626603970523
avg_train_sample_per_sec: 17.049626603970523
avg_episode_per_sec: 0.14697953968940106
collect_time: 40.822008373949686
reward_mean: -102.84943977591037
reward_std: 2.3076712595005318
reward_max: -99.86764705882354
reward_min: -106.718487394958
queue_len: 0.0682025462704976
wait_time: 0.6493357400431436
delay_time: 4.284274615443299
pressure: 0.8420645446507514
total_envstep_count: 849120
total_train_sample_count: 849120
total_episode_count: 7320
total_duration: 50677.9036522651
[2024-12-28 02:13:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.92170215066423
avg_train_sample_per_sec: 16.92170215066423
avg_episode_per_sec: 0.1458767426781399
collect_time: 41.130614036524676
reward_mean: -103.00875350140056
reward_std: 2.6992496764472835
reward_max: -98.13165266106441
reward_min: -105.7738095238095
queue_len: 0.06830819197705608
wait_time: 0.6542686592762658
delay_time: 4.286725540817129
pressure: 0.8398541114058355
total_envstep_count: 849816
total_train_sample_count: 849816
total_episode_count: 7326
total_duration: 50719.03426630163
[2024-12-28 02:14:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.78197606091152
avg_train_sample_per_sec: 16.78197606091152
avg_episode_per_sec: 0.14467220742165104
collect_time: 41.47306595324725
reward_mean: -104.94782913165267
reward_std: 2.6514499870757318
reward_max: -101.92717086834737
reward_min: -109.65616246498598
queue_len: 0.0695940511483108
wait_time: 0.6601604390651044
delay_time: 4.395565760209663
pressure: 0.8504641909814324
total_envstep_count: 850512
total_train_sample_count: 850512
total_episode_count: 7332
total_duration: 50760.50733225488
[2024-12-28 02:15:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.447222046001027
avg_train_sample_per_sec: 16.447222046001027
avg_episode_per_sec: 0.1417863969482847
collect_time: 42.317176606077695
reward_mean: -104.56314192343604
reward_std: 3.161827738650011
reward_max: -101.53431372549018
reward_min: -109.71778711484592
queue_len: 0.06933895353012999
wait_time: 0.6555390392231163
delay_time: 4.373965350558193
pressure: 0.8523430592396108
total_envstep_count: 851208
total_train_sample_count: 851208
total_episode_count: 7338
total_duration: 50802.824508860955
[2024-12-28 02:15:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.757850894164353
avg_train_sample_per_sec: 16.757850894164353
avg_episode_per_sec: 0.14446423184624443
collect_time: 41.53277197629026
reward_mean: -103.60667600373483
reward_std: 2.184052487286505
reward_max: -101.30952380952382
reward_min: -107.85994397759104
queue_len: 0.06870469231016899
wait_time: 0.6534318524049761
delay_time: 4.33737501409851
pressure: 0.8485853227232538
total_envstep_count: 851904
total_train_sample_count: 851904
total_episode_count: 7344
total_duration: 50844.35728083725
[2024-12-28 02:16:26][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.911567930221995
avg_train_sample_per_sec: 16.911567930221995
avg_episode_per_sec: 0.1457893787088103
collect_time: 41.15526146787406
reward_mean: -104.92915499533144
reward_std: 4.587495202245141
reward_max: -99.35924369747896
reward_min: -112.44397759103643
queue_len: 0.06958166776878745
wait_time: 0.6636134670490654
delay_time: 4.313569636705633
pressure: 0.8628426171529621
total_envstep_count: 852600
total_train_sample_count: 852600
total_episode_count: 7350
total_duration: 50885.51254230512
[2024-12-28 02:17:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8306990678686
avg_train_sample_per_sec: 16.8306990678686
avg_episode_per_sec: 0.1450922333436948
collect_time: 41.35300602746383
reward_mean: -105.4344070961718
reward_std: 4.191976454355486
reward_max: -100.14005602240894
reward_min: -112.71428571428575
queue_len: 0.06991671558101577
wait_time: 0.6691650134855003
delay_time: 4.4280783753707444
pressure: 0.8631741821396993
total_envstep_count: 853296
total_train_sample_count: 853296
total_episode_count: 7356
total_duration: 50926.865548332586
[2024-12-28 02:17:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.852733362860747
avg_train_sample_per_sec: 16.852733362860747
avg_episode_per_sec: 0.14528218416259264
collect_time: 41.29893857656419
reward_mean: -102.719070961718
reward_std: 2.5020260491412314
reward_max: -98.75350140056018
reward_min: -106.54411764705883
queue_len: 0.06811609480220027
wait_time: 0.6433711305034834
delay_time: 4.3331155920913575
pressure: 0.8342175066312998
total_envstep_count: 853992
total_train_sample_count: 853992
total_episode_count: 7362
total_duration: 50968.16448690915
[2024-12-28 02:18:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.47896449095433
avg_train_sample_per_sec: 16.47896449095433
avg_episode_per_sec: 0.14206003871512352
collect_time: 42.235663556532934
reward_mean: -104.7376283846872
reward_std: 1.3457194845930789
reward_max: -102.88655462184875
reward_min: -106.57002801120451
queue_len: 0.0694546607325512
wait_time: 0.6594727745209491
delay_time: 4.370694125163049
pressure: 0.8582007073386384
total_envstep_count: 854688
total_train_sample_count: 854688
total_episode_count: 7368
total_duration: 51010.40015046568
[2024-12-28 02:19:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.9154947530463
avg_train_sample_per_sec: 16.9154947530463
avg_episode_per_sec: 0.1458232306297095
collect_time: 41.14570753980801
reward_mean: -104.89425770308122
reward_std: 2.119909101660688
reward_max: -101.27731092436974
reward_min: -108.2745098039216
queue_len: 0.0695585263283032
wait_time: 0.6608742634985029
delay_time: 4.390638586878041
pressure: 0.8582007073386384
total_envstep_count: 855384
total_train_sample_count: 855384
total_episode_count: 7374
total_duration: 51051.545858005484
[2024-12-28 02:19:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.802012758410527
avg_train_sample_per_sec: 16.802012758410527
avg_episode_per_sec: 0.14484493757250452
collect_time: 41.423608588298784
reward_mean: -106.03069561157797
reward_std: 2.7758748675332625
reward_max: -101.96778711484593
reward_min: -110.75630252100844
queue_len: 0.07031213236842039
wait_time: 0.6706024142636718
delay_time: 4.420818665732026
pressure: 0.8631741821396993
total_envstep_count: 856080
total_train_sample_count: 856080
total_episode_count: 7380
total_duration: 51092.969466593786
[2024-12-28 02:20:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90593857420347
avg_train_sample_per_sec: 16.90593857420347
avg_episode_per_sec: 0.14574084977761612
collect_time: 41.168965387228866
reward_mean: -105.94794584500467
reward_std: 3.189760425415672
reward_max: -102.11134453781514
reward_min: -111.29061624649857
queue_len: 0.07025725851790761
wait_time: 0.6668663486614804
delay_time: 4.393924385968341
pressure: 0.8695844385499559
total_envstep_count: 856776
total_train_sample_count: 856776
total_episode_count: 7386
total_duration: 51134.13843198102
[2024-12-28 02:21:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.94050303011822
avg_train_sample_per_sec: 16.94050303011822
avg_episode_per_sec: 0.14603881922515705
collect_time: 41.08496653036772
reward_mean: -103.79423436041083
reward_std: 3.482618049723408
reward_max: -100.36484593837535
reward_min: -109.44817927170871
queue_len: 0.06882906787825652
wait_time: 0.649707705805576
delay_time: 4.316823491191591
pressure: 0.8500221043324491
total_envstep_count: 857472
total_train_sample_count: 857472
total_episode_count: 7392
total_duration: 51175.223398511385
[2024-12-28 02:22:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.766174856495606
avg_train_sample_per_sec: 16.766174856495606
avg_episode_per_sec: 0.14453599014220347
collect_time: 41.51215205359459
reward_mean: -106.27299253034549
reward_std: 3.977413751799864
reward_max: -99.61064425770311
reward_min: -113.01330532212886
queue_len: 0.07047280671773574
wait_time: 0.6730701896143074
delay_time: 4.47799937277473
pressure: 0.8677055702917773
total_envstep_count: 858168
total_train_sample_count: 858168
total_episode_count: 7398
total_duration: 51216.73555056498
[2024-12-28 02:22:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.796443950518622
avg_train_sample_per_sec: 16.796443950518622
avg_episode_per_sec: 0.14479693060791915
collect_time: 41.437342454770594
reward_mean: -104.01633986928105
reward_std: 2.200328426335013
reward_max: -100.27170868347342
reward_min: -106.66316526610645
queue_len: 0.06897635269846224
wait_time: 0.6548384495265833
delay_time: 4.330078698751372
pressure: 0.8522325375773652
total_envstep_count: 858864
total_train_sample_count: 858864
total_episode_count: 7404
total_duration: 51258.17289301976
[2024-12-28 02:23:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.775843498566992
avg_train_sample_per_sec: 16.775843498566992
avg_episode_per_sec: 0.14461934050488787
collect_time: 41.48822681014239
reward_mean: -103.03956582633054
reward_std: 1.8273159638712517
reward_max: -100.9747899159664
reward_min: -106.0427170868347
queue_len: 0.06832862455326959
wait_time: 0.6527034775006378
delay_time: 4.3322503068366585
pressure: 0.8428381962864723
total_envstep_count: 859560
total_train_sample_count: 859560
total_episode_count: 7410
total_duration: 51299.6611198299
[2024-12-28 02:24:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.944643311705487
avg_train_sample_per_sec: 16.944643311705487
avg_episode_per_sec: 0.14607451130780594
collect_time: 41.074927763111894
reward_mean: -103.15511204481788
reward_std: 2.8766542070060614
reward_max: -98.50560224089634
reward_min: -106.0644257703081
queue_len: 0.06840524671407022
wait_time: 0.6480703134481024
delay_time: 4.311673771246955
pressure: 0.8450486295313882
total_envstep_count: 860256
total_train_sample_count: 860256
total_episode_count: 7416
total_duration: 51340.73604759301
[2024-12-28 02:24:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.865201123791138
avg_train_sample_per_sec: 16.865201123791138
avg_episode_per_sec: 0.1453896648602684
collect_time: 41.26840794197098
reward_mean: -103.49253034547151
reward_std: 3.5928761283851687
reward_max: -98.62955182072828
reward_min: -107.37535014005603
queue_len: 0.06862899890283257
wait_time: 0.6533252005488314
delay_time: 4.319556156276122
pressure: 0.8459328028293545
total_envstep_count: 860952
total_train_sample_count: 860952
total_episode_count: 7422
total_duration: 51382.00445553498
[2024-12-28 02:25:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.704833906662035
avg_train_sample_per_sec: 16.704833906662035
avg_episode_per_sec: 0.1440071888505348
collect_time: 41.66458666329086
reward_mean: -108.49299719887955
reward_std: 2.446233331449339
reward_max: -104.46358543417364
reward_min: -111.29131652661063
queue_len: 0.07194495835469467
wait_time: 0.6856691173374744
delay_time: 4.469558730595572
pressure: 0.8861626878868258
total_envstep_count: 861648
total_train_sample_count: 861648
total_episode_count: 7428
total_duration: 51423.66904219827
[2024-12-28 02:26:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.70269183406226
avg_train_sample_per_sec: 16.70269183406226
avg_episode_per_sec: 0.14398872270743326
collect_time: 41.66993002772332
reward_mean: -105.70238095238095
reward_std: 3.11865746703397
reward_max: -100.08613445378153
reward_min: -108.66526610644259
queue_len: 0.0700944170771757
wait_time: 0.6612808253274784
delay_time: 4.469166020324132
pressure: 0.8583112290008841
total_envstep_count: 862344
total_train_sample_count: 862344
total_episode_count: 7434
total_duration: 51465.338972225996
[2024-12-28 02:26:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.88956021408145
avg_train_sample_per_sec: 16.88956021408145
avg_episode_per_sec: 0.14559965701794353
collect_time: 41.208888282343736
reward_mean: -105.93394024276377
reward_std: 1.9386129647478785
reward_max: -103.63585434173672
reward_min: -109.39145658263301
queue_len: 0.07024797098326512
wait_time: 0.6652881643373528
delay_time: 4.399743449788547
pressure: 0.8616268788682581
total_envstep_count: 863040
total_train_sample_count: 863040
total_episode_count: 7440
total_duration: 51506.54786050834
[2024-12-28 02:27:39][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.85530668077986
avg_train_sample_per_sec: 16.85530668077986
avg_episode_per_sec: 0.14530436793775742
collect_time: 41.29263342289999
reward_mean: -103.76167133520077
reward_std: 3.748636825073199
reward_max: -100.10854341736699
reward_min: -111.72338935574236
queue_len: 0.06880747436021271
wait_time: 0.6516834740085248
delay_time: 4.3602339685673295
pressure: 0.8398541114058355
total_envstep_count: 863736
total_train_sample_count: 863736
total_episode_count: 7446
total_duration: 51547.84049393124
[2024-12-28 02:28:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.859471015633947
avg_train_sample_per_sec: 16.859471015633947
avg_episode_per_sec: 0.1453402673761547
collect_time: 41.28243403097242
reward_mean: -103.02217553688142
reward_std: 2.735283888526325
reward_max: -100.87254901960786
reward_min: -108.53501400560224
queue_len: 0.06831709253108847
wait_time: 0.6470909429200504
delay_time: 4.37757729183583
pressure: 0.8420645446507516
total_envstep_count: 864432
total_train_sample_count: 864432
total_episode_count: 7452
total_duration: 51589.12292796221
[2024-12-28 02:29:03][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90874327122087
avg_train_sample_per_sec: 16.90874327122087
avg_episode_per_sec: 0.14576502820017992
collect_time: 41.162136584367595
reward_mean: -103.21300186741361
reward_std: 3.017763696702436
reward_max: -100.16316526610646
reward_min: -108.48389355742293
queue_len: 0.06844363519059259
wait_time: 0.6473424029204962
delay_time: 4.345905818111019
pressure: 0.8436118479221927
total_envstep_count: 865128
total_train_sample_count: 865128
total_episode_count: 7458
total_duration: 51630.28506454658
[2024-12-28 02:29:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.870996499888438
avg_train_sample_per_sec: 16.870996499888438
avg_episode_per_sec: 0.14543962499903826
collect_time: 41.254231782017285
reward_mean: -102.56349206349205
reward_std: 4.921161769056997
reward_max: -96.20728291316523
reward_min: -108.29481792717088
queue_len: 0.06801292577154645
wait_time: 0.6479981802623791
delay_time: 4.2655500320335555
pressure: 0.8342175066312998
total_envstep_count: 865824
total_train_sample_count: 865824
total_episode_count: 7464
total_duration: 51671.5392963286
[2024-12-28 02:30:27][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.837386919184784
avg_train_sample_per_sec: 16.837386919184784
avg_episode_per_sec: 0.1451498872343516
collect_time: 41.33658051220327
reward_mean: -104.46977124183009
reward_std: 3.3030833282419665
reward_max: -101.6932773109244
reward_min: -109.83753501400565
queue_len: 0.06927703663251332
wait_time: 0.6586282280374572
delay_time: 4.38097725075475
pressure: 0.850685234305924
total_envstep_count: 866520
total_train_sample_count: 866520
total_episode_count: 7470
total_duration: 51712.8758768408
[2024-12-28 02:31:08][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.055181666353555
avg_train_sample_per_sec: 17.055181666353555
avg_episode_per_sec: 0.1470274281582203
collect_time: 40.80871219173631
reward_mean: -105.2455648926237
reward_std: 2.0129360951840995
reward_max: -101.57492997198877
reward_min: -107.71848739495799
queue_len: 0.06979148865558601
wait_time: 0.659699235573982
delay_time: 4.437022570227985
pressure: 0.853448275862069
total_envstep_count: 867216
total_train_sample_count: 867216
total_episode_count: 7476
total_duration: 51753.684589032535
[2024-12-28 02:31:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.93464603136864
avg_train_sample_per_sec: 16.93464603136864
avg_episode_per_sec: 0.1459883278566262
collect_time: 41.09917613339982
reward_mean: -104.8795518207283
reward_std: 2.2508617628929053
reward_max: -100.4803921568627
reward_min: -107.24229691876752
queue_len: 0.0695487744169286
wait_time: 0.662825806715259
delay_time: 4.366191735161752
pressure: 0.8556587091069848
total_envstep_count: 867912
total_train_sample_count: 867912
total_episode_count: 7482
total_duration: 51794.783765165936
[2024-12-28 02:32:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.759392654575336
avg_train_sample_per_sec: 16.759392654575336
avg_episode_per_sec: 0.14447752288427013
collect_time: 41.5289512182884
reward_mean: -104.99439775910365
reward_std: 3.2921138057331967
reward_max: -100.18767507002804
reward_min: -109.54061624649862
queue_len: 0.06962493220099712
wait_time: 0.6593044379555536
delay_time: 4.391917969138786
pressure: 0.8614058355437666
total_envstep_count: 868608
total_train_sample_count: 868608
total_episode_count: 7488
total_duration: 51836.31271638422
[2024-12-28 02:33:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.943851773093865
avg_train_sample_per_sec: 16.943851773093865
avg_episode_per_sec: 0.14606768769908504
collect_time: 41.07684659430385
reward_mean: -103.9421101774043
reward_std: 3.493510149312319
reward_max: -101.08403361344537
reward_min: -111.41596638655464
queue_len: 0.06892712876485697
wait_time: 0.6548060979475786
delay_time: 4.317122450463917
pressure: 0.8461538461538461
total_envstep_count: 869304
total_train_sample_count: 869304
total_episode_count: 7494
total_duration: 51877.389562978526
[2024-12-28 02:33:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.164102530801692
avg_train_sample_per_sec: 17.164102530801692
avg_episode_per_sec: 0.1479664011276008
collect_time: 40.549746119903396
reward_mean: -107.39484126984127
reward_std: 3.643023602911909
reward_max: -103.10784313725489
reward_min: -111.53851540616247
queue_len: 0.07121673824260029
wait_time: 0.6790415326165834
delay_time: 4.505193667618695
pressure: 0.878868258178603
total_envstep_count: 870000
total_train_sample_count: 870000
total_episode_count: 7500
total_duration: 51917.93930909843
[2024-12-28 02:34:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.809295324536787
avg_train_sample_per_sec: 16.809295324536787
avg_episode_per_sec: 0.14490771831497232
collect_time: 41.405661960382005
reward_mean: -106.22969187675072
reward_std: 2.7590760626053528
reward_max: -102.03781512605045
reward_min: -109.00210084033613
queue_len: 0.07044409275646599
wait_time: 0.6719518930472278
delay_time: 4.396363510134367
pressure: 0.8773209549071618
total_envstep_count: 870696
total_train_sample_count: 870696
total_episode_count: 7506
total_duration: 51959.34497105881
[2024-12-28 02:35:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.05235576286456
avg_train_sample_per_sec: 17.05235576286456
avg_episode_per_sec: 0.1470030669212462
collect_time: 40.815474980629986
reward_mean: -103.98809523809524
reward_std: 1.8159424100208585
reward_max: -100.90056022408963
reward_min: -106.62815126050417
queue_len: 0.06895762283693317
wait_time: 0.6562407124653574
delay_time: 4.319364522566443
pressure: 0.8584217506631299
total_envstep_count: 871392
total_train_sample_count: 871392
total_episode_count: 7512
total_duration: 52000.16044603944
[2024-12-28 02:36:01][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8134659304888
avg_train_sample_per_sec: 16.8134659304888
avg_episode_per_sec: 0.1449436718145586
collect_time: 41.39539122257382
reward_mean: -106.21031746031747
reward_std: 3.531044092787124
reward_max: -101.93137254901964
reward_min: -112.29551820728295
queue_len: 0.07043124500021053
wait_time: 0.6725684305552461
delay_time: 4.4174272492109266
pressure: 0.876105216622458
total_envstep_count: 872088
total_train_sample_count: 872088
total_episode_count: 7518
total_duration: 52041.555837262014
[2024-12-28 02:36:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.66765346997973
avg_train_sample_per_sec: 16.66765346997973
avg_episode_per_sec: 0.14368666784465284
collect_time: 41.75752761200443
reward_mean: -103.34337068160598
reward_std: 1.468022341707091
reward_max: -101.43697478991596
reward_min: -105.9712885154062
queue_len: 0.0685300866588899
wait_time: 0.65182921090629
delay_time: 4.357929608385583
pressure: 0.8464854111405836
total_envstep_count: 872784
total_train_sample_count: 872784
total_episode_count: 7524
total_duration: 52083.31336487402
[2024-12-28 02:37:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.108250115089
avg_train_sample_per_sec: 17.108250115089
avg_episode_per_sec: 0.14748491478525
collect_time: 40.68212677029706
reward_mean: -104.46965452847807
reward_std: 2.319321446699523
reward_max: -100.14985994397765
reward_min: -106.9509803921569
queue_len: 0.0692769592363913
wait_time: 0.6576476965675749
delay_time: 4.402069914012383
pressure: 0.8463748894783377
total_envstep_count: 873480
total_train_sample_count: 873480
total_episode_count: 7530
total_duration: 52123.99549164432
[2024-12-28 02:38:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.957018658875835
avg_train_sample_per_sec: 16.957018658875835
avg_episode_per_sec: 0.14618119533513652
collect_time: 41.044951002379875
reward_mean: -104.22397292250234
reward_std: 2.565633141531858
reward_max: -100.42366946778712
reward_min: -108.81232492997196
queue_len: 0.06911404039953735
wait_time: 0.6547283148449475
delay_time: 4.337839064735193
pressure: 0.8460433244916002
total_envstep_count: 874176
total_train_sample_count: 874176
total_episode_count: 7536
total_duration: 52165.0404426467
[2024-12-28 02:38:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.002123714584002
avg_train_sample_per_sec: 17.002123714584002
avg_episode_per_sec: 0.1465700320222759
collect_time: 40.93606255805493
reward_mean: -108.32609710550888
reward_std: 1.469655269985819
reward_max: -105.05042016806723
reward_min: -109.08683473389353
queue_len: 0.0718342819002048
wait_time: 0.679975007244277
delay_time: 4.4608683182941835
pressure: 0.8791998231653405
total_envstep_count: 874872
total_train_sample_count: 874872
total_episode_count: 7542
total_duration: 52205.97650520475
[2024-12-28 02:39:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.906643525749672
avg_train_sample_per_sec: 16.906643525749672
avg_episode_per_sec: 0.14574692694611788
collect_time: 41.167248776491725
reward_mean: -104.49019607843137
reward_std: 3.178359748398055
reward_max: -100.07913165266105
reward_min: -108.94117647058822
queue_len: 0.06929058095386695
wait_time: 0.6557964587249577
delay_time: 4.398971144564143
pressure: 0.845711759504863
total_envstep_count: 875568
total_train_sample_count: 875568
total_episode_count: 7548
total_duration: 52247.14375398124
[2024-12-28 02:40:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.038021584713007
avg_train_sample_per_sec: 17.038021584713007
avg_episode_per_sec: 0.14687949641993972
collect_time: 40.849813256749876
reward_mean: -102.55170401493932
reward_std: 3.5872808787480226
reward_max: -97.60084033613444
reward_min: -106.88235294117644
queue_len: 0.06800510876322235
wait_time: 0.6395573591947832
delay_time: 4.286682774935175
pressure: 0.8429487179487181
total_envstep_count: 876264
total_train_sample_count: 876264
total_episode_count: 7554
total_duration: 52287.99356723799
[2024-12-28 02:40:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.577233416593977
avg_train_sample_per_sec: 16.577233416593977
avg_episode_per_sec: 0.14290718462581015
collect_time: 41.98529287180676
reward_mean: -103.48634453781513
reward_std: 2.6425713358651444
reward_max: -100.79621848739495
reward_min: -106.53011204481793
queue_len: 0.06862489690836547
wait_time: 0.6536605579455479
delay_time: 4.332625881249687
pressure: 0.8399646330680813
total_envstep_count: 876960
total_train_sample_count: 876960
total_episode_count: 7560
total_duration: 52329.9788601098
[2024-12-28 02:41:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.931843677653216
avg_train_sample_per_sec: 16.931843677653216
avg_episode_per_sec: 0.1459641696349415
collect_time: 41.105978371309114
reward_mean: -105.1520774976657
reward_std: 2.4571946171021426
reward_max: -101.46988795518206
reward_min: -107.8725490196078
queue_len: 0.06972949436184729
wait_time: 0.6610023540804474
delay_time: 4.42228977348785
pressure: 0.8572060123784261
total_envstep_count: 877656
total_train_sample_count: 877656
total_episode_count: 7566
total_duration: 52371.0848384811
[2024-12-28 02:42:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.933658696936963
avg_train_sample_per_sec: 16.933658696936963
avg_episode_per_sec: 0.14597981635290486
collect_time: 41.1015724632442
reward_mean: -106.74218020541552
reward_std: 2.1870834437474413
reward_max: -102.63165266106436
reward_min: -108.50210084033614
queue_len: 0.0707839391282596
wait_time: 0.6720667488923068
delay_time: 4.468838101953717
pressure: 0.8702475685234305
total_envstep_count: 878352
total_train_sample_count: 878352
total_episode_count: 7572
total_duration: 52412.18641094435
[2024-12-28 02:43:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.675892174632633
avg_train_sample_per_sec: 16.675892174632633
avg_episode_per_sec: 0.14375769116062617
collect_time: 41.736897355258456
reward_mean: -101.4328898225957
reward_std: 1.0883414437648682
reward_max: -99.74649859943979
reward_min: -102.41526610644259
queue_len: 0.0672631895375303
wait_time: 0.6384176239019039
delay_time: 4.314988339436933
pressure: 0.8275862068965517
total_envstep_count: 879048
total_train_sample_count: 879048
total_episode_count: 7578
total_duration: 52453.92330829961
[2024-12-28 02:43:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.353283454054903
avg_train_sample_per_sec: 16.353283454054903
avg_episode_per_sec: 0.1409765815004733
collect_time: 42.56026026549563
reward_mean: -105.37278244631186
reward_std: 2.7773575288816814
reward_max: -102.01050420168067
reward_min: -110.29551820728292
queue_len: 0.06987585042858876
wait_time: 0.6615707512005687
delay_time: 4.416824494284586
pressure: 0.857316534040672
total_envstep_count: 879744
total_train_sample_count: 879744
total_episode_count: 7584
total_duration: 52496.483568565105
[2024-12-28 02:44:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.718987032339886
avg_train_sample_per_sec: 16.718987032339886
avg_episode_per_sec: 0.1441291985546542
collect_time: 41.62931633679197
reward_mean: -103.94736227824465
reward_std: 2.2726856209306288
reward_max: -101.91036414565826
reward_min: -108.4264705882353
queue_len: 0.0689306115903479
wait_time: 0.6521196785522343
delay_time: 4.3514466153476805
pressure: 0.8520114942528737
total_envstep_count: 880440
total_train_sample_count: 880440
total_episode_count: 7590
total_duration: 52538.1128849019
[2024-12-28 02:45:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.8530014256385
avg_train_sample_per_sec: 16.8530014256385
avg_episode_per_sec: 0.14528449504860774
collect_time: 41.298281678251925
reward_mean: -107.27275910364146
reward_std: 4.2833744358288275
reward_max: -100.90896358543417
reward_min: -114.85504201680672
queue_len: 0.07113578189896648
wait_time: 0.6753462547706969
delay_time: 4.42581199853451
pressure: 0.8730106100795755
total_envstep_count: 881136
total_train_sample_count: 881136
total_episode_count: 7596
total_duration: 52579.411166580154
[2024-12-28 02:45:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.91212538679685
avg_train_sample_per_sec: 16.91212538679685
avg_episode_per_sec: 0.14579418436893835
collect_time: 41.15390491034091
reward_mean: -109.21965452847803
reward_std: 3.0636318957736943
reward_max: -105.44537815126048
reward_min: -114.44677871148454
queue_len: 0.07242682661039658
wait_time: 0.6862563991113689
delay_time: 4.524531673536992
pressure: 0.8885941644562334
total_envstep_count: 881832
total_train_sample_count: 881832
total_episode_count: 7602
total_duration: 52620.56507149049
[2024-12-28 02:46:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.1236565690516
avg_train_sample_per_sec: 17.1236565690516
avg_episode_per_sec: 0.1476177290435483
collect_time: 40.645524347756066
reward_mean: -103.56967787114844
reward_std: 1.5822909195931472
reward_max: -100.80952380952378
reward_min: -106.1596638655462
queue_len: 0.06868015773948836
wait_time: 0.6493942515113915
delay_time: 4.304831305612715
pressure: 0.8452696728558796
total_envstep_count: 882528
total_train_sample_count: 882528
total_episode_count: 7608
total_duration: 52661.210595838245
[2024-12-28 02:47:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.011725284183747
avg_train_sample_per_sec: 17.011725284183747
avg_episode_per_sec: 0.1466528041739978
collect_time: 40.91295787894539
reward_mean: -105.89600840336135
reward_std: 3.1981043348276086
reward_max: -101.75560224089635
reward_min: -110.9306722689076
queue_len: 0.07022281724360831
wait_time: 0.6715720328803493
delay_time: 4.405022125448949
pressure: 0.864500442086649
total_envstep_count: 883224
total_train_sample_count: 883224
total_episode_count: 7614
total_duration: 52702.12355371719
[2024-12-28 02:47:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.931408286431857
avg_train_sample_per_sec: 16.931408286431857
avg_episode_per_sec: 0.1459604162623436
collect_time: 41.10703541168198
reward_mean: -105.7313258636788
reward_std: 1.388907974823536
reward_max: -103.87955182072834
reward_min: -107.85364145658262
queue_len: 0.07011361131543686
wait_time: 0.6635811154700605
delay_time: 4.371882827829532
pressure: 0.8648320070733865
total_envstep_count: 883920
total_train_sample_count: 883920
total_episode_count: 7620
total_duration: 52743.23058912887
[2024-12-28 02:48:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.807360611345075
avg_train_sample_per_sec: 16.807360611345075
avg_episode_per_sec: 0.1448910397529748
collect_time: 41.41042821025662
reward_mean: -105.90989729225022
reward_std: 2.8170322070480496
reward_max: -102.25140056022414
reward_min: -111.08333333333333
queue_len: 0.07023202738212879
wait_time: 0.6690246169201545
delay_time: 4.446174427410018
pressure: 0.8614058355437666
total_envstep_count: 884616
total_train_sample_count: 884616
total_episode_count: 7626
total_duration: 52784.64101733913
[2024-12-28 02:49:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.89185100824294
avg_train_sample_per_sec: 16.89185100824294
avg_episode_per_sec: 0.14561940524347364
collect_time: 41.2032997248415
reward_mean: -106.71767040149393
reward_std: 2.439979058736969
reward_max: -103.53081232492994
reward_min: -111.01400560224091
queue_len: 0.07076768594263523
wait_time: 0.6687993168089519
delay_time: 4.42207080766494
pressure: 0.8723474801061007
total_envstep_count: 885312
total_train_sample_count: 885312
total_episode_count: 7632
total_duration: 52825.844317063966
[2024-12-28 02:50:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.74488312875522
avg_train_sample_per_sec: 16.74488312875522
avg_episode_per_sec: 0.1443524407651312
collect_time: 41.56493626430817
reward_mean: -107.1669000933707
reward_std: 3.8332170801822265
reward_max: -102.06792717086837
reward_min: -114.32703081232495
queue_len: 0.07106558361629355
wait_time: 0.675613658372279
delay_time: 4.454533931753143
pressure: 0.8791998231653403
total_envstep_count: 886008
total_train_sample_count: 886008
total_episode_count: 7638
total_duration: 52867.409253328275
[2024-12-28 02:50:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.084640340322736
avg_train_sample_per_sec: 17.084640340322736
avg_episode_per_sec: 0.14728138224416154
collect_time: 40.738346616365014
reward_mean: -106.02124183006539
reward_std: 2.1216519996840355
reward_max: -102.79901960784318
reward_min: -108.64565826330536
queue_len: 0.07030586328253673
wait_time: 0.663330042450225
delay_time: 4.38991190595927
pressure: 0.8666003536693192
total_envstep_count: 886704
total_train_sample_count: 886704
total_episode_count: 7644
total_duration: 52908.14759994464
[2024-12-28 02:51:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.030443743427423
avg_train_sample_per_sec: 17.030443743427423
avg_episode_per_sec: 0.14681417020196055
collect_time: 40.8679897297807
reward_mean: -105.18102240896359
reward_std: 3.7315317236327328
reward_max: -102.03431372549024
reward_min: -112.97198879551819
queue_len: 0.06974868860010847
wait_time: 0.6599184987876672
delay_time: 4.327341657399827
pressure: 0.8570954907161803
total_envstep_count: 887400
total_train_sample_count: 887400
total_episode_count: 7650
total_duration: 52949.015589674425
[2024-12-28 02:52:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.019479788374795
avg_train_sample_per_sec: 17.019479788374795
avg_episode_per_sec: 0.1467196533480586
collect_time: 40.89431690358743
reward_mean: -104.65511204481793
reward_std: 4.098952073895398
reward_max: -97.79901960784312
reward_min: -110.04061624649859
queue_len: 0.06939994167428244
wait_time: 0.6554242607741593
delay_time: 4.368534084821007
pressure: 0.8478116710875331
total_envstep_count: 888096
total_train_sample_count: 888096
total_episode_count: 7656
total_duration: 52989.90990657801
[2024-12-28 02:52:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.55469531597924
avg_train_sample_per_sec: 16.55469531597924
avg_episode_per_sec: 0.14271289065499346
collect_time: 42.04245301501825
reward_mean: -105.19199346405229
reward_std: 2.431458449358438
reward_max: -101.8956582633053
reward_min: -109.31232492997195
queue_len: 0.06975596383557843
wait_time: 0.6638860561908229
delay_time: 4.339175190238349
pressure: 0.8585322723253758
total_envstep_count: 888792
total_train_sample_count: 888792
total_episode_count: 7662
total_duration: 53031.95235959303
[2024-12-28 02:53:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.690438350685714
avg_train_sample_per_sec: 16.690438350685714
avg_episode_per_sec: 0.14388308923004925
collect_time: 41.70052250134014
reward_mean: -104.97957516339869
reward_std: 2.5887477405794774
reward_max: -99.93977591036413
reward_min: -107.63375350140058
queue_len: 0.06961510289350047
wait_time: 0.6583773098098656
delay_time: 4.4223818286475645
pressure: 0.855658709106985
total_envstep_count: 889488
total_train_sample_count: 889488
total_episode_count: 7668
total_duration: 53073.65288209437
[2024-12-28 02:54:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.54083692773704
avg_train_sample_per_sec: 16.54083692773704
avg_episode_per_sec: 0.14259342179083653
collect_time: 42.077677389642226
reward_mean: -105.26073762838469
reward_std: 3.6649220081494733
reward_max: -100.15896358543418
reward_min: -110.95588235294116
queue_len: 0.06980155015144872
wait_time: 0.6617852932508106
delay_time: 4.367161912787272
pressure: 0.8493589743589743
total_envstep_count: 890184
total_train_sample_count: 890184
total_episode_count: 7674
total_duration: 53115.730559484015
[2024-12-28 02:54:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.658810335933154
avg_train_sample_per_sec: 16.658810335933154
avg_episode_per_sec: 0.14361043393045825
collect_time: 41.77969410569035
reward_mean: -104.73552754435104
reward_std: 1.8749349147394174
reward_max: -101.9866946778711
reward_min: -107.60154061624648
queue_len: 0.0694532676023548
wait_time: 0.6602234395084294
delay_time: 4.365633666023323
pressure: 0.8555481874447391
total_envstep_count: 890880
total_train_sample_count: 890880
total_episode_count: 7680
total_duration: 53157.5102535897
[2024-12-28 02:55:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.67239227795948
avg_train_sample_per_sec: 16.67239227795948
avg_episode_per_sec: 0.14372751963758174
collect_time: 41.74565883506088
reward_mean: -104.34348739495796
reward_std: 1.8514506843058631
reward_max: -101.50420168067227
reward_min: -107.01820728291314
queue_len: 0.06919329402848672
wait_time: 0.6579894004462971
delay_time: 4.3979434053703494
pressure: 0.8498010610079576
total_envstep_count: 891576
total_train_sample_count: 891576
total_episode_count: 7686
total_duration: 53199.255912424764
[2024-12-28 02:56:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.087402352932315
avg_train_sample_per_sec: 17.087402352932315
avg_episode_per_sec: 0.14730519269769238
collect_time: 40.73176165835187
reward_mean: -101.33928571428571
reward_std: 3.2163019026579267
reward_max: -97.21218487394957
reward_min: -107.42507002801125
queue_len: 0.06720111784766956
wait_time: 0.6390575350387723
delay_time: 4.283535011386318
pressure: 0.8240495137046863
total_envstep_count: 892272
total_train_sample_count: 892272
total_episode_count: 7692
total_duration: 53239.98767408312
[2024-12-28 02:57:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95107075078144
avg_train_sample_per_sec: 16.95107075078144
avg_episode_per_sec: 0.14612992026535723
collect_time: 41.05935313661024
reward_mean: -105.03618113912232
reward_std: 1.1996853439753905
reward_max: -103.50070028011206
reward_min: -106.7766106442577
queue_len: 0.06965264001268058
wait_time: 0.6643221833384104
delay_time: 4.355227053587972
pressure: 0.8611847922192749
total_envstep_count: 892968
total_train_sample_count: 892968
total_episode_count: 7698
total_duration: 53281.04702721973
[2024-12-28 02:57:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.75430824208819
avg_train_sample_per_sec: 16.75430824208819
avg_episode_per_sec: 0.14443369174213955
collect_time: 41.54155396589823
reward_mean: -106.49778244631187
reward_std: 3.6538582187216084
reward_max: -102.68697478991598
reward_min: -112.078431372549
queue_len: 0.07062187164874792
wait_time: 0.6706551984188901
delay_time: 4.44696993846042
pressure: 0.8713527851458887
total_envstep_count: 893664
total_train_sample_count: 893664
total_episode_count: 7704
total_duration: 53322.58858118563
[2024-12-28 02:58:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.830182006282083
avg_train_sample_per_sec: 16.830182006282083
avg_episode_per_sec: 0.14508777591622485
collect_time: 41.354276486149054
reward_mean: -103.11846405228759
reward_std: 1.8687143032501563
reward_max: -99.92436974789916
reward_min: -105.42436974789916
queue_len: 0.06838094433175569
wait_time: 0.6459120451894286
delay_time: 4.368721657738296
pressure: 0.8405172413793104
total_envstep_count: 894360
total_train_sample_count: 894360
total_episode_count: 7710
total_duration: 53363.94285767178
[2024-12-28 02:59:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.531301022203273
avg_train_sample_per_sec: 16.531301022203273
avg_episode_per_sec: 0.14251121570864891
collect_time: 42.10194945123792
reward_mean: -105.14320728291314
reward_std: 3.447694695921292
reward_max: -100.73459383753503
reward_min: -110.31512605042013
queue_len: 0.0697236122565737
wait_time: 0.6600513105330549
delay_time: 4.403754790285451
pressure: 0.8569849690539345
total_envstep_count: 895056
total_train_sample_count: 895056
total_episode_count: 7716
total_duration: 53406.04480712301
[2024-12-28 02:59:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.71573520926204
avg_train_sample_per_sec: 16.71573520926204
avg_episode_per_sec: 0.14410116559708655
collect_time: 41.6374147644043
reward_mean: -104.19456115779646
reward_std: 2.2989098390939597
reward_max: -100.1015406162465
reward_min: -107.25910364145656
queue_len: 0.06909453657678809
wait_time: 0.6542962896918273
delay_time: 4.3800505939914745
pressure: 0.8464854111405834
total_envstep_count: 895752
total_train_sample_count: 895752
total_episode_count: 7722
total_duration: 53447.682221887415
[2024-12-28 03:00:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.88375696401937
avg_train_sample_per_sec: 16.88375696401937
avg_episode_per_sec: 0.14554962900016696
collect_time: 41.22305251628719
reward_mean: -102.78454715219424
reward_std: 1.6992255513094132
reward_max: -100.0357142857143
reward_min: -104.6687675070028
queue_len: 0.06815951402665399
wait_time: 0.6484172802631221
delay_time: 4.316555236034184
pressure: 0.8366489832007074
total_envstep_count: 896448
total_train_sample_count: 896448
total_episode_count: 7728
total_duration: 53488.9052744037
[2024-12-28 03:01:13][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.009066117610498
avg_train_sample_per_sec: 17.009066117610498
avg_episode_per_sec: 0.1466298803242284
collect_time: 40.91935413663833
reward_mean: -102.47572362278247
reward_std: 2.3033832289561644
reward_max: -99.76120448179275
reward_min: -106.44887955182072
queue_len: 0.06795472388778677
wait_time: 0.6405197799721126
delay_time: 4.306644147768829
pressure: 0.8333333333333334
total_envstep_count: 897144
total_train_sample_count: 897144
total_episode_count: 7734
total_duration: 53529.824628540344
[2024-12-28 03:01:55][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.83276991002159
avg_train_sample_per_sec: 16.83276991002159
avg_episode_per_sec: 0.14511008543122061
collect_time: 41.34791859690473
reward_mean: -103.40802987861814
reward_std: 2.0035768963451086
reward_max: -100.47268907563026
reward_min: -106.72478991596635
queue_len: 0.06857296411048946
wait_time: 0.6474521506215217
delay_time: 4.3819287214599125
pressure: 0.8387488947833776
total_envstep_count: 897840
total_train_sample_count: 897840
total_episode_count: 7740
total_duration: 53571.17254713725
[2024-12-28 03:02:37][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.7176244796286
avg_train_sample_per_sec: 16.7176244796286
avg_episode_per_sec: 0.14411745241059137
collect_time: 41.632709291210396
reward_mean: -103.8876050420168
reward_std: 1.9914960406140614
reward_max: -100.04271708683471
reward_min: -106.42436974789916
queue_len: 0.06889098477587322
wait_time: 0.656524833629296
delay_time: 4.361723415851768
pressure: 0.8430592396109637
total_envstep_count: 898536
total_train_sample_count: 898536
total_episode_count: 7746
total_duration: 53612.80525642846
[2024-12-28 03:03:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.094768731709046
avg_train_sample_per_sec: 17.094768731709046
avg_episode_per_sec: 0.14736869596300903
collect_time: 40.71420976342261
reward_mean: -104.50035014005601
reward_std: 2.481587496955622
reward_max: -102.45378151260503
reward_min: -109.89635854341738
queue_len: 0.06929731441648278
wait_time: 0.6563325042660743
delay_time: 4.336934376763725
pressure: 0.8598585322723253
total_envstep_count: 899232
total_train_sample_count: 899232
total_episode_count: 7752
total_duration: 53653.51946619188
[2024-12-28 03:04:00][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.018077043512594
avg_train_sample_per_sec: 17.018077043512594
avg_episode_per_sec: 0.14670756071993618
collect_time: 40.89768768941611
reward_mean: -100.7909663865546
reward_std: 1.6246014005418288
reward_max: -98.28991596638652
reward_min: -102.88865546218486
queue_len: 0.06683751086641553
wait_time: 0.6316896564107518
delay_time: 4.19931882987841
pressure: 0.8184129089301503
total_envstep_count: 899928
total_train_sample_count: 899928
total_episode_count: 7758
total_duration: 53694.417153881295
[2024-12-28 03:04:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.774254176188276
avg_train_sample_per_sec: 16.774254176188276
avg_episode_per_sec: 0.14460563944989893
collect_time: 41.49215772514046
reward_mean: -105.16538281979457
reward_std: 2.7244856048777963
reward_max: -101.45098039215684
reward_min: -109.91946778711485
queue_len: 0.06973831751975768
wait_time: 0.6653945840051317
delay_time: 4.422064150078408
pressure: 0.8548850574712642
total_envstep_count: 900624
total_train_sample_count: 900624
total_episode_count: 7764
total_duration: 53735.90931160643
[2024-12-28 03:05:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.734330592506584
avg_train_sample_per_sec: 16.734330592506584
avg_episode_per_sec: 0.14426147062505676
collect_time: 41.59114678370581
reward_mean: -102.25828664799253
reward_std: 2.7059413558711425
reward_max: -97.80532212885153
reward_min: -106.38445378151262
queue_len: 0.06781053491246189
wait_time: 0.6399211209682811
delay_time: 4.329141091607685
pressure: 0.831343943412909
total_envstep_count: 901320
total_train_sample_count: 901320
total_episode_count: 7770
total_duration: 53777.50045839014
[2024-12-28 03:06:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.888498996310698
avg_train_sample_per_sec: 16.888498996310698
avg_episode_per_sec: 0.1455905085888853
collect_time: 41.211477713445205
reward_mean: -100.33531746031743
reward_std: 1.8974686080025052
reward_max: -98.10084033613441
reward_min: -104.1428571428571
queue_len: 0.06653535640604603
wait_time: 0.6298252612273911
delay_time: 4.185697533290515
pressure: 0.8167550839964632
total_envstep_count: 902016
total_train_sample_count: 902016
total_episode_count: 7776
total_duration: 53818.71193610359
[2024-12-28 03:06:48][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.746126178673162
avg_train_sample_per_sec: 16.746126178673162
avg_episode_per_sec: 0.14436315671269967
collect_time: 41.561850936390464
reward_mean: -103.35387488328665
reward_std: 3.7789839140760293
reward_max: -96.43137254901961
reward_min: -107.58263305322129
queue_len: 0.06853705230987178
wait_time: 0.6544654776145648
delay_time: 4.2916041714118265
pressure: 0.8480327144120247
total_envstep_count: 902712
total_train_sample_count: 902712
total_episode_count: 7782
total_duration: 53860.27378703998
[2024-12-28 03:07:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.996268569320957
avg_train_sample_per_sec: 16.996268569320957
avg_episode_per_sec: 0.14651955663207722
collect_time: 40.95016486479343
reward_mean: -103.78886554621847
reward_std: 2.5039279229622253
reward_max: -100.88445378151258
reward_min: -107.37535014005601
queue_len: 0.06882550765664355
wait_time: 0.6526335114063309
delay_time: 4.349952163061302
pressure: 0.839080459770115
total_envstep_count: 903408
total_train_sample_count: 903408
total_episode_count: 7788
total_duration: 53901.22395190477
[2024-12-28 03:08:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.90771354489439
avg_train_sample_per_sec: 16.90771354489439
avg_episode_per_sec: 0.14575615124908955
collect_time: 41.164643471864984
reward_mean: -105.32177871148461
reward_std: 2.483740932010731
reward_max: -101.26820728291317
reward_min: -108.91176470588239
queue_len: 0.06984202832326565
wait_time: 0.6672677249502806
delay_time: 4.367669719831518
pressure: 0.8535587975243147
total_envstep_count: 904104
total_train_sample_count: 904104
total_episode_count: 7794
total_duration: 53942.38859537664
[2024-12-28 03:08:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.95593957069257
avg_train_sample_per_sec: 16.95593957069257
avg_episode_per_sec: 0.14617189285079804
collect_time: 41.04756313256733
reward_mean: -106.51458916900094
reward_std: 2.3376405856899796
reward_max: -101.78431372549022
reward_min: -109.00070028011204
queue_len: 0.07063301669031893
wait_time: 0.6704616307177158
delay_time: 4.447372489734821
pressure: 0.8723474801061007
total_envstep_count: 904800
total_train_sample_count: 904800
total_episode_count: 7800
total_duration: 53983.436158509205
[2024-12-28 03:09:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.97563280669125
avg_train_sample_per_sec: 16.97563280669125
avg_episode_per_sec: 0.14634166212664873
collect_time: 40.99994432759284
reward_mean: -103.98202614379085
reward_std: 1.4033773410870334
reward_max: -101.12675070028014
reward_min: -105.75000000000003
queue_len: 0.06895359823858808
wait_time: 0.6441243495629907
delay_time: 4.364834628712393
pressure: 0.8417329796640142
total_envstep_count: 905496
total_train_sample_count: 905496
total_episode_count: 7806
total_duration: 54024.4361028368
[2024-12-28 03:10:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.927990272206323
avg_train_sample_per_sec: 16.927990272206323
avg_episode_per_sec: 0.1459309506224683
collect_time: 41.115335536478085
reward_mean: -101.65394491129784
reward_std: 2.9327030864347505
reward_max: -95.88235294117644
reward_min: -104.47128851540616
queue_len: 0.06740977779263783
wait_time: 0.635662863730815
delay_time: 4.2776239722417975
pressure: 0.8293545534924845
total_envstep_count: 906192
total_train_sample_count: 906192
total_episode_count: 7812
total_duration: 54065.55143837328
[2024-12-28 03:10:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.865169037645938
avg_train_sample_per_sec: 16.865169037645938
avg_episode_per_sec: 0.14538938825556844
collect_time: 41.2684864555113
reward_mean: -103.33975256769372
reward_std: 2.110461180055732
reward_max: -99.64075630252097
reward_min: -106.60154061624652
queue_len: 0.06852768737910725
wait_time: 0.6510622927331853
delay_time: 4.314488595826695
pressure: 0.8431697612732095
total_envstep_count: 906888
total_train_sample_count: 906888
total_episode_count: 7818
total_duration: 54106.81992482879
[2024-12-28 03:11:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.923494748516106
avg_train_sample_per_sec: 16.923494748516106
avg_episode_per_sec: 0.14589219610789744
collect_time: 41.1262573329322
reward_mean: -102.87079831932772
reward_std: 2.5428878840657134
reward_max: -99.7317927170868
reward_min: -107.27100840336135
queue_len: 0.0682167097608274
wait_time: 0.6491676356661146
delay_time: 4.287333310051685
pressure: 0.8415119363395226
total_envstep_count: 907584
total_train_sample_count: 907584
total_episode_count: 7824
total_duration: 54147.94618216172
[2024-12-28 03:12:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.780071972437945
avg_train_sample_per_sec: 16.780071972437945
avg_episode_per_sec: 0.14465579286584437
collect_time: 41.477772034781054
reward_mean: -102.45529878618113
reward_std: 3.185931005602883
reward_max: -99.24579831932773
reward_min: -108.48599439775907
queue_len: 0.06794117956643311
wait_time: 0.6437806333850958
delay_time: 4.265347879460626
pressure: 0.8299071618037135
total_envstep_count: 908280
total_train_sample_count: 908280
total_episode_count: 7830
total_duration: 54189.4239541965
[2024-12-28 03:13:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.007442869766674
avg_train_sample_per_sec: 17.007442869766674
avg_episode_per_sec: 0.1466158868083334
collect_time: 40.92325961813144
reward_mean: -105.02450980392159
reward_std: 2.267922562297158
reward_max: -103.03991596638659
reward_min: -109.59803921568627
queue_len: 0.0696449004004785
wait_time: 0.6632504018406655
delay_time: 4.367325230262314
pressure: 0.8604111405835543
total_envstep_count: 908976
total_train_sample_count: 908976
total_episode_count: 7836
total_duration: 54230.34721381463
[2024-12-28 03:13:46][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27591591401956
avg_train_sample_per_sec: 17.27591591401956
avg_episode_per_sec: 0.1489303096036169
collect_time: 40.28729958306811
reward_mean: -102.59442110177405
reward_std: 2.629493709476928
reward_max: -98.41456582633056
reward_min: -106.49299719887954
queue_len: 0.06803343574388199
wait_time: 0.6435789390911095
delay_time: 4.32170757181454
pressure: 0.8306808134394341
total_envstep_count: 909672
total_train_sample_count: 909672
total_episode_count: 7842
total_duration: 54270.6345133977
[2024-12-28 03:14:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.853141222343233
avg_train_sample_per_sec: 16.853141222343233
avg_episode_per_sec: 0.14528570019261408
collect_time: 41.29793910925463
reward_mean: -102.79948646125115
reward_std: 4.667598015400816
reward_max: -97.66736694677867
reward_min: -109.9607843137255
queue_len: 0.06816942073027264
wait_time: 0.6484574488504508
delay_time: 4.28542210243694
pressure: 0.8388594164456235
total_envstep_count: 910368
total_train_sample_count: 910368
total_episode_count: 7848
total_duration: 54311.93245250695
[2024-12-28 03:15:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.036995050925427
avg_train_sample_per_sec: 17.036995050925427
avg_episode_per_sec: 0.14687064699073646
collect_time: 40.85227458947898
reward_mean: -104.0031512605042
reward_std: 3.136124656505948
reward_max: -99.49929971988793
reward_min: -108.18417366946782
queue_len: 0.06896760693667388
wait_time: 0.6559775656504866
delay_time: 4.331516686652718
pressure: 0.8478116710875332
total_envstep_count: 911064
total_train_sample_count: 911064
total_episode_count: 7854
total_duration: 54352.784727096434
[2024-12-28 03:15:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.684515333577984
avg_train_sample_per_sec: 16.684515333577984
avg_episode_per_sec: 0.14383202873774123
collect_time: 41.71532622222975
reward_mean: -103.73529411764707
reward_std: 2.8696451679258796
reward_max: -100.06862745098043
reward_min: -107.53641456582632
queue_len: 0.06878998283663598
wait_time: 0.6539478523504892
delay_time: 4.326121793782827
pressure: 0.8494694960212202
total_envstep_count: 911760
total_train_sample_count: 911760
total_episode_count: 7860
total_duration: 54394.50005331866
[2024-12-28 03:16:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76346079067724
avg_train_sample_per_sec: 16.76346079067724
avg_episode_per_sec: 0.14451259302307964
collect_time: 41.51887302334793
reward_mean: -103.88982259570496
reward_std: 1.6997483614404765
reward_max: -100.77030812324927
reward_min: -106.47759103641457
queue_len: 0.06889245530219161
wait_time: 0.6551401396102208
delay_time: 4.397089175432539
pressure: 0.8452696728558796
total_envstep_count: 912456
total_train_sample_count: 912456
total_episode_count: 7866
total_duration: 54436.01892634201
[2024-12-28 03:17:16][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.723910546362422
avg_train_sample_per_sec: 16.723910546362422
avg_episode_per_sec: 0.14417164264105536
collect_time: 41.61706067911164
reward_mean: -103.17927170868347
reward_std: 1.3649942622670495
reward_max: -101.4558823529412
reward_min: -105.3921568627451
queue_len: 0.06842126771132856
wait_time: 0.6514258223183172
delay_time: 4.327264595983171
pressure: 0.8422855879752432
total_envstep_count: 913152
total_train_sample_count: 913152
total_episode_count: 7872
total_duration: 54477.63598702112
[2024-12-28 03:17:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.46577001268506
avg_train_sample_per_sec: 16.46577001268506
avg_episode_per_sec: 0.14194629321280222
collect_time: 42.26950816535205
reward_mean: -107.37733426704015
reward_std: 1.6744409369745759
reward_max: -104.21008403361346
reward_min: -109.08333333333333
queue_len: 0.07120512882429718
wait_time: 0.6803295588792547
delay_time: 4.477129889249668
pressure: 0.866710875331565
total_envstep_count: 913848
total_train_sample_count: 913848
total_episode_count: 7878
total_duration: 54519.905495186475
[2024-12-28 03:18:41][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.855412468113652
avg_train_sample_per_sec: 16.855412468113652
avg_episode_per_sec: 0.1453052798975315
collect_time: 41.29237426355854
reward_mean: -103.23354341736695
reward_std: 2.0066483436229157
reward_max: -99.25630252100841
reward_min: -105.46358543417362
queue_len: 0.06845725690806827
wait_time: 0.6512382141185385
delay_time: 4.244356003688908
pressure: 0.8415119363395225
total_envstep_count: 914544
total_train_sample_count: 914544
total_episode_count: 7884
total_duration: 54561.197869450036
[2024-12-28 03:19:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.619946290377598
avg_train_sample_per_sec: 16.619946290377598
avg_episode_per_sec: 0.1432753990549793
collect_time: 41.877391649752866
reward_mean: -101.4090802987862
reward_std: 2.2245716294922064
reward_max: -99.39635854341742
reward_min: -105.34733893557421
queue_len: 0.06724740072863807
wait_time: 0.6357098431768817
delay_time: 4.250622652022884
pressure: 0.8263704686118479
total_envstep_count: 915240
total_train_sample_count: 915240
total_episode_count: 7890
total_duration: 54603.07526109979
[2024-12-28 03:20:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.792246985530866
avg_train_sample_per_sec: 16.792246985530866
avg_episode_per_sec: 0.14476074987526608
collect_time: 41.44769908397085
reward_mean: -102.61181139122311
reward_std: 4.3533188199118795
reward_max: -95.7443977591036
reward_min: -110.39845938375349
queue_len: 0.06804496776606309
wait_time: 0.6440611169312995
delay_time: 4.271901337367585
pressure: 0.8383068081343943
total_envstep_count: 915936
total_train_sample_count: 915936
total_episode_count: 7896
total_duration: 54644.52296018376
[2024-12-28 03:20:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.068292495865663
avg_train_sample_per_sec: 17.068292495865663
avg_episode_per_sec: 0.14714045255056607
collect_time: 40.77736540831998
reward_mean: -103.60539215686275
reward_std: 2.352295543215394
reward_max: -101.18277310924367
reward_min: -108.60294117647058
queue_len: 0.06870384095282676
wait_time: 0.650668269075977
delay_time: 4.313848698091631
pressure: 0.8459328028293545
total_envstep_count: 916632
total_train_sample_count: 916632
total_episode_count: 7902
total_duration: 54685.30032559208
[2024-12-28 03:21:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.977547143918088
avg_train_sample_per_sec: 16.977547143918088
avg_episode_per_sec: 0.1463581650337766
collect_time: 40.995321297006676
reward_mean: -104.9968487394958
reward_std: 2.563277462738826
reward_max: -102.69817927170868
reward_min: -109.73319327731092
queue_len: 0.06962655751955955
wait_time: 0.6679564730401445
delay_time: 4.34031282791018
pressure: 0.8680371352785147
total_envstep_count: 917328
total_train_sample_count: 917328
total_episode_count: 7908
total_duration: 54726.295646889084
[2024-12-28 03:22:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.799826952039442
avg_train_sample_per_sec: 16.799826952039442
avg_episode_per_sec: 0.14482609441413313
collect_time: 41.428998166883375
reward_mean: -105.0716619981326
reward_std: 1.91732345230309
reward_max: -101.3165266106443
reward_min: -107.38515406162468
queue_len: 0.06967616843377494
wait_time: 0.6591076970133766
delay_time: 4.376520749907728
pressure: 0.8555481874447391
total_envstep_count: 918024
total_train_sample_count: 918024
total_episode_count: 7914
total_duration: 54767.72464505597
[2024-12-28 03:22:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.624774666086896
avg_train_sample_per_sec: 16.624774666086896
avg_episode_per_sec: 0.1433170229835077
collect_time: 41.86522909208387
reward_mean: -105.70623249299722
reward_std: 2.38918599393685
reward_max: -101.48529411764707
reward_min: -109.05252100840337
queue_len: 0.07009697114920241
wait_time: 0.6653045723152213
delay_time: 4.412107833038076
pressure: 0.8614058355437665
total_envstep_count: 918720
total_train_sample_count: 918720
total_episode_count: 7920
total_duration: 54809.589874148056
[2024-12-28 03:23:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.01290229614949
avg_train_sample_per_sec: 17.01290229614949
avg_episode_per_sec: 0.14666295082887493
collect_time: 40.91012737770937
reward_mean: -104.40499533146591
reward_std: 1.5461935728404035
reward_max: -101.73669467787117
reward_min: -106.19607843137254
queue_len: 0.06923408178479172
wait_time: 0.6520984720148005
delay_time: 4.400375191442299
pressure: 0.8488063660477455
total_envstep_count: 919416
total_train_sample_count: 919416
total_episode_count: 7926
total_duration: 54850.50000152577
[2024-12-28 03:24:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.949061003320956
avg_train_sample_per_sec: 16.949061003320956
avg_episode_per_sec: 0.14611259485621517
collect_time: 41.06422177981585
reward_mean: -101.79960317460318
reward_std: 4.069873248941126
reward_max: -97.51120448179272
reward_min: -109.937675070028
queue_len: 0.06750636815291988
wait_time: 0.6460571629182178
delay_time: 4.262055161959374
pressure: 0.8317860300618921
total_envstep_count: 920112
total_train_sample_count: 920112
total_episode_count: 7932
total_duration: 54891.564223305584
[2024-12-28 03:24:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.6744573147419
avg_train_sample_per_sec: 16.6744573147419
avg_episode_per_sec: 0.1437453216788095
collect_time: 41.7404888724424
reward_mean: -102.68382352941177
reward_std: 2.929802764890587
reward_max: -99.44187675070027
reward_min: -107.69747899159665
queue_len: 0.06809272117334998
wait_time: 0.6478700122843125
delay_time: 4.313375046674639
pressure: 0.8395225464190982
total_envstep_count: 920808
total_train_sample_count: 920808
total_episode_count: 7938
total_duration: 54933.304712178026
[2024-12-28 03:25:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.641238185756478
avg_train_sample_per_sec: 16.641238185756478
avg_episode_per_sec: 0.14345894987721103
collect_time: 41.823810958713295
reward_mean: -102.53781512605043
reward_std: 1.3831118426513351
reward_max: -100.42717086834736
reward_min: -104.42016806722695
queue_len: 0.06799589862470189
wait_time: 0.6424741868453836
delay_time: 4.293130538275926
pressure: 0.841290893015031
total_envstep_count: 921504
total_train_sample_count: 921504
total_episode_count: 7944
total_duration: 54975.12852313674
[2024-12-28 03:26:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.65111747210144
avg_train_sample_per_sec: 16.65111747210144
avg_episode_per_sec: 0.14354411613880552
collect_time: 41.798996443700055
reward_mean: -103.23237628384688
reward_std: 3.819252583917192
reward_max: -96.44187675070032
reward_min: -108.56512605042016
queue_len: 0.06845648294684807
wait_time: 0.6564808726319881
delay_time: 4.287016049958763
pressure: 0.8468169761273211
total_envstep_count: 922200
total_train_sample_count: 922200
total_episode_count: 7950
total_duration: 55016.92751958044
[2024-12-28 03:27:06][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.65985149414305
avg_train_sample_per_sec: 16.65985149414305
avg_episode_per_sec: 0.14361940943226767
collect_time: 41.77708308172412
reward_mean: -102.65569561157798
reward_std: 1.60988791291538
reward_max: -100.37885154061622
reward_min: -104.41876750700278
queue_len: 0.06807406870794296
wait_time: 0.6493954898493438
delay_time: 4.311948886919098
pressure: 0.837312113174182
total_envstep_count: 922896
total_train_sample_count: 922896
total_episode_count: 7956
total_duration: 55058.70460266216
[2024-12-28 03:27:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.76349056073017
avg_train_sample_per_sec: 16.76349056073017
avg_episode_per_sec: 0.14451284966146696
collect_time: 41.518799290550874
reward_mean: -104.12184873949582
reward_std: 2.40098683000307
reward_max: -100.87254901960785
reward_min: -107.44397759103639
queue_len: 0.06904631879276911
wait_time: 0.6591067682599122
delay_time: 4.316907471619685
pressure: 0.8483642793987624
total_envstep_count: 923592
total_train_sample_count: 923592
total_episode_count: 7962
total_duration: 55100.22340195271
[2024-12-28 03:28:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.2891506844952
avg_train_sample_per_sec: 17.2891506844952
avg_episode_per_sec: 0.14904440245254486
collect_time: 40.256459828542546
reward_mean: -101.76237161531277
reward_std: 1.9629110392996059
reward_max: -99.79761904761904
reward_min: -105.62114845938372
queue_len: 0.06748167878999521
wait_time: 0.6406817700555022
delay_time: 4.279395087901045
pressure: 0.8263704686118479
total_envstep_count: 924288
total_train_sample_count: 924288
total_episode_count: 7968
total_duration: 55140.47986178125
[2024-12-28 03:29:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.84602179068628
avg_train_sample_per_sec: 17.84602179068628
avg_episode_per_sec: 0.1538450154369507
collect_time: 39.00028858886846
reward_mean: -102.75373482726424
reward_std: 2.7466203591406004
reward_max: -99.96568627450984
reward_min: -107.05742296918768
queue_len: 0.06813908145044048
wait_time: 0.6530888327921797
delay_time: 4.307297852563697
pressure: 0.8375331564986738
total_envstep_count: 924984
total_train_sample_count: 924984
total_episode_count: 7974
total_duration: 55179.48015037012
[2024-12-28 03:29:50][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.160544374361887
avg_train_sample_per_sec: 17.160544374361887
avg_episode_per_sec: 0.14793572736518867
collect_time: 40.558153914967555
reward_mean: -103.74521475256769
reward_std: 1.555581830724759
reward_max: -100.7983193277311
reward_min: -106.00280112044818
queue_len: 0.06879656150700776
wait_time: 0.6554354832118524
delay_time: 4.321900990854625
pressure: 0.8542219274977896
total_envstep_count: 925680
total_train_sample_count: 925680
total_episode_count: 7980
total_duration: 55220.03830428508
[2024-12-28 03:30:31][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.403803878701968
avg_train_sample_per_sec: 17.403803878701968
avg_episode_per_sec: 0.1500327920577756
collect_time: 39.99125736252033
reward_mean: -104.83975256769374
reward_std: 2.101747758301539
reward_max: -102.859243697479
reward_min: -109.22619047619048
queue_len: 0.06952238233931946
wait_time: 0.6646783602919506
delay_time: 4.366815131580361
pressure: 0.8582007073386384
total_envstep_count: 926376
total_train_sample_count: 926376
total_episode_count: 7986
total_duration: 55260.0295616476
[2024-12-28 03:31:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.2211299951414
avg_train_sample_per_sec: 17.2211299951414
avg_episode_per_sec: 0.14845801719949483
collect_time: 40.41546636001021
reward_mean: -105.87896825396827
reward_std: 2.7191062004353976
reward_max: -101.63305322128846
reward_min: -109.50490196078434
queue_len: 0.07021151740979327
wait_time: 0.6728627680072913
delay_time: 4.475601046747645
pressure: 0.8701370468611848
total_envstep_count: 927072
total_train_sample_count: 927072
total_episode_count: 7992
total_duration: 55300.44502800761
[2024-12-28 03:31:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.493622381762716
avg_train_sample_per_sec: 17.493622381762716
avg_episode_per_sec: 0.15080708949795443
collect_time: 39.78592796913161
reward_mean: -101.72443977591037
reward_std: 1.530626979206616
reward_max: -98.47689075630257
reward_min: -103.04481792717084
queue_len: 0.06745652505033845
wait_time: 0.6441217954909638
delay_time: 4.260545148032219
pressure: 0.8345490716180372
total_envstep_count: 927768
total_train_sample_count: 927768
total_episode_count: 7998
total_duration: 55340.230955976745
[2024-12-28 03:32:34][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.215718187051987
avg_train_sample_per_sec: 17.215718187051987
avg_episode_per_sec: 0.14841136368148264
collect_time: 40.42817107237876
reward_mean: -106.35422502334266
reward_std: 3.421762525131115
reward_max: -101.32913165266102
reward_min: -110.25560224089638
queue_len: 0.07052667441866224
wait_time: 0.674222772663442
delay_time: 4.389192231863455
pressure: 0.8670424403183024
total_envstep_count: 928464
total_train_sample_count: 928464
total_episode_count: 8004
total_duration: 55380.659127049126
[2024-12-28 03:33:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.27858871599823
avg_train_sample_per_sec: 17.27858871599823
avg_episode_per_sec: 0.14895335099998475
collect_time: 40.281067594112834
reward_mean: -101.60189075630255
reward_std: 2.0862514674867403
reward_max: -98.54201680672269
reward_min: -104.98039215686275
queue_len: 0.06737525912221654
wait_time: 0.6395291870063674
delay_time: 4.25698563241901
pressure: 0.8299071618037135
total_envstep_count: 929160
total_train_sample_count: 929160
total_episode_count: 8010
total_duration: 55420.94019464324
[2024-12-28 03:33:56][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.256396026653007
avg_train_sample_per_sec: 17.256396026653007
avg_episode_per_sec: 0.14876203471252591
collect_time: 40.33287129740229
reward_mean: -103.22105508870214
reward_std: 1.7569016993601543
reward_max: -100.80392156862744
reward_min: -105.3529411764706
queue_len: 0.06844897552301203
wait_time: 0.6482257248611203
delay_time: 4.361763364072771
pressure: 0.8417329796640142
total_envstep_count: 929856
total_train_sample_count: 929856
total_episode_count: 8016
total_duration: 55461.273065940644
[2024-12-28 03:34:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.42148406755604
avg_train_sample_per_sec: 17.42148406755604
avg_episode_per_sec: 0.15018520747893138
collect_time: 39.950672244746244
reward_mean: -105.77345938375349
reward_std: 2.4353796800931167
reward_max: -101.7471988795518
reward_min: -108.86064425770306
queue_len: 0.0701415513154864
wait_time: 0.6664411343670978
delay_time: 4.407251578819683
pressure: 0.8586427939876216
total_envstep_count: 930552
total_train_sample_count: 930552
total_episode_count: 8022
total_duration: 55501.22373818539
[2024-12-28 03:35:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.444508312406995
avg_train_sample_per_sec: 17.444508312406995
avg_episode_per_sec: 0.15038369234833618
collect_time: 39.89794309679605
reward_mean: -105.62523342670403
reward_std: 2.5770694548322943
reward_max: -102.2415966386555
reward_min: -109.14425770308122
queue_len: 0.07004325824051992
wait_time: 0.67155214207699
delay_time: 4.374512414812544
pressure: 0.8647214854111406
total_envstep_count: 931248
total_train_sample_count: 931248
total_episode_count: 8028
total_duration: 55541.12168128219
[2024-12-28 03:35:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.3985463126283
avg_train_sample_per_sec: 17.3985463126283
avg_episode_per_sec: 0.14998746821231293
collect_time: 40.00334208926557
reward_mean: -101.16514939309057
reward_std: 3.248603073176169
reward_max: -97.36484593837534
reward_min: -107.77310924369746
queue_len: 0.06708564283361444
wait_time: 0.6344807153630683
delay_time: 4.257917199931163
pressure: 0.8229442970822282
total_envstep_count: 931944
total_train_sample_count: 931944
total_episode_count: 8034
total_duration: 55581.12502337145
[2024-12-28 03:36:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.357722453808815
avg_train_sample_per_sec: 17.357722453808815
avg_episode_per_sec: 0.1496355383949036
collect_time: 40.09742648277432
reward_mean: -104.26575630252103
reward_std: 4.131295478040579
reward_max: -100.65546218487393
reward_min: -112.81232492997202
queue_len: 0.06914174821122084
wait_time: 0.6571897437135773
delay_time: 4.385807699195849
pressure: 0.8512378426171529
total_envstep_count: 932640
total_train_sample_count: 932640
total_episode_count: 8040
total_duration: 55621.22244985423
[2024-12-28 03:37:19][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.542057613900596
avg_train_sample_per_sec: 17.542057613900596
avg_episode_per_sec: 0.15122463460259136
collect_time: 39.67607536806166
reward_mean: -103.50700280112044
reward_std: 2.6779212334017446
reward_max: -97.96638655462182
reward_min: -106.20028011204482
queue_len: 0.06863859602196315
wait_time: 0.6551899053166802
delay_time: 4.361575491525142
pressure: 0.8442749778956676
total_envstep_count: 933336
total_train_sample_count: 933336
total_episode_count: 8046
total_duration: 55660.89852522229
[2024-12-28 03:37:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.465130785668016
avg_train_sample_per_sec: 17.465130785668016
avg_episode_per_sec: 0.15056147229024153
collect_time: 39.85083241238259
reward_mean: -104.10154061624648
reward_std: 2.6528733152483603
reward_max: -99.74439775910362
reward_min: -106.86974789915965
queue_len: 0.06903285186753746
wait_time: 0.6524082886912501
delay_time: 4.350550265749895
pressure: 0.8409593280282935
total_envstep_count: 934032
total_train_sample_count: 934032
total_episode_count: 8052
total_duration: 55700.749357634675
[2024-12-28 03:38:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.36891173247842
avg_train_sample_per_sec: 17.36891173247842
avg_episode_per_sec: 0.14973199769377948
collect_time: 40.07159519951603
reward_mean: -105.70191409897292
reward_std: 1.4886939349647814
reward_max: -103.19817927170871
reward_min: -107.27240896358545
queue_len: 0.07009410749268762
wait_time: 0.6684676744260921
delay_time: 4.342954664604098
pressure: 0.866158267020336
total_envstep_count: 934728
total_train_sample_count: 934728
total_episode_count: 8058
total_duration: 55740.82095283419
[2024-12-28 03:39:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.232020862531208
avg_train_sample_per_sec: 17.232020862531208
avg_episode_per_sec: 0.148551903987338
collect_time: 40.38992324535549
reward_mean: -104.2998366013072
reward_std: 2.440876781342615
reward_max: -101.30252100840337
reward_min: -108.47408963585431
queue_len: 0.06916434787885094
wait_time: 0.6594383332466497
delay_time: 4.3666805672977995
pressure: 0.842948717948718
total_envstep_count: 935424
total_train_sample_count: 935424
total_episode_count: 8064
total_duration: 55781.210876079545
[2024-12-28 03:40:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40126180783708
avg_train_sample_per_sec: 17.40126180783708
avg_episode_per_sec: 0.15001087765376792
collect_time: 39.997099502665925
reward_mean: -102.9089635854342
reward_std: 3.52597341429047
reward_max: -97.58893557422967
reward_min: -108.55252100840336
queue_len: 0.06824201829272823
wait_time: 0.6495868904591015
delay_time: 4.274559167219851
pressure: 0.8452696728558796
total_envstep_count: 936120
total_train_sample_count: 936120
total_episode_count: 8070
total_duration: 55821.20797558221
[2024-12-28 03:40:42][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.348834882810156
avg_train_sample_per_sec: 17.348834882810156
avg_episode_per_sec: 0.14955892140353583
collect_time: 40.11796784633772
reward_mean: -103.95133053221286
reward_std: 1.5467558014054528
reward_max: -101.83193277310927
reward_min: -106.14635854341736
queue_len: 0.06893324305849662
wait_time: 0.6583807926353563
delay_time: 4.332769987769562
pressure: 0.8549955791335102
total_envstep_count: 936816
total_train_sample_count: 936816
total_episode_count: 8076
total_duration: 55861.32594342855
[2024-12-28 03:41:23][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.498109422548335
avg_train_sample_per_sec: 17.498109422548335
avg_episode_per_sec: 0.1508457708840374
collect_time: 39.77572566228918
reward_mean: -103.01388888888887
reward_std: 1.750789046146755
reward_max: -99.45168067226895
reward_min: -104.86834733893554
queue_len: 0.06831159740642499
wait_time: 0.6502951423717144
delay_time: 4.31344855678907
pressure: 0.8473695844385499
total_envstep_count: 937512
total_train_sample_count: 937512
total_episode_count: 8082
total_duration: 55901.10166909084
[2024-12-28 03:42:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.540005464288264
avg_train_sample_per_sec: 17.540005464288264
avg_episode_per_sec: 0.15120694365765744
collect_time: 39.68071739869565
reward_mean: -102.98190943043885
reward_std: 2.2738872505061716
reward_max: -98.56862745098036
reward_min: -105.92016806722685
queue_len: 0.06829039086899127
wait_time: 0.6485765614822411
delay_time: 4.286170328809464
pressure: 0.8405172413793104
total_envstep_count: 938208
total_train_sample_count: 938208
total_episode_count: 8088
total_duration: 55940.78238648953
[2024-12-28 03:42:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.548135649182488
avg_train_sample_per_sec: 17.548135649182488
avg_episode_per_sec: 0.15127703145846974
collect_time: 39.662333020113415
reward_mean: -103.83881886087768
reward_std: 3.268963204333774
reward_max: -98.50210084033608
reward_min: -107.48039215686279
queue_len: 0.06885863319686848
wait_time: 0.6545520064789841
delay_time: 4.382570765320472
pressure: 0.8491379310344827
total_envstep_count: 938904
total_train_sample_count: 938904
total_episode_count: 8094
total_duration: 55980.44471950964
[2024-12-28 03:43:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.385912710549935
avg_train_sample_per_sec: 17.385912710549935
avg_episode_per_sec: 0.14987855784956838
collect_time: 40.032410813707855
reward_mean: -103.83881886087768
reward_std: 2.7492747009224114
reward_max: -99.77941176470588
reward_min: -108.5280112044818
queue_len: 0.0688586331968685
wait_time: 0.6539664274197742
delay_time: 4.3778786954405335
pressure: 0.8469274977895668
total_envstep_count: 939600
total_train_sample_count: 939600
total_episode_count: 8100
total_duration: 56020.47713032335
[2024-12-28 03:44:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.753185702920874
avg_train_sample_per_sec: 17.753185702920874
avg_episode_per_sec: 0.15304470433552478
collect_time: 39.20423137834295
reward_mean: -102.15242763772176
reward_std: 4.615800350639005
reward_max: -95.49929971988794
reward_min: -109.20938375350143
queue_len: 0.06774033662978897
wait_time: 0.6485343031996176
delay_time: 4.349555858688815
pressure: 0.8288019451812555
total_envstep_count: 940296
total_train_sample_count: 940296
total_episode_count: 8106
total_duration: 56059.681361701696
[2024-12-28 03:44:45][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.386548467668838
avg_train_sample_per_sec: 17.386548467668838
avg_episode_per_sec: 0.14988403851438653
collect_time: 40.030946987221014
reward_mean: -103.24147992530345
reward_std: 2.575862539170376
reward_max: -99.87955182072828
reward_min: -108.01540616246498
queue_len: 0.06846251984436567
wait_time: 0.6509677920681978
delay_time: 4.304716152947545
pressure: 0.8451591511936339
total_envstep_count: 940992
total_train_sample_count: 940992
total_episode_count: 8112
total_duration: 56099.71230868892
[2024-12-28 03:45:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.756884963137292
avg_train_sample_per_sec: 17.756884963137292
avg_episode_per_sec: 0.15307659450980424
collect_time: 39.19606403064913
reward_mean: -101.69502801120449
reward_std: 3.423467206812292
reward_max: -96.96568627450978
reward_min: -108.28781512605042
queue_len: 0.06743702122758918
wait_time: 0.6431736929962082
delay_time: 4.258934654078354
pressure: 0.8281388152077808
total_envstep_count: 941688
total_train_sample_count: 941688
total_episode_count: 8118
total_duration: 56138.90837271957
[2024-12-28 03:46:05][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.40352684777227
avg_train_sample_per_sec: 17.40352684777227
avg_episode_per_sec: 0.15003040386010577
collect_time: 39.991893947007135
reward_mean: -100.98284313725492
reward_std: 2.0949249020547924
reward_max: -98.45238095238095
reward_min: -104.07072829131657
queue_len: 0.06696475009101784
wait_time: 0.6384807017413509
delay_time: 4.268516544819369
pressure: 0.8241600353669319
total_envstep_count: 942384
total_train_sample_count: 942384
total_episode_count: 8124
total_duration: 56178.90026666658
[2024-12-28 03:46:47][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.008245546267965
avg_train_sample_per_sec: 17.008245546267965
avg_episode_per_sec: 0.14662280643334452
collect_time: 40.921328311415394
reward_mean: -101.66024743230626
reward_std: 1.992618005033185
reward_max: -98.72198879551826
reward_min: -105.29971988795516
queue_len: 0.06741395718322696
wait_time: 0.6380749912697173
delay_time: 4.281662733478914
pressure: 0.8311229000884173
total_envstep_count: 943080
total_train_sample_count: 943080
total_episode_count: 8130
total_duration: 56219.82159497799
[2024-12-28 03:47:28][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.31183232284456
avg_train_sample_per_sec: 17.31183232284456
avg_episode_per_sec: 0.14923993381762551
collect_time: 40.203716569133114
reward_mean: -103.2950513538749
reward_std: 2.871194423200972
reward_max: -99.70518207282916
reward_min: -106.80812324929971
queue_len: 0.06849804466437327
wait_time: 0.6547153122964482
delay_time: 4.282337246054738
pressure: 0.8477011494252874
total_envstep_count: 943776
total_train_sample_count: 943776
total_episode_count: 8136
total_duration: 56260.02531154713
[2024-12-28 03:48:09][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.24264140072099
avg_train_sample_per_sec: 17.24264140072099
avg_episode_per_sec: 0.14864346035104303
collect_time: 40.36504522856325
reward_mean: -102.36041083099906
reward_std: 1.8076627409633432
reward_max: -99.4670868347339
reward_min: -104.7254901960784
queue_len: 0.06787825651923016
wait_time: 0.6482804439193891
delay_time: 4.24891757718983
pressure: 0.8347701149425287
total_envstep_count: 944472
total_train_sample_count: 944472
total_episode_count: 8142
total_duration: 56300.39035677569
[2024-12-28 03:48:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.388512073353635
avg_train_sample_per_sec: 17.388512073353635
avg_episode_per_sec: 0.1499009661496003
collect_time: 40.02642647420988
reward_mean: -102.64647525676939
reward_std: 2.418871729600489
reward_max: -99.41106442577032
reward_min: -106.09733893557421
queue_len: 0.0680679544143033
wait_time: 0.6493250593783049
delay_time: 4.32893794560751
pressure: 0.8388594164456235
total_envstep_count: 945168
total_train_sample_count: 945168
total_episode_count: 8148
total_duration: 56340.4167832499
[2024-12-28 03:49:30][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.30139590349391
avg_train_sample_per_sec: 17.30139590349391
avg_episode_per_sec: 0.14914996468529232
collect_time: 40.227967956010254
reward_mean: -103.76225490196077
reward_std: 4.360192145743216
reward_max: -99.67857142857144
reward_min: -112.78641456582633
queue_len: 0.0688078613408228
wait_time: 0.6512146083013223
delay_time: 4.2902708387566895
pressure: 0.8554376657824934
total_envstep_count: 945864
total_train_sample_count: 945864
total_episode_count: 8154
total_duration: 56380.64475120591
[2024-12-28 03:50:11][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.43558748693196
avg_train_sample_per_sec: 17.43558748693196
avg_episode_per_sec: 0.15030678868044792
collect_time: 39.91835666688345
reward_mean: -99.55578898225959
reward_std: 1.8355735772273778
reward_max: -97.47058823529409
reward_min: -103.22058823529412
queue_len: 0.06601842770706869
wait_time: 0.6275123555169196
delay_time: 4.1636724124707
pressure: 0.8093501326259948
total_envstep_count: 946560
total_train_sample_count: 946560
total_episode_count: 8160
total_duration: 56420.56310787279
[2024-12-28 03:50:52][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.242157543004513
avg_train_sample_per_sec: 17.242157543004513
avg_episode_per_sec: 0.148639289163832
collect_time: 40.36617797187343
reward_mean: -102.61659663865545
reward_std: 2.29582826181763
reward_max: -99.99509803921566
reward_min: -107.38305322128855
queue_len: 0.06804814100706597
wait_time: 0.6396537947628212
delay_time: 4.30763446432016
pressure: 0.8395225464190982
total_envstep_count: 947256
total_train_sample_count: 947256
total_episode_count: 8166
total_duration: 56460.929285844664
[2024-12-28 03:51:33][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.182153464556542
avg_train_sample_per_sec: 17.182153464556542
avg_episode_per_sec: 0.14812201262548744
collect_time: 40.50714605917781
reward_mean: -102.16690009337067
reward_std: 3.7599024530993335
reward_max: -98.04761904761905
reward_min: -108.34033613445376
queue_len: 0.06774993374891954
wait_time: 0.6459158375994075
delay_time: 4.322848599416028
pressure: 0.8332228116710875
total_envstep_count: 947952
total_train_sample_count: 947952
total_episode_count: 8172
total_duration: 56501.43643190384
[2024-12-28 03:52:14][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.42712103314991
avg_train_sample_per_sec: 17.42712103314991
avg_episode_per_sec: 0.150233802009913
collect_time: 39.937749825462696
reward_mean: -105.21650326797386
reward_std: 2.8916590336849866
reward_max: -101.89565826330532
reward_min: -109.81372549019609
queue_len: 0.06977221702120283
wait_time: 0.6574838489772566
delay_time: 4.32419856481546
pressure: 0.8579796640141467
total_envstep_count: 948648
total_train_sample_count: 948648
total_episode_count: 8178
total_duration: 56541.374181729305
[2024-12-28 03:52:54][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.66922924168753
avg_train_sample_per_sec: 17.66922924168753
avg_episode_per_sec: 0.15232094173868557
collect_time: 39.39051276542991
reward_mean: -103.46008403361344
reward_std: 4.660094829051079
reward_max: -95.828431372549
reward_min: -109.90056022408967
queue_len: 0.06860748278091078
wait_time: 0.6543938862016955
delay_time: 4.274814451725002
pressure: 0.8463748894783377
total_envstep_count: 949344
total_train_sample_count: 949344
total_episode_count: 8184
total_duration: 56580.764694494734
[2024-12-28 03:53:35][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.300679411252744
avg_train_sample_per_sec: 17.300679411252744
avg_episode_per_sec: 0.1491437880280409
collect_time: 40.22963396150247
reward_mean: -103.34173669467786
reward_std: 2.7737463193176337
reward_max: -99.70938375350141
reward_min: -107.6533613445378
queue_len: 0.06852900311318161
wait_time: 0.6521754037600894
delay_time: 4.255474443966763
pressure: 0.8431697612732094
total_envstep_count: 950040
total_train_sample_count: 950040
total_episode_count: 8190
total_duration: 56620.99432845624
[2024-12-28 03:54:15][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.260616590921956
avg_train_sample_per_sec: 17.260616590921956
avg_episode_per_sec: 0.14879841888725825
collect_time: 40.32300910768472
reward_mean: -103.02579365079363
reward_std: 3.9547843309365427
reward_max: -96.5924369747899
reward_min: -107.63235294117645
queue_len: 0.06831949181087112
wait_time: 0.6474904617019221
delay_time: 4.27890704215838
pressure: 0.8443854995579133
total_envstep_count: 950736
total_train_sample_count: 950736
total_episode_count: 8196
total_duration: 56661.31733756392
[2024-12-28 03:54:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.134246158369912
avg_train_sample_per_sec: 17.134246158369912
avg_episode_per_sec: 0.14770901860663718
collect_time: 40.62040393063985
reward_mean: -101.68078898225957
reward_std: 2.5966324363034166
reward_max: -98.390756302521
reward_min: -105.28711484593839
queue_len: 0.06742757890070263
wait_time: 0.6374301267810396
delay_time: 4.267644865007531
pressure: 0.8331122900088417
total_envstep_count: 951432
total_train_sample_count: 951432
total_episode_count: 8202
total_duration: 56701.93774149456
[2024-12-28 03:55:36][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.96248844019655
avg_train_sample_per_sec: 17.96248844019655
avg_episode_per_sec: 0.1548490382775565
collect_time: 38.747415332637736
reward_mean: -103.89028944911297
reward_std: 1.412704911758077
reward_max: -101.70238095238093
reward_min: -105.7016806722689
queue_len: 0.06889276488667968
wait_time: 0.654117349857715
delay_time: 4.409011030132076
pressure: 0.8444960212201592
total_envstep_count: 952128
total_train_sample_count: 952128
total_episode_count: 8208
total_duration: 56740.6851568272
[2024-12-28 03:56:17][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.514993393969966
avg_train_sample_per_sec: 17.514993393969966
avg_episode_per_sec: 0.15099132236181007
collect_time: 39.73738295782731
reward_mean: -101.71860410830999
reward_std: 3.4027661124273805
reward_max: -95.63725490196079
reward_min: -105.09943977591034
queue_len: 0.0674526552442374
wait_time: 0.6338757098772313
delay_time: 4.289133954774218
pressure: 0.8255968169761275
total_envstep_count: 952824
total_train_sample_count: 952824
total_episode_count: 8214
total_duration: 56780.42253978503
[2024-12-28 03:56:57][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.37013567704718
avg_train_sample_per_sec: 17.37013567704718
avg_episode_per_sec: 0.14974254894006192
collect_time: 40.06877165154739
reward_mean: -103.72198879551821
reward_std: 4.126846042480404
reward_max: -97.76120448179272
reward_min: -110.72478991596645
queue_len: 0.06878115967872563
wait_time: 0.6585523024417549
delay_time: 4.376035305656283
pressure: 0.8459328028293545
total_envstep_count: 953520
total_train_sample_count: 953520
total_episode_count: 8220
total_duration: 56820.49131143658
[2024-12-28 03:57:38][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.535358243268984
avg_train_sample_per_sec: 17.535358243268984
avg_episode_per_sec: 0.15116688140749124
collect_time: 39.69123358327523
reward_mean: -103.91071428571428
reward_std: 3.188469830672373
reward_max: -99.07142857142858
reward_min: -108.72619047619051
queue_len: 0.06890630920803334
wait_time: 0.6574097808884826
delay_time: 4.386082402069183
pressure: 0.8469274977895668
total_envstep_count: 954216
total_train_sample_count: 954216
total_episode_count: 8226
total_duration: 56860.18254501985
[2024-12-28 03:58:18][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.520563257814885
avg_train_sample_per_sec: 17.520563257814885
avg_episode_per_sec: 0.15103933842943867
collect_time: 39.72475026963278
reward_mean: -104.06991129785246
reward_std: 2.478333279441858
reward_max: -101.2079831932773
reward_min: -108.50560224089637
queue_len: 0.06901187751846981
wait_time: 0.648639407133322
delay_time: 4.348898442179213
pressure: 0.8515694076038903
total_envstep_count: 954912
total_train_sample_count: 954912
total_episode_count: 8232
total_duration: 56899.907295289486
[2024-12-28 03:58:59][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.101732659046128
avg_train_sample_per_sec: 17.101732659046128
avg_episode_per_sec: 0.14742872981936317
collect_time: 40.69763069485501
reward_mean: -104.67448646125116
reward_std: 3.3291668436538675
reward_max: -99.35364145658262
reward_min: -110.08053221288515
queue_len: 0.06941278943053791
wait_time: 0.6554799085858923
delay_time: 4.412474573447571
pressure: 0.8527851458885941
total_envstep_count: 955608
total_train_sample_count: 955608
total_episode_count: 8238
total_duration: 56940.60492598434
[2024-12-28 03:59:40][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.273152180414552
avg_train_sample_per_sec: 17.273152180414552
avg_episode_per_sec: 0.14890648431391854
collect_time: 40.29374561923741
reward_mean: -102.47700746965454
reward_std: 2.4240860192976883
reward_max: -98.97829131652661
reward_min: -106.43347338935575
queue_len: 0.067955575245129
wait_time: 0.6431054296165857
delay_time: 4.34095239338363
pressure: 0.8394120247568524
total_envstep_count: 956304
total_train_sample_count: 956304
total_episode_count: 8244
total_duration: 56980.89867160358
[2024-12-28 04:00:21][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.437545927629348
avg_train_sample_per_sec: 17.437545927629348
avg_episode_per_sec: 0.15032367178990816
collect_time: 39.913873367765916
reward_mean: -101.95273109243696
reward_std: 3.402660770180316
reward_max: -96.89075630252101
reward_min: -106.37955182072828
queue_len: 0.06760791186501126
wait_time: 0.6396604508293149
delay_time: 4.32141698870309
pressure: 0.8363174182139699
total_envstep_count: 957000
total_train_sample_count: 957000
total_episode_count: 8250
total_duration: 57020.81254497135
[2024-12-28 04:01:02][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.116279073914686
avg_train_sample_per_sec: 17.116279073914686
avg_episode_per_sec: 0.1475541299475404
collect_time: 40.66304346840828
reward_mean: -105.59372082166199
reward_std: 2.2048541249413707
reward_max: -103.27591036414567
reward_min: -108.65196078431376
queue_len: 0.07002236128757428
wait_time: 0.6678226551451704
delay_time: 4.452216501313757
pressure: 0.8601900972590628
total_envstep_count: 957696
total_train_sample_count: 957696
total_episode_count: 8256
total_duration: 57061.47558843975
[2024-12-28 04:01:43][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.34906280052673
avg_train_sample_per_sec: 17.34906280052673
avg_episode_per_sec: 0.14956088621143734
collect_time: 40.11744080947525
reward_mean: -101.17016806722688
reward_std: 1.7781401407096138
reward_max: -98.50070028011206
reward_min: -104.2598039215686
queue_len: 0.06708897086686133
wait_time: 0.6366959471675496
delay_time: 4.249330805851882
pressure: 0.8271441202475686
total_envstep_count: 958392
total_train_sample_count: 958392
total_episode_count: 8262
total_duration: 57101.59302924923
[2024-12-28 04:02:24][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.445653513039538
avg_train_sample_per_sec: 17.445653513039538
avg_episode_per_sec: 0.15039356476758223
collect_time: 39.8953240404427
reward_mean: -103.36087768440711
reward_std: 3.405229150201334
reward_max: -99.56582633053222
reward_min: -109.43557422969191
queue_len: 0.06854169607719306
wait_time: 0.6512520680243806
delay_time: 4.285149103214418
pressure: 0.8419540229885056
total_envstep_count: 959088
total_train_sample_count: 959088
total_episode_count: 8268
total_duration: 57141.48835328967
[2024-12-28 04:03:04][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.422583700099946
avg_train_sample_per_sec: 17.422583700099946
avg_episode_per_sec: 0.1501946870698271
collect_time: 39.94815074391104
reward_mean: -101.75396825396824
reward_std: 3.546761694510467
reward_max: -96.75280112044813
reward_min: -106.40126050420169
queue_len: 0.0674761062692097
wait_time: 0.64309103393789
delay_time: 4.221143341649636
pressure: 0.8300176834659593
total_envstep_count: 959784
total_train_sample_count: 959784
total_episode_count: 8274
total_duration: 57181.43650403358
[2024-12-28 04:03:44][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.639758554088882
avg_train_sample_per_sec: 17.639758554088882
avg_episode_per_sec: 0.15206688408697314
collect_time: 39.45632236778364
reward_mean: -102.39239028944912
reward_std: 3.776028064147965
reward_max: -96.75840336134452
reward_min: -108.48249299719885
queue_len: 0.06789946305666388
wait_time: 0.6419444103901507
delay_time: 4.257111279010764
pressure: 0.8293545534924845
total_envstep_count: 960480
total_train_sample_count: 960480
total_episode_count: 8280
total_duration: 57220.89282640137
[2024-12-28 04:04:25][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.29292607865954
avg_train_sample_per_sec: 17.29292607865954
avg_episode_per_sec: 0.14907694895396154
collect_time: 40.24767103231326
reward_mean: -100.59920634920634
reward_std: 2.9756722420963544
reward_max: -96.20378151260503
reward_min: -105.94747899159664
queue_len: 0.06671034903793524
wait_time: 0.6339503197388593
delay_time: 4.23737365262305
pressure: 0.8183023872679045
total_envstep_count: 961176
total_train_sample_count: 961176
total_episode_count: 8286
total_duration: 57261.14049743368
[2024-12-28 04:05:07][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 16.962855825230065
avg_train_sample_per_sec: 16.962855825230065
avg_episode_per_sec: 0.14623151573474194
collect_time: 41.030826835466556
reward_mean: -103.7396125116713
reward_std: 4.206667256020661
reward_max: -98.48459383753504
reward_min: -111.34313725490188
queue_len: 0.06879284649315073
wait_time: 0.6473282394301664
delay_time: 4.29150869580135
pressure: 0.8391909814323607
total_envstep_count: 961872
total_train_sample_count: 961872
total_episode_count: 8292
total_duration: 57302.17132426914
[2024-12-28 04:05:49][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.073120258518742
avg_train_sample_per_sec: 17.073120258518742
avg_episode_per_sec: 0.14718207119412707
collect_time: 40.765834801211945
reward_mean: -103.60644257703082
reward_std: 1.7303384518281313
reward_max: -101.80882352941178
reward_min: -106.4488795518208
queue_len: 0.06870453751792495
wait_time: 0.6519125665297064
delay_time: 4.334192555921641
pressure: 0.8448275862068967
total_envstep_count: 962568
total_train_sample_count: 962568
total_episode_count: 8298
total_duration: 57342.93715907035
[2024-12-28 04:06:29][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.41532026779066
avg_train_sample_per_sec: 17.41532026779066
avg_episode_per_sec: 0.1501320712740574
collect_time: 39.964811975765976
reward_mean: -100.33846872082167
reward_std: 3.2224063507906937
reward_max: -95.43417366946778
reward_min: -104.13515406162462
queue_len: 0.06653744610134063
wait_time: 0.6265697481468272
delay_time: 4.199634025672075
pressure: 0.8201812555260831
total_envstep_count: 963264
total_train_sample_count: 963264
total_episode_count: 8304
total_duration: 57382.90197104612
[2024-12-28 04:07:10][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.372216747066417
avg_train_sample_per_sec: 17.372216747066417
avg_episode_per_sec: 0.14976048919884843
collect_time: 40.06397169305011
reward_mean: -104.19747899159665
reward_std: 3.680603763572367
reward_max: -99.4110644257703
reward_min: -109.57913165266108
queue_len: 0.06909647147983862
wait_time: 0.6558798917444962
delay_time: 4.301592823971908
pressure: 0.8574270557029177
total_envstep_count: 963960
total_train_sample_count: 963960
total_episode_count: 8310
total_duration: 57422.965942739174
[2024-12-28 04:07:51][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.28519756274097
avg_train_sample_per_sec: 17.28519756274097
avg_episode_per_sec: 0.1490103238167325
collect_time: 40.2656664740853
reward_mean: -101.28699813258636
reward_std: 1.905826634394944
reward_max: -98.94887955182074
reward_min: -104.68977591036416
queue_len: 0.06716644438500421
wait_time: 0.6346544696570052
delay_time: 4.228202473624388
pressure: 0.834106984969054
total_envstep_count: 964656
total_train_sample_count: 964656
total_episode_count: 8316
total_duration: 57463.23160921326
[2024-12-28 04:08:32][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.324365193006177
avg_train_sample_per_sec: 17.324365193006177
avg_episode_per_sec: 0.1493479758017774
collect_time: 40.17463221572899
reward_mean: -102.71755368814193
reward_std: 3.281708009820656
reward_max: -97.16666666666666
reward_min: -106.57072829131653
queue_len: 0.06811508865261401
wait_time: 0.6458543076824009
delay_time: 4.341220944325557
pressure: 0.8345490716180372
total_envstep_count: 965352
total_train_sample_count: 965352
total_episode_count: 8322
total_duration: 57503.40624142899
[2024-12-28 04:09:12][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.339543489920928
avg_train_sample_per_sec: 17.339543489920928
avg_episode_per_sec: 0.14947882318897351
collect_time: 40.13946505596117
reward_mean: -102.00536881419232
reward_std: 0.8438019552559123
reward_max: -100.84803921568626
reward_min: -103.00770308123245
queue_len: 0.06764281751604266
wait_time: 0.648932583643537
delay_time: 4.305992988935377
pressure: 0.8394120247568523
total_envstep_count: 966048
total_train_sample_count: 966048
total_episode_count: 8328
total_duration: 57543.54570648495
[2024-12-28 04:09:53][sample_serial_collector.py:386][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 17.465408154231834
avg_train_sample_per_sec: 17.465408154231834
avg_episode_per_sec: 0.15056386339855032
collect_time: 39.85019954036176
reward_mean: -100.89390756302521
reward_std: 2.5091291713545063
reward_max: -98.5714285714286
reward_min: -104.97058823529409
queue_len: 0.06690577424603793
wait_time: 0.6342798724264243
delay_time: 4.293379429017047
pressure: 0.8288019451812555
total_envstep_count: 966744
total_train_sample_count: 966744
total_episode_count: 8334
total_duration: 57583.39590602531
