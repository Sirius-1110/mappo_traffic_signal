{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_obs_shape: 10\n",
      "global_obs_shape: 5\n",
      "action_shape: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "agent_obs_shape = (1, 10)  # 假设原始形状\n",
    "global_obs_shape = (1, 5, 1)  # 假设原始形状\n",
    "action_shape = (1,)  # 假设原始形状\n",
    "\n",
    "# 使用自定义的 squeeze 函数\n",
    "def squeeze(shape):\n",
    "    if isinstance(shape, (list, tuple)):\n",
    "        return int(np.prod([dim for dim in shape if dim != 1]))\n",
    "    return shape\n",
    "\n",
    "agent_obs_shape = squeeze(agent_obs_shape)  # 结果为 10\n",
    "global_obs_shape = squeeze(global_obs_shape)  # 结果为 (5,)\n",
    "action_shape = squeeze(action_shape)  # 结果为 1\n",
    "\n",
    "print(f\"agent_obs_shape: {agent_obs_shape}\")\n",
    "print(f\"global_obs_shape: {global_obs_shape}\")\n",
    "print(f\"action_shape: {action_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TestNNLinear(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # 初始化一个简单的 nn.Linear 层\n",
    "        self.linear = nn.Linear(in_features=3, out_features=2, bias=True)\n",
    "        # 设置固定的权重和偏置以便测试\n",
    "        self.linear.weight.data = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        self.linear.bias.data = torch.tensor([0.1, 0.2])\n",
    "\n",
    "    def test_forward(self):\n",
    "        # 创建一个输入张量\n",
    "        input_tensor = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "        # 计算期望的输出\n",
    "        expected_output = torch.tensor([[14.1, 32.2]])\n",
    "        # 获取实际输出\n",
    "        output = self.linear(input_tensor)\n",
    "        # 检查输出是否与期望输出一致\n",
    "        self.assertTrue(torch.allclose(output, expected_output, atol=1e-6))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest_main = TestNNLinear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest_main.setUp()\n",
    "unittest_main.test_forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential 是 PyTorch 中用于按顺序堆叠多个模块的容器。\n",
    "# 可以简化模型的定义，特别是在需要连续应用多个层时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNNSequential(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # 初始化一个 nn.Sequential 模型\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=3, out_features=4, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4, out_features=2, bias=True)\n",
    "        )\n",
    "        # 设置固定的权重和偏置以便测试\n",
    "        self.model[0].weight.data = torch.tensor([\n",
    "            [1.0, 2.0, 3.0],\n",
    "            [4.0, 5.0, 6.0],\n",
    "            [7.0, 8.0, 9.0],\n",
    "            [10.0, 11.0, 12.0]\n",
    "        ])\n",
    "        self.model[0].bias.data = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
    "        self.model[2].weight.data = torch.tensor([\n",
    "            [13.0, 14.0, 15.0, 16.0],\n",
    "            [17.0, 18.0, 19.0, 20.0]\n",
    "        ])\n",
    "        self.model[2].bias.data = torch.tensor([0.5, 0.6])\n",
    "\n",
    "    def test_forward(self):\n",
    "        # 创建一个输入张量\n",
    "        input_tensor = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "        \n",
    "        # 计算每一层的输出\n",
    "        # 第一层输出: [10.1, 25.2, 40.3, 55.4]\n",
    "        first_layer_output = self.model[0](input_tensor)\n",
    "        print(f\"First Layer Output: {first_layer_output}\")\n",
    "        \n",
    "        # ReLU 后: [10.1, 25.2, 40.3, 55.4]\n",
    "        relu_output = self.model[1](first_layer_output)\n",
    "        print(f\"ReLU Output: {relu_output}\")\n",
    "        \n",
    "        # 第二层输出: [2483.5, 3144.6]\n",
    "        second_layer_output = self.model[2](relu_output)\n",
    "        print(f\"Second Layer Output: {second_layer_output}\")\n",
    "        \n",
    "        # 计算期望的输出\n",
    "        expected_output = torch.tensor([[2483.5, 3143.6]])\n",
    "        \n",
    "        # 获取实际输出\n",
    "        output = self.model(input_tensor)\n",
    "        print(f\"Model Output: {output}\")\n",
    "        \n",
    "        # 检查输出是否与期望输出一致\n",
    "        self.assertTrue(torch.allclose(output, expected_output, atol=1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Layer Output: tensor([[14.1000, 32.2000, 50.3000, 68.4000]], grad_fn=<AddmmBackward0>)\n",
      "ReLU Output: tensor([[14.1000, 32.2000, 50.3000, 68.4000]], grad_fn=<ReluBackward0>)\n",
      "Second Layer Output: tensor([[2483.5000, 3143.6001]], grad_fn=<AddmmBackward0>)\n",
      "Model Output: tensor([[2483.5000, 3143.6001]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sequential_test = TestNNSequential()\n",
    "\n",
    "sequential_test.setUp()\n",
    "sequential_test.test_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_test.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.1000, 0.2000, 0.3000, 0.4000], requires_grad=True)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_test.model[0]._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[13., 14., 15., 16.],\n",
       "         [17., 18., 19., 20.]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.5000, 0.6000], requires_grad=True)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_test.model[2]._parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_test.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
